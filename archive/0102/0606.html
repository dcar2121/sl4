<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: partial Transcendance?</title>
<meta name="Author" content="Brian Phillips (deepbluehalo@earthlink.net)">
<meta name="Subject" content="partial Transcendance?">
<meta name="Date" content="2001-02-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>partial Transcendance?</h1>
<!-- received="Mon Feb 26 11:37:08 2001" -->
<!-- isoreceived="20010226183708" -->
<!-- sent="Mon, 26 Feb 2001 11:12:37 -0500" -->
<!-- isosent="20010226161237" -->
<!-- name="Brian Phillips" -->
<!-- email="deepbluehalo@earthlink.net" -->
<!-- subject="partial Transcendance?" -->
<!-- id="000e01c0a00f$30d6a1e0$6159f7a5@computer" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="3A99D62E.6C477894@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brian Phillips (<a href="mailto:deepbluehalo@earthlink.net?Subject=Re:%20partial%20Transcendance?"><em>deepbluehalo@earthlink.net</em></a>)<br>
<strong>Date:</strong> Mon Feb 26 2001 - 09:12:37 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0607.html">Eliezer S. Yudkowsky: "Re: partial Transcendance?"</a>
<li><strong>Previous message:</strong> <a href="0605.html">Brian Phillips: "Re: Military in or out?"</a>
<li><strong>In reply to:</strong> <a href="0600.html">Eliezer S. Yudkowsky: "Re: Military in or out?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0607.html">Eliezer S. Yudkowsky: "Re: partial Transcendance?"</a>
<li><strong>Reply:</strong> <a href="0607.html">Eliezer S. Yudkowsky: "Re: partial Transcendance?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#606">[ date ]</a>
<a href="index.html#606">[ thread ]</a>
<a href="subject.html#606">[ subject ]</a>
<a href="author.html#606">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eliezar,
<br>
&nbsp;&nbsp;I have a few questions on (heehee) what you think of the possibilities
<br>
inherent in superhuman AI are. I have been candid about some of the issues
<br>
that worry me.  I'll also cast some of the questions in SF terms for the
<br>
general consumption.
<br>
&nbsp;&nbsp;Much of the dialogue has concerned Friendly vs. Unfriendly AI.
<br>
My question is...is there any reason to believe a truly transintelligent AI
<br>
would be anything but Neutral and Remote (and from our perspective,
<br>
utterly Unknowable)? I realize this is a question with a dozen logical
<br>
contradictions bound up in it. Still I'd like your instinct.
<br>
&nbsp;&nbsp;What reason is there to think a prehuman AI evolving inside a system at
<br>
hyper-speeds would even slow down to say &quot;Bye&quot; as they zoomed up
<br>
into the 300+ IQ equiv. range and onwards?
<br>
&nbsp;&nbsp;I know from my personal experience that the one commonality to highly
<br>
intelligent people is &quot;curiousity&quot;. Curious Primates have other things
<br>
pulling at them..they can't scratch the curious itch all the time, they have
<br>
jobs!
<br>
. Perhaps even more compelling than normal curiousity is the curiousity
<br>
about your own mental substrata. Your CaTAI doc suggests, very astutely,
<br>
&nbsp;that the seed AI  should be designed to rewrite it's own code. Isn't this
<br>
the
<br>
&nbsp;functional equivalent of &quot;curiousity&quot; and a powerful desire to explore
<br>
oneSelf?
<br>
&nbsp;&nbsp;What sort of &quot;Supergoal&quot; could be more powerful that the MetaGoal of
<br>
&quot;Know and Improve Thyself ASAP&quot;.
<br>
(Granted one could dismasturbate about an AI converting the planet into
<br>
a solid mass of computronium in a mad rush &quot;Upwards and Onward&quot;
<br>
but my question is a basic functional one, not a horror scenario).
<br>
<p>&nbsp;&nbsp;Niven uses a similar situation as a plot device. The AIs lock(from the
<br>
human perspective of course) as they fall into Transcendance.
<br>
&nbsp;&nbsp;Obviously Niven wanted a non-AI world to tell space-opera stories
<br>
in ..but what basic rational keeps hyper-evolutionary artificial
<br>
intelligences playing in the same basic league as us?
<br>
&nbsp;&nbsp;Put another way Vinge deliberatly invented a galaxy where Powers and
<br>
humans neccessarily coexisted, because of the Zones.  But he also &quot;defined&quot;
<br>
the half-life of a Singular intelligence as ten years. Is there any reason
<br>
<p>to think that the half-life of a hyper-evolutionary AI isn't measured in the
<br>
milliseconds as they vanish into a techno-diety-ridden plenun? Is there
<br>
a general principle here I am missing because I want to miss it?
<br>
<p><p>brian
<br>
d e e p b l u e h a l o
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0607.html">Eliezer S. Yudkowsky: "Re: partial Transcendance?"</a>
<li><strong>Previous message:</strong> <a href="0605.html">Brian Phillips: "Re: Military in or out?"</a>
<li><strong>In reply to:</strong> <a href="0600.html">Eliezer S. Yudkowsky: "Re: Military in or out?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0607.html">Eliezer S. Yudkowsky: "Re: partial Transcendance?"</a>
<li><strong>Reply:</strong> <a href="0607.html">Eliezer S. Yudkowsky: "Re: partial Transcendance?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#606">[ date ]</a>
<a href="index.html#606">[ thread ]</a>
<a href="subject.html#606">[ subject ]</a>
<a href="author.html#606">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
