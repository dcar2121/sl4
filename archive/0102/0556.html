<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Six theses on superintelligence</title>
<meta name="Author" content="Mitchell Porter (mitchtemporarily@hotmail.com)">
<meta name="Subject" content="Re: Six theses on superintelligence">
<meta name="Date" content="2001-02-10">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Six theses on superintelligence</h1>
<!-- received="Sat Feb 10 02:01:21 2001" -->
<!-- isoreceived="20010210090121" -->
<!-- sent="Sat, 10 Feb 2001 05:12:40 " -->
<!-- isosent="20010210121240" -->
<!-- name="Mitchell Porter" -->
<!-- email="mitchtemporarily@hotmail.com" -->
<!-- subject="Re: Six theses on superintelligence" -->
<!-- id="F49IhTrBoe2U8QVjp3b000065b5@hotmail.com" -->
<!-- inreplyto="Six theses on superintelligence" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Mitchell Porter (<a href="mailto:mitchtemporarily@hotmail.com?Subject=Re:%20Six%20theses%20on%20superintelligence"><em>mitchtemporarily@hotmail.com</em></a>)<br>
<strong>Date:</strong> Sat Feb 10 2001 - 05:12:40 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0557.html">Eliezer S. Yudkowsky: "Re: Learning to be evil"</a>
<li><strong>Previous message:</strong> <a href="0555.html">Gordon Worley: "Re: Learning to be evil"</a>
<li><strong>Maybe in reply to:</strong> <a href="0548.html">Mitchell Porter: "Six theses on superintelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0558.html">Anders Sandberg: "Re: Six theses on superintelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#556">[ date ]</a>
<a href="index.html#556">[ thread ]</a>
<a href="subject.html#556">[ subject ]</a>
<a href="author.html#556">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I said
<br>
<p><em>&gt;2. Self-enhancement: It seems likely to me that there is
</em><br>
<em>&gt;an optimal strategy of intelligence increase which
</em><br>
<em>&gt;cannot be bettered except by luck or by working solely
</em><br>
<em>&gt;within a particular problem domain, and that this
</em><br>
<em>&gt;strategy is in some way isomorphic to calculating
</em><br>
<em>&gt;successive approximations to Chaitin's halting
</em><br>
<em>&gt;probability for a Turing machine given random
</em><br>
<em>&gt;input.
</em><br>
<p>Anders said
<br>
<p><em>&gt;Why is this isomorphic to Chaitin approximations? I
</em><br>
<em>&gt;might have had too
</em><br>
<em>&gt;little sleep for the last nights, but it doesn't
</em><br>
<em>&gt;seem clear to me.
</em><br>
<p>If you know the halting probability for a Turing
<br>
machine, you can solve the halting problem for
<br>
any program on that machine. (&quot;... knowing Omega_N
<br>
[first N bits of the halting probability] enables
<br>
one to solve the halting problem for all N-bit
<br>
programs&quot; --<a href="http://www.cs.umaine.edu/~chaitin/nv.html">http://www.cs.umaine.edu/~chaitin/nv.html</a>)
<br>
<p>The idea is that a superintelligence would have
<br>
a 'computational core' which spends its time
<br>
approximating Omega, and modules which take general
<br>
problems, encode them as halting problems, and look
<br>
them up in Approximate Omega.
<br>
<p>What I don't know yet is the most rapid way of
<br>
approximating Omega. Chaitin says somewhere that
<br>
you cannot know how rapidly you are converging,
<br>
it's another aspect of the noncomputability.
<br>
I think the Resource Bounded Probability method
<br>
of induction (<a href="http://world.std.com/~rjs/isis96.html">http://world.std.com/~rjs/isis96.html</a>)
<br>
might amount to an Omega approximation strategy,
<br>
but I'm not sure yet.
<br>
<p><em>&gt;I'm not as certain as you are that there exists an
</em><br>
<em>&gt;unique optimal
</em><br>
<em>&gt;strategy. Without working within a certain problem
</em><br>
<em>&gt;domain the no free
</em><br>
<em>&gt;lunch theorems get you. Taking the problem domain to
</em><br>
<em>&gt;be 'the entire
</em><br>
<em>&gt;physical universe' doesn't really help, since you
</em><br>
<em>&gt;also have to include
</em><br>
<em>&gt;the probability distribution of the environment, and
</em><br>
<em>&gt;this will be very
</em><br>
<em>&gt;dependent not just on the interests but also actions
</em><br>
<em>&gt;of the being.
</em><br>
<p>I think approximating Omega is precisely the sort of
<br>
task where a no-free-lunch theorem is likely to apply.
<br>
The optimal strategy probably involves nothing more
<br>
intelligent than simulating all possible programs, and
<br>
incrementing Approximate Omega appropriately when one
<br>
is seen to terminate. The no-free-lunch theorem might
<br>
be: even if you have an approximation strategy which
<br>
outperforms blind simulation in calculating some finite
<br>
number of Omega bits, its asymptotic performance can't
<br>
beat blind simulation.
<br>
<p>Even if you decide to approximate Omega by blind
<br>
simulation, you still have decisions to make - you can't
<br>
let all the nonterminating programs run forever. If
<br>
there's no free lunch, that might mean even if you cull
<br>
them randomly, you'll still be converging on Omega as
<br>
fast as possible.
<br>
<p><em>&gt; &gt; 3. If this is so, then once this strategy is
</em><br>
<em>&gt;known,
</em><br>
<em>&gt; &gt; winning the intelligence race may after all boil
</em><br>
<em>&gt;down
</em><br>
<em>&gt; &gt; to hardware issues of speed and size (and possibly
</em><br>
<em>&gt;to
</em><br>
<em>&gt; &gt; issues of physics, if there are physical processes
</em><br>
<em>&gt; &gt; which can act as oracles that compute trans-Turing
</em><br>
<em>&gt; &gt; functions).
</em><br>
<em>&gt;
</em><br>
<em>&gt;What if this strategy is hard to compute
</em><br>
<em>&gt;efficiently, and different
</em><br>
<em>&gt;choices in initial conditions will produce
</em><br>
<em>&gt;noticeable differences in
</em><br>
<em>&gt;performance?
</em><br>
<p>If the No-Free-Omega Hypothesis :) is correct, then
<br>
such differences in performance will disappear
<br>
asymptotically (assuming hardware equality, and assuming
<br>
no-one pursues a *sub*optimal strategy).
<br>
<p><em>&gt; &gt; 5. Initial conditions: For an entity with goals or
</em><br>
<em>&gt;values,
</em><br>
<em>&gt; &gt; intelligence is just another tool for the
</em><br>
<em>&gt;realization
</em><br>
<em>&gt; &gt; of goals. It seems that a self-enhancing
</em><br>
<em>&gt;intelligence
</em><br>
<em>&gt; &gt; could still reach superintelligence having started
</em><br>
<em>&gt;with
</em><br>
<em>&gt; &gt; almost *any* set of goals; the only constraint is
</em><br>
<em>&gt;that
</em><br>
<em>&gt; &gt; the pursuit of those goals should not hinder the
</em><br>
<em>&gt;process
</em><br>
<em>&gt; &gt; of self-enhancement.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Some goals are not much helped by intelligence
</em><br>
<em>&gt;beyond a certain level
</em><br>
<em>&gt;(like, say, gardening), so the self-enhancement
</em><br>
<em>&gt;process would peter
</em><br>
<em>&gt;out before it reached any strong limits.
</em><br>
<p>Only if self-enhancement was strictly a subgoal of
<br>
the gardening goal. But perhaps this is more precise:
<br>
self-enhancement will not be hindered if it is a
<br>
subgoal of an open-ended goal, or a co-goal of just
<br>
about anything.
<br>
<p>Ben Goertzel said
<br>
<p><em>&gt;My intuition is that there's going to be a huge diversity of possible ways
</em><br>
<em>&gt;to achieve intelligence increase by self-enhancement, each one with its own
</em><br>
<em>&gt;advantages and disadvantages in various environments.
</em><br>
<p>This is surely true. Assuming that calculating Omega
<br>
really is a meta-solution to all problems, the real
<br>
question is then: What's more important - solving
<br>
environment-specific problems which Approximate Omega
<br>
can't yet solve for you, by domain-specific methods,
<br>
or continuing to calculate Omega? My guess is that in
<br>
most environments, even such a stupid process as
<br>
approximating Omega by blind simulation and random
<br>
culling always deserves its share of CPU time.
<br>
<p>(Okay, that's a retreat from 'You don't have to do
<br>
anything *but* approximate Omega!' But this is what
<br>
I want a general theory of self-enhancement to tell me -
<br>
in what sort of environments will you *always* need
<br>
domain-specific modules that do something more than
<br>
consult the Omega module? Maybe this will even prove
<br>
to be true in the majority of environments.)
<br>
<p>_________________________________________________________________________
<br>
Get Your Private, Free E-mail from MSN Hotmail at <a href="http://www.hotmail.com">http://www.hotmail.com</a>.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0557.html">Eliezer S. Yudkowsky: "Re: Learning to be evil"</a>
<li><strong>Previous message:</strong> <a href="0555.html">Gordon Worley: "Re: Learning to be evil"</a>
<li><strong>Maybe in reply to:</strong> <a href="0548.html">Mitchell Porter: "Six theses on superintelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0558.html">Anders Sandberg: "Re: Six theses on superintelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#556">[ date ]</a>
<a href="index.html#556">[ thread ]</a>
<a href="subject.html#556">[ subject ]</a>
<a href="author.html#556">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
