<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Beyond evolution</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: Beyond evolution">
<meta name="Date" content="2001-02-04">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Beyond evolution</h1>
<!-- received="Sun Feb 04 23:04:19 2001" -->
<!-- isoreceived="20010205060419" -->
<!-- sent="Sun, 04 Feb 2001 20:03:14 -0800" -->
<!-- isosent="20010205040314" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Beyond evolution" -->
<!-- id="3A7E2602.E85D1653@objectent.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3A76F04F.FB8E2922@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20Beyond%20evolution"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Sun Feb 04 2001 - 21:03:14 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0539.html">Eliezer S. Yudkowsky: "Re: Beyond evolution"</a>
<li><strong>Previous message:</strong> <a href="0537.html">Ben Goertzel: "RE: Beyond evolution"</a>
<li><strong>In reply to:</strong> <a href="../0101/0534.html">Eliezer S. Yudkowsky: "Re: Beyond evolution"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0539.html">Eliezer S. Yudkowsky: "Re: Beyond evolution"</a>
<li><strong>Reply:</strong> <a href="0539.html">Eliezer S. Yudkowsky: "Re: Beyond evolution"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#538">[ date ]</a>
<a href="index.html#538">[ thread ]</a>
<a href="subject.html#538">[ subject ]</a>
<a href="author.html#538">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&quot;Eliezer S. Yudkowsky&quot; wrote:
<br>
<em>&gt; 
</em><br>
<p><em>&gt; Advice - freely offered, freely rejected.
</em><br>
<p>What does it mean to reject the advice of a Being that controls all the
<br>
material local universe to a very fine level and will not allow
<br>
disagreement that leads to possible actions that it decides are possibly
<br>
harmful to the sentiences in its care?  Where is the freedom?  I see
<br>
freedom to disagree but not to fully act on one's disagreement?
<br>
<p><em>&gt; 
</em><br>
<em>&gt; Build another SI of equal intelligence - sure, as long as you build ver
</em><br>
<em>&gt; inside the Sysop.
</em><br>
<em>&gt; 
</em><br>
<p>What for?  That would rather defeat the purpose of having more than one
<br>
local Entity of such power.  A single entitity is a single point of
<br>
failure of Friendliness and a great danger.
<br>
<p><em>&gt; Build an Ultraweapon of Megadeath and Destruction so you can see how it
</em><br>
<em>&gt; works - sure, as long as there's a bit of Sysop somewhere inside the
</em><br>
<em>&gt; trigger making sure you don't point it at the Amish communities on Old
</em><br>
<em>&gt; Earth.
</em><br>
<p>Building ultra-weapons is not at all the point or anything I intend.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; Build an Ultraweapon that you can aim anywhere, with no Sysopmatter
</em><br>
<em>&gt; (visible or not) anywhere near it - you might still be able to get away
</em><br>
<em>&gt; with this, as long as the Sysop can predict the future with total
</em><br>
<em>&gt; certainty and predict that you'll never abuse the Ultraweapon, regardless
</em><br>
<em>&gt; of any external influences you encounter.  Probably no human, even Gandhi,
</em><br>
<em>&gt; is subject to this prediction, but an uploaded Gandhi turned transhuman
</em><br>
<em>&gt; might be.
</em><br>
<em>&gt; 
</em><br>
<p>Again, the Sysop abrogates all decisions and all wisdom to itself.  How
<br>
about upgrading its uploads to their own ever-increasing wisdom.  Why
<br>
have Cosmic Mom for all time?
<br>
<p><em>&gt; 
</em><br>
<em>&gt; Under absolutely none of these circumstances does the Sysop need to strike
</em><br>
<em>&gt; back at you.  Ve just gives you an API error.
</em><br>
<em>&gt; 
</em><br>
<p>Err.  Already assumes precisely my point.  This being is effectively
<br>
God.  You exist only within it and as it allows.  Are you really willing
<br>
to take on the building of such?  Are you so convinced it is the Only
<br>
Answer?
<br>
<p><p><em>&gt; &gt; What if onery sentiences simply do not want to have to pass all
</em><br>
<em>&gt; &gt; decisions through this Sysop, no matter how intelligent and benign it
</em><br>
<em>&gt; &gt; may be?  This is not an unexpected situation.  What will the Sysop do in
</em><br>
<em>&gt; &gt; those cases?  What if some group of sentients decided that what the
</em><br>
<em>&gt; &gt; Sysop considered an unacceptable risk was perfectly acceptable to them?
</em><br>
<em>&gt; &gt; Why would the Sysop want to forbid all entities that disagreed from
</em><br>
<em>&gt; &gt; going somewhere outside its territory?  Can't stand the possibility of
</em><br>
<em>&gt; &gt; competition or that something might not be under its metaphorical
</em><br>
<em>&gt; &gt; thumb?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; For all I know, it's entirely okay to fork off and run under your own
</em><br>
<em>&gt; Sysop as long as that Sysop is also Friendly.  (People who chime in about
</em><br>
<em>&gt; how this would dump us into a Darwinian regime may take this as an
</em><br>
<em>&gt; argument against Sysop splitting.)  The static uploads may even form their
</em><br>
<em>&gt; own polises with different operating systems and rules, with the
</em><br>
<em>&gt; underlying Sysop merely acting to ensure that no citizen can be trapped
</em><br>
<em>&gt; inside a polis.
</em><br>
<em>&gt; 
</em><br>
<p>But this Sysop can't be built by your earlier response except totally
<br>
within the Sysop so in no real sense is it independent. I am concerned
<br>
by the phrase &quot;static uploads&quot;.  Do you mean by this that uploads cannot
<br>
grow indefinitely in capability?  If so, then why on Earth (or beyond
<br>
it) would I or any other trans/post-human agree to such?
<br>
<p><em>&gt; &gt; How is it good for humans, being just the type of onery
</em><br>
<em>&gt; &gt; independent creatures that we are, to have a benign Sysop rule over us?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This brings up a point I keep on trying to make, which is that the Sysop
</em><br>
<em>&gt; is not a ruler; the Sysop is an operating system.  The Sysop may not even
</em><br>
<em>&gt; have a public personality as such; our compounded &quot;wishes about wishes&quot;
</em><br>
<em>&gt; may form an independent operating system and API that differs from citizen
</em><br>
<em>&gt; to citizen, ranging from genie interfaces with a personality, to an Eganic
</em><br>
<em>&gt; &quot;exoself&quot;, to transhumans that simply dispense with the appearance of an
</em><br>
<em>&gt; interface and integrate their abilities into themselves, like motor
</em><br>
<em>&gt; functions.  The fact that there's a Sysop underneath it all changes
</em><br>
<em>&gt; nothing; it just means that your interface (a) can exhibit arbitrarily
</em><br>
<em>&gt; high levels of intelligence and (b) will return some kind of error if you
</em><br>
<em>&gt; try to harm another citizen.
</em><br>
<em>&gt; 
</em><br>
<p>Let's see.  The SysOp is a super-intelligence.  Therefore it has its own
<br>
agenda and interests.  It controls all aspects of material reality and
<br>
all virtual ones that we have access to.  This is a good deal more than
<br>
just an operating system.  What precisely constitutes harm of another
<br>
citizen to the Sysop?  For entities in a VR who are playing with
<br>
designer universes of simulated beings they experience from inside, is
<br>
it really harm that in this universe these simulated beings maim and
<br>
kill one another?  In other words, does the SysOp prevent real harm or
<br>
all appearance of harm?  What is and isn't real needs answering also,
<br>
obviously.
<br>
<p><em>&gt; Things might be different in the transhuman spaces - I can guess for
</em><br>
<em>&gt; static uploads only.  And the above scenario may not be true for everyone,
</em><br>
<em>&gt; but it is certainly much more likely to be true for people who resent the
</em><br>
<em>&gt; &quot;rule&quot; of the Sysop.
</em><br>
<em>&gt; 
</em><br>
<p>Again, what does *static* mean in the above?  I don't really parse what
<br>
you had in mind with the rest of this paragraph.
<br>
<p><em>&gt; &gt; It strongly goes against the grain of the species.  How will the Sysop
</em><br>
<em>&gt; &gt; deal with the likely mass revolt?  What will &quot;Friendliness&quot; dictate?
</em><br>
<em>&gt; &gt; Simply wait it out as it holds all the cards?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Yep.  Again, for static uploads, the Sysop won't *necessarily* be a
</em><br>
<em>&gt; dominant feature of reality, or even a noticeable one.  For sysophobic
</em><br>
<em>&gt; statics, the complexity of the future would be embedded entirely in social
</em><br>
<em>&gt; interactions and so on.
</em><br>
<em>&gt; 
</em><br>
<p>If it is present at all it will be noticeable except for those who
<br>
purposefully choose to design a local space where they do not see it.  
<br>
<p><em>&gt; &gt; Will the Sysop be sure
</em><br>
<em>&gt; &gt; this is actually being &quot;Friendly&quot; to the type of creatures we are?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; If it's what we say we want.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; Are you sure?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Of course not.  You could be right and I could be wrong, in which case -
</em><br>
<em>&gt; if I've built well - the Sysop will do something else, or the seed AI will
</em><br>
<em>&gt; do something other than become Sysop.
</em><br>
<em>&gt; 
</em><br>
<p>OK.  If it is not the Sysop what are some of the alternate scenarios
<br>
that you could see occurring that are desirable outcomes?
<br>
<p><em>&gt; &gt;
</em><br>
<em>&gt; &gt; What if I simply want an extended vacation from Sysop controlled space?
</em><br>
<em>&gt; &gt; From what you have said, if I decide I want to extend that permanently
</em><br>
<em>&gt; &gt; the Sysop will say no.  Interesting.  Do you honestly think humanity
</em><br>
<em>&gt; &gt; will put up with this?  Do you honestly think it is ok to effectively
</em><br>
<em>&gt; &gt; force them to by leaving no alternative?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Yes.  I think that, if the annoyance resulting from pervasive forbiddance
</em><br>
<em>&gt; is a necessary subgoal of ruling out the space of possibilities in which
</em><br>
<em>&gt; citizenship rights are violated, then it's an acceptable tradeoff.
</em><br>
<em>&gt; 
</em><br>
<p>If the citizens have no choice then there is no morality.  There is only
<br>
that which works by the Sysop's rules and that which does not.  In such
<br>
a universe I see little impetus for the citizens to evolve. 
<br>
<p><em>&gt; Please note that in your scenario, people are not all free free free as a
</em><br>
<em>&gt; bird.  In your scenario, you can take an extended vacation from Sysop
</em><br>
<em>&gt; space, manufacture a million helpless sentients, and then refuse to let
</em><br>
<em>&gt; *them* out of Samantha space.  You can take actions that would make them
</em><br>
<em>&gt; *desperate* to leave Samantha space and they still won't be able to go,
</em><br>
<em>&gt; because the Sysop that would ensure those rights has gone away to give you
</em><br>
<em>&gt; a little personal space.  I daresay that in terms of the total integral
</em><br>
<em>&gt; over all sentients and their emotions, the Samantha scenario involves many
</em><br>
<em>&gt; many more sentients feeling much more intense desire to escape control.
</em><br>
<em>&gt; 
</em><br>
<p>The Sysop is refusing to let me out of Sysop space.  Truthfully we have
<br>
no idea how various sentiences will react to being in Sysop space no
<br>
matter how benign you think it is.  Your hypothetical space where I
<br>
torture sentients is an utter strawman.  
<br>
<p>- samantha
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0539.html">Eliezer S. Yudkowsky: "Re: Beyond evolution"</a>
<li><strong>Previous message:</strong> <a href="0537.html">Ben Goertzel: "RE: Beyond evolution"</a>
<li><strong>In reply to:</strong> <a href="../0101/0534.html">Eliezer S. Yudkowsky: "Re: Beyond evolution"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0539.html">Eliezer S. Yudkowsky: "Re: Beyond evolution"</a>
<li><strong>Reply:</strong> <a href="0539.html">Eliezer S. Yudkowsky: "Re: Beyond evolution"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#538">[ date ]</a>
<a href="index.html#538">[ thread ]</a>
<a href="subject.html#538">[ subject ]</a>
<a href="author.html#538">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
