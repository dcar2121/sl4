<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Ethical basics</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Ethical basics">
<meta name="Date" content="2002-01-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Ethical basics</h1>
<!-- received="Thu Jan 24 09:03:31 2002" -->
<!-- isoreceived="20020124160331" -->
<!-- sent="Thu, 24 Jan 2002 07:02:42 -0700" -->
<!-- isosent="20020124140242" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Ethical basics" -->
<!-- id="LAEGJLOGJIOELPNIOOAJEEIHCCAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3C4F8D9E.E1278208@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Ethical%20basics"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Thu Jan 24 2002 - 07:02:42 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2653.html">Dani Eder: "Re: Neural Nets vs. Neurons"</a>
<li><strong>Previous message:</strong> <a href="2651.html">Ben Goertzel: "RE: Ethical basics"</a>
<li><strong>In reply to:</strong> <a href="2649.html">Eliezer S. Yudkowsky: "Re: Ethical basics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2657.html">Jerry Mitchell: "RE: Ethical basics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2652">[ date ]</a>
<a href="index.html#2652">[ thread ]</a>
<a href="subject.html#2652">[ subject ]</a>
<a href="author.html#2652">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
hi,
<br>
<p><em>&gt; &gt; Yes, this is a silly topic of conversation...
</em><br>
<em>&gt;
</em><br>
<em>&gt; Rational altruism?  Why would it be?  I've often considered starting a
</em><br>
<em>&gt; third mailing list devoted solely to that.
</em><br>
<p>Not rational altruism, but the extended discussion of *your own personal
<br>
psyche*,
<br>
struck me as mildly (yet, I must admit, mildly pleasantly) absurd...
<br>
<p><em>&gt; &gt; It seems to me that you take a certain pleasure in being more altruistic
</em><br>
<em>&gt; &gt; than most others.  Doesn't this mean that your apparent
</em><br>
<em>&gt; altruism is actually
</em><br>
<em>&gt; &gt; partially ego gratification ;&gt;  And if you think you don't take this
</em><br>
<em>&gt; &gt; pleasure, how do you know you don't do it unconsciously?  Unlike a
</em><br>
<em>&gt; &gt; superhuman AI, &quot;you&quot; (i.e. the conscious, reasoning component
</em><br>
<em>&gt; of Eli) don't
</em><br>
<em>&gt; &gt; have anywhere complete knowledge of your own mind-state...
</em><br>
<em>&gt;
</em><br>
<em>&gt; No offense, Ben, but this is very simple stuff
</em><br>
<p>Of course it is... the simple traps are the hardest to avoid, even if you
<br>
think
<br>
you're avoiding them
<br>
<p>Anyway, there isn't much point to argue on &amp; on about how altruistic Eli
<br>
really
<br>
is, in the depth of his mind .
<br>
<p>As imperfect as your own knowledge about this topic is, Eli, mine is
<br>
obviously far
<br>
more so!! ;&gt;
<br>
<p>The tricks the mind plays on itself are numerous, deep and fascinating.  And
<br>
yet
<br>
all sorts of wonderful people do emerge, including some fairly (though in my
<br>
view
<br>
never completely) altruistic ones...
<br>
<p><em>&gt; It's amazing how many things the modern synthesis in neo-Darwinism doesn't
</em><br>
<em>&gt; fail to take into account.  Constraints on evolvability (or more
</em><br>
<em>&gt; generally, fitness landscapes for evolvability) is most certainly one of
</em><br>
<em>&gt; them.  I can't recall reading anything explicitly about, e.g., local
</em><br>
<em>&gt; adaptations mirroring local rules and thereby giving rise to
</em><br>
<em>&gt; un-selected-for global mirroring of Platonic forms - but I have explicitly
</em><br>
<em>&gt; written about it, and specifically in the context of the implications for
</em><br>
<em>&gt; human morality.
</em><br>
<p>I don't doubt that *you personally* are aware of the role of
<br>
self-organization and
<br>
&quot;Platonic forms&quot; in evolution and morality, but the books that you mentioned
<br>
certainly do not take this point of view at all, which is what I was saying.
<br>
My own tendency is to *emphasize* this part as opposed to the game theory
<br>
and
<br>
selectionist part, whereas the books you refer emphasize the latter part.
<br>
<p><p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2653.html">Dani Eder: "Re: Neural Nets vs. Neurons"</a>
<li><strong>Previous message:</strong> <a href="2651.html">Ben Goertzel: "RE: Ethical basics"</a>
<li><strong>In reply to:</strong> <a href="2649.html">Eliezer S. Yudkowsky: "Re: Ethical basics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2657.html">Jerry Mitchell: "RE: Ethical basics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2652">[ date ]</a>
<a href="index.html#2652">[ thread ]</a>
<a href="subject.html#2652">[ subject ]</a>
<a href="author.html#2652">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
