<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)</title>
<meta name="Author" content="Dan Clemmensen (dgc@cox.rr.com)">
<meta name="Subject" content="Re: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)">
<meta name="Date" content="2002-01-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)</h1>
<!-- received="Sat Jan 19 14:23:47 2002" -->
<!-- isoreceived="20020119212347" -->
<!-- sent="Sat, 19 Jan 2002 14:22:45 -0500" -->
<!-- isosent="20020119192245" -->
<!-- name="Dan Clemmensen" -->
<!-- email="dgc@cox.rr.com" -->
<!-- subject="Re: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)" -->
<!-- id="3C49C785.4050106@cox.rr.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="LAEGJLOGJIOELPNIOOAJEEEFCCAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Dan Clemmensen (<a href="mailto:dgc@cox.rr.com?Subject=Re:%20Steve%20Harris,%20&quot;Return%20of%20the%20Krell%20Machine&quot;%20(Singularity%20Article)"><em>dgc@cox.rr.com</em></a>)<br>
<strong>Date:</strong> Sat Jan 19 2002 - 12:22:45 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2622.html">Ben Goertzel: "RE: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)"</a>
<li><strong>Previous message:</strong> <a href="2620.html">Ben Goertzel: "RE: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)"</a>
<li><strong>In reply to:</strong> <a href="2620.html">Ben Goertzel: "RE: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2622.html">Ben Goertzel: "RE: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)"</a>
<li><strong>Reply:</strong> <a href="2622.html">Ben Goertzel: "RE: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)"</a>
<li><strong>Reply:</strong> <a href="2625.html">Damien Broderick: "&quot;Paths to the Singularity&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2621">[ date ]</a>
<a href="index.html#2621">[ thread ]</a>
<a href="subject.html#2621">[ subject ]</a>
<a href="author.html#2621">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Summary: my thesis remains:
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Human/computer collaboration --&gt; &quot;weak&quot; SI --&gt; AI-based &quot;Strong&quot; SI
<br>
<p><p>Ben Goertzel wrote:
<br>
<p><em>&gt; [Dan Clemmensen wrote]
</em><br>
<em>&gt;&gt;This whole argument misses the point: AI may not be the
</em><br>
<em>&gt;&gt;only path to SI. I feel that we'll get SI via human-computer
</em><br>
<em>&gt;&gt;collaboration.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I understand the idea....  Francis Heylighen (Principia Cybernetica; Free
</em><br>
<em>&gt; University of Brussels) is a big advocate of this as well, so you're in good
</em><br>
<em>&gt; company....  This is the &quot;global brain&quot; about which I've written a fair bit,
</em><br>
<em>&gt; going back to 1995; and Turchin wrote about it in the early 70's...
</em><br>
<em>&gt; 
</em><br>
<em>&gt; However, my intuition is that there is a *relatively* low upper limit to how
</em><br>
<em>&gt; much human collective intelligence can be accelerated through computer
</em><br>
<em>&gt; technology.
</em><br>
<p><p>I agree. I do not think that the human/computer collaboration will 
<br>
continue to operate without an &quot;AI&quot; component. I merely believe that it 
<br>
may start that way. Let's consider &quot;technical creative intelligence,&quot; 
<br>
which we define circularly as the collection of qualities that enable 
<br>
the creation of new technical stuff. If a human/computer collaboration 
<br>
is more &quot;intelligent&quot; in this regard than today's researchers, then the 
<br>
collaboration will be able to augment its own technological component 
<br>
(software) more effectively than today's researchers. So let's speculate
<br>
that this relatively low upper bound restricts the collaboration to less
<br>
than ten times the effectiveness of an unaugmented researcher. I 
<br>
speculate that this means that the collaboration can then develop an AI
<br>
component in one tenth the time it would otherwise take: 50 years 
<br>
compressed to five.
<br>
<p><p><em>&gt; 
</em><br>
<em>&gt; I tend to believe the big breakthrough in this domain has almost &quot;already
</em><br>
<em>&gt; happened&quot;.  The Net has given us the ability to interact fairly freely with
</em><br>
<em>&gt; people all over the world using our familiar media -- language, pictures,
</em><br>
<em>&gt; and sound.  The process will be massively streamlined during the next
</em><br>
<em>&gt; decade, and the Net will turn into an easy place to exchange and collaborate
</em><br>
<em>&gt; on information of these standard types.  But will this lead to a qualitative
</em><br>
<em>&gt; increase in collective intelligence?  Well, perhaps it will, but a much
</em><br>
<em>&gt; *smaller* qualitative increase than could be obtained if AI's were thrown
</em><br>
<em>&gt; into the mix....
</em><br>
<p><p>Again I agree, but I don't think you go far enough. You are talking 
<br>
mostly about existing tools( &quot;language, pictures and sound,&quot;) and not 
<br>
about newer tools (search engines, groupware) that let the computerized 
<br>
portion of the collaboration do more than just store and transmit data.
<br>
Yes, with AI we achieve a second breakthrough, but the first 
<br>
breakthrough increases our effective intelligence and dramatically 
<br>
reduces the time we need to reach the second.
<br>
<p><p><em>&gt; 
</em><br>
<em>&gt; For instance, in biotech, the presence of BLAST and various other Internet
</em><br>
<em>&gt; services and sites has made a huge qualitative difference in how fast (and
</em><br>
<em>&gt; *how*) bioscience can progress.  But an AI that could integrate all the data
</em><br>
<em>&gt; from the different sites to make judgments humans can't make (because humans
</em><br>
<em>&gt; can't integrate that much diverse data effectively), would create an even
</em><br>
<em>&gt; bigger qualitative difference...
</em><br>
<p><p>Well sure, given an AI. That misses the point. If we use un-intelligent 
<br>
software designed to properly present data, we can let humans do the 
<br>
integration. This software is easier to produce than AI software. The
<br>
DNA sequence search software is stupid and brute-force, but it can 
<br>
identify possible matches that permit a researcher to see patterns and
<br>
make inferences about protein homology. I'm suggesting that we should 
<br>
try to create a similar qualitative difference in the way we develop
<br>
software, and then apply it first to itself and then to AI.
<br>
<p><p><em>&gt; 
</em><br>
<em>&gt; If there is going to be a *truly astounding* breakthrough here, I suspect it
</em><br>
<em>&gt; will have to somehow involve going beyond &quot;technology as a  medium for
</em><br>
<em>&gt; linguistic and visual and acoustic communication.&quot;  Perhaps, if we could
</em><br>
<em>&gt; directly control some 3D graphical medium via our brain waves, and
</em><br>
<em>&gt; communicate and interact in this way, we could really achieve a hugely
</em><br>
<em>&gt; higher qualitative level of emergent intelligence -- I don't know....
</em><br>
<em>&gt; 
</em><br>
My first little paper on this subject (&quot;Paths to the Singularity,&quot; 1996) is
<br>
<p>lost, darn it. At the time, I thought that we needed new peripherals, 
<br>
but I changed my mind shortly thereafter. A good computer display can
<br>
present information as fast as a human can accept it, and a 
<br>
joystick/game controller can accept decisions as fast as a human can 
<br>
convey them: If you don't believe this, watch a kid playing a video 
<br>
game. We would all like to believe we think faster than this, but we 
<br>
don't. In any event I don't think the human/computer interface is an 
<br>
important constraint on the human/computer SI. It's a software problem, 
<br>
mostly in the data presentation.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2622.html">Ben Goertzel: "RE: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)"</a>
<li><strong>Previous message:</strong> <a href="2620.html">Ben Goertzel: "RE: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)"</a>
<li><strong>In reply to:</strong> <a href="2620.html">Ben Goertzel: "RE: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2622.html">Ben Goertzel: "RE: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)"</a>
<li><strong>Reply:</strong> <a href="2622.html">Ben Goertzel: "RE: Steve Harris, &quot;Return of the Krell Machine&quot; (Singularity Article)"</a>
<li><strong>Reply:</strong> <a href="2625.html">Damien Broderick: "&quot;Paths to the Singularity&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2621">[ date ]</a>
<a href="index.html#2621">[ thread ]</a>
<a href="subject.html#2621">[ subject ]</a>
<a href="author.html#2621">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
