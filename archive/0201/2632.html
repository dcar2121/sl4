<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Neural Nets vs. Neurons</title>
<meta name="Author" content="Dani Eder (danielravennest@yahoo.com)">
<meta name="Subject" content="Neural Nets vs. Neurons">
<meta name="Date" content="2002-01-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Neural Nets vs. Neurons</h1>
<!-- received="Tue Jan 22 10:59:23 2002" -->
<!-- isoreceived="20020122175923" -->
<!-- sent="Tue, 22 Jan 2002 07:55:54 -0800 (PST)" -->
<!-- isosent="20020122155554" -->
<!-- name="Dani Eder" -->
<!-- email="danielravennest@yahoo.com" -->
<!-- subject="Neural Nets vs. Neurons" -->
<!-- id="20020122155554.52537.qmail@web13303.mail.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Dani Eder (<a href="mailto:danielravennest@yahoo.com?Subject=Re:%20Neural%20Nets%20vs.%20Neurons"><em>danielravennest@yahoo.com</em></a>)<br>
<strong>Date:</strong> Tue Jan 22 2002 - 08:55:54 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2633.html">ben goertzel: "Re: Neural Nets vs. Neurons"</a>
<li><strong>Previous message:</strong> <a href="2631.html">Damien Broderick: "Re: Why AI does not require Reductionism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2633.html">ben goertzel: "Re: Neural Nets vs. Neurons"</a>
<li><strong>Reply:</strong> <a href="2633.html">ben goertzel: "Re: Neural Nets vs. Neurons"</a>
<li><strong>Reply:</strong> <a href="2647.html">Arona Ndiaye: "Re: Neural Nets vs. Neurons"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2632">[ date ]</a>
<a href="index.html#2632">[ thread ]</a>
<a href="subject.html#2632">[ subject ]</a>
<a href="author.html#2632">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
An interesting report on how single neurons encode
<br>
facial recognition:
<br>
<p><a href="http://www.eurekalert.org/pub_releases/2002-01/m-pis011802.php">http://www.eurekalert.org/pub_releases/2002-01/m-pis011802.php</a>
<br>
<p>This type of research should eventually resolve
<br>
Penrose's
<br>
hypothesis.  If it can be shown that all the
<br>
computation
<br>
that occurs in the brain can be explained by the
<br>
visible
<br>
neuron interactions (synapse pattern, connection
<br>
strength,
<br>
firing rates, perhaps some internal structural
<br>
features
<br>
in the neuron), then there is no reason to invoke
<br>
'spooky quantum' computation.
<br>
<p>If there is no easier way to build an AI (easier
<br>
defined by the amount of computer hardware required
<br>
to implement it), then I expect a sufficiently large
<br>
neural network will eventually work.  This is, in
<br>
fact, how I personally estimate the time to the
<br>
singularity.  
<br>
<p>If you look at chess playing computers, they beat
<br>
the best humans when they had specialized hardware
<br>
that was estimated to be 3% of a human brain in
<br>
total capacity.  The implication is that the best
<br>
human players devote 3% of their brain to chess,
<br>
and the rest to the usual stuff our brains do.
<br>
<p>Thus, I take a lower bound on 'when will the
<br>
Singularity happen' as when we have computers at
<br>
that capacity level available for specific tasks
<br>
like optimizing code and designing chips.  This
<br>
could be sufficient for a runaway acceleration
<br>
in computer power.  Specifically, 3 billion
<br>
neurons x 10,000 synapses/neuron x 100 Hz firing
<br>
rate x 1 bit/firing = 3,000 Tbits/sec = 100 Tflops.
<br>
When 100 Tflop machines reach the 100th place
<br>
in the Top500 supercomuter list I would say they
<br>
are available for specific tasks on a full time
<br>
basis. This chart: 
<br>
<p><a href="http://www.top500.org/lists/2001/11/slides/PerformanceDevelopment2.pdf">http://www.top500.org/lists/2001/11/slides/PerformanceDevelopment2.pdf</a>
<br>
<p>projects reaching that level in 2012.  
<br>
<p>If you then say that instead of taking 3% of a 
<br>
brain, it takes a full brain, that gives you a
<br>
date of 2018.  Now if you say 1 synapse firing =
<br>
1 floating point operation rather than 1 bit, you
<br>
get a date of 2024.  So if asked, I would say I
<br>
expect the singularity about 2018 +- 6 years.
<br>
Note that the 2 sigma early date would then be
<br>
2006, so I would estimate a small but non-zero
<br>
chance of a singularity in the next 4 years.
<br>
<p>Daniel
<br>
<p>&nbsp;&nbsp;
<br>
<p>__________________________________________________
<br>
Do You Yahoo!?
<br>
Send FREE video emails in Yahoo! Mail!
<br>
<a href="http://promo.yahoo.com/videomail/">http://promo.yahoo.com/videomail/</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2633.html">ben goertzel: "Re: Neural Nets vs. Neurons"</a>
<li><strong>Previous message:</strong> <a href="2631.html">Damien Broderick: "Re: Why AI does not require Reductionism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2633.html">ben goertzel: "Re: Neural Nets vs. Neurons"</a>
<li><strong>Reply:</strong> <a href="2633.html">ben goertzel: "Re: Neural Nets vs. Neurons"</a>
<li><strong>Reply:</strong> <a href="2647.html">Arona Ndiaye: "Re: Neural Nets vs. Neurons"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2632">[ date ]</a>
<a href="index.html#2632">[ thread ]</a>
<a href="subject.html#2632">[ subject ]</a>
<a href="author.html#2632">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
