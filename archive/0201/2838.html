<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Revision of &quot;Simulations&quot; essay available.</title>
<meta name="Author" content="Alan Grimes (alangrimes@starpower.net)">
<meta name="Subject" content="Re: Revision of &quot;Simulations&quot; essay available.">
<meta name="Date" content="2002-01-31">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Revision of &quot;Simulations&quot; essay available.</h1>
<!-- received="Thu Jan 31 22:52:12 2002" -->
<!-- isoreceived="20020201055212" -->
<!-- sent="Thu, 31 Jan 2002 22:53:40 -0500" -->
<!-- isosent="20020201035340" -->
<!-- name="Alan Grimes" -->
<!-- email="alangrimes@starpower.net" -->
<!-- subject="Re: Revision of &quot;Simulations&quot; essay available." -->
<!-- id="3C5A1144.C4F5030F@starpower.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="001301c1aaac$84cb5720$8312e63f@mitch" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Alan Grimes (<a href="mailto:alangrimes@starpower.net?Subject=Re:%20Revision%20of%20&quot;Simulations&quot;%20essay%20available."><em>alangrimes@starpower.net</em></a>)<br>
<strong>Date:</strong> Thu Jan 31 2002 - 20:53:40 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2839.html">Eliezer S. Yudkowsky: "META: Sysops basics are still &quot;exhausted&quot; for SL4"</a>
<li><strong>Previous message:</strong> <a href="2837.html">Ben Goertzel: "RE: Sadness on voluntary death (was: Singularity Memetics)"</a>
<li><strong>In reply to:</strong> <a href="2823.html">Mitch Howe: "Re: Revision of &quot;Simulations&quot; essay available."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2839.html">Eliezer S. Yudkowsky: "META: Sysops basics are still &quot;exhausted&quot; for SL4"</a>
<li><strong>Reply:</strong> <a href="2839.html">Eliezer S. Yudkowsky: "META: Sysops basics are still &quot;exhausted&quot; for SL4"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2838">[ date ]</a>
<a href="index.html#2838">[ thread ]</a>
<a href="subject.html#2838">[ subject ]</a>
<a href="author.html#2838">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Mitch Howe wrote:
<br>
<em>&gt; Alan Grimes wrote on January 31, 2002 2:52 PM
</em><br>
<em>&gt; &gt; However there seems to be an underlying premice, that a &quot;Big
</em><br>
<em>&gt; &gt; Brother&quot;/&quot;nany&quot;/&quot;G0D&quot; AI should be ruling everyone's life.
</em><br>
<p><em>&gt; &quot;Ruling&quot; is such a strong word, and I confess that I always feel like I 
</em><br>
<em>&gt; run against limitations in the English language when trying to explain 
</em><br>
<em>&gt; the minimum degree of regulation that the preservation of the human 
</em><br>
<em>&gt; race will require.
</em><br>
<p>Now that is an interesting proposal...
<br>
<p>Two questions: 
<br>
<p>1. How would it be held accountable. (there must _ALWAYS_ be checks and
<br>
balances)
<br>
<p>2. Would there be an option of living outside the system, say on a
<br>
different planet...
<br>
<p><em>&gt; One way to look at a minimalist singleton SI like a Sysop is this:  A 
</em><br>
<em>&gt; Sysop is not interested in restricting or punishing the actions of 
</em><br>
<em>&gt; would-be murderers;  It is interested in protecting those who do not 
</em><br>
<em>&gt; wish to be murdered. (Take this same reasoning and apply it to 
</em><br>
<em>&gt; nanotech grey goo, bioengineered super-plagues, nuclear weapons, etc.)
</em><br>
<p>That's fair, but why would it need to be implemented as anything beyond
<br>
a shielding system for people who choose to use it?
<br>
<p>-- I'm not sure which reality I'm talking about here....
<br>
<p><em>&gt; Would you be upset if your local police department were 100% efficient 
</em><br>
<em>&gt; and preventing violent crime and 0% corrupt in the use of this power?
</em><br>
<p>The police are not there to _prevent_ violent crime.
<br>
They are there to deal with offenders, past-tense. 
<br>
<p>I will admit that prevention has been impossible throughout history,
<br>
leading to this general tennant, however I don't see this as sufficient
<br>
reason to change tenants....
<br>
<p><em>&gt; The reason so many people cringe at their first exposure to a concept 
</em><br>
<em>&gt; like Sysop is that they assume the system would for some reason abuse 
</em><br>
<em>&gt; its ability to completely protect those who desire protection.  
</em><br>
<p>Power guarentees corruption.
<br>
If the SI is not corrupt, it will be hacked and corrupted from the
<br>
outside. Once that happens, it will be the end.
<br>
<p>Case in point: Windows XP. 
<br>
<p>If you study its design you will find it extremely limiting of personal
<br>
freedom. How would you suppose a system derived from it would behave?
<br>
<p>I am so fed up with &quot;modern&quot; operating systems that I have held on to
<br>
windows 3.11 for all these years... =\ 
<br>
<p>Linux _REALLY_ sucks. =(((
<br>
<p>I've designed my own OS but &quot;bootstrapping&quot; it will be incredibly
<br>
challenging...
<br>
<p><em>&gt; Everyone on this list would agree that giving any human this kind of 
</em><br>
<em>&gt; power would be a mistake,
</em><br>
<p>The only person I would trust with that kind of power would be myself.
<br>
;)
<br>
<p><em>&gt; but assigning ulterior motives to a Sysop is anthropomorphism, and 
</em><br>
<em>&gt; several threads in the SL4 archives have already discussed it at 
</em><br>
<em>&gt; length. I think March '01 was an especially good month for this topic.
</em><br>
<p>That wasn't the question.
<br>
Let me put it this way: &quot;I hope there isn't a God because there isn't
<br>
enough room in this universe for the two of us.&quot; ;)
<br>
<p>I have made a standing invitation to be smitten... 
<br>
<p><p><em>&gt;  I know people who feel that this would strip away some valuable 
</em><br>
<em>&gt; component of 'humanity', and I don't have a good answer for them 
</em><br>
<p>Good! =)
<br>
This proves that you don't have a pathalogicly inflated ego.
<br>
<p><em>&gt; - my only response is that if the ability to carry out murder is an 
</em><br>
<em>&gt; essential element of humanity, then I look forward to becoming 
</em><br>
<em>&gt; something other than human.
</em><br>
<p>It is a neccessary skill...
<br>
<p><p><em>&gt; Earth.  Please do not take phrases like, &quot;Even if all the matter in the 
</em><br>
<em>&gt; solar system were converted to computronium. . .&quot; to mean &quot;The entire 
</em><br>
<em>&gt; solar system should be converted to computronium.&quot;
</em><br>
<p>Then I would ugre writers to take greater care...
<br>
<p><p><a href="mailto:DarkVegeta26@aol.com?Subject=Re:%20Revision%20of%20&quot;Simulations&quot;%20essay%20available.">DarkVegeta26@aol.com</a> wrote:
<br>
<em>&gt; &lt;&lt;could not tolerate such tyrany, no matter how benevolant. Take that
</em><br>
<em>&gt; away, and much of the argument for simulation falls through....&gt;&gt;
</em><br>
<p><em>&gt; You tolerate the tyranny of the laws of physics and the human 
</em><br>
<em>&gt; condition... 
</em><br>
<p>laws of Physics: I require them to remain alive. If they were to be
<br>
suspended, even one of them, I would be dead instantly. They may be
<br>
inconvenient, but then I have not seen a single proposal that will have
<br>
any direct effect on them anyway....
<br>
<p>As for the human condition: Just let me have AI, nanites, and a few
<br>
decades to work on my next body. ;)
<br>
<p><em>&gt; list, so I recommend everyone reads the essential prerequisites to 
</em><br>
<em>&gt; Singularitarian thought in lieu of laziness.
</em><br>
<p>I need to keep focused on my projects... 
<br>
<p><em>&gt; &lt;&lt;Would you really so casually brush asside _ALL_ Life including people 
</em><br>
<em>&gt; who disagree with the &quot;sysop&quot;... &gt;&gt;
</em><br>
<p><em>&gt; Life would just be implemented on a higher level, not brushed aside.  
</em><br>
<p>Here you diverge from the other d00d....
<br>
<p>I think you, and many on this list, totally misunderstand what computers
<br>
are, what the internet means, and where meaning comes from. 
<br>
<p>AI will indeed open the door to a whole new phase in evolution but this
<br>
notion of &quot;level&quot; especially, one being &quot;higher&quot; than the other, is
<br>
ludacrous in the extreme. Its almost as bad as the claim that
<br>
transmuting into silicon based life is the next higer plane from eariler
<br>
carbon life just because its on the next row of the pereodic table...
<br>
<p><em>&gt; It's impossible to disagree with the &quot;Sysop&quot;, because it would be so 
</em><br>
<em>&gt; darn smart, and know what's best for you and the universe, even better 
</em><br>
<em>&gt; than parents &quot;know what is best&quot; for their children! 
</em><br>
<p>I hate my father.
<br>
There will never be more than one person who knows what's best for me.
<br>
<p><p><a href="mailto:DarkVegeta26@aol.com?Subject=Re:%20Revision%20of%20&quot;Simulations&quot;%20essay%20available.">DarkVegeta26@aol.com</a> wrote:
<br>
[The Ego]
<br>
<em>&gt; Why make unconstructive quips about Eliezer's ego?
</em><br>
<p><em>&gt;From my viewpoint they *are* constructive because I see Eliezer's ego as
</em><br>
a major obsticle towards more efficient progress...
<br>
<p><em>&gt; Doesn't anyone respect him for what he is doing, what he has done, and 
</em><br>
<em>&gt; what he has wrote?
</em><br>
<p>He has shown himself to be an active thinker, however he could be even
<br>
better if he is more open to differing and critical viewpoints. 
<br>
<p>You will see a number of people on this list have taken viewpoints
<br>
supporting my own with regards to things Eliezer has said. 
<br>
<p>If I could just get past that confounded Ego barrier, I would be able to
<br>
gain greater access to his source material and his current theories, if
<br>
indeed he has any.... 
<br>
<p>It would be a win-win situation for everyone.
<br>
<p><p><em>&gt; I have no past in gaia spirituality/mysticism and don't hold any views 
</em><br>
<em>&gt; not based on rationalism.
</em><br>
<p>Look again.
<br>
<p><p><em>&gt; &lt;&lt;Faith is dangerous -- ALWAYS.&gt;&gt;
</em><br>
<p><em>&gt; Faith in technology?  Faith in intellect?  Faith in ethics?
</em><br>
<p>Faith is dangerous. -- ALWAYS.
<br>
<p><em>&gt; We appear to already be in that environment. Our challenge lies with
</em><br>
<em>&gt; improving ourselves not crawling into a box with lots of blinking 
</em><br>
<em>&gt; LEDs.&gt;&gt;
</em><br>
<p><em>&gt; Oh my.  Improving ourselves is transcending onto another level of
</em><br>
<em>&gt; implementation.
</em><br>
<p>Mind yes
<br>
Body too
<br>
I'll start with an almost human look and then evolve as need presents
<br>
itself. I'm ready for ME-2.0. =)
<br>
<p><em>&gt;  Your &quot;box with blinking LEDs&quot; is a wonderful example 
</em><br>
<em>&gt; of a stereotype of uploading, however.  You could be in a &quot;box with 
</em><br>
<em>&gt; blinking LEDs&quot; right now, and not know it, if the LEDs were complex 
</em><br>
<em>&gt; enough.
</em><br>
<p>In that case, I would not be in a position to care...
<br>
<p><em>&gt; &lt;&lt;That sounds very authoritarian. Please be clear about where you stand 
</em><br>
<em>&gt; on the political spectrum. &gt;&gt;
</em><br>
<p><em>&gt; I'm a radical libertarian, if you must put me into some political
</em><br>
<em>&gt; classification.
</em><br>
<p>That much is good...
<br>
<p><em>&gt;  The Singularity is &quot;arch-anarchy&quot;, freedom from all 
</em><br>
<em>&gt; possible restraints, including those of the laws of physics (when 
</em><br>
<em>&gt; within a simulation, for sure). 
</em><br>
<p>But confinement to the simulation. -- the most horrible form of
<br>
confinement of all....
<br>
<p><em>&gt; The &quot;Sysop&quot; will not restrain us but rather guide us and help us, 
</em><br>
<em>&gt; putting in necessary guidelines for a smoothly functioning Omega State. 
</em><br>
<p>Why?
<br>
How would that be any different from death?
<br>
<p><pre>
-- 
DOS LIVES! MWAHAHAHAHA
<a href="http://users.rcn.com/alangrimes/">http://users.rcn.com/alangrimes/</a>  &lt;my website.
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2839.html">Eliezer S. Yudkowsky: "META: Sysops basics are still &quot;exhausted&quot; for SL4"</a>
<li><strong>Previous message:</strong> <a href="2837.html">Ben Goertzel: "RE: Sadness on voluntary death (was: Singularity Memetics)"</a>
<li><strong>In reply to:</strong> <a href="2823.html">Mitch Howe: "Re: Revision of &quot;Simulations&quot; essay available."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2839.html">Eliezer S. Yudkowsky: "META: Sysops basics are still &quot;exhausted&quot; for SL4"</a>
<li><strong>Reply:</strong> <a href="2839.html">Eliezer S. Yudkowsky: "META: Sysops basics are still &quot;exhausted&quot; for SL4"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2838">[ date ]</a>
<a href="index.html#2838">[ thread ]</a>
<a href="subject.html#2838">[ subject ]</a>
<a href="author.html#2838">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
