<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Ethical basics</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Ethical basics">
<meta name="Date" content="2002-01-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Ethical basics</h1>
<!-- received="Wed Jan 23 17:18:24 2002" -->
<!-- isoreceived="20020124001824" -->
<!-- sent="Wed, 23 Jan 2002 17:17:38 -0500" -->
<!-- isosent="20020123221738" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Ethical basics" -->
<!-- id="3C4F3682.E2E12CAA@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Ethical%20basics"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Wed Jan 23 2002 - 15:17:38 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2641.html">ben goertzel: "Re: Ethical basics"</a>
<li><strong>Previous message:</strong> <a href="2639.html">Gordon Worley: "Re: META: Archive Search"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2641.html">ben goertzel: "Re: Ethical basics"</a>
<li><strong>Reply:</strong> <a href="2641.html">ben goertzel: "Re: Ethical basics"</a>
<li><strong>Reply:</strong> <a href="2655.html">Vlad Vul: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2665.html">gabriel C: "RE: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2669.html">DarkVegeta26@aol.com: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2670.html">DarkVegeta26@aol.com: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2681.html">Michael Roy Ames: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2683.html">Michael Roy Ames: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2684.html">Michael Roy Ames: "RE: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2693.html">Michael Roy Ames: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2696.html">Michael Roy Ames: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2770.html">Hooky Sun: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2771.html">Hooky Sun: "Re: Ethical basics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2640">[ date ]</a>
<a href="index.html#2640">[ thread ]</a>
<a href="subject.html#2640">[ subject ]</a>
<a href="author.html#2640">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Sorry for all the delays in replying.  However, it's now getting to the
<br>
point where I need to make time, because this is not something that can be
<br>
left undealt-with.
<br>
<p>The main question I faced, thinking about writing these replies, is where
<br>
to start.  I eventually concluded that I should start at the beginning, on
<br>
the theory that whether or not Michael Anissimov already knows all this
<br>
stuff, someone else may not.
<br>
<p>The title of this message is &quot;ethical basics&quot;.  I mentally use separate
<br>
terms for &quot;ethics&quot; and &quot;morality&quot; to refer to means and ends
<br>
respectively.  That is, morality is what you normatively want, and ethics
<br>
is how you normatively get it.  Both should be distinguished from &quot;PR&quot;,
<br>
which is the art of automatically inserting the word &quot;normatively&quot; into
<br>
the logically straightforward phrase &quot;morality is what you want and ethics
<br>
is how you get it&quot; in order to prevent nitwit journalists from quoting you
<br>
out of context.
<br>
<p>Anissimov's position, if I understand it correctly, is that ethics are
<br>
unnecessary, and may be dispensed with, in the pursuit of morality; that
<br>
there is no moral reason to be ethical.  He seems to think - although it
<br>
is not stated explicitly - that there never was any good reason for such
<br>
ethics; that it is simply an impediment along the path of life which
<br>
people keep because they are not yet sufficiently self-aware to get rid of
<br>
it.
<br>
<p>Now, it is certainly possible to spend too much time praising ethics, for
<br>
the wrong reasons, without rational discipline.  Whenever somebody says
<br>
something in favor of an ethics or morality that is commonly accepted in
<br>
the immediate group, we should immediately be skeptical as to whether the
<br>
statement is genuine rational thinking or simply political campaigning -
<br>
&quot;Vote for me, I'm so damn righteous&quot; - whether as a conscious strategy or,
<br>
more likely, as a genetic adaptation subtly causing the person to favor
<br>
thinking about, and publicly talking about, those conclusions that turn
<br>
out to be in favor of social or ethical norms.
<br>
<p>Nonetheless, there are, in fact, some legitimate moral reasons to be
<br>
ethical, and perhaps more importantly, some very important reasons to
<br>
*distrust* your instincts if they start telling you &quot;Ditch the ethics;
<br>
this cause is more important than that.&quot;  Not only are your genes set up
<br>
to promote personal reproduction by *hijacking* any consciously held
<br>
altruistic cause, but those genes are also optimized for a society of
<br>
maybe 200 illiterate hunter-gatherers, not a world with six billion
<br>
people.
<br>
<p>Defeating evolution is a lifelong job, not a one-time decision.  Deciding
<br>
to stay a virgin or get a vasectomy or whatever isn't going to cause the
<br>
genes to say, &quot;Oh well, guess you're not going to reproduce, we give up.&quot; 
<br>
The genome doesn't work that way.  Individual organisms are
<br>
adaptation-executers, not fitness-maximizers.  Defeating evolution with
<br>
respect to the adaptation for sex-having or child-bearing isn't going to
<br>
switch off all the other adaptations, even if it defeats the purpose of
<br>
all those adaptations.
<br>
<p>Certain classes of altruistic efforts tend to go wrong for clear,
<br>
understandable, and recurrent reasons.  So, if you want to be an altruist,
<br>
you study history and evolutionary psychology.  You look at the
<br>
differences between the American Revolution and the French Revolution and
<br>
the Soviet Revolution and the civil-rights revolution.  You learn to
<br>
distrust your own instincts because your genes are always working at
<br>
cross-purposes to your chosen path.  To be a Singularitarian you have to
<br>
have enough self-awareness to actually work *for the Singularity* and not
<br>
let your genes just use the Singularity meme as a path for their own
<br>
purposes.  This is not a minor issue.  This is not a remote possibility. 
<br>
This is, historically, what happens to altruistic groups as the *default
<br>
scenario* unless care is exercised.
<br>
<p>Anissimov, as I understand it, seems to think of ethics as a simple burden
<br>
to be dispensed with.  If this were the case, there would be no human
<br>
instinct for acting honorably.  It's not a trustworthy instinct, but it's
<br>
there, and that means that under some circumstances in the ancestral
<br>
environment, acting &quot;honorably&quot; in the face of apparent short-term
<br>
inconvenience must have contributed to reproductive success in the long
<br>
run.
<br>
<p>The basis of the evolution of honorableness instincts and even altruistic
<br>
instincts is game theory, and specifically the iterated Prisoner's
<br>
Dilemna.  Good books to read are Douglas Hofstadter's &quot;Metamagical
<br>
Themas&quot;, which contains a discussion of the game theory of altruism in a
<br>
couple of the chapters (and the rest of the book is also a great deal of
<br>
fun); &quot;The Moral Animal&quot; by Robert Wright; &quot;The Origins of Virtue&quot; by Matt
<br>
Ridley.
<br>
<p>There are also a few words on evolutionary psychology to be found in:
<br>
&nbsp;&nbsp;<a href="http://intelligence.org/CFAI/anthro.html">http://intelligence.org/CFAI/anthro.html</a>
<br>
<p>Briefly:  If you play nice with other people, they'll play nice with you. 
<br>
Repeat for seven million years.  Now the evolved mind contains a whole set
<br>
of instincts for finding cooperators, detecting cheaters, and punishing
<br>
defectors.  Then expand the pool of people you interact with from a
<br>
200-person illiterate hunter-gatherer tribe to a world of 6 billion
<br>
people.  Now you *really* don't want to be a defector.  Neither do you
<br>
want to begin invoking the chunk of brainware that whispers &quot;The ends
<br>
justifies the means&quot;, in front of a literate (timebinding) population,
<br>
right after World War II.  In the post-WWII social environment, anyone who
<br>
says that the end justifies the means is automatically and instantly
<br>
labeled as a defector, a bad guy, a &quot;black hat&quot;, by the worldwide pool of
<br>
good guys and approximate good guys; that is the internal agreement that
<br>
the world's current supply of good guys have reached among themselves.
<br>
<p>Next point:  When I spoke of transhumanism's origin in &quot;scientifically
<br>
literate aggressive rationalists&quot;, Michael Anissimov responded by saying:
<br>
<p><em>&gt; Look forward to Singularitarian ideas reaching far, far beyond the &quot;core 
</em><br>
<em>&gt; audience of scientifically literate aggressive rationalists&quot; in the very near 
</em><br>
<em>&gt; future.  Instead of insisting that the meme be stapled down to its original 
</em><br>
<em>&gt; tiny group, (however rational and intelligent they may be) perhaps we should 
</em><br>
<em>&gt; be considering what variants would have the best net result in conditions of 
</em><br>
<em>&gt; imminent mass propagation.
</em><br>
<p>As for trying to propagate the meme outwards, I've been trying to do that
<br>
for six years!  And I've made some progress, although not as much progress
<br>
as I would be making if memetics, rather than AI, were my full-time job. 
<br>
But I've been doing it very very carefully, because again, historically,
<br>
this is a very very dangerous thing to do!  Projects have been destroyed
<br>
by going public the wrong way - not rarely, but *frequently*.
<br>
<p>It is a mistake to think that giving up all your ethics automatically
<br>
leads to success.  Usually, giving up all the ethics turns out to mean
<br>
giving up all the morality as well, or delaying it until some indefinite
<br>
future date.  The memes that are optimized for maximum propagation are NOT
<br>
THE SAME MEMES OPTIMIZED FOR ACTUAL ACHIEVEMENT OF THE SINGULARITY.  The
<br>
memes that propagate best are pretty much *useless* for achieving the
<br>
Singularity.
<br>
<p>Anissimov, you do not NEED to attach false promises or
<br>
mental-flaw-exploits to the Singularity concept in order to get it
<br>
accepted.  The legitimate and entirely truthful offer of immortality,
<br>
freedom, and unlimited personal growth is ENOUGH.  What we need is to make
<br>
sure that this wonderfully attractive package doesn't get hijacked.  And
<br>
that means making very clear that the Singularity is not destiny and it is
<br>
not something that someone else does for you; it is something that comes
<br>
about only if you put active efforts into it.  I know of no way to &quot;cheat&quot;
<br>
that does not destroy this principle as well.  I have seen a few mutations
<br>
of the Singularity meme here and there, and I hope like hell that they all
<br>
die out, because there isn't a single one of them that could help actually
<br>
create the Singularity.
<br>
<p><em>&gt; It could be argued that even in creating distinct labels for those with 
</em><br>
<em>&gt; different levels of future shock is perpetuating a group polarization 
</em><br>
<em>&gt; mentality.  Keep in mind that a successful memeticist (but not a cognitive 
</em><br>
<em>&gt; scientist) will use flaws in the human psychology to ver advantage, 
</em><br>
<em>&gt; oftentimes even projecting these flaws outwards from verself for the purpose 
</em><br>
<em>&gt; of harmonizing with larger portions of society.
</em><br>
<p>And you think that this doesn't involve any risk?!
<br>
<p>What disturbs me almost as much as your proposal is that you're proposing
<br>
to *start out* with this as your guiding principle.  If you start out with
<br>
an ethical compromise of that magnitude, where are you going to end up
<br>
at?  Why would someone else expect you to have any morals left at all,
<br>
when you're done?
<br>
<p>You're just beginning your career as a writer.  Even if you don't believe
<br>
in the absoluteness of ethics, right now you should be accepting those
<br>
ethics as absolute restraints in any case and learn to write within them,
<br>
for the same reason that programmers should not start out by sprinkling
<br>
&quot;gotos&quot; through their programs just because &quot;structured programming is too
<br>
hard&quot;.  When you're starting out in *any* skill is exactly the wrong time
<br>
to get sloppy, because you pick up bad habits that take a long time to
<br>
unlearn.  When you begin, at anything, you should be a perfectionist. 
<br>
I've been arguing ethically my whole career, and I don't *need* to resort
<br>
to unethical methods of argumentation, and I have no particular
<br>
expectation that I would lose to an &quot;unethical&quot; arguer in a fair fight. 
<br>
Don't take the easy way out, and the decision will pay off.
<br>
<p>As it is, believe me when I say that, ethical violation or no, you are
<br>
definitely messing up the memetic side of this.  It is quite possible that
<br>
reporters will spend the next five years quoting you as definitive proof
<br>
that all Singularitarians are ends-justifies-means scary fanatics.  Don't
<br>
think that reporters aren't that evil; they are.  Don't think that they
<br>
don't know how to use a search engine; they do.  Don't think that because
<br>
you think a webpage is, in your mind, only for the &quot;inner circle&quot;, that
<br>
that's how it'll be used; reporters will read it and they will quote it. 
<br>
Everything is out in the open, which is indeed as it should be, but it
<br>
also means that you've just screwed up.
<br>
<p>Now, I screwed up PR issues too when I started writing.  I was still
<br>
screwing up even after I had three years of experience.  For all I know
<br>
I'm still screwing up now.  The fact that I never made excuses for those
<br>
errors and instead just shut up and corrected them means that I learned
<br>
quickly, but some of those ancient writings are still out there and still
<br>
being used against me.  The Internet is like that.  All errors are
<br>
permanent.
<br>
<p>But at least I screwed up for reasons that the audience would have
<br>
respected if they'd ever had the chance to learn the whole story.  If you
<br>
propose being &quot;pragmatic&quot; and abandoning all ethics in order to promote a
<br>
debased form of the Singularity meme, what other response could you
<br>
possibly expect from existing Singularitarians?  What sympathy could you
<br>
expect from the audience even if given the best possible opportunity to
<br>
defend yourself?  If that's the supposed PR advantage of &quot;pragmatic
<br>
memetics&quot; in action, I'll stick with &quot;the right conclusion for the right
<br>
reasons&quot;, thank you very much.  Even if, somehow, I were to come to agree
<br>
with you that &quot;pragmatic memetics&quot; actually represents an advantage to the
<br>
Singularity, right now I'd tell you to spend the next three years
<br>
imitating Gandhi, because whatever &quot;pragmatic&quot; ethical compromise you try
<br>
right now is solidly *guaranteed* to spin out of your control.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2641.html">ben goertzel: "Re: Ethical basics"</a>
<li><strong>Previous message:</strong> <a href="2639.html">Gordon Worley: "Re: META: Archive Search"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2641.html">ben goertzel: "Re: Ethical basics"</a>
<li><strong>Reply:</strong> <a href="2641.html">ben goertzel: "Re: Ethical basics"</a>
<li><strong>Reply:</strong> <a href="2655.html">Vlad Vul: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2665.html">gabriel C: "RE: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2669.html">DarkVegeta26@aol.com: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2670.html">DarkVegeta26@aol.com: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2681.html">Michael Roy Ames: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2683.html">Michael Roy Ames: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2684.html">Michael Roy Ames: "RE: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2693.html">Michael Roy Ames: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2696.html">Michael Roy Ames: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2770.html">Hooky Sun: "Re: Ethical basics"</a>
<li><strong>Maybe reply:</strong> <a href="2771.html">Hooky Sun: "Re: Ethical basics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2640">[ date ]</a>
<a href="index.html#2640">[ thread ]</a>
<a href="subject.html#2640">[ subject ]</a>
<a href="author.html#2640">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
