<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: A Power's Nostalgia of Hairy-Ape-Life (was: Re: Singularity Memetics.)</title>
<meta name="Author" content="ben goertzel (ben@goertzel.org)">
<meta name="Subject" content="Re: A Power's Nostalgia of Hairy-Ape-Life (was: Re: Singularity Memetics.)">
<meta name="Date" content="2002-01-31">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: A Power's Nostalgia of Hairy-Ape-Life (was: Re: Singularity Memetics.)</h1>
<!-- received="Thu Jan 31 20:02:13 2002" -->
<!-- isoreceived="20020201030213" -->
<!-- sent="Thu, 31 Jan 2002 17:56:57 -0700" -->
<!-- isosent="20020201005657" -->
<!-- name="ben goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="Re: A Power's Nostalgia of Hairy-Ape-Life (was: Re: Singularity Memetics.)" -->
<!-- id="007501c1aabb$6b859f50$93156a40@thomas" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="22.22e9ed9b.298b3d86@aol.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> ben goertzel (<a href="mailto:ben@goertzel.org?Subject=Re:%20A%20Power's%20Nostalgia%20of%20Hairy-Ape-Life%20(was:%20Re:%20Singularity%20Memetics.)"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Thu Jan 31 2002 - 17:56:57 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2832.html">ben goertzel: "Re: A Power's Nostalgia of Hairy-Ape-Life (was: Re: Singularity Memetics.)"</a>
<li><strong>Previous message:</strong> <a href="2830.html">Eliezer S. Yudkowsky: "META: recent bounces"</a>
<li><strong>In reply to:</strong> <a href="2827.html">DarkVegeta26@aol.com: "Re: A Power's Nostalgia of Hairy-Ape-Life (was: Re: Singularity Memetics.)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2834.html">Alan Grimes: "Re: A Power's Nostalgia of Hairy-Ape-Life (was: Re: Singularity Memetics.)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2831">[ date ]</a>
<a href="index.html#2831">[ thread ]</a>
<a href="subject.html#2831">[ subject ]</a>
<a href="author.html#2831">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
People, the bottom line is, when we start talking about the presence of a
<br>
godlike supermind with the power to convince people of anything and
<br>
reconfigure our brains and our molecules at will -- we may as well just stop
<br>
talking, take off all our clothes and start dancing around going &quot;Qua qua
<br>
qua qua!!!&quot;
<br>
<p>Yes, it may happen -- I expect it probably will happen -- but applying our
<br>
current brains and cultural mindsets to this scenario is just not going to
<br>
be very productive.  No matter how smart we are, and no matter how
<br>
openmindedly and creatively we think.
<br>
<p>We can't know that it will be good or bad for this to happen, and we have no
<br>
basis on which to make probability estimates about such an event.  The ideas
<br>
of &quot;good&quot; and &quot;bad&quot; were formulated in a limited regime of experience, which
<br>
is not terribly relevant to events such as this.
<br>
<p>By pushing for such an eventuality, as most of us on this list are doing, we
<br>
are taking a big bad-assed existential leap of faith.  We are not making a
<br>
rational decision, because we just don't have the knowledge base on which to
<br>
make a rational decision about such a thing with more than a terribly
<br>
minimal degree of confidence.  In my view, if you think you're making a
<br>
plausibly confident rational judgment about what the Sysop is going to be
<br>
like, what it's going to do, what life will be like then, etc. -- you're
<br>
almost certainly fooling yourself.   Take the leap of faith -- fine --
<br>
wonderful -- but realize that's what you're doing!
<br>
<p><p>-- Ben G
<br>
<p>----- Original Message -----
<br>
From: &lt;<a href="mailto:DarkVegeta26@aol.com?Subject=Re:%20A%20Power's%20Nostalgia%20of%20Hairy-Ape-Life%20(was:%20Re:%20Singularity%20Memetics.)">DarkVegeta26@aol.com</a>&gt;
<br>
To: &lt;<a href="mailto:sl4@sysopmind.com?Subject=Re:%20A%20Power's%20Nostalgia%20of%20Hairy-Ape-Life%20(was:%20Re:%20Singularity%20Memetics.)">sl4@sysopmind.com</a>&gt;
<br>
Sent: Thursday, January 31, 2002 5:38 PM
<br>
Subject: Re: A Power's Nostalgia of Hairy-Ape-Life (was: Re: Singularity
<br>
Memetics.)
<br>
<p><p><em>&gt; In a message dated 1/31/2002 3:58:35 AM Pacific Standard Time,
</em><br>
<em>&gt; <a href="mailto:szegedy@or.uni-bonn.de?Subject=Re:%20A%20Power's%20Nostalgia%20of%20Hairy-Ape-Life%20(was:%20Re:%20Singularity%20Memetics.)">szegedy@or.uni-bonn.de</a> writes:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &lt;&lt;Perhaps it is unetical to convince a human to upload and waste valuable
</em><br>
<em>&gt; computational resources,  instead of letting them used by
</em><br>
<em>&gt; some well tuned AI much much more effectively.
</em><br>
<em>&gt; I may say so: if you save one human life by uploading, you kill a
</em><br>
<em>&gt; hyperintelligent/hypersensitive AI in the same turn.&gt;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; The consumption of power in convincing a human being to upload would be
</em><br>
<em>&gt; negligible to an SI, therefore it would be easier to build new SI's or SI
</em><br>
<em>&gt; components out of simply transcend-ifying human minds which are *already
</em><br>
<em>&gt; there*, and more ethical too.  So both the SI and we win.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &lt;&lt;Most
</em><br>
<em>&gt; people let themselves convinced by people on the same level rather than
</em><br>
<em>&gt; by more intelligent ones, let alone by machines. And even if a
</em><br>
<em>&gt; superintelligent AI would find very effective (but semantic wrong)
</em><br>
<em>&gt; arguments
</em><br>
<em>&gt; for uploading by analysing the human memetic flora and the flaws of
</em><br>
<em>&gt; human thinking, would it be &quot;ethical&quot;to convince them that way?&gt;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; ~shock level deficency detected~
</em><br>
<em>&gt; This SI &quot;machine&quot;, as you put it, would be very, very far from our current
</em><br>
<em>&gt; conception from what a machine is.  This &quot;machine&quot; would be much more like
</em><br>
<em>&gt; &quot;God&quot; (not in the Christian sense) than any &quot;machine&quot; seen up to this
</em><br>
point.
<br>
<em>&gt; For example, it could take on the appearance of your long lost father or
</em><br>
<em>&gt; lover, or give you a feeling of complete bliss when in its &quot;presence&quot;.
</em><br>
And
<br>
<em>&gt; those are very anthropocentric examples.  A true SI would be &quot;more human
</em><br>
than
<br>
<em>&gt; human&quot;, in the godliest sense we can comphrehend.  Super empathic, super
</em><br>
<em>&gt; ethical, super nice, just an all around great guy to be around!  =D   Is
</em><br>
it
<br>
<em>&gt; &quot;ethical&quot; to bring in a starving homeless child from off the street and
</em><br>
<em>&gt; clothe them and educate them, even if they are afraid of social
</em><br>
interaction
<br>
<em>&gt; or family love, at first?  This is analogous to the humanity+the Sysop
</em><br>
<em>&gt; situation (In case you couldn't guess.  It seems someone missed my earlier
</em><br>
<em>&gt; analogy about human love being a fleck of gold and the Singularity being a
</em><br>
<em>&gt; block of gold the size of a house, amazingly.)
</em><br>
<em>&gt; If you wish to continue arguing this point further then please mail me
</em><br>
<em>&gt; directly, and spare the list.  Thank you kindly.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Michael Anissimov
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2832.html">ben goertzel: "Re: A Power's Nostalgia of Hairy-Ape-Life (was: Re: Singularity Memetics.)"</a>
<li><strong>Previous message:</strong> <a href="2830.html">Eliezer S. Yudkowsky: "META: recent bounces"</a>
<li><strong>In reply to:</strong> <a href="2827.html">DarkVegeta26@aol.com: "Re: A Power's Nostalgia of Hairy-Ape-Life (was: Re: Singularity Memetics.)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2834.html">Alan Grimes: "Re: A Power's Nostalgia of Hairy-Ape-Life (was: Re: Singularity Memetics.)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2831">[ date ]</a>
<a href="index.html#2831">[ thread ]</a>
<a href="subject.html#2831">[ subject ]</a>
<a href="author.html#2831">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
