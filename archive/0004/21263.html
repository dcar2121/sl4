<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [SL4] washington post article</title>
<meta name="Author" content="Greg A (greg.a@facttechnologies.com)">
<meta name="Subject" content="Re: [SL4] washington post article">
<meta name="Date" content="2000-04-02">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [SL4] washington post article</h1>
<!-- received="Sun Apr  2 18:09:09 2000" -->
<!-- isoreceived="20000403000909" -->
<!-- sent="Sun, 2 Apr 2000 15:59:19 -0700" -->
<!-- isosent="20000402225919" -->
<!-- name="Greg A" -->
<!-- email="greg.a@facttechnologies.com" -->
<!-- subject="Re: [SL4] washington post article" -->
<!-- id="007d01bf9cf7$146ce800$8aa30918@pinol1.sfba.home.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="38E7ADD1.7A376861@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Greg A (<a href="mailto:greg.a@facttechnologies.com?Subject=Re:%20[SL4]%20washington%20post%20article"><em>greg.a@facttechnologies.com</em></a>)<br>
<strong>Date:</strong> Sun Apr 02 2000 - 16:59:19 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="21264.html">Eliezer S. Yudkowsky: "Re: [SL4] washington post article"</a>
<li><strong>Previous message:</strong> <a href="21262.html">Eliezer S. Yudkowsky: "Re: [SL4] washington post article"</a>
<li><strong>In reply to:</strong> <a href="21262.html">Eliezer S. Yudkowsky: "Re: [SL4] washington post article"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="21264.html">Eliezer S. Yudkowsky: "Re: [SL4] washington post article"</a>
<li><strong>Reply:</strong> <a href="21264.html">Eliezer S. Yudkowsky: "Re: [SL4] washington post article"</a>
<li><strong>Reply:</strong> <a href="21266.html">Randall Randall: "Re: [SL4] washington post article"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#21263">[ date ]</a>
<a href="index.html#21263">[ thread ]</a>
<a href="subject.html#21263">[ subject ]</a>
<a href="author.html#21263">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
This is a good countermove, Eliezer, but I think I'm going to win this game
<br>
of semantic chess. Everyone else please pay attention. If I can out-dialog,
<br>
Eliezer, I'm on to something worth noticing (in the Yudkowsky sense). :)
<br>
<p>Note for future reference: I've pretty much adopted his semantics for
<br>
RNUI -- they're genius-level work in the truest sense of the word.
<br>
<p>The key element that I think you're missing, Eliezer, (and which I don't
<br>
blame you for, since it's intentionally withheld in the preliminary
<br>
announcement) is the (relatively) novel concept (at 30 hours old) of the
<br>
semantic network. This only makes sense if you read this:
<br>
<p><a href="http://www.intelligententerprise.com/9811/online2.shtml">http://www.intelligententerprise.com/9811/online2.shtml</a>
<br>
<p>particularly the mathematical concept of &quot;projection.&quot; Dr. Codd noticed it
<br>
in 1969. I noticed it in 1999. I understood it about 10 days ago, and I came
<br>
across the Codd paper (while search for the name of SQL's inventor and the
<br>
date of origin) on Friday morning. That killed the last of my doubt.
<br>
<p>My non-linguistic math sucks. I'm sure you guys can see much bigger
<br>
implications after you see the link I'm talking about.
<br>
<p>The essence of my idea (quickly maturing into a theory) is that the Codd
<br>
concept of projection is/(can be) equivalent to semantic meaning in
<br>
fact-based computation involving human beings.
<br>
<p>[NOTE: There are lots of interesting fallout implications here, but I'm
<br>
trying to excite the world about the business implications first before they
<br>
figure these out. SL4 is a suitably rarefied atmosphere for exploration of
<br>
the deeper meaning in an attention-secure arena.]
<br>
<p>What THAT means, is that a team of links humans sharing fact-based data can
<br>
perform fact-based computations much better than a pure machine will for the
<br>
foreseeable future (i.e. the next 30 days).
<br>
<p>Welcome to the New World of Computing, everyone. Check what I'm saying.
<br>
Follow the links. Decide whether I'm crazy or genius or both, and let me
<br>
know.
<br>
<p>&quot;Essential humanity&quot; means what's left over as uniquely human here in the
<br>
New World. I'm hoping it will largely be the good stuff, since the good guys
<br>
have built the first cybersocial weapon with potentially planetary scale
<br>
effect. I think we can stay ahead of the bad guys for long enough to make it
<br>
not matter, mainly because the bad guys won't WANT to understand what we're
<br>
talking about.
<br>
<p>If that's not good news to this group (particularly in light of Mr. Bill
<br>
Joy's recent Wired article), I don't know what will be.
<br>
<p>REQUEST FOR INACTION: Although this idea is revolutionary, I would very much
<br>
appreciate it if nobody took the perceived connection outside this list for
<br>
now. I am declaring this idea humanity's first un-patent (i.e. uncontrolled
<br>
idea), in the tradition of copyleft, and Fact Technologies doesn't need to
<br>
get involved in expensive legal games at this hypercritical early stage of
<br>
the process. I'm counting on you guys for support in effecting this social
<br>
explosion, so please prove to me that my decision to trust you was valid.
<br>
<p>Sincerely,
<br>
<p>Greg A
<br>
<p><p>===============================
<br>
Greg A
<br>
Chief Executive Officer
<br>
Fact Technologies LLC
<br>
Giving Business A Mind Of Its Own.(TM)
<br>
<a href="http://www.facttechnologies.com">http://www.facttechnologies.com</a>
<br>
<p>510-681-8997 (direct)
<br>
510-549-1255 (fax)
<br>
<a href="mailto:greg.a@facttechnologies.com?Subject=Re:%20[SL4]%20washington%20post%20article">greg.a@facttechnologies.com</a>
<br>
===============================
<br>
<p><p><p><p><p><p>----- Original Message -----
<br>
From: &quot;Eliezer S. Yudkowsky&quot; &lt;<a href="mailto:sentience@pobox.com?Subject=Re:%20[SL4]%20washington%20post%20article">sentience@pobox.com</a>&gt;
<br>
To: &lt;<a href="mailto:SL4@onelist.com?Subject=Re:%20[SL4]%20washington%20post%20article">SL4@onelist.com</a>&gt;
<br>
Sent: Sunday, April 02, 2000 1:30 PM
<br>
Subject: Re: [SL4] washington post article
<br>
<p><p><em>&gt; Greg A wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I have an answer. How about:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Use MPC technology, such as that being developed by Fact Technologies,
</em><br>
to
<br>
<em>&gt; &gt; extend humanity's control of the universe through successive legions of
</em><br>
<em>&gt; &gt; Vinge-style physical, digital, and social automation,
</em><br>
<em>&gt;
</em><br>
<em>&gt; Now, there goes someone who really loves relational databases.  If I
</em><br>
<em>&gt; ever need a relational database built, this is probably the person to ask.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I don't know about a Singularity or an AI, though.
</em><br>
<em>&gt;
</em><br>
<em>&gt; SQL doesn't exactly capture the full complexity of physics, life, mind,
</em><br>
<em>&gt; and culture, except in the Physicist's Paradigm sense that SQL is
</em><br>
Turing-complete.
<br>
<em>&gt;
</em><br>
<em>&gt; Of course, this isn't really what you're talking about, according to
</em><br>
<em>&gt; FactTechnologies's video whitepaper.  You're talking about using
</em><br>
<em>&gt; real-time enterprise computing systems (which are usually built on
</em><br>
<em>&gt; relational databases, albeit not real-time ones) to add another layer of
</em><br>
<em>&gt; organization to the company; that is, by automating the flows of
</em><br>
<em>&gt; information that result in certain types of responses - even
</em><br>
<em>&gt; thermostat-like feedback - you hope that certain types of higher-level
</em><br>
<em>&gt; phenomena will emerge, just as a capitalist economy emerges from
</em><br>
<em>&gt; selfishness, Gaia effects from DaisyWorld, brains from selfish-neuron
</em><br>
<em>&gt; wiring algorithms, and so on.  Personally, I'm not sure how much
</em><br>
<em>&gt; higher-level phenomena you're going to get, but it does seem worth a
</em><br>
<em>&gt; shot.  An organization with real-time feedback mechanisms should at
</em><br>
<em>&gt; least be more efficient than one without them, maybe substantially more
</em><br>
<em>&gt; efficient.  I've had my own ideas along those lines.  But I don't think
</em><br>
<em>&gt; it's enough to save the world.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Even with real-time feedback mechanisms and emergent phenomena, a
</em><br>
<em>&gt; corporation composed of human elements plus automation does not have the
</em><br>
<em>&gt; complexity of a single human brain.  If you have an automated
</em><br>
<em>&gt; corporation with hundreds of non-genius humans, they will not be able to
</em><br>
<em>&gt; outthink a genius human.  Thoughts are enormous structures that exist in
</em><br>
<em>&gt; a brain with a hundred billion neurons and a hundred trillion synapses;
</em><br>
<em>&gt; the bandwidth between humans, in a corporation, isn't enough to expand
</em><br>
<em>&gt; the class of things that are Obvious, and while it does expand the class
</em><br>
<em>&gt; that's Inventable, it does so in a very limited, airy way.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Maybe two or three or sixty-four nongeniuses with BCI telepathy links
</em><br>
<em>&gt; (BCI:  Brain-Computer Interface) could outthink a genius, if the
</em><br>
<em>&gt; interconnection bandwidth was high enough.  (Certainly, both
</em><br>
<em>&gt; corporations and telepaths can do things that a genius can't; the
</em><br>
<em>&gt; question I'm asking is whether they can do genius-things - invent
</em><br>
<em>&gt; Newtonian physics, predict General and Special Relativity, design an
</em><br>
AI...)
<br>
<em>&gt;
</em><br>
<em>&gt; Groups of humans can spread out a thought-structure over multiple
</em><br>
<em>&gt; individuals, enabling the construction of mental structures far larger
</em><br>
<em>&gt; than any single human is capable of.  But the elements of that structure
</em><br>
<em>&gt; have to be joined by links limited to the bandwidth of human language
</em><br>
<em>&gt; (admittedly with a shared reference base).  Human genius is
</em><br>
<em>&gt; characterized by very dense, tightly-interconnected chains of reasoning.
</em><br>
<em>&gt;  Those genius thoughts might be Understandable by a corporation - they
</em><br>
<em>&gt; are, for that matter, understandable by individuals; GEB, Q.E.D. - but
</em><br>
<em>&gt; the thought processes that Invent them cannot be spread across
</em><br>
corporations.
<br>
<em>&gt;
</em><br>
<em>&gt; A group of humans is simply capable of holding a larger overall
</em><br>
<em>&gt; structure.  Each individual link, each individual insight, is the
</em><br>
<em>&gt; product of a single individual, because the cognitive abilities that
</em><br>
<em>&gt; produce those insights are neural modules and neural processes with
</em><br>
<em>&gt; internal variables that just don't get shared by language.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Imagine a thousand Gary Kasparovs trying to beat Deep Thought.  If they
</em><br>
<em>&gt; were all in the same room thinking about it out loud, that's analogous
</em><br>
<em>&gt; to a modern corporation.  If a computer system projects a couple of
</em><br>
<em>&gt; moves ahead and assigns various positions to each separate Kasparov,
</em><br>
<em>&gt; then that's a FactSystem corporation - or at least, that's what they're
</em><br>
<em>&gt; aiming for.  Even so, though, the Kasparovs won't be able to share
</em><br>
<em>&gt; insights, chess-perceptions, about each of the hundred boards assigned.
</em><br>
<em>&gt; They'll need to have the same insights over and over.  They won't be
</em><br>
<em>&gt; able to take an insight on one board and apply it to a second, or invent
</em><br>
<em>&gt; forks that they'd have to look at two boards at once to see.  And when
</em><br>
<em>&gt; it comes time to chose the best move, each one will have to give some
</em><br>
<em>&gt; kind of numeric rating to the chessboard in the absence of any knowledge
</em><br>
<em>&gt; about what the other possibilities are like.  They won't be able to
</em><br>
<em>&gt; match a BCI-telepathic team, and a BCI group can't match a
</em><br>
<em>&gt; general-intelligent AI with a chess cortex.
</em><br>
<em>&gt;
</em><br>
<em>&gt; This is essentially the same objection I have to Marc Stiegler's
</em><br>
<em>&gt; characterization of the Earthweb as a superintelligence, or Robin
</em><br>
<em>&gt; Hanson's characterization of modern corporations as being in the same
</em><br>
<em>&gt; league as hardware intelligence enhancement.  (Greg A, if you
</em><br>
<em>&gt; haven't read a book called _Earthweb_ by Marc Stiegler, I think you'd
</em><br>
<em>&gt; really enjoy it.)
</em><br>
<em>&gt;
</em><br>
<em>&gt; If humans are Legos, then corporations represent the class of structures
</em><br>
<em>&gt; that can be built with Legos; automated corporations are the class of
</em><br>
<em>&gt; structures that can be built with motorized Legos; hardware intelligence
</em><br>
<em>&gt; enhancement is the class of structures that can be built with modern
</em><br>
<em>&gt; manufacturing; and AI is nanotechnology.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; while attempting to
</em><br>
<em>&gt; &gt; restrain that growth to such an extent that it doesn't dilute our
</em><br>
essential
<br>
<em>&gt; &gt; humanity?
</em><br>
<em>&gt;
</em><br>
<em>&gt; Just thinking about the Singularity for a few years has severely diluted
</em><br>
<em>&gt; my &quot;essential humanity&quot;, or at least what most people would cite as
</em><br>
<em>&gt; &quot;essential humanity&quot; - my fear of nonexistence, my emotional attachment
</em><br>
<em>&gt; to various parts of my personality and cognitive architecture, my
</em><br>
<em>&gt; allegiance to the human race (though I'm still fond of it), that sort of
</em><br>
thing.
<br>
<em>&gt;
</em><br>
<em>&gt; Can't we just admit that we don't even know which parts of ourselves are
</em><br>
<em>&gt; valuable, and keep an open mind about which parts we might want to throw
</em><br>
<em>&gt; away?  Right now, it's all theory.  Once we're faced with the reality,
</em><br>
<em>&gt; our perspectives will change.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I certainly don't have the moral (or engineering) authority to chide
</em><br>
<em>&gt; anyone about remaining attached to their humanity, but the correct goal
</em><br>
<em>&gt; from that perspective is to ensure that each individual has the option
</em><br>
<em>&gt; of remaining human.  Not to ensure that everyone is similarly restrained.
</em><br>
<em>&gt; --
</em><br>
<em>&gt;        <a href="mailto:sentience@pobox.com?Subject=Re:%20[SL4]%20washington%20post%20article">sentience@pobox.com</a>      Eliezer S. Yudkowsky
</em><br>
<em>&gt;           <a href="http://pobox.com/~sentience/beyond.html">http://pobox.com/~sentience/beyond.html</a>
</em><br>
<em>&gt;                  Member, Extropy Institute
</em><br>
<em>&gt;            Senior Associate, Foresight Institute
</em><br>
<em>&gt;
</em><br>
<em>&gt; ------------------------------------------------------------------------
</em><br>
<em>&gt; GET A NEXTCARD VISA, in 30 seconds!  Get rates as low as 2.9%
</em><br>
<em>&gt; Intro or 9.9% Fixed APR and no hidden fees.  Apply NOW!
</em><br>
<em>&gt; <a href="http://click.egroups.com/1/936/6/_/626675/_/954707465/">http://click.egroups.com/1/936/6/_/626675/_/954707465/</a>
</em><br>
<em>&gt; ------------------------------------------------------------------------
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<p><p>------------------------------------------------------------------------
<br>
Get a NextCard Visa, in 30 seconds!  
<br>
1. Fill in the brief application
<br>
2. Receive approval decision within 30 seconds
<br>
3. Get rates as low as 2.9% Intro or 9.9% Fixed APR
<br>
Apply NOW!
<br>
<a href="http://click.egroups.com/1/2646/6/_/626675/_/954716444/">http://click.egroups.com/1/2646/6/_/626675/_/954716444/</a>
<br>
------------------------------------------------------------------------
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="21264.html">Eliezer S. Yudkowsky: "Re: [SL4] washington post article"</a>
<li><strong>Previous message:</strong> <a href="21262.html">Eliezer S. Yudkowsky: "Re: [SL4] washington post article"</a>
<li><strong>In reply to:</strong> <a href="21262.html">Eliezer S. Yudkowsky: "Re: [SL4] washington post article"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="21264.html">Eliezer S. Yudkowsky: "Re: [SL4] washington post article"</a>
<li><strong>Reply:</strong> <a href="21264.html">Eliezer S. Yudkowsky: "Re: [SL4] washington post article"</a>
<li><strong>Reply:</strong> <a href="21266.html">Randall Randall: "Re: [SL4] washington post article"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#21263">[ date ]</a>
<a href="index.html#21263">[ thread ]</a>
<a href="subject.html#21263">[ subject ]</a>
<a href="author.html#21263">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:07 MDT
</em></small></p>
</body>
</html>
