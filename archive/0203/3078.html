<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Regulating AI Development</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Regulating AI Development">
<meta name="Date" content="2002-03-01">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Regulating AI Development</h1>
<!-- received="Fri Mar 01 17:37:10 2002" -->
<!-- isoreceived="20020302003710" -->
<!-- sent="Fri, 1 Mar 2002 15:39:01 -0700" -->
<!-- isosent="20020301223901" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Regulating AI Development" -->
<!-- id="LAEGJLOGJIOELPNIOOAJOEFHCEAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="OF8C7D37B0.6D3F622D-ON85256B6F.0074D090@ey.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Regulating%20AI%20Development"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Fri Mar 01 2002 - 15:39:01 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3079.html">Eliezer S. Yudkowsky: "Re: Regulating AI Development"</a>
<li><strong>Previous message:</strong> <a href="3077.html">doug.bailey@ey.com: "RE: Regulating AI Development"</a>
<li><strong>In reply to:</strong> <a href="3077.html">doug.bailey@ey.com: "RE: Regulating AI Development"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3079.html">Eliezer S. Yudkowsky: "Re: Regulating AI Development"</a>
<li><strong>Reply:</strong> <a href="3079.html">Eliezer S. Yudkowsky: "Re: Regulating AI Development"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3078">[ date ]</a>
<a href="index.html#3078">[ thread ]</a>
<a href="subject.html#3078">[ subject ]</a>
<a href="author.html#3078">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; &gt; Computers are too cheap and widespread, and so is programming
</em><br>
<em>&gt; &gt; and cognitive science knowledge.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; AI can't be successfully regulated except via imposition of a
</em><br>
<em>&gt; &gt; draconian, Luddite police state.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Exactly, which is why I believe my proposal is germane.  I doubt
</em><br>
<em>&gt; you could design a sufficiently comprehensive monitoring system
</em><br>
<em>&gt; to police AI development regardless of whether you wanted to be
</em><br>
<em>&gt; draconian or not.  Accordingly, the proposal of identifying the
</em><br>
<em>&gt; best option and shifting vast resources towards that path is the
</em><br>
<em>&gt; most effective way to guide AI development.
</em><br>
<p><p>The best option is to build a super-smart, super-Friendly AI fast,
<br>
before somebody else builds a nasty one.
<br>
<p>I would be happy to see vast financial resources devoted toward
<br>
this project.
<br>
<p>In fact, I would be happen to see even a modest amount of
<br>
financial resources devoted toward this project!  I know from
<br>
experience however how difficult this is to achieve.
<br>
<p>The fact is, the individuals and organizations
<br>
controlling the resources in our society
<br>
do not have a realistic view of future developments in technology,
<br>
and hence are very unlikely to fund such projects until success
<br>
(for good or for ill) has already been essentially achieved.
<br>
<p>Hey, you work for Ernst &amp; Young.  When I was at Webmind Inc., I
<br>
tried to strike a deal with E&amp;Y to supply AI components to their
<br>
knowledge management solutions.  Guess what, it fell through due
<br>
to some corporate merger on their end (with Cap Gemini).
<br>
Had that gone through,
<br>
it could have generated profits to fund some of our real AI
<br>
development (which was &quot;Friendly&quot; in nature, although I don't
<br>
share all of Eli's views on goal system architecture).  But, well...
<br>
just another example of how the individuals and organizations
<br>
controlling the resources do not value this sort of thing.
<br>
<p>The only way the government funds AI significantly is by way
<br>
of military applications.  Not the best route to Friendly AI
<br>
in my view.
<br>
<p><p><p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3079.html">Eliezer S. Yudkowsky: "Re: Regulating AI Development"</a>
<li><strong>Previous message:</strong> <a href="3077.html">doug.bailey@ey.com: "RE: Regulating AI Development"</a>
<li><strong>In reply to:</strong> <a href="3077.html">doug.bailey@ey.com: "RE: Regulating AI Development"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3079.html">Eliezer S. Yudkowsky: "Re: Regulating AI Development"</a>
<li><strong>Reply:</strong> <a href="3079.html">Eliezer S. Yudkowsky: "Re: Regulating AI Development"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3078">[ date ]</a>
<a href="index.html#3078">[ thread ]</a>
<a href="subject.html#3078">[ subject ]</a>
<a href="author.html#3078">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
