<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: goal systems, AI, destruction of the Earth, etc.</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="goal systems, AI, destruction of the Earth, etc.">
<meta name="Date" content="2002-03-12">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>goal systems, AI, destruction of the Earth, etc.</h1>
<!-- received="Tue Mar 12 10:10:48 2002" -->
<!-- isoreceived="20020312171048" -->
<!-- sent="Tue, 12 Mar 2002 07:51:18 -0700" -->
<!-- isosent="20020312145118" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="goal systems, AI, destruction of the Earth, etc." -->
<!-- id="JBEPKOGDDIKKAHFPOEFIIEFHCMAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=Re:%20goal%20systems,%20AI,%20destruction%20of%20the%20Earth,%20etc."><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Tue Mar 12 2002 - 07:51:18 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3166.html">w d: "RE:Novamente goal system"</a>
<li><strong>Previous message:</strong> <a href="3164.html">patrick: "RE: Wednesday's chatlog"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3165">[ date ]</a>
<a href="index.html#3165">[ thread ]</a>
<a href="subject.html#3165">[ subject ]</a>
<a href="author.html#3165">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
****
<br>
&nbsp;Intelligenesis broke out
<br>
from
<br>
the one-AI one-theory straightjacket, which had previously held for
<br>
*general
<br>
intelligence* projects (e.g. Cyc) even if it was occasionally violated
<br>
by
<br>
more pragmatic robotics architectures and so on.  Correspondingly,
<br>
Webmind
<br>
broke out of the AI-as-single-algorithm straightjacket, not so much
<br>
because
<br>
any individual researcher had a picture of AI as a supersystem, but
<br>
because
<br>
all the different researchers thought that AI was composed of different
<br>
systems.  In combination, all the ideas added up to a much bigger idea
<br>
than
<br>
any previous single AI researcher had ever had for general
<br>
intelligence.
<br>
****
<br>
<p>Yes, I agree with this, pretty much.
<br>
<p>Actually, most of the researchers involved DID believe in building an AI as
<br>
a supersystem.
<br>
<p>But there were many different ideas of how this supersystem should be.  For
<br>
instance, Pei saw it as having inference at the center and other things at
<br>
the periphery.  Shane and Youlian (roughly like Peter Voss) thought it had
<br>
to be founded on a neural-net-like dynamic.  Etc. etc.
<br>
<p>***
<br>
&nbsp;Of course I expect my visit to Webmind
<br>
played a
<br>
larger role in my week than it did yours, and hence looms larger in my
<br>
memory.
<br>
***
<br>
<p>yeah -- for most of the staff it played the role of light entertainment ;&gt;
<br>
<p>I was quite happy to get a chance to meet with you &amp; talk in person
<br>
though...
<br>
<p>****
<br>
The two most important questions, from my perspective, are:  (1):  Now
<br>
that
<br>
you're working with the Novamente approach, did you learn from
<br>
Intelligenesis *how* to build supersystems, or did you just learn about
<br>
*a*
<br>
supersystem that will become a new cul-de-sac for you?
<br>
***
<br>
<p>That's an interesting question.  We certainly learned a lot *intuitively*
<br>
about how to build AI supersystems.  We do not have a scientific,
<br>
systematized understanding of how to build AI supersystems.
<br>
<p>However, last month I spent some time working out an alternate,
<br>
non-Novamente approach to AI based on neural networks, called Hebbian Logic.
<br>
I found that having worked out the basics of this, it was pretty easy for me
<br>
to envision how to build a whole AI supersystem founded on Hebbian logic.
<br>
Of course, it would take me at least 6 months to work out and write up the
<br>
details of this envisioned AI supersystem in a comprehensible way.  But, I
<br>
guess that this is some evidence that we did gain *some* generic knowledge
<br>
about how to build AI supersystems.  Cassio and Pei and I did anyway, I
<br>
don't know about everyone else ;)
<br>
<p>***
<br>
&nbsp;(2):  How much
<br>
intelligence does it take for a seed AI takeoff anyway?  The latter one
<br>
in
<br>
particular has too many internal variables for me to guess it.  It
<br>
could be
<br>
anywhere from human-level intelligence to just above Eurisko.
<br>
***
<br>
<p>It is very clear to me intuitively that &quot;just above Eurisko&quot; is not right.
<br>
I feel very strongly that the answer is: Human-level or above.  Of course I
<br>
realize that &quot;human-level&quot; is a pretty vague term.  But I think that for the
<br>
hard takeoff to happen, one way or another, the seed AI in question has got
<br>
to learn or reinvent a lot of computer science theory....
<br>
<p><p>****
<br>
Your
<br>
current estimation of me appears to be as someone who'd make a nice
<br>
researcher for Intelligenesis, at least if he could learn to just build
<br>
his
<br>
own Friendliness system and see what it contributes to intelligence as
<br>
a
<br>
whole, instead of insisting that everyone do things his way.  This is
<br>
very
<br>
kind of you, and I do appreciate it.  But the thing is, I'm not
<br>
*supposed*
<br>
to be a typical Intelligenesis researcher.  I'm supposed to be the guy
<br>
that
<br>
takes the project over the &quot;hump&quot; that's defeated all AI projects up to
<br>
this
<br>
point.
<br>
***
<br>
<p>My estimation of you is a lot more complicated than that ;)
<br>
<p>I think your achievements as an *AI philosopher* are quite considerable.
<br>
<p>As a thinker about *AI design*, I think you have a lot of deep and
<br>
interesting ideas; but, as far as I can tell, nearly all of your ideas are
<br>
still at a relatively preliminary and theoretical stage.   As an AI
<br>
designer, you seem to me to be at roughly the same stage as Shane Legg,
<br>
Youlian Troyanov, Anton Kolonin and a number of other non-famous
<br>
genius-level thinkers I know -- all of whom have deep intuitions about how
<br>
to build an AI,and all of whom are engaged in the process of transforming
<br>
their intuitions into designs.   This is where I was from roughly 1988-1996,
<br>
before I coded the first crude (and useless!) Webmind system.
<br>
<p>***
<br>
Now, of course I realize that you haven't seen me in action enough to
<br>
know
<br>
that I'm any smarter than a run-of-the-mill AI researcher
<br>
***
<br>
<p>Eliezer, I'm sure you are very smart.  So am I.
<br>
<p>Not surprisingly, there are a LOT of terrifyingly clever people working in
<br>
this area.
<br>
<p>Here are 10 names.  Eliezer, Ben, Pei Wang, jeff pressing, anton kolonin,
<br>
shane legg, Cassio, Thiago, Senna, Guilherme.  ALL of us have genius-level
<br>
IQ's. ALL  of were the smartest kids on our block, in our whole school, in
<br>
all or nearly all of our university classes, etc. etc.  None of us are &quot;run
<br>
of the mill&quot; computer science researchers in any sense.
<br>
<p>If you're asking me to believe that you possess a level of supergenius above
<br>
and beyond all us other highly clever individuals -- well, no, I don't
<br>
believe it.  I'm not totally closed to the idea but I haven't seen you
<br>
demonstrate this level of supergenius so far!!
<br>
<p>If you're asking me to believe that you have some special insight into
<br>
aspects of the AI problem that no one else has -- well, I can believe that a
<br>
lot  more easily.  Einstein for instance had a special insight into physics
<br>
that his other -- equally clever -- colleagues did not have.  Having a
<br>
special insight into some domain is an interesting combination of things:
<br>
general intelligence, specialized intelligence in the domain, and a
<br>
philosophical/personal bias that in some way matches a given domain at a
<br>
given time.
<br>
<p>***
<br>
&nbsp;you
<br>
don't
<br>
trust AI researchers' arguments until you see them implemented in
<br>
practice.
<br>
***
<br>
<p>I would also trust rigorous mathematical proofs, to an extent.
<br>
<p>***
<br>
<em>&gt; I can solve problem 1 by giving you detailed information about
</em><br>
Novamente
<br>
<em>&gt; (privately, off list), though it will take you  many many days of
</em><br>
reading
<br>
<em>&gt; and asking questions to really get it (it's just a lot of
</em><br>
information).
<br>
<p>I'll take it.  Please send.
<br>
****
<br>
<p>We're working on a new draft of our overall design doc; it should be ready
<br>
in early April, so I'll talk to you about it then...
<br>
<p>ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3166.html">w d: "RE:Novamente goal system"</a>
<li><strong>Previous message:</strong> <a href="3164.html">patrick: "RE: Wednesday's chatlog"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3165">[ date ]</a>
<a href="index.html#3165">[ thread ]</a>
<a href="subject.html#3165">[ subject ]</a>
<a href="author.html#3165">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
