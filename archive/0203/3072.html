<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Regulating AI Development</title>
<meta name="Author" content="doug.bailey@ey.com (doug.bailey@ey.com)">
<meta name="Subject" content="Regulating AI Development">
<meta name="Date" content="2002-03-01">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Regulating AI Development</h1>
<!-- received="Fri Mar 01 15:37:09 2002" -->
<!-- isoreceived="20020301223709" -->
<!-- sent="Fri, 1 Mar 2002 15:31:14 -0500" -->
<!-- isosent="20020301203114" -->
<!-- name="doug.bailey@ey.com" -->
<!-- email="doug.bailey@ey.com" -->
<!-- subject="Regulating AI Development" -->
<!-- id="OFCC20BBE7.D18FE028-ON85256B6F.006C26FF@ey.com" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> <a href="mailto:doug.bailey@ey.com?Subject=Re:%20Regulating%20AI%20Development"><em>doug.bailey@ey.com</em></a><br>
<strong>Date:</strong> Fri Mar 01 2002 - 13:31:14 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3073.html">Ben Goertzel: "G. Chaitin on AI"</a>
<li><strong>Previous message:</strong> <a href="3071.html">DarkVegeta26@aol.com: "Ever So Many Comments"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3075.html">Ben Goertzel: "RE: Regulating AI Development"</a>
<li><strong>Reply:</strong> <a href="3075.html">Ben Goertzel: "RE: Regulating AI Development"</a>
<li><strong>Maybe reply:</strong> <a href="3077.html">doug.bailey@ey.com: "RE: Regulating AI Development"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3072">[ date ]</a>
<a href="index.html#3072">[ thread ]</a>
<a href="subject.html#3072">[ subject ]</a>
<a href="author.html#3072">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I searched through the archives and could not locate prior discussions on
<br>
the topic of if we should and, if so, how we should, regulate AI
<br>
development through some formal function or body.  I confess I have not
<br>
thought very deeply on this subject but after the last few days of postings
<br>
it seems it would be productive to discuss if and how AI development should
<br>
be regulated.  Substantial discourse is ongoing about what approach might
<br>
be successful in achieving certain thresholds of AI.  However, I am fearful
<br>
that once the core method for developing AI of a respectable level of
<br>
sophistication (Sophisticated AI) is achieved we'll be faced with a sudden
<br>
and huge problem of how this particular technology might be advanced beyond
<br>
this point without imperling the human race.
<br>
<p>There are many schools of thought as to where we go from Sophisticated AI.
<br>
I believe Eliezer's general approach (correct me if I'm wrong) is we need
<br>
to achieve Friendy AI as soon as possible before potential &quot;evils&quot; such as
<br>
self-replicating nanotechnology and/or &quot;unFriendly&quot; AI hit the scene.
<br>
Kurzweil's general approach seems to be to enhance ourselves and thus have
<br>
&quot;humanity&quot; and all the baggage you get with it built-in to any AI.  There
<br>
are other approaches out there, some we are aware of and many others we
<br>
might not be aware of.
<br>
<p>Should we have a regulatory framework in place to determine as a community,
<br>
as a race, how we proceed with developing the seed AI we use for a takeoff
<br>
event?  Others have written about this for other profound technologies
<br>
(e.g., <a href="http://www.foresight.org/NanoRev/Forrest1989.html">http://www.foresight.org/NanoRev/Forrest1989.html</a> ).  I can't think
<br>
of a more profound product of technological development than a Power.
<br>
Thus, if you agree with development-by-committee approach of regulation
<br>
then I would presume you would agree that regulation of AI development is
<br>
appropriate.
<br>
<p>How should AI be developed? I'm trying to resist the &quot;mad scientist working
<br>
in his basement&quot; scenario but it or some variation comes to mind when
<br>
considering how to regulate AI development.  Regulating weaponized nuclear
<br>
capacity is fairly easy due to the huge financial resources and easily
<br>
identifiable physical plant requirements to develop such capacity.
<br>
Regulating nanotechnology is more troublesome - especially once the general
<br>
blueprint for self-replicating nanotechnology is understood.  However,
<br>
regulating AI development would seem to be the most difficult to regulate.
<br>
I would offer up that the way to regulate AI development is to (1) jointly
<br>
determine what the correct approach should be and then (2) invest so much
<br>
financial and intellectual momentum into this approach that it is
<br>
actualized before any other approach.  Regulation by domination or &quot;beating
<br>
them to the punch&quot; seems the best chance we have for ensuring a
<br>
human-friendly post-Singularity environment.  This requires faith in the
<br>
quorum though - or whatever mechanism is created to make decisions.  What
<br>
if the U.S. federal government creates a panel populated with the
<br>
_perceived_ gods of the AI pantheon, i.e., Minsky, Lenat, Kurzweil,
<br>
Hopfield, Penrose, Moravec, etc.  Perhaps these guys get it all wrong.  How
<br>
might we otherwise form such a panel?
<br>
<p>Maybe I'm just getting a realization others have already made  through a
<br>
different avenue (or perhaps the same), but it seems that identifying the
<br>
preferred AI development path and then putting the momentum behind that
<br>
approach to get there before something else hits the streets first is the
<br>
best way to maximize our chances of survival in a post-Singularity
<br>
environment.
<br>
<p><p><p><p><p>______________________________________________________________________
<br>
The information contained in this message may be privileged and
<br>
confidential and protected from disclosure.  If the reader of this message
<br>
is not the intended recipient, or an employee or agent responsible for
<br>
delivering this message to the intended recipient, you are hereby notified
<br>
that any dissemination, distribution or copying of this communication is
<br>
strictly prohibited. If you have received this communication in error,
<br>
please notify us immediately by replying to the message and deleting it
<br>
from your computer.  Thank you.  Ernst &amp; Young LLP
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3073.html">Ben Goertzel: "G. Chaitin on AI"</a>
<li><strong>Previous message:</strong> <a href="3071.html">DarkVegeta26@aol.com: "Ever So Many Comments"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3075.html">Ben Goertzel: "RE: Regulating AI Development"</a>
<li><strong>Reply:</strong> <a href="3075.html">Ben Goertzel: "RE: Regulating AI Development"</a>
<li><strong>Maybe reply:</strong> <a href="3077.html">doug.bailey@ey.com: "RE: Regulating AI Development"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3072">[ date ]</a>
<a href="index.html#3072">[ thread ]</a>
<a href="subject.html#3072">[ subject ]</a>
<a href="author.html#3072">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
