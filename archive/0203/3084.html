<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: G. Chaitin on AI</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: G. Chaitin on AI">
<meta name="Date" content="2002-03-02">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: G. Chaitin on AI</h1>
<!-- received="Sat Mar 02 10:04:05 2002" -->
<!-- isoreceived="20020302170405" -->
<!-- sent="Sat, 2 Mar 2002 08:01:26 -0700" -->
<!-- isosent="20020302150126" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: G. Chaitin on AI" -->
<!-- id="LAEGJLOGJIOELPNIOOAJGEGCCEAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="007401c1c1b2$ed235620$1100a8c0@Presario" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20G.%20Chaitin%20on%20AI"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sat Mar 02 2002 - 08:01:26 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3085.html">Eliezer S. Yudkowsky: "Re: G. Chaitin on AI"</a>
<li><strong>Previous message:</strong> <a href="3083.html">Simon McClenahan: "Re: G. Chaitin on AI"</a>
<li><strong>In reply to:</strong> <a href="3083.html">Simon McClenahan: "Re: G. Chaitin on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3085.html">Eliezer S. Yudkowsky: "Re: G. Chaitin on AI"</a>
<li><strong>Reply:</strong> <a href="3085.html">Eliezer S. Yudkowsky: "Re: G. Chaitin on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3084">[ date ]</a>
<a href="index.html#3084">[ thread ]</a>
<a href="subject.html#3084">[ subject ]</a>
<a href="author.html#3084">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; &gt; &quot;[M]y personal opinion is that AI is not a mathematical problem, it's an
</em><br>
<em>&gt; &gt; engineering problem..  To me a human being is just a very complicated
</em><br>
<em>&gt; piece
</em><br>
<em>&gt; &gt; of engineering that's exquisitely well-suited for surviving in this
</em><br>
<em>&gt; world..
</em><br>
<em>&gt;
</em><br>
<em>&gt; I have always thought this. But surely anyone who agrees with the
</em><br>
<em>&gt; &quot;mind is a
</em><br>
<em>&gt; machine&quot; theory, like I assume all of us on this list are, could
</em><br>
<em>&gt; infer that
</em><br>
<em>&gt; &quot;reverse engineering&quot; the mind inside a modern computer substrate
</em><br>
<em>&gt; is indeed
</em><br>
<em>&gt; an engineering problem.
</em><br>
<p>Well, of course everyone who believes that the mind is a machine believes
<br>
that there is an engineering problem involved in building a mind.
<br>
<p>But the question is: is the problem *primarily* one of engineering, or
<br>
*primarily* one of mathematics, or *primarily* one of neuroscience, or
<br>
*primarily* one of cognitive psychology, etc.
<br>
<p>I know a few individuals who believe the mind is a machine, but who believe
<br>
there is some simple mathematical trick underlying mind operations, and that
<br>
if we just find this trick, then creating an artificial mind will be easy.
<br>
So they believe that figuring out the math is the main thing required.
<br>
<p>Kurzweil and others believe that the main problem is figuring out exactly
<br>
how the human brain works.  Once this is known, they reckon, it's just a
<br>
matter of emulating the brain on a sufficiently powerful computer, using a
<br>
simple neural simulator program (feeding in the exact distribution of
<br>
neurons, neurotransmitters, synapses, etc. as inputs).
<br>
<p>Chaitin is making the statement that mind is mechanical, but he's also
<br>
making the statement that the task of constructing a thinking machine
<br>
requires *primarily* engineering-type thinking.
<br>
<p>Of course, most of us probably hold views that are intermediate between
<br>
these extremes.  It's the extreme views that get remembered and propagated
<br>
because they're so compact to state and simple to recall.
<br>
<p>My own view is an intermediate one: I think it takes a mixture of
<br>
philosophy, neuroscience, math, engineering and psychology.  When I started
<br>
out I underestimated the importance of the &quot;engineering&quot; part, but
<br>
recognizing that importance doesn't mean denigrating the importance of the
<br>
other aspects.
<br>
<p>Chaitin's view is a little more like that of Danny Hillis (the parallel
<br>
computing pioneer), who has stated that he thinks intelligence is just &quot;a
<br>
lot of little things all working together.&quot;  Minsky's Society of Mind theory
<br>
is somewhat in this direction as well.  These guys don't place much stock in
<br>
emergence, and in the need for different structures and dynamics to be
<br>
exquisitely harmonized together.
<br>
<p><em>&gt; &gt; &quot;[I]t's very often the case that theoreticians can show that in theory
</em><br>
<em>&gt; &gt; there's no way to solve a problem, but software engineers can find a
</em><br>
<em>&gt; clever
</em><br>
<em>&gt; &gt; algorithm that usually works, or that usually gives you a good
</em><br>
<em>&gt; approximation
</em><br>
<em>&gt; &gt; in a reasonable amount of time.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Maybe I'm thinking on a different plane here, but to me the clever
</em><br>
<em>&gt; algorithms are indeed a mathematical problem.
</em><br>
<p>Some clever algorithms involve significant math, some don't.
<br>
<p>In my own AI work, I have not yet had the opportunity to apply &quot;deep math.&quot;
<br>
I.e. there have been no profound theorems proved about Novamente or Webmind
<br>
components, critical to the AI work.
<br>
<p>On the other hand, there have been plenty of applications of known math,
<br>
e.g. probability theory, combinatory logic, nonlinear dynamics,....
<br>
<p>To a real mathematician like Chaitin, working out fairly straightforward
<br>
applications of known math is not &quot;doing math.&quot;
<br>
<p>As a mathematician, I understood immediately this undertone in his
<br>
statement, but it may not be obvious to those who have not spent time in the
<br>
elitist, peculiar but fascinating &amp; wonderful tribe of professional
<br>
mathematicians ;&gt;
<br>
<p><em>&gt; &gt; &quot;We humans aren't artistic masterpieces of design, we're
</em><br>
<em>&gt; patched together,
</em><br>
<em>&gt; &gt; bit by bit, and retouched every time that there's an emergency and the
</em><br>
<em>&gt; &gt; design has to be changed!
</em><br>
<em>&gt;
</em><br>
<em>&gt; Sounds like the eXtreme Programming methodology! :-) Or more likely the
</em><br>
<em>&gt; timeless classic Waterfall method of software development.
</em><br>
<p>The way we work is sort of like Extreme Programming.  We start with a
<br>
mathematical design for a system component.  Then an XP type process is used
<br>
to get the implementation working.  Sometimes there's a detailed design
<br>
document prior to programming -- usually but not always, it depends on the
<br>
complexity of the component.  If something really fucked comes up during
<br>
implementation or detailed design, then a new math approach needs to be
<br>
worked out; but this has happened only a few times (and all of them have
<br>
been *really* big deals...).
<br>
<p><em>&gt; So I still believe that a general AI could come from a cluster of
</em><br>
<em>&gt; 286's. All
</em><br>
<em>&gt; you need is enough of them working in parallel, not necessarily running
</em><br>
<em>&gt; exactly the same software, or individual OS. Of course, the more powerful
</em><br>
<em>&gt; computers help speed things up a bit, but it doesn't make the
</em><br>
<em>&gt; 286's useless.
</em><br>
<p>Real AI could run on a network of 286's, but it would be very slow.
<br>
<p>The problem is, each piece of knowledge in the mind needs to be frequently
<br>
interacting with a high percentage of other pieces of knowledge in the mind.
<br>
So, dividing the mind's knowledge up into little chunks of memory, one chunk
<br>
stored on each 286 and processed on each 286, is feasible -- but one is
<br>
going to have a HUGE amount of distributed processing going on.  To make the
<br>
latency manageable, you introduce sophisticated adaptive load balancing and
<br>
so forth.
<br>
<p>We designed and implemented a system like this at Webmind Inc., as an
<br>
infrastructure for running our AI system on.  It did work, but it was slow,
<br>
and a huge pain in the butt to work with and debug.  We never tried it on
<br>
286's, but plenty of low-end early Pentiums as well as snazzier better
<br>
machines.
<br>
<p>In our current project we are focusing first on getting everything to work
<br>
together nicely on one machine, and then we will reimplement (a slicker
<br>
version of) the distributed processing framework.
<br>
<p>Dealing with distributed processing so early in our project was a
<br>
significant mistake, because it took a lot of effort, and a distributed AI
<br>
system is vastly harder to debug than an isolated one.  There are no real
<br>
testing tools that handle distributed nondeterministic self-organizing
<br>
systems.  Testing tools for distributed systems that exist at present are
<br>
*very* simplistic and limited, mostly focused on application server setups.
<br>
<p>On the other hand, through our experience, we now know exactly how to make
<br>
Novamente a distributed system when the time comes; so all the work we put
<br>
in on this was certainly not worthless.
<br>
<p>Consider two scenarios:
<br>
<p>A)
<br>
You have X amount of RAM on one machine, with P processors on that one
<br>
machine.
<br>
<p>B)
<br>
You have the P processors and X amount of RAM spread among K machines, where
<br>
P/K is small (commonly 2-4)...
<br>
<p><p>Our experience was that the speed of configuration B was *after copious
<br>
optimization* about 1/5 that of configuration A.  This is not because of
<br>
network latency, it's because of all the software stuff you have to do to
<br>
make your system distributed-processing-friendly.  It's possible this could
<br>
be improved to 1/3 or so.  We did a lot of work on this in Java but also
<br>
some prototyping in C.
<br>
<p>Also, the effective amount of information you can store in configuration B
<br>
is about 2/3 that in configuration A, because of the need to repeatedly
<br>
cache information to achieve reasonable time-efficiency.
<br>
<p>- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3085.html">Eliezer S. Yudkowsky: "Re: G. Chaitin on AI"</a>
<li><strong>Previous message:</strong> <a href="3083.html">Simon McClenahan: "Re: G. Chaitin on AI"</a>
<li><strong>In reply to:</strong> <a href="3083.html">Simon McClenahan: "Re: G. Chaitin on AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3085.html">Eliezer S. Yudkowsky: "Re: G. Chaitin on AI"</a>
<li><strong>Reply:</strong> <a href="3085.html">Eliezer S. Yudkowsky: "Re: G. Chaitin on AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3084">[ date ]</a>
<a href="index.html#3084">[ thread ]</a>
<a href="subject.html#3084">[ subject ]</a>
<a href="author.html#3084">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
