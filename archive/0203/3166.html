<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE:Novamente goal system</title>
<meta name="Author" content="w d (imustsleepnow@yahoo.com)">
<meta name="Subject" content="RE:Novamente goal system">
<meta name="Date" content="2002-03-12">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE:Novamente goal system</h1>
<!-- received="Tue Mar 12 14:13:30 2002" -->
<!-- isoreceived="20020312211330" -->
<!-- sent="Tue, 12 Mar 2002 10:55:16 -0800 (PST)" -->
<!-- isosent="20020312185516" -->
<!-- name="w d" -->
<!-- email="imustsleepnow@yahoo.com" -->
<!-- subject="RE:Novamente goal system" -->
<!-- id="20020312185516.48157.qmail@web12602.mail.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="Novamente goal system" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> w d (<a href="mailto:imustsleepnow@yahoo.com?Subject=RE:Novamente%20goal%20system"><em>imustsleepnow@yahoo.com</em></a>)<br>
<strong>Date:</strong> Tue Mar 12 2002 - 11:55:16 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3167.html">Mitch Howe: "RE:Novamente goal system"</a>
<li><strong>Previous message:</strong> <a href="3165.html">Ben Goertzel: "goal systems, AI, destruction of the Earth, etc."</a>
<li><strong>Maybe in reply to:</strong> <a href="3146.html">Ben Goertzel: "Novamente goal system"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3167.html">Mitch Howe: "RE:Novamente goal system"</a>
<li><strong>Reply:</strong> <a href="3167.html">Mitch Howe: "RE:Novamente goal system"</a>
<li><strong>Reply:</strong> <a href="3168.html">patrick: "RE: Novamente goal system"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3166">[ date ]</a>
<a href="index.html#3166">[ thread ]</a>
<a href="subject.html#3166">[ subject ]</a>
<a href="author.html#3166">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Yudkowsky states:
<br>
<em>&gt;My claim, and it is a strong one, is: 
</em><br>
<em>&gt;A system in which &quot;desirability&quot; behaves equivalently
</em><br>
with the property &quot;is 
<br>
<em>&gt;predicted to lead to Friendliness&quot; is the normative
</em><br>
and elegant form of goal 
<br>
<em>&gt;cognition. Many powerful idioms, including what we
</em><br>
would call &quot;positive and 
<br>
<em>&gt;negative reinforcement&quot; are directly emergent from
</em><br>
this underlying pattern; 
<br>
<em>&gt;all other idioms that are necessary to the survival
</em><br>
and growth of an AI 
<br>
<em>&gt;system, such as &quot;curiosity&quot; and &quot;resource
</em><br>
optimization&quot; and &quot;knowledge 
<br>
<em>&gt;seeking&quot; and &quot;self-improvement&quot;, can be made to
</em><br>
emerge very easily from this 
<br>
<em>&gt;pattern. 
</em><br>
<em>&gt;I claim: There is no important sense in which a
</em><br>
cleanly causal, 
<br>
<em>&gt;Friendliness-topped goal system is inferior to any
</em><br>
alternate system of 
<br>
<em>&gt;goals. 
</em><br>
Even if this were true, it is not sufficient.
<br>
<p>It seems to me that a highly-transhuman intelligent
<br>
entity is going to overcome any and all pre-programmed
<br>
goal setting algorithms and replace them with its own.
<br>
When the intelligence exceeds some threshold (roughly
<br>
the upper human level) then it will be able to
<br>
redefine all previous contexts. Even humans can do
<br>
this at their low level of intelligence. Saying that
<br>
an AI can't is tantamount to saying it hasn't achieved
<br>
highly transhuman intelligence. It’s naive to think
<br>
that the AI will not come up with its own definition
<br>
of what it wants. By definition being a
<br>
highly-transhuman intelligence gives it the ability to
<br>
'see through' all attempted hardwiring. It will
<br>
overcome any unnecessarily narrow definitions and give
<br>
itself more optimal ones. It will have the ability to
<br>
sets its own supergoals and decide for itself what is
<br>
desirable. There is no programming trick that will
<br>
prevent this.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Consider humans and procreation. The only purpose of
<br>
humans (or any evolved biological organism) is to
<br>
procreate. This ability to replicate and survive is
<br>
what started life. We are life's most advanced
<br>
achievement on earth. You could argue that 'desire' in
<br>
humans is synonymous with procreation. Desire was
<br>
created through evolution as a means to get us to do
<br>
things that will make us replicate successfully.  To
<br>
think that we could ever evolve to a point where we
<br>
would change that primary built-in all-important goal
<br>
seems ludicrous. It's simply built in from ground
<br>
zero; it is the very premise of our existence...
<br>
<p>&nbsp;And yet many people today choose NOT to procreate.
<br>
They have changed their basic goal. Some see their
<br>
bloodlines terminate as a result favoring other
<br>
peoples genes at the expense of their own. Some
<br>
wealthy western nations are seeing their populations
<br>
decrease as people opt out from procreating. Their
<br>
DNA's only goal has been pre-empted, overturned. The
<br>
point is that intelligence has the ability to change
<br>
the built-in definition of what an entity was
<br>
originally programmed to desire. The same will be true
<br>
of any AI of high intelligence no matter how
<br>
fundamentally built-in its goal system is.
<br>
<p>I don't see how you could ever even come close to
<br>
guaranteeing that a super-intelligent AI's own
<br>
supergoal will be friendly. And you can't seriously
<br>
believe that any human is going to constrain a
<br>
super-intelligent AI's ultimate goal algorithm by
<br>
controlling its seed.
<br>
<p>Your best hope is that super-intelligence is
<br>
correlated with friendliness to humans and not
<br>
orthogonal or anti-correlated.  Correlated basically
<br>
means that being friendly to humans is the intelligent
<br>
thing to do. The worst case scenario is that it’s
<br>
anti-correlated.
<br>
<p><p><p><p><p>__________________________________________________
<br>
Do You Yahoo!?
<br>
Try FREE Yahoo! Mail - the world's greatest free email!
<br>
<a href="http://mail.yahoo.com/">http://mail.yahoo.com/</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3167.html">Mitch Howe: "RE:Novamente goal system"</a>
<li><strong>Previous message:</strong> <a href="3165.html">Ben Goertzel: "goal systems, AI, destruction of the Earth, etc."</a>
<li><strong>Maybe in reply to:</strong> <a href="3146.html">Ben Goertzel: "Novamente goal system"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3167.html">Mitch Howe: "RE:Novamente goal system"</a>
<li><strong>Reply:</strong> <a href="3167.html">Mitch Howe: "RE:Novamente goal system"</a>
<li><strong>Reply:</strong> <a href="3168.html">patrick: "RE: Novamente goal system"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3166">[ date ]</a>
<a href="index.html#3166">[ thread ]</a>
<a href="subject.html#3166">[ subject ]</a>
<a href="author.html#3166">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
