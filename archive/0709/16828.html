<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: META: Created a blog on how AI's react to the Simulation Argument</title>
<meta name="Author" content="Rolf Nelson (rolf.h.d.nelson@gmail.com)">
<meta name="Subject" content="META: Created a blog on how AI's react to the Simulation Argument">
<meta name="Date" content="2007-09-28">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>META: Created a blog on how AI's react to the Simulation Argument</h1>
<!-- received="Fri Sep 28 23:29:36 2007" -->
<!-- isoreceived="20070929052936" -->
<!-- sent="Sat, 29 Sep 2007 01:27:29 -0400" -->
<!-- isosent="20070929052729" -->
<!-- name="Rolf Nelson" -->
<!-- email="rolf.h.d.nelson@gmail.com" -->
<!-- subject="META: Created a blog on how AI's react to the Simulation Argument" -->
<!-- id="79ecaa350709282227t55b1427ei6aee4e5d333ca68@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Rolf Nelson (<a href="mailto:rolf.h.d.nelson@gmail.com?Subject=Re:%20META:%20Created%20a%20blog%20on%20how%20AI's%20react%20to%20the%20Simulation%20Argument"><em>rolf.h.d.nelson@gmail.com</em></a>)<br>
<strong>Date:</strong> Fri Sep 28 2007 - 23:27:29 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16829.html">Stefan Pernar: "Re: META: Created a blog on how AI's react to the Simulation Argument"</a>
<li><strong>Previous message:</strong> <a href="16827.html">Spudboy100@aol.com: "Re: An amazing blind (?!!) boy  (and a super mom!)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16829.html">Stefan Pernar: "Re: META: Created a blog on how AI's react to the Simulation Argument"</a>
<li><strong>Reply:</strong> <a href="16829.html">Stefan Pernar: "Re: META: Created a blog on how AI's react to the Simulation Argument"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16828">[ date ]</a>
<a href="index.html#16828">[ thread ]</a>
<a href="subject.html#16828">[ subject ]</a>
<a href="author.html#16828">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
As a follow-up to the &quot;deterring AI&quot; thread from August, I've created a new
<br>
blog at &lt;<a href="http://aibeliefs.blogspot.com/">http://aibeliefs.blogspot.com/</a>&gt;.
<br>
<p>Description:
<br>
<p>What does an AI believe about the world?
<br>
<p>Nick Bostrom's Simulation Argument
<br>
&lt;<a href="http://www.simulation-argument.com/">http://www.simulation-argument.com/</a>&gt;claims that, using universally
<br>
accepted principles such as Occam's Razor and
<br>
Bayesian Logic, you and I should (under certain conditions) logically
<br>
conclude we are likely living in a simulation.
<br>
<p>Our &quot;AI Beliefs&quot; blog does not concern itself about the nature of reality.
<br>
Instead, our blog asks: under what circumstances would an
<br>
AGI&lt;<a href="http://en.wikipedia.org/wiki/Artificial_general_intelligence">http://en.wikipedia.org/wiki/Artificial_general_intelligence</a>&gt;reach
<br>
the conclusion that it might be in a simulated environment? The
<br>
purposes of asking this question include:
<br>
<p>1. Answering this question may provide some unsolicited insight towards the
<br>
question of &quot;how to predict the behavior of an AGI&quot;, which in turn may
<br>
provide some insight towards the World's Most Important Math Problem, the
<br>
question of &quot;how to build a Friendly
<br>
AI&lt;<a href="http://en.wikipedia.org/wiki/Friendly_Artificial_Intelligence">http://en.wikipedia.org/wiki/Friendly_Artificial_Intelligence</a>&gt;.&quot;
<br>
The Simulation Argument might be deliberately built into the design of a
<br>
Friendly AI, or alternatively may be used as a test of how well a proposed
<br>
Friendly AI handles such a philosophical
<br>
crisis&lt;<a href="http://www.intelligence.org/upload/CFAI/design/structure/crisis.html">http://www.intelligence.org/upload/CFAI/design/structure/crisis.html</a>&gt;
<br>
.
<br>
<p>2. Answering this question may make it possible to develop a &quot;last line of
<br>
defense&quot; against an UnFriendly AGI that was accidentally loosed upon the
<br>
world, even if the AGI gained a trans-human level of intelligence. Such a
<br>
&quot;last line of defense&quot; might include trying to convince the AGI that it may
<br>
be inside a simulated environment.
<br>
<p>-Rolf
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16829.html">Stefan Pernar: "Re: META: Created a blog on how AI's react to the Simulation Argument"</a>
<li><strong>Previous message:</strong> <a href="16827.html">Spudboy100@aol.com: "Re: An amazing blind (?!!) boy  (and a super mom!)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16829.html">Stefan Pernar: "Re: META: Created a blog on how AI's react to the Simulation Argument"</a>
<li><strong>Reply:</strong> <a href="16829.html">Stefan Pernar: "Re: META: Created a blog on how AI's react to the Simulation Argument"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16828">[ date ]</a>
<a href="index.html#16828">[ thread ]</a>
<a href="subject.html#16828">[ subject ]</a>
<a href="author.html#16828">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
