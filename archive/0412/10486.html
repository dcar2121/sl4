<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Conservative Estimation of the Economic Impact of Artificial Intelligence</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Conservative Estimation of the Economic Impact of Artificial Intelligence">
<meta name="Date" content="2004-12-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Conservative Estimation of the Economic Impact of Artificial Intelligence</h1>
<!-- received="Wed Dec 29 09:00:37 2004" -->
<!-- isoreceived="20041229160037" -->
<!-- sent="Wed, 29 Dec 2004 11:00:29 -0500" -->
<!-- isosent="20041229160029" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Conservative Estimation of the Economic Impact of Artificial Intelligence" -->
<!-- id="JNEIJCJJHIEAILJBFHILAEHFCPAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3ad827f30412280329221f0922@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Conservative%20Estimation%20of%20the%20Economic%20Impact%20of%20Artificial%20Intelligence"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Wed Dec 29 2004 - 09:00:29 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10487.html">BillK: "Google Directory AI links"</a>
<li><strong>Previous message:</strong> <a href="10485.html">justin corwin: "Conservative Estimation of the Economic Impact of Artificial Intelligence"</a>
<li><strong>In reply to:</strong> <a href="10485.html">justin corwin: "Conservative Estimation of the Economic Impact of Artificial Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0501/10546.html">Peter Voss: "a2i2 news update"</a>
<li><strong>Reply:</strong> <a href="../0501/10546.html">Peter Voss: "a2i2 news update"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10486">[ date ]</a>
<a href="index.html#10486">[ thread ]</a>
<a href="subject.html#10486">[ subject ]</a>
<a href="author.html#10486">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi Justin,
<br>
<p>My opinion is that nearly all intelligent businesspeople understand that a
<br>
powerful AGI would be amazingly economically lucrative.
<br>
<p>However, by the same token, nearly all such folks feel that a powerful AGI
<br>
is a *long way off*.
<br>
<p>It will not be at all difficult to get business partnerships or investment
<br>
money, in massive amounts, once one actually has a powerful AGI -- or a
<br>
sufficiently convincing technology demonstration that an average computer
<br>
science professor is convinced by it that one has the secret to building a
<br>
powerful AGI.
<br>
<p>What is difficult is to get anyone to invest in R&amp;D aimed at creating an
<br>
AGI -- precisely because they believe it's a long way off.  And because the
<br>
mainstream of scientific researchers firmly believes and argues that it's a
<br>
long way off.
<br>
<p>-- Ben G
<br>
<p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Conservative%20Estimation%20of%20the%20Economic%20Impact%20of%20Artificial%20Intelligence">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Conservative%20Estimation%20of%20the%20Economic%20Impact%20of%20Artificial%20Intelligence">owner-sl4@sl4.org</a>]On Behalf Of justin
</em><br>
<em>&gt; corwin
</em><br>
<em>&gt; Sent: Tuesday, December 28, 2004 6:29 AM
</em><br>
<em>&gt; To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Conservative%20Estimation%20of%20the%20Economic%20Impact%20of%20Artificial%20Intelligence">sl4@sl4.org</a>
</em><br>
<em>&gt; Subject: Conservative Estimation of the Economic Impact of Artificial
</em><br>
<em>&gt; Intelligence
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; In my work, I concentrate largely on the practical, necessary research
</em><br>
<em>&gt; to allow us to build an artificial intelligence. It is the central
</em><br>
<em>&gt; fascination of most of the people in my company. I would imagine that
</em><br>
<em>&gt; most people in this community have great interest(if not actual
</em><br>
<em>&gt; involvement) in the research, development, and application of novel
</em><br>
<em>&gt; intelligent systems, IA, AI, or otherwise.
</em><br>
<em>&gt;
</em><br>
<em>&gt; However, in the process of explaining my involvement to other people,
</em><br>
<em>&gt; as well as attempting to instill enthusiasm (or at least explain
</em><br>
<em>&gt; potential impact) for my research, I've been encountering the
</em><br>
<em>&gt; following baffling response with increasing frequency. My fearless
</em><br>
<em>&gt; leader here at A2I2, Peter Voss, has been encountering the same thing.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;How do you intend to productize your research, what is it that you
</em><br>
<em>&gt; expect to come out of this company, and how can you make money?&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; I would like to take a moment to say that I am only indirectly
</em><br>
<em>&gt; interested in money. My involvement in A2I2 and AI research in general
</em><br>
<em>&gt; is motivated both by interest and idealism, with a backdrop of
</em><br>
<em>&gt; pragmatic analysis. AI is a very large lever. It will count, in game
</em><br>
<em>&gt; theoretic terms, an inconceivable amount, before changing the
</em><br>
<em>&gt; landscape entirely. Money, for me, is just a poorly normalized utility
</em><br>
<em>&gt; token, and inasmuch as I am interested in it, I expect to be more than
</em><br>
<em>&gt; able to backwards exchange the influence I have on the creation of AI
</em><br>
<em>&gt; for it. Digression ended.
</em><br>
<em>&gt;
</em><br>
<em>&gt; What these people are really asking, via the agency of hypothetical
</em><br>
<em>&gt; investors, is &quot;what is AI good for, and how can that be delivered from
</em><br>
<em>&gt; your research.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Initially, much like Peter had in previous discussion, I discounted
</em><br>
<em>&gt; this reaction as simply the miscategorization of AI as 'yet another
</em><br>
<em>&gt; techno-widget', to be judged in the marketplace and priced for proper
</em><br>
<em>&gt; placement on shelves. It has become clear to me, however, that it runs
</em><br>
<em>&gt; somewhat deeper than this.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Artificial Intelligence, even very weakly achieved, is not just
</em><br>
<em>&gt; another technology. It represents, at the very least, a complete
</em><br>
<em>&gt; industry, and most likely, is one of those events that redefines the
</em><br>
<em>&gt; landscape of human activity.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Any transhuman intelligence, of course, represents an absolute
</em><br>
<em>&gt; departure from human prediction, but for the time being, let us speak
</em><br>
<em>&gt; of what we can.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The unfortunate thing, from my point of view, is that generating a
</em><br>
<em>&gt; conservative estimation of the economic impact of AI is nearly
</em><br>
<em>&gt; impossible. It pre-supposes several things.
</em><br>
<em>&gt;
</em><br>
<em>&gt; -First, that AI impacts economically before it changes the entire
</em><br>
<em>&gt; landscape, this seems quite possible, AI will take some time to
</em><br>
<em>&gt; develop, and even once complete will require some time to run. Even if
</em><br>
<em>&gt; it's just inflation hitting the roof as everyone with any money does
</em><br>
<em>&gt; whatever they think will avert the apocalypse during the last week of
</em><br>
<em>&gt; the Final Program, that counts as economic impact.
</em><br>
<em>&gt;
</em><br>
<em>&gt; -Second, that there is some period of stability in the development of
</em><br>
<em>&gt; AI that allows for AI 'products' to be evaluated in terms of
</em><br>
<em>&gt; relatively cognizant economic terms. This is very tricky. It has been
</em><br>
<em>&gt; popularly supposed by some that human-commensurate intelligence
</em><br>
<em>&gt; represents the top level, or a hard barrier, that AI research will
</em><br>
<em>&gt; continue to that point and then stop, or at least be slowed. It is
</em><br>
<em>&gt; likely that a certain level of intelligence represents the maximum
</em><br>
<em>&gt; effective potential of a particular design, due to scaling laws,
</em><br>
<em>&gt; architectural support requirements, or flaws in the design to start
</em><br>
<em>&gt; with. Unfortunately, an AI will not be using the same design as a
</em><br>
<em>&gt; human. It is, in my estimation, just as likely to top out at the
</em><br>
<em>&gt; commensurate intelligence of a mouse, or a dolphin, or so far above us
</em><br>
<em>&gt; that the intelligence is not measurable. It seems clear to me that
</em><br>
<em>&gt; minds need not follow a uniform plan with uniform strengths, although
</em><br>
<em>&gt; they may be very correlated. This makes design-independent analysis
</em><br>
<em>&gt; complicated.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Some hope in the form of computer power requirements, assuming
</em><br>
<em>&gt; biologicals and previous experience with unintelligent mechanical
</em><br>
<em>&gt; computation hold, the physical task of running an intelligence may
</em><br>
<em>&gt; limit it to certain levels of potential until larger/faster computers
</em><br>
<em>&gt; can be built.  Unfortunately even Kurzweil's rather charming little
</em><br>
<em>&gt; graphs give us little time before available computation far outstrips
</em><br>
<em>&gt; human level, leaving us in the same boat. The stability given us there
</em><br>
<em>&gt; is fleeting, but does allow enough years to be evaluated on the
</em><br>
<em>&gt; economic scale.
</em><br>
<em>&gt;
</em><br>
<em>&gt; -Third, that our status, as AI researchers and developers, will give
</em><br>
<em>&gt; us a privileged and controllable stake in the construction and
</em><br>
<em>&gt; deployment of AI products and resources, allowing us to capitalize on
</em><br>
<em>&gt; our investment, as per the standard industrial research model. This
</em><br>
<em>&gt; seems fairly safe, until one realizes that there are many forces that
</em><br>
<em>&gt; oppose such status, merely because of the nature of AI. Governments
</em><br>
<em>&gt; may not allow technology of this kind to remain concentrated in the
</em><br>
<em>&gt; hands of private corporations. AI may follow the same path as other
</em><br>
<em>&gt; technologies, with many parallel breakthroughs at the same time,
</em><br>
<em>&gt; leaving us as merely members of a population of AI projects suddenly
</em><br>
<em>&gt; getting results. The information nature of this development increases
</em><br>
<em>&gt; this problem a great deal. I have no reason to imagine that AI
</em><br>
<em>&gt; development requires specialized hardware, or is impossible to employ
</em><br>
<em>&gt; without the experience gained in the research of said AI software. So
</em><br>
<em>&gt; piracy, industrial espionage, and simple reverse-engineering may
</em><br>
<em>&gt; render our position very tenuous indeed. I have no easy answers for
</em><br>
<em>&gt; this assumption, save that while worrying, little evidence exists
</em><br>
<em>&gt; either way. I personally believe that our position is privileged and
</em><br>
<em>&gt; will remain so until the formation of other AI projects with
</em><br>
<em>&gt; commensurate theory, developed technology, and talent, at that point
</em><br>
<em>&gt; it becomes more problematic.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Assuming we have answers to all these questions, we may find that AI
</em><br>
<em>&gt; is indeed a good way to make money, or at least in the near term.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I have a story I can tell here, but the supporting evidence is
</em><br>
<em>&gt; abstract, and indirect. Artificial Intelligence is likely, in my
</em><br>
<em>&gt; opinion, to follow an accelerating series of plateaus of development,
</em><br>
<em>&gt; starting with the low animal intelligence which is the focus of our
</em><br>
<em>&gt; research now. Progress will be slow, and spin off products limited in
</em><br>
<em>&gt; their scope. As intelligence increases, the more significant
</em><br>
<em>&gt; bottleneck will be trainability and transfer of learned content
</em><br>
<em>&gt; between AIs. This period represents the most fruitful opportunity for
</em><br>
<em>&gt; standard economic gain. The AI technology at this point will create
</em><br>
<em>&gt; three divisions across most industry, in terms of decision technology.
</em><br>
<em>&gt; You will have tasks that require human decision-making, tasks that can
</em><br>
<em>&gt; be fully mechanized, performed by standard programmatic
</em><br>
<em>&gt; approaches(normal coding, specialized hardware, special purpose
</em><br>
<em>&gt; products), and a new category, AI decision-making. This will be any
</em><br>
<em>&gt; task too general or too expensive to be solved algorithmically, and
</em><br>
<em>&gt; not complex enough to require human intervention. Both borders will
</em><br>
<em>&gt; expand, as it gets cheaper to throw AI at the problem than to go
</em><br>
<em>&gt; through and solve it mechanically, and as the upper bound of decision
</em><br>
<em>&gt; making gets more and more capable.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I'm afraid I have no real evidence as to how long this period will
</em><br>
<em>&gt; last. It depends entirely on the difficulty of increasing the
</em><br>
<em>&gt; intelligence of the AI, which may reside in design, hardware, and to a
</em><br>
<em>&gt; certain extent, motivation(goal systems are a thesis in themselves,
</em><br>
<em>&gt; ask EY).  I suspect, based on my experiences thus far, that early AI
</em><br>
<em>&gt; designs will be very lossy and faulty and poorly optimized for
</em><br>
<em>&gt; increasing in intelligence. This may mean that a complete redesign of
</em><br>
<em>&gt; AI theory will be necessary to get to the next series of plateaus.
</em><br>
<em>&gt; Unless this is simply beyond human capability, there is no reason to
</em><br>
<em>&gt; think this will take any longer than the development of AI theory
</em><br>
<em>&gt; sufficient to get us to this point.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Sometime after this, economic aspirations become fleeting in the
</em><br>
<em>&gt; general upheaval and reconstitution caused by the arrival of another
</em><br>
<em>&gt; kind of intelligence. Some might say this is rather the point of AI
</em><br>
<em>&gt; research.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Projecting into the future is always dangerous. I think that any
</em><br>
<em>&gt; attempt, especially the one above, to characterize the trajectory of
</em><br>
<em>&gt; any technology is doomed to be largely irrelevant. But some choices
</em><br>
<em>&gt; must be made on best available guesses, so here are mine. AI research
</em><br>
<em>&gt; will change a lot of things. In the near term, it will remain a fringe
</em><br>
<em>&gt; activity, and people will still ask the strange question 'what will
</em><br>
<em>&gt; those AIs be good for, anyway?'. But some investors will come, and the
</em><br>
<em>&gt; clearest way I can communicate with them what the goals and value of
</em><br>
<em>&gt; AI research is that it is vastly enabling. I don't know what the first
</em><br>
<em>&gt; task an AI will perform is. I know that it will be something that
</em><br>
<em>&gt; can't be done with anything else. It represents, in the near term, an
</em><br>
<em>&gt; investment in future capability. If money is what you're after
</em><br>
<em>&gt; primarily, I don't know how to defend an investment in AI research
</em><br>
<em>&gt; from the perspective of, say, venture capital. I can point to examples
</em><br>
<em>&gt; of enabling technology, like CAD, or tooling, or electrical power,
</em><br>
<em>&gt; which did not fit into the world they arrived in, but created their
</em><br>
<em>&gt; own industries.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I'm not saying I can't make up clever uses for AI technologies that
</em><br>
<em>&gt; could make a gazillion dollars, if I had designs for them in my hand.
</em><br>
<em>&gt; There are obvious and clear storytelling ideas. But that would be
</em><br>
<em>&gt; intellectually dishonest. I'm looking for a way to express, in terms
</em><br>
<em>&gt; of investment return, what AI is likely to actually do for us, in a
</em><br>
<em>&gt; conservative, defensible sense.
</em><br>
<em>&gt;
</em><br>
<em>&gt; This must be separated from, for example, safety concerns, in which it
</em><br>
<em>&gt; is perhaps useful to imagine, as some do on this forum, what the
</em><br>
<em>&gt; failure modes, what the fastest take off, what the actual capability
</em><br>
<em>&gt; of such developments may be. That isn't helpful in this kind of
</em><br>
<em>&gt; planning.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I must anticipate a response suggesting that non-profit, private
</em><br>
<em>&gt; efforts to research AI, such as the Singularity Institute, AGIRI, etc
</em><br>
<em>&gt; are better suited for this subject matter, and in fact invalidate my
</em><br>
<em>&gt; queries as relevant at all. I remain very doubtful that this is the
</em><br>
<em>&gt; case. AI is not something to be solved quickly, nor something to be
</em><br>
<em>&gt; solved with few people with no money. It is in it's first stages of
</em><br>
<em>&gt; real development, and a massive amount of research and data needs to
</em><br>
<em>&gt; be collected,  if AI theories are to be informed by more than
</em><br>
<em>&gt; introspection and biological analogue. Like so many things in our
</em><br>
<em>&gt; modern world, AI will be done long before we can properly evaluate and
</em><br>
<em>&gt; prepare ourselves for the results, however long it takes. But people
</em><br>
<em>&gt; need to have reasons to join AI efforts, to fund them, and to support
</em><br>
<em>&gt; them, in levels thus far not seen. I submit this is at least partially
</em><br>
<em>&gt; because this kind of analysis is either not publicised, or has simply
</em><br>
<em>&gt; not been done.
</em><br>
<em>&gt;
</em><br>
<em>&gt; ...
</em><br>
<em>&gt;
</em><br>
<em>&gt; This kind of analysis also raises the rather uncomfortable spectre of
</em><br>
<em>&gt; doubt, that I have jumped into a field of study without sufficient
</em><br>
<em>&gt; research and investigation, or have unrealistic(at least ungrounded)
</em><br>
<em>&gt; expectations for the fruits of my work. I submit that my primary
</em><br>
<em>&gt; interest in AI is at least partially unrelated to gain of these kinds,
</em><br>
<em>&gt; and secondarily informed by the safety concerns, asymmetric potential,
</em><br>
<em>&gt; and increasing importance investigated much more clearly by other
</em><br>
<em>&gt; authors(Vinge, Yudkowsky, Good).
</em><br>
<em>&gt;
</em><br>
<em>&gt; Any responses or questions can be asked on the sl4 mailing list, to
</em><br>
<em>&gt; which this is posted, to me privately, or on my blog.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Justin Corwin
</em><br>
<em>&gt; <a href="mailto:outlawpoet@hell.com?Subject=RE:%20Conservative%20Estimation%20of%20the%20Economic%20Impact%20of%20Artificial%20Intelligence">outlawpoet@hell.com</a>
</em><br>
<em>&gt; <a href="http://outlawpoet.blogspot.com">http://outlawpoet.blogspot.com</a>
</em><br>
<em>&gt; <a href="http://www.adaptiveai.com">http://www.adaptiveai.com</a>
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10487.html">BillK: "Google Directory AI links"</a>
<li><strong>Previous message:</strong> <a href="10485.html">justin corwin: "Conservative Estimation of the Economic Impact of Artificial Intelligence"</a>
<li><strong>In reply to:</strong> <a href="10485.html">justin corwin: "Conservative Estimation of the Economic Impact of Artificial Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0501/10546.html">Peter Voss: "a2i2 news update"</a>
<li><strong>Reply:</strong> <a href="../0501/10546.html">Peter Voss: "a2i2 news update"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10486">[ date ]</a>
<a href="index.html#10486">[ thread ]</a>
<a href="subject.html#10486">[ subject ]</a>
<a href="author.html#10486">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
