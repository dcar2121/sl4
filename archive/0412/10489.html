<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Conservative Estimation of the Economic Impact of Artificial Intelligence</title>
<meta name="Author" content="Yan King Yin (y.k.y@lycos.com)">
<meta name="Subject" content="Re: Conservative Estimation of the Economic Impact of Artificial Intelligence">
<meta name="Date" content="2004-12-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Conservative Estimation of the Economic Impact of Artificial Intelligence</h1>
<!-- received="Thu Dec 30 07:12:49 2004" -->
<!-- isoreceived="20041230141249" -->
<!-- sent="Thu, 30 Dec 2004 09:12:46 -0500" -->
<!-- isosent="20041230141246" -->
<!-- name="Yan King Yin" -->
<!-- email="y.k.y@lycos.com" -->
<!-- subject="Re: Conservative Estimation of the Economic Impact of Artificial Intelligence" -->
<!-- id="20041230141246.197EB3384B@ws7-3.us4.outblaze.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="Conservative Estimation of the Economic Impact of Artificial Intelligence" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Yan King Yin (<a href="mailto:y.k.y@lycos.com?Subject=Re:%20Conservative%20Estimation%20of%20the%20Economic%20Impact%20of%20Artificial%20Intelligence"><em>y.k.y@lycos.com</em></a>)<br>
<strong>Date:</strong> Thu Dec 30 2004 - 07:12:46 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10490.html">Russell Wallace: "Re: Conservative Estimation of the Economic Impact of Artificial Intelligence"</a>
<li><strong>Previous message:</strong> <a href="10488.html">Eliezer Yudkowsky: "Re: Conservative Estimation of the Economic Impact of Artificial Intelligence"</a>
<li><strong>Maybe in reply to:</strong> <a href="10485.html">justin corwin: "Conservative Estimation of the Economic Impact of Artificial Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0501/10522.html">Stephen Reed: "Re: Conservative Estimation of the Economic Impact of Artificial Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10489">[ date ]</a>
<a href="index.html#10489">[ thread ]</a>
<a href="subject.html#10489">[ subject ]</a>
<a href="author.html#10489">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi Justin =)
<br>
<p>Your exposition is very readable and well-thought, so I wish to chime
<br>
in and share some opinion.
<br>
<p><em>&gt; [...]
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &quot;How do you intend to productize your research, what is it that you
</em><br>
<em>&gt; expect to come out of this company, and how can you make money?&quot;
</em><br>
<p>This is a very important question for for-profit AI companies.  The
<br>
assumption that, simply because AI is intelligent, that it can *replace*
<br>
all human jobs, is actually questionable.  I think there will be a lot
<br>
of resistence from society to oppose this trend.  For example, right
<br>
now, with 2004 technology, we can already replace all McDonalds' workers
<br>
with robots, but this has not happened, even though economically it is
<br>
feasible.  On the other hand, the erosion of jobs by automation is
<br>
indeed happening right now.  So I think we should understand that the
<br>
transformation of society by automation is governed by several factors:
<br>
economical, technological, and (often neglected) societal and eco-
<br>
-logical factors.
<br>
<p><em>&gt; [...]
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Artificial Intelligence, even very weakly achieved, is not just
</em><br>
<em>&gt; another technology. It represents, at the very least, a complete
</em><br>
<em>&gt; industry, and most likely, is one of those events that redefines the
</em><br>
<em>&gt; landscape of human activity.
</em><br>
<p>I agree that it will be a new industry, but can you pinpoint what
<br>
exactly is about AI, that makes it qualitatively different from the
<br>
tools/technologies we had before?  I think, on a quite deep level,
<br>
that there is no real difference.
<br>
<p><em>&gt; -Third, that our status, as AI researchers and developers, will give
</em><br>
<em>&gt; us a privileged and controllable stake in the construction and
</em><br>
<em>&gt; deployment of AI products and resources, allowing us to capitalize on
</em><br>
<em>&gt; our investment, as per the standard industrial research model. This
</em><br>
<em>&gt; seems fairly safe, until one realizes that there are many forces that
</em><br>
<em>&gt; oppose such status, merely because of the nature of AI. Governments
</em><br>
<em>&gt; may not allow technology of this kind to remain concentrated in the
</em><br>
<em>&gt; hands of private corporations. AI may follow the same path as other
</em><br>
<em>&gt; technologies, with many parallel breakthroughs at the same time,
</em><br>
<em>&gt; leaving us as merely members of a population of AI projects suddenly
</em><br>
<em>&gt; getting results. The information nature of this development increases
</em><br>
<em>&gt; this problem a great deal. I have no reason to imagine that AI
</em><br>
<em>&gt; development requires specialized hardware, or is impossible to employ
</em><br>
<em>&gt; without the experience gained in the research of said AI software. So
</em><br>
<em>&gt; piracy, industrial espionage, and simple reverse-engineering may
</em><br>
<em>&gt; render our position very tenuous indeed. I have no easy answers for
</em><br>
<em>&gt; this assumption, save that while worrying, little evidence exists
</em><br>
<em>&gt; either way. I personally believe that our position is privileged and
</em><br>
<em>&gt; will remain so until the formation of other AI projects with
</em><br>
<em>&gt; commensurate theory, developed technology, and talent, at that point
</em><br>
<em>&gt; it becomes more problematic.
</em><br>
<p>There is some truth in what you said above.  Information, in general,
<br>
is very difficult to control, but it is also true that there has always
<br>
been control of information, even in advanced societies (eg laws against
<br>
piracy of software).  Again, your assumption that AI will spread extremely
<br>
fast and without resistence is ignoring the human factors.
<br>
<p><em>&gt; I have a story I can tell here, but the supporting evidence is
</em><br>
<em>&gt; abstract, and indirect. Artificial Intelligence is likely, in my
</em><br>
<em>&gt; opinion, to follow an accelerating series of plateaus of development,
</em><br>
<em>&gt; starting with the low animal intelligence which is the focus of our
</em><br>
<em>&gt; research now. Progress will be slow, and spin off products limited in
</em><br>
<em>&gt; their scope. As intelligence increases, the more significant
</em><br>
<em>&gt; bottleneck will be trainability and transfer of learned content
</em><br>
<em>&gt; between AIs. This period represents the most fruitful opportunity for
</em><br>
<em>&gt; standard economic gain. The AI technology at this point will create
</em><br>
<em>&gt; three divisions across most industry, in terms of decision technology.
</em><br>
<em>&gt; You will have tasks that require human decision-making, tasks that can
</em><br>
<em>&gt; be fully mechanized, performed by standard programmatic
</em><br>
<em>&gt; approaches(normal coding, specialized hardware, special purpose
</em><br>
<em>&gt; products), and a new category, AI decision-making. This will be any
</em><br>
<em>&gt; task too general or too expensive to be solved algorithmically, and
</em><br>
<em>&gt; not complex enough to require human intervention. Both borders will
</em><br>
<em>&gt; expand, as it gets cheaper to throw AI at the problem than to go
</em><br>
<em>&gt; through and solve it mechanically, and as the upper bound of decision
</em><br>
<em>&gt; making gets more and more capable.
</em><br>
<p>When all the factors are combined in consideration, it becomes very
<br>
likely that AI development and adoption will be gradual.  In fact,
<br>
right now I and some partners are having a hard time trying to think
<br>
of a business model for our visual recognition prototype.  You can
<br>
say that this here is an economic/social barrier -- The technology
<br>
is here, but people don't want the automation;  They are OK with
<br>
doing things manually!!
<br>
<p><em>&gt; I'm not saying I can't make up clever uses for AI technologies that
</em><br>
<em>&gt; could make a gazillion dollars, if I had designs for them in my hand.
</em><br>
<em>&gt; There are obvious and clear storytelling ideas. But that would be
</em><br>
<em>&gt; intellectually dishonest. I'm looking for a way to express, in terms
</em><br>
<em>&gt; of investment return, what AI is likely to actually do for us, in a
</em><br>
<em>&gt; conservative, defensible sense.
</em><br>
<p>What can AI do for us?  In the short term, I think we really have
<br>
to think hard to create some new niches.  The prospect of having to
<br>
fire a huge number of low-skill labor is a nightmare, so it may be
<br>
wiser to stay clear of that.
<br>
<p>YKY
<br>
<p><pre>
-- 
_______________________________________________
Find what you are looking for with the Lycos Yellow Pages
<a href="http://r.lycos.com/r/yp_emailfooter/http://yellowpages.lycos.com/default.asp?SRC=lycos10">http://r.lycos.com/r/yp_emailfooter/http://yellowpages.lycos.com/default.asp?SRC=lycos10</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10490.html">Russell Wallace: "Re: Conservative Estimation of the Economic Impact of Artificial Intelligence"</a>
<li><strong>Previous message:</strong> <a href="10488.html">Eliezer Yudkowsky: "Re: Conservative Estimation of the Economic Impact of Artificial Intelligence"</a>
<li><strong>Maybe in reply to:</strong> <a href="10485.html">justin corwin: "Conservative Estimation of the Economic Impact of Artificial Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0501/10522.html">Stephen Reed: "Re: Conservative Estimation of the Economic Impact of Artificial Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10489">[ date ]</a>
<a href="index.html#10489">[ thread ]</a>
<a href="subject.html#10489">[ subject ]</a>
<a href="author.html#10489">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
