<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: FW: [agi] Artificial General Intelligence Research - Help Wanted</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="FW: [agi] Artificial General Intelligence Research - Help Wanted">
<meta name="Date" content="2004-12-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>FW: [agi] Artificial General Intelligence Research - Help Wanted</h1>
<!-- received="Wed Dec 22 16:29:03 2004" -->
<!-- isoreceived="20041222232903" -->
<!-- sent="Wed, 22 Dec 2004 18:28:56 -0500" -->
<!-- isosent="20041222232856" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="FW: [agi] Artificial General Intelligence Research - Help Wanted" -->
<!-- id="JNEIJCJJHIEAILJBFHILCENHCOAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="[agi] Artificial General Intelligence Research - Help Wanted" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=FW:%20[agi]%20Artificial%20General%20Intelligence%20Research%20-%20Help%20Wanted"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Wed Dec 22 2004 - 16:28:56 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10480.html">Ben Goertzel: "RE: [agi] Artificial General Intelligence Research - Help Wanted"</a>
<li><strong>Previous message:</strong> <a href="10478.html">Ben Goertzel: "Symposium on machine ethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10480.html">Ben Goertzel: "RE: [agi] Artificial General Intelligence Research - Help Wanted"</a>
<li><strong>Reply:</strong> <a href="10480.html">Ben Goertzel: "RE: [agi] Artificial General Intelligence Research - Help Wanted"</a>
<li><strong>Reply:</strong> <a href="10483.html">Ben Goertzel: "RE: [agi] Artificial General Intelligence Research - Help Wanted"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10479">[ date ]</a>
<a href="index.html#10479">[ thread ]</a>
<a href="subject.html#10479">[ subject ]</a>
<a href="author.html#10479">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi all,
<br>
<p>Recently David Hart -- who's been working with me on AGIRI (the nonprofit
<br>
side of the Novamente project, which hasn't been very active, but we'd like
<br>
to make it more so, because funding Novamente AGI development via the
<br>
minimal revenue from our narrow-AI consulting projects is proving
<br>
*massively* too sluggish for our tastes...) -- recently posted an email on
<br>
the list pertaining an AGIRI fundraising drive.
<br>
<p>By way of commentary on this, I'll post here an excerpt from the informal
<br>
&quot;Concluding Remarks&quot; to the latest, still-not-yet-finished draft of the
<br>
ever-evolving and improving &quot;Novamente book&quot; (now three books).   I have 6
<br>
chapters to revise out of the 29 in the book and then this version will be
<br>
ready to send off to the publisher ;-))
<br>
<p>-- Ben G
<br>
<p>The excerpt:
<br>
<p>**********************
<br>
<p>Reactions of people who have read early drafts of this book have varied
<br>
widely.  Most readers are surprised and at least mildly impressed that
<br>
anyone has taken the trouble to work out a serious AGI design in so much
<br>
detail.   However, not surprisingly, there is a lot of skepticism regarding
<br>
our conjecture that, when fully implemented and tuned and taught, the
<br>
Novamente design will actually lead to general intelligence at or beyond the
<br>
human level.   The only complaints that really interest us are the ones made
<br>
by people who believe that some AGI design is possible.  Among these
<br>
readers, the primary complaints made seem to be things like:
<br>
<p>&nbsp;&nbsp;a.. The design is too complicated, there are too many parts to coordinate,
<br>
too many things that could go wrong
<br>
&nbsp;&nbsp;&nbsp;&nbsp;a.. Answer: Yes it IS complicated, and we wish it were simpler, but we
<br>
haven’t found a simpler design that doesn’t seem patently unworkable.  Note
<br>
that the human brain is also mighty complicated – this may just be the
<br>
nature of making general intelligence work with limited resources.
<br>
&nbsp;&nbsp;b.. BOA and PTL are not enough, you need some kind of more fundamentally
<br>
innovative, efficient, or (whatever) learning algorithm.  This complaint
<br>
never comes along with any suggestion regarding what this “mystery
<br>
&nbsp;algorithm” might be, though – most often it is hypothesized that detailed
<br>
understanding of the human brain will reveal it.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;a.. Answer: This is possible, but it seems to us that a hybrid of BOA
<br>
and PTL will be enough.  The question is whether deeper integration of BOA
<br>
and PTL than we’ve done now will allow BOA learning of reasonably large
<br>
(500-1000 node) combinator trees.  If so, then we almost surely don’t need
<br>
any other learning algorithm, though other algorithms may be helpful.
<br>
&nbsp;&nbsp;c.. You’re programming in too much stuff: you should be making more of a
<br>
pure self-organizing learning system without so many in-built rules and
<br>
heuristics
<br>
&nbsp;&nbsp;&nbsp;&nbsp;a.. Answer: Well, the human brain seems to have a lot of stuff
<br>
programmed in, as well as a robust capability for self-organizing learning.
<br>
Conceptually, we love the idea of a pure self-organizing learning system as
<br>
much as anyone, but it doesn’t seem to be feasible given realistic time and
<br>
processing power and memory constraints.
<br>
&nbsp;&nbsp;d.. Programming explicit logical rules is just wrong; logic should occur
<br>
as an emergent phenomenon from more fundamental subsymbolic dynamics
<br>
&nbsp;&nbsp;&nbsp;&nbsp;a.. Answer: Probabilistic logic is not necessarily symbolic; in the
<br>
Novamente design we use PTL for both subsymbolic and symbolic learning,
<br>
which we believe is a highly elegant approach.  The differences between
<br>
subsymbolic probabilistic logic and e.g. Hebbian learning are not really
<br>
very great when you look at them mathematically rather than in terms of
<br>
verbiage.  The Novamente design is not tied to programming-in logical
<br>
knowledge a la Cyc.  It’s true that the PTL rules are programmed in (though
<br>
in Novamente 2.0 they will be made adaptable), but this isn’t so different
<br>
from the brain having particular kinds of long-term potentiation wired in,
<br>
is it?
<br>
Of course, we don’t expect our answers to fully please the complainants –
<br>
but they generally seem to convince the complainants that we’ve thought
<br>
through the issues carefully.  Almost no one who has seriously studied
<br>
Novamente has accused us of being naïve or foolish in our approach, though
<br>
obviously many have considered our confidence excessive, and have proposed
<br>
other directions as seeming more promising.
<br>
<p>At time of writing, our biggest frustrations with the Novamente project are
<br>
twofold.  The first is a technical frustration: existing software tools are
<br>
a pain to work with.  Both Windows and Unix carry with them their own forms
<br>
of irritation, similarly with all existing programming languages: C++, Java,
<br>
LISP, functional and logical languages.   All existing operating systems and
<br>
programming languages place unnecessary hassles in the way of creating a
<br>
powerful general AI.  As a Novamente software developer, one spends too much
<br>
of one’s time wrestling with purely software-level issues that have no
<br>
direct connection to AI.  And needless to say, the software industry does
<br>
not put much effort into creating software development environments that are
<br>
specifically conducive to AGI R&amp;D!
<br>
<p>The second frustration is financial: because of the radical nature of the
<br>
project, we have not been able to secure a significant amount of R&amp;D
<br>
funding.  We have sustained the project, so far, based on a combination of a
<br>
small amount of R&amp;D funding with revenues derived from small businesses that
<br>
we’ve built by deploying portions of the Novamente system within narrow-AI
<br>
software products.  This is not the right way to build a thinking machine.
<br>
What the Novamente project needs is a small group of programmers and
<br>
scientists dedicated full-time to creation of AGI.  We view the current
<br>
phase of Novamente development as preliminary – our goal is to get the
<br>
system to the stage where it does things that are exciting enough that
<br>
marshalling significant R&amp;D funding becomes easy.  At that point we’ll be
<br>
able to pay a top-notch full-time team (including the authors and the other
<br>
Novamente originators) to complete the job, and progress will start going an
<br>
awful lot faster.
<br>
<p>We mention these frustrations not out of the desire to personally vent, but
<br>
mainly because of the general point that they illustrate: neither
<br>
contemporary human society, nor the computer science community, nor even the
<br>
AI community is at all supportive of the quest to create powerful AGI
<br>
software.  We believe that in hindsight, after AGI has been created, this
<br>
lack of support and enthusiasm will be viewed with incredulity.  AGI is a
<br>
hard problem but it’s far from an impossible problem – it seems clear that
<br>
there are many possible solutions, and we believe that Novamente is one of
<br>
them.  Almost surely it’s not the best one, but so far as we know it’s the
<br>
only likely-looking solution that’s been proposed in detail so far.
<br>
<p>&nbsp;************
<br>
<p>&nbsp;-----Original Message-----
<br>
From: <a href="mailto:owner-agi@v2.listbox.com?Subject=FW:%20[agi]%20Artificial%20General%20Intelligence%20Research%20-%20Help%20Wanted">owner-agi@v2.listbox.com</a> [mailto:<a href="mailto:owner-agi@v2.listbox.com?Subject=FW:%20[agi]%20Artificial%20General%20Intelligence%20Research%20-%20Help%20Wanted">owner-agi@v2.listbox.com</a>]On Behalf Of
<br>
David Hart
<br>
Sent: Tuesday, December 21, 2004 11:20 AM
<br>
To: <a href="mailto:agi@v2.listbox.com?Subject=FW:%20[agi]%20Artificial%20General%20Intelligence%20Research%20-%20Help%20Wanted">agi@v2.listbox.com</a>
<br>
Subject: [agi] Artificial General Intelligence Research - Help Wanted
<br>
<p><p><p>Hi All,
<br>
<p>AGIRI (the Artificial General Intelligence Research Institute) is pleased to
<br>
launch a new drive to raise $80,000 dedicated to pure AGI research with a
<br>
specific goal: to complete the next major milestone of Novamente development
<br>
by the end of 2005.
<br>
<p><p>Milestone M10, shown in the Novamente Development Roadmap, is the deployment
<br>
of a Novamente system specialized to control an embodied agent, interacting
<br>
linguistically and &quot;physically&quot; with other agents and objects in a simulated
<br>
world. For more information on the project, see the AGI-SIM Development
<br>
Plan. AGIRI is also seeking capable programmers, for both volunteer and paid
<br>
positions.
<br>
<p>We believe that upon completion of the AGI-SIM project, AGIRI will be
<br>
well-poised to raise the larger-dollar research funding needed to move
<br>
Novamente quickly toward its longer-term AGI goals. The AGI-SIM application
<br>
of Novamente may also open up new commercial possibilities, for instance in
<br>
the area of partnerships with firms developing mobile robotics technology.
<br>
<p>For more information about Novamente, see the new concise but deep
<br>
single-page description located at the AGIRI home page, and the eight-page
<br>
technical paper at Novamente: An Integrative Architecture for General
<br>
Intelligence. A new series of books that will describe Novamente's
<br>
conceptual and technical under-pinnings in great detail is due for
<br>
publication in 2005.
<br>
<p>Read more about fundraising at AGIRI on the contributions page.
<br>
<p><p>Best Regards,
<br>
<p>from all of us at AGIRI
<br>
<p><pre>
--
AGIRI Team
<a href="http://agiri.org">http://agiri.org</a>
----------------------------------------------------------------------------
----
To unsubscribe, change your address, or temporarily deactivate your
subscription, please go to
<a href="http://v2.listbox.com/member/?listname=<a href="mailto:agi@v2.listbox.com?Subject=FW:%20[agi]%20Artificial%20General%20Intelligence%20Research%20-%20Help%20Wanted">agi@v2.listbox.com</a>">http://v2.listbox.com/member/?listname=<a href="mailto:agi@v2.listbox.com?Subject=FW:%20[agi]%20Artificial%20General%20Intelligence%20Research%20-%20Help%20Wanted">agi@v2.listbox.com</a></a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10480.html">Ben Goertzel: "RE: [agi] Artificial General Intelligence Research - Help Wanted"</a>
<li><strong>Previous message:</strong> <a href="10478.html">Ben Goertzel: "Symposium on machine ethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10480.html">Ben Goertzel: "RE: [agi] Artificial General Intelligence Research - Help Wanted"</a>
<li><strong>Reply:</strong> <a href="10480.html">Ben Goertzel: "RE: [agi] Artificial General Intelligence Research - Help Wanted"</a>
<li><strong>Reply:</strong> <a href="10483.html">Ben Goertzel: "RE: [agi] Artificial General Intelligence Research - Help Wanted"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10479">[ date ]</a>
<a href="index.html#10479">[ thread ]</a>
<a href="subject.html#10479">[ subject ]</a>
<a href="author.html#10479">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
