<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Join: Pete &amp; Passive AI</title>
<meta name="Author" content="Phillip Huggan (cdnprodigy@yahoo.com)">
<meta name="Subject" content="Re: Join: Pete &amp; Passive AI">
<meta name="Date" content="2005-12-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Join: Pete &amp; Passive AI</h1>
<!-- received="Wed Dec  7 14:28:14 2005" -->
<!-- isoreceived="20051207212814" -->
<!-- sent="Wed, 7 Dec 2005 13:28:11 -0800 (PST)" -->
<!-- isosent="20051207212811" -->
<!-- name="Phillip Huggan" -->
<!-- email="cdnprodigy@yahoo.com" -->
<!-- subject="Re: Join: Pete &amp; Passive AI" -->
<!-- id="20051207212811.44426.qmail@web61315.mail.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="BAY108-F111B4F2A3A01C963FB02F591430@phx.gbl" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Phillip Huggan (<a href="mailto:cdnprodigy@yahoo.com?Subject=Re:%20Join:%20Pete%20&amp;%20Passive%20AI"><em>cdnprodigy@yahoo.com</em></a>)<br>
<strong>Date:</strong> Wed Dec 07 2005 - 14:28:11 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13049.html">Eliezer S. Yudkowsky: "Fwd: Transhumanist Community"</a>
<li><strong>Previous message:</strong> <a href="13047.html">Phillip Huggan: "Re: Join: Pete &amp; Passive AI"</a>
<li><strong>In reply to:</strong> <a href="13046.html">P K: "Join: Pete &amp; Passive AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13057.html">David Picon Alvarez: "Re: Pete &amp; Passive AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13048">[ date ]</a>
<a href="index.html#13048">[ thread ]</a>
<a href="subject.html#13048">[ subject ]</a>
<a href="author.html#13048">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&nbsp;&nbsp;&nbsp;&nbsp;Yep, I really like the idea of an AGI that merely offers suggestions and leaves the measured actions up to people.  A few billion man-years gained by an active AGI going VOOOOMMM and remaking the world is not worth even an infinitesimal increase in extinction risks if the VOOOOMMM goes horribly wrong.  The PAI could still give us faulty advice, but at least we humans would have a chance of analyzing the obvious implications of implementing the advice and reject any unclear potentially trojan-advice.
<br>
&nbsp;&nbsp;
<br>
P K &lt;<a href="mailto:kpete1@hotmail.com?Subject=Re:%20Join:%20Pete%20&amp;%20Passive%20AI">kpete1@hotmail.com</a>&gt; wrote:
<br>
&nbsp;&nbsp;7) PASSIVE AI (PAI):
<br>
Proposed solution: Since AI can be so dangerous, why not make vim incapable 
<br>
of ¡§acting¡¨ and only capable of ¡§thinking¡¨?
<br>
<p>First of all, PAI should not be confused with AI boxing. A boxed AI IS 
<br>
capable of acting. Vis actions are simply restricted by a digital cage. 
<br>
Assuming ve wants to escape, ve probably has a very good chance since, by 
<br>
definition, ve is smarter than vis jailers are. So, from the jailers¡¦ point 
<br>
of view, the cage is a crappy security measure. In fact, this is the wrong 
<br>
attitude when designing AI. The AI should¡¦ t be the enemy. But I digress¡K
<br>
<p>The kind of pacification I¡¦m talking about, by analogy, would be like if 
<br>
the jailers removed the part of the prisoners¡¦ brain responsible for his 
<br>
will. The prisoners ceases to be a prisoners because he doesn¡¦t WANT to 
<br>
escape (or anything for that mater) and the jailers cease to be jailers 
<br>
because they don¡¦t have to keep him captive. This analogy seems pretty 
<br>
gruesome, let¡¦s get back to AI. (Building a mind from scratch without a 
<br>
piece is not the same as removing a part from a human¡¦s brain, so we won¡¦t 
<br>
feel uncomfortable on ethical grounds).
<br>
<p>Let¡¦s say you build an AI without a goal system. What working parts will 
<br>
that AI have? It would have an Inference engine (probably Bayesian), a 
<br>
memory etc. Basically, it would have all the parts that PREDICT and help 
<br>
predict. (I.e.: S1 „³ S2) Now you have an empty slot where the goal system 
<br>
should be. You set up your program such that you can act as a temporary goal 
<br>
system for the AI by manually feeding it input.
<br>
<p>Are humans too slow to act as manual goal systems? Probably slower than the 
<br>
computer and some things will be impossible to do in this way but it is 
<br>
still very useful. I will illustrate this with examples:
<br>
<p>Human: What is X?
<br>
AI: Insufficient parameters. Equation data required.
<br>
Human: X*X = 4
<br>
Human: What is X?
<br>
AI: X=2 or X=-2
<br>
<p>Human: Is global warming real?
<br>
AI: Insufficient parameters. Weather data and satellite imagery required.
<br>
Human:  [input] 
<br>
Human: Is global warming real?
<br>
AI: :-p
<br>
<p>Human: Given universe state S1, what is the next most likely state?
<br>
AI: S2
<br>
<p>Human: What are the required conditions for S2 to occur?
<br>
AI: S1
<br>
<p>As you can see the ¡§predicting¡¨ part can solve for things given parameter. 
<br>
However it does not chose the question or what actions to take. Moving 
<br>
along¡K
<br>
<p>Human: What is the best goal system?
<br>
AI: Insufficient parameters. Define ¡§best¡¨.
<br>
and points out inconsistencies&gt;
<br>
<p>As you can see the ¡§predicting¡¨ part can be used to get the goal system 
<br>
and unlike humans, the AI wont make any mistakes and will notice all the 
<br>
inconsistencies. Also, it is unaffected by human biases. An AI doesn¡¦t need 
<br>
a goal system to do these things. It reacts to input the same way your leg 
<br>
reacts when a doctor hits it with a hammer, automatically.
<br>
<p>Note: I do not claim to know how an AI would answer in the examples since I 
<br>
am not superintelligent nor to I claim that the interface will be exactly in 
<br>
this way (console chat).
<br>
&nbsp;&nbsp;
<br>
<p><p><p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
---------------------------------
<br>
&nbsp;Yahoo! Personals
<br>
&nbsp;Single? There's someone we'd like you to meet.
<br>
&nbsp;Lots of someones, actually. Try Yahoo! Personals
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13049.html">Eliezer S. Yudkowsky: "Fwd: Transhumanist Community"</a>
<li><strong>Previous message:</strong> <a href="13047.html">Phillip Huggan: "Re: Join: Pete &amp; Passive AI"</a>
<li><strong>In reply to:</strong> <a href="13046.html">P K: "Join: Pete &amp; Passive AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13057.html">David Picon Alvarez: "Re: Pete &amp; Passive AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13048">[ date ]</a>
<a href="index.html#13048">[ thread ]</a>
<a href="subject.html#13048">[ subject ]</a>
<a href="author.html#13048">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:54 MDT
</em></small></p>
</body>
</html>
