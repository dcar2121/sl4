<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Re:Passive AI     was[Join: Pete &amp; Passive AI]</title>
<meta name="Author" content="David Picon Alvarez (eleuteri@myrealbox.com)">
<meta name="Subject" content="Re: Re:Passive AI     was[Join: Pete &amp; Passive AI]">
<meta name="Date" content="2005-12-09">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Re:Passive AI     was[Join: Pete &amp; Passive AI]</h1>
<!-- received="Fri Dec  9 01:49:04 2005" -->
<!-- isoreceived="20051209084904" -->
<!-- sent="Fri, 9 Dec 2005 09:48:58 +0100" -->
<!-- isosent="20051209084858" -->
<!-- name="David Picon Alvarez" -->
<!-- email="eleuteri@myrealbox.com" -->
<!-- subject="Re: Re:Passive AI     was[Join: Pete &amp; Passive AI]" -->
<!-- id="006301c5fc9d$67ca8dc0$0302a8c0@enterprise" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="BAY108-F26DC84144643E883F76F6E91420@phx.gbl" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> David Picon Alvarez (<a href="mailto:eleuteri@myrealbox.com?Subject=Re:%20Re:Passive%20AI%20%20%20%20%20was[Join:%20Pete%20&amp;%20Passive%20AI]"><em>eleuteri@myrealbox.com</em></a>)<br>
<strong>Date:</strong> Fri Dec 09 2005 - 01:48:58 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13081.html">Michael Wilson: "Re: On The Nature Of Qualia"</a>
<li><strong>Previous message:</strong> <a href="13079.html">David Picon Alvarez: "Re: Pete &amp; Passive AI"</a>
<li><strong>In reply to:</strong> <a href="13075.html">P K: "Re:Passive AI     was[Join: Pete &amp; Passive AI]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13087.html">Phillip Huggan: "Re: Re:Passive AI"</a>
<li><strong>Reply:</strong> <a href="13087.html">Phillip Huggan: "Re: Re:Passive AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13080">[ date ]</a>
<a href="index.html#13080">[ thread ]</a>
<a href="subject.html#13080">[ subject ]</a>
<a href="author.html#13080">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
From: &quot;P K&quot; &lt;<a href="mailto:kpete1@hotmail.com?Subject=Re:%20Re:Passive%20AI%20%20%20%20%20was[Join:%20Pete%20&amp;%20Passive%20AI]">kpete1@hotmail.com</a>&gt;
<br>
<em>&gt; That would never happen. For the AI to give an order it would have to have
</em><br>
a
<br>
<em>&gt; goal system. Passive AI does NOT have a goal system. Let me take another
</em><br>
<em>&gt; shot at explaining passive AI.
</em><br>
<p>Intelligence *requires* goals. Even subhuman theorem provers need goals.
<br>
<p><em>&gt; Lets say Mr. A want ice cream. Some part of his brain &quot;says&quot;: &quot;I want ice
</em><br>
<em>&gt; cream.&quot; Some other part of his brain has the definition of ice cream. Some
</em><br>
<em>&gt; other part can infer things. I.e.: it can infer that he remains seated his
</em><br>
<em>&gt; odds of getting ice cream are lower than if he goes to his fridge. Various
</em><br>
<em>&gt; other parts do various things. The important thing is that only the
</em><br>
<em>&gt; &quot;wanting&quot; part can initiate action
</em><br>
<p>This is a hypothesis, and I'd say not a very plausible one. Say our
<br>
inference can't keep its data in memory, it might initiate the action to
<br>
take a paper and pen and scroll some calculations. Say it is missing a
<br>
formula, it might start the action of looking for the book where Bayes
<br>
theorem is hidden. Any sufficiently complex inference process must be
<br>
represented as having goals, making choices and initiating actions.
<br>
<p><em>&gt; Readout: &lt;empty&gt;
</em><br>
<em>&gt; Send: What is ice cream?
</em><br>
<em>&gt; Readout: &lt;definition of ice cream&gt;
</em><br>
Readout: consider context, do search, choose definition if several exist,
<br>
send definition.
<br>
<p><em>&gt; Send: How can you increase your odds of getting ice cream?
</em><br>
<em>&gt; Readout: Maximum &quot;ice cream getting&quot; odds will occur if I go to the
</em><br>
fridge.
<br>
How to ensure that the person getting up, go to the fridge to check if there
<br>
is icecream, look for the phonebook for an icecream place, etc, do not
<br>
happen?
<br>
<p><em>&gt; Send: Do you want ice cream?
</em><br>
<em>&gt; Readout: No
</em><br>
<em>&gt; Send: Do you want to kill me?
</em><br>
<em>&gt; Readout: No
</em><br>
<em>&gt; Send: What do you want?
</em><br>
<em>&gt; Readout: I don't want anything.
</em><br>
I don't want anything is a volitional act in itself.
<br>
<p><em>&gt; As you can see, he is still quite useful. I can browse his knowledge and
</em><br>
get
<br>
<em>&gt; various insights from him. However, Mr. A is completely passive. He
</em><br>
doesn't
<br>
<em>&gt; want ANYTHING. What's left of his brain just reacts automatically to input
</em><br>
<em>&gt; as if those systems were communicating with the goal system. In effect,
</em><br>
the
<br>
<em>&gt; interface acts as a surrogate goal system.
</em><br>
<p>&lt;sarcasm&gt;
<br>
It's going to be very interesting to be a surrogate goal system when the
<br>
inference engine asks you whether to break up or not a parenthesized
<br>
expression, whether to move or not a component of an equation from a side to
<br>
another, whether to use a certain level of approximation or not, etc.
<br>
&lt;/sarcasm&gt;
<br>
<p>Good luck though, maybe there's some trivial ontological way to distinguish
<br>
between existential-risk-creating action and non-existential-risk-creating
<br>
action.
<br>
<p>All these arguments aside, we don't just want an AI to do our goals, we
<br>
partialy want an AI to work out what our goals should be. Yes, think about
<br>
it, if we were smart enough we'd be in a position to avoid most existential
<br>
risks from MNT...
<br>
<p>--David.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13081.html">Michael Wilson: "Re: On The Nature Of Qualia"</a>
<li><strong>Previous message:</strong> <a href="13079.html">David Picon Alvarez: "Re: Pete &amp; Passive AI"</a>
<li><strong>In reply to:</strong> <a href="13075.html">P K: "Re:Passive AI     was[Join: Pete &amp; Passive AI]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13087.html">Phillip Huggan: "Re: Re:Passive AI"</a>
<li><strong>Reply:</strong> <a href="13087.html">Phillip Huggan: "Re: Re:Passive AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13080">[ date ]</a>
<a href="index.html#13080">[ thread ]</a>
<a href="subject.html#13080">[ subject ]</a>
<a href="author.html#13080">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:54 MDT
</em></small></p>
</body>
</html>
