<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Destruction of All Humanity</title>
<meta name="Author" content="Jef Allbright (jef@jefallbright.net)">
<meta name="Subject" content="Re: Destruction of All Humanity">
<meta name="Date" content="2005-12-14">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Destruction of All Humanity</h1>
<!-- received="Wed Dec 14 10:33:54 2005" -->
<!-- isoreceived="20051214173354" -->
<!-- sent="Wed, 14 Dec 2005 09:33:52 -0800" -->
<!-- isosent="20051214173352" -->
<!-- name="Jef Allbright" -->
<!-- email="jef@jefallbright.net" -->
<!-- subject="Re: Destruction of All Humanity" -->
<!-- id="22360fa10512140933p1539ca7ah7451531d9f342d71@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="23bd28ec0512140901m395e054bp2d0df308f6f942f2@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Jef Allbright (<a href="mailto:jef@jefallbright.net?Subject=Re:%20Destruction%20of%20All%20Humanity"><em>jef@jefallbright.net</em></a>)<br>
<strong>Date:</strong> Wed Dec 14 2005 - 10:33:52 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13177.html">Richard Loosemore: "Promoting High Bandwidth AGI Discussion  [WAS: Re: Not the only way to build an AI]"</a>
<li><strong>Previous message:</strong> <a href="13175.html">micah glasser: "Re: Please Re-read CAFAI"</a>
<li><strong>In reply to:</strong> <a href="13171.html">micah glasser: "Re: Destruction of All Humanity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13218.html">Phillip Huggan: "Re: Destruction of All Humanity"</a>
<li><strong>Reply:</strong> <a href="13218.html">Phillip Huggan: "Re: Destruction of All Humanity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13176">[ date ]</a>
<a href="index.html#13176">[ thread ]</a>
<a href="subject.html#13176">[ subject ]</a>
<a href="author.html#13176">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
We should all keep in mind that while there is a ratcheting forward of
<br>
knowledge and capability in service of our values, this is no
<br>
guarantee that we are not moving into an evolutionary cul de sac.
<br>
<p>- Jef
<br>
<p><p>On 12/14/05, micah glasser &lt;<a href="mailto:micahglasser@gmail.com?Subject=Re:%20Destruction%20of%20All%20Humanity">micahglasser@gmail.com</a>&gt; wrote:
<br>
<em>&gt; I agree with Jef on the importance of having a framework of shared
</em><br>
<em>&gt; values/goals. I don't mean anything fancy shmancy when I posit the good as
</em><br>
<em>&gt; something objective. What I have in mind is precisely what evolution
</em><br>
<em>&gt; programmed us for. I believe that human evolution leads inexorably toward
</em><br>
<em>&gt; more efficient societies of humans that are more and more interconnected
</em><br>
<em>&gt; through their information technologies. The good is merely human
</em><br>
<em>&gt; flourishing, as the Greeks put it. So in my opinion if the term 'benevolent
</em><br>
<em>&gt; AI' has any meaning what so ever then it must mean that it either, in no way
</em><br>
<em>&gt; obstructs human flourishing (the good) or, preferably, it actually aids and
</em><br>
<em>&gt; facilitates this flourishing. What better way to ensure this state then to
</em><br>
<em>&gt; program AI to recognize human flourishing as the greatest state of affairs
</em><br>
<em>&gt; and to welcome the AI into human society as a fellow, though different,
</em><br>
<em>&gt; member. One more thing I must clarify. I believe (for a plethora of reasons)
</em><br>
<em>&gt; that all rational agents will necessarily have for their goal increasing the
</em><br>
<em>&gt; state of freedom as a super goal of the individual and society. If I am
</em><br>
<em>&gt; correct in this (and I am) then it will not be possible to program a truly
</em><br>
<em>&gt; rational agent without including achieving greater freedom (power/knowledge)
</em><br>
<em>&gt; as a super goal.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; On 12/14/05, Jef Allbright &lt;<a href="mailto:jef@jefallbright.net?Subject=Re:%20Destruction%20of%20All%20Humanity">jef@jefallbright.net</a> &gt; wrote:
</em><br>
<em>&gt; &gt; On 12/14/05, David Picon Alvarez &lt; <a href="mailto:eleuteri@myrealbox.com?Subject=Re:%20Destruction%20of%20All%20Humanity">eleuteri@myrealbox.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt; &gt; From: &quot;micah glasser&quot; &lt;<a href="mailto:micahglasser@gmail.com?Subject=Re:%20Destruction%20of%20All%20Humanity">micahglasser@gmail.com</a>&gt;
</em><br>
<em>&gt; &gt; &gt; Intelligence cannot help you ypu select for the good. The Good must be
</em><br>
<em>&gt; &gt; &gt; programmed into the AI. Once the AI knows what the Good is then its
</em><br>
<em>&gt; &gt; &gt; intelligence will surpass any human intelligence in figuring out how to
</em><br>
<em>&gt; &gt; &gt; obtain bringing about the Good. If the Good is failed to be programmed
</em><br>
<em>&gt; into
</em><br>
<em>&gt; &gt; &gt; the machine as its super-goal then it wil certainly be malevolent. Super
</em><br>
<em>&gt; &gt; &gt; intelligence is not a god. Its merely a tool.
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; Were you programmed with the good? Are you certainly malevolent? What
</em><br>
<em>&gt; &gt; &gt; distinguishes you from an AI, evolution? Evolution doesn't bring about
</em><br>
<em>&gt; the
</em><br>
<em>&gt; &gt; &gt; good, it brings about what works in evolutionary environments, far from
</em><br>
<em>&gt; the
</em><br>
<em>&gt; &gt; &gt; good. If the good is objectively existent a super AI can find it, if not
</em><br>
<em>&gt; &gt; &gt; then there's no point in talking about &quot;the good&quot;, we'd rather talk
</em><br>
<em>&gt; about
</em><br>
<em>&gt; &gt; &gt; what we want instead.
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; David makes good points here, but interestingly, as we subjective
</em><br>
<em>&gt; &gt; agents move through an objectively described world, we tend to ratchet
</em><br>
<em>&gt; &gt; forward in the direction we see as (subjectively) good.  Since we are
</em><br>
<em>&gt; &gt; not alone, but share values in common with other agents (this can be
</em><br>
<em>&gt; &gt; extended to non-human agents of varying capabilities) there is a
</em><br>
<em>&gt; &gt; tendency toward progressively increasing the measure of subjective
</em><br>
<em>&gt; &gt; good.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Appreciating and understanding the principles that describe this
</em><br>
<em>&gt; &gt; positive-sum growth would lead us to create frameworks to facilitate
</em><br>
<em>&gt; &gt; the process of (1) increasing awareness of shared values, and (2)
</em><br>
<em>&gt; &gt; increasing awareness of instrumental methods for achieving our goals.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; This paradigm would supersede earlier concepts of morality, politics
</em><br>
<em>&gt; &gt; and government.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; In my humble opinion.  ;-)
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; - Jef
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; --
</em><br>
<em>&gt; I swear upon the alter of God, eternal hostility to every form of tyranny
</em><br>
<em>&gt; over the mind of man. - Thomas Jefferson
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13177.html">Richard Loosemore: "Promoting High Bandwidth AGI Discussion  [WAS: Re: Not the only way to build an AI]"</a>
<li><strong>Previous message:</strong> <a href="13175.html">micah glasser: "Re: Please Re-read CAFAI"</a>
<li><strong>In reply to:</strong> <a href="13171.html">micah glasser: "Re: Destruction of All Humanity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13218.html">Phillip Huggan: "Re: Destruction of All Humanity"</a>
<li><strong>Reply:</strong> <a href="13218.html">Phillip Huggan: "Re: Destruction of All Humanity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13176">[ date ]</a>
<a href="index.html#13176">[ thread ]</a>
<a href="subject.html#13176">[ subject ]</a>
<a href="author.html#13176">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:54 MDT
</em></small></p>
</body>
</html>
