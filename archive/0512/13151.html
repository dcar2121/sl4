<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Please Re-read CAFAI</title>
<meta name="Author" content="micah glasser (micahglasser@gmail.com)">
<meta name="Subject" content="Re: Please Re-read CAFAI">
<meta name="Date" content="2005-12-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Please Re-read CAFAI</h1>
<!-- received="Tue Dec 13 22:58:11 2005" -->
<!-- isoreceived="20051214055811" -->
<!-- sent="Wed, 14 Dec 2005 00:58:10 -0500" -->
<!-- isosent="20051214055810" -->
<!-- name="micah glasser" -->
<!-- email="micahglasser@gmail.com" -->
<!-- subject="Re: Please Re-read CAFAI" -->
<!-- id="23bd28ec0512132158r1df28582mc639ca33a0b54eab@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="22360fa10512132108m359e796eq80d980077985a15e@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> micah glasser (<a href="mailto:micahglasser@gmail.com?Subject=Re:%20Please%20Re-read%20CAFAI"><em>micahglasser@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Dec 13 2005 - 22:58:10 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13152.html">Jef Allbright: "Re: Please Re-read CAFAI"</a>
<li><strong>Previous message:</strong> <a href="13150.html">Tennessee Leeuwenburg: "Re: Please Re-read CAFAI"</a>
<li><strong>In reply to:</strong> <a href="13149.html">Jef Allbright: "Re: Please Re-read CAFAI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13154.html">Jef Allbright: "Re: Please Re-read CAFAI"</a>
<li><strong>Reply:</strong> <a href="13154.html">Jef Allbright: "Re: Please Re-read CAFAI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13151">[ date ]</a>
<a href="index.html#13151">[ thread ]</a>
<a href="subject.html#13151">[ subject ]</a>
<a href="author.html#13151">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Let me clarify on my comments about the categorical imeperative. Of course
<br>
the CI does not constitute a goal system in and of itself. What I am
<br>
proposing is that personal freedom be the highest attainable goal. If this
<br>
is the goal and it is left unchecked then any intelligence would quickly
<br>
learn to impose its will on others. And in the case of a super intelligence
<br>
this would be a disaster. However, if the descsion making network were built
<br>
around a CI then the AI would continuously act to advance its own knowledge
<br>
and power (to increase personal freedom) as part of its goal system but
<br>
would never act in a way that would obviously interfere with the free will
<br>
of another. In this manner it could fulfill all of its potential with out
<br>
coming into conflict with any other rational agent.On 12/14/05, Jef
<br>
Allbright &lt;<a href="mailto:jef@jefallbright.net?Subject=Re:%20Please%20Re-read%20CAFAI">jef@jefallbright.net</a> &gt; wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; On 12/13/05, Tennessee Leeuwenburg &lt; <a href="mailto:tennessee@tennessee.id.au?Subject=Re:%20Please%20Re-read%20CAFAI">tennessee@tennessee.id.au</a>&gt; wrote:
</em><br>
<em>&gt; &gt; Jef Allbright wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; &gt;On 12/13/05, Michael Vassar &lt;<a href="mailto:michaelvassar@hotmail.com?Subject=Re:%20Please%20Re-read%20CAFAI">michaelvassar@hotmail.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;&gt;The same confusion relates to the discussion of the categorical
</em><br>
<em>&gt; imperative.
</em><br>
<em>&gt; &gt; &gt;&gt;The categorical imperative simply makes no sense for an AI.  It
</em><br>
<em>&gt; doesn't tell
</em><br>
<em>&gt; &gt; &gt;&gt;the AI what to want universally done.  Rational entities WILL do what
</em><br>
<em>&gt; their
</em><br>
<em>&gt; &gt; &gt;&gt;goal system tells them to do.  They don't need &quot;ethics&quot; in the human
</em><br>
<em>&gt; sense
</em><br>
<em>&gt; &gt; &gt;&gt;of rules countering other inclinations.  What they need is
</em><br>
<em>&gt; inclinations
</em><br>
<em>&gt; &gt; &gt;&gt;compatible with ours.
</em><br>
<em>&gt; &gt; &gt;&gt;
</em><br>
<em>&gt; &gt; &gt;&gt;
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;Let me see if I can understand what you're saying here.  Do you mean
</em><br>
<em>&gt; &gt; &gt;that to the extent an agent is rational, it will naturally use all of
</em><br>
<em>&gt; &gt; &gt;its instrumental knowledge to promote its own goals and from its point
</em><br>
<em>&gt; &gt; &gt;of view there would be no question that such action is good?
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;If this is true, then would it also see increasing its objective
</em><br>
<em>&gt; &gt; &gt;knowledge in support of its goals as rational and inherently good
</em><br>
<em>&gt; &gt; &gt;(from its point of view?)
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;If I'm still understanding the implications of what you said, would
</em><br>
<em>&gt; &gt; &gt;this also mean that cooperation with other like-minded agents, to the
</em><br>
<em>&gt; &gt; &gt;extent that this increased the promotion of its own goals, would be
</em><br>
<em>&gt; &gt; &gt;rational and good (from its point of view?)
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;If this makes sense, then I think you may be on to an effective and
</em><br>
<em>&gt; &gt; &gt;rational way of looking at decision-making about &quot;right&quot; and &quot;wrong&quot;
</em><br>
<em>&gt; &gt; &gt;that avoids much of the contradiction of conventional views of
</em><br>
<em>&gt; &gt; &gt;morality.
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;- Jef
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; Perhaps I can simplify this argument.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; The Categorical Imperative theory is an &quot;is&quot; not an &quot;ought&quot;.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Cheers,
</em><br>
<em>&gt; &gt; -T
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Huh?  Thanks for playing.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Would you like to comment on the questions I posed to Michael?
</em><br>
<em>&gt;
</em><br>
<em>&gt; - Jef
</em><br>
<em>&gt;
</em><br>
<p><p><p><pre>
--
I swear upon the alter of God, eternal hostility to every form of tyranny
over the mind of man. - Thomas Jefferson
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13152.html">Jef Allbright: "Re: Please Re-read CAFAI"</a>
<li><strong>Previous message:</strong> <a href="13150.html">Tennessee Leeuwenburg: "Re: Please Re-read CAFAI"</a>
<li><strong>In reply to:</strong> <a href="13149.html">Jef Allbright: "Re: Please Re-read CAFAI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13154.html">Jef Allbright: "Re: Please Re-read CAFAI"</a>
<li><strong>Reply:</strong> <a href="13154.html">Jef Allbright: "Re: Please Re-read CAFAI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13151">[ date ]</a>
<a href="index.html#13151">[ thread ]</a>
<a href="subject.html#13151">[ subject ]</a>
<a href="author.html#13151">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:54 MDT
</em></small></p>
</body>
</html>
