<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: SIAI &amp; Kurweil's Singularity</title>
<meta name="Author" content="Jef Allbright (jef@jefallbright.net)">
<meta name="Subject" content="Re: SIAI &amp; Kurweil's Singularity">
<meta name="Date" content="2005-12-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: SIAI &amp; Kurweil's Singularity</h1>
<!-- received="Thu Dec 15 15:44:55 2005" -->
<!-- isoreceived="20051215224455" -->
<!-- sent="Thu, 15 Dec 2005 14:44:52 -0800" -->
<!-- isosent="20051215224452" -->
<!-- name="Jef Allbright" -->
<!-- email="jef@jefallbright.net" -->
<!-- subject="Re: SIAI &amp; Kurweil's Singularity" -->
<!-- id="22360fa10512151444p7e3bf899l87c983affd25aa55@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20051215191758.73403.qmail@web61120.mail.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Jef Allbright (<a href="mailto:jef@jefallbright.net?Subject=Re:%20SIAI%20&amp;%20Kurweil's%20Singularity"><em>jef@jefallbright.net</em></a>)<br>
<strong>Date:</strong> Thu Dec 15 2005 - 15:44:52 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13205.html">Olie L: "RE: SIAI &amp; Kurweil's Singularity"</a>
<li><strong>Previous message:</strong> <a href="13203.html">micah glasser: "Re: Please Re-read CAFAI"</a>
<li><strong>In reply to:</strong> <a href="13200.html">1Arcturus: "SIAI &amp; Kurweil's Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13211.html">1Arcturus: "Re: SIAI &amp; Kurweil's Singularity"</a>
<li><strong>Reply:</strong> <a href="13211.html">1Arcturus: "Re: SIAI &amp; Kurweil's Singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13204">[ date ]</a>
<a href="index.html#13204">[ thread ]</a>
<a href="subject.html#13204">[ subject ]</a>
<a href="author.html#13204">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 12/15/05, 1Arcturus &lt;<a href="mailto:arcturus12453@yahoo.com?Subject=Re:%20SIAI%20&amp;%20Kurweil's%20Singularity">arcturus12453@yahoo.com</a>&gt; wrote:
<br>
<em>&gt; I had another question about SIAI in relation to Kurzweil's latest book
</em><br>
<em>&gt; Singularity is Near.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If I have him right, Kurzweil predicts that humans will gradually merge with
</em><br>
<em>&gt; their technology - the technology becoming more humanlike, more
</em><br>
<em>&gt; biological-compatible, and integrating into the human body and mental
</em><br>
<em>&gt; processes, until eventually the purely 'biological' portion becomes less and
</em><br>
<em>&gt; less predominant or disappears entirely.
</em><br>
<em>&gt;
</em><br>
<em>&gt; SIAI seems to presuppose a very different scenario - that strongly
</em><br>
<em>&gt; superintelligent AI will arise first in pure machines, and never
</em><br>
<em>&gt; (apparently) in humans. There seems to be no indication of 'merger', more
</em><br>
<em>&gt; like a kind of AI-rule over mostly unmodified humans.
</em><br>
<em>&gt;
</em><br>
<p>Some of us think that one possible solution to the problem of
<br>
unfriendly AIs is to aggressively augment and amplify the intelligence
<br>
of humans--and more importantly, the intelligence of human social
<br>
organizations composed of augmented humans--such that we have a broad,
<br>
powerful, and evolving base of intelligence based on human values in
<br>
place to deal with the threat of unfriendly AIs.  Society is already
<br>
proceeding down this broad path, but certainly not with any sense of
<br>
urgency.
<br>
<p>On the other hand, some of us think that the risk of unfriendly AI is
<br>
so great in its consequences, and possibly so near in time, that
<br>
humanity's best chance is for a small independent group to be the
<br>
first to develop recursively self-improving AI and to build in
<br>
safeguards which, unfortunately, have not yet been conceived or
<br>
demonstrated to be possible.  I don't disagree with this thinking, but
<br>
I assign it a very small probability of success because I think it is
<br>
vastly outweighed in terms of military and industrial resources that
<br>
can and will pick up the project when they think the time is right.
<br>
<p>My (optimistic and hopeful) bet is on Google to be prominent in both scenarios.
<br>
<p>- Jef
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13205.html">Olie L: "RE: SIAI &amp; Kurweil's Singularity"</a>
<li><strong>Previous message:</strong> <a href="13203.html">micah glasser: "Re: Please Re-read CAFAI"</a>
<li><strong>In reply to:</strong> <a href="13200.html">1Arcturus: "SIAI &amp; Kurweil's Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13211.html">1Arcturus: "Re: SIAI &amp; Kurweil's Singularity"</a>
<li><strong>Reply:</strong> <a href="13211.html">1Arcturus: "Re: SIAI &amp; Kurweil's Singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13204">[ date ]</a>
<a href="index.html#13204">[ thread ]</a>
<a href="subject.html#13204">[ subject ]</a>
<a href="author.html#13204">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:54 MDT
</em></small></p>
</body>
</html>
