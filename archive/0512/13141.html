<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: List of envisioned global catastrophic risks</title>
<meta name="Author" content="Dani Eder (danielravennest@yahoo.com)">
<meta name="Subject" content="Re: List of envisioned global catastrophic risks">
<meta name="Date" content="2005-12-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: List of envisioned global catastrophic risks</h1>
<!-- received="Tue Dec 13 16:06:11 2005" -->
<!-- isoreceived="20051213230611" -->
<!-- sent="Tue, 13 Dec 2005 15:05:50 -0800 (PST)" -->
<!-- isosent="20051213230550" -->
<!-- name="Dani Eder" -->
<!-- email="danielravennest@yahoo.com" -->
<!-- subject="Re: List of envisioned global catastrophic risks" -->
<!-- id="20051213230550.59137.qmail@web30909.mail.mud.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="BAY106-F34AD16065975938D546718BA390@phx.gbl" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Dani Eder (<a href="mailto:danielravennest@yahoo.com?Subject=Re:%20List%20of%20envisioned%20global%20catastrophic%20risks"><em>danielravennest@yahoo.com</em></a>)<br>
<strong>Date:</strong> Tue Dec 13 2005 - 16:05:50 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13142.html">Nick Bostrom: "Re:  Passive AI"</a>
<li><strong>Previous message:</strong> <a href="13140.html">Ben Goertzel: "Re: AGI w/ NO goals"</a>
<li><strong>In reply to:</strong> <a href="13122.html">Olie L: "Re: List of envisioned global catastrophic risks"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13130.html">Kaj Sotala: "RE: List of envisioned global catastrophic risks"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13141">[ date ]</a>
<a href="index.html#13141">[ thread ]</a>
<a href="subject.html#13141">[ subject ]</a>
<a href="author.html#13141">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I was an astrophysics major in college.  The correct
<br>
terms
<br>
are meteoroid while it is in space, meteor when it is
<br>
bright
<br>
entering the atmosphere, and meteorite when what is
<br>
left
<br>
is found on the ground.
<br>
<p>Bolides (note spelling) are particularly bright and
<br>
long
<br>
lasting meteors, possibly with audible effects.
<br>
<p>Meteoroids are small particles that approach the
<br>
Earth.
<br>
Big objects in solar orbit are called asteroids.  I
<br>
don't
<br>
know if there is an official size limit, but I have
<br>
seen
<br>
20 meter objects passing close to the Earth described
<br>
as
<br>
asteroids.  Anything much bigger than that would
<br>
certainly
<br>
be in the asteroid class.
<br>
<p>The largest object in the inner asteroid belt - 1
<br>
Ceres -
<br>
is 1000 km in diameter.  There are arguments over
<br>
whether
<br>
Pluto should be considered a planet or merely the
<br>
largest
<br>
of the Kuiper Belt objects which exist in the area
<br>
just
<br>
outside Neptune's orbit.
<br>
<p>Daniel
<br>
<p>--- Olie L &lt;<a href="mailto:neomorphy@hotmail.com?Subject=Re:%20List%20of%20envisioned%20global%20catastrophic%20risks">neomorphy@hotmail.com</a>&gt; wrote:
<br>
<p><em>&gt; 
</em><br>
to call a 
<br>
<em>&gt; small planet hitting another planet a &quot;meteorite&quot; -
</em><br>
<em>&gt; it would be a boloid.  
</em><br>
<em>&gt; However, it seems that this term is neither in the
</em><br>
<em>&gt; dictionary, nor on 
</em><br>
<em>&gt; particularly many webpages, so it's not a common use
</em><br>
<em>&gt; term.  Any astro 
</em><br>
<em>&gt; experts?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; ...
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Because (1) It might be useful for certain
</em><br>
<em>&gt; futurology purposes, and even 
</em><br>
<em>&gt; planning;  and (2) I Have something of a fondness
</em><br>
<em>&gt; for contemplating disaster 
</em><br>
<em>&gt; scenarios;  I would be interested to see a list of
</em><br>
<em>&gt; possible events that 
</em><br>
<em>&gt; would have a significant impact on society, with one
</em><br>
<em>&gt; key measure being AI 
</em><br>
<em>&gt; development.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Furthermore, I would be interested to put together
</em><br>
<em>&gt; some informed opinions 
</em><br>
<em>&gt; about the probability of  some disaster scenarios. 
</em><br>
<em>&gt; If the predictions are 
</em><br>
<em>&gt; any good, they might be useful for developing
</em><br>
<em>&gt; policies, and whether the risk 
</em><br>
<em>&gt; of pushing one tech might be offset the the benefits
</em><br>
<em>&gt; of averting a different 
</em><br>
<em>&gt; risk- see the discussions on:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Re: [sl4] Singularity, &quot;happiness&quot;, suffering, Mars
</em><br>
<em>&gt; 
</em><br>
<em>&gt; from back in Late September '05
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Note that things don't have to be existential risks
</em><br>
<em>&gt; to be globally 
</em><br>
<em>&gt; problematic and singularity relevant...  For
</em><br>
<em>&gt; instance, although economic 
</em><br>
<em>&gt; stagnation is clearly not an existential risk, if
</em><br>
<em>&gt; there is enough economic 
</em><br>
<em>&gt; stagnation, it could seriously interrupt AI
</em><br>
<em>&gt; development and consequently FAI 
</em><br>
<em>&gt; singularity development, and consequently reduce our
</em><br>
<em>&gt; ability to address real 
</em><br>
<em>&gt; existential risks.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Another thing: although regional risks won't stop
</em><br>
<em>&gt; humanity, they are serious 
</em><br>
<em>&gt; concerns for AI development.  F'rinstance, if a
</em><br>
<em>&gt; supervolcano - particularly 
</em><br>
<em>&gt; Yosemite - goes off, the US economy is rooted.  The
</em><br>
<em>&gt; chances of this 
</em><br>
<em>&gt; happening are, what, in the order of 3E-06 per year
</em><br>
<em>&gt; (once every three 
</em><br>
<em>&gt; hundred thousand years or so)?  Now, a supervolcano
</em><br>
<em>&gt; won't be a big issue for 
</em><br>
<em>&gt; the whole of humanity, but if the US economy is
</em><br>
<em>&gt; kaput, it's going to wreck 
</em><br>
<em>&gt; the global economy, and put a tangible dampener on
</em><br>
<em>&gt; AI development.  How 
</em><br>
<em>&gt; much?  Well, just say it put FAI development back 20
</em><br>
<em>&gt; years (blind 
</em><br>
<em>&gt; conjecture), that's 20 extra years of risk of
</em><br>
<em>&gt; another catastrophy that 
</em><br>
<em>&gt; could... you get the picture.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -- Olie
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;From: BillK &lt;<a href="mailto:pharos@gmail.com?Subject=Re:%20List%20of%20envisioned%20global%20catastrophic%20risks">pharos@gmail.com</a>&gt;
</em><br>
<em>&gt; &gt;Reply-To: <a href="mailto:sl4@sl4.org?Subject=Re:%20List%20of%20envisioned%20global%20catastrophic%20risks">sl4@sl4.org</a>
</em><br>
<em>&gt; &gt;To: <a href="mailto:sl4@sl4.org?Subject=Re:%20List%20of%20envisioned%20global%20catastrophic%20risks">sl4@sl4.org</a>
</em><br>
<em>&gt; &gt;Subject: Re: List of envisioned global catastrophic
</em><br>
<em>&gt; risks
</em><br>
<em>&gt; &gt;Date: Mon, 12 Dec 2005 09:59:59 +0000
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;On 12/12/05, Tyler Emerson wrote:
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; I recall seeing a long list of envisioned GCRs.
</em><br>
<em>&gt; Anyone know the URL?
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;You might be thinking of
</em><br>
<em>&gt; &gt;&lt;<a href="http://en.wikipedia.org/wiki/End_of_civilization">http://en.wikipedia.org/wiki/End_of_civilization</a>&gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;BillK
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<p><p>__________________________________________________
<br>
Do You Yahoo!?
<br>
Tired of spam?  Yahoo! Mail has the best spam protection around 
<br>
<a href="http://mail.yahoo.com">http://mail.yahoo.com</a> 
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13142.html">Nick Bostrom: "Re:  Passive AI"</a>
<li><strong>Previous message:</strong> <a href="13140.html">Ben Goertzel: "Re: AGI w/ NO goals"</a>
<li><strong>In reply to:</strong> <a href="13122.html">Olie L: "Re: List of envisioned global catastrophic risks"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13130.html">Kaj Sotala: "RE: List of envisioned global catastrophic risks"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13141">[ date ]</a>
<a href="index.html#13141">[ thread ]</a>
<a href="subject.html#13141">[ subject ]</a>
<a href="author.html#13141">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:54 MDT
</em></small></p>
</body>
</html>
