<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AGI project planning</title>
<meta name="Author" content="Michael Wilson (mwdestinystar@yahoo.co.uk)">
<meta name="Subject" content="Re: AGI project planning">
<meta name="Date" content="2005-12-06">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AGI project planning</h1>
<!-- received="Tue Dec  6 09:35:20 2005" -->
<!-- isoreceived="20051206163520" -->
<!-- sent="Tue, 6 Dec 2005 16:35:16 +0000 (GMT)" -->
<!-- isosent="20051206163516" -->
<!-- name="Michael Wilson" -->
<!-- email="mwdestinystar@yahoo.co.uk" -->
<!-- subject="Re: AGI project planning" -->
<!-- id="20051206163517.90086.qmail@web26710.mail.ukl.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="638d4e150512051041g23b6f50ey8f9fcdb821519597@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Wilson (<a href="mailto:mwdestinystar@yahoo.co.uk?Subject=Re:%20AGI%20project%20planning"><em>mwdestinystar@yahoo.co.uk</em></a>)<br>
<strong>Date:</strong> Tue Dec 06 2005 - 09:35:16 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13046.html">P K: "Join: Pete &amp; Passive AI"</a>
<li><strong>Previous message:</strong> <a href="13044.html">Thomas Buckner: "Re: guaranteeing friendliness [more about reaching AGI now that Ben has improved the thread]"</a>
<li><strong>In reply to:</strong> <a href="13035.html">Ben Goertzel: "Re: AGI project planning"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13093.html">Ben Goertzel: "Re: AGI project planning"</a>
<li><strong>Reply:</strong> <a href="13093.html">Ben Goertzel: "Re: AGI project planning"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13045">[ date ]</a>
<a href="index.html#13045">[ thread ]</a>
<a href="subject.html#13045">[ subject ]</a>
<a href="author.html#13045">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Goertzel wrote:
<br>
<em>&gt; I suspect that if the Novamente team and I had taken more of
</em><br>
<em>&gt; an evangelical, absolutely-certain stance, then we might well
</em><br>
<em>&gt; have gotten the funding from these individuals.
</em><br>
<p>Yep, I know exactly what you mean. When raising funding I have
<br>
been focusing on the near-term commercial applications of a
<br>
partly working system. Historically the most 'successful' AGI
<br>
projects to date are the ones that failed to produce AGI, but
<br>
managed to repurpose their work into profitable narrow AI
<br>
applications before the funding ran out completely. I'm picking
<br>
a selection of promising commercial applications as early I can,
<br>
and trying to ensure that that if successful they will match a
<br>
steady buildup in capability towards AGI, rather than being
<br>
last ditch fundraising efforts or a series of unrelated
<br>
distractions. This lets me be more honestly confident with
<br>
potential investors while still hopefully producing experimental
<br>
work relevant to the SIAI's eventual project. Incidentally my
<br>
recent work has put me even more in agreement with you on the
<br>
importance of implementation experience in solving the really
<br>
thorny structural issues underpinning tractable fluid reasoning,
<br>
though we are still in disagreement as to theory and
<br>
methodology.
<br>
<p><em>&gt; But we presented ourselves honestly, as a group of
</em><br>
<em>&gt; individuals with different estimates of the time it would
</em><br>
<em>&gt; take to complete our project and of our ultimate odds of
</em><br>
<em>&gt; success.
</em><br>
<p>It's true that AGI is somewhat all-or-nothing, but I don't
<br>
think a simple estimate of completion time is much use at all.
<br>
Arguably it's worse than useless as people often fixate on it
<br>
and then decry you if you miss the deadline. I think to be
<br>
useful you have to summarise you project plan into a set of
<br>
major components, the key challenges for each, the dependencies
<br>
between them, the resources assigned and a description of how
<br>
the various capabilities your system should have will become
<br>
available as you put the components together. Then you can
<br>
label all that with confidence-bounded completion time
<br>
estimates. Some people will probably still read it and reduce
<br>
it down to 'they say they can do it in X years', but at least
<br>
if you miss the deadline you can reference you project plan
<br>
and show where you got things right and wrong, and meanwhile
<br>
the people with a clue will be impressed that you made a
<br>
serious effort to plan your project and justify your
<br>
predictions. Personally I don't even have enough information
<br>
to do this usefully yet, but I think I'm getting steadily
<br>
closer to being able to.
<br>
<p>None of that applies if you're trying to evolve an AGI with
<br>
cheap tricks and brute force, but you know my opinions on
<br>
that endeavour.
<br>
<p><em>&gt; All of us on the team think the project has a nontrivial
</em><br>
<em>&gt; probability of achieving human-level AGI
</em><br>
<p>I'm beginning to think that the phrase 'human-level AGI'
<br>
has become an in-joke used on people who aren't clued up on
<br>
how non-anthropomorphic (non-neuromorphic) AGI is.
<br>
<p><em>&gt; Unfortunately, it seemed that presenting our opinions and
</em><br>
<em>&gt; attitudes honestly in this way turned off the investors,
</em><br>
<p>They usually prefer strong technical leadership that everyone
<br>
else agrees with; having multiple people trying to impose
<br>
their own directions on a project results in disaster unless
<br>
those people are exceptionally competent and good at teamwork,
<br>
consensus building and lossless compromise. I hope that the
<br>
latter is something the SIAI will endeavour to strive for, as
<br>
the organisation continues to gain funding, staff and the
<br>
means to begin practical work. I get the impression that's
<br>
what you want your project to look like too.
<br>
<p><em>&gt; I am happy you have been able to find funding for your work
</em><br>
<em>&gt; while presenting your case honestly.
</em><br>
<p>Again, this is largely because I am neither claiming to be
<br>
building an AGI nor actually attempting to build one (though I
<br>
confess that having colleagues very skilled in finding and
<br>
obtaining minor government grants helps too). The probability
<br>
of success (on my first attempt, starting now) if I tried to
<br>
simply build an AGI would be very low even if I had as much
<br>
funding and staff as I could use*. I believe that despite
<br>
also beliving that I'm probably in the top ten people with the
<br>
most chance of success in the whole field. For investors I thus
<br>
focus on making money while explaining that there is a
<br>
technological development path that will keep opening up new
<br>
application areas if pursued (though this is a path very
<br>
different from the ascent through animal, toddler, child and
<br>
then adult human capabilities that anthropomorphic projects
<br>
often claim to be following). For the SIAI, I am focused on
<br>
raising the probability that an eventual direct assault on
<br>
the AGI problem will be a success, by gathering as much
<br>
high-value data on what works, how well and why as possible.
<br>
<p>That said, I rate the probability of being able to do /cool
<br>
new stuff/+ fairly soon a lot higher, and I think that after
<br>
five years of high-minded talk the SIAI could sure as hell
<br>
use some of that.
<br>
<p>&nbsp;* Michael Wilson
<br>
<p>* Assuming I didn't throw all caution to the wind, though as
<br>
usual building an AGI without an FAI scheme worked out would
<br>
be pretty dangerous even with maximum precautions.
<br>
<p>+ As in, cool to any IT-literate person, not just to people
<br>
studying the details of AI theory. :)
<br>
<p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
___________________________________________________________ 
<br>
Yahoo! Messenger - NEW crystal clear PC to PC calling worldwide with voicemail <a href="http://uk.messenger.yahoo.com">http://uk.messenger.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13046.html">P K: "Join: Pete &amp; Passive AI"</a>
<li><strong>Previous message:</strong> <a href="13044.html">Thomas Buckner: "Re: guaranteeing friendliness [more about reaching AGI now that Ben has improved the thread]"</a>
<li><strong>In reply to:</strong> <a href="13035.html">Ben Goertzel: "Re: AGI project planning"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13093.html">Ben Goertzel: "Re: AGI project planning"</a>
<li><strong>Reply:</strong> <a href="13093.html">Ben Goertzel: "Re: AGI project planning"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13045">[ date ]</a>
<a href="index.html#13045">[ thread ]</a>
<a href="subject.html#13045">[ subject ]</a>
<a href="author.html#13045">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:54 MDT
</em></small></p>
</body>
</html>
