<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: SIAI &amp; Kurweil's Singularity</title>
<meta name="Author" content="1Arcturus (arcturus12453@yahoo.com)">
<meta name="Subject" content="RE: SIAI &amp; Kurweil's Singularity">
<meta name="Date" content="2005-12-16">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: SIAI &amp; Kurweil's Singularity</h1>
<!-- received="Fri Dec 16 09:03:48 2005" -->
<!-- isoreceived="20051216160348" -->
<!-- sent="Fri, 16 Dec 2005 08:03:44 -0800 (PST)" -->
<!-- isosent="20051216160344" -->
<!-- name="1Arcturus" -->
<!-- email="arcturus12453@yahoo.com" -->
<!-- subject="RE: SIAI &amp; Kurweil's Singularity" -->
<!-- id="20051216160344.24550.qmail@web61125.mail.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="BAY106-F2335B38384B4008E60C553BA3B0@phx.gbl" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> 1Arcturus (<a href="mailto:arcturus12453@yahoo.com?Subject=RE:%20SIAI%20&amp;%20Kurweil's%20Singularity"><em>arcturus12453@yahoo.com</em></a>)<br>
<strong>Date:</strong> Fri Dec 16 2005 - 09:03:44 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13214.html">1Arcturus: "Re: SIAI &amp; Kurweil's Singularity"</a>
<li><strong>Previous message:</strong> <a href="13212.html">pdugan: "RE: SIAI &amp; Kurweil's Singularity"</a>
<li><strong>In reply to:</strong> <a href="13205.html">Olie L: "RE: SIAI &amp; Kurweil's Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13206.html">Samantha Atkins: "Re: SIAI &amp; Kurweil's Singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13213">[ date ]</a>
<a href="index.html#13213">[ thread ]</a>
<a href="subject.html#13213">[ subject ]</a>
<a href="author.html#13213">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Olie L &lt;<a href="mailto:neomorphy@hotmail.com?Subject=RE:%20SIAI%20&amp;%20Kurweil's%20Singularity">neomorphy@hotmail.com</a>&gt; wrote:
<br>
&nbsp;&nbsp;It's not so much a &quot;never&quot;. It's that the best way to achieve 
<br>
superintelligence is to start with an expandable design. Once there is 
<br>
superintelligence, it would be much easier to figure how to integrate human 
<br>
people.
<br>
&nbsp;&nbsp;Olie,
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;Superintelligence should begin with intelligence, which is in humans. Humans are making rapid advances in understanding this intelligence (cf. Kurzweil's discussion of acclerating progress on reverse-engineering the brain). We already know how to expand designs, and in 30 years we will know very much more. According to Kurzweil, we already have 'neural transistors' which allow two-way communication between neurons and machines. People will be easy to integrate, likely already fully integrated, by the time we crack the intelligence nut. Then, of course, superintelligence will follow easily (hopefully).
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As I read it, the big difference is that certain groups, including the SIAI, 
<br>
envisage that the ability of an AI that is able to directly modify itself 
<br>
could result in a rate of technological improvement far beyond current 
<br>
trends, even if current trends are exponential. Such self-improving AIs 
<br>
(~seed AI) do not fit neatly into the GNR revolutions, as described by 
<br>
Kurzweil.
<br>
<p>They are the &quot;R&quot; part of GNR. Kurzweil (confusingly IMO) groups machine AI with robotics.
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I don't see that being a necessity at all. Uploading is _very_ different 
<br>
from a full understanding of brain ops.
<br>
<p><p>&nbsp;&nbsp;How so? I kind of agree with Kurzweil, that if we really understood the brain (human intelligence - the 'software'), we could already implement it on our current machines. The hardware isn't the holdup, the software is. Embodiment (even virtual) would suck at today's methods, but human intelligence could be instantiated on machines.
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Consider for a moment that a lot of people won't want to change themselves. 
<br>
Would they rather be       ted by upgraded humans (who have human foibles 
<br>
and motivations) or be &quot;governed&quot; by AIs who lack self-interested biases?
<br>
<p><p>&nbsp;&nbsp;I think the discussions on this list tend to demonstrate that humans, even you humans, disagree over how to define lack of self-interested bias, and how to discern it. If you don't think the majority of humanity would be wildly suspicious of a 'black box' intelligence, with a supposed perfectly morality (designed by humans with foibles and motivations, no less!), then I would say you are being naive.
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;Humans who want to stay unmodified are going to face a real crisis, but I don't think there will be many such humans. Humans are going to try to keep up with each other's capabilities, as they always have, out of paranoia, if nothing else. And if the time comes that unmodified humans cannot even understand or compete seriously with their modified brethren, they will have to work out some sort of practical arrangement together, hopefully in both of their best interests.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Yes, and I'm sure you're aware of humanity's success in long-term planning. 
<br>
Foresight is not our greatest quality; being amongst rapid rates of 
<br>
technological development does not help us guide all the development by all 
<br>
the people...
<br>
<p><p>&nbsp;&nbsp;Humanity's success without advanced technologies cannot be fairly compared to humanity's success with the advanced technologies, specifically the implementation of human-machine merger. 
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;Our ability to understand our human condition will have its own sort of 'hard takeoff' after the reverse-engineering. Our ability to work out a working harmony between our individual, competing interests will also be strengthened immeasurably by access to machine intelligence capabilities. Artificial intelligence, in humans merged with technology, will likely allow us to solve all sorts of social and political and ethical problems that now seem so intractable, solved now only by force or accident. And our ability to solve these problems will be advanced by our machinelike control over the nature and functioning of our own minds, and our ability to advance it further.
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;gej
<br>
<p><p><p>__________________________________________________
<br>
Do You Yahoo!?
<br>
Tired of spam?  Yahoo! Mail has the best spam protection around 
<br>
<a href="http://mail.yahoo.com">http://mail.yahoo.com</a> 
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13214.html">1Arcturus: "Re: SIAI &amp; Kurweil's Singularity"</a>
<li><strong>Previous message:</strong> <a href="13212.html">pdugan: "RE: SIAI &amp; Kurweil's Singularity"</a>
<li><strong>In reply to:</strong> <a href="13205.html">Olie L: "RE: SIAI &amp; Kurweil's Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13206.html">Samantha Atkins: "Re: SIAI &amp; Kurweil's Singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13213">[ date ]</a>
<a href="index.html#13213">[ thread ]</a>
<a href="subject.html#13213">[ subject ]</a>
<a href="author.html#13213">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:54 MDT
</em></small></p>
</body>
</html>
