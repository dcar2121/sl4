<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Destruction of All Humanity</title>
<meta name="Author" content="micah glasser (micahglasser@gmail.com)">
<meta name="Subject" content="Re: Destruction of All Humanity">
<meta name="Date" content="2005-12-14">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Destruction of All Humanity</h1>
<!-- received="Wed Dec 14 22:40:49 2005" -->
<!-- isoreceived="20051215054049" -->
<!-- sent="Thu, 15 Dec 2005 00:40:46 -0500" -->
<!-- isosent="20051215054046" -->
<!-- name="micah glasser" -->
<!-- email="micahglasser@gmail.com" -->
<!-- subject="Re: Destruction of All Humanity" -->
<!-- id="23bd28ec0512142140h16d25a93mea07457078ffea56@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="22360fa10512141341j1c47c55aydef806ab4c4c2611@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> micah glasser (<a href="mailto:micahglasser@gmail.com?Subject=Re:%20Destruction%20of%20All%20Humanity"><em>micahglasser@gmail.com</em></a>)<br>
<strong>Date:</strong> Wed Dec 14 2005 - 22:40:46 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13196.html">Michael Vassar: "Re: Please Re-read CAFAI"</a>
<li><strong>Previous message:</strong> <a href="13194.html">micah glasser: "Re: Please Re-read CAFAI"</a>
<li><strong>In reply to:</strong> <a href="13191.html">Jef Allbright: "Re: Destruction of All Humanity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13198.html">David Picon Alvarez: "Re: Destruction of All Humanity"</a>
<li><strong>Reply:</strong> <a href="13198.html">David Picon Alvarez: "Re: Destruction of All Humanity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13195">[ date ]</a>
<a href="index.html#13195">[ thread ]</a>
<a href="subject.html#13195">[ subject ]</a>
<a href="author.html#13195">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
David,
<br>
Let me clarify what I mean by 'rational agent' because I certainly am not
<br>
talking about a thermostat. What I mean is any entity that acts on or
<br>
through the environment using tools of any kind, by predicting a possible
<br>
future state of affairs and acting to realize the possible state of fairs
<br>
which most closly aproximates the nearest goal at hand. That nearest goal
<br>
should also be in service to a highest goal. The more rational the agent the
<br>
further into the future that super-goal is projected. I stipulate that
<br>
greater freedom must be part of that super-goal for any rational agent
<br>
because one part of freedom means increasing ones ability to control the
<br>
environment and contropl of the environment is a result of growing
<br>
effectiveness of system modelling (science) and manipulating that system
<br>
according to its fundamental laws (technology). All rational agents must
<br>
have this as a goal system because it is required by the definition of
<br>
rational agency. A thermostat is NOT a rational agent precisely because it
<br>
cannot effectuate a possible state of affaires because it can not model a
<br>
system. Yes, it acts according to rational priciples because it was designed
<br>
to operate according to a function. But it is NOT an agent. A rational agent
<br>
has power becasue it is able to lacate its powers of causality from a higher
<br>
state of emergent properties which function as 'top down' locust of
<br>
causation. This is in distinction to the only other form of agency which is
<br>
the 'bottom-up' causality which opereates according to the lowest level of
<br>
complexity in the cosmological systtem and determines the outcome of that
<br>
system. I hope I have made myself clear on this but I realize I am probably
<br>
just confusing your simple picture.
<br>
<p>On 12/14/05, Jef Allbright &lt;<a href="mailto:jef@jefallbright.net?Subject=Re:%20Destruction%20of%20All%20Humanity">jef@jefallbright.net</a>&gt; wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; On 12/14/05, David Picon Alvarez &lt;<a href="mailto:eleuteri@myrealbox.com?Subject=Re:%20Destruction%20of%20All%20Humanity">eleuteri@myrealbox.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt; From: &quot;Jef Allbright&quot; &lt;<a href="mailto:jef@jefallbright.net?Subject=Re:%20Destruction%20of%20All%20Humanity">jef@jefallbright.net</a>&gt;
</em><br>
<em>&gt; &gt; &gt; David makes good points here, but interestingly, as we subjective
</em><br>
<em>&gt; &gt; &gt; agents move through an objectively described world, we tend to ratchet
</em><br>
<em>&gt; &gt; &gt; forward in the direction we see as (subjectively) good.  Since we are
</em><br>
<em>&gt; &gt; &gt; not alone, but share values in common with other agents (this can be
</em><br>
<em>&gt; &gt; &gt; extended to non-human agents of varying capabilities) there is a
</em><br>
<em>&gt; &gt; &gt; tendency toward progressively increasing the measure of subjective
</em><br>
<em>&gt; &gt; &gt; good.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; That's only a consequence of relatively symmetric game theory
</em><br>
<em>&gt; situations.
</em><br>
<em>&gt; &gt; Subjective good is rising for us humans, because we're playing a
</em><br>
<em>&gt; symmetric
</em><br>
<em>&gt; &gt; game and a certain level of cooperation is desireable for ourselves.
</em><br>
<em>&gt; &gt; Subjective good isn't, or needs not, be rising for cows, which are
</em><br>
<em>&gt; playing a
</em><br>
<em>&gt; &gt; completely assymetric game with us, we eat them, whether they like it or
</em><br>
<em>&gt; &gt; not.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; &gt; Appreciating and understanding the principles that describe this
</em><br>
<em>&gt; &gt; &gt; positive-sum growth would lead us to create frameworks to facilitate
</em><br>
<em>&gt; &gt; &gt; the process of (1) increasing awareness of shared values, and (2)
</em><br>
<em>&gt; &gt; &gt; increasing awareness of instrumental methods for achieving our goals.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; That would essentially come to game theory. A super AI probably would be
</em><br>
<em>&gt; &gt; also assymetrically placed with respect to us. Our consent or
</em><br>
<em>&gt; cooperation is
</em><br>
<em>&gt; &gt; probably not necessary or even helpful to an SAI.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Thanks David for highlighting the necessity of near-symmetry between
</em><br>
<em>&gt; agents.  I was going to mention this later in the discussion since it
</em><br>
<em>&gt; is of critical importance to the question of whether we'll have time
</em><br>
<em>&gt; to develop a broad-based collective intelligence augmented with AI
</em><br>
<em>&gt; before we're made irrelevant by one or more narrowly focused SAIs.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Of course, this list has dealt with this particular question many
</em><br>
<em>&gt; times already so I don't intend to bring it up for rehashing.  My
</em><br>
<em>&gt; intent was to clarify what we mean when we talk about &quot;morality&quot; in
</em><br>
<em>&gt; general and the inconsistencies of conventional ethical thinking in
</em><br>
<em>&gt; particular.
</em><br>
<em>&gt;
</em><br>
<em>&gt; - Jef
</em><br>
<em>&gt;
</em><br>
<p><p><p><pre>
--
I swear upon the alter of God, eternal hostility to every form of tyranny
over the mind of man. - Thomas Jefferson
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13196.html">Michael Vassar: "Re: Please Re-read CAFAI"</a>
<li><strong>Previous message:</strong> <a href="13194.html">micah glasser: "Re: Please Re-read CAFAI"</a>
<li><strong>In reply to:</strong> <a href="13191.html">Jef Allbright: "Re: Destruction of All Humanity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13198.html">David Picon Alvarez: "Re: Destruction of All Humanity"</a>
<li><strong>Reply:</strong> <a href="13198.html">David Picon Alvarez: "Re: Destruction of All Humanity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13195">[ date ]</a>
<a href="index.html#13195">[ thread ]</a>
<a href="subject.html#13195">[ subject ]</a>
<a href="author.html#13195">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:54 MDT
</em></small></p>
</body>
</html>
