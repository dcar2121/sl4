<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re:  Passive AI</title>
<meta name="Author" content="Nick Bostrom (nick.bostrom@philosophy.oxford.ac.uk)">
<meta name="Subject" content="Re:  Passive AI">
<meta name="Date" content="2005-12-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re:  Passive AI</h1>
<!-- received="Tue Dec 13 17:00:03 2005" -->
<!-- isoreceived="20051214000003" -->
<!-- sent="Wed, 14 Dec 2005 00:00:01 +0000" -->
<!-- isosent="20051214000001" -->
<!-- name="Nick Bostrom" -->
<!-- email="nick.bostrom@philosophy.oxford.ac.uk" -->
<!-- subject="Re:  Passive AI" -->
<!-- id="6.0.0.22.2.20051213233342.02c742d0@sfop0079.herald.ox.ac.uk" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="BAY101-F255B0A4241D16AC0B614ABAC460@phx.gbl" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Nick Bostrom (<a href="mailto:nick.bostrom@philosophy.oxford.ac.uk?Subject=Re:%20%20Passive%20AI"><em>nick.bostrom@philosophy.oxford.ac.uk</em></a>)<br>
<strong>Date:</strong> Tue Dec 13 2005 - 17:00:01 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13143.html">Michael Vassar: "Re: Passive AI"</a>
<li><strong>Previous message:</strong> <a href="13141.html">Dani Eder: "Re: List of envisioned global catastrophic risks"</a>
<li><strong>In reply to:</strong> <a href="13112.html">Michael Vassar: "Re:  Passive AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13143.html">Michael Vassar: "Re: Passive AI"</a>
<li><strong>Reply:</strong> <a href="13143.html">Michael Vassar: "Re: Passive AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13142">[ date ]</a>
<a href="index.html#13142">[ thread ]</a>
<a href="subject.html#13142">[ subject ]</a>
<a href="author.html#13142">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Michael Vassar wrote:
<br>
<p><em>&gt;Nick Bostrom said
</em><br>
<em>&gt;&quot;There are different options for who should decide what questions could be
</em><br>
<em>&gt;posed to the Oracle. It might be difficult to ensure that the best such
</em><br>
<em>&gt;option is instantiated. But this problem is not unique to the
</em><br>
<em>&gt;Oracle-approach. It is also difficult to ensure that the first AGI is built
</em><br>
<em>&gt;by the best people to do it. The question here is, for whichever group has
</em><br>
<em>&gt;control over the first AGI - whether it's SIAI, the Pentagon, the UN, or
</em><br>
<em>&gt;whatever - what is the best way to build the AGI? &quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt;Of course, we don't need to worry about what the best way to build an AI 
</em><br>
<em>&gt;is for the pentagon, UN, or whatever, since they will absolutely not 
</em><br>
<em>&gt;listen to us.
</em><br>
<p>&quot;Whatever&quot; also includes private AI groups. Maybe the probability that 
<br>
&quot;they&quot; will listen to &quot;us&quot; is small, but I think the probability that &quot;we&quot; 
<br>
will create the first AGI is also small.
<br>
<p><p><em>&gt;  How many of the world's most respected minds, far more respected than 
</em><br>
<em>&gt; anyone here can realistically hope to become, protested nuclear build-up?
</em><br>
<p>The cases are different. Opting to go for Oracle first does need not to 
<br>
mean giving up a powerful technology that adversaries would then inquire 
<br>
instead, nor does it require global coordination.
<br>
<p>Anyway, protesting nuclear build-up might have been a good thing to do even 
<br>
though in retrospect we know it didn't succeed.
<br>
<p><p><em>&gt;&quot;Find the most accurate answer to
</em><br>
<em>&gt;the question you can within 5 seconds by shuffling electrons in these
</em><br>
<em>&gt;circuits and accessing these sources of information, and output the answer
</em><br>
<em>&gt;in the form of 10 pages print-out. &quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt;Two difficulties with this include the difficulty of bringing an AI to 
</em><br>
<em>&gt;useful oracle status without utilizing rapid take-off or bootstrapping 
</em><br>
<em>&gt;procedures
</em><br>
<p>Yes, that would surely be a difficulty.
<br>
<p><em>&gt;  and the difficulty of defining allowable methods.
</em><br>
<p>The point is that it might be much easier to reliably define allowable 
<br>
methods than to define something like Friendliness or Collective 
<br>
Extrapolated Volition in the right way.
<br>
<p><em>&gt;Without an understanding of the programmer's minds, the best output might 
</em><br>
<em>&gt;be a compressed version of the input and the utilized data.  To do much 
</em><br>
<em>&gt;better, the AI will probably need roughly human-level mental modeling, 
</em><br>
<em>&gt;which implies non-trivial volition extraction anyway.
</em><br>
<p>Yes, but less ambitious than in CEV. More importantly, if only this part 
<br>
fails we might get a few useless pages of print rather than an existential 
<br>
disaster.
<br>
<p><p>Nick Bostrom
<br>
Director, Future of Humanity Institute
<br>
Faculty of Philosophy, Oxford University
<br>
10 Merton Str., OX1 4JJ, Oxford     +44 (0)7789 74 42 42
<br>
Homepage: <a href="http://www.nickbostrom.com">http://www.nickbostrom.com</a>     FHI: <a href="http://www.fhi.ox.ac.uk">http://www.fhi.ox.ac.uk</a>
<br>
<p>For administrative matters, please contact my PA, Miriam Wood
<br>
+44(0)1865 27 69 34     <a href="mailto:miriam.wood@philosophy.ox.ac.uk?Subject=Re:%20%20Passive%20AI">miriam.wood@philosophy.ox.ac.uk</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13143.html">Michael Vassar: "Re: Passive AI"</a>
<li><strong>Previous message:</strong> <a href="13141.html">Dani Eder: "Re: List of envisioned global catastrophic risks"</a>
<li><strong>In reply to:</strong> <a href="13112.html">Michael Vassar: "Re:  Passive AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13143.html">Michael Vassar: "Re: Passive AI"</a>
<li><strong>Reply:</strong> <a href="13143.html">Michael Vassar: "Re: Passive AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13142">[ date ]</a>
<a href="index.html#13142">[ thread ]</a>
<a href="subject.html#13142">[ subject ]</a>
<a href="author.html#13142">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:54 MDT
</em></small></p>
</body>
</html>
