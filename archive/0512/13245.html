<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: SIAI &amp; Kurweil's Singularity</title>
<meta name="Author" content="1Arcturus (arcturus12453@yahoo.com)">
<meta name="Subject" content="Re: SIAI &amp; Kurweil's Singularity">
<meta name="Date" content="2005-12-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: SIAI &amp; Kurweil's Singularity</h1>
<!-- received="Tue Dec 20 08:50:31 2005" -->
<!-- isoreceived="20051220155031" -->
<!-- sent="Tue, 20 Dec 2005 07:50:28 -0800 (PST)" -->
<!-- isosent="20051220155028" -->
<!-- name="1Arcturus" -->
<!-- email="arcturus12453@yahoo.com" -->
<!-- subject="Re: SIAI &amp; Kurweil's Singularity" -->
<!-- id="20051220155028.10414.qmail@web61122.mail.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="BAY101-F36D94DFE45465DE0B274E5DC3E0@phx.gbl" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> 1Arcturus (<a href="mailto:arcturus12453@yahoo.com?Subject=Re:%20SIAI%20&amp;%20Kurweil's%20Singularity"><em>arcturus12453@yahoo.com</em></a>)<br>
<strong>Date:</strong> Tue Dec 20 2005 - 08:50:28 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13246.html">Phillip Huggan: "Re: Free Will not an illusion"</a>
<li><strong>Previous message:</strong> <a href="13244.html">Tyler Emerson: "The Singularity Institute's 2006 $100,000 Singularity Challenge - Double Your Gift!"</a>
<li><strong>In reply to:</strong> <a href="13240.html">H C: "Re: SIAI &amp; Kurweil's Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13210.html">Michael Vassar: "Re: SIAI &amp; Kurweil's Singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13245">[ date ]</a>
<a href="index.html#13245">[ thread ]</a>
<a href="subject.html#13245">[ subject ]</a>
<a href="author.html#13245">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
H C &lt;<a href="mailto:lphege@hotmail.com?Subject=Re:%20SIAI%20&amp;%20Kurweil's%20Singularity">lphege@hotmail.com</a>&gt; wrote:   Holy crap...
<br>
<p>How can you say things that are so completely ridiculous and nobody properly 
<br>
respond?
<br>
<p>(cont.)
<br>
<p><em>&gt;From: 1Arcturus 
</em><br>
<em>&gt;Reply-To: <a href="mailto:sl4@sl4.org?Subject=Re:%20SIAI%20&amp;%20Kurweil's%20Singularity">sl4@sl4.org</a>
</em><br>
<em>&gt;To: <a href="mailto:sl4@sl4.org?Subject=Re:%20SIAI%20&amp;%20Kurweil's%20Singularity">sl4@sl4.org</a>
</em><br>
<em>&gt;Subject: Re: SIAI &amp; Kurweil's Singularity
</em><br>
<em>&gt;Date: Fri, 16 Dec 2005 08:12:40 -0800 (PST)
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;Samantha Atkins wrote:
</em><br>
<em>&gt; It is an interesting question whetheter an SAI can be trusted more or 
</em><br>
<em>&gt;less than a radically augmented human being. To date the more intelligent 
</em><br>
<em>&gt;and otherwise more capable instance of human being are not particularly 
</em><br>
<em>&gt;more trustworthy than other humans
</em><br>
<em>&gt; If an SAI is designed by humans, it will indirectly carry on human 
</em><br>
<em>&gt;directionalities, so trusting the SAI will be, in an indirect way, still 
</em><br>
<em>&gt;just trusting humans,
</em><br>
<em>&gt;
</em><br>
<em>&gt; And what else *should* we trust? Trusting an alien entity, with random 
</em><br>
<em>&gt;characteristics?
</em><br>
<p><p>We should trust exactly what all the evidence indicates. Nothing more and 
<br>
nothing less. In this case, we would trust an AGI who'se design accounted 
<br>
for sufficient evidence that it would act in a generally Friendly, and 
<br>
probably friendly, manner. It's that damn simple. If our evidence is wrong, 
<br>
then it's not evidence, it's an illusion. That's part of what you have to do 
<br>
to trust something, you have to verify your evidence, and *correctly* 
<br>
calibrate your probability estimates. In having true understanding, you are 
<br>
given major, extreme, responsibility. This is because, this element of your 
<br>
understanding is within your control. You know what the actual causes and 
<br>
effects are, and thus you have the power, implicitly, to (have free will) 
<br>
choose whether those causes happen or not happen.
<br>
<p>&nbsp;&nbsp;Th3Hegem0n,
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;I was responding to Samantha Atkins, not necessarily expecting another reply, but I have no idea why any of you post or do not post, so don't ask me.
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;I get the impression from your post that you misunderstood my argument from absurdity as a serious proposal - to trust an alien, random entity, that is. I thought it was pretty obvious I was asking a rhetorical question since I argued the exact opposite in the rest of my post. So much for human-level intelligence...
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;I don't trust your ability to judge properties I and many others would consider 'friendly.' How friendly do people in your life judge you to be? How well do any of you understand friendliness, if you once entertained as a logical conclusion the necessity of exterminating the entire human race? I don't trust any one in particular as much as I trust humanity as a whole.
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;A *design* of an AGI is not evidence of any future behavior, especially behavior once the AGI had surpassed human-level intelligence, that is, your intelligence, the intelligence of every one of you here. This has nothing to do with probability estimates - it has to do with your inability to properly estimate anything at all about such an intelligence. Even if you ran a full simulation of your design, you would have no idea what you were looking at.
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;Humans can't 'verify' friendliness in an alien, external superintelligence. But if humans become superintelligent, they may figure out ways to be a little friendlier than they are now. But there is more to life than being friendly, and unmodified humans probably won't be able to keep their present monopoly on rudeness and unjustified arrogance.
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;gej
<br>
&nbsp;&nbsp;
<br>
&nbsp;
<br>
&nbsp;&nbsp;&nbsp;
<br>
<p>__________________________________________________
<br>
Do You Yahoo!?
<br>
Tired of spam?  Yahoo! Mail has the best spam protection around 
<br>
<a href="http://mail.yahoo.com">http://mail.yahoo.com</a> 
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13246.html">Phillip Huggan: "Re: Free Will not an illusion"</a>
<li><strong>Previous message:</strong> <a href="13244.html">Tyler Emerson: "The Singularity Institute's 2006 $100,000 Singularity Challenge - Double Your Gift!"</a>
<li><strong>In reply to:</strong> <a href="13240.html">H C: "Re: SIAI &amp; Kurweil's Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13210.html">Michael Vassar: "Re: SIAI &amp; Kurweil's Singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13245">[ date ]</a>
<a href="index.html#13245">[ thread ]</a>
<a href="subject.html#13245">[ subject ]</a>
<a href="author.html#13245">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:54 MDT
</em></small></p>
</body>
</html>
