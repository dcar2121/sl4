<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Please Re-read CAFAI</title>
<meta name="Author" content="micah glasser (micahglasser@gmail.com)">
<meta name="Subject" content="Re: Please Re-read CAFAI">
<meta name="Date" content="2005-12-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Please Re-read CAFAI</h1>
<!-- received="Thu Dec 15 10:35:27 2005" -->
<!-- isoreceived="20051215173527" -->
<!-- sent="Thu, 15 Dec 2005 12:35:25 -0500" -->
<!-- isosent="20051215173525" -->
<!-- name="micah glasser" -->
<!-- email="micahglasser@gmail.com" -->
<!-- subject="Re: Please Re-read CAFAI" -->
<!-- id="23bd28ec0512150935o52ff505bp92c8bd34f8dcb708@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="BAY101-F1604D121D992078EE06121AC3B0@phx.gbl" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> micah glasser (<a href="mailto:micahglasser@gmail.com?Subject=Re:%20Please%20Re-read%20CAFAI"><em>micahglasser@gmail.com</em></a>)<br>
<strong>Date:</strong> Thu Dec 15 2005 - 10:35:25 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13198.html">David Picon Alvarez: "Re: Destruction of All Humanity"</a>
<li><strong>Previous message:</strong> <a href="13196.html">Michael Vassar: "Re: Please Re-read CAFAI"</a>
<li><strong>In reply to:</strong> <a href="13196.html">Michael Vassar: "Re: Please Re-read CAFAI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13199.html">David Picon Alvarez: "Re: Please Re-read CAFAI"</a>
<li><strong>Reply:</strong> <a href="13199.html">David Picon Alvarez: "Re: Please Re-read CAFAI"</a>
<li><strong>Reply:</strong> <a href="13209.html">Michael Vassar: "Re: Not the only way to build an AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13197">[ date ]</a>
<a href="index.html#13197">[ thread ]</a>
<a href="subject.html#13197">[ subject ]</a>
<a href="author.html#13197">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I can't really say I disagree with much you've said here. I guess my point
<br>
was just that consciousness could turn out to be a necessary emergent
<br>
property of any sufficiently intelligent system.
<br>
To answer your question all that I mean by consciousness is the phenomenal
<br>
awareness of qualia, and by self conscious the phenomenal awareness of a
<br>
self. (I think Hume refutes himself on this point). Descartes's cogito is
<br>
really the only place from which to begin a rational discussion in my
<br>
opinion but this is off topic. The next issue I wish to address is your
<br>
stipulation that evolution is an intelligent process. Evolution does not act
<br>
according to a goal system which means that it is neither intelligent nor
<br>
conscious. Of course if one believes in some sort of theism then one would
<br>
say that evolution was exactly an intelligent process. I remain agnostic on
<br>
this point because I don't believe the possibility can be ruled out. At any
<br>
rate nature has only produced one entity that we know of with General
<br>
Intelligence and that is man. Man is a conscious and self-aware being. So it
<br>
is not to much of a stretch to suppose that consciousness and intelligence
<br>
are related.
<br>
<p>On 12/15/05, Michael Vassar &lt;<a href="mailto:michaelvassar@hotmail.com?Subject=Re:%20Please%20Re-read%20CAFAI">michaelvassar@hotmail.com</a>&gt; wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; &gt;Any intelligence which is conscious and aware of that consciousness
</em><br>
<em>&gt; &gt;certainly would have a self.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Huh?  Hume and Siddhartha would beg to differ, but I would simply ask what
</em><br>
<em>&gt; you mean by &quot;conscious&quot; and why it is relevant to talk about
</em><br>
<em>&gt; &quot;consciousness&quot;
</em><br>
<em>&gt; when thinking about intelligences in general?  Evolution is certainly an
</em><br>
<em>&gt; effective optimization process, but not a conscious one.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The category &quot;Intelligent Processes&quot; is the super-category which includes
</em><br>
<em>&gt; both human minds and evolution, and processes as different from both as
</em><br>
<em>&gt; they
</em><br>
<em>&gt; are from one another, including all possible GAIs.  Unless you understand
</em><br>
<em>&gt; that, anthropomorphising from your sense of what &quot;conscious&quot; implies is
</em><br>
<em>&gt; harmful to your understanding.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;I argue that sufficiently
</em><br>
<em>&gt; &gt;powerful AGI must have self consciousness because such an intelligence,
</em><br>
<em>&gt; in
</em><br>
<em>&gt; &gt;order to be sufficiently intelligent, must be able to add its own agency
</em><br>
<em>&gt; as
</em><br>
<em>&gt; &gt;one aspect of the system that it is modeling (reality).
</em><br>
<em>&gt;
</em><br>
<em>&gt; The above is all clearly true, but none of it implies anything like what
</em><br>
<em>&gt; the
</em><br>
<em>&gt; mental model of a &quot;self&quot; that you and many others seem to be
</em><br>
<em>&gt; using.  Rather,
</em><br>
<em>&gt; an entity must model it &quot;self&quot; if it is to self-improve and if it is to be
</em><br>
<em>&gt; able to judge &quot;improvements&quot;.  The model it uses of its &quot;self&quot; may be
</em><br>
<em>&gt; identical to the model it would use for any process it found externally
</em><br>
<em>&gt; which behaved in the same manner and which it had the same information
</em><br>
<em>&gt; about, or at least far more similar than the model of self used by a human
</em><br>
<em>&gt; is to the human's other models.
</em><br>
<em>&gt;
</em><br>
<em>&gt; A strongly suspected feature of Intelligent Processes of sufficient power
</em><br>
<em>&gt; is
</em><br>
<em>&gt; that they will converge to a potentially Friendly and otherwise omnicidal
</em><br>
<em>&gt; &quot;Really Powerful Optimization Processes&quot; because consistant &quot;improvement&quot;
</em><br>
<em>&gt; requires a well-ordered preference structure.
</em><br>
<em>&gt;
</em><br>
<em>&gt; It is important to note that to a great extent &quot;morality&quot; is an attempt
</em><br>
<em>&gt; for
</em><br>
<em>&gt; agents with competing preference structures to generate a well ordered
</em><br>
<em>&gt; aggregate preference structure.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;Now if this is true,
</em><br>
<em>&gt; &gt;i.e. that real AGI must be self-aware, then it would be highly dangerous
</em><br>
<em>&gt; to
</em><br>
<em>&gt; &gt;have a bunch of super intelligent AGI running around treating people as a
</em><br>
<em>&gt; &gt;means to an end alone. Note that it is ok to treat a person as means to
</em><br>
<em>&gt; an
</em><br>
<em>&gt; &gt;end as long as that action can be justified as also being an end in
</em><br>
<em>&gt; itself.
</em><br>
<em>&gt; &gt;Also I contend that if an AGI is self-aware that it must be programmed to
</em><br>
<em>&gt; &gt;understand that it is not just an individual but part of a collective
</em><br>
<em>&gt; which
</em><br>
<em>&gt; &gt;is human civilization and part of its goal system should be in service to
</em><br>
<em>&gt; &gt;this collective. This is not just true for machines but for people as
</em><br>
<em>&gt; well.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Until you understand what powerful optimization processes are, you won't
</em><br>
<em>&gt; have any idea what &quot;highly dangerous&quot; means by SL4 standards.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<p><p><pre>
--
I swear upon the alter of God, eternal hostility to every form of tyranny
over the mind of man. - Thomas Jefferson
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13198.html">David Picon Alvarez: "Re: Destruction of All Humanity"</a>
<li><strong>Previous message:</strong> <a href="13196.html">Michael Vassar: "Re: Please Re-read CAFAI"</a>
<li><strong>In reply to:</strong> <a href="13196.html">Michael Vassar: "Re: Please Re-read CAFAI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13199.html">David Picon Alvarez: "Re: Please Re-read CAFAI"</a>
<li><strong>Reply:</strong> <a href="13199.html">David Picon Alvarez: "Re: Please Re-read CAFAI"</a>
<li><strong>Reply:</strong> <a href="13209.html">Michael Vassar: "Re: Not the only way to build an AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13197">[ date ]</a>
<a href="index.html#13197">[ thread ]</a>
<a href="subject.html#13197">[ subject ]</a>
<a href="author.html#13197">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:54 MDT
</em></small></p>
</body>
</html>
