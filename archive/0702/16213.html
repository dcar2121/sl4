<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [agi] Optimality of using probability</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="Re: [agi] Optimality of using probability">
<meta name="Date" content="2007-02-03">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [agi] Optimality of using probability</h1>
<!-- received="Sat Feb  3 05:30:26 2007" -->
<!-- isoreceived="20070203123026" -->
<!-- sent="Sat, 3 Feb 2007 07:29:26 -0500" -->
<!-- isosent="20070203122926" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="Re: [agi] Optimality of using probability" -->
<!-- id="B03BE03A-7ABA-42C4-8AEF-3EEBCD6B368B@goertzel.org" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="45C40E5A.1080003@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=Re:%20[agi]%20Optimality%20of%20using%20probability"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sat Feb 03 2007 - 05:29:26 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16214.html">Giu1i0 Pri5c0: "SNOWCRASHING INTO THE DIAMOND AGE: AN ESSAY BY EXTROPIA DaSILVA"</a>
<li><strong>Previous message:</strong> <a href="16212.html">Eliezer S. Yudkowsky: "Optimality of using probability"</a>
<li><strong>In reply to:</strong> <a href="16212.html">Eliezer S. Yudkowsky: "Optimality of using probability"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16218.html">Mitchell Porter: "Re: Optimality of using probability"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16213">[ date ]</a>
<a href="index.html#16213">[ thread ]</a>
<a href="subject.html#16213">[ subject ]</a>
<a href="author.html#16213">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;
</em><br>
<p>Eliezer,
<br>
<p><p><em>&gt; I don't think a mind that evaluates probabilities *is*  
</em><br>
<em>&gt; automatically the best way to make use of limited computing  
</em><br>
<em>&gt; resources.  That is: if you have limited computing resources, and  
</em><br>
<em>&gt; you want to write a computer program that makes the best use of  
</em><br>
<em>&gt; those resources to solve a problem you're facing, then only under  
</em><br>
<em>&gt; very *rare* circumstances does it make sense to write a program  
</em><br>
<em>&gt; consisting of an intelligent mind that thinks in probabilities.  In  
</em><br>
<em>&gt; fact, these rare circumstances are what define AGI work.
</em><br>
<em>&gt;
</em><br>
<p>Hmmm..
<br>
<p>My approach was to formulate a notion of &quot;general intelligence&quot; as  
<br>
&quot;achieving a complex goal&quot;, and then ask something like: Given what  
<br>
resource levels R and goals G, is approximating probability theory  
<br>
the best way to approximately achieve G using software that utilizes  
<br>
only resources R.
<br>
<p><p><em>&gt;
</em><br>
<em>&gt; What state of subjective uncertainty must you, the programmer, be  
</em><br>
<em>&gt; in with respect to the environment, before coding a probability- 
</em><br>
<em>&gt; processing mind is a rational use of your limited computing  
</em><br>
<em>&gt; resources?  This is how I would state the question.
</em><br>
<em>&gt;
</em><br>
<p>That is an interesting way to put the problem....
<br>
<p>Consider the nearly-degenerate case of a demi-God-programmer, who  
<br>
knows an extremely large amount about the future of the universe.   
<br>
Suppose the demi-God-programmer wants to build a robotic salesman  
<br>
that will venture to all the planets in the galaxy and sell their  
<br>
residents soap.  But, suppose the different creatures in the galaxy  
<br>
have different psychologies, so that a different strategy must be  
<br>
taken to sell each species soap.  But, suppose the robot has a very  
<br>
limited brain capacity, comparable to that of a human.  Then, the  
<br>
demi-God-programmer must program the robot with a learning system,  
<br>
because the robot's head can't be filled with all the details of the  
<br>
psychologies of the 10 decillion species it needs to sell soap to,  
<br>
because there isn't room in its brain....  So, a probabilistic  
<br>
solution to the robot-brain-programming problem will likely be  
<br>
optimal, even though the demi-God-programmer itself has comprehensive  
<br>
knowledge of the environment.
<br>
<p>But in this case the demi-God-programmer does lack some knowledge  
<br>
about the future.  It may know something about the psychology of each  
<br>
species (even though there's no room to put this knowledge into the  
<br>
brain of the robot), but it doesn't know the exact conversations that  
<br>
the robot will have on each planet....
<br>
<p>The case of a God-programmer that has truly complete knowledge of the  
<br>
future of the universe is subtler.  In this case, would the  
<br>
probabilistic solution still be optimal for the robot, or would the  
<br>
God-programmer be able to come up with some highly clever highly  
<br>
specialized trick that would give better performance given the exact  
<br>
specifics of the future destiny of the robot?  You seem to be  
<br>
asserting the latter, but I'm not quite sure why...
<br>
<p><p><em>&gt; Intuitively, I answer:  When you, the programmer, can identify  
</em><br>
<em>&gt; parts of the environmental structure; but you are extremely  
</em><br>
<em>&gt; uncertain about other parts of the environment; and yet you do  
</em><br>
<em>&gt; believe there's structure (the unknown parts are not believed by  
</em><br>
<em>&gt; you to be pure random noise).  In this case, it makes sense to  
</em><br>
<em>&gt; write a Probabilistic Structure Identifier and Exploiter, aka, a  
</em><br>
<em>&gt; rational mind.
</em><br>
<em>&gt;
</em><br>
<p><p>Is it really necessary to introduce the programmer into the problem  
<br>
formulation, though?
<br>
<p>Can't we just speak about this in terms of optimization?
<br>
<p>I think I want to ask: If we want to write a program P that will  
<br>
optimize some function G, using resources R, in what cases will it be  
<br>
optimal for the program P to use an approximation to probability theory?
<br>
<p>The subtlety comes in the definition of what it means to &quot;use an  
<br>
approximation to probability theory.&quot;
<br>
<p>The cleanest definition would be: &quot;To act in such a way that its  
<br>
behaviors are approximately consistent with probability theory&quot;
<br>
<p>Now, how can we define this?   We can define this if we have a notion  
<br>
of the set of actions that are available to the system at a given  
<br>
point in time.
<br>
<p>Then, the system's choice of action A instead of action B may be  
<br>
taken as an implicit assessment that
<br>
<p>&quot;my expected achievement of G given I take action A&quot; &gt; &quot;my expected  
<br>
achievement of G given I take action B&quot;
<br>
<p>where the quantities on both sides of this inequality are expected  
<br>
plausibilities.
<br>
<p>So, we can then ask whether these expected plausibilities, implicit  
<br>
in the system's actions, are consistent with probability theory or not.
<br>
<p>And, the hypothesis is that for a broad class of goal functions G and  
<br>
resource restrictions R, the optimal way to achieve G given R will be  
<br>
using software whose implicit plausibility judgments (as defined  
<br>
above) approximately obey probability theory.
<br>
<p>Note that the hypothesis is about how the various implicit  
<br>
plausibility judgments of the system will **relate to each other**.   
<br>
They need to relate to each other approximately consistently  
<br>
according to probability theory, is the hypothesis (for G that is  
<br>
complex in the right way, and R that is not too small relative to the  
<br>
complexity of G).
<br>
<p>Of course, the above formulation is just a bunch of hand-waving and I  
<br>
have not succeeded in proving this [or even formulating it in a  
<br>
thoroughly rigorous way] any better than you have succeeded in  
<br>
proving your formulation (nor have I put terribly much effort into it  
<br>
yet, due to other priorities).
<br>
<p>What interests me in this dialogue is largely to see whether you feel  
<br>
we are both approaching essentially the same question, though using  
<br>
different specific formulations.
<br>
<p>-- Ben 
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16214.html">Giu1i0 Pri5c0: "SNOWCRASHING INTO THE DIAMOND AGE: AN ESSAY BY EXTROPIA DaSILVA"</a>
<li><strong>Previous message:</strong> <a href="16212.html">Eliezer S. Yudkowsky: "Optimality of using probability"</a>
<li><strong>In reply to:</strong> <a href="16212.html">Eliezer S. Yudkowsky: "Optimality of using probability"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16218.html">Mitchell Porter: "Re: Optimality of using probability"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16213">[ date ]</a>
<a href="index.html#16213">[ thread ]</a>
<a href="subject.html#16213">[ subject ]</a>
<a href="author.html#16213">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:57 MDT
</em></small></p>
</body>
</html>
