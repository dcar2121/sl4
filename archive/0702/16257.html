<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Safety of brain-like AGIs</title>
<meta name="Author" content="Larry (entropy@farviolet.com)">
<meta name="Subject" content="Re: Safety of brain-like AGIs">
<meta name="Date" content="2007-02-28">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Safety of brain-like AGIs</h1>
<!-- received="Wed Feb 28 09:01:56 2007" -->
<!-- isoreceived="20070228160156" -->
<!-- sent="Wed, 28 Feb 2007 09:09:50 -0800 (PST)" -->
<!-- isosent="20070228170950" -->
<!-- name="Larry" -->
<!-- email="entropy@farviolet.com" -->
<!-- subject="Re: Safety of brain-like AGIs" -->
<!-- id="Pine.LNX.4.60.0702280851470.8412@farviolet.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="d13d7ef40702280408m665037e3oa8bf9e12435d6bbb@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Larry (<a href="mailto:entropy@farviolet.com?Subject=Re:%20Safety%20of%20brain-like%20AGIs"><em>entropy@farviolet.com</em></a>)<br>
<strong>Date:</strong> Wed Feb 28 2007 - 10:09:50 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16258.html">Ben Goertzel: "Re: Safety of brain-like AGIs"</a>
<li><strong>Previous message:</strong> <a href="16256.html">Ben Goertzel: "Re: Safety of brain-like AGIs"</a>
<li><strong>In reply to:</strong> <a href="16252.html">Shane Legg: "Safety of brain-like AGIs"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16258.html">Ben Goertzel: "Re: Safety of brain-like AGIs"</a>
<li><strong>Reply:</strong> <a href="16258.html">Ben Goertzel: "Re: Safety of brain-like AGIs"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16257">[ date ]</a>
<a href="index.html#16257">[ thread ]</a>
<a href="subject.html#16257">[ subject ]</a>
<a href="author.html#16257">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Wed, 28 Feb 2007, Shane Legg wrote:
<br>
<p><em>&gt; I don't know of any formal definition of friendliness, in which case, how
</em><br>
<em>&gt; could I possibly
</em><br>
<em>&gt; ensure that an AGI, which doesn't yet exist, has a formal property that
</em><br>
<em>&gt; isn't yet defined?
</em><br>
<em>&gt; That applies to all systems, brain-like or otherwise.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If we consider informal definitions, then clearly some humans are friendly
</em><br>
<em>&gt; and intelligent.
</em><br>
<em>&gt; Thus at an informal level, I don't see any reason why a brain-like system
</em><br>
<em>&gt; cannot be both.
</em><br>
<p>I see this as a very drastic problem. At best a human is friendly within
<br>
a fairly vague social context. Consider 200 years ago.
<br>
<p>&quot;He is a good man, he treats his slaves almost as if they where free men
<br>
&nbsp;&nbsp;so long as they get the work done.&quot;
<br>
<p>For the time that was about as good as it got. Except for those rare
<br>
people who could see beyond cultural norms. Still even then you sometimes
<br>
make things worse trying to make them better. I'd argue that a day in
<br>
the stocks for petty thefy is far 'friendlier' to all involved than
<br>
the supposedly more civilized month in jail where you get repeatedly 
<br>
beaten and raped conviently out of view of 'civilized' people.
<br>
<p>I'd say this isn't just a difficult problem its an intractable problem
<br>
defining friendlyness.
<br>
<p>Back to the 200 year ago theme. The human race is in the position of a
<br>
slave being shipped off for auction whose discovered they have a choice
<br>
of the stage coach they board. That is about our level of knowledge of
<br>
the situation.
<br>
<p>But we do have one other choice the slave didn't have, we can choose not
<br>
to go, or delay until we know more. I don't think AI can be stopped
<br>
forever, but I think the human race needs to seriously consider holding
<br>
off the 'singularity' and advancing toward it slowly. Some view it as a 
<br>
utopia, but this is not the way world history has ever worked. Great 
<br>
upheaval is usually very messy. Violently losing the human race entirely 
<br>
is more likely than the utopian outcome. A much more slow approach may 
<br>
allow evolutionary steps where there is time to grasp the next step at 
<br>
each stage.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16258.html">Ben Goertzel: "Re: Safety of brain-like AGIs"</a>
<li><strong>Previous message:</strong> <a href="16256.html">Ben Goertzel: "Re: Safety of brain-like AGIs"</a>
<li><strong>In reply to:</strong> <a href="16252.html">Shane Legg: "Safety of brain-like AGIs"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16258.html">Ben Goertzel: "Re: Safety of brain-like AGIs"</a>
<li><strong>Reply:</strong> <a href="16258.html">Ben Goertzel: "Re: Safety of brain-like AGIs"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16257">[ date ]</a>
<a href="index.html#16257">[ thread ]</a>
<a href="subject.html#16257">[ subject ]</a>
<a href="author.html#16257">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:57 MDT
</em></small></p>
</body>
</html>
