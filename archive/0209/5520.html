<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: continuity of self  [ was META: Sept. 11 and  Singularity]</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: continuity of self  [ was META: Sept. 11 and  Singularity]">
<meta name="Date" content="2002-09-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: continuity of self  [ was META: Sept. 11 and  Singularity]</h1>
<!-- received="Tue Sep 17 11:23:21 2002" -->
<!-- isoreceived="20020917172321" -->
<!-- sent="Tue, 17 Sep 2002 07:18:14 -0600" -->
<!-- isosent="20020917131814" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: continuity of self  [ was META: Sept. 11 and  Singularity]" -->
<!-- id="LAEGJLOGJIOELPNIOOAJOEOCDJAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3D86C4AA.8090400@objectent.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20continuity%20of%20self%20%20[%20was%20META:%20Sept.%2011%20and%20%20Singularity]"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Tue Sep 17 2002 - 07:18:14 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5521.html">Gordon Worley: "Re: Eliezer's Birthday"</a>
<li><strong>Previous message:</strong> <a href="5519.html">Ben Goertzel: "RE: continuity of self  [ was META: Sept. 11 and  Singularity]"</a>
<li><strong>In reply to:</strong> <a href="5509.html">Samantha Atkins: "Re: continuity of self  [ was META: Sept. 11 and  Singularity]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5502.html">Aaron McBride: "Re: continuity of self  [ was META: Sept. 11 and  Singularity]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5520">[ date ]</a>
<a href="index.html#5520">[ thread ]</a>
<a href="subject.html#5520">[ subject ]</a>
<a href="author.html#5520">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>

<br>

<br>

<br>
Samantha wrote:
<br>
<em>&gt; &gt; And I still think that, based on all the evidence available,
</em><br>
<em>&gt; the Friendly AI
</em><br>
<em>&gt; &gt; route has the highest chance of success, out of all the possibilities
</em><br>
<em>&gt; &gt; raised.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I am not so sure these days.  Eliezer and team, afaik, haven't
</em><br>
<em>&gt; really got moving on implementation.  You know your own status
</em><br>
<em>&gt; far better than I.
</em><br>

<br>
My own team's situation is as follows.  Engineering is proceeding at a slow
<br>
but steady pace (4 people working half-time on the AGI project, and spending
<br>
the other half of their time on related AI product work; plus a few other
<br>
part-timers).  I am working hard on a full mathematical and verbal
<br>
formalization of the AI design, which will be done within 6 months (within
<br>
2-3 months minus all the graphs and diagrams...).  We're going to publish a
<br>
technical book containing this overview of the design (hopefully in late
<br>
2003) and following that we'll make a major push to get significant funding
<br>
for the project.  In 1998-2001 we had over 40 R&amp;D staff on our previous
<br>
project, Webmind, and we intend to get Novamente back to this level within a
<br>
few years.
<br>

<br>
Giving precise timing estimates is always fraught with difficulty.  The
<br>
following numbers should be taken with a grain of salt, because there are
<br>
plenty of uncertainties involved.  Completion of the engineering of the
<br>
system will occur in the time-frame 2003-2005 [2004-2005 if the current team
<br>
does not expand in any way].  Then comes the teaching phase, which will
<br>
undoubtedly involve a lot of tuning and refactoring of parts of the system.
<br>
If our design for AGI is basically correct and workable, we could have a
<br>
human-level AI by 2010, or conceivably by 2007-2008 if things just go
<br>
swimmingly well and we get a bigger team in the 2004-2005 timeframe.
<br>

<br>
Of course, if our AI design is totally wrong (as Eliezer believes, based on
<br>
having read a very rough, early draft of the current book manuscript), then
<br>
all we'll discover by 2006 or so is that our AI design is unable to be
<br>
taught !!!
<br>

<br>
In short, we have a long path ahead of us, but we're pretty happy to have a
<br>
detailed design that appears to us to plausibly account for all aspects of
<br>
human-level intelligence.
<br>

<br>
For those not familiar with my Novamente Artificial General Intelligence
<br>
project please see www.realai.net.
<br>

<br>
For those who want to wade through some of Eliezer's and my arguments about
<br>
the Novamente system, see the archives of this list, sometime around May of
<br>
this year I think.
<br>

<br>
<em>&gt; It is an unknown whether  AI can be
</em><br>
<em>&gt; produced in the time frame (&lt; 30 years) I believe is the most
</em><br>
<em>&gt; hyper-critical. And of course it would be really useful if it
</em><br>
<em>&gt; existed next week.
</em><br>

<br>
Even if my own and other current AGI projects fail, I think Kurzweil has
<br>
made a very strong case that detailed computational emulation of the human
<br>
brain will likely be possible in another 30 years or so.
<br>

<br>
<em>&gt;  But no pressure! :-) If it is produced it is
</em><br>
<em>&gt; another huge unknown if it will be &quot;friendly&quot; in the rather
</em><br>
<em>&gt; collogial sense of actually being a boon, a freeing of humanity
</em><br>
<em>&gt; from so many limitations and so much suffering in a positive
</em><br>
<em>&gt; sense or not.
</em><br>

<br>
Naturally, I have faith in my own team's approach to AI friendliness, but I
<br>
do worry about some future scenarios.
<br>

<br>
Actually, I worry less about my initial AI being unfriendly, than I do about
<br>
scenarios like: &quot;human-level but not yet transhuman AI's are taken by
<br>
governments and brainwashed to produce advanced weaponry, leading to the end
<br>
of us all.&quot;
<br>

<br>
Yes, brainwashing an advanced AI will be hard.  But do we know enough yet to
<br>
estimate just how hard?
<br>

<br>
<em>&gt; As unlikely as sufficient shift of institutions and people's
</em><br>
<em>&gt; perceptions and practices are, I think that is at least as
</em><br>
<em>&gt; likely to work as FAI.
</em><br>

<br>
Well, my intuition differs, but obviously we're in a domain of highly weak &amp;
<br>
scattered bits of evidence here, so it can't be expected that different
<br>
intelligent, rational, insightful observers are necessarily going to agree!
<br>

<br>

<br>
<em>&gt; &gt; But I can't make this statement with enough confidence to say that other
</em><br>
<em>&gt; &gt; possible solutions shouldn't be avidly pursued too.  As far as
</em><br>
<em>&gt; I can tell
</em><br>
<em>&gt; &gt; right now, they should be.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Yes.  That is also my conclusion.  I plan to attempt the shift
</em><br>
<em>&gt; of consciousness approach.  Someone has to.
</em><br>

<br>
Well, best of luck ;_)  you have my support, for what it's worth...
<br>

<br>

<br>
ben g
<br>

<br>

<br>

<br>

<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5521.html">Gordon Worley: "Re: Eliezer's Birthday"</a>
<li><strong>Previous message:</strong> <a href="5519.html">Ben Goertzel: "RE: continuity of self  [ was META: Sept. 11 and  Singularity]"</a>
<li><strong>In reply to:</strong> <a href="5509.html">Samantha Atkins: "Re: continuity of self  [ was META: Sept. 11 and  Singularity]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5502.html">Aaron McBride: "Re: continuity of self  [ was META: Sept. 11 and  Singularity]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5520">[ date ]</a>
<a href="index.html#5520">[ thread ]</a>
<a href="subject.html#5520">[ subject ]</a>
<a href="author.html#5520">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:41 MDT
</em></small></p>
</body>
</html>
