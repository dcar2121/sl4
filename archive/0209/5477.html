<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re[2]: continuity of self  [ was META: Sept. 11 and Singularity]</title>
<meta name="Author" content="Cliff Stabbert (cps46@earthlink.net)">
<meta name="Subject" content="Re[2]: continuity of self  [ was META: Sept. 11 and Singularity]">
<meta name="Date" content="2002-09-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re[2]: continuity of self  [ was META: Sept. 11 and Singularity]</h1>
<!-- received="Sun Sep 15 21:00:09 2002" -->
<!-- isoreceived="20020916030009" -->
<!-- sent="Sun, 15 Sep 2002 20:40:27 -0400" -->
<!-- isosent="20020916004027" -->
<!-- name="Cliff Stabbert" -->
<!-- email="cps46@earthlink.net" -->
<!-- subject="Re[2]: continuity of self  [ was META: Sept. 11 and Singularity]" -->
<!-- id="12015821019.20020915204027@earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3D85158A.8000705@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Cliff Stabbert (<a href="mailto:cps46@earthlink.net?Subject=Re[2]:%20continuity%20of%20self%20%20[%20was%20META:%20Sept.%2011%20and%20Singularity]"><em>cps46@earthlink.net</em></a>)<br>
<strong>Date:</strong> Sun Sep 15 2002 - 18:40:27 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5478.html">Eliezer S. Yudkowsky: "Strong-willed AIs [was: continuity of self]"</a>
<li><strong>Previous message:</strong> <a href="5476.html">Ben Goertzel: "RE: Re[2]: continuity of self  [ was META: Sept. 11 and Singularity]"</a>
<li><strong>In reply to:</strong> <a href="5474.html">Eliezer S. Yudkowsky: "Re: continuity of self  [ was META: Sept. 11 and Singularity]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5476.html">Ben Goertzel: "RE: Re[2]: continuity of self  [ was META: Sept. 11 and Singularity]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5477">[ date ]</a>
<a href="index.html#5477">[ thread ]</a>
<a href="subject.html#5477">[ subject ]</a>
<a href="author.html#5477">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Sunday, September 15, 2002, 7:19:38 PM, Eliezer S. Yudkowsky wrote:
<br>

<br>
ESY&gt; Cliff Stabbert wrote:
<br>
CS&gt; How big would the temptation be for any current superpower to grab
<br>
CS&gt; the first workable nanotech or the first usable general AI and use
<br>
CS&gt; it to wield power over others?
<br>

<br>
ESY&gt; Stealing the first workable nanotech is one thing.  &quot;Stealing&quot; a
<br>
ESY&gt; general AI is a bit different from stealing its physical
<br>
ESY&gt; hardware.  AI is not a tool.  It is a mind.  Moving an AI from
<br>
ESY&gt; one place to another doesn't make it a tool in your hands, any
<br>
ESY&gt; more than moving Gandhi from India to Germany causes him to
<br>
ESY&gt; become a Nazi.  Now of course potential thieves may not know
<br>
ESY&gt; that, but if so, failing to keep track of the distinction
<br>
ESY&gt; ourselves is hardly conducive to enlightening them.
<br>

<br>
You're right; but my concern in the case of AI tech is less about what
<br>
uses they (erroneously or not*) believe they could put it to, than with
<br>
research efforts being halted.  This is also to some degree a concern
<br>
with nanotech, although in that case actual usage seems a larger risk
<br>
factor (and arguably, compared to AI nanotech has less potential for
<br>
private development -- at some point you need big labs, big equipment,
<br>
and visibility in the academic/scientific world (unless it's already a
<br>
government op), so shutting down the research seems harder).
<br>

<br>
* There are a number of approaches to general AI -- perhaps some may
<br>
&nbsp;&nbsp;in their pre-human-level AI stages be subvertible.
<br>

<br>
--
<br>
Cliff
<br>

<br>

<br>

<br>

<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5478.html">Eliezer S. Yudkowsky: "Strong-willed AIs [was: continuity of self]"</a>
<li><strong>Previous message:</strong> <a href="5476.html">Ben Goertzel: "RE: Re[2]: continuity of self  [ was META: Sept. 11 and Singularity]"</a>
<li><strong>In reply to:</strong> <a href="5474.html">Eliezer S. Yudkowsky: "Re: continuity of self  [ was META: Sept. 11 and Singularity]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5476.html">Ben Goertzel: "RE: Re[2]: continuity of self  [ was META: Sept. 11 and Singularity]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5477">[ date ]</a>
<a href="index.html#5477">[ thread ]</a>
<a href="subject.html#5477">[ subject ]</a>
<a href="author.html#5477">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:41 MDT
</em></small></p>
</body>
</html>
