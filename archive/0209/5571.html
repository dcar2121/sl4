<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: QUES: CFAI [#2]</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: QUES: CFAI [#2]">
<meta name="Date" content="2002-09-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: QUES: CFAI [#2]</h1>
<!-- received="Thu Sep 19 16:02:26 2002" -->
<!-- isoreceived="20020919220226" -->
<!-- sent="Thu, 19 Sep 2002 15:58:03 -0400" -->
<!-- isosent="20020919195803" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: QUES: CFAI [#2]" -->
<!-- id="3D8A2C4B.8000707@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="OE100TJG4aqEBw1Cllt0001024f@hotmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20QUES:%20CFAI%20[#2]"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Thu Sep 19 2002 - 13:58:03 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5572.html">Anand: "Re: QUES: CFAI [#2]"</a>
<li><strong>Previous message:</strong> <a href="5570.html">Samantha Atkins: "Re: continuity of self  [ was META: Sept. 11 and Singularity]"</a>
<li><strong>In reply to:</strong> <a href="5563.html">Anand: "QUES: CFAI [#2]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5572.html">Anand: "Re: QUES: CFAI [#2]"</a>
<li><strong>Reply:</strong> <a href="5572.html">Anand: "Re: QUES: CFAI [#2]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5571">[ date ]</a>
<a href="index.html#5571">[ thread ]</a>
<a href="subject.html#5571">[ subject ]</a>
<a href="author.html#5571">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Anand wrote:
<br>
<em> &gt; 01.  What cognitive processes may allow for altruism?
</em><br>

<br>
Can I zoom in on this question a bit?  Do you mean, why does altruism
<br>
evolve?  Do you mean, are there specific known neuroanatomical regions
<br>
whose activation is associated with altruism?  Do you mean, what kind of
<br>
cognitive processes may be involved with altruism aside from regular,
<br>
evolved emotional tones?
<br>

<br>
<em> &gt; 02.  What does it mean for a cognitive process to allow for altruism?
</em><br>

<br>
You used the term &quot;allow for altruism&quot;, right?  Or did I use it somewhere
<br>
and forget it?  Anyway, I'd say that it means that this cognitive process
<br>
plays a role in an altruistic mind or that this cognitive process does not
<br>
actually *rule out* altruism.  But I really don't know what you mean by
<br>
this.  Do you mean *supports* altruism or *plays a role in human altruism*?
<br>

<br>
<em> &gt; The following are prompted by recent difficulty in explaining aspects
</em><br>
<em> &gt; of Friendliness.  (Apologies if some of these are wrong questions.)
</em><br>
<em> &gt;
</em><br>
<em> &gt; 03.  &quot;...for any sort of diverse audience, humans generally use the
</em><br>
<em> &gt; semantics of objectivity, by which I mean that a statement is argued to
</em><br>
<em> &gt;  be 'true' or 'false' without reference to data that the
</em><br>
<em> &gt; audience/persuadee would cognitively process as 'individual.'&quot;
</em><br>
<em> &gt; (www.intelligence.org/CFAI/design/structure/shaper.html#some)
</em><br>
<em> &gt;
</em><br>
<em> &gt; What are the implications of the semantics of objectivity?
</em><br>

<br>
Um... that, ceteris paribus and lacking complex philosophical reasons to
<br>
do otherwise, humans tend to argue with each other as if moral
<br>
propositions were facts?  Because that's the first way evolution stumbled
<br>
on to represent moral propositions in declarative discourse, which
<br>
development would tend to become evolutionary fixed by the way that it
<br>
makes moral propositions easy to communicate between humans?
<br>

<br>
<em> &gt; 04.  &quot;Thus, when humans talk about 'morality,' we generally refer to
</em><br>
<em> &gt; the body of cognitive material that uses the semantics of objectivity.&quot;
</em><br>
<em> &gt;  (www.intelligence.org/CFAI/design/structure/shaper.html#some)
</em><br>
<em> &gt;
</em><br>
<em> &gt; What composes said body of cognitive material?
</em><br>

<br>
Example:  &quot;We hold these truths to be self-evident...&quot;
<br>

<br>
<em> &gt; 05.  What are examples of non-good/non-bad Gaussian abilities that
</em><br>
<em> &gt; ground in panhuman characteristics?
</em><br>

<br>
Uh... what?  Can you rephrase that without using my own jargon?  In
<br>
particular, I use the jargon &quot;gaussian ability&quot; to refer to abilities
<br>
which, among humans, obey some kind of bellish distribution, of which the
<br>
gaussian distribution is the most common kind.  A panhuman characteristic
<br>
is one that is species-typical.  I'm not sure why these two terms are
<br>
appearing in the same sentence above.
<br>

<br>
<em> &gt; 06.  What are examples of good or bad Gaussian abilities that ground in
</em><br>
<em> &gt;  panhuman characteristics and that the shaper network will recognize?
</em><br>

<br>
Same problem - why are those two terms appearing in the same sentence?
<br>

<br>
<em> &gt; 07.  &quot;The renormalizing shaper network should ultimately ground itself
</em><br>
<em> &gt; in the panhuman and gaussian layers, without use of material from the
</em><br>
<em> &gt; personality layer of the original programmer.&quot;
</em><br>
<em> &gt; (www.intelligence.org/CFAI/design/structure/friendliness.html)
</em><br>
<em> &gt;
</em><br>
<em> &gt; What does &quot;material&quot; refer to?  Please give examples of material in the
</em><br>
<em> &gt;  panhuman and gaussian layers that the shaper network will use.
</em><br>

<br>
An example of panhuman material would be the complex functional adaptation
<br>
of &quot;sympathy&quot;, constituting both the cognitive ability to put yourself in
<br>
someone else's shoes, and the emotional affects of doing so, particularly
<br>
with respect to judging fairness in both moral and metamoral arguments.
<br>

<br>
An example of a gaussian characteristic that would be modeled as a shaper,
<br>
and incrementally nudged toward an extreme, would be the internal
<br>
intensity of some of the emotional tones contributing to altruism.  Note
<br>
that the tones themselves are panhuman and their intensity is gaussian.
<br>

<br>
An example of something on the personality layer which should never be
<br>
treated as grounding is Eliezer's fondness for the book Godel, Escher,
<br>
Bach.  Cognitive modules that play a role in my liking GEB might be
<br>
transferred over.  The interim fact that I like GEB might be used as
<br>
evidence to get at those cognitive modules.  The fact that I actually like
<br>
GEB shouldn't ever play a role in bottom-level Friendliness.
<br>

<br>
<em> &gt; 08.  &quot;...requires all the structural Friendliness so far described, an
</em><br>
<em> &gt; explicit surface-level decision of the starting set to converge,
</em><br>
<em> &gt; prejudice against circular logic as a surface decision, protection
</em><br>
<em> &gt; against extraneous causes by causal validity semantics and surface
</em><br>
<em> &gt; decision,...&quot;)
</em><br>
<em> &gt; (www.intelligence.org/CFAI/design/structure/friendliness.html)
</em><br>
<em> &gt;
</em><br>
<em> &gt; What does &quot;surface decision&quot; mean?
</em><br>

<br>
It means the final decision of the entire current Friendliness system with
<br>
respect to some particular choice point.  In the above, it means that the
<br>
initial Friendliness system has to be such that, if the AI is presented
<br>
with a piece of extraneous circular logic, it is already capable of saying
<br>
&quot;Well, that's circular logic, and right now, at least, I think that
<br>
circular logic is a bad thing, so I'm not going to accept it, at least at
<br>
the moment, although I might change my mind about circular logic later.&quot;
<br>

<br>
<em> &gt; 09.  What is the best way to determine whether an action is Friendly,
</em><br>
<em> &gt; and why?  What is the _last_ way, and why?  (Prehuman AI, Infrahuman
</em><br>
<em> &gt; AI)
</em><br>

<br>
You have your current understanding of Friendliness - your current set of
<br>
definitions for figuring out how Friendly something is likely to be - and
<br>
you have your programmers, whom you can consult if you can cross the
<br>
communications gap.  What else is there?
<br>

<br>
<em> &gt; 10.  What are your present predictions on why Friendly AI will fail?
</em><br>

<br>
Huh?
<br>

<br>
Or do you mean, what are the most likely reasons FAI might fail?
<br>

<br>
Those are:
<br>

<br>
1)  Because seed AI is way, way easier than anyone expects.  The hard
<br>
takeoff trajectory is such that it's possible to do a hard takeoff using
<br>
little more than Lenatian complexity, meaning that the AI must spend a
<br>
very extended period in controlled ascent and cooperative ascent without
<br>
having any substantial base of understanding in Friendliness.  Then the
<br>
controlled ascent mechanism fails at sufficiently many points that a
<br>
stratospheric ascent begins and is not detected.
<br>

<br>
2)  Because the FAI is just more alien than the programmers can figure out
<br>
how to deal with, and the programmers don't realize their own
<br>
incompetence.  This interacts strongly with (1) above, since otherwise,
<br>
how the heck did you grow something that alien to the point where it could
<br>
undergo takeoff?  Incidentally, there are really alien things you can do 
<br>
to *support* Friendliness.
<br>

<br>
3)  The AI builders screw up their basic understanding of Friendliness,
<br>
and this only becomes apparent after the AI is past the point of no return.
<br>

<br>
4)  The first AI is built by a project that doesn't care enough about
<br>
Friendliness.  Also interacts with (1).
<br>

<br>
<em> &gt; 11.  What have you studied or what are you studying for Friendliness
</em><br>
<em> &gt; content?
</em><br>

<br>
Study?  People don't *write* about this stuff.  At least not that I know
<br>
about.
<br>

<br>
<em> &gt; 12.  What recent progress have you made and what progress do you need
</em><br>
<em> &gt; to make on Friendliness content?
</em><br>

<br>
Most recently:  Figuring out microtasks that could be used to teach
<br>
an AI an incremental understanding of Friendliness, and more importantly,
<br>
meta-Friendliness.  Probabilistic grounding semantics (where a system 
<br>
tries to figure out what it's an imperfect approximation to).  Using a 
<br>
flawed but redundant definition of &quot;correction&quot; to correct a flawed but 
<br>
redundant definition of &quot;correction&quot;.
<br>

<br>
<em> &gt; 13.  What are the next steps for Friendly AI theory?
</em><br>

<br>
A more detailed model of Friendliness content as well as Friendliness
<br>
structure.  Adapting the theory to an early infrahuman mind.  You might 
<br>
say that CFAI argues that human-equivalent minds and superintelligences 
<br>
*can* be Friendly.  From there you have to go on to figure out how an 
<br>
infrahuman mind actually does understand Friendliness.
<br>

<br>
-- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>

<br>

<br>

<br>

<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5572.html">Anand: "Re: QUES: CFAI [#2]"</a>
<li><strong>Previous message:</strong> <a href="5570.html">Samantha Atkins: "Re: continuity of self  [ was META: Sept. 11 and Singularity]"</a>
<li><strong>In reply to:</strong> <a href="5563.html">Anand: "QUES: CFAI [#2]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5572.html">Anand: "Re: QUES: CFAI [#2]"</a>
<li><strong>Reply:</strong> <a href="5572.html">Anand: "Re: QUES: CFAI [#2]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5571">[ date ]</a>
<a href="index.html#5571">[ thread ]</a>
<a href="subject.html#5571">[ subject ]</a>
<a href="author.html#5571">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:41 MDT
</em></small></p>
</body>
</html>
