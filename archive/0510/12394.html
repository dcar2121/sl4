<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AGI motivations (Sidetrack on Uploading)</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: AGI motivations (Sidetrack on Uploading)">
<meta name="Date" content="2005-10-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AGI motivations (Sidetrack on Uploading)</h1>
<!-- received="Mon Oct 24 13:20:19 2005" -->
<!-- isoreceived="20051024192019" -->
<!-- sent="Mon, 24 Oct 2005 12:22:23 -0700" -->
<!-- isosent="20051024192223" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: AGI motivations (Sidetrack on Uploading)" -->
<!-- id="435D346F.1090607@pobox.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="435D0C35.8030605@lightlink.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20AGI%20motivations%20(Sidetrack%20on%20Uploading)"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Mon Oct 24 2005 - 13:22:23 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12395.html">Chris Capel: "Re: cyborgs &amp; ghosts"</a>
<li><strong>Previous message:</strong> <a href="12393.html">Richard Loosemore: "Re: Loosemore's Proposal"</a>
<li><strong>In reply to:</strong> <a href="12387.html">Richard Loosemore: "Re: AGI motivations (Sidetrack on Uploading)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12397.html">Martin Striz: "Re: AGI motivations (Sidetrack on Uploading)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12394">[ date ]</a>
<a href="index.html#12394">[ thread ]</a>
<a href="subject.html#12394">[ subject ]</a>
<a href="author.html#12394">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Richard Loosemore wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Michael Wilson wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt; Michael Vassar wrote:
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; Trying to build a human derived AI is the general case of which
</em><br>
<em>&gt;&gt;&gt; building a human upload is a special case... I'm skeptical about the
</em><br>
<em>&gt;&gt;&gt; diferences being unavoidabld. Surely true given current computers,
</em><br>
<em>&gt;&gt;&gt; surely false given uploads. There is a substantial space of possible
</em><br>
<em>&gt;&gt;&gt; AGI design around &quot;uploads&quot;.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; This is true in principle, but not in practice. Yes, uploads occupy
</em><br>
<em>&gt;&gt; a small region of cognitive architecture space within a larger region
</em><br>
<em>&gt;&gt; of 'human-like AGI designs'. However we can actually hit the narrower
</em><br>
<em>&gt;&gt; region semi-reliably if we can develop an accurate brain simulation
</em><br>
<em>&gt;&gt; and copy an actual human's brain structure into it.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Okay, I want to make a (probably futile) attempt to steer the 
</em><br>
<em>&gt; conversation away from questions of uploading, because I think we are 
</em><br>
<em>&gt; casually using the term &quot;uploading&quot; as it were technically feasible, and 
</em><br>
<em>&gt; the state of the art is so far away from that at the moment that we are 
</em><br>
<em>&gt; in danger of wasting our breath.
</em><br>
<p>That has always been the reason why I myself have attached little 
<br>
likelihood to uploading, and have focused my attention elsewhere.  It's 
<br>
not just that it's presently infeasible, but that the technology and 
<br>
science for (not necessarily Friendly) AGI appears to be very nearly a 
<br>
strict subset of the technology and science for uploading.  No matter 
<br>
when uploading would have come along, (not necessarily Friendly) AGI 
<br>
will come first and terminate the problem, one way or another.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12395.html">Chris Capel: "Re: cyborgs &amp; ghosts"</a>
<li><strong>Previous message:</strong> <a href="12393.html">Richard Loosemore: "Re: Loosemore's Proposal"</a>
<li><strong>In reply to:</strong> <a href="12387.html">Richard Loosemore: "Re: AGI motivations (Sidetrack on Uploading)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12397.html">Martin Striz: "Re: AGI motivations (Sidetrack on Uploading)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12394">[ date ]</a>
<a href="index.html#12394">[ thread ]</a>
<a href="subject.html#12394">[ subject ]</a>
<a href="author.html#12394">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:23:18 MST
</em></small></p>
</body>
</html>
