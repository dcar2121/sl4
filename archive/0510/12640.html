<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: physics of uploading minds</title>
<meta name="Author" content="Michael Wilson (mwdestinystar@yahoo.co.uk)">
<meta name="Subject" content="Re: physics of uploading minds">
<meta name="Date" content="2005-10-28">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: physics of uploading minds</h1>
<!-- received="Fri Oct 28 02:37:33 2005" -->
<!-- isoreceived="20051028083733" -->
<!-- sent="Fri, 28 Oct 2005 09:37:30 +0100 (BST)" -->
<!-- isosent="20051028083730" -->
<!-- name="Michael Wilson" -->
<!-- email="mwdestinystar@yahoo.co.uk" -->
<!-- subject="Re: physics of uploading minds" -->
<!-- id="20051028083730.15774.qmail@web26702.mail.ukl.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="20051028074951.78761.qmail@web61311.mail.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Wilson (<a href="mailto:mwdestinystar@yahoo.co.uk?Subject=Re:%20physics%20of%20uploading%20minds"><em>mwdestinystar@yahoo.co.uk</em></a>)<br>
<strong>Date:</strong> Fri Oct 28 2005 - 02:37:30 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12641.html">Tomaz Kristan: "Re: physics of uploading minds"</a>
<li><strong>Previous message:</strong> <a href="12639.html">Phillip Huggan: "RE: physics of uploading minds"</a>
<li><strong>In reply to:</strong> <a href="12638.html">Phillip Huggan: "Re: physics of uploading minds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12635.html">Pilot Pirx: "Re: physics of uploading minds"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12640">[ date ]</a>
<a href="index.html#12640">[ thread ]</a>
<a href="subject.html#12640">[ subject ]</a>
<a href="author.html#12640">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Phillip Huggan &lt;<a href="mailto:cdnprodigy@yahoo.com?Subject=Re:%20physics%20of%20uploading%20minds">cdnprodigy@yahoo.com</a>&gt; wrote:
<br>
<em>&gt; I don't *think* the universe functions as anything but an ordered series of
</em><br>
<em>&gt; snapshots, but I know reality at my consciousness's level of resolution is
</em><br>
<em>&gt; continuous somehow. Descartes's reasoning works here in a modified form: I
</em><br>
<em>&gt; think therefore I am, as the thought requires a non-zero amount of time to
</em><br>
<em>&gt; exist in my mind.
</em><br>
<p>Working out what the real minimal physical implications of the existence
<br>
of subjective experience are is a tricky prospect. My own best guess would
<br>
be that all you can say is that some set of elements exists somewhere (at
<br>
least once) as a causal chain that implements the functional characteristics
<br>
of the cognition you're reflecting on. Though the issue is so complicated
<br>
I'm not sure that any one-sentence summary can contain much useful
<br>
description.
<br>
<p><em>&gt; I see no difference between flash-uploading and a Moravec transfer; both
</em><br>
<em>&gt; are impossible unless the ability to harness both types of Singularities
</em><br>
<em>&gt; are assumed.
</em><br>
<p>The accuracy of flash-uploading is bounded by the known laws of physics.
<br>
Moravec transfers aren't subject to the question of accuracy in the same
<br>
way; we can't even compare the similarity of the upload's future history
<br>
with the future history the original brain would've had in abstract,
<br>
because quantum-level uncertainty makes at least the latter very fuzzy. 
<br>
I don't see why you're writing Moravec transfers off as impossible though;
<br>
it would take a lot of knowledge and technology, which /probably/ won't
<br>
be developed without triggering a Singularity anyway, but I can't see a
<br>
fundamental reason why you can't do this before a Singularity occurs.
<br>
<p><em>&gt; A Penrose refutation would involve stating that synapses are affected by
</em><br>
<em>&gt; quantum forces, so *chaotic* effects would affect the likelyhood of whether
</em><br>
<em>&gt; a path of branching synapses turns into a thought. Accurately computer
</em><br>
<em>&gt; modelling every single molecule in the human brain would be very difficult
</em><br>
<em>&gt; even with mature MNT.
</em><br>
<p>Generally we assume that the brain's behaviour can be strongly predicted
<br>
by a theory operating at a higher level than individual molecules. It's
<br>
true that we don't have this theory yet, but it looks highly unlikely
<br>
that processing in the brain is /that/ parallel and mass-efficient. For
<br>
Moravec transfers we can replace each neuron with a custom build
<br>
nanomachine to do the same job, we don't need to use general computation
<br>
and conventional programming (though that does make some other things
<br>
you might want to do next easier).
<br>
<p><em>&gt; Multiplied across all neurons and synapses, personal identity might be
</em><br>
<em>&gt; lost within a second of turning off the biological neurons and turning
</em><br>
<em>&gt; on the robo-neurons. Alternatively, personal identity would be lost
</em><br>
<em>&gt; incrementally as each facet of our mind's biological counterpart was
</em><br>
<em>&gt; replaced incrementally with robo-neuron derived mental processes.
</em><br>
<p>What is this 'personal identity' of which you speak? In physical terms?
<br>
Certainly the upload isn't going to loose any objectively measureable
<br>
cognitive content, including their self-model, as if they did it wouldn't
<br>
be a successful upload in the first place.
<br>
<p><em>&gt; Assume two perfectly identical sheets of paper. If I write on one, is
</em><br>
<em>&gt; the other immediately stained as well?  No.  Why not?  Each sheet's
</em><br>
<em>&gt; gravity independently warps space-time.  Each sheet exerts, consists of,
</em><br>
<em>&gt; and is subject to a whole host of other forces and fields. This is the 
</em><br>
<em>&gt; reasoning that is lacking in a the simple thought experiment contrasting
</em><br>
<em>&gt; robot neurons and bio-neurons.
</em><br>
<p>I have no idea why this is meant to be relevant. The future state of the
<br>
paper doesn't depend on the existing state of the paper; it depends on
<br>
the existing state plus external influences. If the external influences
<br>
differ, the states will diverge, but this is true for /any/ system
<br>
including humans and uploads. The (narrow) question we are interested in
<br>
is 'will the upload and the human stay converged over time assuming no or
<br>
identical external influences (i.e. sensory input)'. The more general
<br>
question is 'why do we care if they diverge anyway, as long as they meet
<br>
a personally acceptable standard of self-similarity?'.
<br>
<p><em>&gt; Incrementally switching the neurons only muddies the waters. If you take
</em><br>
<em>&gt; away a few of my neurons by hitting me in the head with a hockey puck, it
</em><br>
<em>&gt; is very unlikely to affect my identity or future actions. But keep taking
</em><br>
<em>&gt; away more and more neurons...
</em><br>
<p>Any kind of interaction with the world may affect your identity or future
<br>
actions, which are indeterminate anyway. Following this line of reasoning
<br>
to its logical conclusion would result in a total denial of personal
<br>
change, which sounds pretty silly to me.
<br>
<p><em>&gt; As I said, I believe the process referred to as uploading can create
</em><br>
<em>&gt; conscious entities. Just don't look here for immortality. The difference
</em><br>
<em>&gt; is critical in how an AGI treats us. An AGI that kills us off and replaces
</em><br>
<em>&gt; us with conscious agents exhibiting a slightly improved standard-of-living
</em><br>
<em>&gt; is UFAI. Whereas an AGI that keeps us around and instead uses rocks to
</em><br>
<em>&gt; make slightly improved conscious agents, is a lot better than twice as good
</em><br>
<em>&gt; as the first AGI in my books.
</em><br>
<p>I agree that uploading people involuntarily looks like a bad idea from
<br>
here, but I wouldn't go so far as to say that it's definitely a bad idea.
<br>
Perhaps all of these doubts can easily be shown to be silly superstition
<br>
somehow. I think it's possible that entities vastly more intelligent than
<br>
us might validly conclude that we should be immediately uploaded for our
<br>
own good, and if the reasoning was truly well-founded I wouldn't object.
<br>
<p>&nbsp;* Michael Wilson
<br>
<p><p><p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
___________________________________________________________ 
<br>
To help you stay safe and secure online, we've developed the all new Yahoo! Security Centre. <a href="http://uk.security.yahoo.com">http://uk.security.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12641.html">Tomaz Kristan: "Re: physics of uploading minds"</a>
<li><strong>Previous message:</strong> <a href="12639.html">Phillip Huggan: "RE: physics of uploading minds"</a>
<li><strong>In reply to:</strong> <a href="12638.html">Phillip Huggan: "Re: physics of uploading minds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12635.html">Pilot Pirx: "Re: physics of uploading minds"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12640">[ date ]</a>
<a href="index.html#12640">[ thread ]</a>
<a href="subject.html#12640">[ subject ]</a>
<a href="author.html#12640">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
