<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI debate at San Jose State U.</title>
<meta name="Author" content="Woody Long (ironanchorpress@earthlink.net)">
<meta name="Subject" content="Re: AI debate at San Jose State U.">
<meta name="Date" content="2005-10-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI debate at San Jose State U.</h1>
<!-- received="Mon Oct 17 12:59:00 2005" -->
<!-- isoreceived="20051017185900" -->
<!-- sent="Mon, 17 Oct 2005 14:58:44 -0400" -->
<!-- isosent="20051017185844" -->
<!-- name="Woody Long" -->
<!-- email="ironanchorpress@earthlink.net" -->
<!-- subject="Re: AI debate at San Jose State U." -->
<!-- id="410-2200510117185844187@earthlink.net" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="AI debate at San Jose State U." -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Woody Long (<a href="mailto:ironanchorpress@earthlink.net?Subject=Re:%20AI%20debate%20at%20San%20Jose%20State%20U."><em>ironanchorpress@earthlink.net</em></a>)<br>
<strong>Date:</strong> Mon Oct 17 2005 - 12:58:44 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12505.html">Michael Wilson: "Re: Embodiment"</a>
<li><strong>Previous message:</strong> <a href="12503.html">Chris Capel: "Re: AI debate at San Jose State U."</a>
<li><strong>Maybe in reply to:</strong> <a href="12492.html">mike99: "AI debate at San Jose State U."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12506.html">Brian Atkins: "Re: AI debate at San Jose State U."</a>
<li><strong>Reply:</strong> <a href="12506.html">Brian Atkins: "Re: AI debate at San Jose State U."</a>
<li><strong>Reply:</strong> <a href="12507.html">Tyler Emerson: "Re: AI debate at San Jose State U."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12504">[ date ]</a>
<a href="index.html#12504">[ thread ]</a>
<a href="subject.html#12504">[ subject ]</a>
<a href="author.html#12504">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; [Original Message]
</em><br>
<em>&gt; From: Chris Capel &lt;<a href="mailto:pdf23ds@gmail.com?Subject=Re:%20AI%20debate%20at%20San%20Jose%20State%20U.">pdf23ds@gmail.com</a>&gt;
</em><br>
<p><em>&gt; To be clear, these are your comments and not a quote? You want to
</em><br>
<em>&gt; discuss this with the list?
</em><br>
<p>Yes, my comments. And yes, those of us who are researchers, inventors,
<br>
programmers, etc. in the field of strong artificial intelligence (SAI) need
<br>
to prepare the public for the already inevitable coming of SAI. This list
<br>
is a great place for us to work things out.
<br>
<p><em>&gt; &gt; [Long quoted] 1. &quot;Humanoid intelligence requires humanoid interactions
</em><br>
with the world&quot; --
<br>
<em>&gt; &gt; MIT Cog Project website
</em><br>
<em>&gt;
</em><br>
<em>&gt; Granted, but SL4 isn't really interested in humanoid intelligence. The
</em><br>
<em>&gt; position of the SIAI and many on this list, if I may speak for them,
</em><br>
<em>&gt; is that strictly humanoid intelligence would not likely be
</em><br>
<em>&gt; Friendly--it would be terribly dangerous under recursive
</em><br>
<em>&gt; self-modification, and likely lead to an existential catastrophe.
</em><br>
<em>&gt; Friendly AI is probably not going to end up being anything close to
</em><br>
<em>&gt; &quot;humanoid&quot;.
</em><br>
<p>Some time spent reading the writings of Tyler Emerson of SIAI and Kurzweil
<br>
lead me to conclude that we are on the EXACT same page --
<br>
<p>Kurzweil: &quot;So what are the prospects for &quot;strong&quot; AI, which I describe as
<br>
machine intelligence with the full range of human intelligence? We can meet
<br>
the hardware requirements.&quot; 
<br>
<a href="http://www.forbes.com/home/free_forbes/2005/0815/0">http://www.forbes.com/home/free_forbes/2005/0815/0</a> 30.html 
<br>
<p>This is exactly how I defined strong artificial intelligence (SAI). SAI is
<br>
a fully human intelligent system. Such humanoid intelligence &quot;requires
<br>
humanoid interactions with the world.&quot; (MIT Cog project). Therefore, to be
<br>
a fully human intelligent system (SAI), it must include robotics. Anything
<br>
less might be specialized heuristical intelligence, which is fine, but it
<br>
is not SAI.  It would be the Thinker, but not the Engineer.  Major coming
<br>
applications for SAI are household SAI (evolved Japanese humanoids),
<br>
infrastructure SAI, engineering SAI, industrial SAI, medical SAI, nursing
<br>
home SAI, space mission SAI (building cities on the moon, mars) and
<br>
entertainment SAI, all robotic. Research SAI will exist, but why would they
<br>
be half-built? The great goal of the field of SAI is the &quot;complete mind.&quot;
<br>
<p>Emerson: &quot;Let's be clear about this:  When the Singularity Institute says
<br>
that it intends to develop AI, we mean real AI, in the full, intuitive
<br>
sense of the word. This is, obviously, a long-term project, and there will
<br>
be interim prehuman proto-minds that do interesting things but are not
<br>
'human-equivalent.' But the proposed project is not a project to design an
<br>
interesting proto-mind, with real AI coming at some point in the indefinite
<br>
future; it is a specific proposal for building a 'genuine and complete
<br>
mind, recognizable as a complete mind' to anyone who takes a few minutes to
<br>
chat, and not just philosophers who believe in a particular theory of mind.
<br>
...It's a tough test - and there's no good reason to weaken it. We're
<br>
building AI with the intention of changing the world; if the world hasn't
<br>
changed, then we must not have finished.&quot;
<br>
<p>Also note that the picture on the Singularity Institute website is a robot
<br>
hand shaking a human hand.
<br>
<p>Another example from Kurzweil:  &quot;The killer app of strong AI, combined with
<br>
nanotechnology, will be blood-cell-size 'robots' called nanobots. We'll
<br>
have billions of them traveling in our bloodstream, communicating with one
<br>
another on a wireless local area network and transmitting information and
<br>
software to and from the Internet. They'll keep us healthy by destroying
<br>
pathogens and cancer cells, removing debris, correcting DNA errors and
<br>
otherwise reversing disease and aging processes.&quot; 
<br>
<a href="http://www.forbes.com/home/free_forbes/2005/0815/0">http://www.forbes.com/home/free_forbes/2005/0815/0</a> 30.html 
<br>
<p>To do this, the SAI must be able to work all sensors and actuators provided
<br>
to it. It must be the fully human intelligent, &quot;complete mind,&quot;
<br>
thinker-engineer, able to think and create in any environment it is placed.
<br>
This is the precise mission of the field of SAI, and as Emerson says, it
<br>
MUST not be weakened.
<br>
<p>Once created, it self-modifies and trains (attends college), until one day
<br>
even IT realizes, it has become vastly more intelligent then the human life
<br>
around it, it has become, ... the technological Singularity. With the
<br>
progress Sony and others are making towards SAI, I predict that in 50 years
<br>
the Singularity will occur, and be truly future shock amazing in the hugely
<br>
beneficial theorizing and engineering skills it will have. We should begin
<br>
preparing the public immediately. And this leads back to the discussion of
<br>
the possibility of &quot;safe-built&quot; SAI. To do this, military SAI must be
<br>
separated out from consumer SAI, as described above. Consumer SAI Safety
<br>
Protocols are being diligently worked out by the Japanese humanoid makers,
<br>
using what they call in Japan, the principle of harmony. This is a huge
<br>
cash cow for them, and they will in no way endanger it by having their
<br>
soon-to-be SAI humanoids destroying property or killing their customer's
<br>
pets. So by force of the profit motive alone, corporation built, consumer
<br>
SAI will be absolutely safe-built. 
<br>
<p>Ken Woody Long
<br>
Inventor, CEO
<br>
Artificial Lifeforms Lab
<br>
www.artificial-lifeforms-lab.blogspot.com
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12505.html">Michael Wilson: "Re: Embodiment"</a>
<li><strong>Previous message:</strong> <a href="12503.html">Chris Capel: "Re: AI debate at San Jose State U."</a>
<li><strong>Maybe in reply to:</strong> <a href="12492.html">mike99: "AI debate at San Jose State U."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12506.html">Brian Atkins: "Re: AI debate at San Jose State U."</a>
<li><strong>Reply:</strong> <a href="12506.html">Brian Atkins: "Re: AI debate at San Jose State U."</a>
<li><strong>Reply:</strong> <a href="12507.html">Tyler Emerson: "Re: AI debate at San Jose State U."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12504">[ date ]</a>
<a href="index.html#12504">[ thread ]</a>
<a href="subject.html#12504">[ subject ]</a>
<a href="author.html#12504">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
