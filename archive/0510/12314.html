<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI debate at San Jose State U.</title>
<meta name="Author" content="Tyler Emerson (emerson@intelligence.org)">
<meta name="Subject" content="Re: AI debate at San Jose State U.">
<meta name="Date" content="2005-10-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI debate at San Jose State U.</h1>
<!-- received="Mon Oct 17 13:34:08 2005" -->
<!-- isoreceived="20051017193408" -->
<!-- sent="Mon, 17 Oct 2005 12:34:18 -0700" -->
<!-- isosent="20051017193418" -->
<!-- name="Tyler Emerson" -->
<!-- email="emerson@intelligence.org" -->
<!-- subject="Re: AI debate at San Jose State U." -->
<!-- id="200510171934.j9HJY6e31437@tick.javien.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="410-2200510117185844187@earthlink.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Tyler Emerson (<a href="mailto:emerson@intelligence.org?Subject=Re:%20AI%20debate%20at%20San%20Jose%20State%20U."><em>emerson@intelligence.org</em></a>)<br>
<strong>Date:</strong> Mon Oct 17 2005 - 13:34:18 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12315.html">Ben Goertzel: "RE: AI debate at San Jose State U."</a>
<li><strong>Previous message:</strong> <a href="12313.html">Brian Atkins: "Re: AI debate at San Jose State U."</a>
<li><strong>In reply to:</strong> <a href="12311.html">Woody Long: "Re: AI debate at San Jose State U."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12360.html">Woody Long: "Re: AI debate at San Jose State U."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12314">[ date ]</a>
<a href="index.html#12314">[ thread ]</a>
<a href="subject.html#12314">[ subject ]</a>
<a href="author.html#12314">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; Emerson: &quot;Let's be clear about this: [...]&quot;
</em><br>
<p>Unless otherwise noted, our publications are copyrighted under The
<br>
Singularity Institute, not an individual; but for the record, most of the
<br>
present published material was written originally by Yudkowsky.
<br>
<p>~~
<br>
Tyler Emerson | Executive Director | The Singularity Institute
<br>
Box 50182 | Palo Alto, CA 94303 | T-F: 866.667.2524
<br>
<a href="mailto:emerson@intelligence.org?Subject=Re:%20AI%20debate%20at%20San%20Jose%20State%20U.">emerson@intelligence.org</a> | <a href="http://www.singinst.org">http://www.singinst.org</a>
<br>
<p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sl4.org?Subject=Re:%20AI%20debate%20at%20San%20Jose%20State%20U.">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=Re:%20AI%20debate%20at%20San%20Jose%20State%20U.">owner-sl4@sl4.org</a>] On Behalf Of Woody Long
</em><br>
<em>&gt; Sent: Monday, October 17, 2005 11:59 AM
</em><br>
<em>&gt; To: <a href="mailto:sl4@sl4.org?Subject=Re:%20AI%20debate%20at%20San%20Jose%20State%20U.">sl4@sl4.org</a>; <a href="mailto:sl4@sl4.org?Subject=Re:%20AI%20debate%20at%20San%20Jose%20State%20U.">sl4@sl4.org</a>
</em><br>
<em>&gt; Subject: [inbox] Re: AI debate at San Jose State U.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; [Original Message]
</em><br>
<em>&gt; &gt; From: Chris Capel &lt;<a href="mailto:pdf23ds@gmail.com?Subject=Re:%20AI%20debate%20at%20San%20Jose%20State%20U.">pdf23ds@gmail.com</a>&gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; To be clear, these are your comments and not a quote? You want to
</em><br>
<em>&gt; &gt; discuss this with the list?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Yes, my comments. And yes, those of us who are researchers, inventors,
</em><br>
<em>&gt; programmers, etc. in the field of strong artificial intelligence (SAI)
</em><br>
<em>&gt; need
</em><br>
<em>&gt; to prepare the public for the already inevitable coming of SAI. This list
</em><br>
<em>&gt; is a great place for us to work things out.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; &gt; [Long quoted] 1. &quot;Humanoid intelligence requires humanoid interactions
</em><br>
<em>&gt; with the world&quot; --
</em><br>
<em>&gt; &gt; &gt; MIT Cog Project website
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Granted, but SL4 isn't really interested in humanoid intelligence. The
</em><br>
<em>&gt; &gt; position of the SIAI and many on this list, if I may speak for them,
</em><br>
<em>&gt; &gt; is that strictly humanoid intelligence would not likely be
</em><br>
<em>&gt; &gt; Friendly--it would be terribly dangerous under recursive
</em><br>
<em>&gt; &gt; self-modification, and likely lead to an existential catastrophe.
</em><br>
<em>&gt; &gt; Friendly AI is probably not going to end up being anything close to
</em><br>
<em>&gt; &gt; &quot;humanoid&quot;.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Some time spent reading the writings of Tyler Emerson of SIAI and Kurzweil
</em><br>
<em>&gt; lead me to conclude that we are on the EXACT same page --
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Kurzweil: &quot;So what are the prospects for &quot;strong&quot; AI, which I describe as
</em><br>
<em>&gt; machine intelligence with the full range of human intelligence? We can
</em><br>
<em>&gt; meet
</em><br>
<em>&gt; the hardware requirements.&quot;
</em><br>
<em>&gt; <a href="http://www.forbes.com/home/free_forbes/2005/0815/0">http://www.forbes.com/home/free_forbes/2005/0815/0</a> 30.html
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This is exactly how I defined strong artificial intelligence (SAI). SAI is
</em><br>
<em>&gt; a fully human intelligent system. Such humanoid intelligence &quot;requires
</em><br>
<em>&gt; humanoid interactions with the world.&quot; (MIT Cog project). Therefore, to be
</em><br>
<em>&gt; a fully human intelligent system (SAI), it must include robotics. Anything
</em><br>
<em>&gt; less might be specialized heuristical intelligence, which is fine, but it
</em><br>
<em>&gt; is not SAI.  It would be the Thinker, but not the Engineer.  Major coming
</em><br>
<em>&gt; applications for SAI are household SAI (evolved Japanese humanoids),
</em><br>
<em>&gt; infrastructure SAI, engineering SAI, industrial SAI, medical SAI, nursing
</em><br>
<em>&gt; home SAI, space mission SAI (building cities on the moon, mars) and
</em><br>
<em>&gt; entertainment SAI, all robotic. Research SAI will exist, but why would
</em><br>
<em>&gt; they
</em><br>
<em>&gt; be half-built? The great goal of the field of SAI is the &quot;complete mind.&quot;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Emerson: &quot;Let's be clear about this:  When the Singularity Institute says
</em><br>
<em>&gt; that it intends to develop AI, we mean real AI, in the full, intuitive
</em><br>
<em>&gt; sense of the word. This is, obviously, a long-term project, and there will
</em><br>
<em>&gt; be interim prehuman proto-minds that do interesting things but are not
</em><br>
<em>&gt; 'human-equivalent.' But the proposed project is not a project to design an
</em><br>
<em>&gt; interesting proto-mind, with real AI coming at some point in the
</em><br>
<em>&gt; indefinite
</em><br>
<em>&gt; future; it is a specific proposal for building a 'genuine and complete
</em><br>
<em>&gt; mind, recognizable as a complete mind' to anyone who takes a few minutes
</em><br>
<em>&gt; to
</em><br>
<em>&gt; chat, and not just philosophers who believe in a particular theory of
</em><br>
<em>&gt; mind.
</em><br>
<em>&gt; ...It's a tough test - and there's no good reason to weaken it. We're
</em><br>
<em>&gt; building AI with the intention of changing the world; if the world hasn't
</em><br>
<em>&gt; changed, then we must not have finished.&quot;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Also note that the picture on the Singularity Institute website is a robot
</em><br>
<em>&gt; hand shaking a human hand.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Another example from Kurzweil:  &quot;The killer app of strong AI, combined
</em><br>
<em>&gt; with
</em><br>
<em>&gt; nanotechnology, will be blood-cell-size 'robots' called nanobots. We'll
</em><br>
<em>&gt; have billions of them traveling in our bloodstream, communicating with one
</em><br>
<em>&gt; another on a wireless local area network and transmitting information and
</em><br>
<em>&gt; software to and from the Internet. They'll keep us healthy by destroying
</em><br>
<em>&gt; pathogens and cancer cells, removing debris, correcting DNA errors and
</em><br>
<em>&gt; otherwise reversing disease and aging processes.&quot;
</em><br>
<em>&gt; <a href="http://www.forbes.com/home/free_forbes/2005/0815/0">http://www.forbes.com/home/free_forbes/2005/0815/0</a> 30.html
</em><br>
<em>&gt; 
</em><br>
<em>&gt; To do this, the SAI must be able to work all sensors and actuators
</em><br>
<em>&gt; provided
</em><br>
<em>&gt; to it. It must be the fully human intelligent, &quot;complete mind,&quot;
</em><br>
<em>&gt; thinker-engineer, able to think and create in any environment it is
</em><br>
<em>&gt; placed.
</em><br>
<em>&gt; This is the precise mission of the field of SAI, and as Emerson says, it
</em><br>
<em>&gt; MUST not be weakened.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Once created, it self-modifies and trains (attends college), until one day
</em><br>
<em>&gt; even IT realizes, it has become vastly more intelligent then the human
</em><br>
<em>&gt; life
</em><br>
<em>&gt; around it, it has become, ... the technological Singularity. With the
</em><br>
<em>&gt; progress Sony and others are making towards SAI, I predict that in 50
</em><br>
<em>&gt; years
</em><br>
<em>&gt; the Singularity will occur, and be truly future shock amazing in the
</em><br>
<em>&gt; hugely
</em><br>
<em>&gt; beneficial theorizing and engineering skills it will have. We should begin
</em><br>
<em>&gt; preparing the public immediately. And this leads back to the discussion of
</em><br>
<em>&gt; the possibility of &quot;safe-built&quot; SAI. To do this, military SAI must be
</em><br>
<em>&gt; separated out from consumer SAI, as described above. Consumer SAI Safety
</em><br>
<em>&gt; Protocols are being diligently worked out by the Japanese humanoid makers,
</em><br>
<em>&gt; using what they call in Japan, the principle of harmony. This is a huge
</em><br>
<em>&gt; cash cow for them, and they will in no way endanger it by having their
</em><br>
<em>&gt; soon-to-be SAI humanoids destroying property or killing their customer's
</em><br>
<em>&gt; pets. So by force of the profit motive alone, corporation built, consumer
</em><br>
<em>&gt; SAI will be absolutely safe-built.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Ken Woody Long
</em><br>
<em>&gt; Inventor, CEO
</em><br>
<em>&gt; Artificial Lifeforms Lab
</em><br>
<em>&gt; www.artificial-lifeforms-lab.blogspot.com
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12315.html">Ben Goertzel: "RE: AI debate at San Jose State U."</a>
<li><strong>Previous message:</strong> <a href="12313.html">Brian Atkins: "Re: AI debate at San Jose State U."</a>
<li><strong>In reply to:</strong> <a href="12311.html">Woody Long: "Re: AI debate at San Jose State U."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12360.html">Woody Long: "Re: AI debate at San Jose State U."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12314">[ date ]</a>
<a href="index.html#12314">[ thread ]</a>
<a href="subject.html#12314">[ subject ]</a>
<a href="author.html#12314">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:23:04 MST
</em></small></p>
</body>
</html>
