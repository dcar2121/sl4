<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Loosemore's Proposal</title>
<meta name="Author" content="Michael Wilson (mwdestinystar@yahoo.co.uk)">
<meta name="Subject" content="Re: Loosemore's Proposal">
<meta name="Date" content="2005-10-25">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Loosemore's Proposal</h1>
<!-- received="Tue Oct 25 13:59:09 2005" -->
<!-- isoreceived="20051025195909" -->
<!-- sent="Tue, 25 Oct 2005 20:59:02 +0100 (BST)" -->
<!-- isosent="20051025195902" -->
<!-- name="Michael Wilson" -->
<!-- email="mwdestinystar@yahoo.co.uk" -->
<!-- subject="Re: Loosemore's Proposal" -->
<!-- id="20051025195902.75095.qmail@web26705.mail.ukl.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="435E44C6.50804@lightlink.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Wilson (<a href="mailto:mwdestinystar@yahoo.co.uk?Subject=Re:%20Loosemore's%20Proposal"><em>mwdestinystar@yahoo.co.uk</em></a>)<br>
<strong>Date:</strong> Tue Oct 25 2005 - 13:59:02 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12609.html">Keith Henson: "Re: Loosemore's Proposal"</a>
<li><strong>Previous message:</strong> <a href="12607.html">Michael Vassar: "RE: Loosemore's Proposal [Was: Re: Agi motivations]"</a>
<li><strong>In reply to:</strong> <a href="12601.html">Richard Loosemore: "Re: Loosemore's Proposal"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12614.html">Ben Goertzel: "RE: Loosemore's Proposal"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12608">[ date ]</a>
<a href="index.html#12608">[ thread ]</a>
<a href="subject.html#12608">[ subject ]</a>
<a href="author.html#12608">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Russell Wallace wrote:
<br>
<em>&gt; It's the other way around; nobody will understand the reasons
</em><br>
<em>&gt; _until_ you give the details.
</em><br>
<p>Generally, yes. Loosemore seems to have identified a set of moderately
<br>
obvious things about intelligence which he falsely claims can only be
<br>
compreheneded in the context of complex systems theory. He appears to
<br>
be mistaking a different understanding of how these things work for a
<br>
lack of comprehension of them. Disregarding the fact that Loosemore
<br>
seems to refuse to acknowledge the existence of alternate models of
<br>
these features, he isn't going to convince anyone of the validity of
<br>
his own model until he details it sufficiently to be able to show
<br>
how it can reliably achieve interesting competencies.
<br>
<p>Richard Loosemore wrote:
<br>
<em>&gt; And this is not entirely my fault, because I have looked back over
</em><br>
<em>&gt; my writing and I see that the information was clearly stated in the
</em><br>
<em>&gt; posts.
</em><br>
<p>Explaining AI designs is generally very hard. However your explanations
<br>
have been particularly content-free, largely due to making isolated
<br>
unsupported claims as if they were axioms, and this hasn't been helped
<br>
by the fact that you don't seem to have tried to adapt your dismissals
<br>
and defences to take acount of other people's actual positions. It is
<br>
very easy to loose track of the inferential distance between author and
<br>
reader in the heat of the argument, but the solution is generally
<br>
providing more detail to fill in the gaps, not moaning that no one has
<br>
been able to replicate your grand understanding given what you think is
<br>
an adequate set of generic, isolated statments.
<br>
<p><em>&gt; Here is the hypothetical.  Imagine that cognitive systems consist of a 
</em><br>
<em>&gt; large number of &quot;elements&quot; which are the atoms of knowledge 
</em><br>
<em>&gt; representation (an element represents a thing in the world, but that 
</em><br>
<em>&gt; &quot;thing&quot; can be concrete or abstract, a noun-like thing or an action or 
</em><br>
<em>&gt; process .... anything whatsoever). Elements are simple computational 
</em><br>
<em>&gt; structures, we will suppose.
</em><br>
<p>Sounds like the 'active symbols' paradigm to me. At a guess, I'd probably
<br>
take a more complicated, context-dependendent view about splitting cognitive
<br>
functionality between code and data, or at a higher level of abstraction
<br>
content and structure. In my experience 'active symbol' designs tend to
<br>
have counterproductively strict restrictions on the scope of statically
<br>
defined computational structures (i.e. mechanisms implemented in code),
<br>
though you may be an exception.
<br>
<p><em>&gt; The most important aspect of an element's life is its history...
</em><br>
<em>&gt; Notice one important thing:  the specific form of the final dog-element 
</em><br>
<em>&gt; is a result of (a) a basic design for the general form of all elements, 
</em><br>
<em>&gt; and (b) the learning mechanisms that caused the dog-element to grow into 
</em><br>
<em>&gt; the adult form, as a result of experience.
</em><br>
<p>You have a point, albeit a very vague one, regarding something that the
<br>
majority of academic approaches to AI (e.g. classic symbolic and
<br>
connectionist AI) do not handle well or at all. But you haven't really
<br>
done anything more than recognise the problem. All of the minimally
<br>
credible AGI designs I've seen already pose potential solutions to the
<br>
problem of progressive generation and refinement of representations and
<br>
their supporting category structures. I may not agree with most of them,
<br>
but they've gone further than just asking the question, which is another
<br>
thing all serious AGI researchers are already very familiar with.
<br>
<p><em>&gt; But now along comes a complex systems theorist to spoil the party.  The 
</em><br>
<em>&gt; CST says &quot;This looks good, but in a real system those adult elements 
</em><br>
<em>&gt; would have developed as a result of the learning mechanisms interacting 
</em><br>
<em>&gt; with the real world, right?  And the system would recognise real-world 
</em><br>
<em>&gt; patterns as a result of the recognition mechanisms (which also got 
</em><br>
<em>&gt; developed as a result of experience) operating on raw sensory input,
</em><br>
<em>&gt; right?&quot;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The cognitive scientist agrees, and says that the learning mechanisms 
</em><br>
<em>&gt; are a tough issue, and will be dealt with later.
</em><br>
<p>You keep going on about this mistake like a stuck record. Everyone here
<br>
recognises that it was a mistake. No one intends to repeat it. Your ideas
<br>
on how to avoid it are one model out of many, and right now that model
<br>
hasn't had much content described.
<br>
<p><em>&gt; I do understand that while the content changes during development, the 
</em><br>
<em>&gt; structure of the elements does not.... but having said that, doesn't the 
</em><br>
<em>&gt; element structure (as well as the structure of the &quot;thinking&quot; and 
</em><br>
<em>&gt; &quot;reasoning&quot; mechanisms) have to be chosen to fit the learning 
</em><br>
<em>&gt; mechanisms, not the other way around?&quot;
</em><br>
<p>This sounds like a dangerous (i.e. likely to lead to incorrect inferences)
<br>
oversimplification, though to be fair those tend to be ten a penny in any
<br>
concise attempt to discuss AGI. This point isn't quite as widely accepted
<br>
as the one above, but I suspect most people here are aleadyt aware of and
<br>
in basic agreement with it.
<br>
&nbsp;
<br>
<em>&gt; Why? Because all our experience with complex systems indicates that if 
</em><br>
<em>&gt; you start by looking at the final adult form of a system of interacting 
</em><br>
<em>&gt; units like that, and then try to design a set of local mechanisms 
</em><br>
<em>&gt; (equivalent to your learning mechanisms in this case) which could 
</em><br>
<em>&gt; generate that particular adult content, you would get absolutely 
</em><br>
<em>&gt; nowhere.
</em><br>
<p>You've said this about ten times now. Stop repeating it based on the
<br>
idea that people don't understand your point; actually it's quite
<br>
familiar and old hat. The criticisms are of your answers to the
<br>
question, not the existence of the question itself (though there are
<br>
other, possibly better, ways to put it).
<br>
<p><em>&gt; So in other words, by the time you have finished the learning 
</em><br>
<em>&gt; mechanisms you will have completely thrown away your initial presupposed 
</em><br>
<em>&gt; design for the structure and content of the adult elements.
</em><br>
<p>This is an invalid inference. It assumes that you can't design learning,
<br>
inference and representational mechanisms /together/, such that they
<br>
can be shown to work well together at all stages of design. I think this
<br>
is perfectly possible, just hard, and indeed that's what I've been
<br>
trying to do (with due respect for the dangers of under and over
<br>
specification).
<br>
<p><em>&gt; The development environment I suggested would be a way to do things in 
</em><br>
<em>&gt; that (to some people) &quot;backwards&quot; way.
</em><br>
<p>I wouldn't classify it as backwards, I'd classify it as over-focusing on
<br>
a different facet of the problem than the people you criticise. But to
<br>
solve the problem, you'd need to consider the whole problem, and you
<br>
can't do that without building a model of the whole problem. Trying to
<br>
buld an AGI by fiddling with local dynamics is comparable to Michelangelo
<br>
trying to paint the roof of the Sistine Chapel while looking through a
<br>
cardboard tube held six inches away from the plaster.
<br>
<p><em>&gt; And it would not, as some people have insultingly claimed, be just a
</em><br>
<em>&gt; matter of doing some kind of random search through the space of all
</em><br>
<em>&gt; possible cognitive systems ... nothing so crude.
</em><br>
<p>Trial-and-error is not the same thing as exhaustive search or random
<br>
walk. However the actual improvement in efficiency of the former compared
<br>
to the latter is strongly dependent on the available understanding of the
<br>
domain. The cognitive design space is so huge and so full of failure that
<br>
the modest improvements aren't going to significently raise the chance of
<br>
building an AGI that way.
<br>
<p><em>&gt; All power to you if you do:  you will never get what I am trying to
</em><br>
<em>&gt; say here, and there would be no point me talking about the structure
</em><br>
<em>&gt; of the development environment.
</em><br>
<p>If you honestly believe that anyone who disagrees with you must be
<br>
incapable of comprehending your cognitive model, you are engaging in
<br>
preaching rather than discussion, and what you are doing will resemeble
<br>
religion more than science.
<br>
&nbsp;
<br>
&nbsp;* Michael Wilson
<br>
<p><p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
___________________________________________________________ 
<br>
To help you stay safe and secure online, we've developed the all new Yahoo! Security Centre. <a href="http://uk.security.yahoo.com">http://uk.security.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12609.html">Keith Henson: "Re: Loosemore's Proposal"</a>
<li><strong>Previous message:</strong> <a href="12607.html">Michael Vassar: "RE: Loosemore's Proposal [Was: Re: Agi motivations]"</a>
<li><strong>In reply to:</strong> <a href="12601.html">Richard Loosemore: "Re: Loosemore's Proposal"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12614.html">Ben Goertzel: "RE: Loosemore's Proposal"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12608">[ date ]</a>
<a href="index.html#12608">[ thread ]</a>
<a href="subject.html#12608">[ subject ]</a>
<a href="author.html#12608">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
