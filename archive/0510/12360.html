<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI debate at San Jose State U.</title>
<meta name="Author" content="Woody Long (ironanchorpress@earthlink.net)">
<meta name="Subject" content="Re: AI debate at San Jose State U.">
<meta name="Date" content="2005-10-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI debate at San Jose State U.</h1>
<!-- received="Thu Oct 20 14:41:45 2005" -->
<!-- isoreceived="20051020204145" -->
<!-- sent="Thu, 20 Oct 2005 16:41:38 -0400" -->
<!-- isosent="20051020204138" -->
<!-- name="Woody Long" -->
<!-- email="ironanchorpress@earthlink.net" -->
<!-- subject="Re: AI debate at San Jose State U." -->
<!-- id="410-2200510420204138687@earthlink.net" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="AI debate at San Jose State U." -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Woody Long (<a href="mailto:ironanchorpress@earthlink.net?Subject=Re:%20AI%20debate%20at%20San%20Jose%20State%20U."><em>ironanchorpress@earthlink.net</em></a>)<br>
<strong>Date:</strong> Thu Oct 20 2005 - 14:41:38 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12361.html">Michael Wilson: "Re: AI debate at San Jose State U."</a>
<li><strong>Previous message:</strong> <a href="12359.html">Tyler Emerson: "State of the Blogosphere: Part 1: On Blogosphere Growth"</a>
<li><strong>Maybe in reply to:</strong> <a href="12299.html">mike99: "AI debate at San Jose State U."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12361.html">Michael Wilson: "Re: AI debate at San Jose State U."</a>
<li><strong>Reply:</strong> <a href="12361.html">Michael Wilson: "Re: AI debate at San Jose State U."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12360">[ date ]</a>
<a href="index.html#12360">[ thread ]</a>
<a href="subject.html#12360">[ subject ]</a>
<a href="author.html#12360">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; [Original Message]
</em><br>
<em>&gt; From: Olie Lamb &lt;<a href="mailto:olie@vaporate.com?Subject=Re:%20AI%20debate%20at%20San%20Jose%20State%20U.">olie@vaporate.com</a>&gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Woody Long defined Humanoid intelligence:
</em><br>
<em>&gt;
</em><br>
<em>&gt; 1. &quot;Humanoid intelligence requires humanoid interactions with the world&quot;
</em><br>
<pre>
--
&gt; MIT Cog Project website
&gt;
&gt; This means a fully &quot;human intelligent&quot; SAI must...feel the thrill of
victory and the agony of defeat. 
&gt;
&gt;
&gt; If we accept that to be &quot;humanoid&quot;, an intelligence must get pissed-off 
&gt; at losing, we can also define &quot;humanoid&quot; as requiring self-interest 
&gt; /selfishness, which is exactly the characteristic that I thought 
&gt; friendliness was trying to avoid. 
-----------------------------------
If this is true then &quot;friendliness theory&quot; is trying to eliminate the field
of strong AI itself, and by extension the singularity. I don't think that
is what the Singularity Institute is trying to do. In fact the website says
you are trying to build a fully human mind. All SAI by definition will have
an awareness of self and self interests. It is because of this self
interest driven human intelligent behavior that it will be able to build
cities on the moon without human intervention, etc. Can safe SAI exist?
Military SAI, no by definition. Corporate built, consumer SAI, yes, as
self-destructing, non-harming (non-defective) consumer desired products, by
way of the profit motive. Hobbiest built SAI, open question unless safety
protocols must be implemented to interact with public. This would be
equivalent to an inspected car having working bumpers, working brakes,
sealed gas tank, etc.
Is it not true that a singulatarian is by definition someone who believes
in and promotes a coming friendly SAI and Singularity that will have huge
benefits for human, as opposed to an anti-singulatarian who sees only
unfriendly SAI and is opposed to their creation? I thought it was our job
to educate the public on the coming friendly SAI / Singularity, how it will
be safe-built, and the huge science and engineering benefits we humans will
enjoy because of this non-toxic, non-defective, well-engineered, and
safe-built technological product.
Ken Woody Long
www.artificial-intelligence-likeforms.blogspot.com
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12361.html">Michael Wilson: "Re: AI debate at San Jose State U."</a>
<li><strong>Previous message:</strong> <a href="12359.html">Tyler Emerson: "State of the Blogosphere: Part 1: On Blogosphere Growth"</a>
<li><strong>Maybe in reply to:</strong> <a href="12299.html">mike99: "AI debate at San Jose State U."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12361.html">Michael Wilson: "Re: AI debate at San Jose State U."</a>
<li><strong>Reply:</strong> <a href="12361.html">Michael Wilson: "Re: AI debate at San Jose State U."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12360">[ date ]</a>
<a href="index.html#12360">[ thread ]</a>
<a href="subject.html#12360">[ subject ]</a>
<a href="author.html#12360">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:23:13 MST
</em></small></p>
</body>
</html>
