<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Long Self Theory (Re: JOIN)</title>
<meta name="Author" content="Woody Long (ironanchorpress@earthlink.net)">
<meta name="Subject" content="Re: Long Self Theory (Re: JOIN)">
<meta name="Date" content="2005-10-31">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Long Self Theory (Re: JOIN)</h1>
<!-- received="Mon Oct 31 01:55:01 2005" -->
<!-- isoreceived="20051031085501" -->
<!-- sent="Mon, 31 Oct 2005 03:54:49 -0500" -->
<!-- isosent="20051031085449" -->
<!-- name="Woody Long" -->
<!-- email="ironanchorpress@earthlink.net" -->
<!-- subject="Re: Long Self Theory (Re: JOIN)" -->
<!-- id="410-220051013185449468@earthlink.net" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="Long Self Theory (Re: JOIN)" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Woody Long (<a href="mailto:ironanchorpress@earthlink.net?Subject=Re:%20Long%20Self%20Theory%20(Re:%20JOIN)"><em>ironanchorpress@earthlink.net</em></a>)<br>
<strong>Date:</strong> Mon Oct 31 2005 - 01:54:49 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12694.html">Alfio Puglisi: "Re: Long Self Theory (Re: JOIN)"</a>
<li><strong>Previous message:</strong> <a href="12692.html">Olie Lamb: "Re: physics of uploading minds. [poll???]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12694.html">Alfio Puglisi: "Re: Long Self Theory (Re: JOIN)"</a>
<li><strong>Reply:</strong> <a href="12694.html">Alfio Puglisi: "Re: Long Self Theory (Re: JOIN)"</a>
<li><strong>Maybe reply:</strong> <a href="12696.html">Stephen Tattum: "Re: Long Self Theory (Re: JOIN)"</a>
<li><strong>Reply:</strong> <a href="12699.html">Pope Salmon the Lesser Mungojelly: "Re: Long Self Theory"</a>
<li><strong>Reply:</strong> <a href="12701.html">Richard Loosemore: "Bogus Patents [Was: Re: Long Self Theory]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12693">[ date ]</a>
<a href="index.html#12693">[ thread ]</a>
<a href="subject.html#12693">[ subject ]</a>
<a href="author.html#12693">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Yes indeed, let's delve into this a little more. 
<br>
<p>First a little android humor. &quot;Android Builders do it with the lights on.&quot; 
<br>
<p><p>[Original Message]
<br>
<em>&gt; From: Olie Lamb &lt;<a href="mailto:olie@vaporate.com?Subject=Re:%20Long%20Self%20Theory%20(Re:%20JOIN)">olie@vaporate.com</a>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; I was never trying to disprove the Dual Sound Source Experiment.  The 
</em><br>
<em>&gt; experiment is interesting, and &quot;valid&quot;.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I was saying that the inferences that you draw from it are bogus.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;For the musical experience, my subjective experience is strongly 
</em><br>
otherwise.
<br>
&nbsp;
<br>
Let us consider for a moment that the minimum duration of experience is 
<br>
1/10th of a second - 100ms. */this seems to be a reasonably widely held 
<br>
idea, but the best source I've found is in Tononi/Edelman's &quot;A Universe 
<br>
of Consciousness&quot;, and is not supported by research or footnoting. Does 
<br>
anyone know any sources on this idea? It would be extremely helpful for 
<br>
my PhD thesis!/*
<br>
&nbsp;
<br>
Now, I can play scales in contrary motion at 6 notes per second (170ms 
<br>
per note). My mother can play contrary motion scales 4:3 at 120 bpm, 
<br>
which is 125ms and 170 ms. When I play these scales, I make a very 
<br>
deliberate effort not to concentrate on either scale; I think of the two 
<br>
scales together moving against each other. Furthermore, I definitely 
<br>
think of two notes as I play them. If one accepts the 100ms minimum 
<br>
experience duration, there isn't enough time to switch from one note to 
<br>
the other.
<br>
&nbsp;
<br>
What the hell my mother's brain does to play 4 against 3 contrary 
<br>
motion, I don't know.  
<br>
<em>&gt; &gt;
</em><br>
<p>OK, that's disputing the experimental data, not my inferences, so you ARE
<br>
trying to subjectively disprove the experiment.results. My approach is to
<br>
accept that a scientific experiment has been conducted, and the resulting
<br>
objective data shows that the subject could only focalize on and remember
<br>
one sound source at a
<br>
time. It was impossible to attend to both. Then my task is to understand
<br>
what these experimental results mean for android engineering, where the
<br>
goal is to build a human-shaped, human functioning robot. In building these
<br>
androids, the design task is to mimic natural human functioning as closely
<br>
as possible, not build dual processing non-human consciousness systems.
<br>
That is not our field. 
<br>
<p>These are the inferences of my Long Artificial Self Theory --
<br>
<p>Experimental data: The subject could only focalize on and remember one
<br>
sound source at a time. It was impossible to attend to both.
<br>
<p>Inference 1. The subject is acting as a focalizing agent, focalizing on and
<br>
remembering one sound source at a time, never able to attend to both.
<br>
<p>Inference 2. This human focalizing agent is generally termed the self.
<br>
<p>Inference 3. The root of consciousness, being the source memories, was this
<br>
focalizing agent, or self, that had no option but to switch its focalizing
<br>
attention to one single source or the other. 
<br>
<p>Inference 4. But therein arises the phenomenon of choice, of human willed
<br>
behavior. The subject has no option but to switch to one source or the
<br>
other, but within this unwilled, detirministic system, the subject has the
<br>
choice to attend to the right ear or left ear, i.e., the ability to form
<br>
the willed behavior of attending to one or the other. And so the mystery of
<br>
human willed behavior is finally revealed.   
<br>
<p>Inference 5. In accordance with the experimental data, all human
<br>
functioning androids, by industry standards, should possess an artificial
<br>
self, functioning as the root of artificial consciousness.  
<br>
---------------------------------
<br>
<p>These inferences require no stretch of the imagination. In the android
<br>
industry this is all we are interested in - making androids as human-like
<br>
as possible, based on experimental kowledge about humans. Androids
<br>
absolutely will include an artificial self autonomously driving the
<br>
artificial consciousness and tasks of the android. An android with a self,
<br>
referring to itself as I, having a personal memory of its experiences, of
<br>
its life, having a self-awareness, is, if nothing else simply a more
<br>
interesting and human-like android, and will be included ultimately as a
<br>
standard for this reason alone. Thing is, this conscious, motivationally
<br>
autonomous, cognitive, artificial self standard for androids can't be built
<br>
without infringing on my patent.
<br>
<p><em>&gt;
</em><br>
<em>&gt; Just say that an intelligence can pass an elaborate Turing-test test in 
</em><br>
<em>&gt; such a way that it becomes difficult to deny that it is exhibiting 
</em><br>
<em>&gt; conscious awareness.*  &quot;It Passes.&quot;  This happens to be a transparent 
</em><br>
<em>&gt; digital AI on a parallel platform, and we can retropsectively see its 
</em><br>
<em>&gt; computation.  (I think most SL4ers won't have too many problems with 
</em><br>
<em>&gt; such a scenario).  Now just say that we slow it down its mental 
</em><br>
<em>&gt; processes (clock speed) so that it has few to no spare operations, and 
</em><br>
<em>&gt; ask it to carry on two conversations at once, and it is able to, and we 
</em><br>
<em>&gt; examine the computational states, and find that the computational 
</em><br>
<em>&gt; processors are not sequentially switching, but rather parallel 
</em><br>
<em>&gt; structures are working simultaneously on the two different conversations.
</em><br>
<em>&gt;
</em><br>
As I said, I'm not disputing that a non-human dual processing consciousness
<br>
can be built. That is called switching the subject. My subject here is
<br>
human consciousness and its computer implementation, not the subject of
<br>
non-human conciousness implementations. I never made a single argument
<br>
about non-human consciousness systems.
<br>
<p>Ken Woody Long
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12694.html">Alfio Puglisi: "Re: Long Self Theory (Re: JOIN)"</a>
<li><strong>Previous message:</strong> <a href="12692.html">Olie Lamb: "Re: physics of uploading minds. [poll???]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12694.html">Alfio Puglisi: "Re: Long Self Theory (Re: JOIN)"</a>
<li><strong>Reply:</strong> <a href="12694.html">Alfio Puglisi: "Re: Long Self Theory (Re: JOIN)"</a>
<li><strong>Maybe reply:</strong> <a href="12696.html">Stephen Tattum: "Re: Long Self Theory (Re: JOIN)"</a>
<li><strong>Reply:</strong> <a href="12699.html">Pope Salmon the Lesser Mungojelly: "Re: Long Self Theory"</a>
<li><strong>Reply:</strong> <a href="12701.html">Richard Loosemore: "Bogus Patents [Was: Re: Long Self Theory]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12693">[ date ]</a>
<a href="index.html#12693">[ thread ]</a>
<a href="subject.html#12693">[ subject ]</a>
<a href="author.html#12693">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
