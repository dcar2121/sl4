<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Memory Merging Possible For Close Duplicates</title>
<meta name="Author" content="Lee Corbin (lcorbin@rawbw.com)">
<meta name="Subject" content="Re: Memory Merging Possible For Close Duplicates">
<meta name="Date" content="2008-03-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Memory Merging Possible For Close Duplicates</h1>
<!-- received="Sat Mar 15 13:20:40 2008" -->
<!-- isoreceived="20080315192040" -->
<!-- sent="Sat, 15 Mar 2008 12:13:42 -0700" -->
<!-- isosent="20080315191342" -->
<!-- name="Lee Corbin" -->
<!-- email="lcorbin@rawbw.com" -->
<!-- subject="Re: Memory Merging Possible For Close Duplicates" -->
<!-- id="015501c886d1$5b02dbe0$6401a8c0@homeef7b612677" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="62c14240803140747w20f70cb0i378a8716ba5c710d@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Lee Corbin (<a href="mailto:lcorbin@rawbw.com?Subject=Re:%20Memory%20Merging%20Possible%20For%20Close%20Duplicates"><em>lcorbin@rawbw.com</em></a>)<br>
<strong>Date:</strong> Sat Mar 15 2008 - 13:13:42 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="18086.html">Heartland: "[META]A new list dedicated to PI/survival."</a>
<li><strong>Previous message:</strong> <a href="18084.html">Matt Mahoney: "Re: Is a Person One or Many?"</a>
<li><strong>In reply to:</strong> <a href="18070.html">Mike Dougherty: "Re: Memory Merging Possible For Close Duplicates"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18102.html">Mike Dougherty: "Re: Memory Merging Possible For Close Duplicates"</a>
<li><strong>Reply:</strong> <a href="18102.html">Mike Dougherty: "Re: Memory Merging Possible For Close Duplicates"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18085">[ date ]</a>
<a href="index.html#18085">[ thread ]</a>
<a href="subject.html#18085">[ subject ]</a>
<a href="author.html#18085">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Mike writes
<br>
<p><em>&gt; Lee Corbin wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; Ah.  Here you mean not only the computer science &quot;shared memory&quot;
</em><br>
<em>&gt; &gt; but real human type shared memory.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Yes.  Though strained, I don't know what other analogy to use because
</em><br>
<em>&gt; I am assuming the merging of states isn't feasible for discussion unless
</em><br>
<em>&gt; we're talking about uploaded brains.  I guess you could plan for some
</em><br>
<em>&gt; convoluted chemistry and physical manipulation of meat, but that seems
</em><br>
<em>&gt; too icky for discussion.  :)
</em><br>
<p>Yeah, it's a hell of a lot messier, that's for sure.  But seriously, it's the
<br>
*principle* we are talking about, as you know, not the practical
<br>
difficulties of the feasibility.
<br>
<p><em>&gt;&gt;&gt; I expect that the uploaded person will be software running on
</em><br>
<em>&gt;&gt;&gt; top of some general virtual person hardware.  If so, there will
</em><br>
<em>&gt;&gt;&gt; be no direct way to experience whether your memories are
</em><br>
<em>&gt;&gt;&gt; retrieved through a GLUT or somehow recreated on-the-fly
</em><br>
<em>&gt;&gt;&gt; from templates (something like compression/decompression
</em><br>
<em>&gt;&gt;&gt; of a world of context to a few relevant bits that can be used
</em><br>
<em>&gt;&gt;&gt; to reconstruct a most-likely scenario that we believe to be a
</em><br>
<em>&gt;&gt;&gt; real memory)
</em><br>
<p>Nice point.  Does the act, say, in the latter case of generating
<br>
the memories on-the-fly as you suggest contribute any to
<br>
consciousness. At least to me, that's a nice question.
<br>
&nbsp;
<br>
<em>&gt;&gt;&gt; and a context switch back will appear to those inhabiting the
</em><br>
<em>&gt;&gt;&gt; suspended environment that the results of those independent
</em><br>
<em>&gt;&gt;&gt; threads have been computed instantly.
</em><br>
<p>Honestly, I have no idea what you're getting at with that! As I said
<br>
<p><em>&gt;&gt; That's not very clear, IMO.  With ordinary raw threads or processes
</em><br>
<em>&gt;&gt; running on a computer, sure, one moment the process has access to
</em><br>
<em>&gt;&gt; data structures X and Y, and the next, equal access to Z. But that
</em><br>
<em>&gt;&gt; entirely ignores the knotty problem of how memories are added to
</em><br>
<em>&gt;&gt; people, as you say &quot;instantly&quot;.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; what makes &quot;ordinary raw thread&quot; different inside your PC, in a
</em><br>
<em>&gt; computronium Jupiter Brain or the entire detectable universe? 
</em><br>
<em>&gt; I don't mean this to be a rhetorical question.  Given my previous
</em><br>
<em>&gt; paragraph (this post) - I would like you to describe what makes
</em><br>
<em>&gt; PC threads, their [an] equivalent analogue for the software mind
</em><br>
<em>&gt; running on virtual human hardware and the real-world mechanism
</em><br>
<em>&gt; (whatever it might be)[.]
</em><br>
<p>I don't know that they're really any different in principle. Normally
<br>
the computer analogies work splendidly.  But here, again, I just
<br>
note that suddenly being given by your spouse the complete 
<br>
works of Shakespeare does in no way equate to your having
<br>
carefully read them and integrated them line-by-line into your
<br>
memories.   As I said
<br>
&nbsp;
<br>
<em>&gt;&gt; Normally each new experience you have is immediately compared
</em><br>
<em>&gt;&gt; on some sort of salience measure to everything else that has ever
</em><br>
<em>&gt;&gt; happened to you, i.e., to all your other memories. That's why you
</em><br>
<em>&gt;&gt; are &quot;reminded&quot; of things, some of which happened a long time ago.
</em><br>
<em>&gt;&gt; Now if you get enough new experiences, the new memories that
</em><br>
<em>&gt;&gt; are generated are slowly integrated into all your existing ones.
</em><br>
<em>&gt;&gt; The computer analogy seems a little strained here, at least with
</em><br>
<em>&gt;&gt; the kinds of algorithms we have today running on our machines.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Now I have a greater appreciation for the trouble you see with
</em><br>
<em>&gt; close copies not being close enough to merge.
</em><br>
<p>Well, could you have snipped a lot of the foregoing I wonder?
<br>
In addition to your ghastly HTML, I'm having some trouble here
<br>
knowing what we've agreed to and what we haven't, and, alas,
<br>
have not been snipping very conscientiously myself.
<br>
<p><em>&gt; If the salience measure for two different copies were sufficiently
</em><br>
<em>&gt; far apart that one would find a new fact compatible with prior
</em><br>
<em>&gt; experience enough to learn it while the other was unable to
</em><br>
<em>&gt; accept the new information because it was incompatible with
</em><br>
<em>&gt; prior experience.
</em><br>
<p>Right.  One of them might have just finished a class in algebra,
<br>
but not the other, and the fact that &quot;2abc + 3a = 2a(bc + 1.5)&quot;
<br>
might be totally incomprehensible to the latter.
<br>
<p><em>&gt; In an extreme case we could construct a scenario where the
</em><br>
<em>&gt; two copies were lead to believe completely incompatible beliefs
</em><br>
<em>&gt; (e.g.: religious conditioning)
</em><br>
<p>Yes.
<br>
<p><em>&gt; We may need to evolve some method of dealing with this.  My
</em><br>
<em>&gt; guess would be that our normal memory pruning mechanism
</em><br>
<em>&gt; could be employed to simply erase/suppress any incompatibilities.
</em><br>
<p>At first glance, that sounds awful.  I myself definitely want to retain
<br>
good arguments for each side of a dilemma, for example. 
<br>
<p><em>&gt; There is evidence (of varying effectiveness) to suggest that sleep
</em><br>
<em>&gt; facilitates mental housekeeping.  There is also evidence of
</em><br>
<em>&gt; psychological defense mechanisms [that] will artificially create
</em><br>
<em>&gt; memories to block recall of traumatic events.  
</em><br>
<p>Yes, at the sacrifice of true knowledge on the subject's part.
<br>
<p><em>&gt; Perhaps the reintegration process will involve vetting what experience
</em><br>
<em>&gt; to keep from the copy?  If you spawn a LeeCorbin_EmptyTrash
</em><br>
<em>&gt; process, it might not require the vast knowledgebase of your entire
</em><br>
<em>&gt; history  (possibly only the history of events since the last time it was
</em><br>
<em>&gt; invoked)  Now this task/process believes itself to be be LeeCorbin
</em><br>
<em>&gt; (so far as you would only authorize such process to an implicit trust
</em><br>
<em>&gt; as yourself).
</em><br>
<p>Now how can that be?  A LeeCorbin_EmptyTrash process wouldn't
<br>
have any access (nor need any access) to almost all of my history.
<br>
I already have reflexes that kick my leg when the doctor strikes my
<br>
knee. They're not really me, not in the slightest. 
<br>
<p><em>&gt; After this sub-self has fulfilled its reason for existing and you have
</em><br>
<em>&gt; verified success, you may choose to reintegrate the complete
</em><br>
<em>&gt; experiential record of that process.  In that case, you should have
</em><br>
<em>&gt; just done the task directly.
</em><br>
<p>I should have?  If I had done so, then as I made my weary way out
<br>
to the trash receptacle in the downpouring rain, various melancholy
<br>
thoughts might intrude of one kind or another. I prefer your plan:
<br>
I spawn a body that knows nothing but mindlessly taking out the
<br>
trash, and then reintegrate that memory, just to make sure the job
<br>
got done.
<br>
<p><em>&gt; At the opposite extreme, you don't subsume any of the experience
</em><br>
<em>&gt; because you are confident there is minimal novel experience
</em><br>
<em>&gt; associated with that task.  The degree to which you care about
</em><br>
<em>&gt; the experience is probably related to how much of your Self you
</em><br>
<em>&gt; originally invested in the creation of the clone/sub-process.
</em><br>
<p>Right.
<br>
<p><em>&gt; I realize this isn't exactly a copy or close duplicate (per the subject line)
</em><br>
<em>&gt; - Would you call a clone that has _only_ the last 2 minutes of task-
</em><br>
<em>&gt; specific knowledge to be a copy?
</em><br>
<p>No.
<br>
<p><em>&gt; Would you call it a completely different identity?  
</em><br>
<p>It hardly sounds like it's even a person at all, unless I've misread you.
<br>
<p><em>&gt; I think this question comes out of the discussion about what makes
</em><br>
<em>&gt; an identity: the model predicting their behavior, or the memory of
</em><br>
<em>&gt; prior situations?  (tough call because past events are often the raw
</em><br>
<em>&gt; data upon which the model is based)
</em><br>
<p>What makes an identity?  Tough call all right!  I'm not even sure
<br>
that a model predicting my behavior makes it me, seeing as how
<br>
we all act predictably from time to time.  Moreover, a vast
<br>
intelligence could probably predict my behavior at the 98%
<br>
accuracy level, just the way that I might predict an ant's. But
<br>
it seems weird to say that I am the ant, or that that vast intelligence
<br>
is me.
<br>
<p><em>&gt;  Is it possible to observe that I choose blue rather than red in
</em><br>
<em>&gt; 100 instances, so you remember only that I prefer blue - then
</em><br>
<em>&gt; delete your memory of the 100 instances and retain only the
</em><br>
<em>&gt; knowledge that I prefer blue?
</em><br>
<p>Certainly.  I think that that happens *all* the time. I may not
<br>
remember Joe's reasons, but I know that he's a Bush supporter.
<br>
<p><em>&gt; Upon my next choice will you be able to assess that I made a
</em><br>
<em>&gt; characteristic choice of blue?
</em><br>
<p>Sure.  It will accord well with my knowledge of your behavior,
<br>
or, to use trickier and more dangerous, but perhaps more accurate
<br>
language, &quot;my model&quot; of your behavior.
<br>
<p><em>&gt; Is there any value to incur the storage overhead of recording the
</em><br>
<em>&gt; details of every one of those 100 prior instances?
</em><br>
<p>In many situations, yes.  On closer examination later, more subtle
<br>
patterns may emerge.  If I remember Joe's expressed reasons for
<br>
supporting Bush, certainly our future conversation will be more
<br>
efficient.
<br>
<p><em>&gt; How much memory optimization do we already perform, that we
</em><br>
<em>&gt; will need to be able to do in an uploaded state?
</em><br>
<p>How should I know?    :-)
<br>
<p><em>&gt; Again, I apologize for the strained computer analogy
</em><br>
<p>Oh, not at all. 
<br>
<p><em>&gt; - but I continue to assume the most logical way any of these copies
</em><br>
<em>&gt; exist is after uploading.
</em><br>
<p>I don't see them as more logical.  The good old teleporter/scanner
<br>
device is just fine for TEs, no?  But for ease of implementation,
<br>
nothing beats making a copy of an upload!  :-)
<br>
<p>Lee
<br>
<p>P.S.  Sorry, as I explained, for not snipping more. It will be a miracle
<br>
if anyone bothers reading this whole thing except you and me.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="18086.html">Heartland: "[META]A new list dedicated to PI/survival."</a>
<li><strong>Previous message:</strong> <a href="18084.html">Matt Mahoney: "Re: Is a Person One or Many?"</a>
<li><strong>In reply to:</strong> <a href="18070.html">Mike Dougherty: "Re: Memory Merging Possible For Close Duplicates"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18102.html">Mike Dougherty: "Re: Memory Merging Possible For Close Duplicates"</a>
<li><strong>Reply:</strong> <a href="18102.html">Mike Dougherty: "Re: Memory Merging Possible For Close Duplicates"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18085">[ date ]</a>
<a href="index.html#18085">[ thread ]</a>
<a href="subject.html#18085">[ subject ]</a>
<a href="author.html#18085">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:02 MDT
</em></small></p>
</body>
</html>
