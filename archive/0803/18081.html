<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: The GLUT and functionalism</title>
<meta name="Author" content="Lee Corbin (lcorbin@rawbw.com)">
<meta name="Subject" content="Re: The GLUT and functionalism">
<meta name="Date" content="2008-03-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: The GLUT and functionalism</h1>
<!-- received="Sat Mar 15 12:10:20 2008" -->
<!-- isoreceived="20080315181020" -->
<!-- sent="Sat, 15 Mar 2008 11:05:27 -0700" -->
<!-- isosent="20080315180527" -->
<!-- name="Lee Corbin" -->
<!-- email="lcorbin@rawbw.com" -->
<!-- subject="Re: The GLUT and functionalism" -->
<!-- id="014101c886c7$88faf0a0$6401a8c0@homeef7b612677" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="f21c22e30803140455y18dd5053g63d8e7342b8c3912@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Lee Corbin (<a href="mailto:lcorbin@rawbw.com?Subject=Re:%20The%20GLUT%20and%20functionalism"><em>lcorbin@rawbw.com</em></a>)<br>
<strong>Date:</strong> Sat Mar 15 2008 - 12:05:27 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="18082.html">Heartland: "Re: There's more to me than memories, but I won't tell you what"</a>
<li><strong>Previous message:</strong> <a href="18080.html">Matt Mahoney: "Re: There's more to me than memories..."</a>
<li><strong>In reply to:</strong> <a href="18071.html">Stathis Papaioannou: "Re: The GLUT and functionalism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18099.html">Stathis Papaioannou: "Re: The GLUT and functionalism"</a>
<li><strong>Reply:</strong> <a href="18099.html">Stathis Papaioannou: "Re: The GLUT and functionalism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18081">[ date ]</a>
<a href="index.html#18081">[ thread ]</a>
<a href="subject.html#18081">[ subject ]</a>
<a href="author.html#18081">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I have taken the liberty of appending Stathis's entire original description
<br>
of his Thought Experiment (TE), his points, and his conclusion from his
<br>
&quot;Sent: Thursday, March 13, 2008 3:12 AM Subject: Re: The GLUT and
<br>
functionalism&quot; to the very end of this email, mostly for my own reference.
<br>
<p>Stathis writes
<br>
<p><em>&gt; Lee  wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;  &gt; We would then both agree that M1 and M2/M3 with reliable information
</em><br>
<em>&gt;&gt;  &gt; transfer would give rise to consciousness. You would argue that M2/M3
</em><br>
<em>&gt;&gt;  &gt; without reliable information transfer would not give rise to consciousness.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Yes, I would so argue.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;  &gt; But what if the information transfer doesn't fall into the all or none category?
</em><br>
<em>&gt;&gt;  &gt; For example, what if the operator transfers the right information some of the
</em><br>
<em>&gt;&gt;  &gt; time based on whim, but never reveals to anyone what he decides? The
</em><br>
<em>&gt;&gt;  &gt; M2/M3 system (plus operator) would again be useless as a computation
</em><br>
<em>&gt;&gt;  &gt; device to an external observer, but on some runs, known only to the
</em><br>
<em>&gt;&gt;  &gt; operator, [***] there will definitely be a causal link [***].
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Very clear.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Thank-you for following the thought experiment so closely so far.
</em><br>
<em>&gt; However, I think I have made an error by writing &quot;there will
</em><br>
<em>&gt; definitely be a causal link&quot; above. In the extreme case, the operator
</em><br>
<em>&gt; might transfer every possible state in sequence, knowing but not
</em><br>
<em>&gt; saying which of these is the right one to implement the computation.
</em><br>
<em>&gt; Does that count as a causal link on the run in which this occurs? As
</em><br>
<em>&gt; far as you can tell by observing him, the operator is no more
</em><br>
<em>&gt; knowledgeable than an ignorant person trying out every possible state.
</em><br>
<em>&gt; Could the computation possibly divine his mental state in order to
</em><br>
<em>&gt; decide whether there is a causal link and thereby become conscious?
</em><br>
<p>Naturally, I don't see it as the computation getting access to his
<br>
mental state, or anything like that. It's perhaps a bit like the operator
<br>
supposedly transferring quantities of Argon by gas canister into
<br>
a target receptacle but sometimes transfers Krypton either by 
<br>
accident or design. The delicate mass of the target will be affected
<br>
without any access to his intentions, etc. (Sorry for the crude analogy, I
<br>
hope it doesn't have problems, and I hope I am not belating the obvious.)
<br>
<p>Maybe I've got the wrong picture of what you are describing?
<br>
Does the following implement your TE in more slightly more 
<br>
concrete terms?  The 6*7 = 42 computation is carried out in
<br>
Australia by someone with a pocket calculator. The M2/M3
<br>
is carried out by the calculator reaching all but the last step
<br>
of the calculation, when the machine is destroyed but a nimble
<br>
operator manages to record the semifinal state on a diskette and
<br>
sends it to Vienna. A child in Vienna happens to receive this
<br>
diskette, transfers the state to his own calculator, and finishes
<br>
it, getting the answer 42.  But on some cases the operator sends
<br>
a faulty semifinal diskette, and then either by luck the answer 42
<br>
is obtained, or else, say, 58 is obtained. You direct our attention
<br>
to the case where by luck 42 is obtained anyway, despite the
<br>
&quot;noisy channel&quot;?
<br>
<p>Either actual information flows, or it doesn't, i.e., the channel is
<br>
noisy or it's not. The ignorant person trying out &quot;every possible
<br>
state&quot; means what? I apologize for not being able to correctly
<br>
visualize what you mean here---it's probably quite clear but I
<br>
can't see it. Maybe the child in Vienna tries out a huge ensemble
<br>
of diskettes one by one, and every so often one of them happens
<br>
by sheer chance to be identical to the proper diskette produced
<br>
in Australia?
<br>
<p><em>&gt;&gt;  It may (or may not) be simpler, as you suggest, to suppose that
</em><br>
<em>&gt;&gt;  ALL [my emphasis]  that is necessary is that the right physical
</em><br>
<em>&gt;&gt;  states occur [e.g. by random diskette] or are implemented somehow.
</em><br>
<em>&gt;&gt;  I doubt very much that there is a logical flaw in your suggestion.
</em><br>
<p>Because, so far as I can see, it's this sort of thing that lies behind the
<br>
entire Theory of Dust = Schmidhuber = timeless computation sort
<br>
of thing, and I am entirely confident that your side is making no
<br>
*logical* flaw. It's just---as is so often the case---which side has
<br>
to undergo the greater awkwardness or embarrassment in trying
<br>
to maintain difficult or unwieldy positions.
<br>
<p><em>&gt;&gt;  On the other hand, I doubt that there is
</em><br>
<em>&gt;&gt;  any insoluble problem with mine---just a bit of awkwardness,
</em><br>
<em>&gt;&gt;  e.g., why is a 3+1 dimensional creature conscious, a 2+1 dimensional
</em><br>
<em>&gt;&gt;  creature conscious (as in Flatland or the Life Board), but a 3 dimensional
</em><br>
<em>&gt;&gt;  frozen block that is *completely* isomorphic to the 2+1 structure
</em><br>
<em>&gt;&gt;  not conscious?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; How can you be so sure about that last point?
</em><br>
<p>About assuming the complete isomorphism? What do you mean? 
<br>
You could easily have an ordinary 3D sculpture totally isomorphic
<br>
to a 2D run through time.  I used to suggest to people that they
<br>
visualize a stack of very thin gels, each recording the state of a
<br>
Life Board. Piled on top of each other, they depict with 100%
<br>
fidelity a Life Board computation.
<br>
<p><em>&gt;&gt;  Your &quot;awkwardness&quot;, on the other hand, is that you cannot really
</em><br>
<em>&gt;&gt;  give (so far as I know) any reason why I should choose to detonate
</em><br>
<em>&gt;&gt;  the Tsar Bomba next to the Stathis guy in Australia, or a rock I
</em><br>
<em>&gt;&gt;  pick up at random.  They both emulate my friend Stathis, right?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; If a rock emulates anything then blowing it up isn't going to make any
</em><br>
<em>&gt; difference, since the point is that it doesn't matter what the rock's
</em><br>
<em>&gt; atoms are doing.
</em><br>
<p>Touche.  All right, then suppose I have a choice between (a) somehow
<br>
magically removing from the universe---and causing to entirely cease to
<br>
exist---a 400 kilogram of Stathis, or blowing your present biological
<br>
incarnation to smithereens.
<br>
<p><em>&gt; On the other hand, if you blow up the physical Stathis, that would
</em><br>
<em>&gt; mean that at least some branches of the computations in Platonia
</em><br>
<em>&gt; simulating me come to an abrupt end.
</em><br>
<p>Well, I'm sure you don't weigh 400kg, so let's say that you weigh
<br>
100kg. In comparison to the biological 100kg Stathis, how much
<br>
&quot;computation of Stathis&quot;, if I may ask, does a 100kg marble
<br>
statue of you emulate?  Or, in other words, right now your 100kg
<br>
because it's ordinary matter at about 295 degrees Kelvin, already
<br>
emulates you to some degree.  What degree?
<br>
<p><em>&gt; So, even though whatever will be will be, I prefer that you blow
</em><br>
<em>&gt; up the rock.
</em><br>
<p>Oh good. You never know where our thought experiments might
<br>
lead!   :-)
<br>
<p>Lee
<br>
<p>_________________________________________________________
<br>
Stathis's original formulation:  Said he:
<br>
<p>&quot;I agree with you to an extent about the significance of causality in
<br>
computation. Suppose there are steps in a computation which don't
<br>
follow from the preceding step, but just happen to occur correctly *as
<br>
if* they followed from the preceding step.
<br>
<p>&quot;For example, imagine a machine M1 into which you input &quot;6*7&quot;, gears
<br>
and levers and so forth go clickety-clack, and after 100 steps it
<br>
outputs &quot;42&quot;. Next, consider another identical machine, M2, into which
<br>
you input &quot;6*7&quot;, but at the 73rd step you destroy it. The next day on
<br>
the other side of the world, by fantastic coincidence, someone else
<br>
builds a machine, M3, which just happens to be in identical
<br>
configuration to M1 (and hence M2, had it not been destroyed) at the
<br>
73rd step. M3 then goes clickety-clack through steps 74 to 100 and
<br>
outputs &quot;42&quot;.
<br>
<p>&quot;I would agree with you that even though the activity of M2/M3 seen in
<br>
combination might look the same as the activity of M1, they are not
<br>
equivalent computational systems. This is because M1 would
<br>
appropriately handle a counterfactual, but M2/M3 would not: if the
<br>
input to M1 had been &quot;4*5&quot; the output would have been &quot;20&quot;, whereas if
<br>
the input to M2 had been &quot;4*5&quot; the output from M3 would have still
<br>
been &quot;42&quot;, as the lack of a causal link between M2 and M3 means there
<br>
is no way for the input of M2 to influence the output of M3. The
<br>
obvious significance of this is that M2/M3 is useless as a
<br>
computational device. It could be made useful by introducing reliable
<br>
information transfer between the two machines, say by an operator
<br>
passing M2's final state to be used as M3's initial state. The new
<br>
M2/M3 system is then equivalent to the intact M1, albeit a bit slower
<br>
and more cumbersome.
<br>
<p>&quot;Now, let's suppose that implementation of the computation 6*7 = 42 is
<br>
associated with a primitive moment of consciousness, and for
<br>
simplicity that this is the case only if the computation is
<br>
implemented in full. We would then both agree that M1 and M2/M3 with
<br>
reliable information transfer would give rise to consciousness. You
<br>
would argue that M2/M3 without reliable information transfer would not
<br>
give rise to consciousness. But what if the information transfer
<br>
doesn't fall into the all or none category? For example, what if the
<br>
operator transfers the right information some of the time based on
<br>
whim, but never reveals to anyone what he decides? The M2/M3 system
<br>
(plus operator) would again be useless as a computation device to an
<br>
external observer, but on some runs, known only to the operator, there
<br>
will definitely be a causal link. Does consciousness occur on those
<br>
runs or not? Does it make a difference if the operator lies 99.999% of
<br>
the time or 0.001% of the time? Does the computation know when he's
<br>
lying, or does it know the proportion of time he intends to lie so
<br>
that it can experience fractional consciousness at the appropriate
<br>
level?
<br>
<p>&quot;You will have a hard time defining criteria (let alone a mechanism)
<br>
whereby a computation &quot;knows&quot; that there is a causal link. It is
<br>
simpler to assume that consciousness occurs purely as a result of the
<br>
right physical states being implemented, while the presence of a
<br>
recognisable causal link only determines whether the system can be
<br>
used by an external observer for useful computation.&quot;
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="18082.html">Heartland: "Re: There's more to me than memories, but I won't tell you what"</a>
<li><strong>Previous message:</strong> <a href="18080.html">Matt Mahoney: "Re: There's more to me than memories..."</a>
<li><strong>In reply to:</strong> <a href="18071.html">Stathis Papaioannou: "Re: The GLUT and functionalism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18099.html">Stathis Papaioannou: "Re: The GLUT and functionalism"</a>
<li><strong>Reply:</strong> <a href="18099.html">Stathis Papaioannou: "Re: The GLUT and functionalism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18081">[ date ]</a>
<a href="index.html#18081">[ thread ]</a>
<a href="subject.html#18081">[ subject ]</a>
<a href="author.html#18081">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:02 MDT
</em></small></p>
</body>
</html>
