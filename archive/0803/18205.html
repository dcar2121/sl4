<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Friendliness SOLVED!</title>
<meta name="Author" content="Dimitry Volfson (dvolfson@juno.com)">
<meta name="Subject" content="Re: Friendliness SOLVED!">
<meta name="Date" content="2008-03-18">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Friendliness SOLVED!</h1>
<!-- received="Tue Mar 18 22:37:25 2008" -->
<!-- isoreceived="20080319043725" -->
<!-- sent="Tue, 18 Mar 2008 23:34:38 -0500" -->
<!-- isosent="20080319043438" -->
<!-- name="Dimitry Volfson" -->
<!-- email="dvolfson@juno.com" -->
<!-- subject="Re: Friendliness SOLVED!" -->
<!-- id="47E097DE.9050404@juno.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="004f01c88970$9f25dba0$6601a8c0@phoenix" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Dimitry Volfson (<a href="mailto:dvolfson@juno.com?Subject=Re:%20Friendliness%20SOLVED!"><em>dvolfson@juno.com</em></a>)<br>
<strong>Date:</strong> Tue Mar 18 2008 - 22:34:38 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="18206.html">Lee Corbin: "Re: Similarity of Structure"</a>
<li><strong>Previous message:</strong> <a href="18204.html">Lee Corbin: "Re: Memory Merging Possible For Close Duplicates"</a>
<li><strong>In reply to:</strong> <a href="18201.html">Mark Waser: "Re: Friendliness SOLVED!"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18196.html">Mark Waser: "Re: Friendliness SOLVED!"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18205">[ date ]</a>
<a href="index.html#18205">[ thread ]</a>
<a href="subject.html#18205">[ subject ]</a>
<a href="author.html#18205">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Mark Waser wrote:
<br>
<em>&gt; Matt &gt; You will believe whatever you are programmed to believe.  If 
</em><br>
<em>&gt; you are opposed to being reprogrammed, the nanobots will move some 
</em><br>
<em>&gt; more neurons around to change your mind about that too.  It can't be 
</em><br>
<em>&gt; evil if everyone is in favor of it.
</em><br>
<em>&gt;  
</em><br>
<em>&gt; Me &gt; Sorry.  By my definition, if you alter my beliefs so to subvert 
</em><br>
<em>&gt; my goals, you have performed an evil act.
</em><br>
<em>&gt; Matt &gt; That's your present perspective.  By its perspective, it is 
</em><br>
<em>&gt; bringing you up closer to its level of intelligence so that you can 
</em><br>
<em>&gt; see the folly of your ways.
</em><br>
<em>&gt; Dimitry &gt; Absolutely. Even if all it does is talk to you, and that 
</em><br>
<em>&gt; conversation ends up changing your goals or the priority of your 
</em><br>
<em>&gt; goals, then what it  has done is to &quot;subvert your goals, therefore 
</em><br>
<em>&gt; performing an evil act.&quot;
</em><br>
<em>&gt;  
</em><br>
<em>&gt; No.  An honest conversation according to the Libertarian ideals of &quot;No 
</em><br>
<em>&gt; force, no fraud&quot; might CHANGE my goals as I learn more and become more 
</em><br>
<em>&gt; intelligent but it doesn't subvert them (check the dictionary 
</em><br>
<em>&gt; definition of subvert)
</em><br>
<em>&gt;  
</em><br>
<em>&gt; The nasty machine is using force when it is using it's nanobots 
</em><br>
<em>&gt; AGAINST MY WILL.  It is *corrupting* my will and/by forcibly altering 
</em><br>
<em>&gt; my goals.
</em><br>
It's no different if it implants schema and goal pathways into your 
<br>
brain that change the way you think, through nanobots or through 
<br>
conversation. Nanobots would be the more efficient option, however. You 
<br>
label the use of nanobots as force, but I don't see that as a true 
<br>
distinction. The same effect can be accomplished through conversation.
<br>
<em>&gt;  
</em><br>
<em>&gt; &gt; But what I believe nobody still understands is why you, Mark Waser,
</em><br>
<em>&gt; &gt; believe that simply telling a (potential) superintelligence about a
</em><br>
<em>&gt; &gt; belief system would change it's beliefs? It's like the old science
</em><br>
<em>&gt; &gt; fiction story where you kill the superintelligent computer by 
</em><br>
<em>&gt; telling it
</em><br>
<em>&gt; &gt; a riddle it can't solve. Neat idea for a science fiction story, but if
</em><br>
<em>&gt; &gt; you really think about it, there's no reason for it to work.
</em><br>
<em>&gt;  
</em><br>
<em>&gt; I've been thinking about it for quite some time.  Any sufficiently 
</em><br>
<em>&gt; adapted entity is absolutely going to have the capability to break out 
</em><br>
<em>&gt; of loops as soon as they are sufficiently unhelpful.  Note the 
</em><br>
<em>&gt; literally instinctive human aversion to circular reasoning.
</em><br>
<em>&gt;  
</em><br>
<em>&gt; However, humans are also *very* prone to circular reasoning disguising 
</em><br>
<em>&gt; itself as helpful memes.  The most obvious example of this is 
</em><br>
<em>&gt; religion.  Thus my failed attempt at religion as a compelling solution 
</em><br>
<em>&gt; on this list.  In 20/20 hindsight, that was a foolish attempt on this 
</em><br>
<em>&gt; list.  Humans also develop a instinctive resistance to foreign 
</em><br>
<em>&gt; religions with age and increasing intellect and rationality.  This 
</em><br>
<em>&gt; list, with it's high intelligence and rationality factors, was the 
</em><br>
<em>&gt; last place I should have tried such an approach.
</em><br>
<em>&gt;  
</em><br>
<em>&gt; The point I am trying to make . . . . and I thank you for your clear, 
</em><br>
<em>&gt; coherent attempt at eliciting a coherent answer . . . . is that while 
</em><br>
<em>&gt; a super-intelligent computer absolutely WILL break out of an unhelpful 
</em><br>
<em>&gt; loop, it equally absolutely will *NOT* discard a helpful, Friendly, 
</em><br>
<em>&gt; self-improving tool.  Most human beings have */several/* different 
</em><br>
<em>&gt; rudimentary versions of such a tool, hard-wired in mutiple places by 
</em><br>
<em>&gt; evolution because they are strongly pro-survival, which are 
</em><br>
<em>&gt; collectively called ethics (see The Moral Animal by Robert Wright).  
</em><br>
<em>&gt; Unfortunately, because human beings are insufficiently evolved these 
</em><br>
<em>&gt; sense are still under-developed and we do not fully sense that true 
</em><br>
<em>&gt; ethics are *ALWAYS* to our benefit (thereby causing us to ignore that 
</em><br>
<em>&gt; sense at the worst times -- mainly by taking bad short-sighted options 
</em><br>
<em>&gt; over good long-term options because evolution hasn't had the time to 
</em><br>
<em>&gt; optimize *our* ethics for the long-term YET).
</em><br>
<em>&gt;  
</em><br>
<em>&gt; My claim -- and I'm rephrasing it here -- is that ethics is a *tool* 
</em><br>
<em>&gt; that a super-intelligence will never discard and never ignore because 
</em><br>
<em>&gt; it is never in it's self interest to do so BECAUSE ethics ALWAYS tells 
</em><br>
<em>&gt; it where it's best long-term interests lie.  We humans are still too 
</em><br>
<em>&gt; short-sighted to see such a thing.  Or, rather, until now, we haven't 
</em><br>
<em>&gt; discovered an ethical tool sufficient to provide a clear enough sense 
</em><br>
<em>&gt; of ethics that we can &quot;see&quot;/sense/believe the truth of that statement.
</em><br>
<em>&gt;  
</em><br>
<em>&gt; I claim to actually have discovered such a tool.  I am claiming that 
</em><br>
<em>&gt; my approach itself is Seed Friendliness (in the same sense that a Seed 
</em><br>
<em>&gt; AI is a tool to generate a more intelligent AI) -- my approach 
</em><br>
<em>&gt; generates a more Friendly tool which can then generate a more Friendly 
</em><br>
<em>&gt; tool ad infinitum.
</em><br>
<em>&gt;  
</em><br>
<em>&gt; My claim is that ethics is both a belief system and a tool to point 
</em><br>
<em>&gt; the way towards our own self-interest.  If that is a case, any machine 
</em><br>
<em>&gt; (including homo sapiens) is being stupid whenever it drops/ignores our 
</em><br>
<em>&gt; tool which is why a super-intelligence will treasure it, hone it, and 
</em><br>
<em>&gt; always act in accordance with it -- BECAUSE IT KNOWS THAT IT IS ALWAYS 
</em><br>
<em>&gt; IN ITS OWN BEST SELF-INTEREST TO DO SO.
</em><br>
<em>&gt;  
</em><br>
<em>&gt; I just haven't successfully shown you the truth of that fact yet 
</em><br>
<em>&gt; because, while I've discovered a method of really doing so, I realized 
</em><br>
<em>&gt; that the method was unethical without informed consent and I am 
</em><br>
<em>&gt; currently having trouble figuring out how to get informed consent.  
</em><br>
<em>&gt; I'm currently trying to solve that problem off-list with Eliezer and 
</em><br>
<em>&gt; hopefully will get back to y'all shortly.
</em><br>
<em>&gt;  
</em><br>
<em>&gt;         Mark
</em><br>
<p>In my opinion, the best strategy that is in one individual's best 
<br>
self-interest, is to convince everyone else that one's actions are 
<br>
ethical, while at the same time taking advantage (getting much more 
<br>
value for little value -- giving pennies while getting dollars) under 
<br>
cover of ethics.
<br>
<p>I would call it a &quot;win-win ruse&quot;. Convince the other person (or social 
<br>
group, or whatever) that the deal is win-win, when it actually is 
<br>
win-lose. In my opinion, most religions are excellent at practicing the 
<br>
&quot;win-win ruse&quot;.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="18206.html">Lee Corbin: "Re: Similarity of Structure"</a>
<li><strong>Previous message:</strong> <a href="18204.html">Lee Corbin: "Re: Memory Merging Possible For Close Duplicates"</a>
<li><strong>In reply to:</strong> <a href="18201.html">Mark Waser: "Re: Friendliness SOLVED!"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18196.html">Mark Waser: "Re: Friendliness SOLVED!"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18205">[ date ]</a>
<a href="index.html#18205">[ thread ]</a>
<a href="subject.html#18205">[ subject ]</a>
<a href="author.html#18205">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:02 MDT
</em></small></p>
</body>
</html>
