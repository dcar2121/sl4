<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: The GLUT and functionalism</title>
<meta name="Author" content="Lee Corbin (lcorbin@rawbw.com)">
<meta name="Subject" content="Re: The GLUT and functionalism">
<meta name="Date" content="2008-03-25">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: The GLUT and functionalism</h1>
<!-- received="Tue Mar 25 11:25:46 2008" -->
<!-- isoreceived="20080325172546" -->
<!-- sent="Tue, 25 Mar 2008 10:20:54 -0700" -->
<!-- isosent="20080325172054" -->
<!-- name="Lee Corbin" -->
<!-- email="lcorbin@rawbw.com" -->
<!-- subject="Re: The GLUT and functionalism" -->
<!-- id="675f01c88e9c$a7ab8fa0$6401a8c0@homeef7b612677" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="f21c22e30803242352g1785e0ajb5478a0fb35def1f@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Lee Corbin (<a href="mailto:lcorbin@rawbw.com?Subject=Re:%20The%20GLUT%20and%20functionalism"><em>lcorbin@rawbw.com</em></a>)<br>
<strong>Date:</strong> Tue Mar 25 2008 - 11:20:54 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="18315.html">Vladimir Nesov: "Re: Friendliness SOLVED!"</a>
<li><strong>Previous message:</strong> <a href="18313.html">William Pearson: "Re: Hiding AI research from Bad People was Re: OpenCog Concerns"</a>
<li><strong>In reply to:</strong> <a href="18310.html">Stathis Papaioannou: "Re: The GLUT and functionalism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18320.html">Stathis Papaioannou: "Re: The GLUT and functionalism"</a>
<li><strong>Reply:</strong> <a href="18320.html">Stathis Papaioannou: "Re: The GLUT and functionalism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18314">[ date ]</a>
<a href="index.html#18314">[ thread ]</a>
<a href="subject.html#18314">[ subject ]</a>
<a href="author.html#18314">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Stathis writes
<br>
<p><em>&gt; Lee wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;  No, because sufficiently low-level table lookups are just fine. Not
</em><br>
<em>&gt;&gt;  as any kind of estimate to take to the bank, suppose me to be
</em><br>
<em>&gt;&gt;  claiming that when you start looking up bit patches of 10^6 or so
</em><br>
<em>&gt;&gt;  ---or in the inimitable example of a Life Board, a region 1000x1000
</em><br>
<em>&gt;&gt;  ---then a very small diminution of consciousness occurs.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; If consciousness is Turing emulable, then it is GOL emulable.
</em><br>
<p>Surely.
<br>
<p><em>&gt; Suppose we have a large Life Board which is emulating a human mind,
</em><br>
<em>&gt; interfacing with a camera, microphone and loudspeaker so that it has
</em><br>
<em>&gt; vision, hearing and speech. The emulation is shown a picture of a dog
</em><br>
<em>&gt; and asked to describe it, which it does, just as well as you or I
</em><br>
<em>&gt; might.
</em><br>
<p>I do take this as a direct implantation on the Life Board's version
<br>
of our V1 visual processing center.
<br>
<p><em>&gt; Next, a change is made to a patch of the Board so that those
</em><br>
<em>&gt; squares are looked up rather than calculated. This patch is large
</em><br>
<em>&gt; enough that it causes the theorised diminution in conscious
</em><br>
<em>&gt; experience.
</em><br>
<p>Then this is probably not the example you want. If I'm seeing a
<br>
dog and the experimenters who have computer access to my V1
<br>
make a perfect substitute, then naturally I can't even see the 
<br>
difference. The hardest part for us to try to deal with here is
<br>
that starting with V1 and going all &quot;the way up&quot;, there isn't any
<br>
clear dividing line between the person's &quot;mind&quot; and the outside.
<br>
But I still think that you'll have to aim higher  :-)  than V1 here.
<br>
<p><em>&gt; The emulation is still looking at the dog and describing
</em><br>
<em>&gt; what it is seeing as the change is made. What happens?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; If there is a change in consciousness then the emulation notices that
</em><br>
<em>&gt; the picture has suddenly gone blurry, or one of the dog's legs has
</em><br>
<em>&gt; disappeared, or whatever (we can imagine that the looked-up patch
</em><br>
<em>&gt; increases in size until the change in visual perception becomes
</em><br>
<em>&gt; noticeable). So, as per your instructions, the emulation tries to
</em><br>
<em>&gt; report this change.
</em><br>
<p>Well, I don't know what the point is here that you're trying to
<br>
get to. A brutal change is of course going to affect the future
<br>
states of the &quot;subject&quot;.  That is, in the sequence Sa-&gt;Sb-&gt;....
<br>
a sudden substitution of Sm' for Sm may not be alarming to
<br>
the subject---he doesn't know that Sm' was not supposed
<br>
to occur---but as he reports his experiences, presumably, 
<br>
the description becomes different from what it would have been.
<br>
<p><em>&gt; However, there is a problem: the squares on the Board which
</em><br>
<em>&gt; interface with the loudspeaker are *exactly the same* as
</em><br>
<em>&gt; they would have been if the looked-up patch had actually been
</em><br>
<em>&gt; calculated.
</em><br>
<p>Ah, there we go. This is closer to the crux.
<br>
<p><em>&gt; So the emulation would be saying, &quot;It's the same picture
</em><br>
<em>&gt; of a dog, try looking up a larger patch of squares&quot;, while thinking,
</em><br>
<em>&gt; &quot;Oh no, I'm going blind, and my mouth is saying stuff all on its
</em><br>
<em>&gt; own!&quot;.
</em><br>
<p>Oh, wait.  
<br>
<p><em>&gt; But how is this possible unless you posit a disembodied soul,
</em><br>
<em>&gt; which becomes decoupled from the emulation and goes on to
</em><br>
<em>&gt; have its own separate thoughts?
</em><br>
<p>Of course. There are no souls, and if you perfectly substitute
<br>
an entirely different set of pixel values over some region of
<br>
the board, the calculation nonetheless proceeds exactly as
<br>
before.
<br>
<p><em>&gt; The other possibility is that there is a change to visual perception
</em><br>
<em>&gt; which is not actually noticed. When all the squares relating to visual
</em><br>
<em>&gt; perception are looked up the emulation becomes blind, but it doesn't
</em><br>
<em>&gt; realise it's blind and continues to accurately describe what is shown
</em><br>
<em>&gt; to it, using zombie vision. This is almost as implausible, and begs
</em><br>
<em>&gt; the question of what it means to perceive something.
</em><br>
<p>I totally agree. Such a distinction is beneath you and me :-)
<br>
<p>As I say, *all* my visual inputs could be looked up rather than
<br>
faithfully passed in by my retina along all those nerve fibers.
<br>
Naturally I'd never know, (unless what I was seeing was starting
<br>
to clash with my other senses). 
<br>
<p><em>&gt; The above is a variation on Chalmers' &quot;Fading Qualia&quot; argument:
</em><br>
<p>I think that Chalmers almost by definition can never find what he
<br>
is looking for, because any explanation would fail to satisfy him
<br>
either for one reason, or if that doesn't work, then a new one.
<br>
I'm afraid that an explanation would have to *make* Chalmers
<br>
feel conscious, or feel an experience.
<br>
<p>Extremely hypothetical guess:  if you took the set of all 26^500
<br>
explanations of 500 characters in length, not one of them would
<br>
satisfy those who insist that there is an insoluble  mystery to the matter.
<br>
<p>Lee
<br>
<p><em>&gt; <a href="http://consc.net/papers/qualia.html">http://consc.net/papers/qualia.html</a>
</em><br>
<em>&gt; 
</em><br>
<em>&gt; (I might add that many cognitive scientists don't like Chalmers due to
</em><br>
<em>&gt; his insistence that there is a &quot;hard problem&quot; of consciousness, but in
</em><br>
<em>&gt; actual fact, he is mostly an orthodox computationalist, and the above
</em><br>
<em>&gt; paper probably presents the strongest case for consciousness surviving
</em><br>
<em>&gt; neural replacement scenarios.)
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="18315.html">Vladimir Nesov: "Re: Friendliness SOLVED!"</a>
<li><strong>Previous message:</strong> <a href="18313.html">William Pearson: "Re: Hiding AI research from Bad People was Re: OpenCog Concerns"</a>
<li><strong>In reply to:</strong> <a href="18310.html">Stathis Papaioannou: "Re: The GLUT and functionalism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18320.html">Stathis Papaioannou: "Re: The GLUT and functionalism"</a>
<li><strong>Reply:</strong> <a href="18320.html">Stathis Papaioannou: "Re: The GLUT and functionalism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18314">[ date ]</a>
<a href="index.html#18314">[ thread ]</a>
<a href="subject.html#18314">[ subject ]</a>
<a href="author.html#18314">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:02 MDT
</em></small></p>
</body>
</html>
