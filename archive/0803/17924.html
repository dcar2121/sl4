<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: A formal measure of subjective experience</title>
<meta name="Author" content="Matt Mahoney (matmahoney@yahoo.com)">
<meta name="Subject" content="Re: A formal measure of subjective experience">
<meta name="Date" content="2008-03-10">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: A formal measure of subjective experience</h1>
<!-- received="Mon Mar 10 15:03:10 2008" -->
<!-- isoreceived="20080310210310" -->
<!-- sent="Mon, 10 Mar 2008 14:00:55 -0700 (PDT)" -->
<!-- isosent="20080310210055" -->
<!-- name="Matt Mahoney" -->
<!-- email="matmahoney@yahoo.com" -->
<!-- subject="Re: A formal measure of subjective experience" -->
<!-- id="472372.11238.qm@web51904.mail.re2.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="b7a9e8680803091826p6c178c17j5070c94418d0d535@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Matt Mahoney (<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20A%20formal%20measure%20of%20subjective%20experience"><em>matmahoney@yahoo.com</em></a>)<br>
<strong>Date:</strong> Mon Mar 10 2008 - 15:00:55 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17925.html">John K Clark: "Re: Is a Person One or Many?"</a>
<li><strong>Previous message:</strong> <a href="17923.html">Heartland: "Re: Is a Person One or Many?"</a>
<li><strong>In reply to:</strong> <a href="17895.html">Thomas McCabe: "Re: A formal measure of subjective experience"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17924">[ date ]</a>
<a href="index.html#17924">[ thread ]</a>
<a href="subject.html#17924">[ subject ]</a>
<a href="author.html#17924">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- Thomas McCabe &lt;<a href="mailto:pphysics141@gmail.com?Subject=Re:%20A%20formal%20measure%20of%20subjective%20experience">pphysics141@gmail.com</a>&gt; wrote:
<br>
<p><em>&gt; A great deal needs to be said here, but I'll just hit the high points.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; On Sun, Mar 9, 2008 at 4:15 PM, Matt Mahoney &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20A%20formal%20measure%20of%20subjective%20experience">matmahoney@yahoo.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt; I propose the following formal measure of subjective experience.  The
</em><br>
<em>&gt; &gt;  experience of an agent observing event X is K(S2|S1) where S1 is the
</em><br>
<em>&gt; state of
</em><br>
<em>&gt; &gt;  the agent before observing X, S2 is the state afterwards, and K is
</em><br>
<em>&gt; Kolmogorov
</em><br>
<em>&gt; &gt;  complexity.  In other words, the subjective experience is measured by the
</em><br>
<em>&gt; &gt;  length of the shortest program that inputs a description of S1 and
</em><br>
<em>&gt; outputs a
</em><br>
<em>&gt; &gt;  description of S2.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &quot;Subjective experience&quot; is an ill-defined concept (see
</em><br>
<em>&gt; <a href="http://www.overcomingbias.com/2008/03/wrong-questions.html">http://www.overcomingbias.com/2008/03/wrong-questions.html</a>), and we
</em><br>
<em>&gt; could argue about it for thousands of years and never get anywhere.
</em><br>
<em>&gt; Isn't this exactly what philosophers have been doing, ever since the
</em><br>
<em>&gt; days of ancient Greece?
</em><br>
<p>Your concerns are valid.  It is what happens when I try to formalize something
<br>
that doesn't exist.
<br>
<p><em>&gt; &gt;  Conditional Kolmogorov complexity is therefore one possible measure.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; K complexity is hardly a sufficient metric for nontrivial properties
</em><br>
<em>&gt; of Turing machines! Consider all Turing machines with n or fewer
</em><br>
<em>&gt; states acting on a blank tape. The number of possible Turing machines
</em><br>
<em>&gt; increases with C^N, so the number of possible nontrivial properties of
</em><br>
<em>&gt; Turing machines increases with C1^C2^N (see
</em><br>
<em>&gt; <a href="http://www.overcomingbias.com/2008/02/superexp-concep.html">http://www.overcomingbias.com/2008/02/superexp-concep.html</a>). K
</em><br>
<em>&gt; complexity, meanwhile, increases with N. The amount of information
</em><br>
<em>&gt; conveyable with K goes with log(N); the amount of information needed
</em><br>
<em>&gt; as a metric for an arbitrary nontrivial property goes with
</em><br>
<em>&gt; log(C1^C2^N) = C^N.
</em><br>
<p>This is why we need inductive bias.  A complexity measure is simple, therefore
<br>
appealing (as justified by AIXI).  It allows for mathematical analysis.
<br>
<p><em>&gt; &gt;  Applications.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;  Some people believe that it is unethical to harm (kill or decrease
</em><br>
<em>&gt; utility of)
</em><br>
<em>&gt; &gt;  agents that have subjective experience.  I do not take a position on this
</em><br>
<em>&gt; &gt;  issue, but if we assume it is true, then:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Beware using one Really Great Idea to explain absolutely everything
</em><br>
<em>&gt; (<a href="http://www.overcomingbias.com/2007/12/affective-death.html">http://www.overcomingbias.com/2007/12/affective-death.html</a>). Human
</em><br>
<em>&gt; morality is much more complex than this
</em><br>
<em>&gt; (<a href="http://www.overcomingbias.com/2007/11/thou-art-godsha.html">http://www.overcomingbias.com/2007/11/thou-art-godsha.html</a>).
</em><br>
<p>As I said, I don't assert that this model of ethics is correct.
<br>
<p><em>&gt; &gt;  A data compression program like zip has subjective experience in all 3
</em><br>
<em>&gt; modes
</em><br>
<em>&gt; &gt;  that humans do.  A compressor accepts a sequence of symbols from an
</em><br>
<em>&gt; unknown
</em><br>
<em>&gt; &gt;  source and has the task of predicting future symbols so that it can
</em><br>
<em>&gt; assign
</em><br>
<em>&gt; &gt;  shorter codes to the most likely symbols.  It has procedural memory
</em><br>
<em>&gt; because
</em><br>
<em>&gt; &gt;  after each event (observing symbol X in some context), it raises the
</em><br>
<em>&gt; &gt;  probability that X will occur next time the same context is observed.  It
</em><br>
<em>&gt; has
</em><br>
<em>&gt; &gt;  episodic memory because decompression recalls the exact sequence of
</em><br>
<em>&gt; events.
</em><br>
<em>&gt; &gt;  It undergoes reinforcement learning with a utility function equal to the
</em><br>
<em>&gt; &gt;  negative of the length of the compressed output.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I haven't studied compression algorithms extensively, but you seem to
</em><br>
<em>&gt; be playing fast and loose with the idea of &quot;memory&quot; and &quot;utility
</em><br>
<em>&gt; function&quot; here. Compression algorithms, so far as I know, have no
</em><br>
<em>&gt; explicit utility functions, and at least one (LZW) has no explicit
</em><br>
<em>&gt; representation of probability.
</em><br>
<p>LZW represents probability implicitly.  It maintains a dictionary of phrases
<br>
which are used to replace matches in the input with dictionary codes.  Its
<br>
implicit model, which includes a policy for adding and removing phrases, is
<br>
that all phrases are equally likely.  You could still write an equivalent (but
<br>
less efficient) algorithm in the style of more advanced compressors that
<br>
explicitly separate modeling from coding.
<br>
<p>Reinforcement learning stops looking like a utility function when you
<br>
understand the algorithm.  For example, a thermostat looks like it has a goal
<br>
of keeping the room at a set temperature, until you look inside it.
<br>
<p>I use data compression as an example because it is AI-complete.  It is easier
<br>
to see the similarities to human intelligence.
<br>
<a href="http://cs.fit.edu/~mmahoney/compression/rationale.html">http://cs.fit.edu/~mmahoney/compression/rationale.html</a>
<br>
<p><p><em>&gt; There's a big distinction between K complexity and bits of memory in
</em><br>
<em>&gt; the normal sense. Assuming that the universe is a closed
</em><br>
<em>&gt; Turing-computable system, it cannot have a K complexity significantly
</em><br>
<em>&gt; higher than the K complexity at the time of the Big Bang.
</em><br>
<p>Parts of the universe are more complex than the whole because you need to
<br>
specify the boundaries.
<br>
<p>For example &quot;enumerate all universes until intelligent life is found&quot; is very
<br>
simple.  Specifying the one we live in takes a few hundred more bits.
<br>
<p><p><p>-- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20A%20formal%20measure%20of%20subjective%20experience">matmahoney@yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17925.html">John K Clark: "Re: Is a Person One or Many?"</a>
<li><strong>Previous message:</strong> <a href="17923.html">Heartland: "Re: Is a Person One or Many?"</a>
<li><strong>In reply to:</strong> <a href="17895.html">Thomas McCabe: "Re: A formal measure of subjective experience"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17924">[ date ]</a>
<a href="index.html#17924">[ thread ]</a>
<a href="subject.html#17924">[ subject ]</a>
<a href="author.html#17924">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:02 MDT
</em></small></p>
</body>
</html>
