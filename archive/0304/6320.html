<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Me, Myself, and I (was: Rationalizing Suffering)</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Me, Myself, and I (was: Rationalizing Suffering)">
<meta name="Date" content="2003-04-02">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Me, Myself, and I (was: Rationalizing Suffering)</h1>
<!-- received="Wed Apr  2 13:28:21 2003" -->
<!-- isoreceived="20030402202821" -->
<!-- sent="Wed, 02 Apr 2003 15:28:24 -0500" -->
<!-- isosent="20030402202824" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Me, Myself, and I (was: Rationalizing Suffering)" -->
<!-- id="3E8B47E8.3050101@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="004001c2f93c$a3fbb010$ca12a8c0@MWASER01" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Me,%20Myself,%20and%20I%20(was:%20Rationalizing%20Suffering)"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Wed Apr 02 2003 - 13:28:24 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="6321.html">Mark Waser: "Re: Emulated Realities (was Re: Rationalizing Suffering)"</a>
<li><strong>Previous message:</strong> <a href="6319.html">jasonjoachim: "Re: Collapsarity"</a>
<li><strong>In reply to:</strong> <a href="6313.html">Mark Waser: "Rationalizing Suffering"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6323.html">Lee Corbin: "RE: Me, Myself, and I (was: Rationalizing Suffering)"</a>
<li><strong>Reply:</strong> <a href="6323.html">Lee Corbin: "RE: Me, Myself, and I (was: Rationalizing Suffering)"</a>
<li><strong>Reply:</strong> <a href="6326.html">Emil Gilliam: "Re: Me, Myself, and I (was: Rationalizing Suffering)"</a>
<li><strong>Reply:</strong> <a href="6327.html">Samantha Atkins: "Re: Me, Myself, and I (was: Rationalizing Suffering)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6320">[ date ]</a>
<a href="index.html#6320">[ thread ]</a>
<a href="subject.html#6320">[ subject ]</a>
<a href="author.html#6320">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Mark Waser wrote:
<br>
<em>&gt; Lee Corbin wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;&gt;&quot;But as for being morally &quot;okay&quot;, no, suffering of any form is
</em><br>
<em>&gt; 
</em><br>
<em>&gt; inadmissible (contradicting rationalizations for suffering in another
</em><br>
<em>&gt; thread), including our displeasure at having apparently undergone sorrow.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I just have to jump in here . . . .
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Suppose I'm playing a fantasy role-playing game (Dungeons &amp; Dragons or
</em><br>
<em>&gt; something similar) and one of my characters dies a horrible death.  Is this
</em><br>
<em>&gt; morally wrong?
</em><br>
<p>No.  I am reasonably certain that fictionally imagined characters don't 
<br>
have qualia.  I'm in really, really deep trouble if they do.
<br>
<p><em>&gt; Suppose it's twenty years in the future and I'm playing the newest total
</em><br>
<em>&gt; immersion version of this game.  I'm booted out of the game once it's
</em><br>
<em>&gt; apparent that my character is about to die horribly but everyone else &quot;sees&quot;
</em><br>
<em>&gt; me die horribly.  Is this morally wrong?
</em><br>
<p>No.  No qualia.
<br>
<p><em>&gt; Suppose that for the excitement/thrill/entertainment or for some learning
</em><br>
<em>&gt; experience that I'm willing to accept experiencing some shadow of that
</em><br>
<em>&gt; horrible death.  It won't kill me or permanently damage me but it will allow
</em><br>
<em>&gt; me to stay in the game until the last possible instant, try to strive to
</em><br>
<em>&gt; accomplish nearly impossible things, have a great and realistic death scene,
</em><br>
<em>&gt; etc.  Is this morally wrong?  There's certainly might be (minor) suffering
</em><br>
<em>&gt; involved here but it's suffering that I've chosen . . . .
</em><br>
<p>I might perhaps advise against it, or try in my personal capacity to 
<br>
persuade you not to do it, but I would not regard it as permissible to try 
<br>
and prevent it by force.
<br>
<p><em>&gt; Suppose that for the ultimate in realism and to truly &quot;live the game&quot;, I've
</em><br>
<em>&gt; decided to accept the temporary blockage of all outside-game knowledge.
</em><br>
<em>&gt; Until I &quot;die&quot; inside the game, I won't remember/know about anything outside
</em><br>
<em>&gt; the game but once I &quot;die&quot;, I will go on living my normal life outside the
</em><br>
<em>&gt; game.  Is this morally wrong (Assume that we're advanced enough that there
</em><br>
<em>&gt; is no way in which in-game events can harm, much less traumatize, my
</em><br>
<em>&gt; outside-game self)?
</em><br>
<p>Yes, because &quot;you&quot; and &quot;you with your memories elided&quot; are *two different 
<br>
people* - your future self is a different person, for purposes of 
<br>
volition, than your past self.  The past you that decided to have its 
<br>
memories elided is not the you who suffers and says &quot;Let me out!&quot; 
<br>
Furthermore, once the present-day you has been immediately extracted from 
<br>
the simulation in accordance with his volition, there is no reason why the 
<br>
elided memories should be &quot;reloaded&quot; (perhaps effectively killing the new 
<br>
you) unless you consent to it.  Having your memories elided is a one-way 
<br>
trip unless the new you decides to accept them back, and certainly you 
<br>
can't make decisions for your elided self.
<br>
<p><em>&gt; Note: This can also explain Eliezer's asking to be let out of the &quot;sim&quot; but
</em><br>
<em>&gt; apparently not being let out in at least three different ways:
</em><br>
<em>&gt;     a) he left instructions not to be let out
</em><br>
<p>What do I care what my old self did?  I am Eliezer now.
<br>
<p><em>&gt;     b) the instant he got out, he asked to be returned with no in-game time
</em><br>
<em>&gt; elapsed and all memories erased again
</em><br>
<p>&quot;Erased again&quot;?  Who said anything about asking for the memories back?  I 
<br>
might be interested in looking them over, but whoever I am now, my 
<br>
motivations are those of Eliezer, and *I* wouldn't play the video game of 
<br>
me.  I am not interested in having my motivations overwritten by those of 
<br>
someone who is clearly so different from me, even if it's myself.
<br>
<p><em>&gt;     c) someone else is now playing the character &quot;Eliezer&quot;
</em><br>
<p>Er... &quot;someone else&quot;... um... okay, that's rather an interesting statement 
<br>
from my perspective.
<br>
<p><em>&gt; I must admit that I don't see any way in which it can be proved to me that
</em><br>
<em>&gt; I'm not living in a sim.  All the research on vision which has recently been
</em><br>
<em>&gt; referenced here clearly shows that we don't even really see what we think we
</em><br>
<em>&gt; see.  I think that Boostrom's requirements for a simulation are way, WAY
</em><br>
<em>&gt; higher than they need to be because we don't experience/know anywhere near
</em><br>
<em>&gt; what we believe we experience/know (particularly if I/you are in a
</em><br>
<em>&gt; individual/solipsistic sim where everyone else is either programmed or knows
</em><br>
<em>&gt; about the sim and is manipulating it).  And I know that there are all sorts
</em><br>
<em>&gt; of reasons why I would be willing to be placed in the last scenario since I
</em><br>
<em>&gt; could easily imagine it as the method by which an advanced civilization
</em><br>
<em>&gt; investigates other possibilities or even might teach their children.
</em><br>
<p>But wouldn't you have decided to play Darwin or Gandhi rather than Mark Waser?
<br>
<p><em>&gt; But, the final point which I wish to stress, however, is that while arguing
</em><br>
<em>&gt; about whether or not we are in a sim is amusing . . . . ultimately, if the
</em><br>
<em>&gt; sim is to be of any value, we must behave as if we are not in a sim.
</em><br>
<em>&gt; Suffering (or, at least, senseless suffering and senseless deaths) cannot be
</em><br>
<em>&gt; rationalized from OUR perspective and we need to strive against it with all
</em><br>
<em>&gt; our might.
</em><br>
<p>If I could know this was a sim via a method of knowledge that definitely 
<br>
discriminated between simulated Eliezers and planetary-evolved Eliezers, I 
<br>
would behave very differently; I would start looking for a girlfriend, for 
<br>
example.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="6321.html">Mark Waser: "Re: Emulated Realities (was Re: Rationalizing Suffering)"</a>
<li><strong>Previous message:</strong> <a href="6319.html">jasonjoachim: "Re: Collapsarity"</a>
<li><strong>In reply to:</strong> <a href="6313.html">Mark Waser: "Rationalizing Suffering"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6323.html">Lee Corbin: "RE: Me, Myself, and I (was: Rationalizing Suffering)"</a>
<li><strong>Reply:</strong> <a href="6323.html">Lee Corbin: "RE: Me, Myself, and I (was: Rationalizing Suffering)"</a>
<li><strong>Reply:</strong> <a href="6326.html">Emil Gilliam: "Re: Me, Myself, and I (was: Rationalizing Suffering)"</a>
<li><strong>Reply:</strong> <a href="6327.html">Samantha Atkins: "Re: Me, Myself, and I (was: Rationalizing Suffering)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6320">[ date ]</a>
<a href="index.html#6320">[ thread ]</a>
<a href="subject.html#6320">[ subject ]</a>
<a href="author.html#6320">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:42 MDT
</em></small></p>
</body>
</html>
