<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Curriculum for AI</title>
<meta name="Author" content="Colin Hales (colin@versalog.com.au)">
<meta name="Subject" content="RE: Curriculum for AI">
<meta name="Date" content="2003-01-01">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Curriculum for AI</h1>
<!-- received="Wed Jan  1 05:19:33 2003" -->
<!-- isoreceived="20030101121933" -->
<!-- sent="Wed, 1 Jan 2003 23:13:21 +1100" -->
<!-- isosent="20030101121321" -->
<!-- name="Colin Hales" -->
<!-- email="colin@versalog.com.au" -->
<!-- subject="RE: Curriculum for AI" -->
<!-- id="002101c2b18f$2dee5930$0100a8c0@Pc2" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="LAEGJLOGJIOELPNIOOAJOEMLEAAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Colin Hales (<a href="mailto:colin@versalog.com.au?Subject=RE:%20Curriculum%20for%20AI"><em>colin@versalog.com.au</em></a>)<br>
<strong>Date:</strong> Wed Jan 01 2003 - 05:13:21 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="6042.html">Colin Hales: "RE: Another Take on the Fermi Paradox"</a>
<li><strong>Previous message:</strong> <a href="../0212/6040.html">Eliezer S. Yudkowsky: "The thermodynamic New Year"</a>
<li><strong>In reply to:</strong> <a href="../0212/6036.html">Ben Goertzel: "RE: Curriculum for AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6045.html">Michael Roy Ames: "Re: Curriculum for AI"</a>
<li><strong>Reply:</strong> <a href="6045.html">Michael Roy Ames: "Re: Curriculum for AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6041">[ date ]</a>
<a href="index.html#6041">[ thread ]</a>
<a href="subject.html#6041">[ subject ]</a>
<a href="author.html#6041">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Goertzel:
<br>
<em>&gt;
</em><br>
<em>&gt; Gordon Worley wrote:
</em><br>
<em>&gt; &gt; Going to four levels of learning doesn't make any sense, anyway.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; First, let's subtract 1 from all of those levels; it's a
</em><br>
<em>&gt; bit easier to
</em><br>
<em>&gt; &gt; keep track of them then.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; At level 0 there is no learning involved, per se.  The mind is just
</em><br>
<em>&gt; &gt; being force fed facts:  they magically appear in its memory.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; At level 1 there is normally learning involved that we are
</em><br>
<em>&gt; all familiar
</em><br>
<em>&gt; &gt; with.  It's the kind that goes on between children and
</em><br>
<em>&gt; parents, goes on
</em><br>
<em>&gt; &gt; while reading, and goes on in schools (or at least is supposed to).
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Level 2 is more interesting.  This is where you learn
</em><br>
<em>&gt; techniques like
</em><br>
<em>&gt; &gt; associating memories with each other to strengthen your ability to
</em><br>
<em>&gt; &gt; remember them and that practice helps you get better at
</em><br>
<em>&gt; complex tasks
</em><br>
<em>&gt; &gt; like algebra and calculus.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Level 3 is flat out exciting.  Now you can learn to learn
</em><br>
<em>&gt; better.  If
</em><br>
<em>&gt; &gt; you can't understand the theory of Friendly AI, all you
</em><br>
<em>&gt; have to do is
</em><br>
<em>&gt; &gt; reprogram yourself to be able to learn it.  It goes further
</em><br>
<em>&gt; than that,
</em><br>
<em>&gt; &gt; though.  At this level you already get the ability to reprogram
</em><br>
<em>&gt; &gt; yourself to reprogram yourself better.  You're working at that level
</em><br>
<em>&gt; &gt; already, so it's no problem to just jump over and rewrite
</em><br>
<em>&gt; the running
</em><br>
<em>&gt; &gt; code (assuming the system supports it, but in the general case it's
</em><br>
<em>&gt; &gt; already available).
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; If a level 4 exists, this would be extending to ontotechnology but
</em><br>
<em>&gt; &gt; would be debatable to continue to think of this in terms of
</em><br>
<em>&gt; levels of
</em><br>
<em>&gt; &gt; learning.  That would certainly still be an applicable domain, but
</em><br>
<em>&gt; &gt; things were already starting to open up at level 3 and the seams are
</em><br>
<em>&gt; &gt; busted wide open at level 4.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Bateson reckons that level 3 learning occurs in humans only
</em><br>
<em>&gt; very slowly,
</em><br>
<em>&gt; i.e. over years via complex forms of &quot;cognitive maturation.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Basically, your comments are strongly in accordance with Bateson's
</em><br>
<em>&gt; reflections on the topic, which is not surprising...
</em><br>
<em>&gt;
</em><br>
<em>&gt; -- Ben G
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<p>I know nothing of Bateson. Sounds worth a look. I hadn't actually found
<br>
anyone talking like this although I expected it to be somewhere...nothing
<br>
new under the sun and all that.
<br>
<p><em>&gt; Humans would fail a test suite created for dolphins, and vice versa --
</em><br>
etc.
<br>
<em>&gt; etc. etc.
</em><br>
<em>&gt; I note that IQ tests, SAT tests, and the like, do not take explicit
</em><br>
account
<br>
<em>&gt; of embodiment.
</em><br>
<p>It's assumed as human I suppose. When we talk about this kind of
<br>
classification we're really talking 'species', aren't we? Human is not like
<br>
dog training is not like rat training. In a future world populated with
<br>
various AI 'species' we're going to have to deal with appropriate training
<br>
for each. We have a new taxonomy/morphology to define without the biological
<br>
constraints to help. We have to find the hidden othogonal axes in the
<br>
biological vector space of classification, add new non-biological axes (eg
<br>
groundedness), place the species in that space and then we train and test to
<br>
suit. Sounds like a new industry - work out the AI speciation tree.
<br>
<p><em>&gt; I think that tests involving embodiment are interesting.  But I don't
</em><br>
think
<br>
<em>&gt; that a test NOT involving embodiment is intrinsically inapplicable to
</em><br>
<em>&gt; embodied AI's.
</em><br>
<em>&gt; Indeed, if the &quot;embodiment is necessary for AI&quot; theory is correct, then
</em><br>
<em>&gt; embodied AI's should do far better on tests NOT involving embodiment in
</em><br>
any
<br>
<em>&gt; explicit way.  No?
</em><br>
<p>If you mean an AI trained embodied, subsequently disembodied and then tested
<br>
against another AI somehow trained without embodiment in the same thing -
<br>
yes.
<br>
<p>Maybe the whole embodiment discussion stemmed from not understanding which
<br>
meta-learning level any particular AI occupies and the target environment of
<br>
the AI (incl groundedness issues). IMO level 2 embodiment is mandatory.
<br>
However, I can see it possible that an intended 'level 2' AI could become,
<br>
in effect, relegated to 'level 1' by embodiment, substrate and grounding
<br>
choices. Eg The poor AI actually needs rote learning and gets a montessori
<br>
environment - tough ask! (is NOMAD in this position?). I can also see a well
<br>
implemented level 1 outperforming a poor level 2. An interesting problem
<br>
domain indeed. I'm fairly sure 'meta-learning level' is one of the
<br>
orthogonal axes mentioned above.
<br>
<p>With this and Ben's suggested training options, I think we've probably
<br>
complicated Michael's training program enough now! :-) BTW: Apologies to
<br>
Peter if I &quot;hath projected too much&quot; (from my ken of his AGI) in my original
<br>
post.
<br>
<p>cheers,
<br>
<p>Colin Hales
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="6042.html">Colin Hales: "RE: Another Take on the Fermi Paradox"</a>
<li><strong>Previous message:</strong> <a href="../0212/6040.html">Eliezer S. Yudkowsky: "The thermodynamic New Year"</a>
<li><strong>In reply to:</strong> <a href="../0212/6036.html">Ben Goertzel: "RE: Curriculum for AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6045.html">Michael Roy Ames: "Re: Curriculum for AI"</a>
<li><strong>Reply:</strong> <a href="6045.html">Michael Roy Ames: "Re: Curriculum for AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6041">[ date ]</a>
<a href="index.html#6041">[ thread ]</a>
<a href="subject.html#6041">[ subject ]</a>
<a href="author.html#6041">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:41 MDT
</em></small></p>
</body>
</html>
