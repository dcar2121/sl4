<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: JOIN</title>
<meta name="Author" content="maru dubshinki (marudubshinki@gmail.com)">
<meta name="Subject" content="Re: JOIN">
<meta name="Date" content="2006-09-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: JOIN</h1>
<!-- received="Wed Sep 20 13:39:05 2006" -->
<!-- isoreceived="20060920193905" -->
<!-- sent="Wed, 20 Sep 2006 15:37:49 -0400" -->
<!-- isosent="20060920193749" -->
<!-- name="maru dubshinki" -->
<!-- email="marudubshinki@gmail.com" -->
<!-- subject="Re: JOIN" -->
<!-- id="f5238c30609201237j70b6d2e2g54d9e5e9a765632d@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="28553f510609200551n568b167ub752aed02604807e@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> maru dubshinki (<a href="mailto:marudubshinki@gmail.com?Subject=Re:%20JOIN"><em>marudubshinki@gmail.com</em></a>)<br>
<strong>Date:</strong> Wed Sep 20 2006 - 13:37:49 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16020.html">Russell Wallace: "Re: JOIN"</a>
<li><strong>Previous message:</strong> <a href="16018.html">ps udoname: "Re: JOIN"</a>
<li><strong>In reply to:</strong> <a href="16018.html">ps udoname: "Re: JOIN"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16020.html">Russell Wallace: "Re: JOIN"</a>
<li><strong>Reply:</strong> <a href="16020.html">Russell Wallace: "Re: JOIN"</a>
<li><strong>Reply:</strong> <a href="16041.html">ps udoname: "Re: JOIN"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16019">[ date ]</a>
<a href="index.html#16019">[ thread ]</a>
<a href="subject.html#16019">[ subject ]</a>
<a href="author.html#16019">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 9/20/06, ps udoname &lt;<a href="mailto:ps.udoname@gmail.com?Subject=Re:%20JOIN">ps.udoname@gmail.com</a>&gt; wrote:
<br>
<em>&gt;  True, I did not mean that quantum effects would make AI impossible, but
</em><br>
<em>&gt; what it would mean is that work on how to program AI on a classical computer
</em><br>
<em>&gt; might not translate to how to create an AI that uses these quantum effects.
</em><br>
<em>&gt;  Secondly creating the hardware for an AI would be harder if Penrose is
</em><br>
<em>&gt; right, as microtubules are far more complex then other theories of how
</em><br>
<em>&gt; neurones work. This means that AI and uploading come later and so DNI,
</em><br>
<em>&gt; nanotech etc come first, which means we have to worry about grey goo etc.
</em><br>
<p>Well, again, I think you're being overly pessimistic here. From what I
<br>
know of quantum computing, it works really really well for a narrow
<br>
set of problems (looking at Wikipedia's list of &quot;factoring, discrete
<br>
logarithm, and quantum physics simulations&quot; seems about right). Now,
<br>
if Penrose is right, the third problem set would be useful, but I just
<br>
don't see a great boost to AI programs being given by the first two.
<br>
In other words, to me it looks like AI is going to include great gobs
<br>
of classical AI and computing.
<br>
<p><em>&gt;  It's good to see that thought is going into this. However some things worry
</em><br>
<em>&gt; me (and I have looked at the PAQ's but i'm still not happy)
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;The worrying question is: What if only 20% of the planetary population is
</em><br>
<em>&gt; nice, or cares about niceness, or falls into the niceness attractor when
</em><br>
<em>&gt; their volition is extrapolated?&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt;  &quot;If I later find I'm one of the 5% of humanity whose personal philosophies
</em><br>
<em>&gt; predictably work out to pure libertarianism, and I threw away my one chance
</em><br>
<em>&gt; to free humanity - the hell with it.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt;  Yep, assuming humanity as a whole is capable of making good choices in a
</em><br>
<em>&gt; bad idea I think, as shown by all the things democratises have done in the
</em><br>
<em>&gt; past which we find repugnant today. Taking account of volition helps this,
</em><br>
<em>&gt; hopefully democracy based on volition would never have had slavery for
</em><br>
<em>&gt; instance.
</em><br>
<em>&gt;  However, given the number of Christians in the world, what if the world
</em><br>
<em>&gt; falls into a Christianity attractor for instance? (Just an example, I don't
</em><br>
<em>&gt; mean that Christianity is the ultimate evil)
</em><br>
<em>&gt;
</em><br>
<em>&gt;  &quot;The reason for the collective dynamic is that you can go collective -&gt;
</em><br>
<em>&gt; individual, but not the other way 'round. If you could go individual -&gt;
</em><br>
<em>&gt; collective but not collective -&gt; individual, I'd advocate an individual
</em><br>
<em>&gt; dynamic.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt;  Why can it not go the other way round? If collective is fundamentally the
</em><br>
<em>&gt; right way, I would assume that if everyone kept growing mentally eventually
</em><br>
<em>&gt; all individuals would elect to join the collective.
</em><br>
<em>&gt;
</em><br>
<em>&gt;  &quot;What about infants? What about brain-damage cases? What about people with
</em><br>
<em>&gt; Alzheimer's disease?&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt;  Wouldn't the long term extrapolated volition of an infant be the same as
</em><br>
<em>&gt; the long term extrapolated volition of an adult?
</em><br>
<em>&gt;
</em><br>
<em>&gt;  &quot;Maybe everyone wearing a Japanese schoolgirl uniform at the time of
</em><br>
<em>&gt; Singularity will be attacked by tentacle monsters.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt;  WTF?
</em><br>
<p>...It's humor, mon. You're supposed to laugh. Admittedly, it's fairly
<br>
geeky and turn of the century humor, but still fairly normal.
<br>
<p><em>&gt;  Do they want to be attacked? If not, it's a good argument against
</em><br>
<em>&gt; collective volition.
</em><br>
<p>Perhaps they really enjoy it. The point is that from our limited
<br>
perspective it is hard to tell: I remember being a child and being
<br>
disgusted by the mere suggestion of kissing.
<br>
<p><em>&gt;  In general, I would far prefer Individual volition, because I trust my
</em><br>
<em>&gt; volition, but not the rest of humanity's.
</em><br>
<em>&gt;
</em><br>
<em>&gt;  Also, am I correct in understanding that the volition of non-human
</em><br>
<em>&gt; sentients does not count?
</em><br>
.....
<br>
<em>&gt; &gt; Long story short, not giving the AI direct control over anything would
</em><br>
<em>&gt; &gt; probably only work in the early stages and so would be of minimal use.
</em><br>
<em>&gt; &gt; Ditto for the big off button.
</em><br>
<em>&gt;
</em><br>
<em>&gt;  I realise it might only work in the early stages, but that could still be
</em><br>
<em>&gt; useful.
</em><br>
<em>&gt;
</em><br>
<em>&gt;  The links are worrying and very surprising, especially as a real AI could
</em><br>
<em>&gt; be far better at persuading people to let them out. Perhaps AI boxing is a
</em><br>
<em>&gt; bad idear in view of that.
</em><br>
<em>&gt;  I would like to take part in an AI boxing experiment sometime.
</em><br>
<p>Good luck. I think Eliezer is sick of doing them, so you'll have to
<br>
look for someone else.
<br>
<p><em>&gt; &gt; Uploading brains doesn't seem to be a popular suggestion on this list
</em><br>
<em>&gt; &gt; either, since their reasoning goes that humans are not the stablest
</em><br>
<em>&gt; &gt; and sanest mentalities you can get, and would probably become
</em><br>
<em>&gt; &gt; unfriendly in an upload.
</em><br>
<em>&gt;
</em><br>
<em>&gt;  By 'bootstrapping' I didn't just mean uploading but also DNI and all forms
</em><br>
<em>&gt; of intelligence enhancement, some of which will come before AI. I think AI
</em><br>
<em>&gt; will come before uploading, as  it must be easier to reverse engineer a
</em><br>
<em>&gt; generic brain then upload a specific person. However this would not
</em><br>
<em>&gt; necessarily mean FAI comes before uploading.
</em><br>
<em>&gt;  I realise humans are likely to be fairly unfriendly. The best thing to do
</em><br>
<em>&gt; would be to bootstrap as many as possible simultaneously. They would not
</em><br>
<em>&gt; fight each other because of game theory (I hope). Then you would have to
</em><br>
<em>&gt; hope that at least one of the people bootstrapped would be friendly enough
</em><br>
<em>&gt; to upload everyone else.
</em><br>
<p>I'm not following how game theory would help here. If anything, I'd
<br>
think that multiple uploads would be even worse - the pressures for
<br>
preemptive strikes/defections would be overpowering: suppose one were
<br>
an upload and decided to go slow since there is no need to rush to get
<br>
in the capabilities to take out all the other uploads. Isn't it
<br>
obvious that such a strategy would play right into the hands of the
<br>
few bad apples, who could so rush and then obliterate the others? So
<br>
even the Friendly ones would be forced to rush into transcendence or
<br>
whatever just to thwart the possible unFriendly ones. And if two
<br>
managed to acheive the same levels before they turned on each other,
<br>
then the side effects could range anywhere from unnoticeable to an
<br>
existential risk.
<br>
<p><em>&gt;  Sorry about the spelling on my previous post.
</em><br>
<p>Jes' keep it fixed. Solutions are better than apologies, as the saying goes.
<br>
<p>~maru
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16020.html">Russell Wallace: "Re: JOIN"</a>
<li><strong>Previous message:</strong> <a href="16018.html">ps udoname: "Re: JOIN"</a>
<li><strong>In reply to:</strong> <a href="16018.html">ps udoname: "Re: JOIN"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16020.html">Russell Wallace: "Re: JOIN"</a>
<li><strong>Reply:</strong> <a href="16020.html">Russell Wallace: "Re: JOIN"</a>
<li><strong>Reply:</strong> <a href="16041.html">ps udoname: "Re: JOIN"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16019">[ date ]</a>
<a href="index.html#16019">[ thread ]</a>
<a href="subject.html#16019">[ subject ]</a>
<a href="author.html#16019">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:57 MDT
</em></small></p>
</body>
</html>
