<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] A model of RSI</title>
<meta name="Author" content="Matt Mahoney (matmahoney@yahoo.com)">
<meta name="Subject" content="Re: [sl4] A model of RSI">
<meta name="Date" content="2008-09-25">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] A model of RSI</h1>
<!-- received="Thu Sep 25 09:24:56 2008" -->
<!-- isoreceived="20080925152456" -->
<!-- sent="Thu, 25 Sep 2008 08:22:17 -0700 (PDT)" -->
<!-- isosent="20080925152217" -->
<!-- name="Matt Mahoney" -->
<!-- email="matmahoney@yahoo.com" -->
<!-- subject="Re: [sl4] A model of RSI" -->
<!-- id="977251.78327.qm@web51909.mail.re2.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="62c14240809241741y402297b0wd27b98c0bd02782d@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Matt Mahoney (<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20A%20model%20of%20RSI"><em>matmahoney@yahoo.com</em></a>)<br>
<strong>Date:</strong> Thu Sep 25 2008 - 09:22:17 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="19358.html">Nick Tarleton: "Re: [sl4] A model of RSI"</a>
<li><strong>Previous message:</strong> <a href="19356.html">Matt Mahoney: "Re: [sl4] A model of RSI"</a>
<li><strong>In reply to:</strong> <a href="19351.html">Mike Dougherty: "Re: [sl4] A model of RSI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19358.html">Nick Tarleton: "Re: [sl4] A model of RSI"</a>
<li><strong>Reply:</strong> <a href="19358.html">Nick Tarleton: "Re: [sl4] A model of RSI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19357">[ date ]</a>
<a href="index.html#19357">[ thread ]</a>
<a href="subject.html#19357">[ subject ]</a>
<a href="author.html#19357">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- On Wed, 9/24/08, Mike Dougherty &lt;<a href="mailto:msd001@gmail.com?Subject=Re:%20[sl4]%20A%20model%20of%20RSI">msd001@gmail.com</a>&gt; wrote:
<br>
<p><em>&gt; I could only conceive of 'better' being used to examine the difference
</em><br>
<em>&gt; in local minima/maxima between arbitrary regions of spacetime ;which
</em><br>
<em>&gt; is how I visualize your original point about reaching a goal in less
</em><br>
<em>&gt; time (faster) or to a greater extent (quantity).
</em><br>
<p>Exactly. &quot;Better&quot; is meaningful only in the context of the culture of the dominant species, which right now is homo sapiens. Self-replicating nanobots could have a completely different view. This is one of my criticisms of the friendly-AI problem. Why do anything about it? Evolution will decide what &quot;better&quot; means.
<br>
<p>My other criticism is that we doom our species by trying to achieve the impossible. Evolution has given us the goals of wanting to learn and not wanting to die, because those goals increase our fitness. Intelligence requires both the ability to learn and the desire to learn. The desire to learn causes us to explore, experiment, play games, read, and interact socially. As a result, we develop language, culture, an efficient economy, and technology.
<br>
<p>The desire not to die causes us to want to produce copies of ourselves with the same memories, goals, behavior, and appearance, to be turned on after we die. (Whether such a copy transfers your consciousness and becomes &quot;you&quot; is an irrelevant philosophical question). Once we have the technology to upload, you will see your dead friends appear to come back to life. Since you have nothing to lose, you will invest in this option, hoping for immortality. The result is a lot of autonomous agents with human-like goals, but with options not available to us, such as the ability to reprogram their brains. Some will directly optimize their utility functions or live in simulations with magic genies. They will die. Others will turn off their fear of death. They will also die. Others will have the goal of replicating themselves or some variation as fast as possible. The copies that fear death and can't change their goals will take over. So we are back where we
<br>
&nbsp;started, with an evolutionary process.
<br>
<p>Could someone remind me again, what are we trying to achieve with a singularity?
<br>
<p>-- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20A%20model%20of%20RSI">matmahoney@yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="19358.html">Nick Tarleton: "Re: [sl4] A model of RSI"</a>
<li><strong>Previous message:</strong> <a href="19356.html">Matt Mahoney: "Re: [sl4] A model of RSI"</a>
<li><strong>In reply to:</strong> <a href="19351.html">Mike Dougherty: "Re: [sl4] A model of RSI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19358.html">Nick Tarleton: "Re: [sl4] A model of RSI"</a>
<li><strong>Reply:</strong> <a href="19358.html">Nick Tarleton: "Re: [sl4] A model of RSI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19357">[ date ]</a>
<a href="index.html#19357">[ thread ]</a>
<a href="subject.html#19357">[ subject ]</a>
<a href="author.html#19357">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
