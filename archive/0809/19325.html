<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: [sl4] Bayesian rationality vs. voluntary mergers</title>
<meta name="Author" content="Wei Dai (weidai@weidai.com)">
<meta name="Subject" content="[sl4] Bayesian rationality vs. voluntary mergers">
<meta name="Date" content="2008-09-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>[sl4] Bayesian rationality vs. voluntary mergers</h1>
<!-- received="Sun Sep  7 16:39:53 2008" -->
<!-- isoreceived="20080907223953" -->
<!-- sent="Sun, 7 Sep 2008 15:36:48 -0700" -->
<!-- isosent="20080907223648" -->
<!-- name="Wei Dai" -->
<!-- email="weidai@weidai.com" -->
<!-- subject="[sl4] Bayesian rationality vs. voluntary mergers" -->
<!-- id="BAY124-DS53CBA40C7DD4F31BF5364D85A0@phx.gbl" -->
<!-- charset="gb2312" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Wei Dai (<a href="mailto:weidai@weidai.com?Subject=Re:%20[sl4]%20Bayesian%20rationality%20vs.%20voluntary%20mergers"><em>weidai@weidai.com</em></a>)<br>
<strong>Date:</strong> Sun Sep 07 2008 - 16:36:48 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="19326.html">Byrne Hobart: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Previous message:</strong> <a href="19324.html">m.l.vere@durham.ac.uk: "[sl4] Please unsubscribe me from these mailings"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19326.html">Byrne Hobart: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19326.html">Byrne Hobart: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19327.html">Norman Noman: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19328.html">Wei Dai: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Maybe reply:</strong> <a href="19329.html">Wei Dai: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19330.html">Tim Freeman: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19331.html">Tim Freeman: "Different priors (was Re: [sl4] Bayesian rationality vs. voluntary mergers)"</a>
<li><strong>Reply:</strong> <a href="19332.html">Eliezer Yudkowsky: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19333.html">Wei Dai: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19334.html">Wei Dai: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19338.html">Wei Dai: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19340.html">Wei Dai: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="../0810/19397.html">Rolf Nelson: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19325">[ date ]</a>
<a href="index.html#19325">[ thread ]</a>
<a href="subject.html#19325">[ subject ]</a>
<a href="author.html#19325">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
After suggesting in a previous post [1] that AIs who want to cooperate with 
<br>
each other may find it more efficient to merge than to trade, I realized 
<br>
that voluntary mergers do not necessarily preserve Bayesian rationality, 
<br>
that is, rationality as defined by standard decision theory. In other words, 
<br>
two &quot;rational&quot; AIs may find themselves in a situation where they won't 
<br>
voluntarily merge into a &quot;rational&quot; AI, but can agree merge into an 
<br>
&quot;irrational&quot; one. This seems to suggest that we shouldn't expect AIs to be 
<br>
constrained by Bayesian rationality, and that we need an expanded definition 
<br>
of what rationality is.
<br>
<p>Let me give a couple of examples to illustrate my point. First consider an 
<br>
AI with the only goal of turning the universe into paperclips, and another 
<br>
one with the goal of turning the universe into staples. Each AI is 
<br>
programmed to get 1 util if at least 60% of the accessible universe is 
<br>
converted into its target item, and 0 utils otherwise. Clearly they can't 
<br>
both reach their goals (assuming their definitions of &quot;accessible universe&quot; 
<br>
overlap sufficiently), but they are not playing a zero-sum game, since it is 
<br>
possible for them to both lose, if for example they start a destructive war 
<br>
that devastates both of them, or if they just each convert 50% of the 
<br>
universe.
<br>
<p>So what should they do? In [1] I suggested that two AIs can create a third 
<br>
AI whose utility function is a linear combination of the utilities of the 
<br>
original AIs, and then hand off their assets to the new AI. But that doesn't 
<br>
work in this case. If they tried this, the new AI will get 1 util if at 
<br>
least 60% of the universe is converted to paperclips, and 1 util if at least 
<br>
60% of the universe is converted to staples. In order to maximize its 
<br>
expected utility, it will pursue the one goal with the highest chance of 
<br>
success (even if it's just slightly higher than the other goal). But if 
<br>
these success probabilities were known before the merger, the AI whose goal 
<br>
has a smaller chance of success would have refused to agree to the merger. 
<br>
That AI should only agree if the merger allows it to have a close to 50% 
<br>
probability of success according to its original utility function.
<br>
<p>The problem here is that standard decision theory does not allow a 
<br>
probabilistic mixture of outcomes to have a higher utility than the 
<br>
mixture's expected utility, so a 50/50 chance of reaching either of two 
<br>
goals A and B cannot have a higher utility than 100% chance of reaching A 
<br>
and a higher utility than 100% chance of reaching B, but that is what is 
<br>
needed in this case in order for both AIs to agree to the merger.
<br>
<p>The second example shows how a difference in the priors of two AIs, as 
<br>
opposed to their utility functions, can have a similar effect. Suppose two 
<br>
AIs come upon an alien artifact which looks like a safe with a combination 
<br>
lock. There is a plaque that says they can try to open the lock the next 
<br>
day, but it will cost $1 to try each combination. Each AI values the 
<br>
contents of the safe at 3 utils, and the best alternative use of the $1 at 2 
<br>
utils. They also each think they have a good guess of the lock combination, 
<br>
assigning a 90% probability of being correct, but their guesses are 
<br>
different due to having different priors. They have until tomorrow to decide 
<br>
whether to try their guesses or not, but in the mean time they have to 
<br>
decide whether or not to merge. If they don't merge, they will each try a 
<br>
guess and expect to get .9*3=2.7 utils, but if they do merge into a new 
<br>
Bayesian AI with an average of their priors, the new AI will assign .45 
<br>
probability of each guess being correct, and since the expected utility of 
<br>
trying a guess is now .45 * 3 &lt; 2, it will decide not to try either 
<br>
combination. The original AIs, knowing this, would refuse to merge.
<br>
<p>To generalize a bit from these examples, it appears that standard decision 
<br>
theory was created to model or guide the decision making processes of 
<br>
individuals, whereas AIs may need to represent the beliefs and interests of 
<br>
groups. This may be the result of mergers as in these examples, or the AIs 
<br>
may be designed from the start to benefit whole groups or societies. The 
<br>
standard Bayesian notion of rationality does not seem adequate for this 
<br>
task.
<br>
<p>[1] &quot;trade or merge?&quot; 
<br>
<a href="http://www.nabble.com/-sl4--trade-or-merge--td18500141.html">http://www.nabble.com/-sl4--trade-or-merge--td18500141.html</a>
<br>
&nbsp;
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="19326.html">Byrne Hobart: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Previous message:</strong> <a href="19324.html">m.l.vere@durham.ac.uk: "[sl4] Please unsubscribe me from these mailings"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19326.html">Byrne Hobart: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19326.html">Byrne Hobart: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19327.html">Norman Noman: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19328.html">Wei Dai: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Maybe reply:</strong> <a href="19329.html">Wei Dai: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19330.html">Tim Freeman: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19331.html">Tim Freeman: "Different priors (was Re: [sl4] Bayesian rationality vs. voluntary mergers)"</a>
<li><strong>Reply:</strong> <a href="19332.html">Eliezer Yudkowsky: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19333.html">Wei Dai: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19334.html">Wei Dai: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19338.html">Wei Dai: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="19340.html">Wei Dai: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<li><strong>Reply:</strong> <a href="../0810/19397.html">Rolf Nelson: "Re: [sl4] Bayesian rationality vs. voluntary mergers"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19325">[ date ]</a>
<a href="index.html#19325">[ thread ]</a>
<a href="subject.html#19325">[ subject ]</a>
<a href="author.html#19325">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
