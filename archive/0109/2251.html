<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Time and Minds</title>
<meta name="Author" content="aominux (aominux@yahoo.com)">
<meta name="Subject" content="Re: Time and Minds">
<meta name="Date" content="2001-09-28">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Time and Minds</h1>
<!-- received="Fri Sep 28 17:33:14 2001" -->
<!-- isoreceived="20010928233314" -->
<!-- sent="Fri, 28 Sep 2001 16:26:19 -0500" -->
<!-- isosent="20010928212619" -->
<!-- name="aominux" -->
<!-- email="aominux@yahoo.com" -->
<!-- subject="Re: Time and Minds" -->
<!-- id="002501c14864$3a453c70$0100a8c0@a9504" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="3BB42A59.C7CE824C@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> aominux (<a href="mailto:aominux@yahoo.com?Subject=Re:%20Time%20and%20Minds"><em>aominux@yahoo.com</em></a>)<br>
<strong>Date:</strong> Fri Sep 28 2001 - 15:26:19 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2252.html">Aikin, Robert: "Bringing Reality to Nanotechnology"</a>
<li><strong>Previous message:</strong> <a href="2250.html">Eliezer S. Yudkowsky: "Re: Time and Minds"</a>
<li><strong>In reply to:</strong> <a href="2250.html">Eliezer S. Yudkowsky: "Re: Time and Minds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2253.html">Eliezer S. Yudkowsky: "Re: Time and Minds"</a>
<li><strong>Reply:</strong> <a href="2253.html">Eliezer S. Yudkowsky: "Re: Time and Minds"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2251">[ date ]</a>
<a href="index.html#2251">[ thread ]</a>
<a href="subject.html#2251">[ subject ]</a>
<a href="author.html#2251">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
No matter how disgustingly sick this sounds, after spending a certain amount
<br>
of time in a hedonistic environment you WILL begin to desire pain.  It
<br>
doesn't matter whether or not you can conceive this now.
<br>
<p>I doubt any of us could go million subjective years before desiring a
<br>
pre-singularity simulation, let alone an infinity.  The sick truth is that
<br>
we don't desire happiness; we desire sensory stimulation.
<br>
<p>Besides, since you could consume an entire subjective human life in a
<br>
fraction of a second in post-singularity times, it wouldn't seem like much
<br>
of a sacrifice.  We will/do desire variety and we will get it.
<br>
<p>On a related note, the odds that we are not in a simulation are impossible
<br>
to compute since we would have to assume the that we were in a simulation.
<br>
However, if we trust that our world is based on a backup of the future's
<br>
past, it doesn't take much time to figure the probability of a single human
<br>
life being in the &quot;real world.&quot;  Humans have been around for far under one
<br>
million years and we still have billions of years until our sun expires.
<br>
Many many many more humans will exist beyond this point in history than
<br>
before it.  You chances of experiencing pre-singularity firsthand are slim
<br>
to none.
<br>
<p>Even this is pessimistic because this is to say that when the sun expires
<br>
humanity will pass with it.  However, once the singularity is achieved, we
<br>
will undoubtedly move out of the galaxy anyhow.
<br>
<p>Finally,  I would appreciate it if you would stop using Re: Time and Minds
<br>
if you're post has nothing to do with the original purpose of this topic:
<br>
Minds and time travel.
<br>
<p>Sincerely apologizing for grammatical errors and sl4 violations,
<br>
aominux
<br>
<p>----- Original Message -----
<br>
From: &quot;Eliezer S. Yudkowsky&quot; &lt;<a href="mailto:sentience@pobox.com?Subject=Re:%20Time%20and%20Minds">sentience@pobox.com</a>&gt;
<br>
To: &lt;<a href="mailto:sl4@sysopmind.com?Subject=Re:%20Time%20and%20Minds">sl4@sysopmind.com</a>&gt;
<br>
Sent: Friday, September 28, 2001 2:44 AM
<br>
Subject: Re: Time and Minds
<br>
<p><p><em>&gt; Jeff Bone wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; &gt; But life is unpleasant, sometimes very unpleasant.  And life is not a
</em><br>
<em>&gt; &gt; &gt; trade, where you agree to experience some unpleasant things in
</em><br>
exchange
<br>
<em>&gt; &gt; &gt; for the good parts.  That is simply a nitwit philosophical idea that
</em><br>
was
<br>
<em>&gt; &gt; &gt; dreamed up to rationalize away the discomfort from living with
</em><br>
gratuitous
<br>
<em>&gt; &gt; &gt; unpleasantness that humanity was powerless to do anything about.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Not defending or attacking that attitude, but:  &quot;humanity&quot; as such is
</em><br>
powerless
<br>
<em>&gt; &gt; to do anything at all, because it is an abstraction without any volition
</em><br>
or
<br>
<em>&gt; &gt; capacity to act in / of itself.
</em><br>
<em>&gt;
</em><br>
<em>&gt; In this case, &quot;humanity&quot; was not intended to refer to any higher-level
</em><br>
<em>&gt; social phenomena emergent from individual humans, but was simply being
</em><br>
<em>&gt; used as shorthand for &quot;the set of all humans&quot;.  Substitute &quot;99%&quot; for &quot;all&quot;
</em><br>
<em>&gt; if you like.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; &gt; Pain is
</em><br>
<em>&gt; &gt; &gt; not necessary for growth, or to give life meaning, or to teach us
</em><br>
<em>&gt; &gt; &gt; responsibility, or any other nitwit philosophical reason.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Not disputing this point of view, but:  prove it.  This is an
</em><br>
extraordinary
<br>
<em>&gt; &gt; claim, and extraordinary claims require extraordinary proof.  It's
</em><br>
contrary to
<br>
<em>&gt; &gt; most philosophical viewpoints, and someone who seeks to code what they
</em><br>
believe
<br>
<em>&gt; &gt; as a core philosophy into a compulsory &quot;operating system&quot; for the world
</em><br>
should
<br>
<em>&gt; &gt; be ready to defend said philosophy.  I do not disagree with you, but I
</em><br>
want to
<br>
<em>&gt; &gt; see your defense.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Well, let's get the Friendliness misapprehension out of the way first; I
</em><br>
<em>&gt; am not proposing to compulsorily prohibit all pain.  I am proposing that
</em><br>
<em>&gt; pain must be voluntary, and that it should be prohibited (by direct
</em><br>
<em>&gt; intervention) to cause involuntary, unconsented-to pain in other sentient
</em><br>
<em>&gt; beings.  Under these local conditions, if most people come to agree with
</em><br>
<em>&gt; the philosophical position that pain is unnecessary, then the emergent
</em><br>
<em>&gt; result is that most pain will cease to exist.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The requirement to defend the uselessness of pain results from the need to
</em><br>
<em>&gt; argue with people who say:  &quot;The Singularity will give people the ability
</em><br>
<em>&gt; to choose to eliminate pain, and people will make that choice even if it
</em><br>
<em>&gt; is unwise, and pain is necessary; QED the Singularity is bad.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; I don't have time to argue everything, so I'll confine myself to making
</em><br>
<em>&gt; the following observations:
</em><br>
<em>&gt;
</em><br>
<em>&gt; 1)  Given what we know about cognitive dissonance, and also about what
</em><br>
<em>&gt; lousy philosophers humans tend to be, it is quite plausible that all the
</em><br>
<em>&gt; philosophy dealing with the necessity of pain is total bull.  This
</em><br>
<em>&gt; argument doesn't prove that it is bull, but it is sufficient to
</em><br>
<em>&gt; demonstrate the invalidity of saying, or even pointing out as an argument
</em><br>
<em>&gt; token, &quot;A lot of people believe it so there must be something to it.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; 2)  Pain may sometimes play a causal role in a chain of events leading to
</em><br>
<em>&gt; a positive result.  Furthermore, albeit more rarely, it may be impossible
</em><br>
<em>&gt; to plausibly or easily substitute something else for the pain that would
</em><br>
<em>&gt; have the same result.  I am thinking particularly here of some emotional
</em><br>
<em>&gt; changes that seem to verge on pure neurochemistry.  However, if you're an
</em><br>
<em>&gt; upload, you can replace any cognitive realizations that result from
</em><br>
<em>&gt; biohuman-pain with improved intelligence and the ability to make the
</em><br>
<em>&gt; realizations through pure abstract reasoning, and you can replace the
</em><br>
<em>&gt; neurochemistry and hardwired emotional linkages by simple fiat.
</em><br>
<em>&gt;
</em><br>
<em>&gt; 3)  Given (1) and (2), I assert that the ball is now in the other player's
</em><br>
<em>&gt; court; they are required to give a specific example of a desirable
</em><br>
<em>&gt; scenario involving pain, in which the need for the pain cannot be
</em><br>
<em>&gt; eliminated by either improved intelligence or rewired emotions.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; &gt; If you were
</em><br>
<em>&gt; &gt; &gt; constructing a world from scratch it would not contain child abuse
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Again, not disputing you, but I suppose that depends on who you are,
</em><br>
doesn't
<br>
<em>&gt; &gt; it?  My point is not to defend or advance any particular position, but
</em><br>
only to
<br>
<em>&gt; &gt; point out the number of as-yet ungrounded and unexplained assumptions
</em><br>
and
<br>
<em>&gt; &gt; assertions, here.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The variable &quot;you&quot; may be taken to indicate &quot;most people&quot;, with additional
</em><br>
<em>&gt; focusing for &quot;as rationality increases&quot;, &quot;as intelligence increases&quot;, and
</em><br>
<em>&gt; &quot;philosophical systems that a human third party is likely to wish that I
</em><br>
<em>&gt; should pay some attention to&quot;.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; &gt; And similarly, the fun I have, regardless of how it measures up
</em><br>
compared
<br>
<em>&gt; &gt; &gt; to an &quot;average&quot; pre-Singularity life,
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; You say &quot;regardless&quot; but --- interwoven throughout the argument, and
</em><br>
previous
<br>
<em>&gt; &gt; ones --- are assumptions about the Singularity.  As you have previously
</em><br>
and
<br>
<em>&gt; &gt; adamantly asserted the unknowability of post-Singularity existance, I
</em><br>
find it
<br>
<em>&gt; &gt; odd that you fall back on arguments which assumes positive (or negative)
</em><br>
<em>&gt; &gt; qualitative differences between pre- and post-Singularity life.  I would
</em><br>
say
<br>
<em>&gt; &gt; &quot;check your premises&quot; but in this case I think first you should make
</em><br>
them
<br>
<em>&gt; &gt; explicit.  We may not even need or want to be individuals
</em><br>
post-Singularity, so
<br>
<em>&gt; &gt; your argument may be as sensible as pro- and eukaryotic cells arguing
</em><br>
which form
<br>
<em>&gt; &gt; is &quot;superior.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Unknowability is not the same as being unable to say &quot;better or worse&quot;.
</em><br>
<em>&gt; If we don't want to be individuals, and we aren't individuals, that's a
</em><br>
<em>&gt; net improvement.  This holds for a lot of &quot;If we want X, and X ensues,
</em><br>
<em>&gt; that's a net improvement&quot;.  X can be very widely variable, or even
</em><br>
<em>&gt; completely unknown, and still allow a net conclusion of greater
</em><br>
<em>&gt; desirability; not an absolute conclusion, of course, but still the more
</em><br>
<em>&gt; likely conclusion compared to the negative.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; &gt; Some of the unpleasantness in my life is due to choices I made
</em><br>
willingly,
<br>
<em>&gt; &gt; &gt; but I will not forgive any entity that turns out to be responsible for
</em><br>
<em>&gt; &gt; &gt; having made those choices necessary.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; So you are not responsible for everything that has ever happened to you?
</em><br>
<em>&gt;
</em><br>
<em>&gt; No, I am responsible.  Remember, I think that this world is real,
</em><br>
<em>&gt; nonsimulated, and physical.  This means that I am the most intelligent
</em><br>
<em>&gt; entity in the system that produces my choices, and that my beliefs and
</em><br>
<em>&gt; morals and other self-components operate naturally to produce my choices,
</em><br>
<em>&gt; which means that I am &quot;responsible&quot; for my choices under the
</em><br>
<em>&gt; common-to-virtually-everyone set of hardwired emotional processes that
</em><br>
<em>&gt; assign the intuitive perception of moral responsibility.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; Respectfully but gravely, this sounds like the symptoms of a dangerous
</em><br>
memetic
<br>
<em>&gt; &gt; infection called &quot;victimhood.&quot;  It is unfortunately epidemic in our
</em><br>
society.
<br>
<em>&gt;
</em><br>
<em>&gt; Well, having called for precision, I will note the precision of your use
</em><br>
<em>&gt; of the phrase &quot;sounds like&quot;.  I would dispute it, but I can hardly argue
</em><br>
<em>&gt; with your patently true statement that it sounds to you like victimhood.
</em><br>
<em>&gt; I guess your perception of the emotional connotations of the phrasing I
</em><br>
<em>&gt; used conflicts with my own perception, because to me &quot;Some of the
</em><br>
<em>&gt; unpleasantness in my life is due to choices I made willingly&quot; does not
</em><br>
<em>&gt; sound like a confession of victimhood.  I had thought the phrasing I used
</em><br>
<em>&gt; was unambiguous - I take responsibility for my own choices, but if it
</em><br>
<em>&gt; turns out that someone other entity is responsible for reducing my options
</em><br>
<em>&gt; and for making unnecessary sacrifices falsely appear to be necessary, I
</em><br>
<em>&gt; will be severely annoyed, and it seems very unlikely that entity's actions
</em><br>
<em>&gt; could meet any moral standard I care to recognize.
</em><br>
<em>&gt;
</em><br>
<em>&gt; --              --              --              --              --
</em><br>
<em>&gt; Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
</em><br>
<em>&gt; Research Fellow, Singularity Institute for Artificial Intelligence
</em><br>
<p><p>_________________________________________________________
<br>
Do You Yahoo!?
<br>
Get your free @yahoo.com address at <a href="http://mail.yahoo.com">http://mail.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2252.html">Aikin, Robert: "Bringing Reality to Nanotechnology"</a>
<li><strong>Previous message:</strong> <a href="2250.html">Eliezer S. Yudkowsky: "Re: Time and Minds"</a>
<li><strong>In reply to:</strong> <a href="2250.html">Eliezer S. Yudkowsky: "Re: Time and Minds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2253.html">Eliezer S. Yudkowsky: "Re: Time and Minds"</a>
<li><strong>Reply:</strong> <a href="2253.html">Eliezer S. Yudkowsky: "Re: Time and Minds"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2251">[ date ]</a>
<a href="index.html#2251">[ thread ]</a>
<a href="subject.html#2251">[ subject ]</a>
<a href="author.html#2251">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
