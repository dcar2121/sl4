<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Nondeterministic Seed</title>
<meta name="Author" content="x@d-207-5-213-232.s-way.com (x@d-207-5-213-232.s-way.com)">
<meta name="Subject" content="Nondeterministic Seed">
<meta name="Date" content="2001-09-02">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Nondeterministic Seed</h1>
<!-- received="Mon Sep 10 13:58:27 2001" -->
<!-- isoreceived="20010910195827" -->
<!-- sent="Sun, 2 Sep 2001 22:45:37 -0400" -->
<!-- isosent="20010903024537" -->
<!-- name="x@d-207-5-213-232.s-way.com" -->
<!-- email="x@d-207-5-213-232.s-way.com" -->
<!-- subject="Nondeterministic Seed" -->
<!-- id="200109030245.f832jbF01152@d-207-5-213-232.s-way.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> <a href="mailto:x@d-207-5-213-232.s-way.com?Subject=Re:%20Nondeterministic%20Seed"><em>x@d-207-5-213-232.s-way.com</em></a><br>
<strong>Date:</strong> Sun Sep 02 2001 - 20:45:37 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2169.html">Gordon Worley: "Re: Nondeterministic Seed"</a>
<li><strong>Previous message:</strong> <a href="2167.html">Eliezer S. Yudkowsky: "Review of &quot;Open Your Eyes&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2169.html">Gordon Worley: "Re: Nondeterministic Seed"</a>
<li><strong>Reply:</strong> <a href="2169.html">Gordon Worley: "Re: Nondeterministic Seed"</a>
<li><strong>Reply:</strong> <a href="2170.html">Eliezer S. Yudkowsky: "Re: Nondeterministic Seed"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2168">[ date ]</a>
<a href="index.html#2168">[ thread ]</a>
<a href="subject.html#2168">[ subject ]</a>
<a href="author.html#2168">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi, I have a question regarding how Seed AI will cope in a quantum world.
<br>
The plans which Eli has outlined for Seed AI seem to require a deterministic
<br>
world (programming, strict dependence on a supergoal*, etc.) But, as we
<br>
*currently* know, the quantum world is inherently nondeterministic. To a
<br>
good approximation, Eli's model should function as designed. But what about
<br>
when it reaches an intelligence of 10^33 IQ (intelligence quanta:)?
<br>
<p>It seems like, as Seed intelligence grows, so must the complexity of the
<br>
seed. Assuming that the complexity of the seed correlates roughly with the
<br>
number of quantum entities in the seed, the probability of random events
<br>
(ie, nondeterministic events outside the seed mechanism) should increase
<br>
proportionately. Additionally, as seed complexity increases, the potential
<br>
macro effect of a quantum indeterminism will be magnified significantly
<br>
(butterfly effect, etc.) So, it seems like, as seed intelligence is 
<br>
scheduled to increase, it is also scheduled to depart more, and more, from
<br>
its deterministic design.
<br>
<p>This could be a problem. Friendly AI is based upon the the notion of
<br>
*strict dependence upon a supergoal, and General Intelligence is founded
<br>
upon a formalized problem solving strategy. If implementations of such
<br>
systems become nondeterministic, process may suddenly escape plan. The
<br>
seed AI may become unfriendly or even start violating principles laid
<br>
down by Eli (in GISAI) as being required of General Intelligence. It
<br>
seems like trying to tie-down one's own hands, an inherently impossible
<br>
proposition, and may permit seed AIs (friendly or not) a &quot;get out of jail
<br>
free&quot; card. In fact, if intelligence grows large enough, it seems like the
<br>
notion of &quot;friendliness&quot; itself gradually tends to loose its meaning.
<br>
<p>But this does not necessarily doom Seed AI conceptually. Currently, I
<br>
see two ways around this obstacle: First, there is the possibility of
<br>
bootstrapping into a quantum-deterministic seed. While currently beyond
<br>
the design capabilities of any human, it is concievable that a young SI
<br>
would be able to do this. Fully deterministic quantum correlation (for
<br>
example, implementation in some kind of fully-entangled substrate) could
<br>
restore determinism. But, then again, this is also the &quot;I don't know, but
<br>
an SI will solve that problem&quot; way of dealing (or not dealing) with any
<br>
potential problem. So, perhaps I should be CC:'ing this question to ver.
<br>
<p>Second, a young, still mostly deterministic seed *may* be able to find
<br>
deteministic &quot;laws of physics&quot; which accurately forecast the (with our
<br>
intelligence) seemingly random events of the quantum world. Again, this
<br>
is an appeal to an intelligence higher than ours, and still dependend
<br>
upon the existence of such sub-quantum determinism, but still a potential
<br>
solution, nonetheless.
<br>
<p>That said, there seems to be an &quot;intelligence window&quot; through which the
<br>
bootstrapping seed AI must pass in order for it to remain true to form:
<br>
it must reach hyperquantum implementation before becoming undetermined
<br>
and yet after reaching human intelligence. So, what must then be asked is
<br>
if the edges of these windows exist and, if so, how to steer a seed AI
<br>
through them. Regarding the lower IQ bound, all bets are off if quantum
<br>
indeterminism plays any role in human sentience. If the human brain is
<br>
complex enough to be nondeterministic, then any (slightly) superhuman
<br>
brain should also be nondeterministic and able to stray from its program.
<br>
So, the lower constrain on seed IQ requires that *human equivalent*
<br>
general intelligence be at least deterministically modelable. With only
<br>
10^8 neurons in the brain, this seems to be a plausible scenario.
<br>
<p>Regarding the upper bound, the seed must be able to cirucm-design
<br>
quantum effects before becoming sufficiently quantum-demented. Again,
<br>
if human-equivalent intelligence constrain is not met, all bets are
<br>
off. No intelligence could, unless originated by a comparatively
<br>
intelligent superintelligence, be implemented in transquantum mechanics
<br>
without suffering from human nondeterministic thought. But, given the
<br>
possibility of meeting the lower bound and the probability of their
<br>
existing deterministic transquantum mechanics, this is also plausible.
<br>
But, how to steer a launching seed through these fuzzy goalposts?
<br>
<p>Seed development, according to Eli's documentation, is done through
<br>
&quot;stric dependence upon a supergoal&quot;. Implemented in a deterministic
<br>
medium, with knowledge of quantum indeterminacy in mind, a subhuman
<br>
seed should be smart enough to steer clear of indeterminism, itself,
<br>
because allowing itself to become nondeterministic would violate its
<br>
supergoal and be, thus, an unacceptable course of action. But, like
<br>
trying to fit a rug into a room for which it is too small, the corners
<br>
pop out: First, there is the possibility that figuring out how to
<br>
implement oneself in a quantumsafe way would take too much time. In
<br>
this scenario, the accumulated probabilites add up to produce an
<br>
indeterminacy before determinacy can be designed. If the seed realizes
<br>
this, it will destroy itself. If it doesn't, it gets loose. Oh well. :)
<br>
Second, there is the possibility of bootstrap dead-end. If a developing
<br>
seed determines that meeeting window constraints is impossible (for it),
<br>
it may (and should) refuse to develop any further. Not as bad as the
<br>
first case, but, at the upper-limit of deterministic intelligence, may
<br>
be far short of Singularity.
<br>
<p>So, my question: is it possible to create a fully deterministic super-
<br>
intelligence? The answer seems to be: &quot;for now.&quot;
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2169.html">Gordon Worley: "Re: Nondeterministic Seed"</a>
<li><strong>Previous message:</strong> <a href="2167.html">Eliezer S. Yudkowsky: "Review of &quot;Open Your Eyes&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2169.html">Gordon Worley: "Re: Nondeterministic Seed"</a>
<li><strong>Reply:</strong> <a href="2169.html">Gordon Worley: "Re: Nondeterministic Seed"</a>
<li><strong>Reply:</strong> <a href="2170.html">Eliezer S. Yudkowsky: "Re: Nondeterministic Seed"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2168">[ date ]</a>
<a href="index.html#2168">[ thread ]</a>
<a href="subject.html#2168">[ subject ]</a>
<a href="author.html#2168">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
