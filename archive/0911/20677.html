<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] The Jaguar Supercomputer</title>
<meta name="Author" content="Pavitra (celestialcognition@gmail.com)">
<meta name="Subject" content="Re: [sl4] The Jaguar Supercomputer">
<meta name="Date" content="2009-11-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] The Jaguar Supercomputer</h1>
<!-- received="Mon Nov 23 21:30:31 2009" -->
<!-- isoreceived="20091124043031" -->
<!-- sent="Mon, 23 Nov 2009 22:29:15 -0600" -->
<!-- isosent="20091124042915" -->
<!-- name="Pavitra" -->
<!-- email="celestialcognition@gmail.com" -->
<!-- subject="Re: [sl4] The Jaguar Supercomputer" -->
<!-- id="4B0B611B.9000705@gmail.com" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="F07BD9A0-4E94-47E1-A537-5CA3670269B9@gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Pavitra (<a href="mailto:celestialcognition@gmail.com?Subject=Re:%20[sl4]%20The%20Jaguar%20Supercomputer"><em>celestialcognition@gmail.com</em></a>)<br>
<strong>Date:</strong> Mon Nov 23 2009 - 21:29:15 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20678.html">Matt Mahoney: "Goals of AI (was Re: [sl4] The Jaguar Supercomputer)"</a>
<li><strong>Previous message:</strong> <a href="20676.html">Matt Paul: "Re: [sl4] The Jaguar Supercomputer"</a>
<li><strong>In reply to:</strong> <a href="20675.html">Matt Paul: "Re: [sl4] The Jaguar Supercomputer"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20678.html">Matt Mahoney: "Goals of AI (was Re: [sl4] The Jaguar Supercomputer)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20677">[ date ]</a>
<a href="index.html#20677">[ thread ]</a>
<a href="subject.html#20677">[ subject ]</a>
<a href="author.html#20677">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Lizardblue wrote:
<br>
<em>&gt; Ok. More questions:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Is the intelligence that has advanced humanity actually able to be  
</em><br>
<em>&gt; recreated in a machine? I mean what is it. It seems to me that the  
</em><br>
<em>&gt; human &quot;intelligence&quot; that has advanced us is comprised of much more  
</em><br>
<em>&gt; than just processing power. It involves fairly tough to understand  
</em><br>
<em>&gt; things like creativity, the ability to imagine, etc. What about  
</em><br>
<em>&gt; motivations such as compassion, comfort, hate, love, fear of death,  
</em><br>
<em>&gt; desire to defeat an enemy, etc. These seem to all be an integral part  
</em><br>
<em>&gt; of what got us this far. How does this translate to the machine world?
</em><br>
<p>I think it translates as good software design, which is why the
<br>
intelligence of the machine increases accelerates when the intelligence
<br>
of its programmers increases. (Mere processing power would translate as
<br>
good hardware design, which is subject to Moore's Law.)
<br>
<p><em>&gt; Also, can someone cite some examples of what might a super- 
</em><br>
<em>&gt; intelligence do that would truly make our lives better?
</em><br>
<p>Develop a medicine or medical technique to cure cancer; invent new
<br>
architectural techniques and building materials that would make it
<br>
possible to cheaply house and clothe all of humanity; mediate political
<br>
conflicts, figuring out mutually beneficial solutions and persuading the
<br>
parties to adopt them.
<br>
<p>And those are all things that humans can foresee wanting. Look at
<br>
existing species intelligence gaps if you really want to see what could
<br>
happen: what can humans do to make the lives of, say, a gerbil better?
<br>
We can ensure that it always has enough food, which it knows to want;
<br>
likewise, we can keep it safe from predators. But also we can design for
<br>
it a balanced diet to keep it from disease, including inventing new
<br>
foods for that purpose. This is what a vast intelligence gap means.
<br>
<p><em>&gt; My understanding was that the goal is to download people into  
</em><br>
<em>&gt; machines, to make them more capable, and mostly to make them immortal.  
</em><br>
<em>&gt; Downloading people into machines seems a very different thing from  
</em><br>
<em>&gt; having super AIs at our service. We would be the AI.
</em><br>
<p>That sounds like a nice feature to implement, but if &quot;make them more
<br>
capable&quot; is finitely bounded at (say) merely a hundred thousand times
<br>
current human capacity, then it's just not going to be in the same
<br>
league as an intelligent being with maintainable source code.
<br>
<p>Human uploads that are enhanced in part by reimplementing (aspects of?)
<br>
the brain in a more manageable form might possibly become the first
<br>
recursively self-improving artificial general intelligences. But I
<br>
suspect we're going to figure out how to replicate our black-box
<br>
behavior before we reverse-engineer our actual source.
<br>
<p><em>&gt; I see the personal benefit for individuals here, but not so much for  
</em><br>
<em>&gt; humanity in general.
</em><br>
<em>&gt; Seperate AIs I see as potentially beneficial, but also as potentially  
</em><br>
<em>&gt; very dangerous.
</em><br>
<em>&gt; What is the goal here? Eternal humans, supercomputers, or both?
</em><br>
<p>The goal is to attain that which we do not yet know to want.
<br>
Despaghettifying human uploads would probably be the safest way to get
<br>
there, if we could somehow insure that somebody else doesn't do it the
<br>
stupid way first and kill us.
<br>
<p><p>
<br><p>
<p><hr>
<ul>
<li>application/pgp-signature attachment: <a href="../att-20677/01-signature.asc">OpenPGP digital signature</a>
</ul>
<!-- attachment="01-signature.asc" -->
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20678.html">Matt Mahoney: "Goals of AI (was Re: [sl4] The Jaguar Supercomputer)"</a>
<li><strong>Previous message:</strong> <a href="20676.html">Matt Paul: "Re: [sl4] The Jaguar Supercomputer"</a>
<li><strong>In reply to:</strong> <a href="20675.html">Matt Paul: "Re: [sl4] The Jaguar Supercomputer"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20678.html">Matt Mahoney: "Goals of AI (was Re: [sl4] The Jaguar Supercomputer)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20677">[ date ]</a>
<a href="index.html#20677">[ thread ]</a>
<a href="subject.html#20677">[ subject ]</a>
<a href="author.html#20677">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:05 MDT
</em></small></p>
</body>
</html>
