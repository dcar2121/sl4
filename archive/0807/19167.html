<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: [sl4] Re: More silly but friendly ideas</title>
<meta name="Author" content="Lee Corbin (lcorbin@rawbw.com)">
<meta name="Subject" content="[sl4] Re: More silly but friendly ideas">
<meta name="Date" content="2008-07-03">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>[sl4] Re: More silly but friendly ideas</h1>
<!-- received="Thu Jul  3 09:36:39 2008" -->
<!-- isoreceived="20080703153639" -->
<!-- sent="Thu, 3 Jul 2008 08:32:14 -0700" -->
<!-- isosent="20080703153214" -->
<!-- name="Lee Corbin" -->
<!-- email="lcorbin@rawbw.com" -->
<!-- subject="[sl4] Re: More silly but friendly ideas" -->
<!-- id="050801c8dd22$3109ede0$6401a8c0@homeef7b612677" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="001d01c8dc63$c5f4d8d0$0301a8c0@MyComputer" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Lee Corbin (<a href="mailto:lcorbin@rawbw.com?Subject=Re:%20[sl4]%20Re:%20More%20silly%20but%20friendly%20ideas"><em>lcorbin@rawbw.com</em></a>)<br>
<strong>Date:</strong> Thu Jul 03 2008 - 09:32:14 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="19168.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Previous message:</strong> <a href="19166.html">Stathis Papaioannou: "Re: [sl4] Re: More silly but friendly ideas"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19169.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Reply:</strong> <a href="19169.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19167">[ date ]</a>
<a href="index.html#19167">[ thread ]</a>
<a href="subject.html#19167">[ subject ]</a>
<a href="author.html#19167">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Evidently the list is back up, John, so I'll copy the list on my reply.
<br>
<p><em>&gt; On Mon, 30 Jun 2008 &quot;Lee Corbin&quot; said:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; highly capable intelligences won't &quot;work&quot; by any formal logic.
</em><br>
<em>&gt;
</em><br>
<em>&gt; It doesn't matter what the word &quot;work&quot; means, if your mind is capable of
</em><br>
<em>&gt; doing arithmetic then there are statements, lots of them, that you will
</em><br>
<em>&gt; never find a proof to demonstrate it to be true and you will never find
</em><br>
<em>&gt; a counterexample to prove it to be false.
</em><br>
<p>Yes.  One would have supposed this to be true anyway, even
<br>
before Gödel, just because of the finitude of any given human
<br>
(mechanical) mind.  For *practical* matters, even Hilbert would
<br>
have conceded that.  But Gödel proved it even in the most
<br>
idealistic cases, and that includes even second order logics
<br>
and any systems that include an arithmetical subcomponent:
<br>
*formal* proofs have their limitations.
<br>
<p><em>&gt; I'm not saying a mind will &quot;work&quot; by formal logic, I am saying that
</em><br>
<em>&gt; formal logic can be used to examine the limitations of any mind that has
</em><br>
<em>&gt; certain properties, like the ability to do arithmetic for example.
</em><br>
<p>Examine in what sense?  It makes no sense to me that someone
<br>
should examine my mind---even if they have 25th century
<br>
technology---and *because* of Gödel's theorem prove that
<br>
I have limitations. My only limitations---and thus the limitations
<br>
of any mind, when you really come down to it---are only that
<br>
there is only so much time and so much effort that can be applied.
<br>
Gödel's theorem doesn't really apply because only an idiot would
<br>
try to prove everything formally from a fixed system.
<br>
<p><em>&gt; &gt; AIs can be plenty smart without getting hung up on hard problems.
</em><br>
<p><em>&gt; Yes that is true. A real mind might want to solve a certain problem but
</em><br>
<em>&gt; after working on it for a long time and making no progress it might
</em><br>
<em>&gt; judge that its time could be better spent doing other things and move
</em><br>
<em>&gt; on. However your fictional fixed goal mind can't do that, sooner or
</em><br>
<em>&gt; later it is going to encounter one of those Gödel-Turing problems and
</em><br>
<em>&gt; when it does it's going to be caught up in a loop for eternity.
</em><br>
<p>That's true, but *only* if that mind limits itself to formal proofs.
<br>
Nobody does that. In any real model---say, for specifics, the
<br>
reality of the actual set of  literary critics in a certain year---we
<br>
may or may not be able to demonstrate that &quot;all critics admire
<br>
only one another&quot;.  But we won't be using formal proofs to do it.
<br>
<p><em>&gt; I believe that is why Evolution never came up with a fixed goal
</em><br>
<em>&gt; mind, they don't work.
</em><br>
<p>What about a &quot;fixed-goal mind&quot; whose only passion was to find a
<br>
scheme that unified GR and QM?  We cannot say ahead of time
<br>
whether that totally focused individual (be it an AI or not) will
<br>
ever succeed.  Likewise for Goldbach's conjecture.   Now yes,
<br>
*if* it turns out that Goldbach's conjecture is true but (most
<br>
unlikely) suffers from not having a proof at all, then it follows
<br>
trivially that it wouldn't even have a formal proof, and it would
<br>
be an example of Gödelian incompleteness/undecidability.
<br>
<p>In principle, it seems to me that a Focused mind (e.g. the ones
<br>
wonderfully depicted by Vinge in &quot;A Deepness in the Sky&quot;
<br>
whether AI or human, might be what you are calling a fixed
<br>
goal mind.  Yes, I admit that evolution so far as produced
<br>
relatively few of these.  (Probably certain artists, composers,
<br>
or even mathematicians come close to being &quot;fixed goal&quot;
<br>
minds, but only an AI could be 100%, I guess.)  It's here
<br>
that I agree with you that if the thing is highly intelligent---
<br>
e.g. able to absorb inspiration from many sources---then
<br>
it may start fiddling with the very way that it itself thinks,
<br>
and then its behavior is not going to be predictable.
<br>
<p>All we can do, it seems to me, is tilt the odds a bit in our favor,
<br>
and I don't have any reason to dismiss out of hand the efforts
<br>
of the Friendly AI types to do just that.  On the other hand, I
<br>
admit that in distinction to what I wrote the last time I answered
<br>
you on this question, I've read some dubious posts claiming that
<br>
it would be possible to permanently tie down certain artificial
<br>
but exceedingly intelligent AIs so that it could be predicted with
<br>
near 100% probability that there are certain things they will
<br>
never do.  That's because, to me, being highly intelligent *means*
<br>
being open to inspiration from any direction.
<br>
<p>Bottom line of our disagreement.  I still affirm that Gödel's Theorem
<br>
has not the least *practical* effect on the development of AI, nor
<br>
what would be any reasonable limit on what the AI could do, and
<br>
is thus just as irrelevant for any AI's thinking as it is for ours.
<br>
<p>Lee
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="19168.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Previous message:</strong> <a href="19166.html">Stathis Papaioannou: "Re: [sl4] Re: More silly but friendly ideas"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19169.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Reply:</strong> <a href="19169.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19167">[ date ]</a>
<a href="index.html#19167">[ thread ]</a>
<a href="subject.html#19167">[ subject ]</a>
<a href="author.html#19167">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
