<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Friendliness not an Add-on</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="Re: Friendliness not an Add-on">
<meta name="Date" content="2006-02-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Friendliness not an Add-on</h1>
<!-- received="Sun Feb 19 05:37:50 2006" -->
<!-- isoreceived="20060219123750" -->
<!-- sent="Sun, 19 Feb 2006 07:37:48 -0500" -->
<!-- isosent="20060219123748" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="Re: Friendliness not an Add-on" -->
<!-- id="638d4e150602190437y1c6256fauc2875526e53488a@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20060219062802.GA20632@marcello.gotdns.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=Re:%20Friendliness%20not%20an%20Add-on"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sun Feb 19 2006 - 05:37:48 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="14151.html">Tyler Emerson: "RE: Reminder: SIAI Challenge expires this Sunday | SIAI February news"</a>
<li><strong>Previous message:</strong> <a href="14149.html">Nick Hay: "Re: Think of it as AGI suiciding, not boxing"</a>
<li><strong>In reply to:</strong> <a href="14146.html">Marcello Mathias Herreshoff: "Re: Friendliness not an Add-on"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14152.html">Ben Goertzel: "Re: Friendliness not an Add-on"</a>
<li><strong>Reply:</strong> <a href="14152.html">Ben Goertzel: "Re: Friendliness not an Add-on"</a>
<li><strong>Reply:</strong> <a href="14162.html">Charles D Hixson: "Re: Friendliness not an Add-on"</a>
<li><strong>Reply:</strong> <a href="14164.html">Marcello Mathias Herreshoff: "Re: Friendliness not an Add-on"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14150">[ date ]</a>
<a href="index.html#14150">[ thread ]</a>
<a href="subject.html#14150">[ subject ]</a>
<a href="author.html#14150">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi,
<br>
<p>About Rice's theorem... Sorry, I did not phrase my argument against
<br>
the relevance of this theorem very carefully.  Here goes again. 
<br>
Hopefully this reformulation is sufficiently precise.
<br>
<p>What that theorem says (as you know) is that for any nontrivial
<br>
property P (roughly: any property that holds for some arguments and
<br>
not others) it is impossible to make a program that will tell you, for
<br>
all algorithms A, whether A has property P.
<br>
<p>In other words, it says
<br>
<p>It is not true that:
<br>
{ There exists a program so that
<br>
{For All nontrivial properties P and all algorithms A
<br>
{ there exists a program Q that will tell you whether A has property P
<br>
}}}
<br>
<p>But a Friendliness verifier does not need to do this.  A Friendliness
<br>
verifier just needs to verify whether
<br>
<p>* a certain class of algorithms A (the ones that it is plausibly
<br>
likely the AI system in question will ultimately self-modify into)
<br>
<p>satisfy
<br>
<p>* a particular property P: Friendliness
<br>
<p>The existence of a Friendliness verifier of this nature is certainly
<br>
not ruled out by Rice's Theorem.
<br>
<p>The problems are in formulating what is meant by Friendliness, and
<br>
defining the class of algorithms A.
<br>
<p>A log of the complete history of an AI system is not necessary in
<br>
order to define the plausible algorithm-class; this definition may be
<br>
given potentially by a priori knowledge about the nature of the AI
<br>
system in question.
<br>
<p><em>&gt; &gt; &gt; To put it less formally, we'd be giving our Friendliness module the use
</em><br>
<em>&gt; &gt; &gt; of a genie which is somewhat unreliable and whose reliability in any
</em><br>
<em>&gt; &gt; &gt; particular decision is, for all intents and purposes, difficult to check.
</em><br>
<em>&gt; &gt; True
</em><br>
<em>&gt; Right.  Doesn't this stike you as dangerous?
</em><br>
<p>It strikes me as potentially but not necessarily dangerous -- it all
<br>
depends on the details of the AI architecture.
<br>
<p>This is not the same as the &quot;AI boxing&quot; issue, in which the AI in the
<br>
box is like a genie giving suggestions to the human out of the box. 
<br>
In that case, the genie is proposed to be potentially a sentient mind
<br>
with its own goals and motivations and with a lot of flexibility of
<br>
behavior.  In the case I'm discussing, the &quot;genie&quot; is a
<br>
hard-to-predict hypothesis-suggester giving suggestions to a logical
<br>
cognition component controlled by a Friendliness verifier.  And the
<br>
hard-to-predict hypothesis-suggester does not not need to be a
<br>
sentient mind on its own: it does not need flexible goals,
<br>
motivations, feelings, or the ability to self-modify in any general
<br>
way.  It just needs to be a specialized learning component, similar in
<br>
some ways to Eliezer's proposed Very Powerful Optimization Process
<br>
used for world-simulation inside his Collective Volition proposal (I'm
<br>
saying that it's similar in being powerful at problem-solving without
<br>
having goals, motivations, feelings or strong self-modification; of
<br>
course the problem being solved by my hard-to-predict
<br>
hypothesis-suggester (hypothesis generation) is quite different than
<br>
the problem being solved by Eliezer's VPOP (future prediction)).
<br>
<p><em>&gt; I never said evolutionary programming was &quot;nontraceable&quot;.  What I said was
</em><br>
<em>&gt; &quot;nonverifiable&quot;.  I am not splitting hairs, as these are completely different
</em><br>
<em>&gt; things.  No program is nontraceable!  You can just emulate the CPU and
</em><br>
<em>&gt; observe the contents of the registers and memory at any point in time.  With
</em><br>
<em>&gt; that said though, you can probably see why this sort of traceability is not
</em><br>
<em>&gt; good enough.  What needs to be traceable is not the how the bits were
</em><br>
<em>&gt; shuffled but how the conclusion reached was justified.
</em><br>
<p>a)
<br>
You have not presented any argument as to why verifiability in this
<br>
sense is needed for Friendliness verification.
<br>
<p>b)
<br>
Your criterion of verifiability seems to me to be unreasonably strong,
<br>
and to effectively rule out all metaphorical and heuristic inference. 
<br>
But maybe I have misunderstood your meaning.
<br>
<p>Please consider the following scenario.
<br>
<p>Suppose we have a probabilistic-logical theorem-proving system, which
<br>
arrives at a conclusion.  We can then trace the steps that it took to
<br>
arrive at this conclusion.  But suppose that one of these steps was a
<br>
metaphorical ANALOGY, to some other situation -- a loose and fluid
<br>
analogy, of the sort that humans make all the time but current AI
<br>
reasoning software is bad at making (as Douglas Hofstadter has pointed
<br>
out in detail).
<br>
<p>Then, it seems to me that what your verifiability criterion demands is
<br>
not just that the conclusion arrived at through metaphorical analogy
<br>
be checked for correctness and usefulness -- but that a justification
<br>
be given as to why *that particular analogy* was chosen instead of
<br>
some other one.
<br>
<p>This means that according to your requirement of verifiability (as I
<br>
understand it) a stochastic method can't be used to grab one among
<br>
many possible analogies for handling a situation.  Instead, according
<br>
to your requirement, some kind of verifiable logical inference needs
<br>
to be used to choose the possible analogy.
<br>
<p>In Novamente, right now, the way this kind of thing would be handled
<br>
would be (roughly speaking):
<br>
<p>a) a table would be made of the possible analogies, each one
<br>
quantified with a number indicating its contextual desirability
<br>
<p>b) one of the analogies would be chosen from the table, with a
<br>
probability proportional to the desirability number
<br>
<p>According to your definition of verifiability this is a bad approach
<br>
because of the use of a stochastic selection mechanism in Step b.
<br>
<p>However, I have  my doubts whether it is really possible to achieve
<br>
significant levels of general intelligence under severely finite
<br>
resources without making this kind of stochastic selection in one form
<br>
or another.  (I'm not claiming it is necessary to resort to
<br>
pseudorandom number generation; just that I suspect it's necessary to
<br>
resort to something equally arbitrary for selecting among options in
<br>
cases where there are  many possibly relevant pieces of knowledge in
<br>
memory and not much information to go on regarding which one to use in
<br>
a given inference.)
<br>
<p><p><em>&gt; What I meant was that when B proposes an action, A can either verify that B
</em><br>
<em>&gt; did the correct thing or point out a flaw in B's choice.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The statment above is sufficient but not necessary to show that A is smarter
</em><br>
<em>&gt; than B, in the colloquial sence of the phrase.
</em><br>
<p>I find this interpretation of the &quot;smarter&quot; concept very inadequate.
<br>
<p>For instance, suppose I have a collaborator who is more reliable in
<br>
judgment than me but less creative than me.  For sake of concretness,
<br>
let's call this individual by the name &quot;Cassio.&quot;
<br>
<p>Let A=Ben, B=Cassio
<br>
<p>Now, it may be true that &quot;When  Ben proposes an action, Cassio can
<br>
either verify that Ben proposed the correct thing, or point out a flaw
<br>
in his choice&quot;
<br>
<p>This does not necessarily imply that Cassio is smarter than Ben -- it
<br>
may be that Ben is specialized for hypothesis generation and Cassio is
<br>
specialized for quality-verification.
<br>
<p>The colloquial notion of &quot;smartness&quot; is not really sufficient for
<br>
discussing situations like this, IMO.
<br>
<p><em>&gt; To illustrate, suppose Alice is helping Bob play chess.  Whenever Bob
</em><br>
<em>&gt; suggests a move, she always says something like &quot;I agree with your move&quot; or
</em><br>
<em>&gt; &quot;Yikes!  If you go there, he'll fork your rooks in two moves! You overlooked
</em><br>
<em>&gt; this move here.&quot; If she can always do this, it should be absolutely clear
</em><br>
<em>&gt; that Alice is a better chess player than Bob.
</em><br>
<p>Yes, but I can also imagine two chess masters, where master A was
<br>
better at coming up with bold new ideas and master B was better at
<br>
pointing out subtle flaws in ideas (be they bold new ones or not). 
<br>
These two masters, if they were able to cooperate very closely (e.g.
<br>
through mental telepathy), might be able to play much better than
<br>
either one on their own.  This situation is more like the one at hand.
<br>
<p>(i.e., I think your internal quasirandom selection mechanism has
<br>
chosen a suboptimal analogy here ;-)
<br>
<p>This discussion has gotten fairly in-depth, but the crux of it is, I
<br>
don't feel you have made a convincing argument in favor of your point
<br>
that it is implausible-in-principle to add Friendliness on to an AGI
<br>
architecture designed without a detailed theory of Friendliness on
<br>
hand.  I don't feel Eliezer has ever made a convincing argument in
<br>
favor of this point either.  It may be true but you guys seem far from
<br>
demonstrating it...
<br>
<p>-- Ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="14151.html">Tyler Emerson: "RE: Reminder: SIAI Challenge expires this Sunday | SIAI February news"</a>
<li><strong>Previous message:</strong> <a href="14149.html">Nick Hay: "Re: Think of it as AGI suiciding, not boxing"</a>
<li><strong>In reply to:</strong> <a href="14146.html">Marcello Mathias Herreshoff: "Re: Friendliness not an Add-on"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14152.html">Ben Goertzel: "Re: Friendliness not an Add-on"</a>
<li><strong>Reply:</strong> <a href="14152.html">Ben Goertzel: "Re: Friendliness not an Add-on"</a>
<li><strong>Reply:</strong> <a href="14162.html">Charles D Hixson: "Re: Friendliness not an Add-on"</a>
<li><strong>Reply:</strong> <a href="14164.html">Marcello Mathias Herreshoff: "Re: Friendliness not an Add-on"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14150">[ date ]</a>
<a href="index.html#14150">[ thread ]</a>
<a href="subject.html#14150">[ subject ]</a>
<a href="author.html#14150">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:55 MDT
</em></small></p>
</body>
</html>
