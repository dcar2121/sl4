<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Why playing it safe is the most dangerous thing</title>
<meta name="Author" content="Philip Goetz (philgoetz@gmail.com)">
<meta name="Subject" content="Re: Why playing it safe is the most dangerous thing">
<meta name="Date" content="2006-02-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Why playing it safe is the most dangerous thing</h1>
<!-- received="Fri Feb 24 08:27:01 2006" -->
<!-- isoreceived="20060224152701" -->
<!-- sent="Fri, 24 Feb 2006 10:26:58 -0500" -->
<!-- isosent="20060224152658" -->
<!-- name="Philip Goetz" -->
<!-- email="philgoetz@gmail.com" -->
<!-- subject="Re: Why playing it safe is the most dangerous thing" -->
<!-- id="6fdad3790602240726v5c24e03cv7b4e83692947a4a2@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="638d4e150602240304g7acc09fr6c368250f17c26cc@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Philip Goetz (<a href="mailto:philgoetz@gmail.com?Subject=Re:%20Why%20playing%20it%20safe%20is%20the%20most%20dangerous%20thing"><em>philgoetz@gmail.com</em></a>)<br>
<strong>Date:</strong> Fri Feb 24 2006 - 08:26:58 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="14232.html">Keith Henson: "Mandelbrot brains"</a>
<li><strong>Previous message:</strong> <a href="14230.html">Keith Henson: "Re: DNA as a measure of brain complexity"</a>
<li><strong>In reply to:</strong> <a href="14229.html">Ben Goertzel: "Re: Why playing it safe is the most dangerous thing"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14235.html">Dani Eder: "Re: lottery utility"</a>
<li><strong>Reply:</strong> <a href="14235.html">Dani Eder: "Re: lottery utility"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14231">[ date ]</a>
<a href="index.html#14231">[ thread ]</a>
<a href="subject.html#14231">[ subject ]</a>
<a href="author.html#14231">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 2/24/06, Ben Goertzel &lt;<a href="mailto:ben@goertzel.org?Subject=Re:%20Why%20playing%20it%20safe%20is%20the%20most%20dangerous%20thing">ben@goertzel.org</a>&gt; wrote:
<br>
<p><em>&gt; Peter, two points:
</em><br>
<em>&gt;
</em><br>
<em>&gt; 1)
</em><br>
<em>&gt; Eliezer has sometimes proposed that a Singularity not properly planned
</em><br>
<em>&gt; with regard to Friendly AI is almost certain to lead to human
</em><br>
<em>&gt; extinction.  But this has not been convincingly argued for.  He has
</em><br>
<em>&gt; merely shown why this is a significant possibility.
</em><br>
<p>Human extinction might be a likely outcome.  I was speaking of
<br>
extinction of life, which I regard as a definitely bad thing, and an
<br>
unlikely outcome.
<br>
<p><em>&gt; 2)
</em><br>
<em>&gt;  Phil is not really suggesting that rushing into the Singularity
</em><br>
<em>&gt; blindly is the best possible option.  He's merely suggesting that the
</em><br>
<em>&gt; *better-in-principle* options are not very plausible, so that we
</em><br>
<em>&gt; should focus on it because it's by far the highest-probability
</em><br>
<em>&gt; plausible option.
</em><br>
<em>&gt;
</em><br>
<em>&gt; As I understand it, a caricature of Phil's argument would go something like:
</em><br>
<em>&gt;
</em><br>
<em>&gt; * If we launch a Singularity before the jerks in power figure out
</em><br>
<em>&gt; what's up, we have a 50/50 or so chance of a good outcome (by the
</em><br>
<em>&gt; Principle of Indifference, since what happens after the Singularity is
</em><br>
<em>&gt; totally opaque to us lesser beings)
</em><br>
<em>&gt;
</em><br>
<em>&gt; * If we don't launch a Singularity before the jerks in power figure
</em><br>
<em>&gt; out what's up, we have a much lower chance of a good outcome, because
</em><br>
<em>&gt; those jerks are likely to find some way to screw things up
</em><br>
<em>&gt;
</em><br>
<em>&gt; * The truly better-in-principle approach to the Singularity would
</em><br>
<em>&gt; require a long period of peaceful study and experimentation before
</em><br>
<em>&gt; launching the Singularity: but this is just not feasible because once
</em><br>
<em>&gt; the tech gets to a certain point, the jerks in power will pay people
</em><br>
<em>&gt; to develop it quickly and in an unsafe way
</em><br>
<em>&gt;
</em><br>
<em>&gt; Specialized to AGI, the argument would go something like:
</em><br>
<em>&gt;
</em><br>
<em>&gt; -- making provably safe AGI is really hard and will take time X
</em><br>
<em>&gt; -- for a dedicated maverick team to make AGI with unknown safety may
</em><br>
<em>&gt; be easier, and will take time Y
</em><br>
<em>&gt; -- after enough time has passed, some jerks will make unsafe and nasty
</em><br>
<em>&gt; AI; this will take time Z
</em><br>
<em>&gt;
</em><br>
<em>&gt; If
</em><br>
<em>&gt;
</em><br>
<em>&gt; Y &lt; Z &lt; X
</em><br>
<em>&gt;
</em><br>
<em>&gt; then it may be optimal to make AGI with unknown safety.
</em><br>
<p>Yes!  That's what I meant, thank you.  With emphasis on the idea that
<br>
the AI made in time Z would be deliberately designed to lead to
<br>
totalitarianism.
<br>
<p>We could add the notion of negative utility.  &quot;Negative utility&quot; is my
<br>
explanation for why lotteries are so popular in poor communities,
<br>
despite the fact that the expected ROI of a lottery ticket is &lt; 1;
<br>
also why people choose crack addiction despite knowing in advance the
<br>
outcome.
<br>
<p>Suppose, contemplating whether to buy a lottery ticket, a person sums
<br>
up the expected utility of their entire future life without buying the
<br>
lottery ticket, and concludes it is below the &quot;zero utility level&quot;
<br>
below which they would be better off dead.  They then consider the
<br>
expected utility on buying the lottery ticket.  This gives them two
<br>
possible outcomes: one of very high probability, and a slightly lower
<br>
negative utilty; one of small probability, with positive utilty.
<br>
<p>Rather than combining these two, the person reasons that they can kill
<br>
themselves any time they choose, and thus replaces each of the
<br>
negative-utility outcomes with a zero &quot;suicide utility&quot;.  The
<br>
low-probability positive outcome, averaged together with the
<br>
high-probability suicide utility of zero, produces an average utility,
<br>
which is higher than the suicide utility (zero) of their life without
<br>
the lottery ticket.
<br>
<p>(Note that finding oneself with a losing lottery ticket doesn't then
<br>
require one to commit suicide.  One merely begins looking for other
<br>
low-probability branches - future lottery tickets - leading towards
<br>
positive utility.)
<br>
<p>(The crack cocaine case involves planning to create a brief period of
<br>
positive utility, followed by a long period of negative utility, which
<br>
averages out to lower summed utility than without crack.)
<br>
<p>More specifically, this negative utility theory says that, when
<br>
comparing possible actions, you compare the expected utilities only of
<br>
the portions of the probability distributions with positive utility. 
<br>
If you consider the probability distribution on future expected summed
<br>
life utilities, and let
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;- U0 be the positive area for the no-ticket distribution (the
<br>
integral of utility over all outcomes under which utility is positive)
<br>
&nbsp;&nbsp;&nbsp;&nbsp;- UT be the positive area for the bought-a-ticket distribution
<br>
<p>then UT &gt; U0 =&gt; you should buy a ticket.
<br>
<p>We can apply similar logic to possible outcomes of the Singularity. 
<br>
If, as I've argued, the careful approach provides us with a near-1
<br>
probability of negative utility, and the damn-the-torpedoes approach
<br>
provides us with a greater-than-epsilon probability of positive
<br>
utility, then we seem to be in a situation where the summed positive
<br>
utility of damn-the-torpedos is greater than the summed positive
<br>
utility of the cautious approach, EVEN if the expected utility of the
<br>
cautious approach is greater.
<br>
<p>- Phil
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="14232.html">Keith Henson: "Mandelbrot brains"</a>
<li><strong>Previous message:</strong> <a href="14230.html">Keith Henson: "Re: DNA as a measure of brain complexity"</a>
<li><strong>In reply to:</strong> <a href="14229.html">Ben Goertzel: "Re: Why playing it safe is the most dangerous thing"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14235.html">Dani Eder: "Re: lottery utility"</a>
<li><strong>Reply:</strong> <a href="14235.html">Dani Eder: "Re: lottery utility"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14231">[ date ]</a>
<a href="index.html#14231">[ thread ]</a>
<a href="subject.html#14231">[ subject ]</a>
<a href="author.html#14231">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
