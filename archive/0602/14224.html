<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Why playing it safe is the most dangerous thing</title>
<meta name="Author" content="Peter de Blanc (peter.deblanc@verizon.net)">
<meta name="Subject" content="Re: Why playing it safe is the most dangerous thing">
<meta name="Date" content="2006-02-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Why playing it safe is the most dangerous thing</h1>
<!-- received="Thu Feb 23 23:02:08 2006" -->
<!-- isoreceived="20060224060208" -->
<!-- sent="Fri, 24 Feb 2006 00:56:55 -0500" -->
<!-- isosent="20060224055655" -->
<!-- name="Peter de Blanc" -->
<!-- email="peter.deblanc@verizon.net" -->
<!-- subject="Re: Why playing it safe is the most dangerous thing" -->
<!-- id="1140760615.21732.8.camel@localhost.localdomain" -->
<!-- inreplyto="6fdad3790602232033h4e79cb8ey59e8502883299600@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Peter de Blanc (<a href="mailto:peter.deblanc@verizon.net?Subject=Re:%20Why%20playing%20it%20safe%20is%20the%20most%20dangerous%20thing"><em>peter.deblanc@verizon.net</em></a>)<br>
<strong>Date:</strong> Thu Feb 23 2006 - 22:56:55 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="14225.html">Keith Henson: "Re: DNA as a measure of brain complexity [WAS Re: ESSAY: Program length, Omega and Friendliness]"</a>
<li><strong>Previous message:</strong> <a href="14223.html">Olie L: "RE: Not exactly"</a>
<li><strong>In reply to:</strong> <a href="14219.html">Philip Goetz: "Why playing it safe is the most dangerous thing"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14229.html">Ben Goertzel: "Re: Why playing it safe is the most dangerous thing"</a>
<li><strong>Reply:</strong> <a href="14229.html">Ben Goertzel: "Re: Why playing it safe is the most dangerous thing"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14224">[ date ]</a>
<a href="index.html#14224">[ thread ]</a>
<a href="subject.html#14224">[ subject ]</a>
<a href="author.html#14224">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Thu, 2006-02-23 at 23:33 -0500, Philip Goetz wrote:
<br>
<em>&gt; - The worst possible outcome of the Singularity is arguably not total
</em><br>
<em>&gt; extinction, but a super-Orwellian situation in which the people in
</em><br>
<em>&gt; power dictate the thought and actions of everyone else --  and,
</em><br>
<em>&gt; ultimately, George W. Bush or some equivalent wins the singularity and
</em><br>
<em>&gt; becomes the only remaining personality in the solar system.
</em><br>
<p>Extinction is worse.
<br>
<p><em>&gt; - We've already seen, with genetics, what happens when, as a society,
</em><br>
<em>&gt; we &quot;take time to think through the ethical implications&quot;.  We convene
</em><br>
<em>&gt; a panel of experts - Leon Kass &amp; co. on the President's Bioethics
</em><br>
<em>&gt; Committee - and, by coincidence, they come out with exactly the
</em><br>
<em>&gt; recommendation that the President wants.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; - A scenario in which we take time to &quot;consider the ethical
</em><br>
<em>&gt; implications&quot; and regulate the transition to singularity is almost
</em><br>
<em>&gt; guaranteed to result in taking those measures that strengthen the
</em><br>
<em>&gt; power of those already in power, and that seem most likely to lead
</em><br>
<em>&gt; lead to the worst possible scenario:
</em><br>
<em>&gt; Dubya-(or-Cheney)-equivalent-as-Ubermind.
</em><br>
<p>SIAI is not proposing that the US government or the UN should decide how
<br>
to design a Friendly AI. SIAI is not proposing that &quot;we, as a society&quot;
<br>
should be thinking about how to build a Friendly AI. SIAI is trying to
<br>
build a Friendly AI. Believe it or not, individual human beings are
<br>
capable of thinking intelligently about ethics.
<br>
<p><em>&gt; - ... we must conclude that the SAFEST thing to do is to rush into AI
</em><br>
<em>&gt; and the Singularity blindly, without pause, before the Powers That Be
</em><br>
<em>&gt; can control and divert it.
</em><br>
<p>I don't see how committing mass suicide is the safest thing to do.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="14225.html">Keith Henson: "Re: DNA as a measure of brain complexity [WAS Re: ESSAY: Program length, Omega and Friendliness]"</a>
<li><strong>Previous message:</strong> <a href="14223.html">Olie L: "RE: Not exactly"</a>
<li><strong>In reply to:</strong> <a href="14219.html">Philip Goetz: "Why playing it safe is the most dangerous thing"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14229.html">Ben Goertzel: "Re: Why playing it safe is the most dangerous thing"</a>
<li><strong>Reply:</strong> <a href="14229.html">Ben Goertzel: "Re: Why playing it safe is the most dangerous thing"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14224">[ date ]</a>
<a href="index.html#14224">[ thread ]</a>
<a href="subject.html#14224">[ subject ]</a>
<a href="author.html#14224">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
