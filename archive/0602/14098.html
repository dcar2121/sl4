<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Singularity Institute: Likely to win the race to build GAI?</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="Re: Singularity Institute: Likely to win the race to build GAI?">
<meta name="Date" content="2006-02-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Singularity Institute: Likely to win the race to build GAI?</h1>
<!-- received="Wed Feb 15 13:11:47 2006" -->
<!-- isoreceived="20060215201147" -->
<!-- sent="Wed, 15 Feb 2006 15:11:42 -0500" -->
<!-- isosent="20060215201142" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="Re: Singularity Institute: Likely to win the race to build GAI?" -->
<!-- id="638d4e150602151211n1cd41001pccb00fcd3dbdc31c@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="43F36968.4020107@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=Re:%20Singularity%20Institute:%20Likely%20to%20win%20the%20race%20to%20build%20GAI?"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Wed Feb 15 2006 - 13:11:42 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="14099.html">Peter Voss: "RE: Singularity Institute: Likely to win the race to build GAI?"</a>
<li><strong>Previous message:</strong> <a href="14097.html">Eliezer S. Yudkowsky: "Re: Singularity Institute: Likely to win the race to build GAI?"</a>
<li><strong>In reply to:</strong> <a href="14097.html">Eliezer S. Yudkowsky: "Re: Singularity Institute: Likely to win the race to build GAI?"</a>
<!-- nextthread="start" -->
<li><strong>Reply:</strong> <a href="14099.html">Peter Voss: "RE: Singularity Institute: Likely to win the race to build GAI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14098">[ date ]</a>
<a href="index.html#14098">[ thread ]</a>
<a href="subject.html#14098">[ subject ]</a>
<a href="author.html#14098">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eli,
<br>
<p><em>&gt; You can't &quot;add Friendliness&quot;.  It adds requirements like determinism and
</em><br>
<em>&gt; verifiability to the entire architecture.  It rules out entire classes
</em><br>
<em>&gt; of popular AI techniques, like evolutionary programming,
</em><br>
<p>I have never seen you give a convincing argument in favor of this
<br>
point, though I have heard you make it before.
<br>
<p>I don't see why it must be true that an AI system which is Friendly in
<br>
the sense that one can prove its probability of Friendliness is
<br>
greater than 99.99% (to pull a number from a certain well-known
<br>
orifice), must necessarily be &quot;deterministic&quot; in all its operations.
<br>
<p>Firstly, I am not really sure what you mean by &quot;deterministic&quot;, since
<br>
of course even techniques that are typically considered stochastic
<br>
such as evolutionary programming are actually deterministic when
<br>
implemented on digital computers (assuming one is not using a quantum
<br>
random number generator or any other weird tricks).  Perhaps you mean
<br>
something like: &quot;a process whose outcome is relatively easy to
<br>
approximately predict given an approximation of its initial state&quot;? 
<br>
In the rest of this email I will use the terminology &quot;hard-to-predict&quot;
<br>
rather than &quot;nondeterministic&quot; to avoid confusion when discussing
<br>
algorithms like evolutionary programming.
<br>
<p>It seems to me plausible that a FAI system could utilize evolutionary
<br>
programming or other hard-to-predict techniques in a subsidiary role,
<br>
e.g. for &quot;speculative concept creation&quot;, and then utilize a more
<br>
easily-predictable subsystem to decide how and whether to use the
<br>
output of the hard-to-predict subsystem.
<br>
<p>After all, a Friendly AI is going to have to deal with hard-to-predict
<br>
sensations and reactions from the external world.  If it can maintain
<br>
Friendliness in the face of external difficulty-of-prediction, I don't
<br>
see why it would be unable to maintain Friendliness in the face of an
<br>
internal hard-to-predict subsystem.
<br>
<p>I think it is more plausible to conjecture that an FAI would have to
<br>
have a relatively easy-to-predict subsystem in a &quot;controlling role&quot;
<br>
(although I realize that specifying the notion of &quot;controlling role&quot;
<br>
is a very tricky matter, I hope the intended conceptual meaning of the
<br>
statement is clear).
<br>
<p>This point is not just a minor technical point, I think it also
<br>
pertains indirectly to your claim that Friendliness cannot plausibly
<br>
be added onto an AGI architecture.  I do not believe you have  made a
<br>
convincing argument in favor of this assertion.  Potentially, one
<br>
could have a multi-component AGI system without guaranteed
<br>
Friendliness --- but one could then figure out how to insert a
<br>
Friendliness-guaranteeing subsystem into the AGI system in a
<br>
&quot;controlling role&quot;, thus making the overall architecture Friendly.
<br>
<p>Of course, this latter point is not just theoretical for me because I
<br>
think it might be possible within the Novamente architecture. 
<br>
Plausibly (but quite speculatively), within some future Novamente
<br>
version, it might be possible to transition from a NGF (non-guaranteed
<br>
Friendly) Novamente version to a GF (guaranteed Friendly) version via
<br>
replacing the inference control&quot; subsystem with a
<br>
Friendliness-compliant inference control subsystem, while leaving the
<br>
other parts of the system untouched or close to untouched.
<br>
<p>For example, the evolutionary learning component of Novamente might
<br>
make up some whacky possibilities for possible actions --- but the
<br>
inference control system would be in charge of running the inferences
<br>
that decide whether these actions should be taken, and this is where
<br>
the judgment of Friendliness-compliance would be implemented.
<br>
<p>[Unfortunately I do not currently know how to implement
<br>
Friendliness-compliance within a probabilistic-inference-control
<br>
subsystem in a computationally tractable way, though.]
<br>
<p>All in all, I find that your statements about the relation between FAI
<br>
and AGI and the needed capabilities and psychologies of researchers in
<br>
these areas are predicated on your particular hypotheses about FAI and
<br>
AGI, for which which you have not argued all that convincingly.  I
<br>
respect your perspective and find it interesting but after many years
<br>
of listening to you carefully and reflecting upon your writings and
<br>
statements I still am not convinced!!
<br>
<p>-- Ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="14099.html">Peter Voss: "RE: Singularity Institute: Likely to win the race to build GAI?"</a>
<li><strong>Previous message:</strong> <a href="14097.html">Eliezer S. Yudkowsky: "Re: Singularity Institute: Likely to win the race to build GAI?"</a>
<li><strong>In reply to:</strong> <a href="14097.html">Eliezer S. Yudkowsky: "Re: Singularity Institute: Likely to win the race to build GAI?"</a>
<!-- nextthread="start" -->
<li><strong>Reply:</strong> <a href="14099.html">Peter Voss: "RE: Singularity Institute: Likely to win the race to build GAI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14098">[ date ]</a>
<a href="index.html#14098">[ thread ]</a>
<a href="subject.html#14098">[ subject ]</a>
<a href="author.html#14098">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:55 MDT
</em></small></p>
</body>
</html>
