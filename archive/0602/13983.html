<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AGI thoughts was[AGI Reproduction? (Safety)]</title>
<meta name="Author" content="P K (kpete1@hotmail.com)">
<meta name="Subject" content="Re: AGI thoughts was[AGI Reproduction? (Safety)]">
<meta name="Date" content="2006-02-04">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AGI thoughts was[AGI Reproduction? (Safety)]</h1>
<!-- received="Sat Feb  4 00:29:32 2006" -->
<!-- isoreceived="20060204072932" -->
<!-- sent="Sat, 04 Feb 2006 07:29:30 +0000" -->
<!-- isosent="20060204072930" -->
<!-- name="P K" -->
<!-- email="kpete1@hotmail.com" -->
<!-- subject="Re: AGI thoughts was[AGI Reproduction? (Safety)]" -->
<!-- id="BAY108-F149147470D6F4221256690910C0@phx.gbl" -->
<!-- inreplyto="005501c62941$9f81e120$c49cfea9@zeeddeux" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> P K (<a href="mailto:kpete1@hotmail.com?Subject=Re:%20AGI%20thoughts%20was[AGI%20Reproduction?%20(Safety)]"><em>kpete1@hotmail.com</em></a>)<br>
<strong>Date:</strong> Sat Feb 04 2006 - 00:29:30 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13984.html">Rick Geniale: "Re: AGI thoughts was[AGI Reproduction? (Safety)]"</a>
<li><strong>Previous message:</strong> <a href="13982.html">Phillip Huggan: "Re: Possibility Space vs. Extinction (was Re: Genetically Smartifying other Mammals)"</a>
<li><strong>In reply to:</strong> <a href="13980.html">nuzz604: "Re: AGI Reproduction? (Safety)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13984.html">Rick Geniale: "Re: AGI thoughts was[AGI Reproduction? (Safety)]"</a>
<li><strong>Reply:</strong> <a href="13984.html">Rick Geniale: "Re: AGI thoughts was[AGI Reproduction? (Safety)]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13983">[ date ]</a>
<a href="index.html#13983">[ thread ]</a>
<a href="subject.html#13983">[ subject ]</a>
<a href="author.html#13983">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;From: &quot;nuzz604&quot; &lt;<a href="mailto:nuzz604@gmail.com?Subject=Re:%20AGI%20thoughts%20was[AGI%20Reproduction?%20(Safety)]">nuzz604@gmail.com</a>&gt;
</em><br>
<em>&gt;Reply-To: <a href="mailto:sl4@sl4.org?Subject=Re:%20AGI%20thoughts%20was[AGI%20Reproduction?%20(Safety)]">sl4@sl4.org</a>
</em><br>
<em>&gt;To: &lt;<a href="mailto:sl4@sl4.org?Subject=Re:%20AGI%20thoughts%20was[AGI%20Reproduction?%20(Safety)]">sl4@sl4.org</a>&gt;
</em><br>
<em>&gt;Subject: Re: AGI Reproduction? (Safety)
</em><br>
<em>&gt;Date: Fri, 3 Feb 2006 20:15:20 -0800
</em><br>
<em>&gt;
</em><br>
<em>&gt;I understand that you have good intentions with AGI.  My worry involves 
</em><br>
<em>&gt;-accidentally- creating an unfriendly AGI (And this worry applies to 
</em><br>
<em>&gt;anybody who builds an AGI).  You can have good intentions and still create 
</em><br>
<em>&gt;an unfriendly AI because of some design flaw (even if it appears to be a 
</em><br>
<em>&gt;great design).
</em><br>
<p><em>&gt;I am worried because no one really knows how a Seed AI will function when 
</em><br>
<em>&gt;it is turned on, and whether it will be friendly or not.
</em><br>
<p>The odds of randomly stumbling upon a working AGI are extremely small. AGI 
<br>
programming will most likely be a very deliberate process. In other words, 
<br>
if and when AGI is created, the builder(s) will most likely know exactly 
<br>
what they are doing.
<br>
<p><em>&gt;There are so many things that can go wrong.
</em><br>
<p>Yes, but for an AGI to work, allot of things would have to go right. Why 
<br>
would builder(s) capable of overcoming the enormous technical challenges of 
<br>
making a working AGI succeed on all the other points and fail on that 
<br>
particular point; friendliness. I'm amazed at how, in SF, AGI creators are 
<br>
smart enough to build it but give goal systems so stupidly flawed that...(I 
<br>
know SF is just for entertainment, I'm trying to prove a point here.)
<br>
<p>The complexity of the task (AGI) is naturally selecting for builder(s) that 
<br>
have a clue.
<br>
<p>Do you have any particular reason to believe that the FAI problem is more 
<br>
complex than the AGI problem? Most people seem to believe that intuitively. 
<br>
This is due to two reasons.
<br>
1) It is easier to argue about FAI because it doesn't require as much 
<br>
technical knowledge. It is easier to grasp the complexity of the 
<br>
Friendliness problem first hand. It looks like a big thing to solve.
<br>
2) General intelligence seems kind of straightforward because we do it all 
<br>
the time however; doing it is definitely not the same as coding it. In fact, 
<br>
people systematically underestimate how complex AGI really is. There have 
<br>
been many that claimed to have the AGI solution. They have all failed 
<br>
todate. If you ever try coding an AGI you will very likely realize it is 
<br>
more complex than you originally thought.
<br>
<p>These two reasons cause people to focus on the FAI problem more than on the 
<br>
AGI problem. Which, in my opinion is a mistake at this stage.
<br>
<p>There is another twist to this. The FAI or UFAI concepts are mostly useless 
<br>
without AGI however; working on AGI will very likely help develop FAI 
<br>
theory.
<br>
1) AGI theory will give a clearer picture of how FAI can be technically 
<br>
implemented.
<br>
2) AGI work can have semi-intelligent tools as offshoots that, when combined 
<br>
with human intelligence, enhance it (ex: human + computer + Internet &gt; 
<br>
human). We could then work on FAI theory more efficiently (and AGI aswell).
<br>
<p><em>&gt;This is why I think that the system and its safety should be analyzed, and 
</em><br>
<em>&gt;go through at least several phases of testing before activation is even 
</em><br>
<em>&gt;considered.
</em><br>
<p>There will be plenty of testing all along the project. And there wont be 
<br>
just a single activation where the coders put some jargon together, compile 
<br>
and see what happens. (See above)
<br>
Poof-&gt; FAI -&gt; YAY! -&gt;JK -&gt;UFAI -&gt;NOO! -&gt;R.I.P.
<br>
<p><em>&gt;I would also feel better if these tests are conducted by a team of 
</em><br>
<em>&gt;independent AGI researchers rather than just one firm, or RGE Corp. by 
</em><br>
<em>&gt;itself.
</em><br>
<p>The AGI coder(s) will be pre-selected for competence by the complexity of 
<br>
the task. The point is moot for evil coder(s) since they wouldn't agree for 
<br>
inspection anyway.
<br>
How would the &quot;independent AGI researchers&quot; be selected? How would we know 
<br>
they are trustworthy and competent? I think this introduces more uncertainty 
<br>
than it removes.
<br>
<p><em>&gt;  You can have many shots at creating a Seed AI, but you only get one shot 
</em><br>
<em>&gt;at creating a friendly one.
</em><br>
<em>&gt;  If this is the Seed AI that is successful, then I say make that friendly 
</em><br>
<em>&gt;shot count.
</em><br>
<p>If you are shooting randomly, there is a small chance you will hit the right 
<br>
target, a slightly larger chance you will hit the wrong target, and an 
<br>
overwhelmingly huge chance you will never hit anything. If you're one of the 
<br>
few who have some talent, opportunity, and persistence, you can perfect your 
<br>
archery and hit targets at will. We hope you aim at FAI for all.
<br>
<p><em>&gt;Since you want to be open with the technology, I think that it is an idea 
</em><br>
<em>&gt;worth considering.
</em><br>
<p>I am somewhat suspicious of AGI claims. The more advanced an AI is the less 
<br>
public proving it needs. A seed AI could recursively self improve, start the 
<br>
singularity ... trust me we would know. A superhuman AI that is a bit short 
<br>
of the Singularity (could happen) could at least make its owners 
<br>
millionaires, just let it play with the stock market. Even a slow AI could 
<br>
do some amazing things. At least it would be immune to human biases. There 
<br>
might be some areas where it could outperform humans. They would have 
<br>
investors chasing them not them having to prove themselves. When I think of 
<br>
some workshop format proving, what comes to mind is Eliza type AI. It looks 
<br>
smart at first glance but is inferior to humans in practically every way. 
<br>
I'm not trying to be rude, but the lack of a splash sort of indicates that 
<br>
there isn't that much to see.
<br>
<p>_________________________________________________________________
<br>
Take advantage of powerful junk e-mail filters built on patented Microsoft® 
<br>
SmartScreen Technology. 
<br>
<a href="http://join.msn.com/?pgmarket=en-ca&amp;page=byoa/prem&amp;xAPID=1994&amp;DI=1034&amp;SU=http://hotmail.com/enca&amp;HL=Market_MSNIS_Taglines">http://join.msn.com/?pgmarket=en-ca&amp;page=byoa/prem&amp;xAPID=1994&amp;DI=1034&amp;SU=http://hotmail.com/enca&amp;HL=Market_MSNIS_Taglines</a><br>
&nbsp;&nbsp;Start enjoying all the benefits of MSN® Premium right now and get the 
<br>
first two months FREE*.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13984.html">Rick Geniale: "Re: AGI thoughts was[AGI Reproduction? (Safety)]"</a>
<li><strong>Previous message:</strong> <a href="13982.html">Phillip Huggan: "Re: Possibility Space vs. Extinction (was Re: Genetically Smartifying other Mammals)"</a>
<li><strong>In reply to:</strong> <a href="13980.html">nuzz604: "Re: AGI Reproduction? (Safety)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13984.html">Rick Geniale: "Re: AGI thoughts was[AGI Reproduction? (Safety)]"</a>
<li><strong>Reply:</strong> <a href="13984.html">Rick Geniale: "Re: AGI thoughts was[AGI Reproduction? (Safety)]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13983">[ date ]</a>
<a href="index.html#13983">[ thread ]</a>
<a href="subject.html#13983">[ subject ]</a>
<a href="author.html#13983">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:55 MDT
</em></small></p>
</body>
</html>
