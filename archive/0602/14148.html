<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Singularity Institute: Likely to win the race to build GAI?</title>
<meta name="Author" content="Bruce J. Klein (bruce@novamente.net)">
<meta name="Subject" content="Re: Singularity Institute: Likely to win the race to build GAI?">
<meta name="Date" content="2006-02-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Singularity Institute: Likely to win the race to build GAI?</h1>
<!-- received="Sun Feb 19 02:40:42 2006" -->
<!-- isoreceived="20060219094042" -->
<!-- sent="Sun, 19 Feb 2006 04:40:44 -0500" -->
<!-- isosent="20060219094044" -->
<!-- name="Bruce J. Klein" -->
<!-- email="bruce@novamente.net" -->
<!-- subject="Re: Singularity Institute: Likely to win the race to build GAI?" -->
<!-- id="43F83D1C.7050004@novamente.net" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="638d4e150602140957t316dfa4kd1439e0ca705a9e6@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Bruce J. Klein (<a href="mailto:bruce@novamente.net?Subject=Re:%20Singularity%20Institute:%20Likely%20to%20win%20the%20race%20to%20build%20GAI?"><em>bruce@novamente.net</em></a>)<br>
<strong>Date:</strong> Sun Feb 19 2006 - 02:40:44 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="14149.html">Nick Hay: "Re: Think of it as AGI suiciding, not boxing"</a>
<li><strong>Previous message:</strong> <a href="14147.html">Randall Randall: "Re: Think of it as AGI suiciding, not boxing"</a>
<li><strong>In reply to:</strong> <a href="14080.html">Ben Goertzel: "Re: Singularity Institute: Likely to win the race to build GAI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14188.html">Eliezer S. Yudkowsky: "Re: Singularity Institute: Likely to win the race to build GAI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14148">[ date ]</a>
<a href="index.html#14148">[ thread ]</a>
<a href="subject.html#14148">[ subject ]</a>
<a href="author.html#14148">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hoping to facilitate discussions, here 
<br>
is the AGIRI compiled list of various 
<br>
AGI System-Building Projects:
<br>
<p><a href="http://www.agiri.org/forum/index.php?showtopic=44">http://www.agiri.org/forum/index.php?showtopic=44</a>
<br>
<p>The list is &quot;semi-comprehensive&quot; so that 
<br>
you should feel comfortable in making 
<br>
suggestions for additions/subtractions.
<br>
<p>Bruce
<br>
<p>Ben Goertzel wrote:
<br>
<em>&gt; In fact I know of a number of individuals/groups in addition to myself
</em><br>
<em>&gt; who fall into this category (significant progress made toward
</em><br>
<em>&gt; realizing a software implementation whose design has apparent AGI
</em><br>
<em>&gt; potential), though I'm not sure which of them are list members.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; In addition to my Novamente project (www.novamente.net), I would
</em><br>
<em>&gt; mention Steve Omohundro
</em><br>
<em>&gt; 
</em><br>
<em>&gt; <a href="http://home.att.net/~om3/selfawaresystems.html">http://home.att.net/~om3/selfawaresystems.html</a>
</em><br>
<em>&gt; 
</em><br>
<em>&gt; (who is working on a self-modifying AI system using his own variant of
</em><br>
<em>&gt; Bayesian learning) and James Rogers with his
</em><br>
<em>&gt; algorithmic-information-theory related AGI design (James is a list
</em><br>
<em>&gt; member, but his work has been kept sufficiently proprietary that I
</em><br>
<em>&gt; can't say much about it).  There are many others as well...
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Based on crude considerations, it would seem SIAI is nowhere near the
</em><br>
<em>&gt; most advanced group on the path toward an AGI implementation.  On the
</em><br>
<em>&gt; other hand, it's of course possible that those of us who are &quot;further
</em><br>
<em>&gt; along&quot; all have wrong ideas (though I doubt it!) and SIAI will come up
</em><br>
<em>&gt; with the right idea in 2008 or whenever and then proceed rapidly
</em><br>
<em>&gt; toward the end goal.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; ben
</em><br>
<em>&gt; ben
</em><br>
<em>&gt; 
</em><br>
<em>&gt; On 2/14/06, pdugan &lt;<a href="mailto:pdugan@vt.edu?Subject=Re:%20Singularity%20Institute:%20Likely%20to%20win%20the%20race%20to%20build%20GAI?">pdugan@vt.edu</a>&gt; wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;There is a certain list member who already has an AGI model more than half
</em><br>
<em>&gt;&gt;implemented, making it a few years from testablility to see if it classifies
</em><br>
<em>&gt;&gt;as a genuine AGI, and if so then maybe another half a decade before something
</em><br>
<em>&gt;&gt;like recursive self-improvement becomes possible.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;  Patrick
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;===== Original Message From P K &lt;<a href="mailto:kpete1@hotmail.com?Subject=Re:%20Singularity%20Institute:%20Likely%20to%20win%20the%20race%20to%20build%20GAI?">kpete1@hotmail.com</a>&gt; =====
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;&gt;Yes, I know that they are working on _Friendly_ GAI. But my question is:
</em><br>
<em>&gt;&gt;&gt;&gt;What reason is there to think that the Institute has any real chance of
</em><br>
<em>&gt;&gt;&gt;&gt;winning the race to General Artificial Intelligence of any sort, beating
</em><br>
<em>&gt;&gt;&gt;&gt;out those thousands of very smart GAI researchers?
</em><br>
<em>&gt;&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;There is no particular reason(s) I can think of that make the Institute more
</em><br>
<em>&gt;&gt;&gt;likely to develop AGI than any other organization with skilled developers.
</em><br>
<em>&gt;&gt;&gt;It's all a fog. The only way to see if their ideas have any merit is to try
</em><br>
<em>&gt;&gt;&gt;them out. Also, I suspect their donations would increase if they showed some
</em><br>
<em>&gt;&gt;&gt;proofs of concept. It's all speculative at this point.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;As for predicting success or failure, the best calibrated answer is to
</em><br>
<em>&gt;&gt;&gt;predict failure to anyone attempting to build a GAI. You would be right most
</em><br>
<em>&gt;&gt;&gt;of the time and wrong probably only once or right all the time (o dear,
</em><br>
<em>&gt;&gt;&gt;heresy).
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;That doesn't mean it isn't worth trying. By analogy, think of AGI developers
</em><br>
<em>&gt;&gt;&gt;as individual sperm trying to reach the egg. The odds of any individual are
</em><br>
<em>&gt;&gt;&gt;incredibly small but the reward is so good it would be a shame not to try.
</em><br>
<em>&gt;&gt;&gt;Also, FAI has to be developed only once for all to benefit.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;_________________________________________________________________
</em><br>
<em>&gt;&gt;&gt;MSN(r) Calendar keeps you organized and takes the effort out of scheduling
</em><br>
<em>&gt;&gt;&gt;get-togethers.
</em><br>
<em>&gt;&gt;&gt;<a href="http://join.msn.com/?pgmarket=en-ca&amp;page=byoa/prem&amp;xAPID=1994&amp;DI=1034&amp;SU=http">http://join.msn.com/?pgmarket=en-ca&amp;page=byoa/prem&amp;xAPID=1994&amp;DI=1034&amp;SU=http</a></em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;://hotmail.com/enca&amp;HL=Market_MSNIS_Taglines
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; Start enjoying all the benefits of MSN(r) Premium right now and get the
</em><br>
<em>&gt;&gt;&gt;first two months FREE*.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="14149.html">Nick Hay: "Re: Think of it as AGI suiciding, not boxing"</a>
<li><strong>Previous message:</strong> <a href="14147.html">Randall Randall: "Re: Think of it as AGI suiciding, not boxing"</a>
<li><strong>In reply to:</strong> <a href="14080.html">Ben Goertzel: "Re: Singularity Institute: Likely to win the race to build GAI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14188.html">Eliezer S. Yudkowsky: "Re: Singularity Institute: Likely to win the race to build GAI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14148">[ date ]</a>
<a href="index.html#14148">[ thread ]</a>
<a href="subject.html#14148">[ subject ]</a>
<a href="author.html#14148">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:55 MDT
</em></small></p>
</body>
</html>
