<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Singularity Objections: General AI, Implementation</title>
<meta name="Author" content="Thomas McCabe (pphysics141@gmail.com)">
<meta name="Subject" content="Singularity Objections: General AI, Implementation">
<meta name="Date" content="2008-01-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Singularity Objections: General AI, Implementation</h1>
<!-- received="Tue Jan 29 13:39:52 2008" -->
<!-- isoreceived="20080129203952" -->
<!-- sent="Tue, 29 Jan 2008 15:37:30 -0500" -->
<!-- isosent="20080129203730" -->
<!-- name="Thomas McCabe" -->
<!-- email="pphysics141@gmail.com" -->
<!-- subject="Singularity Objections: General AI, Implementation" -->
<!-- id="b7a9e8680801291237l1298b214n548e429033b7fd80@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas McCabe (<a href="mailto:pphysics141@gmail.com?Subject=Re:%20Singularity%20Objections:%20General%20AI,%20Implementation"><em>pphysics141@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Jan 29 2008 - 13:37:30 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17548.html">Thomas McCabe: "Singularity Objections: Friendliness, desirability"</a>
<li><strong>Previous message:</strong> <a href="17546.html">Thomas McCabe: "Singularity Objections: General AI, Consciousness"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17547">[ date ]</a>
<a href="index.html#17547">[ thread ]</a>
<a href="subject.html#17547">[ subject ]</a>
<a href="author.html#17547">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Implementation/(semi)technical
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* We are nowhere near building an AI.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: Most technology development takes place
<br>
behind-the-scenes, in far away government and corporate labs where
<br>
most people don't see it. APRAnet, the predecessor of the Internet,
<br>
was created in 1970. In the 25 years between the first node and
<br>
Netscape's IPO, the network grew exponentially, but few if any seemed
<br>
to notice. Only fifteen years ago, HTML was in its infancy, and most
<br>
people didn't own a computer. Because we only notice the end stages of
<br>
a project, when the technology is popularized, it seems to come from
<br>
out of nowhere.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;*
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o True, the field of &quot;Artificial Intelligence&quot; has made only
<br>
moderate progress in the past thirty years. But all the building
<br>
blocks of human intelligence theory have been quietly falling into
<br>
place. Cognitive science has made huge strides. Bayesian information
<br>
theory has been popularized. Evolutionary psychology has continued to
<br>
make progress. All of these fields are vital to true Artificial
<br>
Intelligence, but their progress has gone mostly unnoticed, except by
<br>
academic specialists.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* Computers can only do what they're programmed to do. (Heading
<br>
6.6. in Turing's classic paper
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: Even simple programs can produce
<br>
surprising, apparently unexplainable results. We still don't
<br>
understand the behavior of a number of five-state Turing machines
<br>
(link).
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* The human brain is not digital but analog: therefore ordinary
<br>
computers cannot simulate it.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: A digital computer can simulate an
<br>
analog system to an arbitrarily high level of accuracy. One kilobyte
<br>
of data is enough for over two thousand digits of precision.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* Godel's Theorem shows that no computer, or mathematical system,
<br>
can match human reasoning.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: Humans are also subject to Godel's
<br>
Theorem. We can't prove the statement &quot;G cannot be proven&quot; either.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* It's impossible to make something more intelligent/complex than yourself.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: Evolution's algorithm is extremely
<br>
simple, but evolution has created creatures of fantastic complexity,
<br>
us included.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* Creating an AI, even if it's possible in theory, is far too
<br>
complex for human programmers.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Does anyone have counter-evidence? This looks like a real
<br>
possibility. - Tom
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+ There's always the &quot;brute forcing AI via
<br>
evolutionary algorithms and such&quot; argument, but that isn't really of
<br>
any use for designs that are supposed to be Friendly. More usefully,
<br>
one could mention that we can always develop simple software tools
<br>
that help us design more complex software tools, but that may not be
<br>
enough. The third response would be that as our understanding of
<br>
intelligence and the human brain develops, we might also develop brain
<br>
implants and such that expand our capability to deal with complexity.
<br>
Of course, that might be too science fiction for lots of readers, but
<br>
throwing a couple of links to that artificial hippocampus they've been
<br>
working on might help. Of course, with the nightmare of regulation
<br>
medical technology has to go through, really powerful brain implants
<br>
will take a long, long time to come on the market...
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* AI is impossible: you can't program it to be prepared for every
<br>
eventuality. (Heading 6.8. in Turing's classic paper, SIAI blog
<br>
comment: general intelligence impossible)
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: With good programming and enough
<br>
memory, an AI can handle an arbitrarily large number of circumstances
<br>
- just like humans do. Evolution has equipped us with different
<br>
modules, such as ones enabling us to easily and effortlessly read the
<br>
expressions of others, and an AI can be designed with far more modules
<br>
than we humans have.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* We still don't have the technological/scientific prerequisites
<br>
for building AGI; if we want to build it, we should develop these
<br>
instead of funding AGI directly.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: Any necessary prerequisites can be
<br>
funded by the AGI project directly. We still don't know what these
<br>
prerequisites are, so at a minimum, the field still needs to be
<br>
investigated until we can determine where to go next.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* There's no way to know whether AGI theory works without actually
<br>
building an AGI. (link)
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: Several theory components, such as
<br>
recursive decision theory, can be tested on much less complex systems.
<br>
It is true, however, that as the system gets more and more complex,
<br>
testing will become more and more difficult.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* Any true intelligence will require a biological substrate.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: Biological substrates are made of
<br>
atoms, which are simulatable on any Turing-equivalent computer with
<br>
enough time and RAM.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* We can't reach the levels of computing power needed to equal the
<br>
brain using currently existing hardware paradigms.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: IBM's BlueGene already exceeds many
<br>
estimates of the human brain's computing power. With nanotechnology,
<br>
we should be able to get 10^20 FLOPS on a desktop computer.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* Nobody seems to have much of a clue on how to solve the grounding problem.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: The &quot;symbol grounding problem&quot; is an
<br>
illusion created by decades of misapplied AI work. See Artificial
<br>
Addition.
<br>
<p>&nbsp;- Tom
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17548.html">Thomas McCabe: "Singularity Objections: Friendliness, desirability"</a>
<li><strong>Previous message:</strong> <a href="17546.html">Thomas McCabe: "Singularity Objections: General AI, Consciousness"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17547">[ date ]</a>
<a href="index.html#17547">[ thread ]</a>
<a href="subject.html#17547">[ subject ]</a>
<a href="author.html#17547">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:01 MDT
</em></small></p>
</body>
</html>
