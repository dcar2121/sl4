<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Singularity Objections: SIAI, General Objections</title>
<meta name="Author" content="Thomas McCabe (pphysics141@gmail.com)">
<meta name="Subject" content="Singularity Objections: SIAI, General Objections">
<meta name="Date" content="2008-01-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Singularity Objections: SIAI, General Objections</h1>
<!-- received="Tue Jan 29 13:35:42 2008" -->
<!-- isoreceived="20080129203542" -->
<!-- sent="Tue, 29 Jan 2008 15:32:59 -0500" -->
<!-- isosent="20080129203259" -->
<!-- name="Thomas McCabe" -->
<!-- email="pphysics141@gmail.com" -->
<!-- subject="Singularity Objections: SIAI, General Objections" -->
<!-- id="b7a9e8680801291232p6c2af5c7lbf36bd474327371d@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas McCabe (<a href="mailto:pphysics141@gmail.com?Subject=Re:%20Singularity%20Objections:%20SIAI,%20General%20Objections"><em>pphysics141@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Jan 29 2008 - 13:32:59 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17543.html">Thomas McCabe: "Singularity Objections: Singularity, Intelligence"</a>
<li><strong>Previous message:</strong> <a href="17541.html">Thomas McCabe: "Singularity Objections"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17568.html">Joshua Fox: "Re: Singularity Objections: SIAI, General Objections"</a>
<li><strong>Reply:</strong> <a href="17568.html">Joshua Fox: "Re: Singularity Objections: SIAI, General Objections"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17542">[ date ]</a>
<a href="index.html#17542">[ thread ]</a>
<a href="subject.html#17542">[ subject ]</a>
<a href="author.html#17542">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
SIAI: General objections
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* The government would never let private citizens build an AGI,
<br>
out of fear/security concerns.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: The government has shown almost no
<br>
interest in the transhumanist movement. We aren't a large voting bloc,
<br>
and politicians won't take our claims seriously. Governments have
<br>
enough trouble keeping up with present-day technology (remember Y2K?);
<br>
they aren't likely to be worrying about technology that may be
<br>
developed twenty or thirty years from now.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+ That may change as awareness of us increases, though
<br>
- one might use the very &quot;politicians won't take our claims seriously&quot;
<br>
response as an argument that SIAI shouldn't do any PR work that would
<br>
endanger itself. - Kaj
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* The government/Google/etc. will start their own project and beat
<br>
us to AI anyway.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: Narrow-AI projects, with little or no
<br>
emphasis on general intelligence, make up the vast majority of current
<br>
government and corporate projects. And if someone else is working on
<br>
it, that just means we have to work faster: a successful AI project
<br>
without Friendly AI could be catastrophic.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* SIAI will just putz around and never actually finish the
<br>
project, like all the other wild-eyed dreamers.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o This, I think, is a real, serious risk. - Tom
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* SIAI is just another crazy &quot;doomsday cult&quot; making fantastic
<br>
claims about the end of the world.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: SIAI has few cultish characteristics.
<br>
We don't believe, as a movement, in any aliens, supernatural beings,
<br>
mystical forces, or anything else outside the normal world of atoms
<br>
bumping together (individuals, of course, have a wide range of
<br>
religious beliefs). The Singularity is not inevitable, or predestined,
<br>
or immune from human error. If we want a positive Singularity, we need
<br>
to get the funding and do the research like any other engineering
<br>
project.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* Eventually, SIAI will catch the attention of governments and set
<br>
off an international military AI arms race.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Possible rebuttal: at least it's better for the arms race
<br>
to be triggered by an organization that's researching Friendliness, so
<br>
that there exist at least some theories about how to achieve it. The
<br>
alternative would be that the arms race was triggered by corporations
<br>
or the military.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+ Email to Tim Kyger (Pentagon employee, OSD): Do you
<br>
know of anyone in the government/military who has shown interest or
<br>
would be interested in transhumanism? We're compiling a list of
<br>
objections (<a href="http://www.acceleratingfuture.com/tom/?p=83">http://www.acceleratingfuture.com/tom/?p=83</a>), and several
<br>
of them revolve around government intervention. - Tom
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Response: I don't know a *soul* in DoD or any
<br>
of the services off the top of my head that has any *inkling* of the
<br>
very existence of trans-H or of the various technical/scientific lanes
<br>
of approach that are leading to a trans/post-human future of some
<br>
sort. Zip. Zero. Nada.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* There's no idea in treating seriously an institution whose
<br>
leader and only full-time researcher is a middle-school drop-out
<br>
without a single peer-reviewed publication.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Incidentally, this might be one of the rare objections
<br>
that it's better to just quietly ignore than try to answer... I don't
<br>
know if any answer will satisfy those who only look for formal
<br>
credentials before respecting someone, and there's no point in
<br>
highlighting the issue. - Kaj
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+ Eli wrote LOGI and those two chapters for Global
<br>
Catastrophic Risks, which were technically peer-reviewed, and were
<br>
certainly published (by Springer-Verlag and Oxford University Press,
<br>
respectively). - Tom
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# True. There are some people who don't accept
<br>
those as real peer-reviews, though. See Miai's comment mentioning
<br>
Springer here, for instance. - Kaj
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* SIAI has set as their goal the creation of an FAI, which if
<br>
successful gives them immense control over humanity's destiny and what
<br>
the AI actually does. That is something all of humanity should have
<br>
input on, not just a select few.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: It would be wonderful if we could
<br>
educate the entire world's population to the point where they could
<br>
make effective decisions about AI programming. However, nobody- not
<br>
the government, not the corporations, and certainly not us- has the
<br>
resources required for such a massive project. Therefore, we must
<br>
program the AI to do it for us, through CEV or a similar technique.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* SIAI is advocating very specific approaches to Friendliness,
<br>
like CEV and the impossibility of &quot;AI boxing&quot;. Isn't this premature
<br>
until we've done more research and have a more concrete theory of AI
<br>
behavior?
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: You have to start somewhere. SIAI's
<br>
current recommendations seem plausible in the light of current
<br>
knowledge. If pursuing those leads will turn out fruitless, the
<br>
suggestions will be revised accordingly.
<br>
<p>&nbsp;- Tom
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17543.html">Thomas McCabe: "Singularity Objections: Singularity, Intelligence"</a>
<li><strong>Previous message:</strong> <a href="17541.html">Thomas McCabe: "Singularity Objections"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17568.html">Joshua Fox: "Re: Singularity Objections: SIAI, General Objections"</a>
<li><strong>Reply:</strong> <a href="17568.html">Joshua Fox: "Re: Singularity Objections: SIAI, General Objections"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17542">[ date ]</a>
<a href="index.html#17542">[ thread ]</a>
<a href="subject.html#17542">[ subject ]</a>
<a href="author.html#17542">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:01 MDT
</em></small></p>
</body>
</html>
