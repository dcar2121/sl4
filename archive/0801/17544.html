<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Singularity Objections: Singularity, exponential growth</title>
<meta name="Author" content="Thomas McCabe (pphysics141@gmail.com)">
<meta name="Subject" content="Singularity Objections: Singularity, exponential growth">
<meta name="Date" content="2008-01-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Singularity Objections: Singularity, exponential growth</h1>
<!-- received="Tue Jan 29 13:37:48 2008" -->
<!-- isoreceived="20080129203748" -->
<!-- sent="Tue, 29 Jan 2008 15:35:28 -0500" -->
<!-- isosent="20080129203528" -->
<!-- name="Thomas McCabe" -->
<!-- email="pphysics141@gmail.com" -->
<!-- subject="Singularity Objections: Singularity, exponential growth" -->
<!-- id="b7a9e8680801291235g4b91e874yc78c2f1336e1efb8@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas McCabe (<a href="mailto:pphysics141@gmail.com?Subject=Re:%20Singularity%20Objections:%20Singularity,%20exponential%20growth"><em>pphysics141@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Jan 29 2008 - 13:35:28 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17545.html">Thomas McCabe: "Singularity Objections: Singularity, Desirability"</a>
<li><strong>Previous message:</strong> <a href="17543.html">Thomas McCabe: "Singularity Objections: Singularity, Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17575.html">Damien Broderick: "Re: Singularity Objections: Singularity, exponential growth"</a>
<li><strong>Maybe reply:</strong> <a href="17575.html">Damien Broderick: "Re: Singularity Objections: Singularity, exponential growth"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17544">[ date ]</a>
<a href="index.html#17544">[ thread ]</a>
<a href="subject.html#17544">[ subject ]</a>
<a href="author.html#17544">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Technological progress and exponential growth
<br>
[edit]
<br>
Extrapolation of graphs doesn't prove anything. It doesn't show that
<br>
we'll have AI in the future.
<br>
<p>Certainly, there is no certain evidence that AI will be developed in
<br>
the near future. However, an increase in processing power, combined
<br>
with improved brain-scanning methods, seems likely to produce
<br>
artificial intelligence in the near future. Molecular nanotechnology,
<br>
in particular, will enable massive amounts of processing power, as
<br>
well as a thorough mapping of the brain. Even if it didn't become
<br>
available, more conventional techniques are also making fast progress:
<br>
by some estimates, the top supercomputers of today already have enough
<br>
processing power to match the human brain, and machines of comparable
<br>
potential are expected to become cheaply and commonly available within
<br>
a few decades. Projects to build brain simulations are currently
<br>
underway, with one team having run a second's worth of a simulation as
<br>
complex as half a mouse brain, and IBM's Blue Brain project seeking to
<br>
simulate the whole human brain.
<br>
<p>Progress made towards reverse-engineering the brain will also help AI
<br>
research by making researchers themselves more intelligent: for
<br>
instance, IQ tests seem to measure working memory capacity (Oberauer
<br>
et al, 2005). As the neural basis for different working memory
<br>
capacities become clear, it might become possible for us to increase
<br>
our own intelligence directly. Even if this wasn't possible,
<br>
algorithms extracted from the brain can be applied to traditional
<br>
computer systems, making them more effective at helping us conduct
<br>
research.
<br>
<p>Even if we exclude the possibility of artificial intelligence by brain
<br>
reverse-engineering, increasing amounts of processing power are likely
<br>
to make it more easy to create AIs by evolutionary programming. The
<br>
human mind was never designed by anyone - it evolved through genetic
<br>
drift and selection pressures. It might not be strictly necessary for
<br>
us to understand how a mind works, as long as we can build a system
<br>
that has enough computing power to simulate evolution and produce an
<br>
artificial mind optimized to the conditions we want it to perform in.
<br>
Combining this with advances in cognitive science and traditional
<br>
artificial intelligence techniques, there's a very
<br>
<p>While nothing is ever certain, these factors are certainly heavy
<br>
enough to make the issue worth our attention.
<br>
[edit]
<br>
Kurzweil's graphs for predicting AI are unrealistic.
<br>
<p>The case for believing that AI may be near does not depend on Ray
<br>
Kurzweil's predictions. For the actual reasons, see &quot;Extrapolation of
<br>
graphs doesn't prove anything&quot;.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* AI is just something out of a sci-fi movie, it has never actually existed.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: rockets flying to the moon were just
<br>
something out of sci-fi books up to 1969.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* Big changes always seem to be predicted to happen during the
<br>
lifetimes of the people predicting them.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: Even if the Singularity takes thousands
<br>
of years, it's still a worthwhile goal for the human species, and we
<br>
need to pursue it.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* The Singularity is the Rapture of religious texts, just dressed
<br>
in different clothes to appeal to proclaimed atheists.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: Unlike any of the various Raptures, the
<br>
Singularity is a technological event, caused by ordinary humans
<br>
following the ordinary laws of physics. It does not involve any
<br>
religious or diving powers. It doesn't involve outside intervention-
<br>
it will only happen when we go out and make it happen.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* Moore's Law is slowing down.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: The original Moore's Law, for number of
<br>
transistors on a chip, has continued into 2007 and 2008 (see Intel's
<br>
website), and engineers expect it to continue for at least another
<br>
decade.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* Progress on much simpler AI systems (chess programs,
<br>
self-driving cars) has been notoriously slow in the past.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: Most of the successful AI software is
<br>
not called &quot;AI software&quot;, and is used by corporations or programmers
<br>
instead of individual consumers. An industry-wide survey would be
<br>
required to see how much progress has actually been made in narrow AI
<br>
overall; to my knowledge, no such survey has ever been done.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* There could be a war/resource exhaustion/other crisis putting
<br>
off the Singularity for a long time. (See Tim O'Reilly's first comment
<br>
in the comments section)
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;o Rebuttal synopsis: With very few exceptions, the past few
<br>
centuries have seen exponential technological growth, and a
<br>
corresponding increase in the general standard of living. It would
<br>
require a *huge* disruption to halt this progress; even WWII, the
<br>
single most catastrophic event in modern human history, didn't slow
<br>
the march of technology.
<br>
<p>[edit]
<br>
References
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;* Oberauer, K. &amp; Wilhelm, O. &amp; Schulze, R. &amp; Süß, H-M. (2005)
<br>
Working memory and intelligence - their correlation and their
<br>
relation: comment on Ackerman, Beier and Boyle. Psychological
<br>
Bulletin, vol. 131, no. 1, s. 61-65.
<br>
<a href="http://eis.bris.ac.uk/~psxko/Oberauer.et-al.PsychBull.2005.pdf">http://eis.bris.ac.uk/~psxko/Oberauer.et-al.PsychBull.2005.pdf</a>
<br>
<p>&nbsp;- Tom
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17545.html">Thomas McCabe: "Singularity Objections: Singularity, Desirability"</a>
<li><strong>Previous message:</strong> <a href="17543.html">Thomas McCabe: "Singularity Objections: Singularity, Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17575.html">Damien Broderick: "Re: Singularity Objections: Singularity, exponential growth"</a>
<li><strong>Maybe reply:</strong> <a href="17575.html">Damien Broderick: "Re: Singularity Objections: Singularity, exponential growth"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17544">[ date ]</a>
<a href="index.html#17544">[ thread ]</a>
<a href="subject.html#17544">[ subject ]</a>
<a href="author.html#17544">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:01 MDT
</em></small></p>
</body>
</html>
