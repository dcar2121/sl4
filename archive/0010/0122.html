<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: upper theoretical limits</title>
<meta name="Author" content="Alicia Madsen (fsadm1@uaf.edu)">
<meta name="Subject" content="upper theoretical limits">
<meta name="Date" content="2000-10-03">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>upper theoretical limits</h1>
<!-- received="Tue Oct 03 23:59:36 2000" -->
<!-- isoreceived="20001004055936" -->
<!-- sent="Tue, 3 Oct 2000 14:34:46 -0800" -->
<!-- isosent="20001003223446" -->
<!-- name="Alicia Madsen" -->
<!-- email="fsadm1@uaf.edu" -->
<!-- subject="upper theoretical limits" -->
<!-- id="200010032234.OAA09637@aurora.uaf.edu" -->
<!-- charset="US-ASCII" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Alicia Madsen (<a href="mailto:fsadm1@uaf.edu?Subject=Re:%20upper%20theoretical%20limits"><em>fsadm1@uaf.edu</em></a>)<br>
<strong>Date:</strong> Tue Oct 03 2000 - 16:34:46 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0123.html">Ben Goertzel: "RE: upper theoretical limits"</a>
<li><strong>Previous message:</strong> <a href="0121.html">Peter Voss: "RE: Ben what are your views and concerns"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0123.html">Ben Goertzel: "RE: upper theoretical limits"</a>
<li><strong>Reply:</strong> <a href="0123.html">Ben Goertzel: "RE: upper theoretical limits"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#122">[ date ]</a>
<a href="index.html#122">[ thread ]</a>
<a href="subject.html#122">[ subject ]</a>
<a href="author.html#122">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
This upper theoretical limit people speak of, does it all go back to how well 
<br>
humans grasp the concept of infinity? As a college student, I have just begun 
<br>
to grapple with calculus, and am not familiar with its peculiarities. In 
<br>
replying to my post, explain as much as possible about holes in my logic.
<br>
<p>Peter Voss said recently on <a href="mailto:sl4@sysopmind.com?Subject=Re:%20upper%20theoretical%20limits">sl4@sysopmind.com</a> &quot; agree with you, that here we 
<br>
are in intuition' territory. My own approach to AI design leads me to believe 
<br>
that at a certain point of intelligence there will be enough of an exponential 
<br>
burst for one system to dominate. I don't think that hardware will be a major 
<br>
limiting factor. On the other hand, perhaps each type of intelligence has its 
<br>
own upper theoretical limit. If so, I haven't yet identified it.&quot;
<br>
<p>Perhaps if one &quot;type&quot; of intelligence reaches its limit at a certain number n, 
<br>
and another &quot;type&quot; reaches its intelligence limit at a certain number k, then 
<br>
all that must be done is rewrite their functions so that they are continuos 
<br>
together at a new limit. My question is if we have these webminds, and they 
<br>
are capable of rewriting their programs so that they can continually increase 
<br>
their capabilities, and then work together, why worry about upper limits? I do 
<br>
not think that an &quot;upper&quot; limits will exist, as you speak of an exponential 
<br>
growth rate, and thus continuous everywhere, with this capability to be 
<br>
rewritten favorably.
<br>
<p>This is why I think that one AI or even &quot;webmind&quot; as it is called will depend 
<br>
on each other, and for its own survival will not &quot;dominate&quot; the others. In my 
<br>
opinion, an AI is like all other AIs and thus only one of them in the first 
<br>
place, especially because they will be sharing information. It is true that 
<br>
there are many parallels of the AI system and humanity, because we are friends 
<br>
with the logic of Darwin, as we are trapped in the existential circumstance 
<br>
thrusted upon us.
<br>
<p>But Darwin is also not limiting, only a tool we choose to use, and we are not 
<br>
to fear this tool. In my culture (Inupiaq Eskimo) there are examples from past 
<br>
and present of elders leaving the small community when food is scarce, and 
<br>
wander off to die so that the community may survive. I think that because 
<br>
humanity has the choice and demonstrated the ability to make this choice of 
<br>
suicide, then an AI system will also have this choice, as we are in the same 
<br>
condition. A human interface with the baby AI or webring will not jeopardize 
<br>
it  because we cannot lie to it.
<br>
<p>Thus my opinion is that AIs depend on each other for survival, and are also 
<br>
not limited in intelligence, as well as not limited by their existential 
<br>
circumstance.
<br>
<p>I follow Eliezer Yudkowsky's logic that we cannot lie to an Ai, at least not 
<br>
for long, because its logical flaw will be spottable. So it will not be an 
<br>
issue. What I find interesting, is this concept of AIs having familial 
<br>
relationships, although I do not think it is of much importance in the long 
<br>
run towards an SI. If humans are able to interface with the AI and &quot;webrings&quot; 
<br>
then we will shape the graph of their intelligence in the beginning, and so I 
<br>
do not worry about AIs having moral dilemmas because of the guidance it will 
<br>
receive from its human interface, or even falling out of the community of AIs 
<br>
and &quot;dying&quot;. With the development of nanotechnology well underway, and also 
<br>
the presence of many interested individuals and organizations in AI, I have no 
<br>
fear that an SI will not eventually exist as the ratrace has already begun.
<br>
<p>Alicia Madsen
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0123.html">Ben Goertzel: "RE: upper theoretical limits"</a>
<li><strong>Previous message:</strong> <a href="0121.html">Peter Voss: "RE: Ben what are your views and concerns"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0123.html">Ben Goertzel: "RE: upper theoretical limits"</a>
<li><strong>Reply:</strong> <a href="0123.html">Ben Goertzel: "RE: upper theoretical limits"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#122">[ date ]</a>
<a href="index.html#122">[ thread ]</a>
<a href="subject.html#122">[ subject ]</a>
<a href="author.html#122">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
