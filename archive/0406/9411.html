<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: My last thoughts on Collective Volition for now</title>
<meta name="Author" content="Marc Geddes (marc_geddes@yahoo.co.nz)">
<meta name="Subject" content="Re: My last thoughts on Collective Volition for now">
<meta name="Date" content="2004-06-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: My last thoughts on Collective Volition for now</h1>
<!-- received="Sat Jun 26 01:33:55 2004" -->
<!-- isoreceived="20040626073355" -->
<!-- sent="Sat, 26 Jun 2004 19:33:53 +1200 (NZST)" -->
<!-- isosent="20040626073353" -->
<!-- name="Marc Geddes" -->
<!-- email="marc_geddes@yahoo.co.nz" -->
<!-- subject="Re: My last thoughts on Collective Volition for now" -->
<!-- id="20040626073353.39948.qmail@web20208.mail.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="948b11e04062411532c1f8cd9@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Marc Geddes (<a href="mailto:marc_geddes@yahoo.co.nz?Subject=Re:%20My%20last%20thoughts%20on%20Collective%20Volition%20for%20now"><em>marc_geddes@yahoo.co.nz</em></a>)<br>
<strong>Date:</strong> Sat Jun 26 2004 - 01:33:53 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9412.html">Simon Gordon: "RE: We Can't Fool the Super Intelligence"</a>
<li><strong>Previous message:</strong> <a href="9410.html">Mike: "RE: We Can't Fool the Super Intelligence"</a>
<li><strong>In reply to:</strong> <a href="9399.html">Samantha Atkins: "Re: My last thoughts on Collective Volition for now"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9413.html">Metaqualia: "Re: My last thoughts on Collective Volition for now"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9411">[ date ]</a>
<a href="index.html#9411">[ thread ]</a>
<a href="subject.html#9411">[ subject ]</a>
<a href="author.html#9411">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- Samantha Atkins &lt;<a href="mailto:sjatkins@gmail.com?Subject=Re:%20My%20last%20thoughts%20on%20Collective%20Volition%20for%20now">sjatkins@gmail.com</a>&gt; wrote: &gt; How
<br>
in the world would you apply &quot;reasonable&quot; to
<br>
<em>&gt; &quot;intuition&quot;?  Either
</em><br>
<em>&gt; &quot;morality&quot;  can possibly be defined for some group
</em><br>
<em>&gt; (like humans) with
</em><br>
<em>&gt; enough objectivity to make its consideration useful
</em><br>
<em>&gt; or it is useless
</em><br>
<em>&gt; to worry over a word we attach no real meaning to.  
</em><br>
<em>&gt; I believe that
</em><br>
<em>&gt; morality is objectively definable within the context
</em><br>
<em>&gt; of a particular
</em><br>
<em>&gt; group of sentients and perhaps all sentients.   But
</em><br>
<em>&gt; that is a minority
</em><br>
<em>&gt; position here.   The problem does not get better by
</em><br>
<em>&gt; assuming that a
</em><br>
<em>&gt; poll of humanity or extrapolation of human/&gt;human
</em><br>
<em>&gt; intent/volition.  I
</em><br>
<em>&gt; can agree that CV may give better guidance over some
</em><br>
<em>&gt; types of
</em><br>
<em>&gt; planning/decisions than morality or what passes for
</em><br>
<em>&gt; morality for most
</em><br>
<em>&gt; folks.
</em><br>
<p>O.K, I can agree with you here.  CV may indeed give
<br>
better guidance (if it's possible to calculate at all,
<br>
which I still have grave doubts about), but as you
<br>
point out, it really leaves fundamental moral
<br>
questions unresolved.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; Conflating morality and CV is a mistake that I don't
</em><br>
<em>&gt; see Eliezer making.  
</em><br>
<p>Well, if CV is the final theory of 'Friendliness' then
<br>
it would seem that Eli is indeed conflating morality
<br>
with CV.  My point is that CV seems to be a pragmatic
<br>
operational definition of 'Friendliness', where
<br>
morality seems to be defined as the results of the CV
<br>
process.  I can agree that this might give &quot;Friendly&quot;
<br>
practical results, but I doubt that CV can be
<br>
calculated at all, for the reasons people like Jef
<br>
and others have mentioned (too much data,
<br>
intractability, combinatorial explosions etc).
<br>
<p>So CV might not be wrong as far as it goes, but just
<br>
be totally useless as a definition of 'Friendliness'. 
<br>
<p><p><em>&gt; 
</em><br>
<em>&gt; BTW, your notion of SM people and their desires is
</em><br>
<em>&gt; very out of whack. 
</em><br>
<p>I was just trying to point out the difficulties of
<br>
qualia based conceptions of morality, since people on
<br>
this list have been suggesting that whatever leads to
<br>
good qualia is good.  But I pointed out that SM people
<br>
might really enjoy themselves, but this is not
<br>
neccesserily good.  For similiar reasons we shouldn't
<br>
just equate what is good with what individual people
<br>
want.
<br>
&nbsp;&nbsp;
<br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; On Thu, 24 Jun 2004 20:30:22 +1200 (NZST), Marc
</em><br>
<em>&gt; Geddes
</em><br>
<em>&gt; &lt;<a href="mailto:marc_geddes@yahoo.co.nz?Subject=Re:%20My%20last%20thoughts%20on%20Collective%20Volition%20for%20now">marc_geddes@yahoo.co.nz</a>&gt; wrote:
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; I wouldn't rule out the possibility of some sort
</em><br>
<em>&gt; of
</em><br>
<em>&gt; &gt; objective morality yet. Sure, you need to look at
</em><br>
<em>&gt; &gt; humans for 'calibration' of any reasonable
</em><br>
<em>&gt; morality
</em><br>
<em>&gt; &gt; that would speak to the wants and needs of humans
</em><br>
<em>&gt; but
</em><br>
<em>&gt; &gt; there doesn't mean that there is isn't some sort
</em><br>
<em>&gt; of
</em><br>
<em>&gt; &gt; objective standard for determining the morality of
</em><br>
<em>&gt; &gt; various human wants and needs.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Wants and needs are not something that have
</em><br>
<em>&gt; &quot;morality&quot; so speaking of
</em><br>
<em>&gt; the morality of wants and needs is meaningless.
</em><br>
<p>What I said should have read:  '...objective standard
<br>
for JUDGING the morality of various human wants and
<br>
needs'.  But also read what I say at the end.
<br>
<p><em>&gt; 
</em><br>
<em>&gt;  
</em><br>
<em>&gt; &gt; What Eli seems to be worried about is the
</em><br>
<em>&gt; possibility
</em><br>
<em>&gt; &gt; of A.I programmers 'taking over the world'. But
</em><br>
<em>&gt; does
</em><br>
<em>&gt; &gt; the world really need anyone to 'run' it? Not
</em><br>
<em>&gt; &gt; according to the anarcho-capitalists and various
</em><br>
<em>&gt; other
</em><br>
<em>&gt; &gt; political systems that have been floated. Not that
</em><br>
<em>&gt; I'm
</em><br>
<em>&gt; &gt; advocating anarchy, I'm just pointing out that the
</em><br>
<em>&gt; &gt; whole idea of a singeton centralized agent might
</em><br>
<em>&gt; be
</em><br>
<em>&gt; &gt; misguided. In any event the way the world seems to
</em><br>
<em>&gt; &gt; work in the modern free market democracies is that
</em><br>
<em>&gt; &gt; people are assigned status roughly acccording to
</em><br>
<em>&gt; their
</em><br>
<em>&gt; &gt; talent and latent cognitive abilities. For
</em><br>
<em>&gt; instance
</em><br>
<em>&gt; &gt; childen have fewer rights than adults, brilliant
</em><br>
<em>&gt; &gt; adults who create good products end up with more
</em><br>
<em>&gt; &gt; economic power etc. Since FAI would have cognitive
</em><br>
<em>&gt; &gt; abilities far beyond an ordinary human, it's not
</em><br>
<em>&gt; clear
</em><br>
<em>&gt; &gt; why it would be wrong for the FAI to be given the
</em><br>
<em>&gt; most
</em><br>
<em>&gt; &gt; rights.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't believe that rights necessarily increase
</em><br>
<em>&gt; based on a
</em><br>
<em>&gt; quantitative increase of some aspect of an entity
</em><br>
<em>&gt; whose rights are
</em><br>
<em>&gt; being derived.  Rights, like morality, can only be
</em><br>
<em>&gt; tied to reality
</em><br>
<em>&gt; through considering the nature of the entities we
</em><br>
<em>&gt; are talking about. 
</em><br>
<em>&gt; Rights of the &quot;unalienable&quot; kind are those things
</em><br>
<em>&gt; required for the
</em><br>
<em>&gt; well-functioning of the type of entity.  It is not a
</em><br>
<em>&gt; matter of &quot;more&quot;
</em><br>
<em>&gt; rights but of different rights for different types
</em><br>
<em>&gt; of entities.   The
</em><br>
<em>&gt; rights of entities will intersect on those rights
</em><br>
<em>&gt; deriving from more
</em><br>
<em>&gt; or less intersecting aspects of their nature.   It
</em><br>
<em>&gt; is possible that a
</em><br>
<em>&gt; vastly greater intelligence would require by its
</em><br>
<em>&gt; nature more rights
</em><br>
<em>&gt; than we do, but since rights are in the interaction
</em><br>
<em>&gt; of entities I do
</em><br>
<em>&gt; not see that it is necessarily so.
</em><br>
<p>Yup I agree.  But I  argue that a vastly greater
<br>
intelligence would require by its nature far more
<br>
rights because far more possibilities are open to it
<br>
(it can rationally calculate outcomes further into the
<br>
future and also consider a greater range of actions). 
<br>
For instance a small child does not have the right to
<br>
drive a car, because the child could not process the
<br>
sensory data to calculate outcomes when driving to the
<br>
same degree as an adult.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; The realm of morality is also the realm of
</em><br>
<em>&gt; inter-entity activity.  
</em><br>
<em>&gt; This is a smaller and more delimited sphere than
</em><br>
<em>&gt; that potentially
</em><br>
<em>&gt; covered by CV.
</em><br>
<em>&gt;  
</em><br>
<em>&gt; -s
</em><br>
<em>&gt;  
</em><br>
<p>In the most general sense of the term, morality is the
<br>
process of consciously determining goals.  But this
<br>
process is itself a goal system.  So a morality is a
<br>
goal system.  
<br>
<p><p>=====
<br>
&quot;Live Free or Die, Death is not the Worst of Evils.&quot;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Gen. John Stark
<br>
<p>&quot;The Universe...or nothing!&quot;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-H.G.Wells
<br>
<p><p>Please visit my web-sites.
<br>
<p>Science-Fiction and Fantasy:  <a href="http://www.prometheuscrack.com">http://www.prometheuscrack.com</a>
<br>
Science, A.I, Maths            :  <a href="http://www.riemannai.org">http://www.riemannai.org</a>
<br>
<p>Find local movie times and trailers on Yahoo! Movies.
<br>
<a href="http://au.movies.yahoo.com">http://au.movies.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9412.html">Simon Gordon: "RE: We Can't Fool the Super Intelligence"</a>
<li><strong>Previous message:</strong> <a href="9410.html">Mike: "RE: We Can't Fool the Super Intelligence"</a>
<li><strong>In reply to:</strong> <a href="9399.html">Samantha Atkins: "Re: My last thoughts on Collective Volition for now"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9413.html">Metaqualia: "Re: My last thoughts on Collective Volition for now"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9411">[ date ]</a>
<a href="index.html#9411">[ thread ]</a>
<a href="subject.html#9411">[ subject ]</a>
<a href="author.html#9411">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
