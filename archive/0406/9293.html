<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Fundamentals - was RE: Visualizing muddled volitions</title>
<meta name="Author" content="Brent Thomas (bthomas@avatar-intl.com)">
<meta name="Subject" content="RE: Fundamentals - was RE: Visualizing muddled volitions">
<meta name="Date" content="2004-06-16">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Fundamentals - was RE: Visualizing muddled volitions</h1>
<!-- received="Wed Jun 16 13:10:58 2004" -->
<!-- isoreceived="20040616191058" -->
<!-- sent="Wed, 16 Jun 2004 15:10:53 -0400" -->
<!-- isosent="20040616191053" -->
<!-- name="Brent Thomas" -->
<!-- email="bthomas@avatar-intl.com" -->
<!-- subject="RE: Fundamentals - was RE: Visualizing muddled volitions" -->
<!-- id="C02025521F687E43B93A11680A71FAD4246958@sherwood.Avatar.local" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="Fundamentals - was RE: Visualizing muddled volitions" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brent Thomas (<a href="mailto:bthomas@avatar-intl.com?Subject=RE:%20Fundamentals%20-%20was%20RE:%20Visualizing%20muddled%20volitions"><em>bthomas@avatar-intl.com</em></a>)<br>
<strong>Date:</strong> Wed Jun 16 2004 - 13:10:53 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9294.html">Eliezer Yudkowsky: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Previous message:</strong> <a href="9292.html">Eliezer Yudkowsky: "Re: ESSAY: 'Debunking 'Hippy dippy moral philosophy'"</a>
<li><strong>Maybe in reply to:</strong> <a href="9285.html">Brent Thomas: "Fundamentals - was RE: Visualizing muddled volitions"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9294.html">Eliezer Yudkowsky: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Reply:</strong> <a href="9294.html">Eliezer Yudkowsky: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Reply:</strong> <a href="9300.html">Metaqualia: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9293">[ date ]</a>
<a href="index.html#9293">[ thread ]</a>
<a href="subject.html#9293">[ subject ]</a>
<a href="author.html#9293">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Answers below as appropriate -- indicated by !!!
<br>
<p>Summary: As far as the system itself, most likely self developed and
<br>
capable of 'changing the world', my only fundamental
<br>
need/desire/request is that it allow me (the current me, not some
<br>
calculated approximation) to act as a 'final judge'
<br>
and accept or reject any modifications it would perform on my person.
<br>
Change the environment to whatever the collective derives as fitting our
<br>
volition, change pretty much anything everyone can agree on...but don't
<br>
change any sentient without
<br>
presenting the choice and ensuring the sentient is comfortable (to the
<br>
limit of their ability to understand) the choice.
<br>
Its not a genie bottle because the 'system' works as you have
<br>
envisioned...only the fundamental difference is that no action can be
<br>
taken to a sentient without their consent. (if they were violent, or
<br>
otherwise inclined not to be involved that is the point of the enclaves
<br>
and the responsibility of the system to provide such space for them to
<br>
exist as they choose...and imho this is no bother or hardship for the
<br>
system...by the point it can alter the environment/bodies/selves of
<br>
sentients it can also protect them) 
<br>
<p>I DO think your collective volition is 'right on' in how the system
<br>
should model and improve itself and the environment...i just must insist
<br>
on the rights of a 'last judge' be in MY hands when it comes to my
<br>
body/self/intellect. And truly, for the capabilities I envision this
<br>
system will develop in a short period, maintaining enclaves and
<br>
providing explanations to whatever level of detail a being requests will
<br>
probably take .0000000001% (or less!) of the systems capability.
<br>
<p>Whats the rush, or the need to impose? Protect the FUNDAMENTAL condition
<br>
where a sentient is not to be affected unless they choose to be
<br>
affected....if you consider this deeply enough I'm confident that you
<br>
will agree that you would wish the ability to refuse outside change. I
<br>
do think that most will embrace the change, and the change will be
<br>
better, smarter, faster etc...but retain the ability to choose.
<br>
<p><p><p>-----Original Message-----
<br>
From: Eliezer Yudkowsky [mailto:<a href="mailto:sentience@pobox.com?Subject=RE:%20Fundamentals%20-%20was%20RE:%20Visualizing%20muddled%20volitions">sentience@pobox.com</a>] 
<br>
Sent: Wednesday, June 16, 2004 1:52 PM
<br>
To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Fundamentals%20-%20was%20RE:%20Visualizing%20muddled%20volitions">sl4@sl4.org</a>
<br>
Subject: Re: Fundamentals - was RE: Visualizing muddled volitions
<br>
<p><p>Brent Thomas wrote:
<br>
<em>&gt; Again I'd like to express the hope that any F(AI) developers would 
</em><br>
<em>&gt; build into their systems (as a fundamental invariant?) the 'right of 
</em><br>
<em>&gt; withdrawal'
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This should not be part of a 'bill of rights' as it is so fundamental 
</em><br>
<em>&gt; to having an acceptable process that it should be a basic condition.
</em><br>
<p>Would you like to name nine other things that are so fundamental to
<br>
having 
<br>
an acceptable process that it should be a basic condition?  If you
<br>
can't, 
<br>
I'm sure nine other people would be happy to do so.  Al-Qaeda thinks
<br>
that 
<br>
basing the AI on the Koran is so fundamental to having an acceptable 
<br>
process that it should be a basic condition.
<br>
<p>!!! NO - there is only one fundamental thing...ASK before modification
<br>
and respect the answer. There is no need for
<br>
other fundamentals in a friendly system operating from our collective
<br>
volition.
<br>
<p><em>&gt; No
</em><br>
<em>&gt; matter what the collective thinks is best, even if it has (correctly!)
</em><br>
<p><em>&gt; extrapolated my wishes or the wishes of the collective, it should 
</em><br>
<em>&gt; still not apply that solution to my (or any sentients) physical being 
</em><br>
<em>&gt; without my express approval.
</em><br>
<p>Including human infants, I assume.  I'll expect you to deliver the
<br>
exact, 
<br>
eternal, unalterable specification of what constitutes a &quot;sentient&quot; by 
<br>
Thursday.  Whatever happened to keeping things simple?
<br>
<p>!!! I'll deliver it today...any being that the system can communicate
<br>
with and that is capable of
<br>
responding. The system should be able to communicate with any human (in
<br>
any modality), and (when!) we encounter alien sentients they should not
<br>
be 'modified' before we are capable of communicating with them ;-) By
<br>
responding I mean that the system must explain what modification it is
<br>
intending to make and allow an informed choice. If the system is unable
<br>
to clearly (to that target) explain why the modification is necessary it
<br>
should not perform it. If the system needs (for some reason determined
<br>
by the collective volition) to modify a sentient and the system cannot
<br>
communicate with it then the sentient should be 'enclaved' if necessary
<br>
until the system is able to explain...dont modify without permission
<br>
anything capable of giving/rejecting permission. Pretty simple.
<br>
<p>For this particular example human infants should generally not need to
<br>
be modified by the system unless their parent wishes them to be (and I
<br>
do think we GIVE the RIGHT to modify infants to human parents
<br>
today...nothing really new here). In this instance the infants are only
<br>
potential sentients as they are not capable of responding. The system
<br>
truly isn't a genie because the collective volition (so I believe) will
<br>
not see the need to modify infants (whats so urgent they need to be
<br>
modified anyway? I don't forsee any condition where the system could not
<br>
enclave them until they develop enough to communicate)
<br>
<p><em>&gt; Change the environment, alter the systems, create the transcendent
</em><br>
<em>&gt; utopia but do it with 'choice' and as such do not modify my
</em><br>
personality
<br>
<em>&gt; or physical being (and as part of that be prepared to create
</em><br>
'enclaves'
<br>
<em>&gt; for those who wish to remain unmodified) without the express consent
</em><br>
of
<br>
<em>&gt; the sentient to be modified.
</em><br>
<p>Could you please elaborate further on all the independent details you
<br>
would 
<br>
like to code into eternal, unalterable invariants?  If you add enough of
<br>
<p>them we can drive the probability of them all working as expected down
<br>
to 
<br>
effectively zero.  Three should be sufficient, but redundancy is always
<br>
a 
<br>
good thing.
<br>
<p>!!! Sure, just one detail --- don't modify a sentient without
<br>
permission, when modification is projected according to the collective
<br>
volition explain process until sentient grasps concept and only proceed
<br>
if accepted. Pretty straight forward.
<br>
<p><em>&gt; Do this and I think the vision of the coming singularity will be more
</em><br>
<em>&gt; palatable for all humanity.
</em><br>
<p>It's not about public relations, it's about living with the actual
<br>
result 
<br>
for the next ten billion years if that wonderful PR invariant turns out
<br>
to 
<br>
be a bad idea.
<br>
<p>!!! First it is about public relations (initially) or else your efforts
<br>
a FAI may be stomped by the establishment and foom! Some non F ai will
<br>
be developed...into the razor blades blindly...it behoves us to make the
<br>
approach palatable to humanity.
<br>
Second, you are correct - it is about living with the result...whatever
<br>
the changes our collective voliton intends to make...it will be capable
<br>
of making them, and of protecting our right to choose...remember this
<br>
fundamental aspect is the 'last judge' decision on the individuals
<br>
part...it doesn't matter to the enviroment, or the system, or the
<br>
majority of the actions of the collective...only and specifically to
<br>
each individual their right to choose/allow/deny action taken TO them.
<br>
<p><em>&gt; (and besides I can't really object about
</em><br>
<em>&gt; modifications if I was consulted now can I?)
</em><br>
<p>Not under your system, no.  I would like to allow your grownup self
<br>
and/or 
<br>
your volition to object effectively.
<br>
<p>!!! Sorry...the decision is MINE...and there is no rush...even if the
<br>
projected volition is correct and my future self will have wanted that I
<br>
still require the CHOICE - maybe it would be better if I were to follow
<br>
the recommendation but life is a journey and I don't want to skip
<br>
ahead...The system should present the option and respect the decision.
<br>
<p><em>&gt; Do not tell me that 'oops we got it wrong...' as indicated here:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;&gt; The reason may be, &quot;That idiot Eliezer screwed up the extrapolation
</em><br>
<p><em>&gt;&gt;&gt; dynamic.&quot;  If so, you got me, there's no defense against that. I'll 
</em><br>
<em>&gt;&gt;&gt; try not to do it.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Instead (using the principal of no modification to sentients without
</em><br>
<em>&gt; express permission) the system can tell me &quot;Hey, you'd be much happier
</em><br>
<em>&gt; if you had green hair, we've done some calculations and if at least
</em><br>
20%
<br>
<em>&gt; of the population had green hair then there would be a 15% reduction
</em><br>
in
<br>
<em>&gt; the general unhappiness quotient... Can I make this modification to
</em><br>
you
<br>
<em>&gt; or would you like a deeper explanation of the intents and
</em><br>
consequences?&quot;
<br>
<p>I suppose that if that is the sort of solution you would come up with
<br>
after 
<br>
thinking about it for a few years, it might be the secondary dynamic.
<br>
For 
<br>
myself I would argue against that, because it sounds like individuals
<br>
have 
<br>
been handed genie bottles with warning labels, and I don't think that's
<br>
a 
<br>
good thing.
<br>
<p>!!!but that's exactly the point...if you don't think it's a good thing,
<br>
well that doesn't matter to me...
<br>
I am the one who has to choose. And remember this is only in respect to
<br>
modifications the system DECIDES to MAKE to me...
<br>
<p>How it reacts to 'wishes' (ala genie) is a whole nother
<br>
discussion...this fundamental application of CHOICE is only to 
<br>
things the system decides it needs to do and in the process must CHANGE
<br>
me...at that point I get to choose.
<br>
<p><em>&gt; I think I'm mindful that the system is likely to evolve fast, (go 
</em><br>
<em>&gt; foom!
</em><br>
<em>&gt; (hopefully in a good way!)) and that even if it is Friendly and has my
</em><br>
<em>&gt; best interests at heart I still may not want to participate in all
</em><br>
<em>&gt; aspects of the system, even if its calculations tell it that I would
</em><br>
in
<br>
<em>&gt; fact in the future have appreciated being modified. I think I do
</em><br>
foresee
<br>
<em>&gt; a hard takeoff scenario and as long as the fundamentals are good then
</em><br>
<em>&gt; even when no person or group of people is capable of understanding
</em><br>
even
<br>
<em>&gt; a small percent of the operations or actions of the system as long as
</em><br>
<em>&gt; they have and retain personal choice over their own person (and
</em><br>
possibly
<br>
<em>&gt; local environment) then things will be fine.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; (I don't particularly care that the system decided it needed to 
</em><br>
<em>&gt; convert
</em><br>
<em>&gt; 90% of Arizona into a giant radio transmitter - just don't make me
</em><br>
into 
<br>
<em>&gt; one of the support beams!)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Brent &lt;== *likely to have green hair if the system says it would help
</em><br>
<em>&gt; the singularity, but glad to be consulted*
</em><br>
<p>The title of this subject line is &quot;fundamentals&quot;.  There is a
<br>
fundamental 
<br>
tradeoff that works like this:  The more *assured* are such details of
<br>
the 
<br>
outcome, even in the face of our later reconsideration, the more control
<br>
is 
<br>
irrevocably exerted over the details of the outcome by a human-level 
<br>
intelligence.  This holds especially true of the things that we are most
<br>
<p>nervous about.  The more control you take away from smarter minds, for
<br>
the 
<br>
sake of your own nervousness, the more you risk damning yourself.  What
<br>
if 
<br>
the Right of Withdrawal that you code (irrevocably and forever, or else
<br>
why 
<br>
bother) is the wrong Right, weaker and less effective than the Right of 
<br>
Withdrawal the initial dynamic would have set in place if you hadn't
<br>
meddled?
<br>
<p>The more *predictable* is the particular detail you care about, the more
<br>
<p>that detail is being specified by a human-level intelligence.  I have
<br>
said 
<br>
this before, but the moral challenges of FAI require FAI to solve - one 
<br>
must work with the stuff that good ideas are made of, dip into the well
<br>
of 
<br>
good solutions, and not depend on one's own ability to come up with the 
<br>
best answer.
<br>
<p>!!! Again...there is only one fundamental thing here...insofar as the
<br>
system decides it needs to modify me
<br>
it must first obtain permission...thats it. Pretty basic and no trade
<br>
off required...remember this applies only to
<br>
modifications to my person/self/intellect that the system deems
<br>
necessary. This control (if I have any say about it and that's the basic
<br>
point isnt it?) must not be surrendered. And there are no circumstances
<br>
that I can forsee (with my limited 2004 intellect yes...but that is the
<br>
sentient being asked to make a choice) that cannot wait, be fully
<br>
explained, and abide by my choice. The collective volition guides the
<br>
systems of the universe as it should...I just reserve the right to say
<br>
'no' as it regards my self/intellect/personality.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
---
Incoming mail is certified Virus Free.
Checked by AVG anti-virus system (<a href="http://www.grisoft.com">http://www.grisoft.com</a>).
Version: 6.0.665 / Virus Database: 428 - Release Date: 4/21/2004
 
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9294.html">Eliezer Yudkowsky: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Previous message:</strong> <a href="9292.html">Eliezer Yudkowsky: "Re: ESSAY: 'Debunking 'Hippy dippy moral philosophy'"</a>
<li><strong>Maybe in reply to:</strong> <a href="9285.html">Brent Thomas: "Fundamentals - was RE: Visualizing muddled volitions"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9294.html">Eliezer Yudkowsky: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Reply:</strong> <a href="9294.html">Eliezer Yudkowsky: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Reply:</strong> <a href="9300.html">Metaqualia: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9293">[ date ]</a>
<a href="index.html#9293">[ thread ]</a>
<a href="subject.html#9293">[ subject ]</a>
<a href="author.html#9293">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
