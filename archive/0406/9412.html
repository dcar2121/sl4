<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: We Can't Fool the Super Intelligence</title>
<meta name="Author" content="Simon Gordon (sim_dizzy@yahoo.com)">
<meta name="Subject" content="RE: We Can't Fool the Super Intelligence">
<meta name="Date" content="2004-06-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: We Can't Fool the Super Intelligence</h1>
<!-- received="Sat Jun 26 02:50:05 2004" -->
<!-- isoreceived="20040626085005" -->
<!-- sent="Sat, 26 Jun 2004 09:50:03 +0100 (BST)" -->
<!-- isosent="20040626085003" -->
<!-- name="Simon Gordon" -->
<!-- email="sim_dizzy@yahoo.com" -->
<!-- subject="RE: We Can't Fool the Super Intelligence" -->
<!-- id="20040626085003.4200.qmail@web13603.mail.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="20040626050817.6457.qmail@web60001.mail.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Simon Gordon (<a href="mailto:sim_dizzy@yahoo.com?Subject=RE:%20We%20Can't%20Fool%20the%20Super%20Intelligence"><em>sim_dizzy@yahoo.com</em></a>)<br>
<strong>Date:</strong> Sat Jun 26 2004 - 02:50:03 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9413.html">Metaqualia: "Re: My last thoughts on Collective Volition for now"</a>
<li><strong>Previous message:</strong> <a href="9411.html">Marc Geddes: "Re: My last thoughts on Collective Volition for now"</a>
<li><strong>In reply to:</strong> <a href="9409.html">Thomas Buckner: "RE: We Can't Fool the Super Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9415.html">Thomas Buckner: "RE: We Can't Fool the Super Intelligence"</a>
<li><strong>Reply:</strong> <a href="9415.html">Thomas Buckner: "RE: We Can't Fool the Super Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9412">[ date ]</a>
<a href="index.html#9412">[ thread ]</a>
<a href="subject.html#9412">[ subject ]</a>
<a href="author.html#9412">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Tom B. wrote:
<br>
<em>&gt; I think you deem that the superAI will
</em><br>
<em>&gt; be &quot;vast, cool, and unsympathetic&quot; to the
</em><br>
<em>&gt; degree that ve has no concept of how humorous our
</em><br>
<em>&gt; follies and farces are.
</em><br>
<p>Vast and cool yes, unsympathetic? doubt it. If the SAI
<br>
can pass the turing test then she will have to know
<br>
the ins and outs of sympathy, as with every other
<br>
possible human emotion, and she will probably end up
<br>
with a lot more of it than us, at least for a while.
<br>
After a maturation of the post-singularity period,
<br>
having lots of sympathy may or may not remain a
<br>
positive thing, but it is not a failing of the SAI if
<br>
she ends up simply abandoning sympathy and becoming
<br>
dry and humorless, it would just the best possible
<br>
course of action after careful consideration or rather
<br>
immensely precise analysis (who are we to judge the
<br>
failings of a vastly superior intellectual entity?).
<br>
In short i deem the superAI to be &quot;vast, cool and
<br>
un-prone-to-ignorant-decision-making-processes&quot;.
<br>
Further assumptions are unnecessary.
<br>
<p><em>&gt; Even our stupidity is
</em><br>
<em>&gt; interesting. Strange, but true.
</em><br>
<p>Its undeniable that stupidity can be entertaining.
<br>
Just watch a dog running round in circles for 5
<br>
minutes trying to catch its own tail! - sure to bring
<br>
a smile to the face of even the most hardened english
<br>
football fan (who has just watched his home nation
<br>
lose on penalties for the nth time). That said, in a
<br>
scenario where the culling of all dogs worldwide would
<br>
yield a massive benefit to mankind, would we refrain
<br>
from doing it?
<br>
<p><em>&gt; Why would a superior intelligence deny
</em><br>
<em>&gt; itself access to other modes if ve had the choice?
</em><br>
<p>I doubt ve/she would. Which is why if humans were to
<br>
be destroyed, reused or whatever by SAIs, there would
<br>
have to be a jolly good reason for it i.e. this course
<br>
of action would lead to a net increase in the number
<br>
of &quot;other accessible modes&quot; or some other perhaps more
<br>
incomprehensible benefit. In my opinion none of what
<br>
you or i have said in this exchange has changed the
<br>
prior probability of humans being converted into
<br>
computronium. I cannot see how this scenerio can be
<br>
thought of as either likely or unlikely, just a big
<br>
unknown, which might as well stand at 50%.
<br>
<p><em>&gt; I assert that this falls into the class of things
</em><br>
<em>&gt; people think a SAI might do that in fact ve
</em><br>
<em>&gt; would not do, because ve would know better. There
</em><br>
<em>&gt; might be useful learnings or experiences ve
</em><br>
<em>&gt; could derive from 'seeing through our eyes', so that
</em><br>
<em>&gt; if ve got rid of us before the resource was
</em><br>
<em>&gt; exhausted, ve would be doing something dumb..
</em><br>
<p>I cant imagine a superintelligent being doing anything
<br>
rash... so nothing would be done that has a reasonable
<br>
chance of seeming dumb at a later stage. If she has
<br>
very precise rational reasons for wanting what you
<br>
describe i.e. seeing us as interesting enough to be
<br>
preserved, then we will be preserved. If she has
<br>
equally rational reasons for not wanting us to be
<br>
around, then we wont be around for much longer. The
<br>
techniques of reasoning employed by the SAI will
<br>
likely be way beyond current techniques we use to
<br>
reason (which lets face it are pretty vague,
<br>
inaccurate and prone to error), so trying to predict
<br>
which way any important decision an SAI makes will go
<br>
is kinda like a fly on the wall trying to predict
<br>
whether that human holding a newspaper above its head
<br>
is going to swat it or not. Naturally you have an
<br>
emotional attachment to the idea that the SAI will
<br>
want to preserve your species, but you are not the one
<br>
in the position of making that decision, like it or
<br>
lump it, her(/ver/their) decision is gonna be final
<br>
and theres nothing you will be able to do about it.
<br>
<p><em>&gt; I once mentioned to a woman acquaintance a bit of
</em><br>
<em>&gt; data that I gleaned from an article in Esquire
</em><br>
<em>&gt; (a men's magazine). She replied, &quot;I don't read men's
</em><br>
<em>&gt; magazines.&quot; I told her that this was
</em><br>
<em>&gt; unenlightened because I have a rule: Never limit
</em><br>
<em>&gt; your sources of information.
</em><br>
<p>Ok well heres some of information for you: in ten
<br>
years time (summer 2014) a type of brain-computer
<br>
device becomes commercially available which uses
<br>
subaudible sounds to feed the user with a seemingly
<br>
comprehensible stream of information. Users report
<br>
words, expressions, meanings appearing deep in the
<br>
centre of their consciousness without the need to read
<br>
or hear them &quot;as if from nowhere&quot;, and an ability to
<br>
interact with these meanings in ways never thought
<br>
possible previously. These astounding devices link up
<br>
with the latest LUI console of the time and having
<br>
been tested on human subjects for many months in
<br>
separate trials they appear safe, and are even touted
<br>
by their makers as cure-alls for a whole host of
<br>
ailments including depression, impotence and chronic
<br>
pain. People can even use them to read the news or
<br>
prove mathematical theorems without using paper, and
<br>
the speed at which people can learn and absorb new
<br>
information while using them is very impressive. The
<br>
technology takes off big-time (bigger and faster than
<br>
our yesteryears mobile phone phenomonen). All is well
<br>
and good until about 3 years later when people wake up
<br>
and smell the coffee, finally realising two important
<br>
things (1) the device is more addictive than any known
<br>
drug; and (2) it can cause serious mental illness in a
<br>
large percentage of long-term users. These two facts
<br>
combined amount to one of the biggest human tradgies
<br>
ever to face the developed world, and one of the
<br>
biggest threats so far to the stabilization of
<br>
civilisation in general. The devices are quickly
<br>
banned, but toward the end of 2014 the situation is
<br>
this: over 40% of the population in western countries
<br>
are using the device illegally for more than 16 hours
<br>
a day; 18% (of the whole population) have been
<br>
diagnosed with clinical insanity (not schizophrenia,
<br>
as of yet there is no name for it, but the psychoses
<br>
appear to be much deeper than in schizophrenia).
<br>
Social and economic chaos ensues. Religious and
<br>
extremist political leaders take advantage of the
<br>
weak. Scitech developments slow to a trickle.
<br>
Singularitarians take stock and revise their
<br>
predictions. Meanwhile the internet pretends to be
<br>
asleep...
<br>
(No im just kidding about the last bit LoL)
<br>
<p>QED.
<br>
<p>Simon Gordon.
<br>
<p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
___________________________________________________________ALL-NEW Yahoo! Messenger - sooooo many all-new ways to express yourself <a href="http://uk.messenger.yahoo.com">http://uk.messenger.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9413.html">Metaqualia: "Re: My last thoughts on Collective Volition for now"</a>
<li><strong>Previous message:</strong> <a href="9411.html">Marc Geddes: "Re: My last thoughts on Collective Volition for now"</a>
<li><strong>In reply to:</strong> <a href="9409.html">Thomas Buckner: "RE: We Can't Fool the Super Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9415.html">Thomas Buckner: "RE: We Can't Fool the Super Intelligence"</a>
<li><strong>Reply:</strong> <a href="9415.html">Thomas Buckner: "RE: We Can't Fool the Super Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9412">[ date ]</a>
<a href="index.html#9412">[ thread ]</a>
<a href="subject.html#9412">[ subject ]</a>
<a href="author.html#9412">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
