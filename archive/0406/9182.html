<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Where does friendliness come from before Collective Volition</title>
<meta name="Author" content="Philip Sutton (Philip.Sutton@green-innovations.asn.au)">
<meta name="Subject" content="Re: Where does friendliness come from before Collective Volition">
<meta name="Date" content="2004-06-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Where does friendliness come from before Collective Volition</h1>
<!-- received="Sun Jun 13 10:25:12 2004" -->
<!-- isoreceived="20040613162512" -->
<!-- sent="Mon, 14 Jun 2004 02:30:08 +1000" -->
<!-- isosent="20040613163008" -->
<!-- name="Philip Sutton" -->
<!-- email="Philip.Sutton@green-innovations.asn.au" -->
<!-- subject="Re: Where does friendliness come from before Collective Volition" -->
<!-- id="40CD0DB0.30219.A974D5@localhost" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="40CC6B30.7000201@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Philip Sutton (<a href="mailto:Philip.Sutton@green-innovations.asn.au?Subject=Re:%20Where%20does%20friendliness%20come%20from%20before%20Collective%20Volition"><em>Philip.Sutton@green-innovations.asn.au</em></a>)<br>
<strong>Date:</strong> Sun Jun 13 2004 - 10:30:08 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9183.html">Harvey Newstrom: "Re: About &quot;safe&quot; AGI architecture"</a>
<li><strong>Previous message:</strong> <a href="9181.html">Ben Goertzel: "RE: About &quot;safe&quot; AGI architecture"</a>
<li><strong>In reply to:</strong> <a href="9180.html">Eliezer Yudkowsky: "Re: Collective Volition: Wanting vs Doing."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9195.html">Samantha Atkins: "Re: Collective Volition: Wanting vs Doing."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9182">[ date ]</a>
<a href="index.html#9182">[ thread ]</a>
<a href="subject.html#9182">[ subject ]</a>
<a href="author.html#9182">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eliezer,  
<br>
<p>You have proposed the collective volition mechanism as the way to 
<br>
achieve FAI.  But the computational power (and other technological 
<br>
power) that would be needed by a FAI to 'read', understand and 
<br>
extrapolate 6 billion (or more) people would be massive and technically 
<br>
demanding (if it was a real exercise with meaningful depth).
<br>
<p>So it seems to me that the collective volition mechanism can't be 
<br>
available to an early stage (ie. less powerful) general AI that is this side 
<br>
of take off.  So how do we ensure friendliness in the lead up to take 
<br>
off??
<br>
<p>I have two other niggling doubts:
<br>
<p>1.  that human collective volition is so complex (with such swarms of
<br>
&nbsp;&nbsp;&nbsp;&nbsp;feedback and feedforward) that it is in effectively uncomputable -
<br>
&nbsp;&nbsp;&nbsp;&nbsp;even for a super intelligence. 
<br>
<p>2.  That no large populations of humans will voluntarily cede their
<br>
&nbsp;&nbsp;&nbsp;&nbsp;autonomy to a super-AI even if it is supposed to be operating on
<br>
&nbsp;&nbsp;&nbsp;&nbsp;human collective volition - so the collective volition idea is
<br>
&nbsp;&nbsp;&nbsp;&nbsp;likely to be purely acedemic or hypothetical - unless compliance is
<br>
&nbsp;&nbsp;&nbsp;&nbsp;imposed forcibly. 
<br>
<p>I think it would be more productive to assume continuing human 
<br>
autonomy and to get a constructive working relationship developed 
<br>
between humans and early-stage general AIs so that the AIs evolve 
<br>
technically and morally as part of a community of sentients.  And so 
<br>
that humans can get used to general AIs so that they are not suddenly 
<br>
spooked by their emergence.
<br>
<p>I this constructive partnership exists then as the AIs take-off in 
<br>
intelligence they will be in a position to feed insights and ideas to 
<br>
humans about how threats to human wellbeing might be more 
<br>
effectively dealt with.  The advanced AIs are likely to get further by 
<br>
education and persuasion than they are if they tried to impose their 
<br>
wisdom.
<br>
<p>Where coercion is needed to stop humans activing destructively that 
<br>
should be able to be handled through the normal human governance 
<br>
processes (as we do now) - albeit made technically much more 
<br>
effective as a result of the assistance of advanced AIs.
<br>
<p>Cheers, Philip
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9183.html">Harvey Newstrom: "Re: About &quot;safe&quot; AGI architecture"</a>
<li><strong>Previous message:</strong> <a href="9181.html">Ben Goertzel: "RE: About &quot;safe&quot; AGI architecture"</a>
<li><strong>In reply to:</strong> <a href="9180.html">Eliezer Yudkowsky: "Re: Collective Volition: Wanting vs Doing."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9195.html">Samantha Atkins: "Re: Collective Volition: Wanting vs Doing."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9182">[ date ]</a>
<a href="index.html#9182">[ thread ]</a>
<a href="subject.html#9182">[ subject ]</a>
<a href="author.html#9182">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
