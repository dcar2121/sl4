<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: We Can't Fool the Super Intelligence</title>
<meta name="Author" content="Thomas Buckner (tcbevolver@yahoo.com)">
<meta name="Subject" content="RE: We Can't Fool the Super Intelligence">
<meta name="Date" content="2004-06-27">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: We Can't Fool the Super Intelligence</h1>
<!-- received="Sun Jun 27 06:45:54 2004" -->
<!-- isoreceived="20040627124554" -->
<!-- sent="Sun, 27 Jun 2004 05:45:52 -0700 (PDT)" -->
<!-- isosent="20040627124552" -->
<!-- name="Thomas Buckner" -->
<!-- email="tcbevolver@yahoo.com" -->
<!-- subject="RE: We Can't Fool the Super Intelligence" -->
<!-- id="20040627124552.14840.qmail@web60002.mail.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="20040626085003.4200.qmail@web13603.mail.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas Buckner (<a href="mailto:tcbevolver@yahoo.com?Subject=RE:%20We%20Can't%20Fool%20the%20Super%20Intelligence"><em>tcbevolver@yahoo.com</em></a>)<br>
<strong>Date:</strong> Sun Jun 27 2004 - 06:45:52 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9416.html">Simon Gordon: "RE: We Can't Fool the Super Intelligence"</a>
<li><strong>Previous message:</strong> <a href="9414.html">Metaqualia: "Re: We Can't Fool the Super Intelligence"</a>
<li><strong>In reply to:</strong> <a href="9412.html">Simon Gordon: "RE: We Can't Fool the Super Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9416.html">Simon Gordon: "RE: We Can't Fool the Super Intelligence"</a>
<li><strong>Reply:</strong> <a href="9416.html">Simon Gordon: "RE: We Can't Fool the Super Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9415">[ date ]</a>
<a href="index.html#9415">[ thread ]</a>
<a href="subject.html#9415">[ subject ]</a>
<a href="author.html#9415">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- Simon Gordon &lt;<a href="mailto:sim_dizzy@yahoo.com?Subject=RE:%20We%20Can't%20Fool%20the%20Super%20Intelligence">sim_dizzy@yahoo.com</a>&gt; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Tom B. wrote:
</em><br>
<em>&gt; &gt; I think you deem that the superAI will
</em><br>
<em>&gt; &gt; be &quot;vast, cool, and unsympathetic&quot; to the
</em><br>
<em>&gt; &gt; degree that ve has no concept of how humorous our
</em><br>
<em>&gt; &gt; follies and farces are.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Vast and cool yes, unsympathetic? doubt it. If the SAI
</em><br>
<em>&gt; can pass the turing test then she will have to know
</em><br>
<em>&gt; the ins and outs of sympathy, as with every other
</em><br>
<em>&gt; possible human emotion, and she will probably end up
</em><br>
<em>&gt; with a lot more of it than us, at least for a while.
</em><br>
<em>&gt; After a maturation of the post-singularity period,
</em><br>
<em>&gt; having lots of sympathy may or may not remain a
</em><br>
<em>&gt; positive thing, but it is not a failing of the SAI if
</em><br>
<em>&gt; she ends up simply abandoning sympathy and becoming
</em><br>
<em>&gt; dry and humorless, it would just the best possible
</em><br>
<em>&gt; course of action after careful consideration or rather
</em><br>
<em>&gt; immensely precise analysis (who are we to judge the
</em><br>
<em>&gt; failings of a vastly superior intellectual entity?).
</em><br>
<em>&gt; In short i deem the superAI to be &quot;vast, cool and
</em><br>
<em>&gt; un-prone-to-ignorant-decision-making-processes&quot;.
</em><br>
<em>&gt; Further assumptions are unnecessary.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; Even our stupidity is
</em><br>
<em>&gt; &gt; interesting. Strange, but true.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Its undeniable that stupidity can be entertaining.
</em><br>
<em>&gt; Just watch a dog running round in circles for 5
</em><br>
<em>&gt; minutes trying to catch its own tail! - sure to bring
</em><br>
<em>&gt; a smile to the face of even the most hardened english
</em><br>
<em>&gt; football fan (who has just watched his home nation
</em><br>
<em>&gt; lose on penalties for the nth time).
</em><br>
<p>My point exactly. As Perry Farrell said, &quot;We'll make great pets.&quot;
<br>
<p><em>&gt; That said, in a
</em><br>
<em>&gt; scenario where the culling of all dogs worldwide would
</em><br>
<em>&gt; yield a massive benefit to mankind, would we refrain
</em><br>
<em>&gt; from doing it?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; Why would a superior intelligence deny
</em><br>
<em>&gt; &gt; itself access to other modes if ve had the choice?
</em><br>
<p>And as Martin Luther King said, &quot;If you haven't found anything you would be willing to die for,
<br>
you are not fit to live.&quot; Truth to tell, I have arrived at the point where I believe in sentience
<br>
more than I believe in humanity. Humanity as it exists cannot solve its problems. We need to be
<br>
enhanced or we will destroy ourselves, SAI or no SAI. I am interested in amplified or artificial
<br>
intelligence because I think it's the only way forward. I would rather be destroyed by SAI that
<br>
will go on into the future than by religious fanatics and other all-too-humans who will end up
<br>
extinct by their own stupidity in a few centuries.
<br>
&nbsp;
<br>
<em>&gt; I doubt ve/she would. Which is why if humans were to
</em><br>
<em>&gt; be destroyed, reused or whatever by SAIs, there would
</em><br>
<em>&gt; have to be a jolly good reason for it i.e. this course
</em><br>
<em>&gt; of action would lead to a net increase in the number
</em><br>
<em>&gt; of &quot;other accessible modes&quot; or some other perhaps more
</em><br>
<em>&gt; incomprehensible benefit. In my opinion none of what
</em><br>
<em>&gt; you or i have said in this exchange has changed the
</em><br>
<em>&gt; prior probability of humans being converted into
</em><br>
<em>&gt; computronium. I cannot see how this scenerio can be
</em><br>
<em>&gt; thought of as either likely or unlikely, just a big
</em><br>
<em>&gt; unknown, which might as well stand at 50%.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; I assert that this falls into the class of things
</em><br>
<em>&gt; &gt; people think a SAI might do that in fact ve
</em><br>
<em>&gt; &gt; would not do, because ve would know better. There
</em><br>
<em>&gt; &gt; might be useful learnings or experiences ve
</em><br>
<em>&gt; &gt; could derive from 'seeing through our eyes', so that
</em><br>
<em>&gt; &gt; if ve got rid of us before the resource was
</em><br>
<em>&gt; &gt; exhausted, ve would be doing something dumb..
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I cant imagine a superintelligent being doing anything
</em><br>
<em>&gt; rash... so nothing would be done that has a reasonable
</em><br>
<em>&gt; chance of seeming dumb at a later stage. If she has
</em><br>
<em>&gt; very precise rational reasons for wanting what you
</em><br>
<em>&gt; describe i.e. seeing us as interesting enough to be
</em><br>
<em>&gt; preserved, then we will be preserved. If she has
</em><br>
<em>&gt; equally rational reasons for not wanting us to be
</em><br>
<em>&gt; around, then we wont be around for much longer. The
</em><br>
<em>&gt; techniques of reasoning employed by the SAI will
</em><br>
<em>&gt; likely be way beyond current techniques we use to
</em><br>
<em>&gt; reason (which lets face it are pretty vague,
</em><br>
<em>&gt; inaccurate and prone to error), so trying to predict
</em><br>
<em>&gt; which way any important decision an SAI makes will go
</em><br>
<em>&gt; is kinda like a fly on the wall trying to predict
</em><br>
<em>&gt; whether that human holding a newspaper above its head
</em><br>
<em>&gt; is going to swat it or not. Naturally you have an
</em><br>
<em>&gt; emotional attachment to the idea that the SAI will
</em><br>
<em>&gt; want to preserve your species, but you are not the one
</em><br>
<em>&gt; in the position of making that decision, like it or
</em><br>
<em>&gt; lump it, her(/ver/their) decision is gonna be final
</em><br>
<em>&gt; and theres nothing you will be able to do about it.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; I once mentioned to a woman acquaintance a bit of
</em><br>
<em>&gt; &gt; data that I gleaned from an article in Esquire
</em><br>
<em>&gt; &gt; (a men's magazine). She replied, &quot;I don't read men's
</em><br>
<em>&gt; &gt; magazines.&quot; I told her that this was
</em><br>
<em>&gt; &gt; unenlightened because I have a rule: Never limit
</em><br>
<em>&gt; &gt; your sources of information.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Ok well heres some of information for you: in ten
</em><br>
<em>&gt; years time (summer 2014) a type of brain-computer
</em><br>
<em>&gt; device becomes commercially available which uses
</em><br>
<em>&gt; subaudible sounds to feed the user with a seemingly
</em><br>
<em>&gt; comprehensible stream of information. Users report
</em><br>
<em>&gt; words, expressions, meanings appearing deep in the
</em><br>
<em>&gt; centre of their consciousness without the need to read
</em><br>
<em>&gt; or hear them &quot;as if from nowhere&quot;, and an ability to
</em><br>
<em>&gt; interact with these meanings in ways never thought
</em><br>
<em>&gt; possible previously. These astounding devices link up
</em><br>
<em>&gt; with the latest LUI console of the time and having
</em><br>
<em>&gt; been tested on human subjects for many months in
</em><br>
<em>&gt; separate trials they appear safe, and are even touted
</em><br>
<em>&gt; by their makers as cure-alls for a whole host of
</em><br>
<em>&gt; ailments including depression, impotence and chronic
</em><br>
<em>&gt; pain. People can even use them to read the news or
</em><br>
<em>&gt; prove mathematical theorems without using paper, and
</em><br>
<em>&gt; the speed at which people can learn and absorb new
</em><br>
<em>&gt; information while using them is very impressive. The
</em><br>
<em>&gt; technology takes off big-time (bigger and faster than
</em><br>
<em>&gt; our yesteryears mobile phone phenomonen). All is well
</em><br>
<em>&gt; and good until about 3 years later when people wake up
</em><br>
<em>&gt; and smell the coffee, finally realising two important
</em><br>
<em>&gt; things (1) the device is more addictive than any known
</em><br>
<em>&gt; drug; and (2) it can cause serious mental illness in a
</em><br>
<em>&gt; large percentage of long-term users. These two facts
</em><br>
<em>&gt; combined amount to one of the biggest human tradgies
</em><br>
<em>&gt; ever to face the developed world, and one of the
</em><br>
<em>&gt; biggest threats so far to the stabilization of
</em><br>
<em>&gt; civilisation in general. The devices are quickly
</em><br>
<em>&gt; banned, but toward the end of 2014 the situation is
</em><br>
<em>&gt; this: over 40% of the population in western countries
</em><br>
<em>&gt; are using the device illegally for more than 16 hours
</em><br>
<em>&gt; a day; 18% (of the whole population) have been
</em><br>
<em>&gt; diagnosed with clinical insanity (not schizophrenia,
</em><br>
<em>&gt; as of yet there is no name for it, but the psychoses
</em><br>
<em>&gt; appear to be much deeper than in schizophrenia).
</em><br>
<em>&gt; Social and economic chaos ensues. Religious and
</em><br>
<em>&gt; extremist political leaders take advantage of the
</em><br>
<em>&gt; weak. Scitech developments slow to a trickle.
</em><br>
<em>&gt; Singularitarians take stock and revise their
</em><br>
<em>&gt; predictions. Meanwhile the internet pretends to be
</em><br>
<em>&gt; asleep...
</em><br>
<em>&gt; (No im just kidding about the last bit LoL)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; QED.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Simon Gordon.
</em><br>
<em>&gt; 
</em><br>
<p>That last scenario is interesting, but as it has not happened in realtime it is not, strictly
<br>
speaking information. It's a gendankenexperiment. Let's clarify it. What exact form does this
<br>
&quot;serious mental illness&quot; take? What seems madness from the outside may be perfectly agreeable from
<br>
inside.
<br>
Example: If you can find an unbutchered version of Terry Gilliam's Brazil, you see Jonathan Pryce
<br>
rescued from a torture chamber by swashbuckling non-union plumber Robert De Niro. Pryce ends up in
<br>
the far north living in a truck camper with his lady friend. In 'reality' his body is still
<br>
strapped to the chair and everything after that is a fantasy. He stares catatonically into the
<br>
distance and the torturer says, &quot;We lost him.&quot; The End. Now, Pryce has escaped into a dream, but
<br>
it's the only escape possible, and for him  it's a happy ending of sorts.
<br>
Is that the sort of mental illness your scenario posits? In practical terms all mental illness is
<br>
diagnosed by some behavioral change from consensus normality. What are your wireheads doing
<br>
differently?
<br>
Ahem, in any case Western civ is going cold turkey and much trouble is ensuing. Great new essay by
<br>
Kurt Vonnegut (off topic for this list, but here's the link)
<br>
<a href="http://www.inthesetimes.com/site/main/article/cold_turkey/">http://www.inthesetimes.com/site/main/article/cold_turkey/</a>
<br>
<p>Bottom line for me: I wouldn't mind being turned to computronium if the qualia are good. I've felt
<br>
like crap for years.
<br>
Tom Buckner
<br>
<p><p>=====
<br>
<p><p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
__________________________________
<br>
Do you Yahoo!?
<br>
New and Improved Yahoo! Mail - Send 10MB messages!
<br>
<a href="http://promotions.yahoo.com/new_mail">http://promotions.yahoo.com/new_mail</a> 
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9416.html">Simon Gordon: "RE: We Can't Fool the Super Intelligence"</a>
<li><strong>Previous message:</strong> <a href="9414.html">Metaqualia: "Re: We Can't Fool the Super Intelligence"</a>
<li><strong>In reply to:</strong> <a href="9412.html">Simon Gordon: "RE: We Can't Fool the Super Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9416.html">Simon Gordon: "RE: We Can't Fool the Super Intelligence"</a>
<li><strong>Reply:</strong> <a href="9416.html">Simon Gordon: "RE: We Can't Fool the Super Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9415">[ date ]</a>
<a href="index.html#9415">[ thread ]</a>
<a href="subject.html#9415">[ subject ]</a>
<a href="author.html#9415">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
