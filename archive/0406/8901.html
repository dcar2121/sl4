<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: FAI: Collective Volition</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: FAI: Collective Volition">
<meta name="Date" content="2004-06-01">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: FAI: Collective Volition</h1>
<!-- received="Tue Jun  1 01:32:29 2004" -->
<!-- isoreceived="20040601073229" -->
<!-- sent="Tue, 1 Jun 2004 00:32:26 -0700" -->
<!-- isosent="20040601073226" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: FAI: Collective Volition" -->
<!-- id="D478897F-B39D-11D8-86D4-000A95B1AFDE@objectent.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="40BB7402.10007@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20FAI:%20Collective%20Volition"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Tue Jun 01 2004 - 01:32:26 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8902.html">Marc Geddes: "Re: FAI: Collective Volition"</a>
<li><strong>Previous message:</strong> <a href="8900.html">J. Andrew Rogers: "Re: One or more AIs??"</a>
<li><strong>In reply to:</strong> <a href="../0405/8885.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8905.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<li><strong>Reply:</strong> <a href="8905.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8901">[ date ]</a>
<a href="index.html#8901">[ thread ]</a>
<a href="subject.html#8901">[ subject ]</a>
<a href="author.html#8901">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Thanks for writing this Eliezer.   My first level comments follow.
<br>
<p>How can we possibly get an SAI, excuse me, a &quot;Friendly Really Powerful 
<br>
Optimization Process&quot;. to successfully extrapolate the full collective 
<br>
volition of humanity?  At this point in the  game we can't even master 
<br>
simple DWIM applications.   We do not have AIs that are capable of 
<br>
understanding immediate volition much less the full extended volition.  
<br>
&nbsp;&nbsp;&nbsp;So how can any device/AI/optimization process claiming to do so 
<br>
possibly seem other than completely arbitrary and un-Friendly?
<br>
<p>Extrapolation of volition based on what we would want if we were very 
<br>
different beings than we are is even more likely to go far off the 
<br>
mark.   How can this possibly not diverge wildly into whatever the FAI 
<br>
(or whatever) forces to converge into simply what it believes would be 
<br>
&quot;best&quot;?   This is unlikely to bear a lot of resemblance to what any 
<br>
actual humans want at any depth.
<br>
<p>The task you describe for the FRPOP is the tasks myths would have a 
<br>
fully enlightened, god-level, super-wise being attempt and only then 
<br>
with a lot of cautions.   IMHO, attempting to do this with a 
<br>
un-sentient recursively self-improving process is the height of folly.  
<br>
It seems even  more hubristic and difficult than the creation of a 
<br>
<em> &gt;human intelligent sentience.    I don't see why you believe yourself 
</em><br>
incapable of the latter but capable of the former.
<br>
<p>Now you do back away from such implications somewhat by having volition 
<br>
extrapolation be only a first level working solution until &quot;that 
<br>
voliton&quot; evolves and/or builds something better.   But what do you mean 
<br>
by &quot;that volition&quot; here?   Is it the FRPOP, what the FRPOP becomes, the 
<br>
FRPOP plus humanity plus the extrapolated vision to date or what?  It 
<br>
isn't very clear to me.
<br>
<p>If the ruleset is scrutable and able to be understood by some, many, 
<br>
most humans then why couldn't humans come up with it?
<br>
<p>I am not at all sure that our &quot;collective volition&quot; is superior to the 
<br>
very best of our relatively individual volition.   Saying it is 
<br>
collective may make it sound more egalitarian, democratic and so on but 
<br>
may not have much to do with it actually being best able to guarantee 
<br>
human survival and well-being.  It looks like you were getting toward 
<br>
the same thing in your 2+ days partial recanting/adjustment-wishes.   I 
<br>
don't see how &quot;referring the problem back to humanity&quot; is all that 
<br>
likely to solve the problem.   It might however be the best that can be 
<br>
done.
<br>
<p>I think I see that you are attempting to extrapolate beyond the present 
<br>
average state of humans and their self-knowledge/stated 
<br>
wishes/prejudices and so on to what they really, really want in their 
<br>
most whole-beyond-idealization core.   I just find it unlikely to near 
<br>
absurdity to believe any un-sentient optimizing process, no matter how 
<br>
recursively self-improving, will ever arrive there.
<br>
<p>Where are sections on enforcement of conditions that keep humanity from 
<br>
destroying itself?  What if the collective volition leads to 
<br>
self-destruction or the destruction of other sentient beings?   But 
<br>
more importantly, what does the FAI protect us from and how is it 
<br>
intended to do so?
<br>
<p>Section 6 is very useful.   You do not want to build a god but you want 
<br>
to enshrine the &quot;true&quot; vox populi, vox Dei.  It is interesting in that 
<br>
the vox populi is the extrapolation of the volition of the people and 
<br>
in that manner a reaching for the highest within human desires and 
<br>
potentials.   This is almost certainly the best that can be done by and 
<br>
for humans including those building an FAI.   But the question is 
<br>
whether that is good enough to create that which to some (yet to be 
<br>
specified extent) enforces or nudges powerfully toward that collective 
<br>
volition.   Is there another choice?  Perhaps not.
<br>
<p>A problem is whether the most desirable volition is part of the 
<br>
collective volition or relatively rare.  A rare individual or group of 
<br>
individuals' vision may be a much better goal and may perhaps even be 
<br>
what most humans eventually have as their volition when they get wise 
<br>
enough, smart enough and so on.   If so then collective volition is not 
<br>
sufficient.  Judgment of the best volition must be made to get the best 
<br>
result.  Especially if the collective volition at this time is adverse 
<br>
to the best volition and if the enforcement of the collective volition, 
<br>
no matter how gentle, might even preclude the better volition.   Just 
<br>
because being able to judge is hard and fraught with danger doesn't 
<br>
mean it is necessarily better not to do so.
<br>
<p>The earth is NOT scheduled to go to &quot;vanish in a puff of smiley faces&quot;. 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;I very much do not agree that that is the only alternative to FAI.
<br>
<p>Q1's answer is no real answer.  The answer today is we have no friggin' 
<br>
idea how to do this.
<br>
<p>Q2's answer is opaque (yes I did raise this question).   I can see 
<br>
using an SAI to tease out and augment the ability of humanity to see 
<br>
and embrace its own best volition.  But this doesn't seem to be what is 
<br>
proposed.  Or at least I need to ask various questions about what kind 
<br>
of rules you plan the FAI to enforce and how to understand whether your 
<br>
proposal is compatible.
<br>
<p>I am not into blaming SIAI and find it amazing you would toss this in.
<br>
<p>Q4's answer disturbs me.  if there are &quot;inalienable rights&quot; it is not 
<br>
because someone or other has the opinion that such rights exists.  It 
<br>
is because the nature of human beings is not utterly mutable and this 
<br>
fixed nature leads to the conclusion that some things are required for 
<br>
human well-functioning.   These things that are required by the nature 
<br>
of humans are &quot;inalienable&quot; in that they are not the made-up opinions 
<br>
of anyone or some favor of some governmental body or other.    As such 
<br>
these true inalienable rights should grow straight out of Friendliness 
<br>
towards humanity.
<br>
<p>Your answer also mixes freely current opinions of the majority of human 
<br>
kind and actual collective volition.  It seems rather sloppy.
<br>
<p>That's all for now.  I am taking a break from computers for the next 4 
<br>
days or so.   So I'll catch up next weekend.
<br>
<p>- samantha
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8902.html">Marc Geddes: "Re: FAI: Collective Volition"</a>
<li><strong>Previous message:</strong> <a href="8900.html">J. Andrew Rogers: "Re: One or more AIs??"</a>
<li><strong>In reply to:</strong> <a href="../0405/8885.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8905.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<li><strong>Reply:</strong> <a href="8905.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8901">[ date ]</a>
<a href="index.html#8901">[ thread ]</a>
<a href="subject.html#8901">[ subject ]</a>
<a href="author.html#8901">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
