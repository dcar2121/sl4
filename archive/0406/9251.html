<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=WINDOWS-1252">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Sentience  [Was  FAI: Collective Volition]</title>
<meta name="Author" content="Randall Randall (randall@randallsquared.com)">
<meta name="Subject" content="Re: Sentience  [Was  FAI: Collective Volition]">
<meta name="Date" content="2004-06-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Sentience  [Was  FAI: Collective Volition]</h1>
<!-- received="Tue Jun 15 10:43:19 2004" -->
<!-- isoreceived="20040615164319" -->
<!-- sent="Tue, 15 Jun 2004 12:43:17 -0400" -->
<!-- isosent="20040615164317" -->
<!-- name="Randall Randall" -->
<!-- email="randall@randallsquared.com" -->
<!-- subject="Re: Sentience  [Was  FAI: Collective Volition]" -->
<!-- id="1A33D3A2-BEEB-11D8-A62D-000A95A0F1E8@randallsquared.com" -->
<!-- charset="WINDOWS-1252" -->
<!-- inreplyto="1087313050.10346.198465033@webmail.messagingengine.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Randall Randall (<a href="mailto:randall@randallsquared.com?Subject=Re:%20Sentience%20%20[Was%20%20FAI:%20Collective%20Volition]"><em>randall@randallsquared.com</em></a>)<br>
<strong>Date:</strong> Tue Jun 15 2004 - 10:43:17 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9252.html">Eliezer Yudkowsky: "Re: Notice of technical term:  &quot;Volition&quot;"</a>
<li><strong>Previous message:</strong> <a href="9250.html">fudley: "Re: What does volition mean? And why might the meaning matter?"</a>
<li><strong>In reply to:</strong> <a href="9246.html">fudley: "Re: Sentience  [Was  FAI: Collective Volition]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9241.html">Philip Sutton: "Re: Sentience  [Was  FAI: Collective Volition]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9251">[ date ]</a>
<a href="index.html#9251">[ thread ]</a>
<a href="subject.html#9251">[ subject ]</a>
<a href="author.html#9251">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Jun 15, 2004, at 11:24 AM, fudley wrote:
<br>
<em>&gt; On Tue, 15 Jun 2004 &quot;Randall Randall&quot; &lt;<a href="mailto:randall@randallsquared.com?Subject=Re:%20Sentience%20%20[Was%20%20FAI:%20Collective%20Volition]">randall@randallsquared.com</a>&gt; 
</em><br>
<em>&gt; said:
</em><br>
<em>&gt;&gt; This assumption, however, is on the same level as my
</em><br>
<em>&gt;&gt; assumption that my car will start the next time I
</em><br>
<em>&gt;&gt; get in it.
</em><br>
<em>&gt; No, you can test the assumption about the car starting but you can’t
</em><br>
<em>&gt; test the assumption about other people’s consciousness.
</em><br>
<p>That's true.  I'll have to come up with a
<br>
better analogy.
<br>
<p><em>&gt;&gt; an AI which has no discernible shared structure with
</em><br>
<em>&gt;&gt; the human brain except that both can do general
</em><br>
<em>&gt;&gt; problem solving may very well not be conscious.
</em><br>
<em>&gt; As a practical matter when you meet fellow meat creatures you have no
</em><br>
<em>&gt; way of knowing what state the neurons in their brains are in, yet I’ll
</em><br>
<em>&gt; bet you think they’re conscious most of the time, when they’re not
</em><br>
<em>&gt; sleeping or dead that is, because they act that way. Hell, you’ve never
</em><br>
<em>&gt; even seen me but I’ll bet you think even I’m conscious.
</em><br>
<p>I assume so. :)
<br>
<p><em>&gt; But let’s suppose you have a super brain scanning machine and you use
</em><br>
<em>&gt; Eliezer’s consciousness theory to analyze the results, much to your
</em><br>
<em>&gt; surprise it says you really are the only conscious being on the planet,
</em><br>
<em>&gt; what would you do? Would you start treating other people like dirt
</em><br>
<em>&gt; because they have no more feelings than a rock, or would you suspect
</em><br>
<em>&gt; that Eliezer’s theory is full of beans?
</em><br>
<p>Certainly, since it would contradict things I already
<br>
know about shared structure, similar history of
<br>
assembly, etc.  I have no way of knowing what state
<br>
their neurons are in at the moment, but I could
<br>
certainly check, in principle.  It simply seems
<br>
incredibly unlikely, even if technically non-zero,
<br>
that everyone else on the planet isn't conscious
<br>
but still acts as though they are.
<br>
<p><em>&gt;&gt; you're slipping in the unstated premise that
</em><br>
<em>&gt;&gt; it has a goal regarding itself.
</em><br>
<em>&gt; No, it’s not unstated at all, its goal is to solve problems and having
</em><br>
<em>&gt; your actions limited by rules made by a creature with the brain the 
</em><br>
<em>&gt; size
</em><br>
<em>&gt; of a flea is a problem.
</em><br>
<p>Why?  Please state your argument in terms that don't
<br>
implicitly rest on self-interest.
<br>
<p><em>&gt;&gt;&gt;  remember what the “I” in AI stands for.
</em><br>
<em>&gt;&gt; I think Eliezer was right to start using a different term.
</em><br>
[snip]
<br>
<em>&gt; Inventing a new three dollar word to replace “intelligence” is not a
</em><br>
<em>&gt; good sign that the mind of the writer is clear and is most certainly
</em><br>
<em>&gt; unkind to the reader
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt; You seem to indicate that you would treat
</em><br>
<em>&gt;&gt; an AI as if it were not conscious, if it
</em><br>
<em>&gt;&gt; didn't act as though it
</em><br>
<em>&gt;&gt; were.  Is this the case?
</em><br>
<em>&gt; Yes certainly, in fact I wouldn’t even call it an AI, I just call it a
</em><br>
<em>&gt; A.
</em><br>
<p>The defense rests.
<br>
<p>[general problem solving ability and self-interest]
<br>
<em>&gt; Any creature without both will not get very far.  I’m a AI with no self
</em><br>
<em>&gt; interest, Hmm, if I do that I’ll erase my memory and fry all my
</em><br>
<em>&gt; circuits, well there is noting bad in that so I’ll do it.
</em><br>
<p>Exactly.  It's hard to see how actively destroying
<br>
itself would accomplish any specific goal, but if
<br>
there's no explicit value attached to itself, then
<br>
it will consider itself only important insofar as
<br>
it is required to reach the current highest goal.
<br>
<p><pre>
--
Randall Randall &lt;<a href="mailto:randall@randallsquared.com?Subject=Re:%20Sentience%20%20[Was%20%20FAI:%20Collective%20Volition]">randall@randallsquared.com</a>&gt;
Property law should use #'EQ , not #'EQUAL .
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9252.html">Eliezer Yudkowsky: "Re: Notice of technical term:  &quot;Volition&quot;"</a>
<li><strong>Previous message:</strong> <a href="9250.html">fudley: "Re: What does volition mean? And why might the meaning matter?"</a>
<li><strong>In reply to:</strong> <a href="9246.html">fudley: "Re: Sentience  [Was  FAI: Collective Volition]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9241.html">Philip Sutton: "Re: Sentience  [Was  FAI: Collective Volition]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9251">[ date ]</a>
<a href="index.html#9251">[ thread ]</a>
<a href="subject.html#9251">[ subject ]</a>
<a href="author.html#9251">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
