<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: qualia, once and for all</title>
<meta name="Author" content="Sebastian Hagen (sebastian_hagen@gmx.de)">
<meta name="Subject" content="Re: qualia, once and for all">
<meta name="Date" content="2004-06-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: qualia, once and for all</h1>
<!-- received="Sat Jun 19 09:37:54 2004" -->
<!-- isoreceived="20040619153754" -->
<!-- sent="Sat, 19 Jun 2004 17:37:43 +0200" -->
<!-- isosent="20040619153743" -->
<!-- name="Sebastian Hagen" -->
<!-- email="sebastian_hagen@gmx.de" -->
<!-- subject="Re: qualia, once and for all" -->
<!-- id="40D45DC7.4080407@gmx.de" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="01f401c45604$1b4c2710$0301a8c0@CURZIOL2" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Sebastian Hagen (<a href="mailto:sebastian_hagen@gmx.de?Subject=Re:%20qualia,%20once%20and%20for%20all"><em>sebastian_hagen@gmx.de</em></a>)<br>
<strong>Date:</strong> Sat Jun 19 2004 - 09:37:43 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9356.html">Jef Allbright: "Re: qualia, once and for all"</a>
<li><strong>Previous message:</strong> <a href="9354.html">Bill Hibbard: "Re: Geddes's 'Moral Perturbation Theory'"</a>
<li><strong>In reply to:</strong> <a href="9349.html">Metaqualia: "Re: qualia, once and for all"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9363.html">Metaqualia: "Re: qualia, once and for all"</a>
<li><strong>Reply:</strong> <a href="9363.html">Metaqualia: "Re: qualia, once and for all"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9355">[ date ]</a>
<a href="index.html#9355">[ thread ]</a>
<a href="subject.html#9355">[ subject ]</a>
<a href="author.html#9355">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Metaqualia wrote:
<br>
<em> &gt;[Sebastian Hagen wrote:]
</em><br>
<em>&gt;&gt;One obvious example of the difference between &quot;pure QBAU&quot; and volitional
</em><br>
<em>&gt;&gt;morality is that an AI whose goal system was based on &quot;pure QBAU&quot; would
</em><br>
<em>&gt;&gt;very likely to immediately start converting all of the matter in the universe
</em><br>
<em>&gt;&gt;into computronium on which to run &quot;happy minds&quot;, painlessly killing all
</em><br>
<em>&gt;&gt;biological life in the process, possibly without even waiting to upload any humans.
</em><br>
<em>&gt; A valid objection, thanks for raising it.
</em><br>
<em>&gt; The total sum of positive qualia is not a straight scalar value. Each
</em><br>
<em>&gt; sentient's qualia stream is produced by a collection of particles. When I
</em><br>
<em>&gt; say maximize positive qualia, minimize negative qualia, I am making an
</em><br>
<em>&gt; oversimplification for sake of introducing the idea. If you want to get into
</em><br>
<em>&gt; exactly _how_ to calculate the sum, great, as long as we accept that the end
</em><br>
<em>&gt; in itself is valuable.
</em><br>
I can't do that unless I understand the idea completely. At the moment I 
<br>
apparently don't, and knowing your algorithm for calculation and the 
<br>
justification for it may help.
<br>
<p><em>&gt; What you are doing is starting from the consequences
</em><br>
<em>&gt; of an idea and using those to reject or accept its validity. This is not
</em><br>
<em>&gt; lawful. If you agree in principle that maximizing positive qualia is really
</em><br>
<em>&gt; &quot;the thing&quot; to do, then it doesn't matter whether we are replaced by
</em><br>
<em>&gt; orgasmium! That would be the right thing to do. 
</em><br>
I agree. The quote about a possible outcome wasn't intended as an argument in 
<br>
itself.
<br>
<p><em>&gt; To answer your concerns, since each one of us is only aware of qualia
</em><br>
<em>&gt; produced in a small portion of the universe, a positive balance must be
</em><br>
<em>&gt; achieved in _each one_ of these subsystems. You can't take a healthy king
</em><br>
<em>&gt; and a sick peasant and average out their qualia.
</em><br>
<em>&gt; Since beings that have lived and are living today have a red balance
</em><br>
<em>&gt; (negative qualia have far overwhelmed positive ones) they have the right for
</em><br>
<em>&gt; immediate assistance. This means that everyone alive today needs to be
</em><br>
<em>&gt; satisfied consistently for some time before they are even (if such thing as
</em><br>
<em>&gt; &quot;even&quot; can ever exist between positive and negative qualia; ideally negative
</em><br>
<em>&gt; qualia should be eradicated which is entirely within our possibilities in
</em><br>
<em>&gt; the next century). It means that every qualia stream that lived before needs
</em><br>
<em>&gt; to be - if physically possible - brought back so that they can also break
</em><br>
<em>&gt; even.
</em><br>
Now I'm getting *really* confused. What is a qualia stream? Human minds may 
<br>
typically think that they have them, but thinking that doesn't make it real. All 
<br>
&quot;qualias&quot; I remember having perceived weren't really perceived by my 
<br>
present-self (at time of the thought; yes, this actually is an illusion in 
<br>
itself) at all, but by my past-selves. Some of these are close to my 
<br>
present-self, others very distant.
<br>
Thought experiment:
<br>
If I made an essentially perfect copy of my body using, say, advanced MNT (some 
<br>
quantum-states will probably be lost, but they don't appear critical) in the 
<br>
future, there would then be two very similar versions of what my present-self 
<br>
would regard as future-selves of itself. Both would the memories of my 
<br>
future-self just before the duplication. Both would perceive qualias they 
<br>
remember as part of &quot;their own&quot; qualia stream. So...does that mean that copying 
<br>
a human also creates a copy of its qualia stream?
<br>
<p><em>&gt;&gt;even uploaded human minds - the SI could modify uploaded human minds to
</em><br>
<em>&gt;&gt;the point of being efficient qualia generators, but why? If qualia generation
</em><br>
<em>&gt;&gt;is the
</em><br>
<em> &gt;
</em><br>
<em>&gt; because we exist? You seem to think of qualia as phenomena which are
</em><br>
<em>&gt; dissociated from a sentient. You say, ok, let's get rid of the sentients and
</em><br>
<em>&gt; pump qualia; actually that is likely not to be possible; you probably need
</em><br>
<em>&gt; vast areas of a sentient's brain in order to create qualia. And even if that
</em><br>
<em>&gt; turns out not to be true, it would simply mean that until the present we
</em><br>
<em>&gt; have thought of ourselves as brains, but we were just that little speck of
</em><br>
<em>&gt; brain which produced the qualia. In that case WE - as qualia producing
</em><br>
<em>&gt; speck - will be preserved while the heavy machinery of our bodies and
</em><br>
<em>&gt; useless parts of our brain will be rightfully wiped out of existence :)
</em><br>
I don't know what sentience is, but if it is required for qualia-generation 
<br>
there are probably more efficient implementations of a general 
<br>
&quot;qualia-generating sentient&quot; than (not modified to the point of being 
<br>
unrecognizable as such) uploaded human minds.
<br>
Whatever qualities you need in a qualia-generator, designing one from scratch is 
<br>
likely to give you a more efficient result than using what evolution came up 
<br>
with in humans.
<br>
<p><em>&gt; 
</em><br>
<em>&gt;&gt;&gt;Freedom has always been associated with the ability of carrying out
</em><br>
<em>&gt;&gt;&gt;one's
</em><br>
<em>&gt;&gt;&gt;wishes which are supposed to increase positive qualia and decrease
</em><br>
<em>&gt;&gt;&gt;negative ones.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;Imho, it equally applies to the ability of carrying out wishes that are
</em><br>
<em>&gt;&gt;supposed to achieve other means.
</em><br>
<em>&gt; 
</em><br>
<em> &gt;
</em><br>
<em>&gt; These other means inevitably will take us and the ones we care about to a
</em><br>
<em>&gt; more favorable balance of positivity and negativity.
</em><br>
That is afaik not always correct, and even in many cases where it is you could 
<br>
classify that as a side-effect.
<br>
<p><em>&gt;&gt;&gt;YET, we can strike a compromise here and say that the
</em><br>
<em>&gt;&gt;&gt;_Variety_ of positive qualia is also important, therefore we account for
</em><br>
<em>&gt;&gt;&gt;growth. More intelligence, bigger brains, more complex and interesting
</em><br>
<em>&gt;&gt;&gt;positive qualia.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;Why would we want to do that if the overall positiveness of qualia is
</em><br>
<em>&gt;&gt;really all we cared about?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; In the same way that I cannot justify objectively why positive qualia are
</em><br>
<em>&gt; better than negative ones, but can only point you back at your own OUCH
</em><br>
<em>&gt; experience,
</em><br>
That really won't do at all in my case. All that tells me is that &quot;evolution 
<br>
wants me to avoid situation X&quot;, nothing more. I don't have any compelling reason 
<br>
to assume that my 'OUCH' is objectively negative. I will avoid it, partly 
<br>
because I'm not a completely rational being, and partly because it would cause 
<br>
my mind to fall into patterns that reduce its efficiency at doing what I 
<br>
consider its real job.
<br>
If I had the ability for complete and safe(!) self-modification, I would likely 
<br>
deactivate my qualia-generating code (yes, all of it) ASAP, assuming that I find 
<br>
something to replace it with that works at least as well (afaik, a typical 
<br>
rational goal system would be likely to work).
<br>
<p><em>&gt; I also cannot justify the need for variation; there are many
</em><br>
<em>&gt; kinds of positivity. They all, perceptually and ineffably, are positive. Red
</em><br>
<em>&gt; is a nice color, so is yellow. You want to pump up redness to infinity and
</em><br>
<em>&gt; forget the yellow? That would be such a waste!
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;&gt;Using qualia as a measuring stick we reconcile all our individual
</em><br>
<em>&gt;&gt;&gt;morality assessments including why Hitler was evil, why we are justified in
</em><br>
<em>&gt;&gt;&gt;forcing our children not to jump from the window thereby limiting their freedom
</em><br>
<em>&gt;&gt;&gt;at times, why a paperclip universe sucks, and so forth.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;I don't think that justifies making a basic assumption as strong as the
</em><br>
<em>&gt;&gt;one that
</em><br>
<em>&gt;&gt;qualia represent objective morality.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; If I unified the forces of the universe into a single theory which contains
</em><br>
<em>&gt; in a more elegant form all other theories, would that justify making a basic
</em><br>
<em>&gt; assumption as strong as the one that my theory represent the theory of
</em><br>
<em>&gt; everything?
</em><br>
Occam's razor still has validity. If you could offer a theory that makes 
<br>
verifiable predictions that classify it at least as good at predicting reality 
<br>
as the best competitors (according to BT), which is simpler (I don't understand 
<br>
what elegance is) than those competitors, then yes, it would justify that.
<br>
<p><em>&gt;&gt;Hmmm. If I understood this correctly you assume that any sufficiently
</em><br>
<em>&gt;&gt;intelligent mind would see &quot;perceiving qualia with as positive a sum as
</em><br>
<em>&gt;&gt;possible&quot; as a justified highest-level goal. Can you offer any proof of
</em><br>
<em>&gt;&gt;that?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; no! wait. It would have to contain the same module that produces qualia in
</em><br>
<em>&gt; us. that is why I want an FAI to get to the bottom of qualia before it makes
</em><br>
<em>&gt; any moral judgment! Since I don't know how qualia are produced it is not out
</em><br>
<em>&gt; of the question that a completely logical and subjectively inert process can
</em><br>
<em>&gt; be started that does computation on an abstract level. A zombie AI. A zombie
</em><br>
<em>&gt; AI would +not+ know about qualia and would correctly judge our subjective
</em><br>
<em>&gt; reports as trash and wipe us out.
</em><br>
How can it correctly judge them as trash if qualia are a part of objective reality?
<br>
<p><em>&gt;&gt;&quot;the other stuff that doesn't make [me] happy&quot; is in my opinion likely to
</em><br>
<em>&gt;&gt;be
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Exactly, we can argue about variety of positive qualia until the sun stops
</em><br>
<em>&gt; shining, but the URGENT need right now is to remove negative qualia! At
</em><br>
<em>&gt; least the most severe and fruitless forms of them, on which everyone will
</em><br>
<em>&gt; agree. For instance, everyone deserves not to be depressed, not to have
</em><br>
<em>&gt; seizures, not to get their limbs amputated, not to be a lab animal, not to
</em><br>
<em>&gt; lose a lover, and so forth!
</em><br>
No, the most URGENT need right now is to stop our house from burning down 
<br>
without blowing it up (sorry, Eliezer). Suffering is a problem, but we can 
<br>
probably tolerate a few more years/decades/centuries of it if we need that time 
<br>
to find a safe way to alleviate it. We probably don't have that time because of 
<br>
other developments, but having some really big problems to be solved doesn't 
<br>
allow us to rush incompletely verified solution-methods into implementation if 
<br>
that runs a serious risk of making our situation a lot worse.
<br>
<p><em>&gt;&gt;perceiving positive qualia in wireheaded-mode is not a future I deem
</em><br>
<em>&gt;&gt;desirable according to my current goal system.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; You forget that you are already in wirehead mode. Right now the wire is
</em><br>
<em>&gt; working in this way. If you make an effort to know more, explore the
</em><br>
<em>&gt; universe, figure out the multiverse, raise 2 children, if you spend your
</em><br>
<em>&gt; life in an endless routine of worry, effort and problem solving, if you go
</em><br>
<em>&gt; through the negativity that the wire will produce for you day in and day
</em><br>
<em>&gt; out, like a passive boxer with anaesthesia, THEN the button will push itself
</em><br>
<em>&gt; and you will see, in a rush of positive chemicals, that it ALL was worth it.
</em><br>
<em>&gt; You will see not how the chemicals are pink and wonderful and smell so good,
</em><br>
<em>&gt; but you will see how wonderful kids are and how great an achievement it is
</em><br>
<em>&gt; to conquer the cosmos and how great boxing is. We are all wired! Question is
</em><br>
<em>&gt; do you prefer cruel mother nature to push the buttons randomly, with an
</em><br>
<em>&gt; evidently unfavorable balance, or do you want to push your own buttons.
</em><br>
I don't want nature to push the buttons (it isn't really randomly). I don't want 
<br>
to push them myself either, unless I really really know what I'm doing (and 
<br>
right now, I definitely wouldn't, and I don't want an SI to give me the choice 
<br>
without giving me some other upgrades or having me read and understand (not just 
<br>
click away) about a thousand warning dialog-boxes first.
<br>
Right now, it seems like a good idea to me to switch them off entirely. I might 
<br>
&nbsp;&nbsp;well be wrong about that (and certainly don't advocate hardwiring it into an 
<br>
AI!), but turning the goodness knob to maximum and everything else to zero 
<br>
doesn't look like a good idea to me at all.
<br>
&lt;qualia_speculation&gt;
<br>
What we call Qualia is imho a type of information-transfer between the human 
<br>
subconscious and conscious (no, I don't know what that really means either) 
<br>
thoughts. A human sees an object that reflects a distinctive part of the light 
<br>
spectrum, and their brain presents it to them as a easy to remember and 
<br>
recognize in the future sensation. A human tries to feel on a fire, and their 
<br>
subconscious transfers this as a form of input that is rated as strongly negative.
<br>
It is a method of transferring information to, and controlling the goals of 
<br>
humans and likely other high mammals. The system doesn't have any more 
<br>
justification than the xenophobic instinct of getting aggressive at and killing 
<br>
people different from ourselves when the resources run low (just an example, 
<br>
there are plenty of other evolutionary adaptions I consider negative). The 
<br>
output of the system doesn't have any more justification either.
<br>
&lt;/qualia_speculation&gt;
<br>
This hypothesis is quite likely to be incorrect, but unless you can rationally 
<br>
show that you have a better one, I'll go on treating qualia as yet another 
<br>
misguided adaption.
<br>
Regardless of who, or whether either of us is correct, if the first SI is 
<br>
CV-using and it works, we both win.
<br>
With my current knowledge I'm not willing at all to put this massive gamble on 
<br>
an AI with a qualia-based morality.
<br>
<p><em>&gt;
</em><br>
<em>&gt;&gt;morality is objectively a good idea, I'll continue considering hardwiring
</em><br>
<em>&gt;&gt;a qualia-based morality into any AI something that is very likely to cause a
</em><br>
<em>&gt;&gt;lot of negative utility.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I have previously presented a theory that says that an AI with sufficient
</em><br>
<em>&gt; intelligence AND an ability to at least initially perceive qualia, will come
</em><br>
<em>&gt; to the same conclusions, that qualia _matter_. So hardwiring this is option
</em><br>
<em>&gt; #2.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It goes something like this: qualia are not completely detached from the
</em><br>
<em>&gt; process that creates them,  because we can say something like &quot;I feel a
</em><br>
I would go farther and claim that they aren't detached from the process at all.
<br>
<p><em>&gt; negative quale&quot;. Therefore it is possible -physically- to analyze a quale
</em><br>
<em>&gt; introspectively. 
</em><br>
Agreed.
<br>
<p><em>&gt; The negative nature of a negative quale is self-evident.
</em><br>
<em>&gt; The AI will be no less puzzled than we are discovering one variable that
</em><br>
<em>&gt; unlike everything else, matters so much and cannot be communicated in
</em><br>
<em>&gt; standard ways. Then it will go the same route I have, declaring war to it,
</em><br>
<em>&gt; and raising qualia balance control to supergoal.
</em><br>
<em>&gt;
</em><br>
It is imho self-evident for certain qualias because evolution hardcoded it. Does 
<br>
yellow have a self-evident positive or negative nature?
<br>
<p><p><em>&gt; But, this requires the machine to be able to modify its goal structure. It
</em><br>
<em>&gt; requires programmer thought. In humans, this is possible but there is
</em><br>
<em>&gt; individual variation. Your objection that &quot;you are a sentient and still see
</em><br>
<em>&gt; happiness alone to have negative utility&quot; may be an indication of your
</em><br>
<em>&gt; personal difficulty to alter your goal structure (actually to flip it
</em><br>
<em>&gt; around) at this point.
</em><br>
Perhaps. I prefer to see it as the ability to put up a little more resistance to 
<br>
&nbsp;&nbsp;my evolutionary programming than the programming evolved to break effectively.
<br>
<p>Sebastian Hagen
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9356.html">Jef Allbright: "Re: qualia, once and for all"</a>
<li><strong>Previous message:</strong> <a href="9354.html">Bill Hibbard: "Re: Geddes's 'Moral Perturbation Theory'"</a>
<li><strong>In reply to:</strong> <a href="9349.html">Metaqualia: "Re: qualia, once and for all"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9363.html">Metaqualia: "Re: qualia, once and for all"</a>
<li><strong>Reply:</strong> <a href="9363.html">Metaqualia: "Re: qualia, once and for all"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9355">[ date ]</a>
<a href="index.html#9355">[ thread ]</a>
<a href="subject.html#9355">[ subject ]</a>
<a href="author.html#9355">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
