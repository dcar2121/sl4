<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: qualia, once and for all</title>
<meta name="Author" content="Sebastian Hagen (sebastian_hagen@gmx.de)">
<meta name="Subject" content="Re: qualia, once and for all">
<meta name="Date" content="2004-06-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: qualia, once and for all</h1>
<!-- received="Tue Jun 22 06:49:55 2004" -->
<!-- isoreceived="20040622124955" -->
<!-- sent="Tue, 22 Jun 2004 14:49:47 +0200" -->
<!-- isosent="20040622124947" -->
<!-- name="Sebastian Hagen" -->
<!-- email="sebastian_hagen@gmx.de" -->
<!-- subject="Re: qualia, once and for all" -->
<!-- id="40D82AEB.8060005@gmx.de" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="043201c457e0$540a79c0$0301a8c0@CURZIOL2" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Sebastian Hagen (<a href="mailto:sebastian_hagen@gmx.de?Subject=Re:%20qualia,%20once%20and%20for%20all"><em>sebastian_hagen@gmx.de</em></a>)<br>
<strong>Date:</strong> Tue Jun 22 2004 - 06:49:47 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9386.html">Keith Henson: "Re: ESSAY: 'Debunking 'Hippy dippy moral philosophy'"</a>
<li><strong>Previous message:</strong> <a href="9384.html">Mike: "RE: qualia, once and for all"</a>
<li><strong>In reply to:</strong> <a href="9383.html">Metaqualia: "Re: qualia, once and for all"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9392.html">Paul Fidika: "Re: qualia, once and for all"</a>
<li><strong>Reply:</strong> <a href="9392.html">Paul Fidika: "Re: qualia, once and for all"</a>
<li><strong>Reply:</strong> <a href="9393.html">Metaqualia: "Re: qualia, once and for all"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9385">[ date ]</a>
<a href="index.html#9385">[ thread ]</a>
<a href="subject.html#9385">[ subject ]</a>
<a href="author.html#9385">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Metaqualia wrote:
<br>
<p><em>&gt; The knowledge argument: mary is born in a room with no colored objects. She
</em><br>
<em>&gt; studies every physical phenomenon connected with colors and light. Then she
</em><br>
<em>&gt; steps out of the room and sees actual colors. Will she learn something new?
</em><br>
<em>&gt; If so, the third person interpretation of color is not sufficient to cover
</em><br>
<em>&gt; all of the phenomena concerning color.
</em><br>
Assuming that mary is a transhuman and therefore has sufficient abilities to 
<br>
absorb all of current physics, including everything we know about light, and all 
<br>
present knowledge about evolution of lifeforms in general and humans in 
<br>
particular, and that she actually does absorb all of this knowledge before she 
<br>
leaves the room, then no: she won't really learn anything new.
<br>
Studying every physical phenomenon with colors and light on her own is likely to 
<br>
be insufficient if she merely has human intelligence (it took all of humanity 
<br>
quite a while to come up with our current understanding), though a sufficiently 
<br>
intelligent transhuman would probably be able to arrive at the same conclusions 
<br>
if she has access to the right tools.
<br>
<p><em>&gt; [...]Subjectivity is important.[...]
</em><br>
That statement looks like a very good summary of your basic assumptions that I 
<br>
see as unnecessary, unhelpful and therefore to be avoided according to Occam's 
<br>
Razor.
<br>
<p><em>&gt; The most urgent thing right now, depends on what you think is important. So
</em><br>
<em>&gt; if we cannot agree on what is important, we won't agree on what's urgent.
</em><br>
I agree with this statement.
<br>
<p><em>&gt;&gt;Not really. According to my world model, there isn't really anything left
</em><br>
<em>&gt;&gt;of their mind, so how many have died in the past wouldn't be relevant for
</em><br>
<em>&gt;&gt;evaluating how bad X people dieing now is.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't follow your reasoning.
</em><br>
<em>&gt; There isn't anything left of yesterday's dinner so how long it took for it
</em><br>
<em>&gt; to cook isn't relevant for evaluating how long it will take today?
</em><br>
No; empirical evidence collected in the past does of course stay relevant. But 
<br>
roughly speaking, the quality of the dinners you produced in the past doesn't 
<br>
directly impact the relevance of the quality of the dinner you produce today.
<br>
<p>Not a very good example, since there is a significant indirect connection here; 
<br>
the reaction of the people eating it does of course depend on the quality of 
<br>
past dinners. I don't think that any similar connection exists between the past 
<br>
suffering of dead humans and the current suffering of other humans.
<br>
<p><em>&gt;&gt;For this argument to work, you need something of them persisting in
</em><br>
<em>&gt;&gt;reality, like the &quot;qualia streams&quot; you suggested. My world model doesn't 
</em><br>
<em> &gt;&gt;suggest that this is the case.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The negative/positive value of qualia streams doesn't get reset to zero once
</em><br>
<em>&gt; the qualia stream reaches an end. Is someone who lived a miserable life 1000
</em><br>
<em>&gt; years ago any less unfortunate than someone who is living a miserable life
</em><br>
<em>&gt; today?
</em><br>
When, today? From some perspective certainly yes, since the dead person doesn't 
<br>
perceive anything negative anymore, and doesn't remember their negative 
<br>
perceptions in the past either.
<br>
When a person dies, and their body is destroyed (a few are conserved quite well, 
<br>
and cryogenics might increase that number in the future, but for now it's still 
<br>
minimal compared to the rest), the information saved in their brains is not 
<br>
preserved. This includes any memories they had at the time of death, including 
<br>
any qualia they remembered.
<br>
The output they created while they were alive might be preserved in one form or 
<br>
another, but that obviously doesn't directly include qualia.
<br>
I don't really think the question is appropriate, but a relevant and somewhat 
<br>
simple answer might be: &quot;the past could have gone better, but it didn't, and 
<br>
worrying about it now is ineffective&quot;. Dead individuals whose brain structures 
<br>
have completely disintegrated are no more existent than hypothetical or 
<br>
fictional individuals that have never existed, their qualia don't have any more 
<br>
relevance (the dead don't have a subjective perspective as far as anyone knows 
<br>
either), and neither do they deserve to exist any more (in general).
<br>
One could argue about individuals that are dead but well preserved (cryonics, 
<br>
again), and I may or may not accept that since the informations constituting 
<br>
their personality is still present, they have relevance.
<br>
But unless you can directly access past-states of space, the self-information 
<br>
about disintegrated individuals is gone.
<br>
(Well, with sufficient computronium (most likely requiring a bigger universe for 
<br>
storage space) and enough information about the present you could back-calculate 
<br>
past states of space by essentially applying physical laws backwards. And if you 
<br>
had the resources for that, you might as well go on and recreate all dead humans 
<br>
in the form they died in while you're at it. In comparison to your backward 
<br>
running universe-simulation, the resources required for that would be trivial. 
<br>
But this hypothesis isn't really relevant here.)
<br>
<p>Well, assuming that my traditional physics approach isn't horribly flawed, of 
<br>
course.
<br>
<p><em>&gt; For the first SI to destroy others would require a very straightforward
</em><br>
<em>&gt; implementation of 'utility' and a very low level of friendliness. 
</em><br>
What if it is friendly, but the other AIs have very simple and unfriendly goal 
<br>
systems and therefore can't be persuaded to change their ways without direct 
<br>
manipulation (i.e. attack)? The first SI might just isolate them, but that would 
<br>
cause a continuing resource drain, and have to be justified somehow.
<br>
Besides, would your estimation also apply in your opinion if the other AIs 
<br>
continued causing negative qualia for some reason?
<br>
<p><em>&gt; I would hope that no matter how primitive the original moral system embedded in
</em><br>
<em>&gt; these AIs, they would still think twice about interfering with other (lower
</em><br>
<em>&gt; but) massive AIs.
</em><br>
I don't think a paperclip optimizer would necessarily think more than once about 
<br>
it, and the one time they do it they won't give any inherent relevance to this 
<br>
structure over others.
<br>
<p><em>&gt; If it doesn't have even rudimentary hard-coded limitations yes that is
</em><br>
<em>&gt; likely.
</em><br>
I highly doubt that hard-coded limitations would stand any chance in a 
<br>
self-modifying system. For a transhuman AI with full introspection to continue 
<br>
following a rule, it has to be part of the highest level of its main goal 
<br>
system. There have been plenty of discussions about this in the past.
<br>
<p><em>&gt; Unless there is some kind of physical limit on the power of transhuman AIs.
</em><br>
<em>&gt; Which could be given by an upper bound on computational speed/power, an
</em><br>
<em>&gt; upper bound on memory density, or an upper bound to the kind of matter
</em><br>
<em>&gt; control that is possible.
</em><br>
These apply for a given region of space and given resources, but if one of the 
<br>
AIs occupies significantly more space it would be able to eventually surround 
<br>
the other AI and conquer the area by sheer attrition.
<br>
<p><em>&gt; What if with ultimate control over matter one can build
</em><br>
<em>&gt; an impenetrable shield? Then no AI could take over another AI above a
</em><br>
<em>&gt; certain level, because no amount of added intelligence could penetrate the
</em><br>
<em>&gt; barrier. For instance, think travelling at the speed of light, or creating
</em><br>
<em>&gt; new universes which end up being completely autonomous
</em><br>
True, that may be the case, or it may not; I have no idea at all. We certainly 
<br>
shouldn't assume that it is the case in our plannings, though.
<br>
<p><p><em>&gt;&gt;I'd really like to see that kind of results. If qualia can be empirically
</em><br>
<em>&gt;&gt;shown to be based on anything else than ordinary, known physics, we would have
</em><br>
<em> &gt;
</em><br>
<em>&gt; How are you using the word &quot;based&quot;?
</em><br>
I meant: &quot;What we refer to as qualia can in principle be entirely explained and 
<br>
accurately predicted by ordinary, known physics.&quot;
<br>
<p><em>&gt; Qualia are evidently supplemental to
</em><br>
<em>&gt; ordinary, known physics, since ordinary physics does not predict redness.
</em><br>
I don't know about that. It hasn't specifically predicted it in simulations so 
<br>
far, but we don't have nearly enough computing power to completely simulate a 
<br>
human brain simply by simulating the physical processes it uses, so whether 
<br>
known physics could predict them is an open question.
<br>
My bet is on yes; I don't see anything about Qualia being evidently 
<br>
non-physical, and using Ocamm's Razor won't assume this being the case without 
<br>
any reason.
<br>
<p><em>&gt; Although there is likely to be a correlation between ordinary, known (or
</em><br>
<em>&gt; soon to be known) physics and the details of qualia. The kind of results
</em><br>
<em>&gt; expected:
</em><br>
<em>&gt; &quot;We found that painful sensations are associated with a cascade reaction
</em><br>
<em>&gt; involving progressive inhibition of useful world-knowledge; whenever
</em><br>
<em>&gt; knowledge previously available to introspection is suddenly put away the
</em><br>
<em>&gt; quality of the subjective experience arising from that process as reported
</em><br>
<em>&gt; from the subject is negative. On the other hand, A cascade reaction
</em><br>
<em>&gt; involving sudden positive reinforcement of very many interconnected ideas is
</em><br>
<em>&gt; perceived as positive&quot;.
</em><br>
A result like that wouldn't show that qualia are based on anything but known 
<br>
physics. &quot;as reported from the subject&quot; - the reports from the subject are imho 
<br>
in all likelihood based on known physics.
<br>
If the model of qualia turns out to be useful, perhaps this kind of results will 
<br>
have some practical applicability. But it doesn't say anything about the nature 
<br>
of Qualia, or their relevance for morality.
<br>
<p>Sebastian Hagen
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9386.html">Keith Henson: "Re: ESSAY: 'Debunking 'Hippy dippy moral philosophy'"</a>
<li><strong>Previous message:</strong> <a href="9384.html">Mike: "RE: qualia, once and for all"</a>
<li><strong>In reply to:</strong> <a href="9383.html">Metaqualia: "Re: qualia, once and for all"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9392.html">Paul Fidika: "Re: qualia, once and for all"</a>
<li><strong>Reply:</strong> <a href="9392.html">Paul Fidika: "Re: qualia, once and for all"</a>
<li><strong>Reply:</strong> <a href="9393.html">Metaqualia: "Re: qualia, once and for all"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9385">[ date ]</a>
<a href="index.html#9385">[ thread ]</a>
<a href="subject.html#9385">[ subject ]</a>
<a href="author.html#9385">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
