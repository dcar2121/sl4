<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Fundamentals - was RE: Visualizing muddled volitions</title>
<meta name="Author" content="Brent Thomas (bthomas@avatar-intl.com)">
<meta name="Subject" content="Fundamentals - was RE: Visualizing muddled volitions">
<meta name="Date" content="2004-06-16">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Fundamentals - was RE: Visualizing muddled volitions</h1>
<!-- received="Wed Jun 16 08:55:21 2004" -->
<!-- isoreceived="20040616145521" -->
<!-- sent="Wed, 16 Jun 2004 10:55:15 -0400" -->
<!-- isosent="20040616145515" -->
<!-- name="Brent Thomas" -->
<!-- email="bthomas@avatar-intl.com" -->
<!-- subject="Fundamentals - was RE: Visualizing muddled volitions" -->
<!-- id="C02025521F687E43B93A11680A71FAD4246955@sherwood.Avatar.local" -->
<!-- charset="us-ascii" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brent Thomas (<a href="mailto:bthomas@avatar-intl.com?Subject=Re:%20Fundamentals%20-%20was%20RE:%20Visualizing%20muddled%20volitions"><em>bthomas@avatar-intl.com</em></a>)<br>
<strong>Date:</strong> Wed Jun 16 2004 - 08:55:15 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9286.html">Metaqualia: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Previous message:</strong> <a href="9284.html">fudley: "Re: ESSAY: 'Debunking 'Hippy dippy moral philosophy'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9286.html">Metaqualia: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Reply:</strong> <a href="9286.html">Metaqualia: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Maybe reply:</strong> <a href="9288.html">Brent Thomas: "RE: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Reply:</strong> <a href="9290.html">Eliezer Yudkowsky: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Maybe reply:</strong> <a href="9293.html">Brent Thomas: "RE: Fundamentals - was RE: Visualizing muddled volitions"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9285">[ date ]</a>
<a href="index.html#9285">[ thread ]</a>
<a href="subject.html#9285">[ subject ]</a>
<a href="author.html#9285">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Again I'd like to express the hope that any F(AI) developers would
<br>
build into their systems (as a fundamental invariant?) the 'right of
<br>
withdrawal'
<br>
<p>This should not be part of a 'bill of rights' as it is so fundamental to
<br>
having an acceptable
<br>
process that it should be a basic condition. No matter what the
<br>
collective thinks is best,
<br>
even if it has (correctly!) extrapolated my wishes or the wishes of the
<br>
collective, it should
<br>
still not apply that solution to my (or any sentients) physical being
<br>
without my express approval.
<br>
<p>Change the environment, alter the systems, create the transcendent
<br>
utopia but do it with 'choice' and
<br>
as such do not modify my personality or physical being (and as part of
<br>
that be prepared to create 'enclaves' for
<br>
those who wish to remain unmodified) without the express consent of the
<br>
sentient to be modified.
<br>
<p>Do this and I think the vision of the coming singularity will be more
<br>
palatable for all humanity. (and besides I can't really object about
<br>
modifications if I was consulted now can I?)
<br>
<p>Do not tell me that 'oops we got it wrong...' as indicated here:
<br>
<p><em>&gt;&gt;The reason may be, &quot;That idiot Eliezer screwed up the extrapolation 
</em><br>
<em>&gt;&gt;dynamic.&quot;  If so, you got me, there's no defense against that.  I'll
</em><br>
try 
<br>
<em>&gt;&gt;not to do it.
</em><br>
<p>Instead (using the principal of no modification to sentients without
<br>
express permission) the system
<br>
can tell me &quot;Hey, you'd be much happier if you had green hair, we've
<br>
done some calculations and if at least
<br>
20% of the population had green hair then there would be a 15% reduction
<br>
in the general unhappiness quotient...
<br>
Can I make this modification to you or would you like a deeper
<br>
explanation of the intents and consequences?&quot;
<br>
<p>I think I'm mindful that the system is likely to evolve fast, (go foom!
<br>
(hopefully in a good way!)) and that
<br>
even if it is Friendly and has my best interests at heart I still may
<br>
not want to participate in all aspects of the system, even if its
<br>
calculations tell it that I would in fact in the future have appreciated
<br>
being modified.
<br>
I think I do foresee a hard takeoff scenario and as long as the
<br>
fundamentals are good then even when no person or group of people is
<br>
capable of understanding even a small percent of the operations or
<br>
actions of the system as long as they have and retain personal choice
<br>
over their own person (and possibly local environment) then things will
<br>
be fine. 
<br>
<p>(I don't particularly care that the system decided it needed to convert
<br>
90% of Arizona into a giant radio transmitter - just don't make me into
<br>
one of the support beams!) 
<br>
<p>Brent &lt;== *likely to have green hair if the system says it would help
<br>
the singularity, but glad to be consulted*
<br>
<p><p><p><p><p>-----Original Message-----
<br>
From: Eliezer Yudkowsky [mailto:<a href="mailto:sentience@pobox.com?Subject=Re:%20Fundamentals%20-%20was%20RE:%20Visualizing%20muddled%20volitions">sentience@pobox.com</a>] 
<br>
Sent: Tuesday, June 15, 2004 7:31 PM
<br>
To: <a href="mailto:sl4@sl4.org?Subject=Re:%20Fundamentals%20-%20was%20RE:%20Visualizing%20muddled%20volitions">sl4@sl4.org</a>
<br>
Subject: Visualizing muddled volitions
<br>
<p><p>There have been - not surprisingly, and it's a legitimate topic - many 
<br>
recent questions of the form, &quot;What if my volition isn't what I want?&quot;
<br>
<p>I would like to point out that, if your volition is not what you want, 
<br>
there is a *reason* for it - it is not something that happens because of
<br>
a 
<br>
random-number generator.
<br>
<p>The reason may be, &quot;That idiot Eliezer screwed up the extrapolation 
<br>
dynamic.&quot;  If so, you got me, there's no defense against that.  I'll try
<br>
<p>not to do it.
<br>
<p>The reason may also be, &quot;My short-range volition is muddled and I
<br>
possess a 
<br>
medium-range volition coherent with that of the rest of humankind.&quot;
<br>
<p>I'd like to take a moment to discourse on the importance of attaching 
<br>
concrete meanings to abstractions.  People get lost when they don't do 
<br>
this.  I've seen people try to manipulate math that they don't have a
<br>
good 
<br>
grasp for, use equations that they have memorized but not seen as
<br>
obvious, 
<br>
manipulate words piled atop words without a strong sense of what the
<br>
words 
<br>
mean.  The same caution holds true for manipulating thoughts about 
<br>
&quot;volition&quot; or &quot;collective volition&quot;.  I know what the words mean because
<br>
I 
<br>
invented them to describe specific things that I wanted to do for
<br>
specific 
<br>
reasons.  I did try to list some of the reasons in &quot;Collective
<br>
Volition&quot;, 
<br>
but I may have failed to convey a proper grounding.  In fact, it seems 
<br>
nearly certain that I have conveyed only a fraction of the grounding.  I
<br>
do 
<br>
not make my choices at random; if you can't see why I would possibly
<br>
want 
<br>
to do something, you probably mis-visualized the thing I want to do.
<br>
<p>So when I say:  'The reason may also be, &quot;My short-range volition is 
<br>
muddled and I possess a medium-range volition coherent with that of the 
<br>
rest of humankind.&quot;'
<br>
<p>I mean:  'The reason may also be, &quot;I am making a decision based on
<br>
really 
<br>
stupid and messed-up reasons, and if I knew more and thought longer I'd 
<br>
come to pretty much the same conclusion as everyone else who thinks
<br>
about 
<br>
the subject, and it wouldn't be the same as my current decision.&quot;'
<br>
<p>Now, remember, I'm not saying that our extrapolated volitions should
<br>
always 
<br>
override our current decisions.  I'm saying that my current decision is 
<br>
that the decision as to whether our extrapolated volitions should
<br>
override 
<br>
our current decisions should be made by our extrapolated volitions.
<br>
What 
<br>
if your current decision disagrees with the decision of our extrapolated
<br>
<p>collective volition about whether the decision should be made by your 
<br>
current decision or your extrapolated volition?  This means that:
<br>
<p>1)  Eliezer screwed up the dynamic.
<br>
2)  Your current decision doesn't have a good handle on reality; there
<br>
are 
<br>
enormous consequences you don't foresee, and if you knew the true 
<br>
consequences, you would repudiate your decision.
<br>
3)  A nicer person who was otherwise extremely similar to you would 
<br>
repudiate your decision.
<br>
4)  Everyone else's volition doesn't agree with your decision, and
<br>
there's 
<br>
no way for you to convince Eliezer to let you personally take over the 
<br>
world, and Eliezer isn't willing to personally take on the onus of
<br>
writing 
<br>
an individual volition dynamic because there's no way for a humane 
<br>
superintelligence to veto his decision in case it turns out to be wrong.
<br>
<p>There are all kinds of reasons why our volitions might contradict our 
<br>
decisions, and most of them involve either being stupid - unforeseen 
<br>
consequences, missing obvious solutions - or being not the people we
<br>
wished 
<br>
we were, i.e., the sort of reason Samantha is justly worried about being
<br>
<p>extrapolated just the way she is rather than a wiser version of herself,
<br>
<p>and that Robin doesn't want murderous thoughts to kill people.
<br>
<p>It is noteworthy that criticisms seem to be equally divided between
<br>
people who:
<br>
<p>A)  Think that humans are too awful for their volitions to be
<br>
extrapolated. 
<br>
(What am I supposed to extrapolate instead?)
<br>
<p>B)  Think that people's present-day decisions are just fine, and this
<br>
whole 
<br>
volition-extrapolating thing is unnecessary.  (Are you absolutely sure 
<br>
about that?  You would go ahead and do it even if you knew that with 
<br>
another few years to think about the subject, you would change your mind
<br>
<p>and be horrified at your previous decision?)
<br>
<p>Maybe I should let the two sides fight it out on their own, and then
<br>
take 
<br>
on the winner, if they haven't already struck a compromise that looks
<br>
just 
<br>
like &quot;Collective Volition&quot;.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
---
Incoming mail is certified Virus Free.
Checked by AVG anti-virus system (<a href="http://www.grisoft.com">http://www.grisoft.com</a>).
Version: 6.0.665 / Virus Database: 428 - Release Date: 4/21/2004
 
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9286.html">Metaqualia: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Previous message:</strong> <a href="9284.html">fudley: "Re: ESSAY: 'Debunking 'Hippy dippy moral philosophy'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9286.html">Metaqualia: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Reply:</strong> <a href="9286.html">Metaqualia: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Maybe reply:</strong> <a href="9288.html">Brent Thomas: "RE: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Reply:</strong> <a href="9290.html">Eliezer Yudkowsky: "Re: Fundamentals - was RE: Visualizing muddled volitions"</a>
<li><strong>Maybe reply:</strong> <a href="9293.html">Brent Thomas: "RE: Fundamentals - was RE: Visualizing muddled volitions"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9285">[ date ]</a>
<a href="index.html#9285">[ thread ]</a>
<a href="subject.html#9285">[ subject ]</a>
<a href="author.html#9285">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
