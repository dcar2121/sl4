<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: No it's not (was: The collective 'volition' project is abitrary and ideosyncratic)</title>
<meta name="Author" content="Eliezer Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="No it's not (was: The collective 'volition' project is abitrary and ideosyncratic)">
<meta name="Date" content="2004-06-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>No it's not (was: The collective 'volition' project is abitrary and ideosyncratic)</h1>
<!-- received="Tue Jun 15 22:15:30 2004" -->
<!-- isoreceived="20040616041530" -->
<!-- sent="Wed, 16 Jun 2004 00:15:32 -0400" -->
<!-- isosent="20040616041532" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="No it's not (was: The collective 'volition' project is abitrary and ideosyncratic)" -->
<!-- id="40CFC964.7040309@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="40D034C6.18925.8CF110@localhost" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20No%20it's%20not%20(was:%20The%20collective%20'volition'%20project%20is%20abitrary%20and%20ideosyncratic)"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Tue Jun 15 2004 - 22:15:32 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9277.html">Philip Sutton: "Don't worry about my tyres"</a>
<li><strong>Previous message:</strong> <a href="9275.html">Philip Sutton: "The collective 'volition' project is abitrary and ideosyncratic"</a>
<li><strong>In reply to:</strong> <a href="9275.html">Philip Sutton: "The collective 'volition' project is abitrary and ideosyncratic"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9278.html">Mike: "RE: No it's not (was: The collective 'volition' project is abitrary and ideosyncratic)"</a>
<li><strong>Reply:</strong> <a href="9278.html">Mike: "RE: No it's not (was: The collective 'volition' project is abitrary and ideosyncratic)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9276">[ date ]</a>
<a href="index.html#9276">[ thread ]</a>
<a href="subject.html#9276">[ subject ]</a>
<a href="author.html#9276">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Philip Sutton wrote:
<br>
<em>&gt; Hi Eliezer,
</em><br>
<em>&gt; 
</em><br>
<em>&gt; You are fully aware that if you create a coercive collective 'volition' 
</em><br>
<em>&gt; machine that you have to get it right first up or we're all screwed for 
</em><br>
<em>&gt; eternity.  I agree with you on this.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; But is it possible to get it right first time in practice or in theory?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I believe that it is not for many reasons. But there is one foundational 
</em><br>
<em>&gt; reason that, as far as I can see, cannot be got around.
</em><br>
<p>Mm hm.  So if I easily loop around it, you'll concede that you should never 
<br>
declare anything impossible until you've spent at least a month, or, heck, 
<br>
five minutes, trying to solve it?
<br>
<p><em>&gt; Your whole concept is based on the notion of extrapolating the 
</em><br>
<em>&gt; collective will of *all humans*.  But what if it's meaningless to frame the 
</em><br>
<em>&gt; issue in terms of a single human collectivity?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Humans certainly exist in collectives - family, organisation, city, nation, 
</em><br>
<em>&gt; etc. etc.  But these collectives are fluid.  People come and go from the 
</em><br>
<em>&gt; collective.  Over time the collectives that people organise themselves 
</em><br>
<em>&gt; into change - get bigger or get smaller, change membership.
</em><br>
<p>A fallacy of verbal thinking again.  The &quot;collective&quot; in &quot;collective 
<br>
volition&quot; doesn't refer to a specific human social grouping.  It refers to 
<br>
the fact that the extrapolation includes supra-individual dynamics such as 
<br>
people talking to one another.
<br>
<p><em>&gt; The collective 'human' is in fact not a real thing - it is a very useful 
</em><br>
<em>&gt; scientific abstraction that groups people together based on common 
</em><br>
<em>&gt; evolutionary history and the current fact that they can interbreed.  It is a 
</em><br>
<em>&gt; taxonomic concept not a physical thing.  In the past there several 
</em><br>
<em>&gt; species of humans - Homo Sapiens, Neandethal humans, Cro Magnon 
</em><br>
<em>&gt; etc.  If you were doing the job of creating a coercive collective 'volition' 
</em><br>
<em>&gt; machine when the others were around would you have included all of 
</em><br>
<em>&gt; these human species or just homo sapiens?
</em><br>
<p>I don't have to answer this because at present, I can get away with using 
<br>
just the six billion genetically human individuals for the *initial 
<br>
dynamic*.  The successor dynamic may or may not include chimpanzees, I 
<br>
don't know.
<br>
<p><em>&gt; And if you were doing the 
</em><br>
<em>&gt; job 1000 years into the future when humans have spread into the solar 
</em><br>
<em>&gt; system and perhaps the galaxy and they had morphed through 
</em><br>
<em>&gt; techological change into a vast variety of types - some up-loaded, 
</em><br>
<em>&gt; some physically manifest, some hybrid, some....(I don't know - fill in 
</em><br>
<em>&gt; your favourite amazing ways that we could be).  Are all these entities 
</em><br>
<em>&gt; humans??  Should they all be governed by the coercive collective 
</em><br>
<em>&gt; 'volition' machine?
</em><br>
<p>I'd hope not.  I view a collective volition as a temporary patch (or, as a 
<br>
matter of fact, a pointer to a temporary patch), not a long-term solution. 
<br>
&nbsp;&nbsp;Incidentally, the frantic alarmist terms are not helpful.
<br>
<p>Not to mention, you haven't explained what you mean by &quot;coercive&quot;.
<br>
<p>Does the initial dynamic contain the potential to write a secondary dynamic 
<br>
in which human infants grow up to be humans even if their directly 
<br>
extrapolated individual volitions would contain no reference to this which 
<br>
we regard as their destiny?  Yes.  Does the initial dynamic contain the 
<br>
potential to write a secondary dynamic in which heroin addicts would wake 
<br>
up one day with their addiction gone even if that wasn't in their initial 
<br>
volition?  Yes.  Does the initial dynamic contain the potential to write a 
<br>
secondary dynamic in which the entire human species is transported into an 
<br>
alternate dimension based on a hentai anime?  Only if that's a really good 
<br>
idea for some nonobvious reason (or, perhaps, the obvious reason), or if I 
<br>
screw up the initial dynamic.  Present possibilities for catching this 
<br>
include a Last Judge and some other things I'm thinking through.
<br>
<p>I'm sorry that you're alarmed over this, but someone or other was bound to 
<br>
be alarmed the moment &quot;Friendliness&quot; became specific enough and detailed 
<br>
enough to alarm people.  I do think you've misunderstood some things.  But 
<br>
if you want to persuade me, the rarest qualities I know of, the ones that 
<br>
would cause me to sit up and pay attention, are moral caution and concrete 
<br>
alternatives.  At the same time, mind you.  You have to propose a concrete 
<br>
alternative that is morally cautious - that doesn't force me to make 
<br>
irrevocable decisions for humankind with no opportunity for a humane 
<br>
superintelligent veto.
<br>
<p><em>&gt; And what about other AGIs?  And what if we find 
</em><br>
<em>&gt; sentient advanced life somewhere else in the universe? And what 
</em><br>
<em>&gt; about dolphins (if we gave then voice control over robots we might find 
</em><br>
<em>&gt; that they could fast evolve into advanced sentients [as we understand 
</em><br>
<em>&gt; it] too.)
</em><br>
<p>I don't have to answer these questions.  Though I'd certainly like to know 
<br>
some of the subproblems before I need to make certain choices.
<br>
<p><em>&gt; But you might say that I'm being fanciful and not dealing with the 
</em><br>
<em>&gt; present need.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; However, the very act of trying to create a coercive collective 'volition' 
</em><br>
<em>&gt; machine might cause the taxonimic fiction of humanity to choose to 
</em><br>
<em>&gt; break into two groups (that would then evolve down entirely different 
</em><br>
<em>&gt; paths):
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -   those willing to subject themselves to the coercive collective
</em><br>
<em>&gt;     'volition' machine 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -   and those that do not agree to subject themselves to the coercive
</em><br>
<em>&gt;     collective 'volition' machine 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Why does this matter?  Because the output from a coercive collective 
</em><br>
<em>&gt; 'volition' machine will vary (even if it can actually do what is claimed for 
</em><br>
<em>&gt; it in terms of objectively reading and extrapolating the collective 
</em><br>
<em>&gt; 'volition' of a certain group of humans) according to the specific sample 
</em><br>
<em>&gt; of humanity that it extrapolates.
</em><br>
<p>Possibly.  Though, I suspect, far less than many seem to believe; the only 
<br>
variance that seems to me likely are male and female poles in the 
<br>
collective volition.  Since those are the only subclasses of &quot;human&quot; that 
<br>
psychologically differ by entire complex adaptations.
<br>
<p>Again, I plan to target the initial dynamic on the six billion existing 
<br>
genetically human individuals.  This is an obvious solution and I can 
<br>
presently imagine absolutely no acceptable reason to modify it.
<br>
<p><em>&gt; And since the choice of which humans to extrapolate is entirely 
</em><br>
<em>&gt; arbitrary (being idiosyncratically chosen by one person, ie. you) the 
</em><br>
<em>&gt; output is entirely arbitrary too.
</em><br>
<p>Hah.  I suppose that saying &quot;everyone&quot; is an idiosyncratic personal 
<br>
decision, and yet somehow it just doesn't feel that way.
<br>
<p><em>&gt; Just to make it clear,  I personally don't want to be controlled by your 
</em><br>
<em>&gt; coercive collective 'volition' machine.
</em><br>
<p>Well, gee, neither do a whole lot of people.  *I* don't want to be 
<br>
controlled by a collective volition.  I suspect that virtually *no one* 
<br>
wants to be controlled by a collective volition.  And yet apparently &quot;chaos 
<br>
theory&quot;, or some such, prevents me from predicting that our collective 
<br>
volition will not be to be controlled by our collective volition.
<br>
<p>I also don't want to be turned into paperclips.  This requires a humanely 
<br>
directed SI of some kind in our solar system.  This SI is not going to be 
<br>
directed by a human-level intelligence.  It's too dangerous.  Not, Russian 
<br>
Roulette dangerous.  More like, Reverse Russian Roulette dangerous.
<br>
<p><em>&gt; If you insist on including all 
</em><br>
<em>&gt; 'humans' in the extrapolation and the regime of coercion then I hereby 
</em><br>
<em>&gt; declare that (using your example of changing the use of words) I no 
</em><br>
<em>&gt; longer wish to be identified as a 'human'.  I wish hereafter to be known 
</em><br>
<em>&gt; as a 'person'.  :)
</em><br>
<p>If you seriously don't want your volition included in the collective 
<br>
volition, at all, and it's the sort of decision you'd stick to after a few 
<br>
years thinking (which is really hard for me to imagine) then I suppose your 
<br>
volition would not be included in the collective volition.  Actually, 
<br>
that's an interesting question.  Whether it's likely to work that way, or 
<br>
guaranteed to work that way, depends on the order of evaluation.  I think 
<br>
it would *probably* end up being guaranteed to work that way.  Not sure, 
<br>
though.
<br>
<p>The SI that is the decision function that is the collective volition would 
<br>
still have the capability of deciding what to do with you.  That's the way 
<br>
the optimization process is written.  Don't confuse capability with 
<br>
probable intent.  There would have to be (I keep on saying this) a 
<br>
*reason*.  Otherwise we're back to, &quot;What if super-Gandhi goes around 
<br>
letting the air out of people's tires?&quot;
<br>
<p>Did you read &quot;Collective Volition&quot;, at all?  If people are commenting on 
<br>
this without having read it, *I'm* going to come round and let the air out 
<br>
of your car's tires.  This is discussed, extensively, in PAQ 4 and other 
<br>
sections, and you haven't addressed any of the reasons I gave for why I am 
<br>
*prohibited*, both technically and morally, from writing a Bill of Rights. 
<br>
&nbsp;&nbsp;You are asking me to do something every bit as morally dangerous as, say, 
<br>
starting a communist revolution.  It would help if you said something like, 
<br>
&quot;I realize this is incredibly, terrifyingly dangerous, like you extensively 
<br>
describe in PAQ 4, but I want you to write in a Right that says...&quot;
<br>
<p>Write in a Bill of 10 Rights, and there'll be at least 3 Wrongs.
<br>
<p><em>&gt; I and any other 'people' I band together with, I'm sure, will be very 
</em><br>
<em>&gt; happy to cooperate with you and your 'humans' on projects to prevent 
</em><br>
<em>&gt; the world being turned into grey goo or any other such nasties, but any 
</em><br>
<em>&gt; relations that I and other 'people' have with your 'humans' will be have 
</em><br>
<em>&gt; to be based on negotiation and collaboration and not on coercion.  
</em><br>
<em>&gt; Should you try to exercise coercion, I and the other 'people' will resist.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Can you see what I'm getting at?
</em><br>
<p>I'm not coercing anything.  I am refusing to rule out, on my own authority, 
<br>
the possibility of infants growing up into humans, which is, like it or 
<br>
not, a case of coercion.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9277.html">Philip Sutton: "Don't worry about my tyres"</a>
<li><strong>Previous message:</strong> <a href="9275.html">Philip Sutton: "The collective 'volition' project is abitrary and ideosyncratic"</a>
<li><strong>In reply to:</strong> <a href="9275.html">Philip Sutton: "The collective 'volition' project is abitrary and ideosyncratic"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9278.html">Mike: "RE: No it's not (was: The collective 'volition' project is abitrary and ideosyncratic)"</a>
<li><strong>Reply:</strong> <a href="9278.html">Mike: "RE: No it's not (was: The collective 'volition' project is abitrary and ideosyncratic)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9276">[ date ]</a>
<a href="index.html#9276">[ thread ]</a>
<a href="subject.html#9276">[ subject ]</a>
<a href="author.html#9276">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
