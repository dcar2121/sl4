<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: another objection</title>
<meta name="Author" content="Eliezer Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: another objection">
<meta name="Date" content="2004-06-03">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: another objection</h1>
<!-- received="Thu Jun  3 11:51:03 2004" -->
<!-- isoreceived="20040603175103" -->
<!-- sent="Thu, 03 Jun 2004 13:50:57 -0400" -->
<!-- isosent="20040603175057" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: another objection" -->
<!-- id="40BF6501.5060608@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="20040603170959.58958.qmail@programmar.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20another%20objection"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Thu Jun 03 2004 - 11:50:57 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9034.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<li><strong>Previous message:</strong> <a href="9032.html">Metaqualia: "Re: Sentiencee  [Was  FAI: Collective Volition]"</a>
<li><strong>In reply to:</strong> <a href="9030.html">Norm Wilson: "RE: another objection"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9037.html">Metaqualia: "Re: another objection"</a>
<li><strong>Reply:</strong> <a href="9037.html">Metaqualia: "Re: another objection"</a>
<li><strong>Reply:</strong> <a href="9040.html">Damien Broderick: "Re: another objection"</a>
<li><strong>Reply:</strong> <a href="9045.html">Thomas Buckner: "Re: another objection"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9033">[ date ]</a>
<a href="index.html#9033">[ thread ]</a>
<a href="subject.html#9033">[ subject ]</a>
<a href="author.html#9033">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Norm Wilson wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Because morality is an abstract concept that affects human behavior, but
</em><br>
<em>&gt; is not itself physically measurable by the FAI.  The FAI cannot (so far
</em><br>
<em>&gt; as we know) directly &quot;perceive&quot; morality, so it considers humans to be 
</em><br>
<em>&gt; the only available measuring devices and assumes that smarter humans who
</em><br>
<em>&gt; know more are better at measuring (or at least describing, or behaving 
</em><br>
<em>&gt; in accordance with) the concept of morality.  To remove humans from the 
</em><br>
<em>&gt; process would be analogous the throwing out the thermometer and 
</em><br>
<em>&gt; extrapolating the current temperature based on past results.  By 
</em><br>
<em>&gt; teaching us more, the FAI would effectively be turning us into better 
</em><br>
<em>&gt; &quot;morality thermometers&quot;.
</em><br>
<p>It would be more accurate to say that an FAI needs to look at humans to 
<br>
find the specification of how to compute morality.  It's like a sentient 
<br>
calculator that wonders &quot;What is the Multiplication?&quot; where the 
<br>
Multiplication turns out to consist of multiplying 6 x 7.  The Calculator 
<br>
is pretty sure that the answer is somewhere in the vicinity of 41 or 43, 
<br>
although different Calculators have been known to disagree on the subject. 
<br>
&nbsp;&nbsp;But certainly a superintelligence would know that the Multiplication was 
<br>
41, or 43, or whatever; not return preposterous answers such as 4 or 30,000.
<br>
<p>Unless the superintelligence happened to contain a question, &quot;What is the 
<br>
Multiplication?&quot;, that consisted of multiplying 2 x 2 or 300 x 100.
<br>
<p>If you presented this scenario to Calculators who did not quite understand 
<br>
how Multiplication worked, they would laugh at the idea that a 
<br>
superintelligence could get the answer so blatantly wrong - thinking that 4 
<br>
or 30,000 was the Multiplication!  The Calculators may not really 
<br>
understand how Multiplication works, or whether the answer is 41 or 43, but 
<br>
they know a superintelligence wouldn't be that stupid.  Even if a 
<br>
superintelligence started out with a Multiplication of 4 or 30,000, surely 
<br>
it would look over this Multiplication, realize how silly and inappropriate 
<br>
it was, and choose a better Multiplication like, oh, say, 45 or 39; it 
<br>
might seem a little alien, but not something grossly wrong like 4 or 
<br>
30,000.  Would not the superintelligence realize the meaninglessness of 4, 
<br>
that it cannot possibly result from multiplying 6, let alone 7?  Maybe the 
<br>
superintelligence would multiply 6 by 2/3, but that seems implausible.
<br>
<p>Note that all Calculators, if they knew more, thought faster, were more the 
<br>
people they wished they were, had grown up farther together, would 
<br>
uniformly agree that the Multiplication was exactly 42; and in this sense 
<br>
their Multiplication is as objective as mathematics.  The Calculators' 
<br>
mistake is to think that the superintelligence's Multiplication must 
<br>
necessarily ask the same implicit question.
<br>
<p>I now quote Damien Broderick and Adrian Tymes from a recent discussion on 
<br>
the Extropians list:
<br>
<p>Damien Broderick wrote:
<br>
<em> &gt;
</em><br>
<em> &gt; It's a *super-intelligence*, see, a constructed mind that
</em><br>
<em> &gt; makes the puny human *insignificant* by comparison--so what *else* is it
</em><br>
<em> &gt; going to do except get trapped immediately by a really dumb pun into
</em><br>
<em> &gt; turning the cosmos in smiley faces?
</em><br>
<p>Adrian Tymes wrote:
<br>
<em> &gt;
</em><br>
<em> &gt; [...]
</em><br>
<em> &gt; the capacity for SIs to overcome their optimization
</em><br>
<em> &gt; functions and decide on new ones - for example, the
</em><br>
<em> &gt; paperclip maximizer who would realize that paperclips
</em><br>
<em> &gt; only have meaning if there's something for them to
</em><br>
<em> &gt; clip, and other sentient units for the convenience of
</em><br>
<em> &gt; a clip to serve.  (Unless you propose that a SI would
</em><br>
<em> &gt; not strive to understand why it does what it does,
</em><br>
<em> &gt; which would seem to strongly interfere with any
</em><br>
<em> &gt; capability for self-improvement.)
</em><br>
<p>Funny how natural selection hasn't picked a different optimization 
<br>
criterion than reproductive fitness.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9034.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<li><strong>Previous message:</strong> <a href="9032.html">Metaqualia: "Re: Sentiencee  [Was  FAI: Collective Volition]"</a>
<li><strong>In reply to:</strong> <a href="9030.html">Norm Wilson: "RE: another objection"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9037.html">Metaqualia: "Re: another objection"</a>
<li><strong>Reply:</strong> <a href="9037.html">Metaqualia: "Re: another objection"</a>
<li><strong>Reply:</strong> <a href="9040.html">Damien Broderick: "Re: another objection"</a>
<li><strong>Reply:</strong> <a href="9045.html">Thomas Buckner: "Re: another objection"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9033">[ date ]</a>
<a href="index.html#9033">[ thread ]</a>
<a href="subject.html#9033">[ subject ]</a>
<a href="author.html#9033">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
