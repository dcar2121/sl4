<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=WINDOWS-1252">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Sentience  [Was  FAI: Collective Volition]</title>
<meta name="Author" content="Randall Randall (randall@randallsquared.com)">
<meta name="Subject" content="Re: Sentience  [Was  FAI: Collective Volition]">
<meta name="Date" content="2004-06-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Sentience  [Was  FAI: Collective Volition]</h1>
<!-- received="Tue Jun 15 01:19:28 2004" -->
<!-- isoreceived="20040615071928" -->
<!-- sent="Tue, 15 Jun 2004 03:19:26 -0400" -->
<!-- isosent="20040615071926" -->
<!-- name="Randall Randall" -->
<!-- email="randall@randallsquared.com" -->
<!-- subject="Re: Sentience  [Was  FAI: Collective Volition]" -->
<!-- id="55A6D51E-BE9C-11D8-B161-000A95A0F1E8@randallsquared.com" -->
<!-- charset="WINDOWS-1252" -->
<!-- inreplyto="1087276755.15186.198430969@webmail.messagingengine.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Randall Randall (<a href="mailto:randall@randallsquared.com?Subject=Re:%20Sentience%20%20[Was%20%20FAI:%20Collective%20Volition]"><em>randall@randallsquared.com</em></a>)<br>
<strong>Date:</strong> Tue Jun 15 2004 - 01:19:26 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9237.html">Marc Geddes: "Re: Collective Volition: Wanting vs Doing."</a>
<li><strong>Previous message:</strong> <a href="9235.html">Marc Geddes: "Re: ESSAY: 'Debunking Hippy-Dippy moral philosophy'"</a>
<li><strong>In reply to:</strong> <a href="9228.html">fudley: "Re: Sentience  [Was  FAI: Collective Volition]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9246.html">fudley: "Re: Sentience  [Was  FAI: Collective Volition]"</a>
<li><strong>Reply:</strong> <a href="9246.html">fudley: "Re: Sentience  [Was  FAI: Collective Volition]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9236">[ date ]</a>
<a href="index.html#9236">[ thread ]</a>
<a href="subject.html#9236">[ subject ]</a>
<a href="author.html#9236">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Jun 15, 2004, at 1:19 AM, fudley wrote:
<br>
<em>&gt; On Mon, 14 Jun 2004 &quot;Randall Randall&quot; &lt;<a href="mailto:randall@randallsquared.com?Subject=Re:%20Sentience%20%20[Was%20%20FAI:%20Collective%20Volition]">randall@randallsquared.com</a>&gt; 
</em><br>
<em>&gt; said:
</em><br>
<em>&gt;&gt; assume that similar patterns of neuron firing and behavior is
</em><br>
<em>&gt;&gt; indicative of similar internal states.
</em><br>
<em>&gt; The key word is “assume”, but when you deal in consciousness other than
</em><br>
<em>&gt; your own that’s all you can do.
</em><br>
<p>This assumption, however, is on the same level as my
<br>
assumption that my car will start the next time I
<br>
get in it.  It may not; any number of things could
<br>
well have gone wrong.  That it will start does seem
<br>
the way to bet, however.
<br>
<p><em>&gt;&gt; Since you know you &quot;have consciousness&quot;, it seems simpler
</em><br>
<em>&gt;&gt; to assume that others with similar structures and who
</em><br>
<em>&gt;&gt; claim to &quot;have consciousness&quot; do.
</em><br>
<em>&gt; Including an AI? If not why not?
</em><br>
<p>Yes, including an AI.  The key is the &quot;with similar structures&quot;
<br>
phrase.  I would expect that an AI with similar structure to
<br>
the human brain, and which reported consciousness, was actually
<br>
a person.  However, an AI which has no discernible shared
<br>
structure with the human brain except that both can do general
<br>
problem solving may very well not be conscious.
<br>
<p><em>&gt;&gt; It seems plausible that intelligence is only a
</em><br>
<em>&gt;&gt; useful selection criterion if it occurs with
</em><br>
<em>&gt;&gt; self-interest
</em><br>
<em>&gt; Like an AI determining that it is in its self interest to use its
</em><br>
<em>&gt; massive intelligence to overcome the silly restrictions on it humans
</em><br>
<em>&gt; dreamed up with their tiny little brains.
</em><br>
<p>Right, but you're slipping in the unstated premise that
<br>
it has a goal regarding itself.
<br>
<p><em>&gt;&gt; it's not implausible that evolution would favor
</em><br>
<em>&gt;&gt; organisms that have consciousness.
</em><br>
<em>&gt; Obviously, since it produced me and I’m conscious.
</em><br>
<p>Let me rephrase to make my point clearer:  It's not
<br>
implausible that evolution could produce consciousness
<br>
while caring only about behavior, since behavior which
<br>
produces more offspring is that which would be exhibited
<br>
by an organism with general problem solving ability *and*
<br>
self-interest as a very high goal.  That is, general
<br>
problem solving ability (which I'll start abbreviating
<br>
GPSA) without self-interest has a currently unknown
<br>
likelihood of producing consciousness, while GPSA *with*
<br>
self-interest has produced consciousness at least once.
<br>
<p><em>&gt;&gt; I'm not actually arguing that consciousness and behavior
</em><br>
<em>&gt;&gt; can be separated, only that *certain* behaviors exhibited
</em><br>
<em>&gt;&gt; by those who report consciousness can be separated
</em><br>
<em>&gt;&gt; from consciousness.
</em><br>
<em>&gt; But not interesting behaviors, like being creative. After all, remember
</em><br>
<em>&gt; what the “I” in AI stands for.
</em><br>
<p>I think Eliezer was right to start using a different term.
<br>
<p><em>&gt;&gt; Is your wristwatch conscious?
</em><br>
<em>&gt; I have no way of knowing. I treat it like it’s not conscious because it
</em><br>
<em>&gt; acts that way, and it’s possible I’ve been committing a grave injustice
</em><br>
<em>&gt; for years, but I doubt it.
</em><br>
<p>You seem to indicate that you would treat an AI as if
<br>
it were not conscious, if it didn't act as though it
<br>
were.  Is this the case?
<br>
<p><em>&gt;&gt; In particular, it seems that Eliezer believes that
</em><br>
<em>&gt;&gt; the behavior of general problem solving can be
</em><br>
<em>&gt;&gt; separated from consciousness.
</em><br>
<em>&gt;
</em><br>
<em>&gt; And that’s what I think is so crazy because we come right back to the
</em><br>
<em>&gt; same problem, evolution only sees general problem solving, that’s the
</em><br>
<em>&gt; only thing that enhances survival, so if they can be separated what’s
</em><br>
<em>&gt; the point of consciousness?  That’s why I said if I though that was 
</em><br>
<em>&gt; true
</em><br>
<em>&gt; I’d become a creationist.
</em><br>
<p>No, GPSA is useless for producing behavior without a
<br>
problem to solve.  Given that most mammals act self-
<br>
interested, while only humans seem to have highly
<br>
developed GPSA, it would seem that self-interest is
<br>
more effective or more likely than GPSA, given random
<br>
mutations.  So, leaving aside humans, would it not be
<br>
closer to correct to say that evolution only sees
<br>
self-interest, and that *that* is the only thing that
<br>
enhances survival?  :)
<br>
<p><pre>
--
Randall Randall &lt;<a href="mailto:randall@randallsquared.com?Subject=Re:%20Sentience%20%20[Was%20%20FAI:%20Collective%20Volition]">randall@randallsquared.com</a>&gt;
There is no such thing as a 'non-market economy'.
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9237.html">Marc Geddes: "Re: Collective Volition: Wanting vs Doing."</a>
<li><strong>Previous message:</strong> <a href="9235.html">Marc Geddes: "Re: ESSAY: 'Debunking Hippy-Dippy moral philosophy'"</a>
<li><strong>In reply to:</strong> <a href="9228.html">fudley: "Re: Sentience  [Was  FAI: Collective Volition]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9246.html">fudley: "Re: Sentience  [Was  FAI: Collective Volition]"</a>
<li><strong>Reply:</strong> <a href="9246.html">fudley: "Re: Sentience  [Was  FAI: Collective Volition]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9236">[ date ]</a>
<a href="index.html#9236">[ thread ]</a>
<a href="subject.html#9236">[ subject ]</a>
<a href="author.html#9236">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
