<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Scenario for early hard takeoff</title>
<meta name="Author" content="Matt Mahoney (matmahoney@yahoo.com)">
<meta name="Subject" content="Scenario for early hard takeoff">
<meta name="Date" content="2007-08-31">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Scenario for early hard takeoff</h1>
<!-- received="Fri Aug 31 11:05:10 2007" -->
<!-- isoreceived="20070831170510" -->
<!-- sent="Fri, 31 Aug 2007 10:03:01 -0700 (PDT)" -->
<!-- isosent="20070831170301" -->
<!-- name="Matt Mahoney" -->
<!-- email="matmahoney@yahoo.com" -->
<!-- subject="Scenario for early hard takeoff" -->
<!-- id="974303.99026.qm@web51908.mail.re2.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Matt Mahoney (<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20Scenario%20for%20early%20hard%20takeoff"><em>matmahoney@yahoo.com</em></a>)<br>
<strong>Date:</strong> Fri Aug 31 2007 - 11:03:01 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16736.html">Vladimir Nesov: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<li><strong>Previous message:</strong> <a href="16734.html">Norman Noman: "Re: ESSAY: Would a Strong AI reject the Simulation Argument?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16737.html">Mike Dougherty: "Re: Scenario for early hard takeoff"</a>
<li><strong>Reply:</strong> <a href="16737.html">Mike Dougherty: "Re: Scenario for early hard takeoff"</a>
<li><strong>Reply:</strong> <a href="16738.html">David Orban: "Re: Scenario for early hard takeoff"</a>
<li><strong>Maybe reply:</strong> <a href="../0709/16747.html">Toby Weston: "Re: Scenario for early hard takeoff"</a>
<li><strong>Reply:</strong> <a href="../0712/17396.html">Doug Sharp: "RE: Scenario for early hard takeoff"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16735">[ date ]</a>
<a href="index.html#16735">[ thread ]</a>
<a href="subject.html#16735">[ subject ]</a>
<a href="author.html#16735">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I would like to hear your opinions on the threat of early, hard takeoff
<br>
following an evolutionary approach to AGI.  As you know, there are many groups
<br>
working independently toward this goal and not everyone is designing for
<br>
friendliness.  In fact, many don't even consider it to be a problem.  They are
<br>
just trying to get their systems to work.
<br>
<p>A singularity is launched when computers have better than human level
<br>
intelligence, because if humans can create such machines, then those machines
<br>
can do likewise, and faster.  But how do know when a machine is smarter than
<br>
you?  My computer has an IQ of 10^12 in arithmetic and 0.001 in art
<br>
appreciation.
<br>
<p>I argue that the relevant measure of intelligence is the ability to
<br>
recursively improve itself.  We know that an agent cannot predict the output
<br>
of another agent of greater algorithmic complexity.  Therefore recursive self
<br>
improvement (RSI) necessarily requires an experimental approach.  The parent
<br>
does not know which mutations will result in a more successful child.
<br>
<p>I think you can see that AGI will likely take an evolutionary approach. 
<br>
Evolution favors intelligences that are the most successful at reproduction. 
<br>
There are two ways to accomplish this.
<br>
<p>1. Good heuristics, e.g. ability to guess which modifications are likely to be
<br>
beneficial.
<br>
<p>2. Access to resources, e.g. CPU cycles, memory, network bandwidth, which
<br>
limit the rate at which experiments can be performed (i.e. the population
<br>
size).  Brute force makes up for bad heuristics.
<br>
<p>Currently, humans have better heuristics than machines.  Random bit flips to a
<br>
program are very unlikely to yield improvements with respect to any meaningful
<br>
goal.  Software is on the chaotic side of Kauffman's threshold for critically
<br>
balanced systems.  Any small change in the code results in a large change in
<br>
behavior.  Software engineers have many techniques for reducing the
<br>
interdependency of programs to bring them closer to a Lyapunov exponent of 0:
<br>
local variables, functions, classes, packages, libraries, and standard
<br>
protocols.  In addition, software development, debugging, testing, and reverse
<br>
engineering require a lot of human level knowledge: understanding how users
<br>
and programmers think, familiarity with similar software, and the ability to
<br>
read vague and incomplete specifications in natural language and fill in the
<br>
blanks with reasonable assumptions.  A hacker reverse engineering a network
<br>
client can spot an icon image embedded in an executable and guess what happens
<br>
when a user clicks on it.  A machine does not have this advantage.
<br>
<p>The second problem is to acquire resources.  This could happen 3 ways.
<br>
<p>1. They could be bought, e.g. Google, Blue Gene/L.
<br>
2. They could be begged, e.g. GIMPS, SETI@Home.
<br>
3. They could be stolen, e.g. the 1988 Morris worm, Code Red, SQL Slammer.
<br>
<p>Worms are primitive organisms.  They reproduce rapidly, taking over a large
<br>
portion of the Internet in minutes or hours, but they can't usefully mutate. 
<br>
Once the environment adapts by closing the security holes they exploited, they
<br>
become extinct.
<br>
<p>A deeper reason is that the worms ultimately failed because they could only
<br>
acquire a small portion of the available resources.  The Internet is not just
<br>
a network of a billion computers.  It is a network of a billion computers and
<br>
a billion human brains.  But what will happen when most of the computing
<br>
resources shift to silicon?
<br>
<p>An intelligent worm that understands software is my nightmare.  Every day
<br>
Microsoft issues security patches.  So does just about every major software
<br>
developer.  I know that there are thousands of vulnerabilities on my computer
<br>
right now.  Usually it is not a problem because if nobody knows about them,
<br>
then nobody can exploit them, and once they are exploited, they are discovered
<br>
and the software is patched.  The window of vulnerability is small.
<br>
<p>But what happens when an AGI can analyze and reverse engineer software, then
<br>
launch an attack that exploits thousands of vulnerabilities at once?
<br>
<p>Here are just a few examples.
<br>
<p>Every few days when I turn off my computer, Windows installs an automatic
<br>
update.  What happens if:
<br>
1. windowsupdate.microsoft.com is hacked, and my PC downloads a trojan.
<br>
2. The DNS server of my ISP was hacked, and returned a bogus IP address for
<br>
windowsupdate.microsoft.com directing me to a lookalike site.
<br>
3. A router between my PC and the server was hacked, and inserts packets
<br>
containing trojan code.
<br>
4. My neighbor's PC was hacked, listens to traffic on the cable modem (which
<br>
is a broadcast medium) and injects packets at just the right time.
<br>
<p>Linux is not immune.  When I boot up Ubuntu I often get a notification that
<br>
updates are available and I happily type in my root password so it can install
<br>
a new kernel.  All sorts of programs now have automatic updates.
<br>
<p>I must stress that fixing these vulnerabilities does not solve the problem,
<br>
because there are thousands more, and an intelligent machine is going to find
<br>
them first.  It will also be far more clever.  Undoubtedly it has hacked into
<br>
Yahoo or a router somewhere and read my email, so it knows that I test data
<br>
compression programs on my PC.  I get an email with a return address from
<br>
someone I know that works in data compression development that a new version
<br>
is available.  My virus detector has never seen the program before.
<br>
<p>Just as the most successful parasites do not kill their hosts, successful
<br>
worms will remain hidden.  Your computer will seem to work normally.  But
<br>
really, what could you do?  You google for a test and download a patch, with
<br>
the worm watching your every move?  Wipe your disk and reinstall the OS from
<br>
CD, and then connect to an Internet where every computer is infected?  Or do
<br>
you just accept that you can't trust your computer, and just live with it?
<br>
<p><p>-- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20Scenario%20for%20early%20hard%20takeoff">matmahoney@yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16736.html">Vladimir Nesov: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<li><strong>Previous message:</strong> <a href="16734.html">Norman Noman: "Re: ESSAY: Would a Strong AI reject the Simulation Argument?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16737.html">Mike Dougherty: "Re: Scenario for early hard takeoff"</a>
<li><strong>Reply:</strong> <a href="16737.html">Mike Dougherty: "Re: Scenario for early hard takeoff"</a>
<li><strong>Reply:</strong> <a href="16738.html">David Orban: "Re: Scenario for early hard takeoff"</a>
<li><strong>Maybe reply:</strong> <a href="../0709/16747.html">Toby Weston: "Re: Scenario for early hard takeoff"</a>
<li><strong>Reply:</strong> <a href="../0712/17396.html">Doug Sharp: "RE: Scenario for early hard takeoff"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16735">[ date ]</a>
<a href="index.html#16735">[ thread ]</a>
<a href="subject.html#16735">[ subject ]</a>
<a href="author.html#16735">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
