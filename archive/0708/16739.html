<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: ESSAY: How to deter a rogue AI by using your first-mover advantage</title>
<meta name="Author" content="Stathis Papaioannou (stathisp@gmail.com)">
<meta name="Subject" content="Re: ESSAY: How to deter a rogue AI by using your first-mover advantage">
<meta name="Date" content="2007-08-31">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: ESSAY: How to deter a rogue AI by using your first-mover advantage</h1>
<!-- received="Fri Aug 31 21:56:17 2007" -->
<!-- isoreceived="20070901035617" -->
<!-- sent="Sat, 1 Sep 2007 13:54:18 +1000" -->
<!-- isosent="20070901035418" -->
<!-- name="Stathis Papaioannou" -->
<!-- email="stathisp@gmail.com" -->
<!-- subject="Re: ESSAY: How to deter a rogue AI by using your first-mover advantage" -->
<!-- id="f21c22e30708312054m3128c72alfa74f9ac098839c8@mail.gmail.com" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="13510504735.20070831212244@mail.ru" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Stathis Papaioannou (<a href="mailto:stathisp@gmail.com?Subject=Re:%20ESSAY:%20How%20to%20deter%20a%20rogue%20AI%20by%20using%20your%20first-mover%20advantage"><em>stathisp@gmail.com</em></a>)<br>
<strong>Date:</strong> Fri Aug 31 2007 - 21:54:18 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16740.html">Gwern Branwen: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<li><strong>Previous message:</strong> <a href="16738.html">David Orban: "Re: Scenario for early hard takeoff"</a>
<li><strong>In reply to:</strong> <a href="16736.html">Vladimir Nesov: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16657.html">Peter de Blanc: "Re: ESSAY: How to deter a rogue AI by using your first-mover	advantage"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16739">[ date ]</a>
<a href="index.html#16739">[ thread ]</a>
<a href="subject.html#16739">[ subject ]</a>
<a href="author.html#16739">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 01/09/2007, Vladimir Nesov &lt;<a href="mailto:robotact@mail.ru?Subject=Re:%20ESSAY:%20How%20to%20deter%20a%20rogue%20AI%20by%20using%20your%20first-mover%20advantage">robotact@mail.ru</a>&gt; wrote:
<br>
<em>&gt; Tuesday, August 28, 2007, Stathis Papaioannou wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt; SP&gt; By TM enumerator I take it you mean a program that enumerates all
</em><br>
<em>&gt; SP&gt; possible programs, like a universal dovetailer. In the sense I have
</em><br>
<em>&gt; SP&gt; described, then yes, all the other simulations are irrelevant.
</em><br>
<em>&gt; SP&gt; However, where there are multiple competing futures (as below) the
</em><br>
<em>&gt; SP&gt; weighting of each one matters. There are theories in which it is
</em><br>
<em>&gt; SP&gt; assumed that the universe is the set of all possible programs (which
</em><br>
<em>&gt; SP&gt; perhaps need only exist as Platonic objects), but I don't know if it
</em><br>
<em>&gt; SP&gt; has been successfully shown that this idea yields the known laws of
</em><br>
<em>&gt; SP&gt; physics.
</em><br>
<em>&gt;
</em><br>
<em>&gt; It yields all laws of physics, including ours, as long as they are
</em><br>
<em>&gt; computable. (It doesn't seem possible to ever prove as a result of
</em><br>
<em>&gt; observations that some laws of physics are not computable. Observations
</em><br>
<em>&gt; are finite. When a decision is drawn by experts, it's equivalent to
</em><br>
<em>&gt; experts' minds being is a particular configuration set, which is also
</em><br>
<em>&gt; a finite thing.)
</em><br>
<p>Of course: but if all computable universes are in fact computed, is
<br>
there a reason to think that you will continue to find yourself in the
<br>
orderly sort of universe you remember, rather than experiencing your
<br>
computer turning into a fire-breathing dragon in the next moment,
<br>
which is also a computable universe? This has been called by John
<br>
Leslie the &quot;failure of induction&quot; problem with ensemble theories. Here
<br>
is one paper addressing this problem, arguing that we should expect to
<br>
find ourselves in a universe with the least information content:
<br>
<p><a href="http://parallel.hpc.unsw.edu.au/rks/docs/occam/occam.html">http://parallel.hpc.unsw.edu.au/rks/docs/occam/occam.html</a>
<br>
<p><em>&gt; &gt;&gt; SP&gt; However, if there are two or more competing &quot;next moments&quot; then the
</em><br>
<em>&gt; &gt;&gt; SP&gt; number of simulations is relevant. If there are X simulations in which
</em><br>
<em>&gt; &gt;&gt; SP&gt; you are tortured and Y simulations in which you are not tortured in
</em><br>
<em>&gt; &gt;&gt; SP&gt; the next moment, then you have a X/(X+Y) chance of being tortured.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I think I found a better argument about this point. Certainly one
</em><br>
<em>&gt; tries to anticipate the future, but this behaviour is grounded in
</em><br>
<em>&gt; anticipation of _future experience_. And future experience itself
</em><br>
<em>&gt; does not depend on number of times it's simulated.
</em><br>
<em>&gt;
</em><br>
<em>&gt; When you use probability theory to make rational choices, you do it
</em><br>
<em>&gt; only because you anticipate that they will pay off in your future
</em><br>
<em>&gt; experience, in dominating bulk of possible futures. Still, you usually
</em><br>
<em>&gt; sacrifice those possible futures where fate plays against you.
</em><br>
<p>So what is your expectation of being tortured in the example above?
<br>
Wouldn't you want to decrease X relative to Y?
<br>
<p><em>&gt; That's not what I meant, but details don't really matter. This
</em><br>
<em>&gt; counting issue raises just another serious problem of simulations.
</em><br>
<em>&gt; What really counts as simulation of certain mathematical model of
</em><br>
<em>&gt; simulated universe? Any implementation arranges matter of host
</em><br>
<em>&gt; universe in certain patterns. Why some patterns are said to provide
</em><br>
<em>&gt; simulations and not others? Matter of host universe has no direct
</em><br>
<em>&gt; correspondence to 'matter' of simulated universe. To establish that
</em><br>
<em>&gt; implementation X (particular pattern of matter in host universe) is
</em><br>
<em>&gt; a simulation of universe model Y (mathematical description), one needs
</em><br>
<em>&gt; an interpretation procedure F that can take X as an input, convert it to
</em><br>
<em>&gt; the same mathemetical notation and compare to Y, F(X)=Y. Presence of this
</em><br>
<em>&gt; procedure (which nobody needs to actually build in order to simulation
</em><br>
<em>&gt; to be a genuine one) is somehow implied, if X is developed to
</em><br>
<em>&gt; implement Y. But how complex is F allowed to be? If it doesn't need to
</em><br>
<em>&gt; be implemented, can't it include whole simulation, so that X is nil
</em><br>
<em>&gt; and F(nil)=Y?
</em><br>
<em>&gt;
</em><br>
<em>&gt; As a simple example, say, state of simulated universe is a finite 2D binary
</em><br>
<em>&gt; image, of size AxB. When is it considered simulated? If a program
</em><br>
<em>&gt; stores this state in computer memory and performs computation that
</em><br>
<em>&gt; modifies it every simulated tick according to simulation's laws of physics, and
</em><br>
<em>&gt; outputs the image to a monitor screen, it seems to simulate that
</em><br>
<em>&gt; universe. But will it cease to simulate it if I turn monitor off?
</em><br>
<em>&gt; Will it simulate it twice if I install two monitors in parallel?
</em><br>
<em>&gt; It's only meaningful to say that implementation provides a way to
</em><br>
<em>&gt; access information about simulated universe.
</em><br>
<p>This is a famous problem in functionalist theories of mind, examined
<br>
by (to give a partial list) Hilary Putnam, John Searle, Greg Egan and
<br>
David Chalmers. For example see this paper:
<br>
<p><a href="http://consc.net/papers/rock.html">http://consc.net/papers/rock.html</a>
<br>
<p>My rationalization is that mind exists as an abstract Platonic object,
<br>
with computers and brains being concrete examples of mind in the way a
<br>
projectile moving under gravity is a concrete example of a parabola.
<br>
This reverses the usual supervenience relationship between the
<br>
physical and the mental. It's weird, but the alternative would seem to
<br>
be to drop functionalism and say that there is some fundamentally
<br>
non-computational process in the brain which generates consciousness.
<br>
<p><em>&gt; I'm mainly interested in this issue because I have doubts about
</em><br>
<em>&gt; uploads not being p-zombies. These handy-wavy theories of simulated
</em><br>
<em>&gt; experience are full of paradoxes. I agree that one can't in principle
</em><br>
<em>&gt; prove that given observed entity has conscience, but at least there
</em><br>
<em>&gt; should be a consistent theory of what conscience is. In this case, I
</em><br>
<em>&gt; take a universe containing a conscious observer as a consciousness
</em><br>
<em>&gt; vessel, so that genuine simulation corresponds to implementation of
</em><br>
<em>&gt; consciousness.
</em><br>
<p>Are you aware of this important paper showing that *if* brain physics
<br>
is computable *then* a computer emulation of the brain will reproduce
<br>
the brain's consciousness as well as its external behaviour:
<br>
<p><a href="http://consc.net/papers/qualia.html">http://consc.net/papers/qualia.html</a>
<br>
<p><p><p><p><pre>
-- 
Stathis Papaioannou
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16740.html">Gwern Branwen: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<li><strong>Previous message:</strong> <a href="16738.html">David Orban: "Re: Scenario for early hard takeoff"</a>
<li><strong>In reply to:</strong> <a href="16736.html">Vladimir Nesov: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16657.html">Peter de Blanc: "Re: ESSAY: How to deter a rogue AI by using your first-mover	advantage"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16739">[ date ]</a>
<a href="index.html#16739">[ thread ]</a>
<a href="subject.html#16739">[ subject ]</a>
<a href="author.html#16739">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
