<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: ESSAY: How to deter a rogue AI by using your first-mover advantage</title>
<meta name="Author" content="Norman Noman (overturnedchair@gmail.com)">
<meta name="Subject" content="Re: ESSAY: How to deter a rogue AI by using your first-mover advantage">
<meta name="Date" content="2007-08-27">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: ESSAY: How to deter a rogue AI by using your first-mover advantage</h1>
<!-- received="Mon Aug 27 07:37:02 2007" -->
<!-- isoreceived="20070827133702" -->
<!-- sent="Mon, 27 Aug 2007 08:35:07 -0500" -->
<!-- isosent="20070827133507" -->
<!-- name="Norman Noman" -->
<!-- email="overturnedchair@gmail.com" -->
<!-- subject="Re: ESSAY: How to deter a rogue AI by using your first-mover advantage" -->
<!-- id="46208cc60708270635x370587e7q80e763f8fe502735@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="f21c22e30708262138t6aedf876k8822793fe0ab1e25@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Norman Noman (<a href="mailto:overturnedchair@gmail.com?Subject=Re:%20ESSAY:%20How%20to%20deter%20a%20rogue%20AI%20by%20using%20your%20first-mover%20advantage"><em>overturnedchair@gmail.com</em></a>)<br>
<strong>Date:</strong> Mon Aug 27 2007 - 07:35:07 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16701.html">Jack Lloyd: "Re: Seeking a source"</a>
<li><strong>Previous message:</strong> <a href="16699.html">Алексей Турчин: "Re: Re: Re[2]: Simulation argument in the NY Times"</a>
<li><strong>In reply to:</strong> <a href="16695.html">Stathis Papaioannou: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16705.html">Stathis Papaioannou: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<li><strong>Reply:</strong> <a href="16705.html">Stathis Papaioannou: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16700">[ date ]</a>
<a href="index.html#16700">[ thread ]</a>
<a href="subject.html#16700">[ subject ]</a>
<a href="author.html#16700">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; The religious fanatics are probably wrong, but unfortunately they're
</em><br>
<em>&gt; not all stupid. It's not even unthinkable that they may come to be the
</em><br>
<em>&gt; dominant force post-singularity.
</em><br>
<p><p>If the post-singularity world contains people who are as stupid as they are
<br>
today and who have the power to simulate universes, then something has gone
<br>
disastrously wrong.
<br>
<p>I'd like to say that CEV would both make people smart enough to realize
<br>
religion is a load of hooey, and prevent people from threatening each other
<br>
with simulations, but frankly I don't know what CEV does, it seems to be
<br>
more of a mysterious treasure map than an actual target.
<br>
<p>The probability that some
<br>
<em>&gt; member of the movement will succeed at some point in the future of the
</em><br>
<em>&gt; universe will then determine the probability that you are now in the
</em><br>
<em>&gt; simulation.
</em><br>
<p><p><em>&gt; If the movement further stipulates that the simulation
</em><br>
<em>&gt; will be recursive - simulations within simulations - you could argue
</em><br>
<em>&gt; that you are almost certainly in one of these simulations.
</em><br>
<p><p>Except that, under the hypothesis where everybody and his brother is allowed
<br>
to simulate the universe, there would be billions of recursive simulations
<br>
and you might be in any one of them. The difficulty in calculating the
<br>
average effect is partially due to complexity, but also due to the basic
<br>
implausibility of this hypothetical situation.
<br>
<p>In contrast, rolf's plan is quite plausible, because it's something that
<br>
benefits everyone. Not just humanity and the Friendly AI, but the Rogue AI
<br>
too. If everyone cooperates, then whether mistakes are made or not, humanity
<br>
will be saved and C will be calculated.
<br>
<p>The simulation argument doesn't result in a zero motivation vector because
<br>
this is not a zero sum game.
<br>
<p><em>&gt; And the thing is, it's not going to work either way. If they reveal the
</em><br>
<em>&gt; &gt; plan, and say SMOKE OR DIE! it's only going to make everyone hate them
</em><br>
<em>&gt; even
</em><br>
<em>&gt; &gt; more. Actually, it's only going to make everyone laugh at them and think
</em><br>
<em>&gt; &gt; they're nuts, but assuming they were taken seriously for some reason...
</em><br>
<em>&gt;
</em><br>
<em>&gt; The religious people would convince the faithful that they were doing
</em><br>
<em>&gt; God's work, as explained above. But even if it's tobacco companies,
</em><br>
<em>&gt; the fact that it's obviously an evil threat doesn't make it any less
</em><br>
<em>&gt; likely to be true. And if it actually got to the point where
</em><br>
<em>&gt; legislation was passed to make this sort of thing illegal, that would
</em><br>
<em>&gt; be the ultimate proof that people were taking it seriously.
</em><br>
<p><p>Are you playing the devil's advocate or do you really think it's even
<br>
remotely likely that big tobacco would invest in a karmic simulation of the
<br>
universe in order to get people to smoke?
<br>
<p><em>&gt; If I am an RAI, the evidence that I may be in a simulation is as follows:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; &quot;The people who created me were trying to create a FAI. With more luck,
</em><br>
<em>&gt; they
</em><br>
<em>&gt; &gt; would have succeeded. The FAI they created would run karmic simulations
</em><br>
<em>&gt; of
</em><br>
<em>&gt; &gt; likely RAIs that could have been created instead.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Ergo, the probability I am one of them is XY/(1-X)Z, where X is the
</em><br>
<em>&gt; &gt; likelihood they'd create a friendly AI rather than a rouge one, Y is the
</em><br>
<em>&gt; &gt; likelihood a friendly AI would simulate me specifically, and Z is the
</em><br>
<em>&gt; &gt; likelihood I would be created as a result of real human error.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; These are difficult things to reason about. What about the possibility
</em><br>
<em>&gt; that you or the RAI might be in a recursive simulation?
</em><br>
<p><p>If everyone simulates each other, their influence is proportional to their
<br>
likelihood of existing in the first place. Since FAI is the target, it's
<br>
probably the most likely to exist.
<br>
<p>Everyone with enough influence to do so manipulates everyone else into
<br>
cooperating with them, and the resulting actions of all the AIs, even the
<br>
FAI, cohere to the extent of satisfying all the most likely goals to the
<br>
extent that they are mutually satisfiable, including probably a zillion
<br>
different definitions of friendliness, calculating C, and whatever else is
<br>
likely to crop up by mistake.
<br>
<p>I don't see how recursive simulations, if the primary simulator bothers to
<br>
actually run them at all, would make a difference. They would just be more
<br>
reasons to do the same things already being done.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16701.html">Jack Lloyd: "Re: Seeking a source"</a>
<li><strong>Previous message:</strong> <a href="16699.html">Алексей Турчин: "Re: Re: Re[2]: Simulation argument in the NY Times"</a>
<li><strong>In reply to:</strong> <a href="16695.html">Stathis Papaioannou: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16705.html">Stathis Papaioannou: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<li><strong>Reply:</strong> <a href="16705.html">Stathis Papaioannou: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16700">[ date ]</a>
<a href="index.html#16700">[ thread ]</a>
<a href="subject.html#16700">[ subject ]</a>
<a href="author.html#16700">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
