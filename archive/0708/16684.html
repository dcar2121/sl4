<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Simulation argument in the NY Times</title>
<meta name="Author" content="Benjamin Goertzel (ben@goertzel.org)">
<meta name="Subject" content="Re: Simulation argument in the NY Times">
<meta name="Date" content="2007-08-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Simulation argument in the NY Times</h1>
<!-- received="Sun Aug 26 10:40:26 2007" -->
<!-- isoreceived="20070826164026" -->
<!-- sent="Sun, 26 Aug 2007 12:38:24 -0400" -->
<!-- isosent="20070826163824" -->
<!-- name="Benjamin Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="Re: Simulation argument in the NY Times" -->
<!-- id="3cf171fe0708260938m203a306fx45475feeeb6a781a@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="858763.72869.qm@web51901.mail.re2.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Benjamin Goertzel (<a href="mailto:ben@goertzel.org?Subject=Re:%20Simulation%20argument%20in%20the%20NY%20Times"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sun Aug 26 2007 - 10:38:24 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16685.html">Giu1i0 Pri5c0: "Re: Singularity Fallacies: An essay by Extropia DaSilva"</a>
<li><strong>Previous message:</strong> <a href="16683.html">Gwern Branwen: "ESSAY: Would a Strong AI reject the Simulation Argument?"</a>
<li><strong>In reply to:</strong> <a href="16590.html">Matt Mahoney: "Re: Simulation argument in the NY Times"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16534.html">Rick Smith: "Re: Re: Simulation argument in the NY Times"</a>
<li><strong>Maybe reply:</strong> <a href="16534.html">Rick Smith: "Re: Re: Simulation argument in the NY Times"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16684">[ date ]</a>
<a href="index.html#16684">[ thread ]</a>
<a href="subject.html#16684">[ subject ]</a>
<a href="author.html#16684">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 8/21/07, Matt Mahoney &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20Simulation%20argument%20in%20the%20NY%20Times">matmahoney@yahoo.com</a>&gt; wrote:
<br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; --- Stathis Papaioannou &lt;<a href="mailto:stathisp@gmail.com?Subject=Re:%20Simulation%20argument%20in%20the%20NY%20Times">stathisp@gmail.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt; I'd be certain that an exact biological copy of me has the same
</em><br>
<em>&gt; &gt; consciousness. I'd be almost certain that a neuron by neuron computer
</em><br>
<em>&gt; &gt; emulation of my brain would have the same consciousness as me (David
</em><br>
<em>&gt; &gt; Chalmer's fading qualia argument). However, I couldn't be certain that
</em><br>
<em>&gt; &gt; some machine designed to copy my behaviour well enough to pass for me
</em><br>
<em>&gt; &gt; would have the same consciousness as me; it might be a p-zombie, or
</em><br>
<em>&gt; &gt; more likely it might just have a completely different consciousness. I
</em><br>
<em>&gt; &gt; would agree to be destructively uploaded in the first two cases, but
</em><br>
<em>&gt; &gt; not the last.
</em><br>
<em>&gt;
</em><br>
<em>&gt; So you argue that consciousness (defined as that which distinguishes you
</em><br>
<em>&gt; from
</em><br>
<em>&gt; a p-zombie) depends on the implementation of your brain?  Does it matter
</em><br>
<em>&gt; if
</em><br>
<em>&gt; the neural emulation is optimized by simulating average firing rate as
</em><br>
<em>&gt; opposed
</em><br>
<em>&gt; to individual pulses.  How about simulating the collective behavior of
</em><br>
<em>&gt; similarly weighted neurons with single neurons?  How about simulating the
</em><br>
<em>&gt; visual cortex with a scanning window filter?  What aspect of the
</em><br>
<em>&gt; computation
</em><br>
<em>&gt; results in consciousness?
</em><br>
<em>&gt;
</em><br>
<p><p>I tend to agree with Stathis... I would comfortably &quot;destructively upload&quot;
<br>
to create
<br>
a physical or digital copy of my brain that would act like me and claim to
<br>
be me ... but
<br>
would be much less comfortable to do so in order to create a behavioral copy
<br>
of me.
<br>
<p>I don't think there is anything mystical or weird about this attitude.
<br>
<p>Let me explain my perspective, in terms of my pattern-theoretic approach to
<br>
self and consciousness.
<br>
<p>I strongly suspect that my individual consciousness and individual self are
<br>
tied to the patterns emergent within my brain, and the patterns emergent
<br>
between my brain-states and their coupled environment-states.
<br>
<p>Furthermore, I strongly suspect that the patterns at hand are mostly
<br>
relatively high-level patterns, rather than low-level patterns such as
<br>
bindings between particular protein molecules, etc. ...
<br>
<p>So, in my view, a physical or digital copy of my brain that maintained
<br>
behavioral faithfulness to my original brain, is very very likely to persist
<br>
the patterns that constitute my individual consciousness/self.
<br>
<p>On the other hand, I **just don't know** whether a behavioral imitation of
<br>
myself would necessarily manifest these patterns-that-constitute-me.
<br>
<p>Resolving the latter point seems to require exploring some deep and nearly
<br>
entirely uncharted mathematical territory.
<br>
<p>The question is: If you fix (hold constant) the **external** behavioral
<br>
patterns of a simulated human organism (where the constancy is relative to
<br>
the perceptual/cognitive acuity of human observers, I presume), and also
<br>
bound the amount of computational resources available for the simulated
<br>
organism (to some fairly low level, similar to the computational resources
<br>
needed for a direct brain simulation), then how much can the correspondent
<br>
**internal** and **emergent-internal/external** patterns vary?
<br>
<p>The resolution of this question would tell you whether having
<br>
behavioral-patterns-like-Ben actually implies having
<br>
individual-self-and-consciousness-defining-patterns-like-Ben.
<br>
<p>But until this math problem is resolved, we really don't know whether our
<br>
behavioral imitators are necessarily &quot;us&quot; in terms of the patterns that
<br>
characterize our individual consciousnesses/selves.
<br>
<p>Anyway, that's my analysis of the situation according to the theory of self
<br>
and consciousness I outlined in &quot;The Hidden Pattern&quot; (BrownWalker, 2006),
<br>
and it happens to agree with Stathis's intuition.
<br>
<p>-- Ben Goertzel
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16685.html">Giu1i0 Pri5c0: "Re: Singularity Fallacies: An essay by Extropia DaSilva"</a>
<li><strong>Previous message:</strong> <a href="16683.html">Gwern Branwen: "ESSAY: Would a Strong AI reject the Simulation Argument?"</a>
<li><strong>In reply to:</strong> <a href="16590.html">Matt Mahoney: "Re: Simulation argument in the NY Times"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16534.html">Rick Smith: "Re: Re: Simulation argument in the NY Times"</a>
<li><strong>Maybe reply:</strong> <a href="16534.html">Rick Smith: "Re: Re: Simulation argument in the NY Times"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16684">[ date ]</a>
<a href="index.html#16684">[ thread ]</a>
<a href="subject.html#16684">[ subject ]</a>
<a href="author.html#16684">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
