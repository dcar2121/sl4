<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Re[2]: A very surreal day</title>
<meta name="Author" content="Tom McCabe (rocketjet314@yahoo.com)">
<meta name="Subject" content="Re: Re[2]: A very surreal day">
<meta name="Date" content="2007-08-01">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Re[2]: A very surreal day</h1>
<!-- received="Wed Aug  1 17:48:46 2007" -->
<!-- isoreceived="20070801234846" -->
<!-- sent="Wed, 1 Aug 2007 16:45:26 -0700 (PDT)" -->
<!-- isosent="20070801234526" -->
<!-- name="Tom McCabe" -->
<!-- email="rocketjet314@yahoo.com" -->
<!-- subject="Re: Re[2]: A very surreal day" -->
<!-- id="356514.62372.qm@web51309.mail.re2.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="bf3acbfc0708011446g131e4336yb8808e4e84225758@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Tom McCabe (<a href="mailto:rocketjet314@yahoo.com?Subject=Re:%20Re[2]:%20A%20very%20surreal%20day"><em>rocketjet314@yahoo.com</em></a>)<br>
<strong>Date:</strong> Wed Aug 01 2007 - 17:45:26 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16439.html">Eliezer S. Yudkowsky: "Re: A very surreal day"</a>
<li><strong>Previous message:</strong> <a href="16437.html">Eliezer S. Yudkowsky: "Re: A very surreal day"</a>
<li><strong>In reply to:</strong> <a href="16436.html">Dagon Gmail: "Re: Re[2]: A very surreal day"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16439.html">Eliezer S. Yudkowsky: "Re: A very surreal day"</a>
<li><strong>Reply:</strong> <a href="16439.html">Eliezer S. Yudkowsky: "Re: A very surreal day"</a>
<li><strong>Reply:</strong> <a href="16440.html">Randall Randall: "Re: Re[2]: A very surreal day"</a>
<li><strong>Reply:</strong> <a href="16445.html">Dagon Gmail: "Re: Re[2]: A very surreal day"</a>
<li><strong>Reply:</strong> <a href="16447.html">Byrne Hobart: "Re: Re[2]: A very surreal day"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16438">[ date ]</a>
<a href="index.html#16438">[ thread ]</a>
<a href="subject.html#16438">[ subject ]</a>
<a href="author.html#16438">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- Dagon Gmail &lt;<a href="mailto:dagonweb@gmail.com?Subject=Re:%20Re[2]:%20A%20very%20surreal%20day">dagonweb@gmail.com</a>&gt; wrote:
<br>
<p><em>&gt; Humanity has shown itself so stubborn, so conceited,
</em><br>
<em>&gt; and so elitist,
</em><br>
<em>&gt; as a quality of almost genetic proportions, the
</em><br>
<em>&gt; implications are
</em><br>
<em>&gt; staggering. We scarcely discarded out pleistocene
</em><br>
<em>&gt; hunter-gatherer
</em><br>
<em>&gt; genes and are already adapting faster than credible
</em><br>
<em>&gt; to modern
</em><br>
<em>&gt; mass-murder realpolitik. The genes allowing such
</em><br>
<em>&gt; creative leaps have
</em><br>
<em>&gt; been migrating steadily upwards in the gene-pool,
</em><br>
<em>&gt; hand in hand with
</em><br>
<em>&gt; all the damn money.
</em><br>
<p>Evolution has not had any significant influence on the
<br>
human species for the past thousand years due to time
<br>
limits and the recent lack of selection pressure; see
<br>
<a href="http://dspace.dial.pipex.com/jcollie/sle/">http://dspace.dial.pipex.com/jcollie/sle/</a>.
<br>
<p><em>&gt; My intuition screams at its loudest, for what it's
</em><br>
<em>&gt; worth, the following points.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 1 - a small but expanding number of extreme thinkers
</em><br>
<em>&gt; in all  3
</em><br>
<em>&gt; remaining superpowers are contemplating the
</em><br>
<em>&gt; emergence of completely
</em><br>
<em>&gt; unorthodox technologies. Russia has shown it thinks
</em><br>
<em>&gt; most outside the
</em><br>
<em>&gt; box, with it's references to He3 mining and nanotech
</em><br>
<em>&gt; superpower
</em><br>
<em>&gt; ambitions and notions of orbital energy stations,
</em><br>
<em>&gt; but the US, with
</em><br>
<em>&gt; it's nutty thinktanks and New American Century
</em><br>
<em>&gt; rhetoric has done its
</em><br>
<em>&gt; fair share of wild eyed speculation too.
</em><br>
<p>No government-sanctioned or political think tank
<br>
speculation that I've seen mentions AGI. PNAC's agenda
<br>
is a political system, not a new piece of technology.
<br>
<p><em>&gt; 2- right now I sincerely believe that no sincere
</em><br>
<em>&gt; powerplayer anywhere
</em><br>
<em>&gt; inhabiting some consolidated power ivory tower,
</em><br>
<em>&gt; anywhere in the US or
</em><br>
<em>&gt; Russia or China will endanger his credibility and
</em><br>
<em>&gt; career by actually
</em><br>
<em>&gt; suggesting that pseudo-raelians like Kurzweil
</em><br>
<p>See <a href="http://www.sl4.org/archive/0511/12949.html">http://www.sl4.org/archive/0511/12949.html</a> on why
<br>
transhumanism is not a cult.
<br>
<p><em>&gt; could
</em><br>
<em>&gt; actually have a
</em><br>
<em>&gt; point - publicly that is. However I am positive the
</em><br>
<em>&gt; filthy cthonian
</em><br>
<em>&gt; tentacles of the sith are even present here, on this
</em><br>
<em>&gt; forum, in the
</em><br>
<em>&gt; shape of junior think tank interns and other
</em><br>
<em>&gt; assorted imps and minions
</em><br>
<em>&gt; of darkness.
</em><br>
<p>If I were offered a position as a junior intern in a
<br>
(sane, non-political) think tank, I would take it.
<br>
Does this make me an imp or minion of darkness?
<br>
<p><em>&gt; 3- I am certain superpowers are terrified and
</em><br>
<em>&gt; extremely defensive
</em><br>
<em>&gt; about emerging technologies
</em><br>
<p>Er... like what? Biowarfare and ICBMs are both
<br>
well-established technologies, and so far as I know,
<br>
we don't even have a well-organized plan in place to
<br>
deal with those. If the US were terrified of AGI, they
<br>
would not have granted SIAI 501(c)3 status.
<br>
<p><em>&gt; and have been building
</em><br>
<em>&gt; reserves of all
</em><br>
<em>&gt; kinds to weather... unknowns... accidents. From
</em><br>
<em>&gt; hidden swiss bank
</em><br>
<em>&gt; accounts overflowing with pentagon money, to
</em><br>
<em>&gt; consolidated oil fields
</em><br>
<em>&gt; and salt mines with unprecedented barrel reserves, I
</em><br>
<em>&gt; am sure and I
</em><br>
<em>&gt; have seen clues the superpowers are cautious.
</em><br>
<p>Political cautiousness has little to do with AGI; if
<br>
we did actually develop AGI, none of this stuff would
<br>
help anyway.
<br>
<p><em>&gt; Take
</em><br>
<em>&gt; for instance the
</em><br>
<em>&gt; paranoid race to develop and keep secret the
</em><br>
<em>&gt; spinoffs of the
</em><br>
<em>&gt; Metalstorm technology. Metalstorm has already shaken
</em><br>
<em>&gt; several strategic
</em><br>
<em>&gt; ballances, and it's still as simple as staplers.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; What if some lunatic comes up with cold fusion? What
</em><br>
<em>&gt; if some lunatic
</em><br>
<em>&gt; comes up antigravity - the brass ponders with a
</em><br>
<em>&gt; furrowed and sweaty
</em><br>
<em>&gt; brow. And that's only linear predictable stuff.
</em><br>
<p>Cold fusion and antigravity are both physically
<br>
impossible according to currently accepted theory;
<br>
they are predictable in the sense that you can very
<br>
confidently predict neither will ever happen.
<br>
Antigravity requires negative energy density, which
<br>
allows for solutions to the Einstein equations (see
<br>
<a href="http://en.wikipedia.org/wiki/Alcubierre_drive">http://en.wikipedia.org/wiki/Alcubierre_drive</a>) which
<br>
permit FTL travel, causality violation, and a whole
<br>
bunch of other weird stuff. Cold fusion is impossible
<br>
because you cannot invoke the strong force (which is
<br>
responsible for fusion) over ranges long enough to
<br>
allow nuclei to be far apart (and thus in low energy
<br>
states).
<br>
<p><em>&gt; The
</em><br>
<em>&gt; same brass,
</em><br>
<em>&gt; generally elder men with straightforward linear
</em><br>
<em>&gt; intellects, will have
</em><br>
<em>&gt; trouble seeing the implications of smart, evolving,
</em><br>
<em>&gt; modular robotics
</em><br>
<em>&gt; with a portable fabber parts womb. The average
</em><br>
<em>&gt; transhumanist gets
</em><br>
<em>&gt; sparkles in his eyes when I say that, but 99% of
</em><br>
<em>&gt; pentagon staff will
</em><br>
<em>&gt; look puzzled and try wiki-ing what I just said.
</em><br>
<p>99%? Why not 99.999%? Out of six billion people in the
<br>
world, there are only a few thousand transhumanists,
<br>
and I don't see any reason why transhumanists would be
<br>
attracted to jobs as Pentagon staff officers.
<br>
<p><em>&gt; And
</em><br>
<em>&gt; then most of them
</em><br>
<em>&gt; will think I am one of those star trek losers.
</em><br>
<em>&gt; Convince them however
</em><br>
<em>&gt; that such a think could be a reality before 2025 and
</em><br>
<em>&gt; they'll get
</em><br>
<em>&gt; seriously nervous.
</em><br>
<p>We have a very hard time convincing technophiles of
<br>
the benefits of the Singularity (see
<br>
<a href="http://www.wholeearthmag.com/ArticleBin/111-6.pdf">http://www.wholeearthmag.com/ArticleBin/111-6.pdf</a> by
<br>
Cory Doctorow). How are we going to convince
<br>
government bureaucrats, even if we wanted two?
<br>
<p><em>&gt; 4- My intuition screams, again,
</em><br>
<p>Your intuition fails when placed into unusual
<br>
situations. See
<br>
<a href="http://en.wikipedia.org/wiki/List_of_cognitive_biases">http://en.wikipedia.org/wiki/List_of_cognitive_biases</a>
<br>
for a long list of all the situations in which your
<br>
intuition has been experimentally demonstrated to
<br>
fail.
<br>
<p><em>&gt; for what it is
</em><br>
<em>&gt; worth, that elements in
</em><br>
<em>&gt; all major superpowers have by now come to the
</em><br>
<em>&gt; conclusion that &quot;it
</em><br>
<em>&gt; wouldn't be so bad if a major percentage of people
</em><br>
<em>&gt; succumbed to a
</em><br>
<em>&gt; variant of passive demise&quot;, somewhere in the next
</em><br>
<em>&gt; 20-50 years. I am
</em><br>
<em>&gt; sure there will be (a) reports detailing how such a
</em><br>
<em>&gt; terrible thing
</em><br>
<em>&gt; could happen have existed for decades, (b) studies
</em><br>
<em>&gt; on how to
</em><br>
<em>&gt; repopulate earth with people less inclined to be
</em><br>
<em>&gt; homosexual or liberal
</em><br>
<em>&gt; or or potheads or french have been completed, (c)
</em><br>
<em>&gt; there may even be
</em><br>
<em>&gt; studies to ehm coalesce such a horrible idea into
</em><br>
<em>&gt; ehm a post-reality
</em><br>
<em>&gt; state. Purely speculative of course, but only
</em><br>
<em>&gt; because the heathen
</em><br>
<em>&gt; communist slopes have a similar program.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; As such one thing is clear: I do not trust people in
</em><br>
<em>&gt; power. Am I
</em><br>
<em>&gt; wrong, after having witnessed several genocides as
</em><br>
<em>&gt; casual topics in
</em><br>
<em>&gt; the news, just after TV-reportings of Paris Hilton
</em><br>
<em>&gt; and blipverts? I am
</em><br>
<em>&gt; positive people are scum, as a rule, and once given
</em><br>
<em>&gt; a good reason and
</em><br>
<em>&gt; a few billion dollars, everyone, even that nice lady
</em><br>
<em>&gt; across the
</em><br>
<em>&gt; street, can sink to the moral equivalent of Dick
</em><br>
<em>&gt; Cheney.
</em><br>
<p>See
<br>
<a href="http://en.wikipedia.org/wiki/Fundamental_attribution_error">http://en.wikipedia.org/wiki/Fundamental_attribution_error</a>
<br>
on why stressful situations can turn people evil.
<br>
However, people who believe they have a great deal of
<br>
moral responsibility (due to the tremendous impact of
<br>
the Singularity on the world) are likely to be much
<br>
more resistant to this then your random nice lady,
<br>
especially if they've studied the subject before.
<br>
<p><em>&gt; Which leads me to one conclusion worth mentioning
</em><br>
<em>&gt; here: people like
</em><br>
<em>&gt; Elizer, people who make the same bold techno-erotic
</em><br>
<em>&gt; statements and
</em><br>
<em>&gt; have the same eloquent charisma and credibility,
</em><br>
<em>&gt; will, at some satured
</em><br>
<em>&gt; point in the future, receive a visit from men in
</em><br>
<em>&gt; dark suits, bearing
</em><br>
<em>&gt; suitcases with money, blonde pleasure-slaves and
</em><br>
<em>&gt; other assorted
</em><br>
<em>&gt; temptations to lure them to all kinds of black ops
</em><br>
<em>&gt; think tanks.
</em><br>
<p>Eliezer's ethical system sounds like it would be
<br>
fairly easy to manipulate; just place him in a
<br>
situation where the optimal path to a Friendly
<br>
Singularity coincides with whatever you want him to
<br>
do. Governments may be bad at technology development,
<br>
but they're fairly good at psychological manipulation.
<br>
<p><em>&gt; They will try and buy the elizers of transhumanism
</em><br>
<em>&gt; when they start
</em><br>
<em>&gt; believing. Once the first stray transhumanist with
</em><br>
<em>&gt; fiery eyes  gets
</em><br>
<em>&gt; his first visit by a present day mefistopheles, we
</em><br>
<em>&gt; can make a sure
</em><br>
<em>&gt; assumption skynet's evil twin-brother is less than 5
</em><br>
<em>&gt; years away.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Dare I say &quot;muhuahua?&quot;
</em><br>
<em>&gt; 
</em><br>
<p>We've had a hard time finding people who are skilled
<br>
enough to work on an AGI project, and we've been
<br>
trying for the past seven years; how the heck is the
<br>
government going to do it?
<br>
<p>&nbsp;- Tom
<br>
<p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;____________________________________________________________________________________
<br>
Shape Yahoo! in your own image.  Join our Network Research Panel today!   <a href="http://surveylink.yahoo.com/gmrs/yahoo_panel_invite.asp?a=7">http://surveylink.yahoo.com/gmrs/yahoo_panel_invite.asp?a=7</a> 
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16439.html">Eliezer S. Yudkowsky: "Re: A very surreal day"</a>
<li><strong>Previous message:</strong> <a href="16437.html">Eliezer S. Yudkowsky: "Re: A very surreal day"</a>
<li><strong>In reply to:</strong> <a href="16436.html">Dagon Gmail: "Re: Re[2]: A very surreal day"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16439.html">Eliezer S. Yudkowsky: "Re: A very surreal day"</a>
<li><strong>Reply:</strong> <a href="16439.html">Eliezer S. Yudkowsky: "Re: A very surreal day"</a>
<li><strong>Reply:</strong> <a href="16440.html">Randall Randall: "Re: Re[2]: A very surreal day"</a>
<li><strong>Reply:</strong> <a href="16445.html">Dagon Gmail: "Re: Re[2]: A very surreal day"</a>
<li><strong>Reply:</strong> <a href="16447.html">Byrne Hobart: "Re: Re[2]: A very surreal day"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16438">[ date ]</a>
<a href="index.html#16438">[ thread ]</a>
<a href="subject.html#16438">[ subject ]</a>
<a href="author.html#16438">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
