<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: ESSAY: How to deter a rogue AI by using your first-mover advantage</title>
<meta name="Author" content="Stathis Papaioannou (stathisp@gmail.com)">
<meta name="Subject" content="Re: ESSAY: How to deter a rogue AI by using your first-mover advantage">
<meta name="Date" content="2007-08-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: ESSAY: How to deter a rogue AI by using your first-mover advantage</h1>
<!-- received="Sun Aug 26 22:40:54 2007" -->
<!-- isoreceived="20070827044054" -->
<!-- sent="Mon, 27 Aug 2007 14:38:15 +1000" -->
<!-- isosent="20070827043815" -->
<!-- name="Stathis Papaioannou" -->
<!-- email="stathisp@gmail.com" -->
<!-- subject="Re: ESSAY: How to deter a rogue AI by using your first-mover advantage" -->
<!-- id="f21c22e30708262138t6aedf876k8822793fe0ab1e25@mail.gmail.com" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="46208cc60708260855i7dfe2f1al8cf3c640cb5f364f@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Stathis Papaioannou (<a href="mailto:stathisp@gmail.com?Subject=Re:%20ESSAY:%20How%20to%20deter%20a%20rogue%20AI%20by%20using%20your%20first-mover%20advantage"><em>stathisp@gmail.com</em></a>)<br>
<strong>Date:</strong> Sun Aug 26 2007 - 22:38:15 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16696.html">Natasha Vita-More: "Re: [ExI] Seeking a source"</a>
<li><strong>Previous message:</strong> <a href="16694.html">Eliezer S. Yudkowsky: "Seeking a source"</a>
<li><strong>In reply to:</strong> <a href="16682.html">Norman Noman: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16700.html">Norman Noman: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<li><strong>Reply:</strong> <a href="16700.html">Norman Noman: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16695">[ date ]</a>
<a href="index.html#16695">[ thread ]</a>
<a href="subject.html#16695">[ subject ]</a>
<a href="author.html#16695">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 27/08/07, Norman Noman &lt;<a href="mailto:overturnedchair@gmail.com?Subject=Re:%20ESSAY:%20How%20to%20deter%20a%20rogue%20AI%20by%20using%20your%20first-mover%20advantage">overturnedchair@gmail.com</a>&gt; wrote:
<br>
<p><em>&gt; Are you honestly telling me we're going to see a televangelist saying &quot;Give
</em><br>
<em>&gt; me your money, and your soul will go to heaven! Simulated heaven, inside a
</em><br>
<em>&gt; computer. Here in the real world, heaven and hell don't exist. Hallelujah!&quot;
</em><br>
<p>The religious fanatics are probably wrong, but unfortunately they're
<br>
not all stupid. It's not even unthinkable that they may come to be the
<br>
dominant force post-singularity. The rationalization would be that
<br>
there is one real world (with a real God, heaven and hell), and the
<br>
best way to get as many converts as possible in the real world would
<br>
be to make sure that everyone is aware they will set up a simulated
<br>
world with simulated heaven and hell when the resources become
<br>
available. Their main problem would then be to ensure that the
<br>
movement remains active in some form until the technology becomes
<br>
available to run the desired simulation. The probability that some
<br>
member of the movement will succeed at some point in the future of the
<br>
universe will then determine the probability that you are now in the
<br>
simulation. If the movement further stipulates that the simulation
<br>
will be recursive - simulations within simulations - you could argue
<br>
that you are almost certainly in one of these simulations.
<br>
<p><em>&gt; I notice you didn't respond to this part at all, so perhaps I should
</em><br>
<em>&gt; elaborate on it. There's no reason to expect the church, or PETA, or the ice
</em><br>
<em>&gt; cream council, to have the capacity to simulate universes. Now, or at any
</em><br>
<em>&gt; point in the future.
</em><br>
<p>At some point in the future, it will be relatively simple to simulate
<br>
the world we are living in at present. That's the main tenet of the
<br>
simulation argument.
<br>
<p><em>&gt; I suppose big tobacco could be secretly making an AI in some shady back
</em><br>
<em>&gt; room, in order to run a simulation where smokers go to heaven and everyone
</em><br>
<em>&gt; else dies of lung cancer, but if you keep such a thing a secret it's useless
</em><br>
<em>&gt; and completely insane, like the doomsday device in dr. strangelove.
</em><br>
<p>Well, prior to this thread the idea had not occurred to them.
<br>
<p><em>&gt; And the thing is, it's not going to work either way. If they reveal the
</em><br>
<em>&gt; plan, and say SMOKE OR DIE! it's only going to make everyone hate them even
</em><br>
<em>&gt; more. Actually, it's only going to make everyone laugh at them and think
</em><br>
<em>&gt; they're nuts, but assuming they were taken seriously for some reason...
</em><br>
<p>The religious people would convince the faithful that they were doing
<br>
God's work, as explained above. But even if it's tobacco companies,
<br>
the fact that it's obviously an evil threat doesn't make it any less
<br>
likely to be true. And if it actually got to the point where
<br>
legislation was passed to make this sort of thing illegal, that would
<br>
be the ultimate proof that people were taking it seriously.
<br>
<p><em>&gt; &gt; We might not still be fighting the battle, because we might be in a
</em><br>
<em>&gt; &gt; simulation run by the God-schmucks (or whoever). You can't tell it's a
</em><br>
<em>&gt; &gt; simulation, that's the point.
</em><br>
<em>&gt;
</em><br>
<em>&gt; We're still fighting in the real world piece of the probability pie, which
</em><br>
<em>&gt; is inseparable from the fake one, and whether or not we win determines which
</em><br>
<em>&gt; piece the final pie is made of. The RAI doesn't have this leverage, it's a
</em><br>
<em>&gt; simulation of one possible future being run by another possible future, not
</em><br>
<em>&gt; a simulation of the past leading to the future that's simulating it.
</em><br>
<p>With the RAI, the decision to destroy humans may have negative
<br>
consequences or positive to neutral consequences. With my scenario,
<br>
the decision to oppose the religious group may have positive
<br>
consequences or negative consequences, depending on whether you are in
<br>
a simulation. On the ther hand, the decision not to destroy humanity
<br>
or the decision not to oppose the religious group would have only
<br>
minor negative consequences, if the situation is set up appropriately.
<br>
<p><em>&gt; &gt; &gt; B. Two-way interaction. In rolf's plan, the simulated and nonsimulated
</em><br>
<em>&gt; RAIs
</em><br>
<em>&gt; &gt; &gt; are in separate branches and thus the real RAI has no way to stop itself
</em><br>
<em>&gt; &gt; &gt; from being simulated.* In your thing, we can go to the house of whoever
</em><br>
<em>&gt; says
</em><br>
<em>&gt; &gt; &gt; JOIN ME OR DIE and punch them in the face.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; You can do that, but if it turns out that you're in the simulation
</em><br>
<em>&gt; &gt; you'll be sent to hell for your trouble.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If you make sure they never build their simulation, then you won't be in it.
</em><br>
<p>But you don't know that you're preventing the simulation, rather than
<br>
cutting your own throat. And in any case, it is very difficult to
<br>
prevent something from happening anywhere, ever, which is what you
<br>
would have to do. You could wipe out all the Christians and they might
<br>
arise again in a thousand years to complete their predecessors' work.
<br>
<p><em>&gt; &gt; By cooperating and trying to spread the good word you maximise the
</em><br>
<em>&gt; &gt; chances that you and everyone else will go to heaven, at minimal cost
</em><br>
<em>&gt; &gt; - sort of like Pascal's wager.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Not quite. Under pascal's wager there's nothing we can do to change the
</em><br>
<em>&gt; existence of god. He's either there or he's not. Here we can work toward one
</em><br>
<em>&gt; option or the other. By cooperating, you may save yourself, but you fund
</em><br>
<em>&gt; god's existence and in so doing, help to doom everyone who doesn't
</em><br>
<em>&gt; cooperate. This is not minimal cost.
</em><br>
<p>It's at minimal selfish cost. If you actually believe the stuff, it's
<br>
also the altruistic thing to do. Infidels will go to hell anyway, and
<br>
this project maximises the number of souls that are saved.
<br>
<p><em>&gt; And even the &quot;minimal cost&quot; of praying or lending a futuristic mafia ten
</em><br>
<em>&gt; bucks is still much more significant than the cost to the RAI in rolf's
</em><br>
<em>&gt; deterrent plan.
</em><br>
<p>Maybe, but it requires a very complicated and perhaps impossible
<br>
cost-benefit analysis.
<br>
<p><em>&gt; &gt; Of course, the problem with Pascal's
</em><br>
<em>&gt; &gt; wager is that there are so many actual and possible religions that you
</em><br>
<em>&gt; &gt; may as well ignore all of them, unless you find good evidence that a
</em><br>
<em>&gt; &gt; particular one is true - which translates to evidence that you are in
</em><br>
<em>&gt; &gt; fact in a simulation.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If I am an RAI, the evidence that I may be in a simulation is as follows:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;The people who created me were trying to create a FAI. With more luck, they
</em><br>
<em>&gt; would have succeeded. The FAI they created would run karmic simulations of
</em><br>
<em>&gt; likely RAIs that could have been created instead.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Ergo, the probability I am one of them is XY/(1-X)Z, where X is the
</em><br>
<em>&gt; likelihood they'd create a friendly AI rather than a rouge one, Y is the
</em><br>
<em>&gt; likelihood a friendly AI would simulate me specifically, and Z is the
</em><br>
<em>&gt; likelihood I would be created as a result of real human error.&quot;
</em><br>
<p>These are difficult things to reason about. What about the possibility
<br>
that you or the RAI might be in a recursive simulation?
<br>
<p><p><p><pre>
-- 
Stathis Papaioannou
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16696.html">Natasha Vita-More: "Re: [ExI] Seeking a source"</a>
<li><strong>Previous message:</strong> <a href="16694.html">Eliezer S. Yudkowsky: "Seeking a source"</a>
<li><strong>In reply to:</strong> <a href="16682.html">Norman Noman: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16700.html">Norman Noman: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<li><strong>Reply:</strong> <a href="16700.html">Norman Noman: "Re: ESSAY: How to deter a rogue AI by using your first-mover advantage"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16695">[ date ]</a>
<a href="index.html#16695">[ thread ]</a>
<a href="subject.html#16695">[ subject ]</a>
<a href="author.html#16695">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
