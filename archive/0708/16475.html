<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Continuing Evolution in Humans (was: A very surreal day)</title>
<meta name="Author" content="Byrne Hobart (sometimesfunnyalwaysright@gmail.com)">
<meta name="Subject" content="Re: Continuing Evolution in Humans (was: A very surreal day)">
<meta name="Date" content="2007-08-14">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Continuing Evolution in Humans (was: A very surreal day)</h1>
<!-- received="Tue Aug 14 08:37:23 2007" -->
<!-- isoreceived="20070814143723" -->
<!-- sent="Tue, 14 Aug 2007 10:34:15 -0400" -->
<!-- isosent="20070814143415" -->
<!-- name="Byrne Hobart" -->
<!-- email="sometimesfunnyalwaysright@gmail.com" -->
<!-- subject="Re: Continuing Evolution in Humans (was: A very surreal day)" -->
<!-- id="fb04b6260708140734nce8cd23t2759cecc5cc81562@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="5eb0f8fd0708140640q14fab822l3f958a03ae9db131@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Byrne Hobart (<a href="mailto:sometimesfunnyalwaysright@gmail.com?Subject=Re:%20Continuing%20Evolution%20in%20Humans%20(was:%20A%20very%20surreal%20day)"><em>sometimesfunnyalwaysright@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Aug 14 2007 - 08:34:15 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16476.html">Daniel: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>Previous message:</strong> <a href="16474.html">Byrne Hobart: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>In reply to:</strong> <a href="16473.html">Diego Navarro: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16477.html">Daniel: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>Reply:</strong> <a href="16477.html">Daniel: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>Reply:</strong> <a href="16483.html">Diego Navarro: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16475">[ date ]</a>
<a href="index.html#16475">[ thread ]</a>
<a href="subject.html#16475">[ subject ]</a>
<a href="author.html#16475">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; The general principle behind that affirmation also implies that
</em><br>
<em>&gt; someone's aptitude for doing fast linear algebra and Fourier
</em><br>
<em>&gt; transforms in their heads (basically autistic savants (I'm not bashing
</em><br>
<em>&gt; autistics, there's a chance I'm one)) correlates to their aptitude for
</em><br>
<em>&gt; scientific (numerical) programming. Do you really want to uphold a
</em><br>
<em>&gt; theory that implies that?
</em><br>
<p><p>All else being equal, of course it does! If nothing else, it means they
<br>
spend more time thinking about hard problems because they spend less time
<br>
looking for their calculator. But in a more serious sense, 1) if there isn't
<br>
a direct correlation, being able to solve certain problems easily will
<br>
affect which problems you consider solvable -- and, again all else being
<br>
equal, the people who make the most progress are the ones who think we can
<br>
make the most progress. 2) there is a correlation, because the variable IQ
<br>
measures is predictive across numerous fields (
<br>
<a href="http://www.gnxp.com/blog/2007/03/g-precis.php">http://www.gnxp.com/blog/2007/03/g-precis.php</a> ).
<br>
<p><p>Oh well. I think I'm killing a fly with a cannonball by now. But
<br>
<em>&gt; really, the discussion on /what/ will differentiate humans in their
</em><br>
<em>&gt; ability to relate to post-singularity Powers or whatever (I'm not keen
</em><br>
<em>&gt; at sci-fi words; the singularity /is/ an event horizon) can't be based
</em><br>
<em>&gt; on their current similarity to what the Powers would work like. I'd
</em><br>
<em>&gt; venture it's the opposite -- what matters is how COMPLEMENTARY to the
</em><br>
<em>&gt; Powers a person is.
</em><br>
<p><p>I'm not sure. When Northern Europe emerged from the Dark Ages, literacy was
<br>
an increasingly valuable skill because it allowed people to interface with
<br>
wealthy and knowledgeable elites. A skill complementary to that of effete,
<br>
wealthy scientist/statesmen like Newton would be the ability to bash in
<br>
skulls using blunt objects, but the demand for skull-bashers was not, as far
<br>
as I know, rising during the Renaissance.
<br>
<p>AIs thrive in an environment that values intelligence. AIs will also be
<br>
powerful enough to change their environment. When we reach an equilibrium, I
<br>
think it'll devalue many human traits (interpersonal skills, for example,
<br>
won't mean much if most emotional responses are an avoidable cost).
<br>
<p>This all, of course, is based on the rather unpleasant scenario of an
<br>
<em>&gt; &quot;unfriendly&quot; singulatiy where we're all reduced to serving a godlike
</em><br>
<em>&gt; Power's needs.
</em><br>
<p><p>We'll always be constrained by somehow -- I'd probably give up a large
<br>
fraction of my political and economic liberty in exchange for faster thought
<br>
and statistical immortality, and that's probably the deal we're going to
<br>
get. The AI's pitch will be, roughly, &quot;I can allocate resources more
<br>
effectively than you, and I'm constantly getting better. But given guidance
<br>
from me, you're worth more than it costs to keep you around. So I'll keep
<br>
you around, as long as you do what I say -- and you'll live a longer,
<br>
happier life for it.&quot; The AI isn't a politician or a cult leader; it's not
<br>
making zero-sum allocations like everyone else who makes that kind of
<br>
promise.
<br>
<p><p>In a rather tangential sidenote, isn't the current research in the
<br>
<em>&gt; mood mechanisms of the human brain transhumanist at some level? I know
</em><br>
<em>&gt; I feel augmented by the psychotropic medication I've been taking, the
</em><br>
<em>&gt; way (though not in the same magnitude) I venture I'd feel if I had
</em><br>
<em>&gt; coprocessor chips implanted.
</em><br>
<p><p>The first step on the road to the Singularity: the invention of beer.
<br>
<p>And this is a good point: between coffee and pot, we've all gotten a lot
<br>
better at using chemicals to regulate our mood so we're productive when we
<br>
have to be and happy when we want to be. Unfortunately, I don't think
<br>
there's a huge amount of progress possible through psychotropics. If we get
<br>
to the point where mood is always aligned with need, how much more
<br>
productive will we be? It probably varies from one field to another, but
<br>
there are limits (and that's ignoring the long-term effect of these
<br>
chemicals; jury's still out, except where it's in and the verdict is bad).
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16476.html">Daniel: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>Previous message:</strong> <a href="16474.html">Byrne Hobart: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>In reply to:</strong> <a href="16473.html">Diego Navarro: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16477.html">Daniel: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>Reply:</strong> <a href="16477.html">Daniel: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<li><strong>Reply:</strong> <a href="16483.html">Diego Navarro: "Re: Continuing Evolution in Humans (was: A very surreal day)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16475">[ date ]</a>
<a href="index.html#16475">[ thread ]</a>
<a href="subject.html#16475">[ subject ]</a>
<a href="author.html#16475">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
