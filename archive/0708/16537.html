<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Simulation argument in the NY Times</title>
<meta name="Author" content="Norman Noman (overturnedchair@gmail.com)">
<meta name="Subject" content="Re: Simulation argument in the NY Times">
<meta name="Date" content="2007-08-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Simulation argument in the NY Times</h1>
<!-- received="Fri Aug 17 04:08:47 2007" -->
<!-- isoreceived="20070817100847" -->
<!-- sent="Fri, 17 Aug 2007 05:05:46 -0500" -->
<!-- isosent="20070817100546" -->
<!-- name="Norman Noman" -->
<!-- email="overturnedchair@gmail.com" -->
<!-- subject="Re: Simulation argument in the NY Times" -->
<!-- id="46208cc60708170305n69e08877p7cb142b0815b8737@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="46C56D92.4020301@141.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Norman Noman (<a href="mailto:overturnedchair@gmail.com?Subject=Re:%20Simulation%20argument%20in%20the%20NY%20Times"><em>overturnedchair@gmail.com</em></a>)<br>
<strong>Date:</strong> Fri Aug 17 2007 - 04:05:46 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16538.html">Daniel Burfoot: "robotics and AI"</a>
<li><strong>Previous message:</strong> <a href="16536.html">Vladimir Nesov: "Re: Simulation argument in the NY Times"</a>
<li><strong>In reply to:</strong> <a href="16535.html">Peter Butler: "Re: Simulation argument in the NY Times"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16540.html">Peter Butler: "Re: Simulation argument in the NY Times"</a>
<li><strong>Reply:</strong> <a href="16540.html">Peter Butler: "Re: Simulation argument in the NY Times"</a>
<li><strong>Reply:</strong> <a href="16542.html">Matt Mahoney: "Re: Simulation argument in the NY Times"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16537">[ date ]</a>
<a href="index.html#16537">[ thread ]</a>
<a href="subject.html#16537">[ subject ]</a>
<a href="author.html#16537">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; &gt; &gt; Can you explain why it is &quot;more likely&quot; for a simulation to have been
</em><br>
<em>&gt; &gt; &gt; created by intelligent beings?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Strictly speaking, to &quot;simulate&quot; entails REPRESENTING certain key
</em><br>
<em>&gt; &gt; characteristics or behaviours of a selected system. Representation is
</em><br>
<em>&gt; &gt; an intentional act, and only intelligent entities have intentions.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Thank you for clearing up my confusion, you are quite right that the act
</em><br>
<em>&gt; of simulating something implies some sort of purpose; therefore if we
</em><br>
<em>&gt; assume simulation then we should by definition assume intentionality. I
</em><br>
<em>&gt; was thinking less of a &quot;simulation&quot; and more of &quot;a universe that exists
</em><br>
<em>&gt; as a system of patterns contained within a larger system&quot;.
</em><br>
<em>&gt;
</em><br>
<p>Actually... considering your original question with the more liberal
<br>
definition of simulation, perhaps it is not so unlikely as I claimed, that
<br>
say a turing machine enumeration might appear spontaneously.
<br>
<p>I don't think it would happen in our universe, the self-replicating molecule
<br>
that began life on earth was probably much less complex than a turing
<br>
machine, and the uncertainty of our universe would doom a turing machine to
<br>
error and thus destruction long before it got around to simulating chicken
<br>
soup.
<br>
<p>But in a more fragile and deterministic universe, say, conway's game of
<br>
life, things might be different... we know how to make a turing machine in
<br>
conway's game of life, and we definitely don't know how to make real,
<br>
reproducing, evolving life.
<br>
<p>However, a replicator may exist which is robust enough to win against the
<br>
random chaos. If so, then it will fill the plane, taking the chaos with it,
<br>
and in the infinite chaos, only even more robust replicators (if they exist)
<br>
will survive. The only chance for turing machines at this point is if:
<br>
A. there is an upper limit on how robust a replicator can be, and
<br>
B. the most robust possible replicator contains a turing machine.
<br>
<p>This strikes me as implausible.
<br>
On the other hand, the chance for evolution, leading eventually to
<br>
intelligence, seems to depend only on A being false. This is unknown for
<br>
conway's game of life, as is the existence of replicators more robust than
<br>
the general chaos. I do not feel capable of estimating the probability of
<br>
these things. There is a long chain of necessary conditions from the
<br>
starting pattern to intelligent life capable of running deliberate
<br>
simulations, but since the game is infinite, none of the steps need to be
<br>
likely, only possible.
<br>
<p>Of course, conway's game of life is ITSELF a deliberate simulation. The
<br>
likelihood of a deterministic cellular automata arising naturally, compared
<br>
with our kind of universe, is unknown, since we've never seen a
<br>
deterministic system arise naturally, and under the simulation hypothesis,
<br>
we've never seen our type of universe arise naturally either.
<br>
<p>This line of thought seems to lead down the rabbit hole fairly quickly.
<br>
<p>On 8/17/07, Rick Smith &lt;<a href="mailto:rick.smith@ntlworld.com?Subject=Re:%20Simulation%20argument%20in%20the%20NY%20Times">rick.smith@ntlworld.com</a>&gt; wrote:
<br>
<p><em>&gt; Perhaps the nature of what's outside the box rests on something incredibly
</em><br>
<em>&gt; likely which we are not capable of imagining. As cognitive units we're just
</em><br>
<em>&gt; not able to conceive it.
</em><br>
<em>&gt;
</em><br>
<em>&gt; How can we assign probabilities to extrapolations when we have no idea
</em><br>
<em>&gt; what proportion of the complete set of imaginable things we can imagine?
</em><br>
<p><p>This objection applies to every assignment of probability, not just ones
<br>
related to looking outside the box. I'm not sure what the real probability
<br>
answer is, if there is one.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16538.html">Daniel Burfoot: "robotics and AI"</a>
<li><strong>Previous message:</strong> <a href="16536.html">Vladimir Nesov: "Re: Simulation argument in the NY Times"</a>
<li><strong>In reply to:</strong> <a href="16535.html">Peter Butler: "Re: Simulation argument in the NY Times"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16540.html">Peter Butler: "Re: Simulation argument in the NY Times"</a>
<li><strong>Reply:</strong> <a href="16540.html">Peter Butler: "Re: Simulation argument in the NY Times"</a>
<li><strong>Reply:</strong> <a href="16542.html">Matt Mahoney: "Re: Simulation argument in the NY Times"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16537">[ date ]</a>
<a href="index.html#16537">[ thread ]</a>
<a href="subject.html#16537">[ subject ]</a>
<a href="author.html#16537">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
