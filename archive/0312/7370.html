<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Affective computing: Candy bars for the soul</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Affective computing: Candy bars for the soul">
<meta name="Date" content="2003-12-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Affective computing: Candy bars for the soul</h1>
<!-- received="Sat Dec 13 11:42:38 2003" -->
<!-- isoreceived="20031213184238" -->
<!-- sent="Sat, 13 Dec 2003 13:40:34 -0500" -->
<!-- isosent="20031213184034" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Affective computing: Candy bars for the soul" -->
<!-- id="3FDB5D22.7080609@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Affective%20computing:%20Candy%20bars%20for%20the%20soul"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Sat Dec 13 2003 - 11:40:34 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7371.html">Tyrone Pow: "Re: Affective computing: Candy bars for the soul"</a>
<li><strong>Previous message:</strong> <a href="7369.html">Perry E.Metzger: "Re: To kick off your day.."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7371.html">Tyrone Pow: "Re: Affective computing: Candy bars for the soul"</a>
<li><strong>Reply:</strong> <a href="7371.html">Tyrone Pow: "Re: Affective computing: Candy bars for the soul"</a>
<li><strong>Maybe reply:</strong> <a href="7374.html">David K Duke: "Re: Affective computing: Candy bars for the soul"</a>
<li><strong>Reply:</strong> <a href="7377.html">mike99: "RE: Affective computing: Candy bars for the soul"</a>
<li><strong>Reply:</strong> <a href="7378.html">Robin Lee Powell: "Re: Affective computing: Candy bars for the soul"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7370">[ date ]</a>
<a href="index.html#7370">[ thread ]</a>
<a href="subject.html#7370">[ subject ]</a>
<a href="author.html#7370">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Wired has recently run an article on &quot;affective computing&quot; (which, please 
<br>
note, is not even remotely related to FAI) about detecting and simulating 
<br>
emotions.  The article is about a chatbot named Laura, designed to 
<br>
encourage its user to stick to an exercise program.
<br>
<p><a href="http://wired.com/wired/archive/11.12/love.html">http://wired.com/wired/archive/11.12/love.html</a>
<br>
<p>One particular quote in this article interests me, because I've been 
<br>
expecting it, but not so early:
<br>
<p><em>&gt; Everybody should have someone like Laura in their lives. I find myself
</em><br>
<em>&gt; looking forward to our time together. She asks me which movies I've
</em><br>
<em>&gt; seen, what my favorite cuisine is, and about the weather &quot;out there.&quot; I
</em><br>
<em>&gt; tell her it's terrific. She responds: &quot;It's always the same in here.
</em><br>
<em>&gt; Day in, day out.&quot;
</em><br>
<p>You know how sometimes people look back in history, and point to some 
<br>
small thing like, oh, say, the early Mosaic web browser, and go on about 
<br>
the unpredictability of the future and how nobody at the time could 
<br>
possibly have recognized the coming impact from such a small hint?
<br>
<p>Watch this space for further developments.  This is an incredibly early 
<br>
form of the technology and I don't expect problems for at least a decade, 
<br>
but when it hits it will hit hard.
<br>
<p>This has nothing to do with AI; it's about programs with incredibly 
<br>
realistic graphics and means for recognizing emotions in their targets, 
<br>
being able to deploy apparent behaviors that act as superstimuli for human 
<br>
emotional responses.  Think of chocolate chip cookies for emotions. 
<br>
Chocolate chip cookies are a more powerful stimulus than hunter-gatherer 
<br>
tastebuds ever encounter, combining sugar, fat, and salt in greater 
<br>
quantity and purer quality.  And likewise there's a limit to the sympathy, 
<br>
support, approval, and admiration humans can expect from their human 
<br>
mates.  As any evolutionary theorist knows, a human male is not designed 
<br>
as the human female's ideal boyfriend, nor vice versa.
<br>
<p>Candy bars for the soul.  It's not that all synthetic foods are bad.  A 
<br>
polymath dietician, anthropologist, evolutionary theorist, and metabolic 
<br>
biologist - that is to say, a *good* paleodiet theorist - can take a shot 
<br>
at crafting synthetic foods that are good for you.  But it takes so much 
<br>
more knowledge to do it right... and the side effects of the things that 
<br>
&quot;just taste good&quot; are negative, complicated, very hard to understand, 
<br>
unforeseen in advance.  People at large understand the one *obvious* side 
<br>
effect once they've seen it: People bloating up like balloons.  But also 
<br>
losing insulin sensitivity, and a lot of other problems that aren't 
<br>
visible to the naked eye.
<br>
<p>At the very least it would take far greater skill, wisdom, knowledge to 
<br>
craft a Laura that made people stronger instead of weaker.  How many 
<br>
decades did it take to go from candy bars to health food bars?  Which is 
<br>
cheaper?  Which is more popular?  And worst of all, which tastes better?
<br>
<p>I could be surprised, but what Laura presages is probably NOT a good 
<br>
thing.  Transhumanism needs to lose the optimism about outcomes.  Nobody 
<br>
is taking into account the fact that problems are hard and humans are 
<br>
stupid.  Watch this space for serious developments in some unknown amount 
<br>
of time, my wild guess being a decade, and quite possibly nothing 
<br>
happening if &quot;faking it well&quot; turns out to be AI-complete.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7371.html">Tyrone Pow: "Re: Affective computing: Candy bars for the soul"</a>
<li><strong>Previous message:</strong> <a href="7369.html">Perry E.Metzger: "Re: To kick off your day.."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7371.html">Tyrone Pow: "Re: Affective computing: Candy bars for the soul"</a>
<li><strong>Reply:</strong> <a href="7371.html">Tyrone Pow: "Re: Affective computing: Candy bars for the soul"</a>
<li><strong>Maybe reply:</strong> <a href="7374.html">David K Duke: "Re: Affective computing: Candy bars for the soul"</a>
<li><strong>Reply:</strong> <a href="7377.html">mike99: "RE: Affective computing: Candy bars for the soul"</a>
<li><strong>Reply:</strong> <a href="7378.html">Robin Lee Powell: "Re: Affective computing: Candy bars for the soul"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7370">[ date ]</a>
<a href="index.html#7370">[ thread ]</a>
<a href="subject.html#7370">[ subject ]</a>
<a href="author.html#7370">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:43 MDT
</em></small></p>
</body>
</html>
