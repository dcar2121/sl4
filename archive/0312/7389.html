<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: An essay I just wrote on the Singularity.</title>
<meta name="Author" content="Michael Anissimov (altima@yifan.net)">
<meta name="Subject" content="Re: An essay I just wrote on the Singularity.">
<meta name="Date" content="2003-12-31">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: An essay I just wrote on the Singularity.</h1>
<!-- received="Wed Dec 31 10:40:10 2003" -->
<!-- isoreceived="20031231174010" -->
<!-- sent="Wed, 31 Dec 2003 09:40:08 -0800" -->
<!-- isosent="20031231174008" -->
<!-- name="Michael Anissimov" -->
<!-- email="altima@yifan.net" -->
<!-- subject="Re: An essay I just wrote on the Singularity." -->
<!-- id="3FF309F8.6000502@yifan.net" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20031231094734.GE11973@digitalkingdom.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Anissimov (<a href="mailto:altima@yifan.net?Subject=Re:%20An%20essay%20I%20just%20wrote%20on%20the%20Singularity."><em>altima@yifan.net</em></a>)<br>
<strong>Date:</strong> Wed Dec 31 2003 - 10:40:08 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7390.html">Ben Goertzel: "RE: An essay I just wrote on the Singularity."</a>
<li><strong>Previous message:</strong> <a href="7388.html">Eugen Leitl: "Re: An essay I just wrote on the Singularity."</a>
<li><strong>In reply to:</strong> <a href="7383.html">Robin Lee Powell: "An essay I just wrote on the Singularity."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7391.html">Ben Goertzel: "RE: An essay I just wrote on the Singularity."</a>
<li><strong>Reply:</strong> <a href="7391.html">Ben Goertzel: "RE: An essay I just wrote on the Singularity."</a>
<li><strong>Reply:</strong> <a href="7399.html">Robin Lee Powell: "Re: An essay I just wrote on the Singularity."</a>
<li><strong>Reply:</strong> <a href="7408.html">Randall Randall: "Re: An essay I just wrote on the Singularity."</a>
<li><strong>Reply:</strong> <a href="../0401/7461.html">Samantha Atkins: "Re: An essay I just wrote on the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7389">[ date ]</a>
<a href="index.html#7389">[ thread ]</a>
<a href="subject.html#7389">[ subject ]</a>
<a href="author.html#7389">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Robin, this is an interesting and entertaining essay!  Congratulations 
<br>
on getting the motivation to write down some of your ideas and reasoning 
<br>
regarding the world-shaking issue of how humanity ought to approach the 
<br>
Singularity.  I disagree with the way you present/argue some things 
<br>
though, so here I go with all the comments:
<br>
<p>1.  Why do you call Singularitarianism your &quot;new religion&quot;?  I know it's 
<br>
basically all in jest, but thousands of people have already 
<br>
misinterpreted the Singularity as a result of the &quot;Singularity = 
<br>
Rapture&quot; meme, and I don't think they need any more encouragement.  I 
<br>
would personally prefer that Singularitarians have the reputation of 
<br>
being extremely atheistic and humanistic. 
<br>
<p>2.  Like Tommy McCabe, I too have a problem with the &quot;FAI means being 
<br>
nice to humans&quot; line.  This gives a lot of people the mistaken 
<br>
impression that FAI is going to be anthropocentric, unfortunately.
<br>
<p>3.  This is a fun paragraph:
<br>
<p>&quot;Combining a few issues here. I believe that strong superintelligence is 
<br>
possible. Furthermore, I believe that to argue to the contrary is 
<br>
amazingly rank anthropocentrism, and should be laughed at. Beyond that, 
<br>
I think full AI is possible. It's the combination of the two that's 
<br>
interesting.&quot;
<br>
<p>I agree that people who believe strong superintelligence is impossible 
<br>
are memetically distant enough from Singularity-aware thought that 
<br>
trying to avoid offending/confusing them is pointless.  Saying that the 
<br>
combination of the two is what's interesting unfortunately gives the 
<br>
reader the impression that AI and strong superintelligence in concert is 
<br>
the only thing capable of initiating a Singularity (when self-improving 
<br>
IA seeds are indeed possible, albeit unlikely.)  It might cause readers 
<br>
to mistakenly overestimate the safety of the IA path.  The Singularity 
<br>
is complicated and confusing enough that little wording issues such as 
<br>
these can actually influence how the paper is interpreted by casual 
<br>
surfers (if that matters.)
<br>
<p>4.  It seems like you're saying the range of possible Singularities 
<br>
basically breaks down into either &quot;seed AI&quot; or &quot;uploading&quot;, when other 
<br>
IA techniques are indeed possible.  Pre-uploading technology could 
<br>
probably be applied to yield substantial human intelligence 
<br>
enhancements, even though AI would almost certainly come before that as 
<br>
well.
<br>
<p>5.  &quot; Source code, /any/ source code, is a paragon of clarity by 
<br>
comparison.&quot; gives the audience the impression that you are worshipping 
<br>
code.  :)  Of course code will be &quot;clearer&quot; in a mathematical sense but 
<br>
&quot;paragon of clarity&quot; in the sense of &quot;it works cleanly&quot; would take a lot 
<br>
of programming effort, of course, and not any code would qualify.
<br>
<p>6.  &quot;You see, Eliezer &lt;<a href="http://yudkowsky.net/beyond.html">http://yudkowsky.net/beyond.html</a>&gt; has convinced 
<br>
me that a Friendly AI must be the first being to develop strong nanotech 
<br>
on Earth, or one of the first, or we are all going to die in a mass of 
<br>
grey goo.&quot; makes you sound like a cult victim, unfortunately.  :(  I 
<br>
know it's fun to write down stuff exactly as it sounds in our heads, but 
<br>
with Singularity issues, the wrong presentation can really damage your 
<br>
credibility...  I also think it's important that we present the FAI meme 
<br>
in a way that doesn't focus on Eliezer so much - even though he 
<br>
originated the idea, FAI-esque thinking has been going on for the past 
<br>
decade or two, and its present day supporters include people like Nick 
<br>
Bostrom, Brian Atkins, etc, not just Eliezer.  Placing too much emphasis 
<br>
on Eliezer will also make you look like a cult victim.
<br>
<p>7.  &quot;Please understand that if someone gets to strong nanotech before 
<br>
everyone else, they rule the world. This is not a subject for debate, 
<br>
you can't fight back, there is no passing Go or collecting two hundred 
<br>
dollars.&quot; is put very clearly, and concisely, and correctly.  A little 
<br>
skimp on the explanations again, but I suppose that if people seriously 
<br>
question you here, they aren't likely to understand the issues 
<br>
surrounding FAI anyway.
<br>
<p>8.  It could be nitpicking, but near the end of the essay, I would 
<br>
personally say we're working towards a &quot;successful&quot; or &quot;benevolent&quot; 
<br>
Singularity, rather than a &quot;sysop scenario&quot;.  &quot;Sysop scenario&quot;, sadly, 
<br>
gives people the wrong idea 90% of the time.
<br>
<p>Anyway, congratulations again on writing something.  Politics is indeed 
<br>
largely irrelevant.  This becomes clear around high SL2, as a matter of 
<br>
fact.  At the very least, politics is something we cannot influence 
<br>
unless we pursue high-leverage goals, like devoting our lives to 
<br>
politics, or, far better yet, building a Friendly AI.
<br>
<p>Michael Anissimov
<br>
<p><p>Robin Lee Powell wrote:
<br>
<p><em>&gt;This kind of captures, I think, why I believe as strongly as I do.
</em><br>
<em>&gt;
</em><br>
<em>&gt;<a href="http://www.digitalkingdom.org/~rlpowell/beliefs/sysop.html">http://www.digitalkingdom.org/~rlpowell/beliefs/sysop.html</a>
</em><br>
<em>&gt;
</em><br>
<em>&gt;Of course, it's almost 2 in the morning, so it might not capture as
</em><br>
<em>&gt;much as I think.  8)
</em><br>
<em>&gt;
</em><br>
<em>&gt;-Robin
</em><br>
<em>&gt;
</em><br>
<em>&gt;  
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7390.html">Ben Goertzel: "RE: An essay I just wrote on the Singularity."</a>
<li><strong>Previous message:</strong> <a href="7388.html">Eugen Leitl: "Re: An essay I just wrote on the Singularity."</a>
<li><strong>In reply to:</strong> <a href="7383.html">Robin Lee Powell: "An essay I just wrote on the Singularity."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7391.html">Ben Goertzel: "RE: An essay I just wrote on the Singularity."</a>
<li><strong>Reply:</strong> <a href="7391.html">Ben Goertzel: "RE: An essay I just wrote on the Singularity."</a>
<li><strong>Reply:</strong> <a href="7399.html">Robin Lee Powell: "Re: An essay I just wrote on the Singularity."</a>
<li><strong>Reply:</strong> <a href="7408.html">Randall Randall: "Re: An essay I just wrote on the Singularity."</a>
<li><strong>Reply:</strong> <a href="../0401/7461.html">Samantha Atkins: "Re: An essay I just wrote on the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7389">[ date ]</a>
<a href="index.html#7389">[ thread ]</a>
<a href="subject.html#7389">[ subject ]</a>
<a href="author.html#7389">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:43 MDT
</em></small></p>
</body>
</html>
