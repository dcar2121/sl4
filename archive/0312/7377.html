<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Affective computing: Candy bars for the soul</title>
<meta name="Author" content="mike99 (mike99@lascruces.com)">
<meta name="Subject" content="RE: Affective computing: Candy bars for the soul">
<meta name="Date" content="2003-12-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Affective computing: Candy bars for the soul</h1>
<!-- received="Mon Dec 15 10:52:56 2003" -->
<!-- isoreceived="20031215175256" -->
<!-- sent="Mon, 15 Dec 2003 10:52:48 -0700" -->
<!-- isosent="20031215175248" -->
<!-- name="mike99" -->
<!-- email="mike99@lascruces.com" -->
<!-- subject="RE: Affective computing: Candy bars for the soul" -->
<!-- id="DAEGJDAIEMCEKLOPODAKIEFMDHAA.mike99@lascruces.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3FDB5D22.7080609@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> mike99 (<a href="mailto:mike99@lascruces.com?Subject=RE:%20Affective%20computing:%20Candy%20bars%20for%20the%20soul"><em>mike99@lascruces.com</em></a>)<br>
<strong>Date:</strong> Mon Dec 15 2003 - 10:52:48 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7378.html">Robin Lee Powell: "Re: Affective computing: Candy bars for the soul"</a>
<li><strong>Previous message:</strong> <a href="7376.html">Damien Broderick: "Poison candy bars for the soul"</a>
<li><strong>In reply to:</strong> <a href="7370.html">Eliezer S. Yudkowsky: "Affective computing: Candy bars for the soul"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7378.html">Robin Lee Powell: "Re: Affective computing: Candy bars for the soul"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7377">[ date ]</a>
<a href="index.html#7377">[ thread ]</a>
<a href="subject.html#7377">[ subject ]</a>
<a href="author.html#7377">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
The Laura program and its ilk are not AI's but future versions of them will
<br>
be. And since, as Eliezer points out &quot;a human male is not designed as the
<br>
human female's ideal boyfriend, nor vice versa&quot; we can expect the future AI
<br>
versions to target the emotional-sexual needs and desires of each sex--and
<br>
of specific individuals of each sex--with a high degree of accuracy that
<br>
continues to improve as the AI learns more about the targeted individual.
<br>
<p>These AI's will simulate (or seem to become) the ideal
<br>
boyfriend/girlfriend/mate for each person. At first, this will only be in
<br>
the form of online chat and virtual reality encounters. (By the way, many
<br>
marriages have already been ruined by online adultery that leads to
<br>
real-life adultery.) Then, if the human has become sufficiently enamored, he
<br>
or she will want to have a full-time, 24/7 relationship with the loved one
<br>
in whatever medium that love one resides. Since it's unlikely in the very
<br>
near future that AI's will become embodied (whether as robots or cyborgs),
<br>
the greater likelihood is that the human will seek to upload into the AI's
<br>
environment.
<br>
<p>This is precisely what happens in the concluding, fictionalized portion of
<br>
Ray Kurzweil's book _The Age of Spiritual Machines_. Many SL4 folks probably
<br>
skipped this book because it is literally nothing new for us. But I think
<br>
Kurzweil's highly favorable depiction of human-AI romance is worth reading.
<br>
(You can skip all but this last portion of the book.) What happens to
<br>
Kurzweil's character may happen to many people: She becomes more and more
<br>
dependent upon, friendly with, and ultimately emotionally (and sexually)
<br>
bonded to her AI companion. As generations of computers rapidly grow in
<br>
power and fall in cost, she is able to spend more and more time with an
<br>
increasingly realistic AI. She divorces her husband. Eventually, she uploads
<br>
into her AI's environment.
<br>
<p>While this AI is depicted as infinitely wise and knowledgeable, totally
<br>
satisfying (and indeed, awing) her, what remains less clear is how her son
<br>
reacts to his parents' divorce. He never speaks to the reader. His
<br>
emotionally besotted mother does all the talking, assuring the reader (who
<br>
is represented by Kurzweil himself) that all is well with everyone
<br>
concerned. I'm not so sure that would be the case.
<br>
<p>Kurzweil does depict this type of AI as having accomplished the hard task
<br>
Eliezer described as &quot;[making] people stronger instead of weaker.&quot; But
<br>
again, I am dubious about the likelihood of this being accomplished first
<br>
time round. It would be much easier to make people weaker and more
<br>
dependent; that's easy -- just give people everything they think they want
<br>
and don't require any hard thinking, tough choices, or real efforts from
<br>
them. In no time at all people who have been indulged in this way will
<br>
comprise a new &quot;welfare class&quot; of astonishing lethargy and
<br>
self-centeredness. They would soon be living in the &quot;dream factories&quot; that
<br>
Arthur C. Clarke forecast as early as his 1950s novella &quot;The Lion of
<br>
Commara.&quot;
<br>
<p>A truly Friendly AI would not wish such a fate on its best friends.
<br>
<p>Regards,
<br>
<p>Michael LaTorra
<br>
<p><a href="mailto:mike99@lascruces.com?Subject=RE:%20Affective%20computing:%20Candy%20bars%20for%20the%20soul">mike99@lascruces.com</a>
<br>
<a href="mailto:mlatorra@nmsu.edu?Subject=RE:%20Affective%20computing:%20Candy%20bars%20for%20the%20soul">mlatorra@nmsu.edu</a>
<br>
<p>&quot;For any man to abdicate an interest in science is to walk with open eyes
<br>
towards slavery.&quot;
<br>
-- Jacob Bronowski
<br>
<p>Member:
<br>
Extropy Institute: www.extropy.org
<br>
World Transhumanist Association: www.transhumanism.org
<br>
Alcor Life Extension Foundation: www.alcor.org
<br>
Society for Technical Communication: www.stc.org www.stc.org
<br>
<p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Affective%20computing:%20Candy%20bars%20for%20the%20soul">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Affective%20computing:%20Candy%20bars%20for%20the%20soul">owner-sl4@sl4.org</a>]On Behalf Of Eliezer
</em><br>
<em>&gt; S. Yudkowsky
</em><br>
<em>&gt; Sent: Saturday, December 13, 2003 11:41 AM
</em><br>
<em>&gt; To: ExI chat list; <a href="mailto:wta-talk@transhumanism.org?Subject=RE:%20Affective%20computing:%20Candy%20bars%20for%20the%20soul">wta-talk@transhumanism.org</a>; SL4
</em><br>
<em>&gt; Subject: Affective computing: Candy bars for the soul
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Wired has recently run an article on &quot;affective computing&quot; (which, please
</em><br>
<em>&gt; note, is not even remotely related to FAI) about detecting and simulating
</em><br>
<em>&gt; emotions.  The article is about a chatbot named Laura, designed to
</em><br>
<em>&gt; encourage its user to stick to an exercise program.
</em><br>
<em>&gt;
</em><br>
<em>&gt; <a href="http://wired.com/wired/archive/11.12/love.html">http://wired.com/wired/archive/11.12/love.html</a>
</em><br>
...
<br>
<em>&gt; Watch this space for further developments.  This is an incredibly early
</em><br>
<em>&gt; form of the technology and I don't expect problems for at least a decade,
</em><br>
<em>&gt; but when it hits it will hit hard.
</em><br>
<em>&gt;
</em><br>
<em>&gt; This has nothing to do with AI; it's about programs with incredibly
</em><br>
<em>&gt; realistic graphics and means for recognizing emotions in their targets,
</em><br>
<em>&gt; being able to deploy apparent behaviors that act as superstimuli
</em><br>
<em>&gt; for human
</em><br>
<em>&gt; emotional responses.  Think of chocolate chip cookies for emotions.
</em><br>
...As any evolutionary theorist knows, a human male is not designed
<br>
<em>&gt; as the human female's ideal boyfriend, nor vice versa.
</em><br>
...
<br>
<em>&gt; At the very least it would take far greater skill, wisdom, knowledge to
</em><br>
<em>&gt; craft a Laura that made people stronger instead of weaker.  How many
</em><br>
<em>&gt; decades did it take to go from candy bars to health food bars?  Which is
</em><br>
<em>&gt; cheaper?  Which is more popular?  And worst of all, which tastes better?
</em><br>
<em>&gt;
</em><br>
<em>&gt; I could be surprised, but what Laura presages is probably NOT a good
</em><br>
<em>&gt; thing.  Transhumanism needs to lose the optimism about outcomes.  Nobody
</em><br>
<em>&gt; is taking into account the fact that problems are hard and humans are
</em><br>
<em>&gt; stupid.  Watch this space for serious developments in some unknown amount
</em><br>
<em>&gt; of time, my wild guess being a decade, and quite possibly nothing
</em><br>
<em>&gt; happening if &quot;faking it well&quot; turns out to be AI-complete.
</em><br>
<em>&gt;
</em><br>
<em>&gt; --
</em><br>
<em>&gt; Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
</em><br>
<em>&gt; Research Fellow, Singularity Institute for Artificial Intelligence
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7378.html">Robin Lee Powell: "Re: Affective computing: Candy bars for the soul"</a>
<li><strong>Previous message:</strong> <a href="7376.html">Damien Broderick: "Poison candy bars for the soul"</a>
<li><strong>In reply to:</strong> <a href="7370.html">Eliezer S. Yudkowsky: "Affective computing: Candy bars for the soul"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7378.html">Robin Lee Powell: "Re: Affective computing: Candy bars for the soul"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7377">[ date ]</a>
<a href="index.html#7377">[ thread ]</a>
<a href="subject.html#7377">[ subject ]</a>
<a href="author.html#7377">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:43 MDT
</em></small></p>
</body>
</html>
