<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI hardware was 'Singularity Realism'</title>
<meta name="Author" content="J. Andrew Rogers (andrew@ceruleansystems.com)">
<meta name="Subject" content="Re: AI hardware was 'Singularity Realism'">
<meta name="Date" content="2004-03-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI hardware was 'Singularity Realism'</h1>
<!-- received="Sun Mar  7 20:28:50 2004" -->
<!-- isoreceived="20040308032850" -->
<!-- sent="Sun, 7 Mar 2004 19:28:42 -0800" -->
<!-- isosent="20040308032842" -->
<!-- name="J. Andrew Rogers" -->
<!-- email="andrew@ceruleansystems.com" -->
<!-- subject="Re: AI hardware was 'Singularity Realism'" -->
<!-- id="B2C46667-70B0-11D8-BF2F-003065C9EC00@ceruleansystems.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="5.1.0.14.0.20040307195247.02e63670@pop.bloor.is.net.cable.rogers.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> J. Andrew Rogers (<a href="mailto:andrew@ceruleansystems.com?Subject=Re:%20AI%20hardware%20was%20'Singularity%20Realism'"><em>andrew@ceruleansystems.com</em></a>)<br>
<strong>Date:</strong> Sun Mar 07 2004 - 20:28:42 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8186.html">Daniel Alexandre: "There are few books on AI"</a>
<li><strong>Previous message:</strong> <a href="8184.html">Philip Sutton: "Re: [SL4] AI --&gt; Jobless Economy"</a>
<li><strong>In reply to:</strong> <a href="8182.html">Keith Henson: "Re: AI hardware was 'Singularity Realism'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8187.html">Keith Henson: "Re: AI hardware was 'Singularity Realism'"</a>
<li><strong>Reply:</strong> <a href="8187.html">Keith Henson: "Re: AI hardware was 'Singularity Realism'"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8185">[ date ]</a>
<a href="index.html#8185">[ thread ]</a>
<a href="subject.html#8185">[ subject ]</a>
<a href="author.html#8185">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Mar 7, 2004, at 5:07 PM, Keith Henson wrote:
<br>
<em>&gt; At 10:11 AM 07/03/04 -0800, andrew wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt; You cannot substitute time complexity for space complexity, and space 
</em><br>
<em>&gt;&gt; complexity generally defines intelligence.  You can substitute space 
</em><br>
<em>&gt;&gt; complexity for time complexity, but not the other way around.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I can't parse this.  It seems likely that you have something here that 
</em><br>
<em>&gt; is worth understanding.  Can you try again from a bit lower level?
</em><br>
<p><p>Sure.
<br>
<p>Time complexity is just the time it takes a given algorithm to run, in 
<br>
terms of how it scales.  I'm sure you already got that.
<br>
<p>A finite machine can be defined in terms of the size of the largest 
<br>
algorithm that can be expressed on that machine, its intrinsic 
<br>
Kolmogorov complexity.  This roughly maps to &quot;memory&quot; for standard 
<br>
silicon, hence &quot;space complexity&quot; i.e. the amount of memory 
<br>
mathematically necessary to run a particular algorithm.
<br>
<p>No algorithm with a Kolmogorov complexity greater than a given machine 
<br>
can be expressed on said machine.  To put it another way, a machine 
<br>
with infinite execution speed is incapable of computing algorithms that 
<br>
do not fit within the space complexity of the machine.  On the other 
<br>
hand, you can improve time complexity by using the excess space 
<br>
capacity of a machine to implement faster but less space efficient 
<br>
algorithms, e.g. using a giant lookup table (O(1)) rather than 
<br>
computing values mathematically, which could be O(n) or worse.  This is 
<br>
also why quantum computers aren't as important to AI as some people 
<br>
seem to think they are.  They don't let us run an entirely new class of 
<br>
algorithms, they only let existing algorithms run faster.  &quot;Faster&quot; 
<br>
doesn't mean &quot;smarter&quot; in the abstract, though in practice speed is 
<br>
admittedly important as well if intelligence is to be useful.
<br>
<p>High time complexity makes getting an answer from a machine 
<br>
intractable; if you wait long enough, you'll get an answer.  High space 
<br>
complexity makes getting an answer from a machine impossible because 
<br>
the pattern is incapable of being expressed or perceived.  Big 
<br>
qualitative difference, that.  The limits of intelligence expressible 
<br>
on any machine is generally defined by the Kolmogorov complexity of the 
<br>
machine, since this is also defines the limit of both expression and 
<br>
inference.  A machine will never be able to perceive a high-order 
<br>
pattern that is more complex than the machine itself.
<br>
<p>The technical details are a bit more complicated than this, but the 
<br>
point about time complexity not being a substitute for space complexity 
<br>
should be clearer now.  Faster machines make some operations faster, 
<br>
nothing more.  Bigger machines (in the memory sense), however, usually 
<br>
make smarter machines no matter what the speed.
<br>
<p><p><em>&gt;&gt; I think the brain storage mechanism is far more efficient in an 
</em><br>
<em>&gt;&gt; information theoretic sense than I think a lot of people think it is.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I hope you are right, because I don't like the conclusions of Thomas 
</em><br>
<em>&gt; Landauer's research.  But I really don't see how to refute him.
</em><br>
<p><p>The number Landauer comes up with for the bits is probably pretty close 
<br>
to being correct, extrapolating from my own models.  There are a couple 
<br>
key points though:
<br>
<p>1.)  The kind of representation efficiencies we get in vanilla silicon 
<br>
is atrocious because of architecture requirements.  Storing a few bits 
<br>
of information in any kind of good associative representational 
<br>
framework probably averages a hundred bytes of memory spent because of 
<br>
alignment, non-locality, addressing, etc.  We don't get much bang for 
<br>
our representation buck.  However, even with these inefficiencies we 
<br>
will easily surpass the real capacity of wetware in silicon very soon.
<br>
<p>2.)   The brain almost certainly gets a much higher compression ratio 
<br>
than we are used to with normal computers, which affects our perception 
<br>
as to what is possible in a given amount of space.  If you loosen the 
<br>
constraints of accuracy a bit, you can actually cram a hell of a lot of 
<br>
information in that space while maintaining high predictive limits 
<br>
(i.e. maintaining good correctness of memory).  Humans don't actually 
<br>
seem to remember that much, and none of what we remember is axiomatic 
<br>
or absolute.
<br>
<p><p><em>&gt; I haven't got the slightest idea of how you map a mathematical 
</em><br>
<em>&gt; structure into a physical one or compare them.  Perhaps you could 
</em><br>
<em>&gt; expand on this and give an example?
</em><br>
<p><p>The data structures look and behave in a fashion similar to biological 
<br>
neural networks (for as much as we know about them), yet are 
<br>
mathematically/algorithmically derived.  It could be coincidence, but I 
<br>
have my doubts.  I'm not a neural network aficionado (biological or 
<br>
otherwise).
<br>
<p><p><em>&gt; That's an awesome claim.  It is of considerable interest to me in a 
</em><br>
<em>&gt; business sense because of the badge camera.
</em><br>
<p><p>It is an expensive and oddly behaving algorithm for embedded systems, 
<br>
and would be better suited for feature extraction rather than vanilla 
<br>
compression.  The compression is a (expected) side-effect that I 
<br>
thought worth studying, not the ends.
<br>
<p><p><em>&gt; I really don't understand this.  Any n-dimentional data set can be 
</em><br>
<em>&gt; turned into a linear string.
</em><br>
<p><p>Sure, and this is what I do.  But in real-world applications where 
<br>
performance matters, data compression is a more complicated 
<br>
implementation that frequently mandates sequential structure because 
<br>
the storage is.  You have many kinds of limitations that make the 
<br>
theoretical impractical for many uses.  If constrained to many standard 
<br>
application parameters, vanilla compression would be more efficient.
<br>
<p>The compression is a necessary theoretical consequence of my main 
<br>
thrust.  I've long used it as a kind of zero-knowledge proof of 
<br>
implementation efficiency and correctness.   I'm not in the data 
<br>
compression business.
<br>
<p><p><em>&gt; If you are talking about remembering a phone number, it is clear that 
</em><br>
<em>&gt; lossy is not useful.
</em><br>
<p><p>Unfortunately, the brain is lossy, even with phone numbers.  
<br>
Fortunately, we can easily selectively reinforce the memory of things 
<br>
that we need to remember with high predictability.
<br>
<p>j. andrew rogers
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8186.html">Daniel Alexandre: "There are few books on AI"</a>
<li><strong>Previous message:</strong> <a href="8184.html">Philip Sutton: "Re: [SL4] AI --&gt; Jobless Economy"</a>
<li><strong>In reply to:</strong> <a href="8182.html">Keith Henson: "Re: AI hardware was 'Singularity Realism'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8187.html">Keith Henson: "Re: AI hardware was 'Singularity Realism'"</a>
<li><strong>Reply:</strong> <a href="8187.html">Keith Henson: "Re: AI hardware was 'Singularity Realism'"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8185">[ date ]</a>
<a href="index.html#8185">[ thread ]</a>
<a href="subject.html#8185">[ subject ]</a>
<a href="author.html#8185">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
