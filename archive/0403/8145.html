<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: 'Singularity Realism' - A few thoughts</title>
<meta name="Author" content="Tommy McCabe (rocketjet314@yahoo.com)">
<meta name="Subject" content="Re: 'Singularity Realism' - A few thoughts">
<meta name="Date" content="2004-03-05">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: 'Singularity Realism' - A few thoughts</h1>
<!-- received="Fri Mar  5 04:37:29 2004" -->
<!-- isoreceived="20040305113729" -->
<!-- sent="Fri, 5 Mar 2004 03:37:23 -0800 (PST)" -->
<!-- isosent="20040305113723" -->
<!-- name="Tommy McCabe" -->
<!-- email="rocketjet314@yahoo.com" -->
<!-- subject="Re: 'Singularity Realism' - A few thoughts" -->
<!-- id="20040305113723.25094.qmail@web11707.mail.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="20040305093318.36698.qmail@web20208.mail.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Tommy McCabe (<a href="mailto:rocketjet314@yahoo.com?Subject=Re:%20'Singularity%20Realism'%20-%20A%20few%20thoughts"><em>rocketjet314@yahoo.com</em></a>)<br>
<strong>Date:</strong> Fri Mar 05 2004 - 04:37:23 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8146.html">Chris Healey: "RE: 'Singularity Realism' - A few thoughts"</a>
<li><strong>Previous message:</strong> <a href="8144.html">Marc Geddes: "'Singularity Realism' - A few thoughts"</a>
<li><strong>In reply to:</strong> <a href="8144.html">Marc Geddes: "'Singularity Realism' - A few thoughts"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8146.html">Chris Healey: "RE: 'Singularity Realism' - A few thoughts"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8145">[ date ]</a>
<a href="index.html#8145">[ thread ]</a>
<a href="subject.html#8145">[ subject ]</a>
<a href="author.html#8145">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- Marc Geddes &lt;<a href="mailto:marc_geddes@yahoo.co.nz?Subject=Re:%20'Singularity%20Realism'%20-%20A%20few%20thoughts">marc_geddes@yahoo.co.nz</a>&gt; wrote:
<br>
<em>&gt; I'm glad to see that Sing Inst finally has an
</em><br>
<em>&gt; executive director.  Good luck!
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Some thoughts on the future:  If you're commited to
</em><br>
<em>&gt; the task of Creating FAI, you need to realize that
</em><br>
<em>&gt; you're in it for the long haul.  Utopian visions of
</em><br>
<em>&gt; a
</em><br>
<em>&gt; Singularity in only 5-20 years are almost certainly
</em><br>
<em>&gt; fantasy (although I'd love to be proved wrong). 
</em><br>
<em>&gt; People at the forefront of research are almost
</em><br>
<em>&gt; always
</em><br>
<em>&gt; far too over optimistic about how long it would take
</em><br>
<em>&gt; to achieve major breakthroughs.  Fundamental
</em><br>
<em>&gt; knowledge
</em><br>
<em>&gt; about general intelligence is still missing. It is
</em><br>
<em>&gt; estimated that only about 2% of everything there is
</em><br>
<em>&gt; to
</em><br>
<em>&gt; know about cognitive science is known.  Even with
</em><br>
<em>&gt; exponential progress, 100% knowledge wouldn't be
</em><br>
<em>&gt; reached for another 40-50 years.
</em><br>
<p>AI is a very difficult problem, yes, but how soon the
<br>
project is completed is a function of probably over
<br>
dozens of variables. Don't jump to conclusions.
<br>
<p><em>&gt; The first design and coding effort of a major AGI is
</em><br>
<em>&gt; not likely to succeed.  Although it will be
</em><br>
<em>&gt; progress,
</em><br>
<em>&gt; and lessons will be learned.  The second generation
</em><br>
<em>&gt; effort won't succeed either, although again it will
</em><br>
<em>&gt; advance the field.  The third generation effort...
</em><br>
<em>&gt; might be closing on it.  And the fourth generation
</em><br>
<em>&gt; effort... that's the one that will get there ;)
</em><br>
<p>When SIAI's AI team gets together, if you just take
<br>
the first ideas that popped into everyone's head, yes,
<br>
it probably won't succeed. But who says an AI can't be
<br>
rewritten by humans, if not by itself yet?
<br>
<p><em>&gt; I would say that a 40-60 time frame for success is
</em><br>
<em>&gt; realistic.  That's what I would call 'Singularity
</em><br>
<em>&gt; Realism'.  You have to be in it for the long haul.
</em><br>
<p>The objective is to get to the Singularity ASAP before
<br>
the planet is destroyed, whether it 'should' happen in
<br>
5 years or 50. It will happen when people go out and
<br>
make it happen. Damn the predictions; Full speed
<br>
ahead!
<br>
<p><em>&gt; Once success starts to look even remotely likely,
</em><br>
<em>&gt; you
</em><br>
<em>&gt; will come to the attention of the government and the
</em><br>
<em>&gt; public in a big way.  You run the risk of regulators
</em><br>
<em>&gt; coming down on you.  
</em><br>
<p>Yes, and we need to insure that these people get the
<br>
Singularity meme, not a horribly distorted version of
<br>
it.
<br>
<p><em>&gt; If Sing Inst is going to have an actual physical
</em><br>
<em>&gt; location at some point, I would recommend moving to
</em><br>
<em>&gt; a
</em><br>
<em>&gt; Libertarian oriented State, where you will be
</em><br>
<em>&gt; surrounded with allies.  Consider especially the
</em><br>
<em>&gt; state
</em><br>
<em>&gt; of New Hampshire, where transhumanists and
</em><br>
<em>&gt; Libertarians are gathering to form a revolutionary
</em><br>
<em>&gt; base. There would be strength in numbers there. 
</em><br>
<em>&gt; Isolated as we are now we're sitting ducks.
</em><br>
<p>Sitting ducks for what? It's not like Eli has
<br>
assassins after him.
<br>
<p><em>&gt; I also wonder just how much Information on AGI
</em><br>
<em>&gt; should
</em><br>
<em>&gt; be shared with the general public whilst the
</em><br>
<em>&gt; projects
</em><br>
<em>&gt; are going on?  I see that Ben is publishing quite a
</em><br>
<em>&gt; lot about his project, and Eliezer has publically 
</em><br>
<em>&gt; published quite a lot as well.  Be aware that anyone
</em><br>
<em>&gt; with net access can read all that.  Dictators in
</em><br>
<em>&gt; China
</em><br>
<em>&gt; and North Korea, the odd pychopath... is it wise to
</em><br>
<em>&gt; provide too much information about how to create
</em><br>
<em>&gt; AGI? 
</em><br>
<em>&gt; On the one hand, sharing can advance research, on
</em><br>
<em>&gt; the
</em><br>
<em>&gt; other, the risk of someone creating Unfriendly A.I
</em><br>
<em>&gt; is
</em><br>
<em>&gt; increased.  And of course, shorter term A.I results
</em><br>
<em>&gt; could have substantial proprietary value.
</em><br>
<p>Damn the value, full speed ahead! Yes, it is a
<br>
tradeoff between the risk of creating UFAI and the
<br>
risk of not sharing insight.
<br>
<p><em>&gt; To tell you the truth, I was slightly uneasy even
</em><br>
<em>&gt; posting those few very general ideas to sl4 you see
</em><br>
<em>&gt; in
</em><br>
<em>&gt; my last couple of posts.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Most of the people working in A.I probably visit sl4
</em><br>
<em>&gt; and copy everything down.  They're probably ripping
</em><br>
<em>&gt; off all our ideas without a second thought. 
</em><br>
<p>Ummm... Do you have any proof?
<br>
<p><em>&gt; The marketing side of it needs to be a lot more
</em><br>
<em>&gt; careful as well.  Some things (like the Sys Op idea)
</em><br>
<em>&gt; will just cause people to go ballistic.  Other
</em><br>
<em>&gt; things,
</em><br>
<em>&gt; like wild speculation about life after the
</em><br>
<em>&gt; Singularity, will just cause people to dismiss it
</em><br>
<em>&gt; all
</em><br>
<em>&gt; as sci-fi fantasy.
</em><br>
<p>Agreed.
<br>
<p><em>&gt; I would never have talked about
</em><br>
<em>&gt; the Singularity at all. 
</em><br>
<p>If people don't become interested in the Singularity,
<br>
how are we supposed to get donors, let alone AI
<br>
programmers?
<br>
<p><em>&gt; And for God's sake
</em><br>
<p>God does not exist.
<br>
<p><em>&gt; don't
</em><br>
<em>&gt; talk
</em><br>
<em>&gt; about life after the Singularity!  Most people just
</em><br>
<em>&gt; don't believe a word of this stuff.  There is too
</em><br>
<em>&gt; much
</em><br>
<em>&gt; hype and far too many 'slip ups' on the marketing
</em><br>
<em>&gt; side.  And the few non-scientifc people in the
</em><br>
<em>&gt; general
</em><br>
<em>&gt; population who do believe this stuff are scared
</em><br>
<em>&gt; shitless by it.
</em><br>
<p>Future shock. Taking an ordinary person and
<br>
introducing him to Staring into the Singularity will
<br>
get him quite shocked and scared, yes, if not outright
<br>
disbelief.
<br>
<p><em>&gt; AI will upset religious and social
</em><br>
<em>&gt; norms.  
</em><br>
<p>That's a good thing!!!
<br>
<p><em>&gt; All of this may sound a bit paranoid, but really
</em><br>
<em>&gt; Sing
</em><br>
<em>&gt; Inst needs to start thinking about these things. 
</em><br>
<em>&gt; It's
</em><br>
<em>&gt; just 'Singularity Realism'.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Cheers!
</em><br>
<em>&gt;  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; =====
</em><br>
<em>&gt; Please visit my web-site at: 
</em><br>
<em>&gt; <a href="http://www.prometheuscrack.com">http://www.prometheuscrack.com</a>
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Find local movie times and trailers on Yahoo!
</em><br>
<em>&gt; Movies.
</em><br>
<em>&gt; <a href="http://au.movies.yahoo.com">http://au.movies.yahoo.com</a>
</em><br>
<p><p>__________________________________
<br>
Do you Yahoo!?
<br>
Yahoo! Search - Find what you’re looking for faster
<br>
<a href="http://search.yahoo.com">http://search.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8146.html">Chris Healey: "RE: 'Singularity Realism' - A few thoughts"</a>
<li><strong>Previous message:</strong> <a href="8144.html">Marc Geddes: "'Singularity Realism' - A few thoughts"</a>
<li><strong>In reply to:</strong> <a href="8144.html">Marc Geddes: "'Singularity Realism' - A few thoughts"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8146.html">Chris Healey: "RE: 'Singularity Realism' - A few thoughts"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8145">[ date ]</a>
<a href="index.html#8145">[ thread ]</a>
<a href="subject.html#8145">[ subject ]</a>
<a href="author.html#8145">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
