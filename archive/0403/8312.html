<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: [SL4] Re: 'Singularity Realism'</title>
<meta name="Author" content="Philip Sutton (Philip.Sutton@green-innovations.asn.au)">
<meta name="Subject" content="RE: [SL4] Re: 'Singularity Realism'">
<meta name="Date" content="2004-03-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: [SL4] Re: 'Singularity Realism'</h1>
<!-- received="Wed Mar 24 20:42:14 2004" -->
<!-- isoreceived="20040325034214" -->
<!-- sent="Thu, 25 Mar 2004 14:44:19 +1000" -->
<!-- isosent="20040325044419" -->
<!-- name="Philip Sutton" -->
<!-- email="Philip.Sutton@green-innovations.asn.au" -->
<!-- subject="RE: [SL4] Re: 'Singularity Realism'" -->
<!-- id="4062F043.8835.14197A0@localhost" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="DAEGJDAIEMCEKLOPODAKKEKJDLAA.mike99@lascruces.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Philip Sutton (<a href="mailto:Philip.Sutton@green-innovations.asn.au?Subject=RE:%20[SL4]%20Re:%20'Singularity%20Realism'"><em>Philip.Sutton@green-innovations.asn.au</em></a>)<br>
<strong>Date:</strong> Wed Mar 24 2004 - 21:44:19 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8313.html">Thomas Buckner: "Re: [SL4] Re: 'Singularity Realism'"</a>
<li><strong>Previous message:</strong> <a href="8311.html">Thomas Buckner: "Re: De-Anthropomorphizing SL3 to SL4."</a>
<li><strong>In reply to:</strong> <a href="8308.html">mike99: "RE: [SL4] Re: 'Singularity Realism'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8313.html">Thomas Buckner: "Re: [SL4] Re: 'Singularity Realism'"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8312">[ date ]</a>
<a href="index.html#8312">[ thread ]</a>
<a href="subject.html#8312">[ subject ]</a>
<a href="author.html#8312">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi Mike,
<br>
<p><em>&gt; Primate politics.
</em><br>
<p>I think that's too much of a generalisation.  It's not Bonobo politics or 
<br>
Orang Utang politics.  It certainly *is* human and chimpanzee politics 
<br>
of a widespread sort but even in the human domain this sort of politics 
<br>
is *not universal*.
<br>
<p>Jared Diamond's book 'Guns, germs and steel' proposes a useful 
<br>
framework for explaning why human communities vary between 
<br>
imperial - barbaric - peaceful/cooperative.
<br>
<p>The work by primatologist Frans de Waal is useful too (eg. book 'Good 
<br>
natured&quot;).
<br>
<p><em>&gt; If we can create a Friendly AI that consistently adheres to a superior
</em><br>
<em>&gt; morality (i.e., our best morality) even without oversight, then we may
</em><br>
<em>&gt; have a situation where humans can relax the imperatives of primate
</em><br>
<em>&gt; politics. We would quickly learn that we can no longer get away with
</em><br>
<em>&gt; doing things the old way because the FAI will not allow it. 
</em><br>
<p>How would you actually see the FAI doing this?  Being a universal 
<br>
dictator?  If we go down that path my guess is some faily nasty 
<br>
primates (read humans) will try to hijack the FAI development process 
<br>
so that they (the humans) can be in charge.  If super-AIs have the 
<br>
prospect of the being the most powerful agents around, then power-
<br>
hungry humans will be attracted to that potential power like moths to a 
<br>
candle.
<br>
<p>I think humans (a great many but of course not all) also demonstrate 
<br>
great capacity for peace and cooperation (as well as 
<br>
war/domination/exploitation) so if AIs simply worked together with 
<br>
humans and human institutions committed to peaceful cooexistence 
<br>
then I think the balance could be tipped decisively away from the 
<br>
war/domination/exploitation end of the human spectrum.  So under this 
<br>
scenario the FAIs would not be designed for or be expected to play a 
<br>
role as benevolent dictator (acting outside of any community-derived 
<br>
law) - instead they would be partnered with humans and human 
<br>
institutions that were working to achieve a peaceful non-exploitative 
<br>
condition - and would work in support of the application of 
<br>
democratically formulated law.
<br>
<p>If FAIs had huge intellectual capacity, deep wisdom and considerable 
<br>
reach in society they could act quite subtly to help nudge things in a 
<br>
good direction without taking any extra-legal actions or acting as a 
<br>
dictator - but simply by working *with* humans who also had the same 
<br>
hopes for a peaceful collaborative democratic joyously unfolding 
<br>
society.
<br>
<p>My current expectation is that a variety of AGIs will emerge with widely 
<br>
varying degrees of friendliness - because they will be developed in a 
<br>
number of organisations at about the same time and that *at least 
<br>
some* of these AIs will be brought into the orbit of fairly unfriendly 
<br>
humans by one means or another (eg. into militiary/intelligence, 
<br>
commercial or criminal orbits).  (I'm assuming a relatively slow start to 
<br>
AGIs with any hard take-off occurring some years down the track).  
<br>
Where things go from there will depend on what happens amongst 
<br>
humans and whether there are any truly Friendly AGIs around (with 
<br>
access to adequate computing and other resources) at the same time 
<br>
as the unfriendly ones are extant.
<br>
<p>At least for a few years (maybe longer) AGIs will be caught up in the 
<br>
sort of politics that you started out calling primate politics.
<br>
<p>You might be wondering why I would think AGIs that had reached hard 
<br>
take off would bother restraining themselves to work with people 
<br>
through democratic processes etc.  There is no certainty about any of 
<br>
this of course. The scenario I've painted is merely one possibility 
<br>
among a vast array.  But I think that if we are to get friendly AI at all we 
<br>
will probably have to go through a period (however short) where there 
<br>
is a pact between friendly AI and friendly humans for mutual benefit.  
<br>
After that the universe (and beyond) is the limit for the AGIs (and any 
<br>
uploads) but I can imagine truly friendly AGIs, while not being limited 
<br>
by humans, would not have problems helping humans get their act 
<br>
together in their own more limited human domain. It might be a nice 
<br>
little nostalgic hobby for a few AGIs!  
<br>
<p>Cheers, Philip
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8313.html">Thomas Buckner: "Re: [SL4] Re: 'Singularity Realism'"</a>
<li><strong>Previous message:</strong> <a href="8311.html">Thomas Buckner: "Re: De-Anthropomorphizing SL3 to SL4."</a>
<li><strong>In reply to:</strong> <a href="8308.html">mike99: "RE: [SL4] Re: 'Singularity Realism'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8313.html">Thomas Buckner: "Re: [SL4] Re: 'Singularity Realism'"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8312">[ date ]</a>
<a href="index.html#8312">[ thread ]</a>
<a href="subject.html#8312">[ subject ]</a>
<a href="author.html#8312">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
