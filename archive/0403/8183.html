<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI hardware was 'Singularity Realism'</title>
<meta name="Author" content="Keith Henson (hkhenson@rogers.com)">
<meta name="Subject" content="Re: AI hardware was 'Singularity Realism'">
<meta name="Date" content="2004-03-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI hardware was 'Singularity Realism'</h1>
<!-- received="Sun Mar  7 19:22:45 2004" -->
<!-- isoreceived="20040308022245" -->
<!-- sent="Sun, 07 Mar 2004 21:30:38 -0500" -->
<!-- isosent="20040308023038" -->
<!-- name="Keith Henson" -->
<!-- email="hkhenson@rogers.com" -->
<!-- subject="Re: AI hardware was 'Singularity Realism'" -->
<!-- id="5.1.0.14.0.20040307200854.03e308c0@pop.bloor.is.net.cable.rogers.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="48055439-705C-11D8-BF2F-003065C9EC00@ceruleansystems.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Keith Henson (<a href="mailto:hkhenson@rogers.com?Subject=Re:%20AI%20hardware%20was%20'Singularity%20Realism'"><em>hkhenson@rogers.com</em></a>)<br>
<strong>Date:</strong> Sun Mar 07 2004 - 19:30:38 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8184.html">Philip Sutton: "Re: [SL4] AI --&gt; Jobless Economy"</a>
<li><strong>Previous message:</strong> <a href="8182.html">Keith Henson: "Re: AI hardware was 'Singularity Realism'"</a>
<li><strong>In reply to:</strong> <a href="8177.html">J. Andrew Rogers: "Re: AI hardware was 'Singularity Realism'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8190.html">Michael Roy Ames: "Re: AI hardware was 'Singularity Realism'"</a>
<li><strong>Reply:</strong> <a href="8190.html">Michael Roy Ames: "Re: AI hardware was 'Singularity Realism'"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8183">[ date ]</a>
<a href="index.html#8183">[ thread ]</a>
<a href="subject.html#8183">[ subject ]</a>
<a href="author.html#8183">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
At 09:24 AM 07/03/04 -0800, you wrote:
<br>
<p><em>&gt;On Mar 6, 2004, at 2:17 PM, Keith Henson wrote:
</em><br>
<em>&gt;&gt;That's not surprising considering how much computational power biology 
</em><br>
<em>&gt;&gt;lavishes on the problem.  Have you ever looked up the MIPS rating of a retina?
</em><br>
<em>&gt;
</em><br>
<em>&gt;The focus on the amount of computing power required to simulate biology is 
</em><br>
<em>&gt;a bit of a strawman in the AGI argument because it asserts a necessarily 
</em><br>
<em>&gt;asymmetric system and then marvels at the asymmetry without recognizing 
</em><br>
<em>&gt;that it *is* an asymmetry.  Modeling any bulk system (like a retina) is 
</em><br>
<em>&gt;exponentially more expensive than modeling the algorithmic machine that 
</em><br>
<em>&gt;generates the state.
</em><br>
<p>*What* the retina does, feature extraction, motion detection, compression 
<br>
is fairly well understood.  Doing it with slow (biology kind of) hardware 
<br>
takes a whacking lot of it in parallel.  Considering the resolution of the 
<br>
retina and the known update speed, and comparing it to Photoshop doing 
<br>
something of the same sort, I can safely state that my retinas have a *lot* 
<br>
more power than the 2GHz processor on this machine.
<br>
<p><em>&gt;Simulating biology at this level is akin to using a lookup table for the 
</em><br>
<em>&gt;first 10^40 digits of pi rather than using the BBP algorithm to generate 
</em><br>
<em>&gt;the digits you need.  And the lookup table is only a relatively poor 
</em><br>
<em>&gt;approximation of pi, unlike BBP.
</em><br>
<p>I don't get the analogy you are trying to make here.
<br>
<p><em>&gt;Any serious AI effort would have to approach it from the standpoint of 
</em><br>
<em>&gt;implementing the underlying algorithmic machinery of intelligence.
</em><br>
<p>Aircraft might be an analogy supporting your contention.  Aircraft didn't 
<br>
use flapping wings to fly, no birds use propellers.  Still, it really helps 
<br>
to understand that the physics of flight apply to both.
<br>
<p><em>&gt;Not only is this approach tractable, it is also a hell of a lot more 
</em><br>
<em>&gt;likely to yield useful results than chasing a ghost that most everyone 
</em><br>
<em>&gt;acknowledges is both intractable and a poor theoretical approximation in 
</em><br>
<em>&gt;the best case.
</em><br>
<p>Short range I agree that trying to simulate a brain is probably beyond 
<br>
us.  Long range, especially given nanotech I don't see any difficulty.  As 
<br>
far as biological brains being &quot;a poor theoretical approximation in the 
<br>
best case,&quot; I really don't understand how you make such a statement.  On 
<br>
the other hand, maybe I do.
<br>
<p><em>&gt;And to answer a previous question, I would say that today we (&quot;we&quot; in the 
</em><br>
<em>&gt;sense of anyone who bothers to study the theoretical issue of AGI) have a 
</em><br>
<em>&gt;pretty good idea of what is going on in the underlying algorithmic 
</em><br>
<em>&gt;machinery of intelligence.  The grasp isn't perfect and there are some 
</em><br>
<em>&gt;implementation issues, but no real theoretical show-stoppers that I can 
</em><br>
<em>&gt;see, and that there are several other people working on implementations in 
</em><br>
<em>&gt;the same general area seems to indicate that many other people versed on 
</em><br>
<em>&gt;the subject don't see any serious show-stoppers either. I'm am cognizant 
</em><br>
<em>&gt;of the history of the field, but I think we have something actually close 
</em><br>
<em>&gt;to a real and usable foundation these days.
</em><br>
<p>Is there a pointer you could suggest where there is a simple explanation of 
<br>
generating intelligence?  I am seriously interested in this, among other 
<br>
reasons because I make the case that humans have (evolved, gene 
<br>
constructed) psychological traits that sabotage intelligence in certain 
<br>
situations.
<br>
<p><em>&gt;&gt;I happen to be a bit skeptical that the hardware is up to the task based 
</em><br>
<em>&gt;&gt;on arguments by Hans Moravec, Ray Kurzweil and others.  In the long run 
</em><br>
<em>&gt;&gt;this is not a problem since hardware equal to the task is less than a 
</em><br>
<em>&gt;&gt;human generation away.  If you have a radical approach that would allow 
</em><br>
<em>&gt;&gt;cockroach level hardware to generate superhuman AI level performance, I 
</em><br>
<em>&gt;&gt;would sure like to know what it is.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Almost any approach that ignores biology and goes to the math will be MANY 
</em><br>
<em>&gt;orders of magnitude more scalable and capable on a given piece of hardware.
</em><br>
<p>Again, the aircraft analogy.  There is no bird with the takeoff weight of a 
<br>
747.
<br>
<p><em>&gt;Moravec, Kurzweil, and others have biology blinders on, and I think it is 
</em><br>
<em>&gt;fairly trivial to show that their view is predicated on some specific 
</em><br>
<em>&gt;assumptions that arguably don't apply in the general case.
</em><br>
<em>&gt;
</em><br>
<em>&gt;For most of the non-biology AGI projects out there, there seems to be some 
</em><br>
<em>&gt;consensus that commodity hardware is within an order of magnitude of what 
</em><br>
<em>&gt;is needed to build human-level intelligence, and that this &quot;order of 
</em><br>
<em>&gt;magnitude&quot; is not a moving target i.e. experience shows that we are 
</em><br>
<em>&gt;actually closing on the necessary hardware.  The specifics of the hardware 
</em><br>
<em>&gt;limitations vary from implementation to implementation, but no one seems 
</em><br>
<em>&gt;to be saying that the hardware is horribly inadequate to do a functional 
</em><br>
<em>&gt;implementation.
</em><br>
<p>Hmm.  If the hardware is within an order of magnitude, then the AGI should 
<br>
just be an order of magnitude slower.  I.e., it could not keep up with a 
<br>
chat room, but it could take part in email list exchanges.
<br>
<p>You may be right.  I don't know if I should be thankful or terrified.
<br>
<p>Keith Henson
<br>
<p>PS.  If you can find them, I recommend the series of books by Alexis Gilliland
<br>
<p>REVOLUTION FROM ROSINANTE
<br>
LONG SHOT FOR ROSINANTE
<br>
THE PIRATES OF ROSINANTE
<br>
<p>These books are (I think) both the best ever done on a space colony theme 
<br>
and the best on AIs and the interactions of AIs with people.  It has the 
<br>
first seduction scene between a human and an AI as well as an AI that 
<br>
writes up a religion and another one that proselytizes.  Further, it has a 
<br>
legal mechanism for giving AIs legal rights that is just inspired.
<br>
<p><em>&gt;j. andrew rogers
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8184.html">Philip Sutton: "Re: [SL4] AI --&gt; Jobless Economy"</a>
<li><strong>Previous message:</strong> <a href="8182.html">Keith Henson: "Re: AI hardware was 'Singularity Realism'"</a>
<li><strong>In reply to:</strong> <a href="8177.html">J. Andrew Rogers: "Re: AI hardware was 'Singularity Realism'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8190.html">Michael Roy Ames: "Re: AI hardware was 'Singularity Realism'"</a>
<li><strong>Reply:</strong> <a href="8190.html">Michael Roy Ames: "Re: AI hardware was 'Singularity Realism'"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8183">[ date ]</a>
<a href="index.html#8183">[ thread ]</a>
<a href="subject.html#8183">[ subject ]</a>
<a href="author.html#8183">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
