<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: AI hardware was 'Singularity Realism'</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: AI hardware was 'Singularity Realism'">
<meta name="Date" content="2004-03-06">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: AI hardware was 'Singularity Realism'</h1>
<!-- received="Sat Mar  6 15:59:01 2004" -->
<!-- isoreceived="20040306225901" -->
<!-- sent="Sat, 6 Mar 2004 17:58:55 -0500" -->
<!-- isosent="20040306225855" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: AI hardware was 'Singularity Realism'" -->
<!-- id="0d9c01c403ce$9ae17670$6701a8c0@ZOMBIETHUSTRA" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="5.1.0.14.0.20040306165618.02e36840@pop.bloor.is.net.cable.rogers.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20AI%20hardware%20was%20'Singularity%20Realism'"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sat Mar 06 2004 - 15:58:55 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8168.html">Ben Goertzel: "RE: AI hardware was 'Singularity Realism'"</a>
<li><strong>Previous message:</strong> <a href="8166.html">Keith Henson: "Re: Article: How Will the Universe End?"</a>
<li><strong>In reply to:</strong> <a href="8165.html">Keith Henson: "RE: AI hardware was 'Singularity Realism'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8169.html">Peter Voss: "RE: AI hardware was 'Singularity Realism'"</a>
<li><strong>Reply:</strong> <a href="8169.html">Peter Voss: "RE: AI hardware was 'Singularity Realism'"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8167">[ date ]</a>
<a href="index.html#8167">[ thread ]</a>
<a href="subject.html#8167">[ subject ]</a>
<a href="author.html#8167">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi,
<br>
<p><em>&gt; &gt;Keith, I am curious what funding sources you're thinking of.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I know at least one computer savvy person who could write a check that
</em><br>
<em>&gt; large.
</em><br>
<p>Indeed, the individual investor/philanthropist is the most likely source
<br>
of funding for pure AGI R&amp;D right now, given the conservative nature of
<br>
the research establishment.
<br>
<p><em>&gt; &gt;The major science and technology funding bodies in the US are very
</em><br>
<em>&gt; &gt;tightly tied into the &quot;narrow AI&quot; research programme and very
</em><br>
skeptical
<br>
<em>&gt; &gt;of radical approaches to AGI.  This is in spite of the fact that
</em><br>
they've
<br>
<em>&gt; &gt;spent hundreds of millions of dollars on narrow AI programs (Cyc
</em><br>
being
<br>
<em>&gt; &gt;the flagship example ;-) without obtaining dramatic returns either
</em><br>
<em>&gt; &gt;scientifically or economically.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; That's not surprising considering how much computational power biology
</em><br>
<em>&gt; lavishes on the problem.  Have you ever looked up the MIPS rating of a
</em><br>
<em>&gt; retina?
</em><br>
<p>Well, comparing contemporary computer hardware with biological systems
<br>
is definitely tougher than the proverbial comparison between apples and
<br>
oranges!  The two are good at different sorts of things.  Simulating
<br>
human neural process on digital computers would definitely require MUCH
<br>
more computing power than is currently affordable for an R&amp;D project.
<br>
On the other hand, this observation does NOT rule out AGI architectures
<br>
specifically designed to exploit the strengths and minimize the
<br>
weaknesses of contemporary computers &amp; networks.
<br>
<p><em>&gt; &gt;So, if by a &quot;strong case&quot; you mean a case that will convince AGI
</em><br>
<em>&gt; &gt;skeptics such as the folks at the National Science Foundation -- I
</em><br>
guess
<br>
<em>&gt; &gt;this essentially means &quot;something like young-child-level human
</em><br>
<em>&gt; &gt;intelligence has been achieved and what remains is teaching of the
</em><br>
<em>&gt; &gt;system and refinement of the algorithms.&quot;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I would not need that level, but you need to sell me that you have a
</em><br>
<em>&gt; viable
</em><br>
<em>&gt; approach before I stick my neck out and try to convince people with
</em><br>
money.
<br>
<p>Yes, of course that makes sense.
<br>
&nbsp;
<br>
<em>&gt; We might consider spending an hour or so in chat.  If nothing else,
</em><br>
you
<br>
<em>&gt; could salvage the chat log for a written presentation material.
</em><br>
<p>Sure, that would probably be worthwhile.  If you'd like to set up a time
<br>
to chat, email me at ben@goertzel.org.  Unfortunately, I lost your email
<br>
address in a recent hard drive crash...
<br>
<p><em>&gt; I happen to be a bit skeptical that the hardware is up to the task
</em><br>
based
<br>
<em>&gt; on
</em><br>
<em>&gt; arguments by Hans Moravec, Ray Kurzweil and others.  In the long run
</em><br>
this
<br>
<em>&gt; is not a problem since hardware equal to the task is less than a human
</em><br>
<em>&gt; generation away.  If you have a radical approach that would allow
</em><br>
<em>&gt; cockroach
</em><br>
<em>&gt; level hardware to generate superhuman AI level performance, I would
</em><br>
sure
<br>
<em>&gt; like to know what it is.
</em><br>
<p>As I said above, hardware is DEFINITELY a problem if you're trying to
<br>
simulate the brain -- rather than achieve qualitatively &quot;human-level&quot;
<br>
(and then beyond) intelligence in a manner fundamentally tailored to the
<br>
hardware at hand. 
<br>
<p>Also, please note that I am not aiming to imitate human sensorimotor
<br>
capability.  Sensorimotor capability is definitely critical, but
<br>
emulation of human strengths and weaknesses in this domain is not
<br>
important if your goal is AGI.
<br>
<p>Kurzweil and Moravec tend to focus on uploading and human brain
<br>
simulation, rather than on AGI that takes non-human-imitative
<br>
approaches.  Kurzweil is skeptical that the cognitive science problems
<br>
involved in structuring AGI systems can be solved in any way other than
<br>
studying and imitating the human brain.  I don't agree with him on this
<br>
point, though I very much respect his thinking generally.
<br>
<p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8168.html">Ben Goertzel: "RE: AI hardware was 'Singularity Realism'"</a>
<li><strong>Previous message:</strong> <a href="8166.html">Keith Henson: "Re: Article: How Will the Universe End?"</a>
<li><strong>In reply to:</strong> <a href="8165.html">Keith Henson: "RE: AI hardware was 'Singularity Realism'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8169.html">Peter Voss: "RE: AI hardware was 'Singularity Realism'"</a>
<li><strong>Reply:</strong> <a href="8169.html">Peter Voss: "RE: AI hardware was 'Singularity Realism'"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8167">[ date ]</a>
<a href="index.html#8167">[ thread ]</a>
<a href="subject.html#8167">[ subject ]</a>
<a href="author.html#8167">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
