<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [SL4] AI --&gt; Jobless Economy</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: [SL4] AI --&gt; Jobless Economy">
<meta name="Date" content="2004-03-10">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [SL4] AI --&gt; Jobless Economy</h1>
<!-- received="Wed Mar 10 02:22:15 2004" -->
<!-- isoreceived="20040310092215" -->
<!-- sent="Wed, 10 Mar 2004 01:22:10 -0800" -->
<!-- isosent="20040310092210" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: [SL4] AI --&gt; Jobless Economy" -->
<!-- id="68BDFDD4-7274-11D8-B794-000A95B1AFDE@objectent.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="404C27E1.80703@earthlink.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20[SL4]%20AI%20--&gt;%20Jobless%20Economy"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Wed Mar 10 2004 - 02:22:10 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8207.html">Philip Sutton: "Re: Unity of thinking &amp; the optimum physical size of thinking unit"</a>
<li><strong>Previous message:</strong> <a href="8205.html">Ben Goertzel: "RE: There are few books on AI"</a>
<li><strong>In reply to:</strong> <a href="8192.html">Charles Hixson: "Re: [SL4] AI --&gt; Jobless Economy"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8198.html">Daniel Alexandre: "New trends in Holographic Memory"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8206">[ date ]</a>
<a href="index.html#8206">[ thread ]</a>
<a href="subject.html#8206">[ subject ]</a>
<a href="author.html#8206">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I am most worried about this present slice of time where existing all 
<br>
too human oligarchies attempt to so control technology and social 
<br>
change as to preserve their power.  The level of surveillance and 
<br>
coercion required and available with accelerating technology may yet 
<br>
doom humanity before greater effective intelligence can be built, 
<br>
organized and deployed.
<br>
<p>- samantha
<br>
<p>On Mar 7, 2004, at 11:59 PM, Charles Hixson wrote:
<br>
<p><em>&gt; Philip Sutton wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt; Hi Charles,
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; I've said this in other contexts, but *I* think it bears repeating. 
</em><br>
<em>&gt;&gt;&gt; If it weren't for the actions taken by persons in power, I would 
</em><br>
<em>&gt;&gt;&gt; feel
</em><br>
<em>&gt;&gt;&gt; that all reasonable steps should be taken to slow the onset of the
</em><br>
<em>&gt;&gt;&gt; singularity.  As it is, I feel the singularity may represent our only
</em><br>
<em>&gt;&gt;&gt; hope for survival, dangerous though it is.
</em><br>
<em>&gt;&gt; Given your preamble on the dynamic of instability in the face of 
</em><br>
<em>&gt;&gt; rapid change, what makes you feel that a coercive oligarchy won't be 
</em><br>
<em>&gt;&gt; the force that actually controls the launch into the singularity ie. 
</em><br>
<em>&gt;&gt; that controls the critical bulk of computational power and other key 
</em><br>
<em>&gt;&gt; technologies?
</em><br>
<em>&gt;&gt; Cheers, Philip
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt; They may well initiate it's launch.  If they do, I feel our chances of 
</em><br>
<em>&gt; survival are worse.  But in any case, those who launch it will soon 
</em><br>
<em>&gt; lose control over it.  Soon may mean in minutes.  The course that we 
</em><br>
<em>&gt; are attempting to follow is to create an entity that will, of it's own 
</em><br>
<em>&gt; volition, make decisions that we would, if we understood the 
</em><br>
<em>&gt; situation, consider life affirming.  I don't think anyone here has the 
</em><br>
<em>&gt; illusion that control would rest with any human or group of humans.  
</em><br>
<em>&gt; At least, humans as we would recognize them today.  Multiple paths to 
</em><br>
<em>&gt; transcendence imply that in some of them the control would rest with a 
</em><br>
<em>&gt; group of entities that had once been human.  Those aren't necessarily 
</em><br>
<em>&gt; the most hopeful paths, either.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8207.html">Philip Sutton: "Re: Unity of thinking &amp; the optimum physical size of thinking unit"</a>
<li><strong>Previous message:</strong> <a href="8205.html">Ben Goertzel: "RE: There are few books on AI"</a>
<li><strong>In reply to:</strong> <a href="8192.html">Charles Hixson: "Re: [SL4] AI --&gt; Jobless Economy"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8198.html">Daniel Alexandre: "New trends in Holographic Memory"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8206">[ date ]</a>
<a href="index.html#8206">[ thread ]</a>
<a href="subject.html#8206">[ subject ]</a>
<a href="author.html#8206">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
