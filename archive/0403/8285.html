<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: De-Anthropomorphizing SL3 to SL4.</title>
<meta name="Author" content="Thomas Buckner (tcbevolver@yahoo.com)">
<meta name="Subject" content="Re: De-Anthropomorphizing SL3 to SL4.">
<meta name="Date" content="2004-03-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: De-Anthropomorphizing SL3 to SL4.</h1>
<!-- received="Wed Mar 17 19:08:51 2004" -->
<!-- isoreceived="20040318020851" -->
<!-- sent="Wed, 17 Mar 2004 18:08:49 -0800 (PST)" -->
<!-- isosent="20040318020849" -->
<!-- name="Thomas Buckner" -->
<!-- email="tcbevolver@yahoo.com" -->
<!-- subject="Re: De-Anthropomorphizing SL3 to SL4." -->
<!-- id="20040318020849.7715.qmail@web60003.mail.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="6.0.3.0.0.20040317182127.01b2b418@pop-server.satx.rr.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas Buckner (<a href="mailto:tcbevolver@yahoo.com?Subject=Re:%20De-Anthropomorphizing%20SL3%20to%20SL4."><em>tcbevolver@yahoo.com</em></a>)<br>
<strong>Date:</strong> Wed Mar 17 2004 - 19:08:49 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8286.html">Elias Sinderson: "Towards Human-level AI"</a>
<li><strong>Previous message:</strong> <a href="8284.html">Peter Voss: "a2i2 news update (seeking another 'AI Psychologist' to join team)"</a>
<li><strong>In reply to:</strong> <a href="8283.html">Damien Broderick: "Re: De-Anthropomorphizing SL3 to SL4."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8287.html">Charles Hixson: "Re: De-Anthropomorphizing SL3 to SL4."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8285">[ date ]</a>
<a href="index.html#8285">[ thread ]</a>
<a href="subject.html#8285">[ subject ]</a>
<a href="author.html#8285">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Damien Broderick &lt;<a href="mailto:thespike@satx.rr.com?Subject=Re:%20De-Anthropomorphizing%20SL3%20to%20SL4.">thespike@satx.rr.com</a>&gt; wrote:
<br>
<p><em>&gt;Robert Anton Wilson pointed toward this future event more than twenty 
</em><br>
<em>&gt;years ago inbooks such as Cosmic Trigger Vol. 1 (The Final Secret of the 
</em><br>
<em>&gt;Illuminati). He called it the Jumping Jesus Phenomenon because a 
</em><br>
<em>&gt;statistician named Anderla had noted that recorded knowledge had doubled 
</em><br>
<em>&gt;many times since the time of Jesus and that the doublings were 
</em><br>
<em>&gt;asymptotically approaching a spike only a few decades away.
</em><br>
<p>Cosmic Trigger came out in 1977, later than that in mass market paperback. 
<br>
Marooned in Realtime was serialized in 1986, but Vinge had written prior to 
<br>
that about intelligence amplification (if any of this matters).
<br>
<p><em>&gt;So when I read about Vinge a couple of years ago, I thought &quot;The techies 
</em><br>
<em>&gt;have finally caught up with RAW.&quot;
</em><br>
<p>Maybe, but then when you read about Vinge a couple of years ago, you had 
<br>
finally caught up with Vinge.
<br>
<p>Of course, Vinge makes sense, whereas Wilson's witterings about the number 
<br>
23 and other superstitious drivel makes paranoiac delusions, and some 
<br>
amusing fiction (the kind that gets adolescents all churned up with its 
<br>
daring antinomianism and naughtiness).
<br>
<p>Damien Broderick
<br>
<p><p>Yeah, I know. However, RAW is joking much of the time and doesn't necessarily believe half the 'superstitious drivel' to which you refer; one of his main themes is the near-impossibility of knowing 'what the hell is really going on.' Vinge is stronger on hard-science matters, while RAW is stronger on sociological observation. (Nobody has all the answers, except Leonardo da Vinci).
<br>
<p>Adding in other sources of fact, fiction and metaphor such as Hofstadter, Tipler, Tegmark, Lem and P. K. Dick, I have concluded that we are in essence already patterns of information, and the question of a successful transition to Singularity can be stated as follows:
<br>
<p>Does this timeline lead to a larger, coherent and stable local pattern of information wherein our patterns (and especially our freedom!) are preserved (preferably enhanced)?
<br>
<p>For comparison, a paperclip AI would be equivalent to wiping most of the present complexity and replacing it with a less 'interesting' collection of simpler patterns. (We needn't hypothesize a superior intelligence to wipe out all humans; dumb robo-mosquitoes with venom could wipe us out if they were ubiquitous).
<br>
<p>An earlier post expresses the objection that 'we will be required to change' in order to fit into whatever unimaginable world of novelty follows on the Singularity. My thought on this is that we have already changed radically from what is 'natural' for us. People aren't meant to live in cities of a million; until 10k years ago, you would have lived in a band of not much more than fifty, and known them all intimately through daily interaction. Modern social and political institutions and customs are a hopeless kludge because they were never really 'designed' from a good knowledge of the human animal, but developed through millennia of bloody trial-and-error.
<br>
<p>Which reminds me that national governments are a lot like a form of AI with citizens as intelligent nodes. You can't put a man on the moon, but the 'superorganism' (see Howard Bloom, The Lucifer Principle) we call the U.S. of A. was able to by pooling the resources of its nodes. And like it or not, any government considers us individually expendable for the greater good (or at least for the supergoals of those nodes in a position to set policy for the rest of the superorganism - see Hussein, Saddam, career of). We just might end up with a (mostly) Friendly AI which occasionally sends telegrams to its nodes: FAI regrets to inform you, Mrs. Smith, that your son was terminated for the good of the whole...
<br>
<p><p><p><p>Do you Yahoo!?
<br>
Yahoo! Mail - More reliable, more storage, less spam
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8286.html">Elias Sinderson: "Towards Human-level AI"</a>
<li><strong>Previous message:</strong> <a href="8284.html">Peter Voss: "a2i2 news update (seeking another 'AI Psychologist' to join team)"</a>
<li><strong>In reply to:</strong> <a href="8283.html">Damien Broderick: "Re: De-Anthropomorphizing SL3 to SL4."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8287.html">Charles Hixson: "Re: De-Anthropomorphizing SL3 to SL4."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8285">[ date ]</a>
<a href="index.html#8285">[ thread ]</a>
<a href="subject.html#8285">[ subject ]</a>
<a href="author.html#8285">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
