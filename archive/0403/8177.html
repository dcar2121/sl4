<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI hardware was 'Singularity Realism'</title>
<meta name="Author" content="J. Andrew Rogers (andrew@ceruleansystems.com)">
<meta name="Subject" content="Re: AI hardware was 'Singularity Realism'">
<meta name="Date" content="2004-03-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI hardware was 'Singularity Realism'</h1>
<!-- received="Sun Mar  7 10:24:31 2004" -->
<!-- isoreceived="20040307172431" -->
<!-- sent="Sun, 7 Mar 2004 09:24:25 -0800" -->
<!-- isosent="20040307172425" -->
<!-- name="J. Andrew Rogers" -->
<!-- email="andrew@ceruleansystems.com" -->
<!-- subject="Re: AI hardware was 'Singularity Realism'" -->
<!-- id="48055439-705C-11D8-BF2F-003065C9EC00@ceruleansystems.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="5.1.0.14.0.20040306165618.02e36840@pop.bloor.is.net.cable.rogers.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> J. Andrew Rogers (<a href="mailto:andrew@ceruleansystems.com?Subject=Re:%20AI%20hardware%20was%20'Singularity%20Realism'"><em>andrew@ceruleansystems.com</em></a>)<br>
<strong>Date:</strong> Sun Mar 07 2004 - 10:24:25 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8178.html">J. Andrew Rogers: "Re: AI hardware was 'Singularity Realism'"</a>
<li><strong>Previous message:</strong> <a href="8176.html">Keith Henson: "Looking for a name (bit off topic perhaps)"</a>
<li><strong>In reply to:</strong> <a href="8165.html">Keith Henson: "RE: AI hardware was 'Singularity Realism'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8183.html">Keith Henson: "Re: AI hardware was 'Singularity Realism'"</a>
<li><strong>Reply:</strong> <a href="8183.html">Keith Henson: "Re: AI hardware was 'Singularity Realism'"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8177">[ date ]</a>
<a href="index.html#8177">[ thread ]</a>
<a href="subject.html#8177">[ subject ]</a>
<a href="author.html#8177">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Mar 6, 2004, at 2:17 PM, Keith Henson wrote:
<br>
<em>&gt; That's not surprising considering how much computational power biology 
</em><br>
<em>&gt; lavishes on the problem.  Have you ever looked up the MIPS rating of a 
</em><br>
<em>&gt; retina?
</em><br>
<p><p>The focus on the amount of computing power required to simulate biology 
<br>
is a bit of a strawman in the AGI argument because it asserts a 
<br>
necessarily asymmetric system and then marvels at the asymmetry without 
<br>
recognizing that it *is* an asymmetry.  Modeling any bulk system (like 
<br>
a retina) is exponentially more expensive than modeling the algorithmic 
<br>
machine that generates the state.
<br>
<p>Simulating biology at this level is akin to using a lookup table for 
<br>
the first 10^40 digits of pi rather than using the BBP algorithm to 
<br>
generate the digits you need.  And the lookup table is only a 
<br>
relatively poor approximation of pi, unlike BBP.
<br>
<p>Any serious AI effort would have to approach it from the standpoint of 
<br>
implementing the underlying algorithmic machinery of intelligence.  Not 
<br>
only is this approach tractable, it is also a hell of a lot more likely 
<br>
to yield useful results than chasing a ghost that most everyone 
<br>
acknowledges is both intractable and a poor theoretical approximation 
<br>
in the best case.
<br>
<p>And to answer a previous question, I would say that today we (&quot;we&quot; in 
<br>
the sense of anyone who bothers to study the theoretical issue of AGI) 
<br>
have a pretty good idea of what is going on in the underlying 
<br>
algorithmic machinery of intelligence.  The grasp isn't perfect and 
<br>
there are some implementation issues, but no real theoretical 
<br>
show-stoppers that I can see, and that there are several other people 
<br>
working on implementations in the same general area seems to indicate 
<br>
that many other people versed on the subject don't see any serious 
<br>
show-stoppers either. I'm am cognizant of the history of the field, but 
<br>
I think we have something actually close to a real and usable 
<br>
foundation these days.
<br>
<p><p><em>&gt; I happen to be a bit skeptical that the hardware is up to the task 
</em><br>
<em>&gt; based on arguments by Hans Moravec, Ray Kurzweil and others.  In the 
</em><br>
<em>&gt; long run this is not a problem since hardware equal to the task is 
</em><br>
<em>&gt; less than a human generation away.  If you have a radical approach 
</em><br>
<em>&gt; that would allow cockroach level hardware to generate superhuman AI 
</em><br>
<em>&gt; level performance, I would sure like to know what it is.
</em><br>
<p><p>Almost any approach that ignores biology and goes to the math will be 
<br>
MANY orders of magnitude more scalable and capable on a given piece of 
<br>
hardware.  Moravec, Kurzweil, and others have biology blinders on, and 
<br>
I think it is fairly trivial to show that their view is predicated on 
<br>
some specific assumptions that arguably don't apply in the general 
<br>
case.
<br>
<p>For most of the non-biology AGI projects out there, there seems to be 
<br>
some consensus that commodity hardware is within an order of magnitude 
<br>
of what is needed to build human-level intelligence, and that this 
<br>
&quot;order of magnitude&quot; is not a moving target i.e. experience shows that 
<br>
we are actually closing on the necessary hardware.  The specifics of 
<br>
the hardware limitations vary from implementation to implementation, 
<br>
but no one seems to be saying that the hardware is horribly inadequate 
<br>
to do a functional implementation.
<br>
<p>j. andrew rogers
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8178.html">J. Andrew Rogers: "Re: AI hardware was 'Singularity Realism'"</a>
<li><strong>Previous message:</strong> <a href="8176.html">Keith Henson: "Looking for a name (bit off topic perhaps)"</a>
<li><strong>In reply to:</strong> <a href="8165.html">Keith Henson: "RE: AI hardware was 'Singularity Realism'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8183.html">Keith Henson: "Re: AI hardware was 'Singularity Realism'"</a>
<li><strong>Reply:</strong> <a href="8183.html">Keith Henson: "Re: AI hardware was 'Singularity Realism'"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8177">[ date ]</a>
<a href="index.html#8177">[ thread ]</a>
<a href="subject.html#8177">[ subject ]</a>
<a href="author.html#8177">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
