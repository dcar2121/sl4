<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Compassion vs Respect; Exponential discounting of utility (was Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI)</title>
<meta name="Author" content="Joshua Fox (joshua@joshuafox.com)">
<meta name="Subject" content="Re: Compassion vs Respect; Exponential discounting of utility (was Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI)">
<meta name="Date" content="2007-12-11">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Compassion vs Respect; Exponential discounting of utility (was Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI)</h1>
<!-- received="Tue Dec 11 03:18:28 2007" -->
<!-- isoreceived="20071211101828" -->
<!-- sent="Tue, 11 Dec 2007 12:15:16 +0200" -->
<!-- isosent="20071211101516" -->
<!-- name="Joshua Fox" -->
<!-- email="joshua@joshuafox.com" -->
<!-- subject="Re: Compassion vs Respect; Exponential discounting of utility (was Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI)" -->
<!-- id="8760b3f20712110215jcfdef6av75908b6f859368de@mail.gmail.com" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="20071209172714.22097D28BA@fungible.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Joshua Fox (<a href="mailto:joshua@joshuafox.com?Subject=Re:%20Compassion%20vs%20Respect;%20Exponential%20discounting%20of%20utility%20(was%20Re:%20Building%20a%20friendly%20AI%20from%20a%20&quot;just%20do%20what%20I%20tell%20you&quot;%20AI)"><em>joshua@joshuafox.com</em></a>)<br>
<strong>Date:</strong> Tue Dec 11 2007 - 03:15:16 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17392.html">Mike Dougherty: "Re: Compassion vs Respect; Exponential discounting of utility (was Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI)"</a>
<li><strong>Previous message:</strong> <a href="17390.html">CyTG: "Re: Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>In reply to:</strong> <a href="17386.html">Tim Freeman: "Compassion vs Respect; Exponential discounting of utility (was Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17392.html">Mike Dougherty: "Re: Compassion vs Respect; Exponential discounting of utility (was Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI)"</a>
<li><strong>Reply:</strong> <a href="17392.html">Mike Dougherty: "Re: Compassion vs Respect; Exponential discounting of utility (was Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17391">[ date ]</a>
<a href="index.html#17391">[ thread ]</a>
<a href="subject.html#17391">[ subject ]</a>
<a href="author.html#17391">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Tim,
<br>
<p>Thanks for those answers.
<br>
<p>Here are my thoughts. I hope they help.
<br>
<p><p><em>&gt; Having respect equal to compassion (and therefore not having to
</em><br>
<em>&gt; distinguish between them) is the alternative Joshua is talking about. An AI
</em><br>
<em>&gt; with these settings would tend to do &quot;Robin Hood&quot; type behavior, taking from
</em><br>
<em>&gt; one person to give to someone else who needs the resources  a little bit
</em><br>
<em>&gt; more.  These involuntary transfers could be money, internal organs, or
</em><br>
<em>&gt; anything else of value.  Well-informed people who value having higher status
</em><br>
<em>&gt; than their neighbors, and who are winning that game at the moment, would
</em><br>
<em>&gt; want to get rid of the AI.
</em><br>
<p><p>Humans sometimes have a bias towards inaction (&quot;leave well enough alone,&quot;
<br>
&quot;the devil you know,&quot; the precautionary principle, sin of commission is
<br>
worse than a sin of omission), because of worries about human intentions --
<br>
we don't trust people. Also, in any given state, the total space of worse
<br>
choices is greater than the space of better choices. People would rather
<br>
hang on to the known quantities they have rather than risk the unknowns.
<br>
<p>As you say, to the extent that the AI must interact with humans, this makes
<br>
sense for the AI. But beyond that, isn't this a bias, and therefore less
<br>
than rational?
<br>
<p>Exponential discounting fixes the odd behaviors you list, but it adds
<br>
<em>&gt; others.  If the AI discounts it's utility at 10% per year, and the economy
</em><br>
<em>&gt; measured in dollars is growing at 20% per year, and the dollar cost of
</em><br>
<em>&gt; utility is constant, then the AI will defer all gratification
</em><br>
<em>&gt; until circumstances change.  The people who the AI is nominally serving
</em><br>
<em>&gt; might not like that.
</em><br>
<p><p>But  the AI has respect/compassion, and so would take into account the
<br>
humans' own discount rate -- in this case that would imply not deferring the
<br>
action so much.
<br>
<p>Joshua
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17392.html">Mike Dougherty: "Re: Compassion vs Respect; Exponential discounting of utility (was Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI)"</a>
<li><strong>Previous message:</strong> <a href="17390.html">CyTG: "Re: Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>In reply to:</strong> <a href="17386.html">Tim Freeman: "Compassion vs Respect; Exponential discounting of utility (was Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17392.html">Mike Dougherty: "Re: Compassion vs Respect; Exponential discounting of utility (was Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI)"</a>
<li><strong>Reply:</strong> <a href="17392.html">Mike Dougherty: "Re: Compassion vs Respect; Exponential discounting of utility (was Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17391">[ date ]</a>
<a href="index.html#17391">[ thread ]</a>
<a href="subject.html#17391">[ subject ]</a>
<a href="author.html#17391">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:01 MDT
</em></small></p>
</body>
</html>
