<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI, just do what I tell you to</title>
<meta name="Author" content="Stathis Papaioannou (stathisp@gmail.com)">
<meta name="Subject" content="Re: AI, just do what I tell you to">
<meta name="Date" content="2007-10-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI, just do what I tell you to</h1>
<!-- received="Tue Oct 30 17:41:33 2007" -->
<!-- isoreceived="20071030234133" -->
<!-- sent="Wed, 31 Oct 2007 10:39:07 +1100" -->
<!-- isosent="20071030233907" -->
<!-- name="Stathis Papaioannou" -->
<!-- email="stathisp@gmail.com" -->
<!-- subject="Re: AI, just do what I tell you to" -->
<!-- id="f21c22e30710301639l1be62ffelc9b284ef7976b0c1@mail.gmail.com" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="c528628a0710301423s6a6ea75ey4d25391e0711856c@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Stathis Papaioannou (<a href="mailto:stathisp@gmail.com?Subject=Re:%20AI,%20just%20do%20what%20I%20tell%20you%20to"><em>stathisp@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Oct 30 2007 - 17:39:07 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16972.html">Peter de Blanc: "Re: AI, just do what I tell you to"</a>
<li><strong>Previous message:</strong> <a href="16970.html">Stathis Papaioannou: "Re: AI, just do what I tell you to"</a>
<li><strong>In reply to:</strong> <a href="16968.html">Nick Hay: "Re: AI, just do what I tell you to"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16969.html">Matt Mahoney: "Re: AI, just do what I tell you to"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16971">[ date ]</a>
<a href="index.html#16971">[ thread ]</a>
<a href="subject.html#16971">[ subject ]</a>
<a href="author.html#16971">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 31/10/2007, Nick Hay &lt;<a href="mailto:nickjhay@gmail.com?Subject=Re:%20AI,%20just%20do%20what%20I%20tell%20you%20to">nickjhay@gmail.com</a>&gt; wrote:
<br>
<p><em>&gt; On 10/30/07, Stathis Papaioannou &lt;<a href="mailto:stathisp@gmail.com?Subject=Re:%20AI,%20just%20do%20what%20I%20tell%20you%20to">stathisp@gmail.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt; The AI should always remain in character as the ideal expert.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Why?  This is aiming pretty low if we are considering a smarter than
</em><br>
<em>&gt; human AI.  If we're not, then you probably can't implement CEV
</em><br>
<em>&gt; anywhere (probably = maybe, there are tricks I don't know).  It's not
</em><br>
<em>&gt; even clear this is useful for less intelligent AIs.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Are you saying an ideal expert would have competing motives?  That's
</em><br>
<em>&gt; far from my idea of ideal.
</em><br>
<p>No, an ideal expert is one who (a) has perfect knowledge of their
<br>
field, and (b) has no competing interests of their own.
<br>
<p><em>&gt; &gt; We've had to deal with problems like this throughout history anyway.
</em><br>
<em>&gt; &gt; Consider nuclear weapons, and the people who might have urged their
</em><br>
<em>&gt; &gt; use in the belief that a pre-emptive strike against the other side was
</em><br>
<em>&gt; &gt; a good idea. What we rely on is that humanity collectively will do the
</em><br>
<em>&gt; &gt; right thing. This will apply to AI's as well, when there are many of
</em><br>
<em>&gt; &gt; them all monitoring and policing each other, as they have been
</em><br>
<em>&gt; &gt; programmed to do. If one rogue human with an AI can easily do terrible
</em><br>
<em>&gt; &gt; things despite this, then we are doomed, and no attempt to ensure that
</em><br>
<em>&gt; &gt; each AI comes out of the factory friendly will work.
</em><br>
<em>&gt;
</em><br>
<em>&gt; In that scenario we may well be doomed.  But perhaps we can build an
</em><br>
<em>&gt; AI which uses the first mover advantage to protect against later rogue
</em><br>
<em>&gt; AIs.  If one AI can do terrible things maybe another AI can do
</em><br>
<em>&gt; terrific things.
</em><br>
<p>With every other powerful human invention it has been the fact that
<br>
other competing interests have eventually gained access to the
<br>
technology that has prevented absolute world domination by one party,
<br>
not the benevolence of the original inventor. I would be far more
<br>
comfortable if multiple AI's with a variety of competing interests
<br>
arose at about the same time than if the first AI quickly gained
<br>
primacy, no matter how carefully guaranteed the friendliness of that
<br>
first AI was. Of course, wishing it does not mean it will be so.
<br>
<p><p><p><pre>
-- 
Stathis Papaioannou
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16972.html">Peter de Blanc: "Re: AI, just do what I tell you to"</a>
<li><strong>Previous message:</strong> <a href="16970.html">Stathis Papaioannou: "Re: AI, just do what I tell you to"</a>
<li><strong>In reply to:</strong> <a href="16968.html">Nick Hay: "Re: AI, just do what I tell you to"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16969.html">Matt Mahoney: "Re: AI, just do what I tell you to"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16971">[ date ]</a>
<a href="index.html#16971">[ thread ]</a>
<a href="subject.html#16971">[ subject ]</a>
<a href="author.html#16971">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
