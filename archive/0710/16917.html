<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?</title>
<meta name="Author" content="Vladimir Nesov (robotact@mail.ru)">
<meta name="Subject" content="Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?">
<meta name="Date" content="2007-10-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?</h1>
<!-- received="Tue Oct 23 20:29:47 2007" -->
<!-- isoreceived="20071024022947" -->
<!-- sent="Wed, 24 Oct 2007 06:27:38 +0400" -->
<!-- isosent="20071024022738" -->
<!-- name="Vladimir Nesov" -->
<!-- email="robotact@mail.ru" -->
<!-- subject="Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?" -->
<!-- id="b54769d90710231927t6d88ca5fy35c465bb7616a869@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="b54769d90710231839h29d84d45s57c4ca1f3ab76605@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Vladimir Nesov (<a href="mailto:robotact@mail.ru?Subject=Re:%20Is%20there%20evidence%20for,%20&quot;Humans%20are%20going%20to%20create%20an%20AI,&quot;%20to%20be%20a%20probable%20hypothesis?"><em>robotact@mail.ru</em></a>)<br>
<strong>Date:</strong> Tue Oct 23 2007 - 20:27:38 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16918.html">William Pearson: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Previous message:</strong> <a href="16916.html">Eliezer S. Yudkowsky: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Maybe in reply to:</strong> <a href="16914.html">William Pearson: "Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16919.html">Benjamin Goertzel: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16917">[ date ]</a>
<a href="index.html#16917">[ thread ]</a>
<a href="subject.html#16917">[ subject ]</a>
<a href="author.html#16917">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Do you consider brain-on-transistors way improbable? In some decades
<br>
technology should allow at least destructive by-layer brain scanning, so
<br>
that brain then can be reimplemented on a different substrate to run 1000
<br>
times faster, which should be almost as good singularity-wise.
<br>
<p>On 10/24/07, William Pearson &lt;<a href="mailto:wil.pearson@gmail.com?Subject=Re:%20Is%20there%20evidence%20for,%20&quot;Humans%20are%20going%20to%20create%20an%20AI,&quot;%20to%20be%20a%20probable%20hypothesis?">wil.pearson@gmail.com</a>&gt; wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; I can't currently get around the problem that we haven't had any
</em><br>
<em>&gt; instances of this happening. In a way we have had negative instances
</em><br>
<em>&gt; of some hypotheses involving AI, e.g. each planck time we don't create
</em><br>
<em>&gt; a realistic intelligence could be counted as evidence that we won't
</em><br>
<em>&gt; create one in the next planck second (and this hypothesis is very
</em><br>
<em>&gt; reliable, to date). And by induction it is not probable to create one
</em><br>
<em>&gt; in any planck time. And until we do create one, we shouldn't have a
</em><br>
<em>&gt; reason for increasing the probability of one being created, and we
</em><br>
<em>&gt; should be forever decreasing it.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Now you could argue that the probability of creating an AI in any
</em><br>
<em>&gt; given time period is independent of one another. We have no evidence
</em><br>
<em>&gt; for this meta-hypothesis either, due to not having created an AI for
</em><br>
<em>&gt; us to analyse the distributions of how they are created. Although we
</em><br>
<em>&gt; have a fair amount of evidence that is consistent with the hypothesis
</em><br>
<em>&gt; that the probability of creating an AI not independent of time, and
</em><br>
<em>&gt; just very low.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Possibly you could look at the number of people that have put there
</em><br>
<em>&gt; mind to creating something new, and see how many actually achieved
</em><br>
<em>&gt; there goal. How to get a good delineation of what to include as
</em><br>
<em>&gt; evidence would be problematic in this case (e.g. should the alchemists
</em><br>
<em>&gt; and there philosopher's stone be counted), and it is likely that we
</em><br>
<em>&gt; will have far more evidence of people being successful compared to the
</em><br>
<em>&gt; number of unknown failures.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Or the kurzweil way, which I will paraphrase as: Defining AI as part
</em><br>
<em>&gt; of the type of computer system with a high resource usage and showing
</em><br>
<em>&gt; that the hypothesis that we have been increasing the resources
</em><br>
<em>&gt; available of computer systems by a certain rate over time has a lot of
</em><br>
<em>&gt; evidence. Now I don't like this one much, because while we have
</em><br>
<em>&gt; evidence we will increase resources available to computers, there is
</em><br>
<em>&gt; no evidence we will create the right computer system for intelligence
</em><br>
<em>&gt; given sufficient resources.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Is there any principled way of deciding which way of calculating the
</em><br>
<em>&gt; probability of humans creating AI is the better to base decisions off?
</em><br>
<em>&gt; PTL?
</em><br>
<em>&gt;
</em><br>
<em>&gt; Now my knowledge of bayesian decision theory is rusty, so it may well
</em><br>
<em>&gt; be that I am missing something or my analyses are faulty. Any pointers
</em><br>
<em>&gt; to things already written? And note I am looking for a body of data I
</em><br>
<em>&gt; could feed to a Bayesian classifier, so no general human type
</em><br>
<em>&gt; arguments for AI.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Will Pearson
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<p><pre>
-- 
Vladimir Nesov                            mailto:<a href="mailto:robotact@gmail.com?Subject=Re:%20Is%20there%20evidence%20for,%20&quot;Humans%20are%20going%20to%20create%20an%20AI,&quot;%20to%20be%20a%20probable%20hypothesis?">robotact@gmail.com</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16918.html">William Pearson: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Previous message:</strong> <a href="16916.html">Eliezer S. Yudkowsky: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Maybe in reply to:</strong> <a href="16914.html">William Pearson: "Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16919.html">Benjamin Goertzel: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16917">[ date ]</a>
<a href="index.html#16917">[ thread ]</a>
<a href="subject.html#16917">[ subject ]</a>
<a href="author.html#16917">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
