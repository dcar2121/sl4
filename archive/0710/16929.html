<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?</title>
<meta name="Author" content="William Pearson (wil.pearson@gmail.com)">
<meta name="Subject" content="Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?">
<meta name="Date" content="2007-10-25">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?</h1>
<!-- received="Thu Oct 25 09:46:28 2007" -->
<!-- isoreceived="20071025154628" -->
<!-- sent="Thu, 25 Oct 2007 16:45:09 +0100" -->
<!-- isosent="20071025154509" -->
<!-- name="William Pearson" -->
<!-- email="wil.pearson@gmail.com" -->
<!-- subject="Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?" -->
<!-- id="ab5bcc90710250845h18b1ed0s49e35a1c30e0b235@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="79ecaa350710241932g50001452k368f11f8c6129ded@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> William Pearson (<a href="mailto:wil.pearson@gmail.com?Subject=Re:%20Is%20there%20evidence%20for,%20&quot;Humans%20are%20going%20to%20create%20an%20AI,&quot;%20to%20be%20a%20probable%20hypothesis?"><em>wil.pearson@gmail.com</em></a>)<br>
<strong>Date:</strong> Thu Oct 25 2007 - 09:45:09 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16930.html">Robin Brandt: "Re: Hacking your own motivational and emotional systems, how dangerous?"</a>
<li><strong>Previous message:</strong> <a href="16928.html">Byrne Hobart: "Re: Hacking your own motivational and emotional systems, how dangerous?"</a>
<li><strong>In reply to:</strong> <a href="16925.html">Rolf Nelson: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16917.html">Vladimir Nesov: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16929">[ date ]</a>
<a href="index.html#16929">[ thread ]</a>
<a href="subject.html#16929">[ subject ]</a>
<a href="author.html#16929">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 25/10/2007, Rolf Nelson &lt;<a href="mailto:rolf.h.d.nelson@gmail.com?Subject=Re:%20Is%20there%20evidence%20for,%20&quot;Humans%20are%20going%20to%20create%20an%20AI,&quot;%20to%20be%20a%20probable%20hypothesis?">rolf.h.d.nelson@gmail.com</a>&gt; wrote:
<br>
<em>&gt; Bayesian reasoning involves determining a prior probability &quot;before you've
</em><br>
<em>&gt; considered the data&quot;, and then getting a final posterior probability by
</em><br>
<em>&gt; shifting based on the data you've collected. It can be applied if you have
</em><br>
<em>&gt; 2000 data points, or if you have 2 data points, or even if you have 0 data
</em><br>
<em>&gt; points (in which case the posterior probability remains trivially equal to
</em><br>
<em>&gt; the prior probability.)
</em><br>
<p>Thinking that it is probable that humans will create AI, is not part
<br>
of humanities prior, we have all acquired that belief in one way or
<br>
another. My question was partially a test of the bayesian view of
<br>
intelligent agents, as well as an honest inquiry because I do like
<br>
statistics and backing up my beliefs.
<br>
<p>If  there was a belief that had been acquired (so not in their prior)
<br>
by a group of people, that I could not find a way to collect evidence
<br>
that should have adjusted their prior, I would have had to have
<br>
concluded one of three things.
<br>
<p>1) It is acceptable for intelligences to acquire beliefs in the high
<br>
probability of events that there has been no statistical evidence for.
<br>
<p>1.1) Which would mean that the view that, bayesian reasoning is all we
<br>
need to explain what intelligences should do, is lacking.
<br>
<p>2) They were thinking incorrectly and shouldn't have held that belief.
<br>
<p>3) There is other evidence I am missing.
<br>
<p>It turned out to be number 3, in this case. However, in order to be
<br>
able to say there is evidence for AI to be probable, I would need to
<br>
do some actual stats on how well the success rate of inventors is
<br>
correlated and whether you can justify predictions about future
<br>
inventions of certain types (bio-mimetic ones for example) from past
<br>
successes. But at least you can hypothesise that society as a whole
<br>
has done something like that in an unconscious fashion. Our beliefs
<br>
about AI being probable in this case being received wisdom, of the
<br>
good sort.
<br>
<p>&nbsp;Will Pearson
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16930.html">Robin Brandt: "Re: Hacking your own motivational and emotional systems, how dangerous?"</a>
<li><strong>Previous message:</strong> <a href="16928.html">Byrne Hobart: "Re: Hacking your own motivational and emotional systems, how dangerous?"</a>
<li><strong>In reply to:</strong> <a href="16925.html">Rolf Nelson: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16917.html">Vladimir Nesov: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16929">[ date ]</a>
<a href="index.html#16929">[ thread ]</a>
<a href="subject.html#16929">[ subject ]</a>
<a href="author.html#16929">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
