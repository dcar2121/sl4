<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?</title>
<meta name="Author" content="William Pearson (wil.pearson@gmail.com)">
<meta name="Subject" content="Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?">
<meta name="Date" content="2007-10-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?</h1>
<!-- received="Tue Oct 23 17:59:59 2007" -->
<!-- isoreceived="20071023235959" -->
<!-- sent="Wed, 24 Oct 2007 00:58:27 +0100" -->
<!-- isosent="20071023235827" -->
<!-- name="William Pearson" -->
<!-- email="wil.pearson@gmail.com" -->
<!-- subject="Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?" -->
<!-- id="ab5bcc90710231658y238c894cva44c64d72f8983f9@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> William Pearson (<a href="mailto:wil.pearson@gmail.com?Subject=Re:%20Is%20there%20evidence%20for,%20&quot;Humans%20are%20going%20to%20create%20an%20AI,&quot;%20to%20be%20a%20probable%20hypothesis?"><em>wil.pearson@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Oct 23 2007 - 17:58:27 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16915.html">Thomas McCabe: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Previous message:</strong> <a href="16913.html">Eliezer S. Yudkowsky: "Yudkowsky's reply (was: Minsky's Transcript)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16915.html">Thomas McCabe: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Reply:</strong> <a href="16915.html">Thomas McCabe: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Reply:</strong> <a href="16916.html">Eliezer S. Yudkowsky: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Maybe reply:</strong> <a href="16917.html">Vladimir Nesov: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Reply:</strong> <a href="16919.html">Benjamin Goertzel: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Reply:</strong> <a href="16924.html">Kaj Sotala: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16914">[ date ]</a>
<a href="index.html#16914">[ thread ]</a>
<a href="subject.html#16914">[ subject ]</a>
<a href="author.html#16914">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I can't currently get around the problem that we haven't had any
<br>
instances of this happening. In a way we have had negative instances
<br>
of some hypotheses involving AI, e.g. each planck time we don't create
<br>
a realistic intelligence could be counted as evidence that we won't
<br>
create one in the next planck second (and this hypothesis is very
<br>
reliable, to date). And by induction it is not probable to create one
<br>
in any planck time. And until we do create one, we shouldn't have a
<br>
reason for increasing the probability of one being created, and we
<br>
should be forever decreasing it.
<br>
<p>Now you could argue that the probability of creating an AI in any
<br>
given time period is independent of one another. We have no evidence
<br>
for this meta-hypothesis either, due to not having created an AI for
<br>
us to analyse the distributions of how they are created. Although we
<br>
have a fair amount of evidence that is consistent with the hypothesis
<br>
that the probability of creating an AI not independent of time, and
<br>
just very low.
<br>
<p>Possibly you could look at the number of people that have put there
<br>
mind to creating something new, and see how many actually achieved
<br>
there goal. How to get a good delineation of what to include as
<br>
evidence would be problematic in this case (e.g. should the alchemists
<br>
and there philosopher's stone be counted), and it is likely that we
<br>
will have far more evidence of people being successful compared to the
<br>
number of unknown failures.
<br>
<p>Or the kurzweil way, which I will paraphrase as: Defining AI as part
<br>
of the type of computer system with a high resource usage and showing
<br>
that the hypothesis that we have been increasing the resources
<br>
available of computer systems by a certain rate over time has a lot of
<br>
evidence. Now I don't like this one much, because while we have
<br>
evidence we will increase resources available to computers, there is
<br>
no evidence we will create the right computer system for intelligence
<br>
given sufficient resources.
<br>
<p>Is there any principled way of deciding which way of calculating the
<br>
probability of humans creating AI is the better to base decisions off?
<br>
PTL?
<br>
<p>Now my knowledge of bayesian decision theory is rusty, so it may well
<br>
be that I am missing something or my analyses are faulty. Any pointers
<br>
to things already written? And note I am looking for a body of data I
<br>
could feed to a Bayesian classifier, so no general human type
<br>
arguments for AI.
<br>
<p>&nbsp;Will Pearson
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16915.html">Thomas McCabe: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Previous message:</strong> <a href="16913.html">Eliezer S. Yudkowsky: "Yudkowsky's reply (was: Minsky's Transcript)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16915.html">Thomas McCabe: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Reply:</strong> <a href="16915.html">Thomas McCabe: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Reply:</strong> <a href="16916.html">Eliezer S. Yudkowsky: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Maybe reply:</strong> <a href="16917.html">Vladimir Nesov: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Reply:</strong> <a href="16919.html">Benjamin Goertzel: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<li><strong>Reply:</strong> <a href="16924.html">Kaj Sotala: "Re: Is there evidence for, &quot;Humans are going to create an AI,&quot; to be a probable hypothesis?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16914">[ date ]</a>
<a href="index.html#16914">[ thread ]</a>
<a href="subject.html#16914">[ subject ]</a>
<a href="author.html#16914">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:58 MDT
</em></small></p>
</body>
</html>
