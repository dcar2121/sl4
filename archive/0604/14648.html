<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI Goals [WAS Re: The Singularity vs. the Wall]</title>
<meta name="Author" content="micah glasser (micahglasser@gmail.com)">
<meta name="Subject" content="Re: AI Goals [WAS Re: The Singularity vs. the Wall]">
<meta name="Date" content="2006-04-27">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI Goals [WAS Re: The Singularity vs. the Wall]</h1>
<!-- received="Thu Apr 27 23:12:43 2006" -->
<!-- isoreceived="20060428051243" -->
<!-- sent="Fri, 28 Apr 2006 01:12:24 -0400" -->
<!-- isosent="20060428051224" -->
<!-- name="micah glasser" -->
<!-- email="micahglasser@gmail.com" -->
<!-- subject="Re: AI Goals [WAS Re: The Singularity vs. the Wall]" -->
<!-- id="23bd28ec0604272212ne0aadf3u6ad310d967bf596a@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="62c14240604261527h37adbfacx77693b85a3c108db@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> micah glasser (<a href="mailto:micahglasser@gmail.com?Subject=Re:%20AI%20Goals%20[WAS%20Re:%20The%20Singularity%20vs.%20the%20Wall]"><em>micahglasser@gmail.com</em></a>)<br>
<strong>Date:</strong> Thu Apr 27 2006 - 23:12:24 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="14649.html">Bob Seidensticker: "Re: Anti-singularity spam."</a>
<li><strong>Previous message:</strong> <a href="14647.html">Dani Eder: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<li><strong>In reply to:</strong> <a href="14637.html">Mike Dougherty: "Re: AI Goals [WAS Re: The Singularity vs. the Wall]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14587.html">Jeff Medina: "Re: The Singularity vs. the Wall"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14648">[ date ]</a>
<a href="index.html#14648">[ thread ]</a>
<a href="subject.html#14648">[ subject ]</a>
<a href="author.html#14648">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
In response to Mike I would add that there is also no reason why future IA
<br>
humans who are networked with each other via and with AI would not also
<br>
represent a single entity. I think this is Kurzweil's reasoning for speaking
<br>
about a Human-Machine civilization. I agree with Kurzweil on this point.
<br>
This line of reasoning (in my mind) follows from the notion of a fully
<br>
automated economy coordinated through an artificial intelligence which also
<br>
maintains the equilibrium of the biosphere. I think that the infrastructure
<br>
for such an economy/ SE singularity machine (as Woody says) is a natural
<br>
part of the course of technological-memetic evolution. If this idea is
<br>
correct then the memetic-technological evolution of the human species and
<br>
the evolution of AI is one and the same (which is actually the evolution of
<br>
the human-machine civilization).
<br>
I realize that such thinking is unpopular with SIAI which seems to stress
<br>
human action (which I am all for), however I have come to this sort of
<br>
thinking (which stresses cosmic development and biological evolution) as a
<br>
logical conclusion of the scientific world-view. What I mean to say is that
<br>
I think more emphasis should be placed on the fact that technology
<br>
(including all AI) is a natural part of the development of the cosmos and
<br>
the evolution of life on earth, and as such, we should attempt to understand
<br>
AI and what kinds of 'goals' it will have or should have in this light. If
<br>
we cannot do this our envisioning of AI goals will be myopic.
<br>
<p>On 4/26/06, Mike Dougherty &lt;<a href="mailto:msd001@gmail.com?Subject=Re:%20AI%20Goals%20[WAS%20Re:%20The%20Singularity%20vs.%20the%20Wall]">msd001@gmail.com</a>&gt; wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; I suggest that there will only be one AGI in the same way an ET would
</em><br>
<em>&gt; refer to the first human they encounter as being representative of
</em><br>
<em>&gt; Humanity.
</em><br>
<em>&gt;
</em><br>
<em>&gt; 1.  Any AGI that follows the first will be viewed as so similar to the
</em><br>
<em>&gt; first as to be indistinguishable.
</em><br>
<em>&gt; 2.  Any self-directed AGI would likely be able to recognize another as a
</em><br>
<em>&gt; resource in the same way that other humans are limited resources or that the
</em><br>
<em>&gt; Internet is a resource.  Assuming the interconnect between two AGI is
</em><br>
<em>&gt; high-bandwidth and low latency, there is no reason why our communication
</em><br>
<em>&gt; with either one of them would not immediately aggregate the knowledge base
</em><br>
<em>&gt; of both or them.  This aggregation would either happen as a result of our
</em><br>
<em>&gt; own double-checking, or they would &quot;compare notes&quot; with each other in an
</em><br>
<em>&gt; effort to evaluate answer fitness.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If the AGI is based on a distributed architecture such that any sub-system
</em><br>
<em>&gt; is an &quot;expert&quot; at a limited range of knowledge, with the collective whole
</em><br>
<em>&gt; being &quot;the AGI&quot; - then conversing with a single sub-system is an unfair
</em><br>
<em>&gt; measure of the whole in the way that analyzing a single neuron is an unfair
</em><br>
<em>&gt; measure of the function of our entire brain.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Sorry that until this sentence I did not mention &quot;Goal System&quot; or an
</em><br>
<em>&gt; acronymic buzzword  :)
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; On 4/25/06, Richard Loosemore &lt;<a href="mailto:rpwl@lightlink.com?Subject=Re:%20AI%20Goals%20[WAS%20Re:%20The%20Singularity%20vs.%20the%20Wall]">rpwl@lightlink.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Here is another subtle issue:  is there going to be one AGI, or are
</em><br>
<em>&gt; &gt; there going to be thousands/millions/billions of them?  The assumption
</em><br>
<em>&gt; &gt; always seems to be &quot;lots of them,&quot; but is this realistic?  It might well
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; be only on AGI, with large numbers of drones that carry out dumb donkey
</em><br>
<em>&gt; &gt; work for the central AGI.  Now in that case, you suddenly get a
</em><br>
<em>&gt; &gt; situation in which there are no collective effects of conflicting
</em><br>
<em>&gt; &gt; motivations among the members of the AGI species.  At the very least,
</em><br>
<em>&gt; &gt; all the questions about goals and species dominance get changed by this
</em><br>
<em>&gt; &gt; one-AGI scenario, and yet people make the default assumption that this
</em><br>
<em>&gt; &gt; is not going to happen:  I think it very likely indeed.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<p><p><pre>
--
I swear upon the alter of God, eternal hostility to every form of tyranny
over the mind of man. - Thomas Jefferson
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="14649.html">Bob Seidensticker: "Re: Anti-singularity spam."</a>
<li><strong>Previous message:</strong> <a href="14647.html">Dani Eder: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<li><strong>In reply to:</strong> <a href="14637.html">Mike Dougherty: "Re: AI Goals [WAS Re: The Singularity vs. the Wall]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14587.html">Jeff Medina: "Re: The Singularity vs. the Wall"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14648">[ date ]</a>
<a href="index.html#14648">[ thread ]</a>
<a href="subject.html#14648">[ subject ]</a>
<a href="author.html#14648">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
