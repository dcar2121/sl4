<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI Goals</title>
<meta name="Author" content="Woody Long (ironanchorpress@earthlink.net)">
<meta name="Subject" content="Re: AI Goals">
<meta name="Date" content="2006-04-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI Goals</h1>
<!-- received="Wed Apr 26 13:34:00 2006" -->
<!-- isoreceived="20060426193400" -->
<!-- sent="Wed, 26 Apr 2006 15:31:58 -0400" -->
<!-- isosent="20060426193158" -->
<!-- name="Woody Long" -->
<!-- email="ironanchorpress@earthlink.net" -->
<!-- subject="Re: AI Goals" -->
<!-- id="410-22006432619315846@earthlink.net" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="AI Goals" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Woody Long (<a href="mailto:ironanchorpress@earthlink.net?Subject=Re:%20AI%20Goals"><em>ironanchorpress@earthlink.net</em></a>)<br>
<strong>Date:</strong> Wed Apr 26 2006 - 13:31:58 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="14635.html">Samantha Atkins: "Re: AI Goals"</a>
<li><strong>Previous message:</strong> <a href="14633.html">Jef Allbright: "Re: Game theory and morality"</a>
<li><strong>Maybe in reply to:</strong> <a href="14627.html">Jef Allbright: "Re: AI Goals"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14635.html">Samantha Atkins: "Re: AI Goals"</a>
<li><strong>Reply:</strong> <a href="14635.html">Samantha Atkins: "Re: AI Goals"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14634">[ date ]</a>
<a href="index.html#14634">[ thread ]</a>
<a href="subject.html#14634">[ subject ]</a>
<a href="author.html#14634">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; [Original Message]
</em><br>
<em>&gt; From: Samantha Atkins &lt;<a href="mailto:sjatkins@gmail.com?Subject=Re:%20AI%20Goals">sjatkins@gmail.com</a>&gt;
</em><br>
<p><em>&gt; Subject: Re: AI Goals
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; On Apr 26, 2006, at 9:22 AM, Woody Long wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;&gt; Fundamentally, I'm saying that with regard to morality, evolutionary
</em><br>
<em>&gt; &gt;&gt; selection prevails (and there's nothing intrinsically nice about  
</em><br>
<em>&gt; &gt;&gt; that)
</em><br>
<em>&gt; &gt;&gt; and I'm also saying that we have reached a level of development where
</em><br>
<em>&gt; &gt;&gt; subjective agents can actively and intentionally contribute to the
</em><br>
<em>&gt; &gt;&gt; process.
</em><br>
<em>&gt; &gt;&gt; - Jef
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I'm just looking for something to believe in - a friendly,  
</em><br>
<em>&gt; &gt; beneficial SAI
</em><br>
<em>&gt; &gt; that I can wholeheartedly support and promote to the general  
</em><br>
<em>&gt; &gt; public. We
</em><br>
<em>&gt; &gt; have polar opposite visions of the technological singularity: I  
</em><br>
<em>&gt; &gt; prefer an
</em><br>
<em>&gt; &gt; exclusively Science and Engineering TS, and you prefer a Values  
</em><br>
<em>&gt; &gt; Promoting
</em><br>
<em>&gt; &gt; TS.  I contend that human values should be the province of humans,  
</em><br>
<em>&gt; &gt; and the
</em><br>
<em>&gt; &gt; human religious and political experts who study and apply them, and  
</em><br>
<em>&gt; &gt; natural
</em><br>
<em>&gt; &gt; human evolution.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Why on earth would you want all value decisions to be made by highly  
</em><br>
<em>&gt; limited intelligences largely under the influence of evolutionary  
</em><br>
<em>&gt; psychology designed around their surviving long enough to breed on  
</em><br>
<em>&gt; the plains of Africa?   How could such severely limited and tainted  
</em><br>
<em>&gt; intelligences possibly make beneficial non-catastrophic value  
</em><br>
<em>&gt; judgments as accelerating change makes the world more and more  
</em><br>
<em>&gt; different than what their design tolerances can handle?  How will  
</em><br>
<em>&gt; such slow and limited beings keep up well enough to make such  
</em><br>
<em>&gt; decisions as the decision points come faster and faster with much  
</em><br>
<em>&gt; more complex interdependencies?
</em><br>
<p>This sounds to me like you have made my point, because as you say these
<br>
value decisions will be &quot;made by highly limited intelligences.&quot; For this
<br>
very reason, I just can't see how VPTS will ever be allowed to be more then
<br>
puppets of their originating countries.  And if you believe a VPTS will
<br>
solve the age-old problem of human war, I think this is mistaken. It seems
<br>
to me a VPTS will only simply amplify the positions of their originating
<br>
country. And some day there will be a Chinese TS, Iranian TS, North Korean
<br>
TS, etc. each I can only imagine pushing their own breed of religious and
<br>
political systems. Electric is thicker then water. So what has been gained?
<br>
<p>Meanwhile, a SETS could be maintaining the mega systems of earth such as
<br>
electric grids, nuclear power plants, weather systems, transportation
<br>
systems, etc., plus actively advance all sciences, such as food science,
<br>
medical science, the space exploration sciences, etc. The human values
<br>
involved in these decisions are simple, constant, and uncontroversial. This
<br>
is all I mean by a technological systems paradise. And I still have to
<br>
believe that a SETS could get us there SAFER, quicker, and easier then the
<br>
never-ending arguing international VPTSs. 
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="14635.html">Samantha Atkins: "Re: AI Goals"</a>
<li><strong>Previous message:</strong> <a href="14633.html">Jef Allbright: "Re: Game theory and morality"</a>
<li><strong>Maybe in reply to:</strong> <a href="14627.html">Jef Allbright: "Re: AI Goals"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14635.html">Samantha Atkins: "Re: AI Goals"</a>
<li><strong>Reply:</strong> <a href="14635.html">Samantha Atkins: "Re: AI Goals"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14634">[ date ]</a>
<a href="index.html#14634">[ thread ]</a>
<a href="subject.html#14634">[ subject ]</a>
<a href="author.html#14634">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
