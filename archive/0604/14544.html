<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Singularity Summit at Stanford, 5/13 - RSVP now</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Singularity Summit at Stanford, 5/13 - RSVP now">
<meta name="Date" content="2006-04-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Singularity Summit at Stanford, 5/13 - RSVP now</h1>
<!-- received="Thu Apr 13 17:02:14 2006" -->
<!-- isoreceived="20060413230214" -->
<!-- sent="Thu, 13 Apr 2006 15:56:37 -0700" -->
<!-- isosent="20060413225637" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Singularity Summit at Stanford, 5/13 - RSVP now" -->
<!-- id="443ED725.7070306@pobox.com" -->
<!-- charset="windows-1252" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Singularity%20Summit%20at%20Stanford,%205/13%20-%20RSVP%20now"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Thu Apr 13 2006 - 16:56:37 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="14545.html">Philip Goetz: "The coming crime wave"</a>
<li><strong>Previous message:</strong> <a href="14543.html">BillK: "Re: Anti-singularity spam."</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14544">[ date ]</a>
<a href="index.html#14544">[ thread ]</a>
<a href="subject.html#14544">[ subject ]</a>
<a href="author.html#14544">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<a href="http://sss.stanford.edu/">http://sss.stanford.edu/</a>
<br>
<p>If you wish to attend, RSVP swiftly.  Apparently seats are going fast.
<br>
<p>------
<br>
<p>FOR IMMEDIATE RELEASE
<br>
<p>Media Contacts:
<br>
<p>Tyler Emerson
<br>
Singularity Institute
<br>
emerson at singinst dot org
<br>
650-353-6063
<br>
<p>Todd Davies
<br>
Stanford University Symbolic Systems Program
<br>
tdavies at csli dot stanford dot edu
<br>
650-723-4091
<br>
<p>Renee Blodgett
<br>
Blodgett Communications
<br>
617-620-9664
<br>
Renee at blodgettcomm dot com
<br>
(business press, bloggers)
<br>
<p><p>Singularity Summit At Stanford Explores Future Of 'Superintelligence'
<br>
<p><p>STANFORD, CA April 13, 2006 -- The Stanford University Symbolic Systems 
<br>
Program and the Singularity Institute for Artificial Intelligence 
<br>
announced today the Singularity Summit at Stanford, a one-day event free 
<br>
to the public, to be held Saturday, May 13, 2006 at Stanford Memorial 
<br>
Auditorium, Stanford, California.
<br>
<p>The event will bring together leading futurists and others to examine 
<br>
the implications of the &quot;Singularity&quot; -- a hypothesized creation of 
<br>
superintelligence as technology accelerates over the coming decades -- 
<br>
to address the profound implications of this radical and controversial 
<br>
scenario.
<br>
<p>“The Singularity will be a future period during which the pace of 
<br>
technological change will be so rapid, its impact so deep, that human 
<br>
life will be irreversibly transformed,&quot; said Ray Kurzweil, keynote 
<br>
speaker and author of the best-selling The Singularity Is Near: When 
<br>
Humans Transcend Biology (Viking, 2005). &quot;Based on models of technology 
<br>
development that I've used to forecast technological change successfully 
<br>
for more than 25 years, I believe computers will pass the Turing Test by 
<br>
2029, and by the 2040s our civilization will be billions of times more 
<br>
intelligent.&quot;
<br>
<p>&quot;Some regard the Singularity as a positive event and work to hasten its 
<br>
arrival, while others view it as unlikely, or even dangerous and 
<br>
undesirable,&quot; said Todd Davies, associate director of Stanford's 
<br>
Symbolic Systems Program. “The conference will bring together a range of 
<br>
thinkers about AI, nanotechnology, cognitive science, and related areas 
<br>
for a public discussion of these important questions about our future.&quot;	
<br>
Noted speakers at the event will also include cognitive scientist 
<br>
Douglas R. Hofstadter, author of the Pulitzer prize-winning Godel, 
<br>
Escher, Bach; nanotechnology pioneers K. Eric Drexler and Christine L. 
<br>
Peterson; science-fiction novelist Cory Doctorow; philosopher Nick 
<br>
Bostrom; futurist Max More; Eliezer S. Yudkowsky, research fellow of the 
<br>
Singularity Institute for Artificial Intelligence; Acceleration Studies 
<br>
Foundation president John Smart; PayPal founder and Clarium Capital 
<br>
Management president Peter Thiel; Steve Jurvetson, a Managing Director 
<br>
of Draper Fisher Jurvetson; and Sebastian Thrun, Stanford Artificial 
<br>
Intelligence Laboratory director and Project Lead of the Stanford Racing 
<br>
Team (DARPA Grand Challenge $2 million winner). In addition, author Bill 
<br>
McKibben will participate remotely from Maine via Teleportec, a two-way, 
<br>
life-size 3D display of the speaker.
<br>
The event will be moderated by Peter Thiel and Tyler Emerson, executive 
<br>
director of the Singularity Institute for Artificial Intelligence.
<br>
<p>Among the issues to be addressed:
<br>
<p>Bostrom: Will superintelligence help us reduce or eliminate existential 
<br>
risks, such as the risk that advanced nanotechnology will be used by 
<br>
humans in warfare or terrorism?
<br>
<p>Doctorow: Will our technology serve us, or control us?
<br>
<p>Drexler: Will productive nanosystems enable the development of more 
<br>
intricate and complex productive systems, creating a feedback loop that 
<br>
drives accelerating change?
<br>
<p>Hofstadter: What is the likelihood of our being eclipsed by (or absorbed 
<br>
into) a vast computational network of superminds, in the course of the 
<br>
next few decades?
<br>
<p>Kurzweil: Will the Singularity be a soft (gradual) or hard (rapid) take 
<br>
off and how will humans stay in control?
<br>
<p>More: Will our emotional, social, psychological, ethical intelligence 
<br>
and self-awareness keep up with our expanding cognitive abilities?
<br>
<p>Peterson: How can we safely bring humanity and the biosphere through the 
<br>
Singularity?
<br>
<p>Thrun: Where does AI stand in comparison to human-level skills, in light 
<br>
of the recent autonomous robot race, the DARPA Grand Challenge?
<br>
<p>Yudkowsky: How can we shape the intelligence explosion for the benefit 
<br>
of humanity?
<br>
<p>The Singularity Summit is hosted by the Symbolic Systems Program at 
<br>
Stanford, and co-sponsored by Clarium Capital Management, 
<br>
KurzweilAI.net, MINE, the Singularity Institute for Artificial 
<br>
Intelligence, the Stanford Transhumanist Association, and United 
<br>
Therapeutics.
<br>
<p>The free event will be held in Stanford Memorial Auditorium, 551 Serra 
<br>
Mall, Stanford, CA 94305. Seating is limited. Please RSVP to 
<br>
<a href="http://sss.stanford.edu/rsvptoday">http://sss.stanford.edu/rsvptoday</a>.  For further information: 
<br>
<a href="http://sss.stanford.edu">http://sss.stanford.edu</a> or 650-353-6063.
<br>
<p>About the Stanford University Symbolic Systems Program
<br>
<p>The Symbolic Systems Program (<a href="http://symsys.stanford.edu">http://symsys.stanford.edu</a>) is an 
<br>
undergraduate and master's interdisciplinary program at Stanford, 
<br>
focusing on the relationships between people and computers. SSP's goal 
<br>
is to prepare students with the vocabulary, theoretical background, and 
<br>
technical skills to understand and participate in interdisciplinary 
<br>
research into questions about language, information, and intelligence -- 
<br>
both human and machine.
<br>
<p>About Clarium Capital Management
<br>
<p>Clarium Capital Management (<a href="http://www.clariumcapital.com">http://www.clariumcapital.com</a>) is a San 
<br>
Francisco-based global macro hedge fund, combining the diligence and 
<br>
prudence of an Old World investment firm with the energy and 
<br>
entrepreneurship of a Silicon Valley start-up. Clarium is a fortress in 
<br>
Greek mythology. Clarium's President and Chairman of the Investment 
<br>
committee is Peter Thiel, the former chairman, CEO, and co-founder of 
<br>
PayPal Inc., acquired by eBay Inc. for $1.5 billion in 2002. Driven by a 
<br>
contrarian bias, CCM pursues opportunities in four areas: currencies, 
<br>
commodities, distressed debt, and micro-cap public equities. CCM also 
<br>
selectively pursues private investments that show exceptional promise.
<br>
<p>About KurzweilAI.net
<br>
<p>Founded by Ray Kurzweil, KurzweilAI.net (<a href="http://kurzweilai.net">http://kurzweilai.net</a>) features 
<br>
more than 600 articles by big thinkers examining the convergence of 
<br>
accelerating revolutions in AI, nanotechnology, genetics, and other 
<br>
areas shaping the future of superintelligence. Its free 
<br>
Accelerating-Intelligence News daily newsletter tracks the latest news 
<br>
in these areas and its Mind-X forum allows for open discussion. 
<br>
KurzweilAI.net also manages singularity.com and fantastic-voyage.net, 
<br>
covering Kurzweil's recent two books.
<br>
<p>About MINE
<br>
<p>MINE (<a href="http://www.minesf.com">http://www.minesf.com</a>) was founded with the philosophy that good 
<br>
design is good business, and that working smart beats working big. A 
<br>
multidisciplinary studio, MINE offers innovative and informed solutions 
<br>
as tools to support corporate, enterprise, and nonprofit organizations. 
<br>
Emphasizing intelligence-based design and sound strategic thinking, MINE 
<br>
seeks to create definitive, stand-out work that projects a unique 
<br>
position of leadership and promotes the highest standards of excellence.
<br>
<p>About the Singularity Institute for Artificial Intelligence
<br>
<p>The Singularity Institute for Artificial Intelligence 
<br>
(<a href="http://www.intelligence.org">http://www.intelligence.org</a>) is a research and public interest institute 
<br>
for the advancement of three emerging research fields: beneficial 
<br>
artificial intelligence, the singularity, and global catastrophic risks 
<br>
associated with anticipated technologies. The Institute aims to develop 
<br>
and foster a community of highly gifted interdisciplinary researchers to 
<br>
accelerate these fields, and create the foundation needed to support 
<br>
this research community. The Institute’s main goal is to ensure the 
<br>
creation of beneficial AI.
<br>
<p>About the Stanford Transhumanist Association
<br>
<p>The Stanford Transhumanist Association 
<br>
(<a href="http://www.stanford.edu/group/transhumanism/blog">http://www.stanford.edu/group/transhumanism/blog</a>) was founded in 2004 
<br>
by Michael Jin (President) and Yonah Berwaldt (Financial Officer), then 
<br>
freshmen. It is a working group dedicated to spreading awareness about 
<br>
the impact of emerging technologies on humanity. The group is a Student 
<br>
Chapter of the World Transhumanist Association, an international 
<br>
nonprofit membership organization advocating the ethical use of 
<br>
technology to expand human capacities.
<br>
<p>About United Therapeutics
<br>
<p>United Therapeutics (<a href="http://www.unither.com">http://www.unither.com</a>) is a biotechnology company 
<br>
focused on the development and commercialization of unique products for 
<br>
patients with chronic and life-threatening cardiovascular, cancer and 
<br>
infectious diseases. In these segments, United Therapeutics is actively 
<br>
developing four technology platforms: Prostacyclin Analogs, 
<br>
Immunotherapeutic Monoclonal Antibodies, Glycobiology, and Telemedicine.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="14545.html">Philip Goetz: "The coming crime wave"</a>
<li><strong>Previous message:</strong> <a href="14543.html">BillK: "Re: Anti-singularity spam."</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14544">[ date ]</a>
<a href="index.html#14544">[ thread ]</a>
<a href="subject.html#14544">[ subject ]</a>
<a href="author.html#14544">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
