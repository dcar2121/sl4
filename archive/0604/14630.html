<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI Goals</title>
<meta name="Author" content="Jef Allbright (jef@jefallbright.net)">
<meta name="Subject" content="Re: AI Goals">
<meta name="Date" content="2006-04-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI Goals</h1>
<!-- received="Wed Apr 26 11:29:18 2006" -->
<!-- isoreceived="20060426172918" -->
<!-- sent="Wed, 26 Apr 2006 10:28:53 -0700" -->
<!-- isosent="20060426172853" -->
<!-- name="Jef Allbright" -->
<!-- email="jef@jefallbright.net" -->
<!-- subject="Re: AI Goals" -->
<!-- id="22360fa10604261028y4e505105v914be58d02ee9f7f@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="410-22006432616225953@earthlink.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Jef Allbright (<a href="mailto:jef@jefallbright.net?Subject=Re:%20AI%20Goals"><em>jef@jefallbright.net</em></a>)<br>
<strong>Date:</strong> Wed Apr 26 2006 - 11:28:53 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="14631.html">Samantha Atkins: "Re: AI Goals"</a>
<li><strong>Previous message:</strong> <a href="14629.html">Woody Long: "Re: AI Goals"</a>
<li><strong>In reply to:</strong> <a href="14629.html">Woody Long: "Re: AI Goals"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14632.html">Mikko Särelä: "Re: AI Goals"</a>
<li><strong>Reply:</strong> <a href="14632.html">Mikko Särelä: "Re: AI Goals"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14630">[ date ]</a>
<a href="index.html#14630">[ thread ]</a>
<a href="subject.html#14630">[ subject ]</a>
<a href="author.html#14630">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Jef Allbright wrote:
<br>
<p><em>&gt; &gt; Fundamentally, I'm saying that with regard to morality, evolutionary
</em><br>
<em>&gt; &gt; selection prevails (and there's nothing intrinsically nice about that)
</em><br>
<em>&gt; &gt; and I'm also saying that we have reached a level of development where
</em><br>
<em>&gt; &gt; subjective agents can actively and intentionally contribute to the
</em><br>
<em>&gt; &gt; process.
</em><br>
<em>&gt; &gt; - Jef
</em><br>
<p><p>On 4/26/06, Woody Long &lt;<a href="mailto:ironanchorpress@earthlink.net?Subject=Re:%20AI%20Goals">ironanchorpress@earthlink.net</a>&gt; wrote:
<br>
<p><em>&gt; I'm just looking for something to believe in - a friendly, beneficial SAI
</em><br>
<em>&gt; that I can wholeheartedly support and promote to the general public. We
</em><br>
<em>&gt; have polar opposite visions of the technological singularity: I prefer an
</em><br>
<em>&gt; exclusively Science and Engineering TS, and you prefer a Values Promoting
</em><br>
<em>&gt; TS.
</em><br>
<p>Woody, I am saying that it is necessary that we increase our awareness
<br>
of *both* aspects: our evolving subjective values and our evolving
<br>
scientific/technical knowledge.  In order to make &quot;good&quot; decisions, it
<br>
is necessary to understand which direction we want to go, and what
<br>
works to get us there.
<br>
<p>Both areas of knowledge will benefit from a framework of collaborative
<br>
knowledge growth over increasing scale.  I envision the
<br>
objective/scientific portion doing increasingly sophisticated modeling
<br>
based on our values, applying objective data  and methods and
<br>
principles of growth of dynamical systems.
<br>
<p>On 4/26/06, Phillip Huggan &lt;<a href="mailto:cdnprodigy@yahoo.com?Subject=Re:%20AI%20Goals">cdnprodigy@yahoo.com</a>&gt; wrote:
<br>
<p><em>&gt; The problem with treating values as evolutionary instead of objective, is
</em><br>
<em>&gt; that it is easy to get stuck in a broad low maximum.  MNT or AGI in service
</em><br>
<em>&gt; of Neocapitalism would be a dystopia.  Evolutionary urges can be sublimated.
</em><br>
<em>&gt;  I'm not saying that is easy or practical for present generations.  But in
</em><br>
<em>&gt; considering a world of the future, sufficiently mature systems of education,
</em><br>
<em>&gt; psychiatry, psychology and social safety nets can make evolutionary
</em><br>
<em>&gt; pressures negligible.  IN the long run the speed of light limits brain sizes
</em><br>
<em>&gt; to a few hundred km across (I think), so get used to ultimate limits to
</em><br>
<em>&gt; growth.
</em><br>
<p>Phillip, when I say evolution prevails, I'm not referring to our
<br>
innate evolved drives.  I'm referring to the universal process of
<br>
evolution that we observe at all scales whereby new configurations
<br>
arise &quot;randomly&quot; and then selection occurs based on fitness within the
<br>
local environment.  This process applies to the development of stars
<br>
and galaxies, biological life, culture, and we have now arrived at the
<br>
unprecedented level where subjective agents can (and should, in the
<br>
moral sense) influence the process (at least from their point of
<br>
view.)
<br>
<p>With respect to the speed of light limiting the size of brains, you
<br>
have a point that the speed of light is a real constraint on the
<br>
structure at that level, but this does not put a limit on growth that
<br>
proceeds at higher levels of organization.  Think of independent city
<br>
states limited by geography and speed of travel, each developing
<br>
mostly independently, and then consider the boost to growth that
<br>
occurs when they begin communicating and trading.  The higher level
<br>
structure accompanies an increase in degrees of freedom--growth.
<br>
<p>In the interest of list quality, I'm going to retire for now from the
<br>
discussion on the public list but welcome ongoing constructive
<br>
discussion offlist.
<br>
<p>- Jef
<br>
<a href="http://www.jefallbright.net">http://www.jefallbright.net</a>
<br>
Increasing awareness for increasing morality
<br>
Empathy, Energy, Efficiency, Extropy
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="14631.html">Samantha Atkins: "Re: AI Goals"</a>
<li><strong>Previous message:</strong> <a href="14629.html">Woody Long: "Re: AI Goals"</a>
<li><strong>In reply to:</strong> <a href="14629.html">Woody Long: "Re: AI Goals"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14632.html">Mikko Särelä: "Re: AI Goals"</a>
<li><strong>Reply:</strong> <a href="14632.html">Mikko Särelä: "Re: AI Goals"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14630">[ date ]</a>
<a href="index.html#14630">[ thread ]</a>
<a href="subject.html#14630">[ subject ]</a>
<a href="author.html#14630">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
