<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Fwd: We Can Understand Anything, But are Just a Bit Slow</title>
<meta name="Author" content="Richard Loosemore (rpwl@lightlink.com)">
<meta name="Subject" content="Re: Fwd: We Can Understand Anything, But are Just a Bit Slow">
<meta name="Date" content="2006-04-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Fwd: We Can Understand Anything, But are Just a Bit Slow</h1>
<!-- received="Mon Apr 24 10:54:11 2006" -->
<!-- isoreceived="20060424165411" -->
<!-- sent="Mon, 24 Apr 2006 12:52:57 -0400" -->
<!-- isosent="20060424165257" -->
<!-- name="Richard Loosemore" -->
<!-- email="rpwl@lightlink.com" -->
<!-- subject="Re: Fwd: We Can Understand Anything, But are Just a Bit Slow" -->
<!-- id="444D0269.20700@lightlink.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="444CF7B8.6030206@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Richard Loosemore (<a href="mailto:rpwl@lightlink.com?Subject=Re:%20Fwd:%20We%20Can%20Understand%20Anything,%20But%20are%20Just%20a%20Bit%20Slow"><em>rpwl@lightlink.com</em></a>)<br>
<strong>Date:</strong> Mon Apr 24 2006 - 10:52:57 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="14595.html">Robin Lee Powell: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<li><strong>Previous message:</strong> <a href="14593.html">Robin Lee Powell: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<li><strong>In reply to:</strong> <a href="14592.html">Eliezer S. Yudkowsky: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14595.html">Robin Lee Powell: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<li><strong>Reply:</strong> <a href="14595.html">Robin Lee Powell: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<li><strong>Reply:</strong> <a href="14596.html">Eliezer S. Yudkowsky: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14594">[ date ]</a>
<a href="index.html#14594">[ thread ]</a>
<a href="subject.html#14594">[ subject ]</a>
<a href="author.html#14594">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eliezer,
<br>
<p>I'm confused:  was your point that Phil's comment was so foolish that it 
<br>
deserved only sarcasm?
<br>
<p>Or maybe this wasn't sarcasm at all (apologies if not) and you can 
<br>
explain a few oddities, like why my cranial volume does not appear to be 
<br>
hundreds of times large than the average cranial volume that I see every 
<br>
day on the street...?
<br>
<p>If the ability to hold simultaneous chunks in working memory is somehow 
<br>
connected to the maximum theoretical amount of total connectivity of 
<br>
concept-level objects in the brain, then it would, as Phil points out 
<br>
scale in a very unfortunate way with increasing brain size.  And if the 
<br>
ability to hold simultaneous chunks is crucial to the power of thought 
<br>
or degree of intelligence (whatever that is), this might have serious 
<br>
consequences.
<br>
<p>I would argue against his conclusion.  But the argument does not seem to 
<br>
me to be incoherent.
<br>
<p>Richard Loosemore
<br>
<p><p><p><p><p><p><p>Eliezer S. Yudkowsky wrote:
<br>
<em>&gt; Philip Goetz wrote:
</em><br>
<em>&gt;&gt; My intuition, based on experience with how much computational power it
</em><br>
<em>&gt;&gt; takes to solve a problem of a particular size, and on Rescher's law of
</em><br>
<em>&gt;&gt; logarithmic returns, is that exponentially-increasing computational
</em><br>
<em>&gt;&gt; power is required to provide linear increase in &quot;smartness&quot;, or some
</em><br>
<em>&gt;&gt; measure of the problems we can handle.  For instance, finding primes
</em><br>
<em>&gt;&gt; of 2N bits takes much more than twice the computational power of
</em><br>
<em>&gt;&gt; finding primes of N bits.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; I also expect that the computational complexity of cognition is an
</em><br>
<em>&gt;&gt; exponential function of the size of working memory, so that if we
</em><br>
<em>&gt;&gt; currently have a working memory that can store 5 chunks, the amount of
</em><br>
<em>&gt;&gt; computation available in the universe limits us to some double-digit
</em><br>
<em>&gt;&gt; number of chunks.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; As we all know, humans required thousands of much times as much brain 
</em><br>
<em>&gt; tissue as chimpanzees to produce only a small increment in performance; 
</em><br>
<em>&gt; if you look around on the street, you can easily see that each 
</em><br>
<em>&gt; additional 10 IQ points requires a rough doubling of cranial volume.  If 
</em><br>
<em>&gt; you still think the ascent of AIs will be rapid, a further caution is 
</em><br>
<em>&gt; provided by the evolutionary history of the hominid family:  After 
</em><br>
<em>&gt; requiring only 50,000 years to go from Australopithecus to late Homo 
</em><br>
<em>&gt; erectus, it then required another five million years to produce Homo 
</em><br>
<em>&gt; sapiens.  Most of what we think of as impressive benefits and major 
</em><br>
<em>&gt; impacts of &quot;human&quot; intelligence, such as guns and nuclear weapons, were 
</em><br>
<em>&gt; invented by monkeys twenty million years ago.  Our closest cousins, the 
</em><br>
<em>&gt; chimpanzees, have most human abilities - including combinatorial 
</em><br>
<em>&gt; language, machines with moving parts, and crude scientific journals - 
</em><br>
<em>&gt; which also suggests that it is unlikely for any particular AI project to 
</em><br>
<em>&gt; get many major abilities in advance of other AI projects.  The ongoing 
</em><br>
<em>&gt; military and economic competition between Cro-Magnons and Neanderthals 
</em><br>
<em>&gt; has stalemated for millennia; slight improvements in brainpower simply 
</em><br>
<em>&gt; do not amount to all that much in the real world.
</em><br>
<em>&gt; 
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="14595.html">Robin Lee Powell: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<li><strong>Previous message:</strong> <a href="14593.html">Robin Lee Powell: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<li><strong>In reply to:</strong> <a href="14592.html">Eliezer S. Yudkowsky: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14595.html">Robin Lee Powell: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<li><strong>Reply:</strong> <a href="14595.html">Robin Lee Powell: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<li><strong>Reply:</strong> <a href="14596.html">Eliezer S. Yudkowsky: "Re: Fwd: We Can Understand Anything, But are Just a Bit Slow"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14594">[ date ]</a>
<a href="index.html#14594">[ thread ]</a>
<a href="subject.html#14594">[ subject ]</a>
<a href="author.html#14594">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
