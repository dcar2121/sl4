<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: The inevitability of death, or the death of inevitability?</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: The inevitability of death, or the death of inevitability?">
<meta name="Date" content="2001-12-08">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: The inevitability of death, or the death of inevitability?</h1>
<!-- received="Sun Dec 09 00:24:42 2001" -->
<!-- isoreceived="20011209072442" -->
<!-- sent="Sun, 09 Dec 2001 00:22:51 -0500" -->
<!-- isosent="20011209052251" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: The inevitability of death, or the death of inevitability?" -->
<!-- id="3C12F52B.F9DEC6FE@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3C12E8B8.84626188@jump.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20The%20inevitability%20of%20death,%20or%20the%20death%20of%20inevitability?"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Sat Dec 08 2001 - 22:22:51 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2452.html">DarkVegeta26@aol.com: "Re: A billion years later..."</a>
<li><strong>Previous message:</strong> <a href="2450.html">Eliezer S. Yudkowsky: "[Fwd: New website: The Simulation Argument]"</a>
<li><strong>In reply to:</strong> <a href="2446.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2456.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Reply:</strong> <a href="2456.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Reply:</strong> <a href="2463.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2451">[ date ]</a>
<a href="index.html#2451">[ thread ]</a>
<a href="subject.html#2451">[ subject ]</a>
<a href="author.html#2451">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Jeff Bone wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; There is also a big difference between saying &quot;long-term predictions made from current
</em><br>
<em>&gt; scientific understanding *may* be inaccurate&quot; and &quot;long-term predictions made from
</em><br>
<em>&gt; current scientific understanding *must* be inaccurate.&quot;  What you are stating is much
</em><br>
<em>&gt; closer to the latter than I am comfortable admitting,
</em><br>
<p>Uh... why?  In what way is this not a total strawman argument?
<br>
<p><em>&gt; and again I will claim that
</em><br>
<em>&gt; those kinds of comments are most often heard from people that are either ignorant of a
</em><br>
<em>&gt; given field or predisposed to be antagonistic to the logical conclusions of a
</em><br>
<em>&gt; particular field.  Given that you're neither, Eli, then I am rather surprised to hear
</em><br>
<em>&gt; you make arguments like this.
</em><br>
<p>... and in what way is this not a total ad hominem?
<br>
<p><em>&gt; So here's what's wrong with this argument:  just as technology has been accelerating
</em><br>
<em>&gt; non-linearly (perhaps asymptotically) over history, so has scientific understanding
</em><br>
<em>&gt; (the accuracy of our models for making predictions at longer terms and finer levels of
</em><br>
<em>&gt; &quot;resolution&quot;) been accelerating similarly.
</em><br>
<p>This observation, I rather like.  The problem, as my humorous post
<br>
suggests, is workarounds where the physicists stand around innocently
<br>
saying &quot;Violation?  What violation?&quot;
<br>
<p><em>&gt; Note we aren't talking about &quot;technological impossibilities,&quot; rather logical and
</em><br>
<em>&gt; physical constraints.  Apples and oranges.  &quot;The world market for computers is around
</em><br>
<em>&gt; five,&quot; &quot;we will never put a man on the moon,&quot; etc. are all dumb statements.  OTOH,
</em><br>
<em>&gt; things like QED aren't about impossibilities, they are probabilistic models for actual
</em><br>
<em>&gt; physical events.
</em><br>
<p>The problem is &quot;physical constraints&quot; that turn out to be merely
<br>
&quot;technological impossibilities&quot;.  Future citizens may look back on us and
<br>
say &quot;How could they possibly believe in the logical impossibility of
<br>
&quot;global causality violation&quot; when there were already so many different
<br>
physics papers proposing methods for constructing closed timelike curves?&quot;
<br>
<p>I say this, BTW, not because I want to have closed timelike curves or
<br>
because my whole precious universe will come apart like tissue paper if
<br>
CTCs are impossible, but because I'm trying to make the point that there
<br>
are *already* proposed workarounds.  These proposals may stand or fall,
<br>
but at any rate it is not *yet* true to say &quot;our current model of physics
<br>
says XYZ is 100% impossible&quot;.  Sure, even if XYZ *is* 100% impossible, I
<br>
would expect a certain number of papers with subtle flaws arguing for
<br>
various unworkable workarounds, so the papers are not evidence in that
<br>
sense.  For that matter, something which appears possible under our own
<br>
laws of physics could turn out to be impossible under the real laws of
<br>
physics!  There could be dozens of basic limits we haven't discovered
<br>
yet!  But the issue isn't settled yet.
<br>
<p>Humanity may have at least as many surprises in waiting as all those it
<br>
has already encountered... or even a far greater number of surprises.  I
<br>
am reminded of the line in Zindell's novel &quot;Neverness&quot; which mentions in
<br>
passing that physicists pursued the trail of fundamental particles
<br>
composing fundamental particles down through 200,000 layers before finally
<br>
giving up.  (And before you accuse me of whatever, I want to say that I
<br>
personally believe that quarks are it - the fundamental particles do keep
<br>
getting simpler, so I doubt the trail continues forever.)
<br>
<p>The sole evidence for the &quot;many surprises&quot; proposition is the Principle of
<br>
Mediocrity, which isn't really evidence at all.  In truth, I have no idea,
<br>
and it is not possible that I should have any idea, no matter which way it
<br>
ultimately turns out.  Sometimes the Principle of Surprise Mediocrity is
<br>
the conservative assumption for Friendly AI (how much philosophical depth
<br>
is required?) and sometimes not (how much specific moral content should we
<br>
be able to generate right now?), so I generally have to keep track of both
<br>
possibilities.
<br>
<p><em>&gt; Modulo accepted physical and mathematical constraints that form the most essential
</em><br>
<em>&gt; underpinnings of our most accurate theories:  things like c, the Beckenstein Bound,
</em><br>
<em>&gt; 2LT, Godel's theorem, the Halting Problem, Chaitin's incompleteness theorems, etc.
</em><br>
<em>&gt; While I place a high probability on at least one of those being incorrect, there's
</em><br>
<em>&gt; good reason to believe that the probability of all of them being incorrect is
</em><br>
<em>&gt; approaching zero.
</em><br>
<p>I don't think that the size of the hole that would be left in our
<br>
comfortable worlds by a stunning disproof should be allowed to mediate
<br>
against the long-term probability of disproof.  Remember also that the
<br>
probability of an &quot;innocent physicist&quot; workaround for any given limit is
<br>
probably much higher than the probability of an actual disproof.
<br>
<p>If, leaving workarounds aside, I had to pick one of these rules as *most*
<br>
likely to survive, I'd pick c - it seems to be built into the nature of
<br>
causality in our universe.
<br>
<p><em>&gt; To the extent that your world-view requires you to blissfully ignore the implications
</em><br>
<em>&gt; of such things, you should recognize it as the former:  a psuedo-religious expression
</em><br>
<em>&gt; of faith used to support belief in highly speculative hypotheses.
</em><br>
<p>To what extent does my world-view require me to blissfully ignore the
<br>
implications of such things?  Obviously I'd rather live in a universe
<br>
where true immortality is possible, but I acknowledge that this is not a
<br>
variable my actions can influence.  None of my current actions are
<br>
predicated on that variable taking on a particular value, so why am I
<br>
being accused of religious faith?  As far as I can tell, my sole crime is
<br>
that I attach a 20% probability to irrelevant-but-fun hypotheses to which
<br>
you would rather grant a 90% probability.  Is this really adequate
<br>
evidence for you to conclude that my entire worldview is religiously
<br>
biased toward pleasant possibilities, especially where the usual outcome
<br>
of such a case is the assignment of 0% probability, or more often a
<br>
complete refusal to address the issue?  Is it your thesis that I am
<br>
ignoring actions which I should be taking to prepare for the 20%/90%
<br>
probability that some law remains solid over the long run?  I've already
<br>
explained why a resolution of this issue is not required to construct
<br>
Friendly AI.
<br>
<p><em>&gt; I want to believe
</em><br>
<em>&gt; in Friendliness, Eli --- indeed I do believe that superhuman AI is an inevitability,
</em><br>
<em>&gt; and I'd like for it to be benign.
</em><br>
<p>Dear me.  How biased.
<br>
<p><em>&gt; But honestly, your arguments are inspiring less
</em><br>
<em>&gt; confidence rather than more. :-(
</em><br>
<p>Yes, well, I have some experience with the bizarre matrix of
<br>
self-reinforcing misinterpretations that usually results in such a
<br>
statement.  You don't appear to be an advanced case, and hopefully can be
<br>
extracted from whatever corner you're currently wedging yourself into.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2452.html">DarkVegeta26@aol.com: "Re: A billion years later..."</a>
<li><strong>Previous message:</strong> <a href="2450.html">Eliezer S. Yudkowsky: "[Fwd: New website: The Simulation Argument]"</a>
<li><strong>In reply to:</strong> <a href="2446.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2456.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Reply:</strong> <a href="2456.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Reply:</strong> <a href="2463.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2451">[ date ]</a>
<a href="index.html#2451">[ thread ]</a>
<a href="subject.html#2451">[ subject ]</a>
<a href="author.html#2451">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
