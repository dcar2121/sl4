<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Sysop yet again Re: New website: The Simulation Argument</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Sysop yet again Re: New website: The Simulation Argument">
<meta name="Date" content="2001-12-06">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Sysop yet again Re: New website: The Simulation Argument</h1>
<!-- received="Fri Dec 07 02:01:55 2001" -->
<!-- isoreceived="20011207090155" -->
<!-- sent="Fri, 07 Dec 2001 01:54:58 -0500" -->
<!-- isosent="20011207065458" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Sysop yet again Re: New website: The Simulation Argument" -->
<!-- id="3C1067C2.B2E504D0@posthuman.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3C0F90DD.DFA9BF5B@jump.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Sysop%20yet%20again%20Re:%20New%20website:%20The%20Simulation%20Argument"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Thu Dec 06 2001 - 23:54:58 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2421.html">Jeff Bone: "Re: Sysop yet again Re: New website: The Simulation Argument"</a>
<li><strong>Previous message:</strong> <a href="2419.html">Bryan Moss: "Re: New website: The Simulation Argument"</a>
<li><strong>In reply to:</strong> <a href="2417.html">Jeff Bone: "Re: New website: The Simulation Argument"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2421.html">Jeff Bone: "Re: Sysop yet again Re: New website: The Simulation Argument"</a>
<li><strong>Reply:</strong> <a href="2421.html">Jeff Bone: "Re: Sysop yet again Re: New website: The Simulation Argument"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2420">[ date ]</a>
<a href="index.html#2420">[ thread ]</a>
<a href="subject.html#2420">[ subject ]</a>
<a href="author.html#2420">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I know at this point Eliezer is beating his head against the wall, but
<br>
I can't resist...
<br>
<p>Jeff Bone wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Gordon Worley wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; Computationally, this is too expensive for a practical Sysop to work.
</em><br>
<em>&gt; &gt; The Sysop need not know the state of everything, but be there when
</em><br>
<em>&gt; &gt; needed.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; And my argument is that in order to determine when and where the Sysop will
</em><br>
<em>&gt; be needed, some agent --- whether the Sysop itself or the environment is
</em><br>
<em>&gt; unimportant --- is going to need a predictive ability that allows it to
</em><br>
<em>&gt; prevent unwanted harm or death to individuals.  This will be, for example,
</em><br>
<em>&gt; *far* more complex than forecasting local weather patterns in detail with
</em><br>
<em>&gt; any accuracy.  Indeed, consider weather:  a Sysop that in fact performs as
</em><br>
<em>&gt; Eli suggests it should (i.e., ensures --- absolutely, reliably --- that
</em><br>
<em>&gt; involuntary harm or damage cannot impact a protected individual under the
</em><br>
<em>&gt; Sysop's care) will either need to be able to control the weather (which
</em><br>
<em>&gt; implies deep simulation ability in that area) or be able to proactively
</em><br>
<em>&gt; protect particular individuals and their goods when threatened by bad
</em><br>
<em>&gt; weather.  Neither of these may be possible:  the first may not be possibly
</em><br>
<em>&gt; due to the complex dynamics of physical phenomenon like weather, the latter
</em><br>
<em>&gt; may not be possible simply because it may be physically impossible to
</em><br>
<em>&gt; protect something against the forces seen in certain disastrous weather
</em><br>
<em>&gt; conditions.  Bad weather, earthquakes, etc. would indeed require extremely
</em><br>
<em>&gt; fine-grained simulation of the time evolution of large interrelated systems
</em><br>
<em>&gt; of effects, to avoid the *eventual* impact on the constituency.
</em><br>
<p>Your scenario is very unlikely, but at any rate should a no-win situation
<br>
become apparent the Sysop likely would simply inform the affected individuals
<br>
of the situation and the lack of absolute safety, and let them decide what
<br>
they want to do. If they then choose to stay in the danger then they are
<br>
now volutarily choosing to risk death. So if they die the Sysop has not
<br>
failed in its task to prevent involuntary death. The Sysop cannot defeat
<br>
the laws of physics, but it can at least keep you informed and provide
<br>
alternatives.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; I agree that this is all, most likely, computationally impractical --- not
</em><br>
<em>&gt; particularly because of lack of computation ability (let's assume
</em><br>
<em>&gt; computronium) but because of the potential physical limitations to
</em><br>
<em>&gt; simulating the real world in sufficient detail to provide absolute
</em><br>
<em>&gt; guarantees of safety.  IMO, the only thing a practical Sysop will be able
</em><br>
<em>&gt; to do is guarantee best-effort protection and safety, and *that* might not
</em><br>
<em>&gt; be worth the risks involved.
</em><br>
<p>Just to clarify, SIAI is not about building a Sysop. We are trying to
<br>
build a seed mind that has low risk of unFriendliness, but what it chooses
<br>
to develop into is up to it, and if stays Friendly then it will not
<br>
choose to develop into something that is &quot;not worth the risks&quot;. Your
<br>
other choice BTW is to wait around until some other organization lets
<br>
loose either by design or accident some sort of higher-risk A-mind.
<br>
The &quot;let's just don't ever build an A-mind&quot; choice is almost certainly
<br>
a fantasy so it is not up for consideration.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; BTW, this all assumes that some part of the constituency &quot;remains&quot;
</em><br>
<em>&gt; interested in being physically present in the physical world.  If everybody
</em><br>
<em>&gt; uploads --- *everybody* --- then this isn't as big a problem, though the
</em><br>
<em>&gt; Sysop must still be concerned with the physical safety of whatever
</em><br>
<em>&gt; substrate it runs on.
</em><br>
<p>I think you face potential disasters from external events no matter what
<br>
substrate so I don't see that it matters much. I find your earthquake
<br>
example to be very unconvincing... I was just reading in New Scientist
<br>
a couple weeks ago about a new prediction theory for earthquakes and
<br>
other sudden events so I think a superintelligence will be able to find
<br>
a way to predict these events, or even if it has to simulate the whole
<br>
damn planet it can do that too quite easily, in fact it could probably
<br>
use a very small chunk of the Earth for the needed hardware assuming
<br>
computronium really is the best way to compute. Of course why bother
<br>
when it probably has the technology to completely eliminate earthquakes.
<br>
<p>Unforseen surprises from outside the solar system seem like the only
<br>
real threats, but perhaps you have some other ideas.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; Logic, common sense, and actuarial reasoning should tell us that that
</em><br>
<em>&gt; *absolute* safety is an impossibility, and my gut tells me that attempting
</em><br>
<em>&gt; to task some Power with providing it is a recipe for disaster.
</em><br>
<em>&gt; 
</em><br>
<p>Personally I don't see how preventing 99.999% of bad stuff is an
<br>
unworthy goal. A Sysop is not about providing perfect safety, it is
<br>
about creating the most perfect universe possible while still within
<br>
the physical laws we are all apparently stuck with. Even if it turns
<br>
out it can only prevent 10% of the bad stuff then that is worth
<br>
doing- why wouldn't it be?
<br>
<p>P.S. I reiterate no one is tasking a Power to do anything. Powers decide
<br>
for themselves what they want to do :-)
<br>
<pre>
-- 
Brian Atkins
Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2421.html">Jeff Bone: "Re: Sysop yet again Re: New website: The Simulation Argument"</a>
<li><strong>Previous message:</strong> <a href="2419.html">Bryan Moss: "Re: New website: The Simulation Argument"</a>
<li><strong>In reply to:</strong> <a href="2417.html">Jeff Bone: "Re: New website: The Simulation Argument"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2421.html">Jeff Bone: "Re: Sysop yet again Re: New website: The Simulation Argument"</a>
<li><strong>Reply:</strong> <a href="2421.html">Jeff Bone: "Re: Sysop yet again Re: New website: The Simulation Argument"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2420">[ date ]</a>
<a href="index.html#2420">[ thread ]</a>
<a href="subject.html#2420">[ subject ]</a>
<a href="author.html#2420">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
