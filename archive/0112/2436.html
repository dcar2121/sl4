<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: The inevitability of death, or the death of inevitability?</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: The inevitability of death, or the death of inevitability?">
<meta name="Date" content="2001-12-08">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: The inevitability of death, or the death of inevitability?</h1>
<!-- received="Sat Dec 08 17:21:09 2001" -->
<!-- isoreceived="20011209002109" -->
<!-- sent="Sat, 08 Dec 2001 17:20:15 -0500" -->
<!-- isosent="20011208222015" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: The inevitability of death, or the death of inevitability?" -->
<!-- id="3C12921F.EA649FCB@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3C1282F6.93BCF293@jump.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20The%20inevitability%20of%20death,%20or%20the%20death%20of%20inevitability?"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Sat Dec 08 2001 - 15:20:15 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2437.html">Ben Goertzel: "RE: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Previous message:</strong> <a href="2435.html">Jeff Bone: "Re: Shocklevel 5"</a>
<li><strong>In reply to:</strong> <a href="2433.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2437.html">Ben Goertzel: "RE: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Reply:</strong> <a href="2437.html">Ben Goertzel: "RE: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Reply:</strong> <a href="2440.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Reply:</strong> <a href="2519.html">Samantha Atkins: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2436">[ date ]</a>
<a href="index.html#2436">[ thread ]</a>
<a href="subject.html#2436">[ subject ]</a>
<a href="author.html#2436">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Jeff Bone wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; &quot;Eliezer S. Yudkowsky&quot; wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; &gt; Bottom line, in the limit:  you cannot.  Extinction of the &quot;individual&quot;
</em><br>
<em>&gt; &gt; &gt; --- even a distributed, omnipotent ubermind --- is 100% certain at some
</em><br>
<em>&gt; &gt; &gt; future point, if for no other reason than the entropic progress of the
</em><br>
<em>&gt; &gt; &gt; universe.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Don't you think we're too young, as a species, to be making judgements
</em><br>
<em>&gt; &gt; about that?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; No --- that's the difference between faith and science.  It's not a judgement,
</em><br>
<em>&gt; it's a prediction from a model that generates predictions consistent with
</em><br>
<em>&gt; observation and measurement.
</em><br>
<p>Perhaps.  Understand that I do not have &quot;faith&quot; that immortality is
<br>
possible.  I am simply stating that before we get all emotional about this
<br>
issue - that is, before we begin making value judgements or philosophical
<br>
assumptions based on it - we should remember that the model the prediction
<br>
is based on is a model which historically has often changed and currently
<br>
is still in flux.
<br>
<p><em>&gt; While the Big Crunch is a pretty specific model of a physical phenomenon, 2LT
</em><br>
<em>&gt; seems much deeper and more abstract than that --- kind of like Godel, Turing,
</em><br>
<em>&gt; etc.  It's that fundamental and deep a concept --- and the greatest long-term
</em><br>
<em>&gt; risk we can predict, given certain assumptions and certain things that are
</em><br>
<em>&gt; observably true about our universe.
</em><br>
<p>Well... this is something I happen to disagree with, because personally
<br>
the second law of thermodynamics strikes me as being statistical in
<br>
nature, and often rather fragile.  I would not be surprised to find out
<br>
that it is utterly impossible to exceed the speed of light within a given
<br>
gravitational frame of reference, forever and amen.  2LT seems to me to
<br>
have more the character of a guideline than a rule.
<br>
<p><em>&gt; IMO, there's still refinement to do, but we're starting to converge on
</em><br>
<em>&gt; something that's a reasonably accurate (yields predictions consistent with
</em><br>
<em>&gt; observed reality) and yet general (works at all scales in all contexts) set of
</em><br>
<em>&gt; base laws.  Note too that these won't be &quot;the&quot; laws of physics, rather &quot;a&quot; laws
</em><br>
<em>&gt; of physics.  We can never prove (epistemological impossibility) that any given
</em><br>
<em>&gt; set of laws, no matter how accurate the predictions they yield, are the best or
</em><br>
<em>&gt; even only model of how the world works.
</em><br>
<p>I think perhaps our species is too young to know that as well.  I can
<br>
conceive of a model which starts at the First Cause and proceeds directly
<br>
to the universe as presently observed, with no room for error or even
<br>
illusion cast by simulators; I can conceive of an ironglad guarantee such
<br>
that even if we lived in a simulated universe, we'd know the ultimate
<br>
universe on top ran according to a certain set of laws.  But this gets
<br>
into questions of the nature of &quot;truth&quot;, which is why I say that our
<br>
species is too young to know for sure; at this present time we do not have
<br>
the capability to perform the experiments required to determine the nature
<br>
of &quot;truth&quot;, which to me is a question bound up with the nature of
<br>
&quot;reality&quot;, which I expect we'll find out when we start tracing back past
<br>
the Big Bang, determining the origin of the laws of physics, and otherwise
<br>
closing in experimentally on the First Cause.
<br>
<p><em>&gt; Interesting.  How did you get 30%?
</em><br>
<p>That's the current balance between (a) the Principle of Mediocrity as
<br>
applied to changes in human civilization over time and our current
<br>
position, and (b) my innate scientific conservatism.
<br>
<p><em>&gt; IMO, any system of &quot;rights&quot; in practice actually results in unresolvable
</em><br>
<em>&gt; inconsistencies and paradoxes.
</em><br>
<p>&quot;Unresolvable?&quot;  That sounds pretty strong.  Can you name a single
<br>
unresolvable inconsistency or paradox?
<br>
<p><em>&gt; It may be that the optimal system for allowing independent actors to achieve
</em><br>
<em>&gt; optimal balance of competing self-interests is not a system of axiomatized
</em><br>
<em>&gt; rights coupled with protective and punitive measures (a &quot;legal&quot; system, or a
</em><br>
<em>&gt; Sysop) but rather a kind of metalegal framework that enables efficient
</em><br>
<em>&gt; negotiation and exchange of consensual, contractual agreements.
</em><br>
<p>The two main problems with this are as stated earlier:  First, the
<br>
possibility of a universe in which offense beats defense; second, the fact
<br>
that a simulated, enslaved citizen has no position from which to
<br>
negotiate.  A metalegal framework might be superimposed on an intelligent
<br>
substrate, but it still requires an intelligent substrate to ensure that
<br>
no being is stripped of citizenship rights.
<br>
<p><em>&gt; &gt; Whether we are all DOOMED in the long run seems to me like an orthogonal
</em><br>
<em>&gt; &gt; issue.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It isn't really orthogonal;  it's possible that the choices we make now --- the
</em><br>
<em>&gt; &quot;angle of attack&quot; with which we enter the Singularity --- may prune the
</em><br>
<em>&gt; eventual possibility tree for us in undesirable ways.  I don't think this is a
</em><br>
<em>&gt; reason to futilely attempt to avoid Singularity, I just think it should give us
</em><br>
<em>&gt; pause to consider outcomes.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Example:  let's assume for a moment that the universe is closed, not open.
</em><br>
<em>&gt; Let's further assume that Tipler's wild scenario --- perfectly harnassing the
</em><br>
<em>&gt; energy of a collapsing universe and using that to control the manner of the
</em><br>
<em>&gt; collapse, allowing an oscillating state and producing exponential &quot;substrate&quot;
</em><br>
<em>&gt; --- is plausible.  Then the best course of action for a civilization would be
</em><br>
<em>&gt; to maximize both propagation and engineering capability to do so when the time
</em><br>
<em>&gt; comes.  This very long-term goal supporting maximum longevity of the civ's
</em><br>
<em>&gt; interests may in fact be in conflict with the concept of individual rights and
</em><br>
<em>&gt; volition.  Hence, putting in place a Power that favors one may prevent the
</em><br>
<em>&gt; other.  That's a tradeoff that needs to be considered in any scenario of
</em><br>
<em>&gt; ascendancy.
</em><br>
<p>If this is indeed an important factor to take into consideration, then my
<br>
design responsibility is to build a Friendly AI which will duplicate that
<br>
portion of your cognitive complexity which causes you to perceive as
<br>
forceful that argument which you have just presented.
<br>
<p><em>&gt; &gt; Eliminate negative events if possible.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; But &quot;negative&quot; has many dimensions, and most of those are subjective...
</em><br>
<p>... he argued, correctly assuming that the audience would perceive
<br>
&quot;subjectivity&quot; as a negative quality with respect to principles intended
<br>
for a Friendly AI.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2437.html">Ben Goertzel: "RE: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Previous message:</strong> <a href="2435.html">Jeff Bone: "Re: Shocklevel 5"</a>
<li><strong>In reply to:</strong> <a href="2433.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2437.html">Ben Goertzel: "RE: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Reply:</strong> <a href="2437.html">Ben Goertzel: "RE: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Reply:</strong> <a href="2440.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Reply:</strong> <a href="2519.html">Samantha Atkins: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2436">[ date ]</a>
<a href="index.html#2436">[ thread ]</a>
<a href="subject.html#2436">[ subject ]</a>
<a href="author.html#2436">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
