<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: New Term: Apexmind?</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: New Term: Apexmind?">
<meta name="Date" content="2001-12-05">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: New Term: Apexmind?</h1>
<!-- received="Wed Dec 05 11:38:40 2001" -->
<!-- isoreceived="20011205183840" -->
<!-- sent="Wed, 05 Dec 2001 08:47:04 -0500" -->
<!-- isosent="20011205134704" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: New Term: Apexmind?" -->
<!-- id="3C0E2558.54CD9FC4@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3.0.6.32.20011205174149.0149a100@ariel.its.unimelb.edu.au" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20New%20Term:%20Apexmind?"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Wed Dec 05 2001 - 06:47:04 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2415.html">Jeff Bone: "Re: The Simulation Argument"</a>
<li><strong>Previous message:</strong> <a href="2413.html">Damien Broderick: "Re: New Term: Apexmind?"</a>
<li><strong>In reply to:</strong> <a href="2413.html">Damien Broderick: "Re: New Term: Apexmind?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0110/2332.html">Matthew Houston: "Re: New Term: Apexmind?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2414">[ date ]</a>
<a href="index.html#2414">[ thread ]</a>
<a href="subject.html#2414">[ subject ]</a>
<a href="author.html#2414">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Damien Broderick wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; I wasn't *really* suggesting `Prefect', you understand (although it amuses
</em><br>
<em>&gt; me that it's an anagram of `Perfect'); I was gesturing toward the nature of
</em><br>
<em>&gt; the beast under discussion. `Monitor' is another possibility; as are
</em><br>
<em>&gt; `Custodian', `Protector' and `Steward'. The last of these is perhaps the
</em><br>
<em>&gt; most general and least offensive... although the idea itself remains rather
</em><br>
<em>&gt; offensive however it's parsed.
</em><br>
<p>Doesn't that last remark say it all...
<br>
<p>If you think the idea has offensive consequences, you're going to pick a
<br>
term that has connotations that remind you of those offensive
<br>
consequences.  Thus, from our perspective, short-circuiting the process of
<br>
rational argument, which should start with a morally neutral term
<br>
describing what the hypothesis *is*.
<br>
<p>A Sysop is not a Prefect, Monitor, Custodian, Protector, or Steward.  At
<br>
most it might be a Protector, and the reason this term is salvageable is
<br>
that a &quot;protector&quot; does not specify how something is being protected, or
<br>
for what motive; the other terms all have specific connotations of
<br>
political and moral authority in a human social context.
<br>
<p>The Sysop is not a human mind.  If it were, most of this would be nonsense
<br>
and the rest would be actively dangerous.  This is something that becomes
<br>
possible only when you step outside the realm of evolved minds and start
<br>
considering what a mind-in-general can be asked to do.  If you import
<br>
terms that have specific connotations and meanings in the context of human
<br>
society, you are anthropomorphizing the whole situation; you have sucked
<br>
all the interestingly alien aspects out of it.
<br>
<p>In this sense, Gordon Worley's Unix Scenario, in which &quot;root&quot; is not a
<br>
*conscious* process, is psychologically superior to the Sysop Scenario; it
<br>
is less likely to be confused with human ideas of gods, fathers, and other
<br>
extrema of the &quot;tribal chief&quot; concept.  Unfortunately I also think the
<br>
Unix Scenario version is less plausible, but that's a separate issue.
<br>
<p>Humans have a phobia of minds, which unfortunately extends from human
<br>
minds (where it is justified) to minds in general (since no other mind
<br>
types were encountered in the ancestral environment).  Someone looking
<br>
over Gordon Worley's Unix Scenario says &quot;Hm, underlying reality works
<br>
according to certain definite physical rules; there are no minds here; I'm
<br>
probably safe.&quot;  Someone in a Sysop Scenario is just as likely to be safe,
<br>
but the human instincts look over the Sysop Scenario and say:  &quot;There is a
<br>
mind here; that mind is likely to act against me,&quot; or even worse, &quot;There
<br>
is a mind here; this mind is an extrema of concept tribal-chief;
<br>
therefore, this mind will boss me around.&quot;  The motivations of a nonhuman
<br>
superintelligence that does not *want* to boss you around can be just as
<br>
solid a safeguard as an absolute physical impossibility of interference. 
<br>
The fact that your sexual habits are of absolutely no concern to the
<br>
singleton substrate mean that your midnight assignations might as well be
<br>
outside the light cone of the solar system; the only difference is that
<br>
nobody else can interfere with you either.
<br>
<p>Outside the human realm, dealing with real extremes of cognition instead
<br>
of imagined extremes of social categories, superintelligent motivations
<br>
can be just as solid and impartial as physical law.  Maybe, to reflect
<br>
this, we should skip both Sysop Scenario and Unix Reality and go straight
<br>
to discussing Michael Anissimov's ontotechnology scenarios.  For some
<br>
reason there's a rule that says you can't hurt someone without their
<br>
consent.  Is it because the Sysop predicts a violation of volition? 
<br>
Because the low-level rules of Unix Reality don't permit the physical
<br>
interaction?  Because, back in the dawn of the Singularity, the first
<br>
Friendly SI made some quiet adjustments to the laws of physics?  Because
<br>
of something entirely unimaginable?  What difference does it really make,
<br>
except to human psychology?
<br>
<p>If it's theoretically possible for transhumans to retain motivations that
<br>
would make them hostile toward other transhumans, then a possible problem
<br>
exists of transhuman war or even transhuman existential catastrophe; but,
<br>
there exists at least one comprehensible proposed solution to this
<br>
problem, and it is therefore disingenuous to present it as unsolvable. 
<br>
Maybe totally unrestricted technology for everyone in the universe,
<br>
including humans who've refused intelligence enhancement and still have
<br>
their original emotional architectures, won't threaten the welfare of one
<br>
single sentient being, for reasons we can't now understand.  But if not,
<br>
we know what to do about it.  That's all.
<br>
<p>The utility of discussing the Sysop Scenario is this: that we retain the
<br>
ability to say &quot;There are no known unsolvable problems between us and the
<br>
Singularity&quot;.  Nothing more.  It's a *prediction*, not a *decision*;
<br>
whether Unix/Sysop/whatever is actually needed would be up to the first
<br>
Friendly SI.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2415.html">Jeff Bone: "Re: The Simulation Argument"</a>
<li><strong>Previous message:</strong> <a href="2413.html">Damien Broderick: "Re: New Term: Apexmind?"</a>
<li><strong>In reply to:</strong> <a href="2413.html">Damien Broderick: "Re: New Term: Apexmind?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0110/2332.html">Matthew Houston: "Re: New Term: Apexmind?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2414">[ date ]</a>
<a href="index.html#2414">[ thread ]</a>
<a href="subject.html#2414">[ subject ]</a>
<a href="author.html#2414">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
