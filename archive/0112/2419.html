<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: New website: The Simulation Argument</title>
<meta name="Author" content="Bryan Moss (bryan.moss@btinternet.com)">
<meta name="Subject" content="Re: New website: The Simulation Argument">
<meta name="Date" content="2001-12-06">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: New website: The Simulation Argument</h1>
<!-- received="Thu Dec 06 18:16:55 2001" -->
<!-- isoreceived="20011207011655" -->
<!-- sent="Thu, 6 Dec 2001 23:07:44 -0000" -->
<!-- isosent="20011206230744" -->
<!-- name="Bryan Moss" -->
<!-- email="bryan.moss@btinternet.com" -->
<!-- subject="Re: New website: The Simulation Argument" -->
<!-- id="003401c17eab$0037d150$fd56073e@computer" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="4715CDD2-EA6C-11D5-AAD5-000A27B4DEFC@rbisland.cx" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Bryan Moss (<a href="mailto:bryan.moss@btinternet.com?Subject=Re:%20New%20website:%20The%20Simulation%20Argument"><em>bryan.moss@btinternet.com</em></a>)<br>
<strong>Date:</strong> Thu Dec 06 2001 - 16:07:44 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2420.html">Brian Atkins: "Sysop yet again Re: New website: The Simulation Argument"</a>
<li><strong>Previous message:</strong> <a href="2418.html">Gordon Worley: "Re: New website: The Simulation Argument"</a>
<li><strong>In reply to:</strong> <a href="2418.html">Gordon Worley: "Re: New website: The Simulation Argument"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2422.html">Jeff Bone: "Re: New website: The Simulation Argument"</a>
<li><strong>Reply:</strong> <a href="2422.html">Jeff Bone: "Re: New website: The Simulation Argument"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2419">[ date ]</a>
<a href="index.html#2419">[ thread ]</a>
<a href="subject.html#2419">[ subject ]</a>
<a href="author.html#2419">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Gordon Worley wrote:
<br>
<p><em>&gt; &gt; Logic, common sense, and actuarial reasoning should tell
</em><br>
<em>&gt; &gt; us that that *absolute* safety is an impossibility, and my
</em><br>
<em>&gt; &gt; gut tells me that attempting to task some Power with
</em><br>
<em>&gt; &gt; providing it is a recipe for disaster.
</em><br>
<em>&gt;
</em><br>
<em>&gt; We've already been down this road: anthropomorphic thinking.
</em><br>
<em>&gt;
</em><br>
<em>&gt; We cannot be 100% safe, but we'll try to get as damn close
</em><br>
<em>&gt; to it as possible and have escape routes in case all hell
</em><br>
<em>&gt; breaks loose.
</em><br>
<p>A wild ride.  Personally I see it as, we're either safe or
<br>
potentially screwed.  I don't know how Eliezer sees it because
<br>
I still haven't read that Friendly AI thing, but I think his
<br>
view is similar.  Basically, either some morality holds for
<br>
all intelligences or it does not.  For some morality to hold
<br>
for all intelligences I think the following must be true: (a)
<br>
finding the optimal intelligence is an intractable problem;
<br>
and (b) comparing the optimality of one intelligence to
<br>
another is an intractable problem.  If both of these prove to
<br>
be true then one intelligence has no grounds to favour itself
<br>
over another (or vice versa) and their morality must be a
<br>
superset of ours.  In other words, it's all sunshine and
<br>
lollipops because we've got SIs[*] batting for our team.  If
<br>
either one of these proves to be false then the drive toward
<br>
optimality *might* result in us being screwed (where &quot;screwed&quot;
<br>
means our evolved morality is at odds with a general morality
<br>
and we might have to do things we don't &quot;like&quot;).
<br>
<p>At the moment I think the &quot;safe&quot; scenario is the most likely.
<br>
<p>BM
<br>
<p>[* Of course, if (a) and (b) hold you might wonder how you can
<br>
have superintelligence.  You can, you just can't be *provably*
<br>
superintelligent.  So no certificates to hang on your wall.]
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2420.html">Brian Atkins: "Sysop yet again Re: New website: The Simulation Argument"</a>
<li><strong>Previous message:</strong> <a href="2418.html">Gordon Worley: "Re: New website: The Simulation Argument"</a>
<li><strong>In reply to:</strong> <a href="2418.html">Gordon Worley: "Re: New website: The Simulation Argument"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2422.html">Jeff Bone: "Re: New website: The Simulation Argument"</a>
<li><strong>Reply:</strong> <a href="2422.html">Jeff Bone: "Re: New website: The Simulation Argument"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2419">[ date ]</a>
<a href="index.html#2419">[ thread ]</a>
<a href="subject.html#2419">[ subject ]</a>
<a href="author.html#2419">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
