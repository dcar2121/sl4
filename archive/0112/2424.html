<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: New website: The Simulation Argument</title>
<meta name="Author" content="Jeff Bone (jbone@jump.net)">
<meta name="Subject" content="Re: New website: The Simulation Argument">
<meta name="Date" content="2001-12-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: New website: The Simulation Argument</h1>
<!-- received="Fri Dec 07 20:03:02 2001" -->
<!-- isoreceived="20011208030302" -->
<!-- sent="Fri, 07 Dec 2001 18:53:01 -0600" -->
<!-- isosent="20011208005301" -->
<!-- name="Jeff Bone" -->
<!-- email="jbone@jump.net" -->
<!-- subject="Re: New website: The Simulation Argument" -->
<!-- id="3C11646D.A2426BC3@jump.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="93F274CA-EB67-11D5-BA38-000A27B4DEFC@rbisland.cx" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Jeff Bone (<a href="mailto:jbone@jump.net?Subject=Re:%20New%20website:%20The%20Simulation%20Argument"><em>jbone@jump.net</em></a>)<br>
<strong>Date:</strong> Fri Dec 07 2001 - 17:53:01 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2425.html">Eliezer S. Yudkowsky: "Direct neuron interface via quantum dots"</a>
<li><strong>Previous message:</strong> <a href="2423.html">Gordon Worley: "Re: New website: The Simulation Argument"</a>
<li><strong>In reply to:</strong> <a href="2423.html">Gordon Worley: "Re: New website: The Simulation Argument"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2429.html">tonyg@kcbbs.gen.nz: "Re: entropy and heat-death"</a>
<li><strong>Reply:</strong> <a href="2429.html">tonyg@kcbbs.gen.nz: "Re: entropy and heat-death"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2424">[ date ]</a>
<a href="index.html#2424">[ thread ]</a>
<a href="subject.html#2424">[ subject ]</a>
<a href="author.html#2424">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Gordon Worley wrote:
<br>
<p><em>&gt; On Friday, December 7, 2001, at 03:34  PM, Jeff Bone wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; Bottom line, as long as there is any connection whatsoever to the
</em><br>
<em>&gt; &gt; physical universe we are almost certainly and absolutely screwed in
</em><br>
<em>&gt; &gt; the long run:  either the universe is open and we experience the heat
</em><br>
<em>&gt; &gt; death due to 2LT, or its closed and we experience collapse, modulo
</em><br>
<em>&gt; &gt; some Tipler-esque imaginary infinity.  Give that safety is
</em><br>
<em>&gt; &gt; *physically* an impossibility of absolute safety, we just need to
</em><br>
<em>&gt; &gt; realistically assess the tradeoffs between the costs and benefits of
</em><br>
<em>&gt; &gt; any desired level of safety.
</em><br>
<em>&gt;
</em><br>
<em>&gt; While a lot of this discussion is redundant, I think it needs to be made
</em><br>
<em>&gt; clear that this doesn't matter.
</em><br>
<p>And let's make it absolutely clear that this is complete bullshit
<br>
reasoning.  The reason actuarial science is called a science is because, um,
<br>
it's a science.  It's &quot;risk science.&quot;  You can't just wish risk away by
<br>
assuming an unspecified ubertechnology or benevolent, artificial uberbeing.
<br>
Doing that is exactly the same kind of tautological faith-based reasoning
<br>
that is the underpinning of *other* major world religions (aside from the
<br>
unexamined and uncritical belief in transhumanism and the possibility of
<br>
omnipotent benevolent go^h^h Sysop or -ops. ;-)
<br>
<p><em>&gt; These figures are based on right now,
</em><br>
<p>No, they are extrapolated from physical constants and metrics.  Granted it's
<br>
possible to make the values change dramatically --- but it is necessary for
<br>
a critical mind to examine *what* is necessary to make those values change.
<br>
And the bottom edge case means that it is entirely impossible to eliminate
<br>
risk entirely from the equation for any system that is grounded in physical
<br>
reality, given physical actuarial considerations.  Any statement that you
<br>
can do so is uninformed, unexamined, implausible.  This isn't a matter of
<br>
opinion, it's a matter of physics and examination of the edge cases.  If you
<br>
want to speculate that a different physics exists that might make absolute
<br>
and perpetual (to timelike-infinity) safety of even a small physical system
<br>
possible, you are welcome to do so --- but understand that you've strayed
<br>
from the bounds of science and empiricism and pragmatism into the realm of
<br>
imagination, fancy, and speculation.
<br>
<p><em>&gt; where you have only one life to live (que the melodramatic music).
</em><br>
<p>Nothing in what I have said assumes that.  Indeed, I pointed out the backup
<br>
question myself.  The actuarial analysis becomes more complex in the case of
<br>
backups vis-a-vis survival of an individual mind, as you then have to
<br>
consider propagation / saturation of a volume of timespace, your worldline
<br>
by the lightcone subtended by your birth event, etc.  But the bottom line is
<br>
that risks continue to exist in this universe unless you turn all of
<br>
spacetime itself into computronium, and IMO while normal matter-based
<br>
computronium is within the realm of possibility turning the substrate of the
<br>
universe itself into computronium belongs in the realm of things like the
<br>
Bible, the Torah, etc.  I.e., interesting *fiction,* but in the absence of
<br>
evidence to the contrary, just that --- fiction.
<br>
<p><em>&gt; So
</em><br>
<em>&gt; what if one copy of your mind can only live x years, you can live
</em><br>
<em>&gt; forever by making copies.
</em><br>
<p>Unless the universe is open, in which case entropy will ultimately get you
<br>
no matter *what* Sysop, etc. you have.  For extra credit:  5000 words
<br>
critically comparing and contrasting Eli's Sysop with Maxwell's Daemon.
<br>
<p>jb
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2425.html">Eliezer S. Yudkowsky: "Direct neuron interface via quantum dots"</a>
<li><strong>Previous message:</strong> <a href="2423.html">Gordon Worley: "Re: New website: The Simulation Argument"</a>
<li><strong>In reply to:</strong> <a href="2423.html">Gordon Worley: "Re: New website: The Simulation Argument"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2429.html">tonyg@kcbbs.gen.nz: "Re: entropy and heat-death"</a>
<li><strong>Reply:</strong> <a href="2429.html">tonyg@kcbbs.gen.nz: "Re: entropy and heat-death"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2424">[ date ]</a>
<a href="index.html#2424">[ thread ]</a>
<a href="subject.html#2424">[ subject ]</a>
<a href="author.html#2424">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
