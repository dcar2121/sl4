<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: The inevitability of death, or the death of inevitability?</title>
<meta name="Author" content="Jeff Bone (jbone@jump.net)">
<meta name="Subject" content="Re: The inevitability of death, or the death of inevitability?">
<meta name="Date" content="2001-12-08">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: The inevitability of death, or the death of inevitability?</h1>
<!-- received="Sat Dec 08 16:55:39 2001" -->
<!-- isoreceived="20011208235539" -->
<!-- sent="Sat, 08 Dec 2001 15:15:34 -0600" -->
<!-- isosent="20011208211534" -->
<!-- name="Jeff Bone" -->
<!-- email="jbone@jump.net" -->
<!-- subject="Re: The inevitability of death, or the death of inevitability?" -->
<!-- id="3C1282F6.93BCF293@jump.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3C11857F.9A8C2691@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Jeff Bone (<a href="mailto:jbone@jump.net?Subject=Re:%20The%20inevitability%20of%20death,%20or%20the%20death%20of%20inevitability?"><em>jbone@jump.net</em></a>)<br>
<strong>Date:</strong> Sat Dec 08 2001 - 14:15:34 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2434.html">Jeff Bone: "Re: Sysop yet again Re: New website: The Simulation Argument"</a>
<li><strong>Previous message:</strong> <a href="2432.html">Eliezer S. Yudkowsky: "Re: entropy and heat-death"</a>
<li><strong>In reply to:</strong> <a href="2428.html">Eliezer S. Yudkowsky: "The inevitability of death, or the death of inevitability?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2436.html">Eliezer S. Yudkowsky: "Re: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Reply:</strong> <a href="2436.html">Eliezer S. Yudkowsky: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2433">[ date ]</a>
<a href="index.html#2433">[ thread ]</a>
<a href="subject.html#2433">[ subject ]</a>
<a href="author.html#2433">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&quot;Eliezer S. Yudkowsky&quot; wrote:
<br>
<p><em>&gt; &gt; Bottom line, in the limit:  you cannot.  Extinction of the &quot;individual&quot;
</em><br>
<em>&gt; &gt; --- even a distributed, omnipotent ubermind --- is 100% certain at some
</em><br>
<em>&gt; &gt; future point, if for no other reason than the entropic progress of the
</em><br>
<em>&gt; &gt; universe.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Don't you think we're too young, as a species, to be making judgements
</em><br>
<em>&gt; about that?
</em><br>
<p>No --- that's the difference between faith and science.  It's not a judgement,
<br>
it's a prediction from a model that generates predictions consistent with
<br>
observation and measurement.  However, I *did* get a bit sloppy in my framing;
<br>
the assumptions which make the above statement empirically true are:  open
<br>
universe, single universe (at least with respect to our ability to be
<br>
somewhere), mostly-constant physics across spacetime, inability to do
<br>
engineering with spacetime or fine-tune certain things, etc.  Entropy seems to
<br>
be very fundamentally tied up in how spacetime works.  While there's a
<br>
considerable amount of refinement to be done in the various theories, all signs
<br>
point to a unified theory of quantum gravity that preserves 2LT.  Also,
<br>
best-guess measurement of the cosmological constant seems to indicate that we
<br>
have an open universe, which given all the rest yields heat death as an
<br>
eventual certainty.  If that's wrong, then we have a closed universe and a
<br>
whole new set of problems and opportunities.
<br>
<p><em>&gt; I do think there's a possibility that, in the long run, the
</em><br>
<em>&gt; probability of extinction approaches unity - for both individual and
</em><br>
<em>&gt; species, albeit with different time constants.  I think this simply
</em><br>
<em>&gt; because forever is such a very, very long time.  I don't think that what
</em><br>
<em>&gt; zaps us will be the second law of thermodynamics, the heat death of the
</em><br>
<em>&gt; Universe, the Big Crunch, et cetera, because these all seem like the kind
</em><br>
<em>&gt; of dooms that keep getting revised every time our model of the laws of
</em><br>
<em>&gt; physics changes.
</em><br>
<p>While the Big Crunch is a pretty specific model of a physical phenomenon, 2LT
<br>
seems much deeper and more abstract than that --- kind of like Godel, Turing,
<br>
etc.  It's that fundamental and deep a concept --- and the greatest long-term
<br>
risk we can predict, given certain assumptions and certain things that are
<br>
observably true about our universe.
<br>
<p><em>&gt; It seems pretty likely to me that we can outlast 10^31
</em><br>
<em>&gt; years.  Living so long that it has to be expressed in Knuth notation is a
</em><br>
<em>&gt; separate issue.  Our current universe may let us get away with big
</em><br>
<em>&gt; exponents, but it just doesn't seem to be really suited to doing things
</em><br>
<em>&gt; that require Knuth notation.
</em><br>
<p>I agree.  We'll have to build another one, if that's possible.
<br>
<p><em>&gt; I don't think the laws of physics have settled down yet.
</em><br>
<p>IMO, there's still refinement to do, but we're starting to converge on
<br>
something that's a reasonably accurate (yields predictions consistent with
<br>
observed reality) and yet general (works at all scales in all contexts) set of
<br>
base laws.  Note too that these won't be &quot;the&quot; laws of physics, rather &quot;a&quot; laws
<br>
of physics.  We can never prove (epistemological impossibility) that any given
<br>
set of laws, no matter how accurate the predictions they yield, are the best or
<br>
even only model of how the world works.  (Neither can we prove the converse,
<br>
except through scientific method:  i.e. creating alternative models that yield
<br>
better predictions.)
<br>
<p><em>&gt; I admit of the
</em><br>
<em>&gt; possibility that the limits which appear under current physical law are
</em><br>
<em>&gt; absolute, even though most of them have highly speculative and
</em><br>
<em>&gt; controversial workarounds scattered through the physics literature.  I'm
</em><br>
<em>&gt; not trying to avoid confronting the possibility; I'm just saying that the
</em><br>
<em>&gt; real probability we need to worry about is probably less than 30%, and
</em><br>
<em>&gt; that the foregoing statement could easily wind up looking completely
</em><br>
<em>&gt; ridiculous (&quot;How could any sane being assign that a probability of more
</em><br>
<em>&gt; than 1%?&quot;) in a few years.
</em><br>
<p>Interesting.  How did you get 30%?
<br>
<p><em>&gt; And here, of course, is where the real disagreement lies.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Under what circumstances is a Sysop Scenario necessary and desirable?  It
</em><br>
<em>&gt; is not necessary to protect individuals from the environment,
</em><br>
<p>[disagree, but checkpoint]
<br>
<p><em>&gt; ...there is still the possibility of the
</em><br>
<em>&gt; violation of sentient rights;
</em><br>
<p>Here is the actual heart of the disagreement.  I've been struggling for the
<br>
last several years to put together a consistent and generally useful system of
<br>
&quot;axiomatic ethics / morals&quot; such as could be used by a hypothetical perfectly
<br>
rational intelligence, or even irrational intelligences that can act as
<br>
impartial arbiters.  It's been an abysmal failure, and my best &quot;guess&quot; (it's
<br>
not yet rigorous enough to call it a hypothesis) is that the failure results
<br>
from the concept of &quot;rights.&quot;
<br>
<p>IMO, any system of &quot;rights&quot; in practice actually results in unresolvable
<br>
inconsistencies and paradoxes.  It seems to me that only a system of
<br>
negotiated, consensual &quot;rights&quot; results in a workable, consistent system that
<br>
optimally balances competing self-interests among the participants --- and the
<br>
inevitable sacrifice involved is the imaginary security that we all cling to in
<br>
our notions of civilization.  The basic problem with the notion of rights and
<br>
of universally-applicable legal systems (axiomatized expressions of the checks
<br>
and balances of rights) is --- my guess --- a kind of incompleteness principle,
<br>
with the same tradeoff of completeness and consistency.
<br>
<p>&quot;Rights&quot; are a very anthropomorphic, spooky manifestation of a kind of
<br>
&quot;faith.&quot;  They aren't subject to any kind of empirical testing at all ---
<br>
indeed, experimental enquiry suggests that they don't exist.  (A person's
<br>
&quot;right&quot; to life doesn't keep another from violating that &quot;right&quot; and not
<br>
suffering any consequences.)
<br>
<p>It may be that the optimal system for allowing independent actors to achieve
<br>
optimal balance of competing self-interests is not a system of axiomatized
<br>
rights coupled with protective and punitive measures (a &quot;legal&quot; system, or a
<br>
Sysop) but rather a kind of metalegal framework that enables efficient
<br>
negotiation and exchange of consensual, contractual agreements.  (If I ever
<br>
manage to get this whole thing whipped into shape, the ongoing book project is
<br>
entitled &quot;Axiomatic Ethics and Moral Machines.&quot;  :-)
<br>
<p><em>&gt; I think that ruling out the possibility of an unimaginable number of
</em><br>
<em>&gt; sentient entities being deprived of citizenship rights, and/or the
</em><br>
<em>&gt; possibility of species extinction due to inter-entity warfare, would both
</em><br>
<em>&gt; be sufficient cause for intelligent substrate, if intelligent substrate
</em><br>
<em>&gt; were the best means to accomplish those ends.
</em><br>
<p>I would mostly agree, modulo concern over what is meant by &quot;rights&quot; --- but I'm
<br>
not sure that it's safe (even given the notion of &quot;Friendly&quot;) to assume either
<br>
<p><em>&gt; Whether we are all DOOMED in the long run seems to me like an orthogonal
</em><br>
<em>&gt; issue.
</em><br>
<p>It isn't really orthogonal;  it's possible that the choices we make now --- the
<br>
&quot;angle of attack&quot; with which we enter the Singularity --- may prune the
<br>
eventual possibility tree for us in undesirable ways.  I don't think this is a
<br>
reason to futilely attempt to avoid Singularity, I just think it should give us
<br>
pause to consider outcomes.
<br>
<p>Example:  let's assume for a moment that the universe is closed, not open.
<br>
Let's further assume that Tipler's wild scenario --- perfectly harnassing the
<br>
energy of a collapsing universe and using that to control the manner of the
<br>
collapse, allowing an oscillating state and producing exponential &quot;substrate&quot;
<br>
--- is plausible.  Then the best course of action for a civilization would be
<br>
to maximize both propagation and engineering capability to do so when the time
<br>
comes.  This very long-term goal supporting maximum longevity of the civ's
<br>
interests may in fact be in conflict with the concept of individual rights and
<br>
volition.  Hence, putting in place a Power that favors one may prevent the
<br>
other.  That's a tradeoff that needs to be considered in any scenario of
<br>
ascendancy.
<br>
<p><em>&gt; Eliminate negative events if possible.
</em><br>
<p>But &quot;negative&quot; has many dimensions, and most of those are subjective...
<br>
<p>jb
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2434.html">Jeff Bone: "Re: Sysop yet again Re: New website: The Simulation Argument"</a>
<li><strong>Previous message:</strong> <a href="2432.html">Eliezer S. Yudkowsky: "Re: entropy and heat-death"</a>
<li><strong>In reply to:</strong> <a href="2428.html">Eliezer S. Yudkowsky: "The inevitability of death, or the death of inevitability?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2436.html">Eliezer S. Yudkowsky: "Re: The inevitability of death, or the death of inevitability?"</a>
<li><strong>Reply:</strong> <a href="2436.html">Eliezer S. Yudkowsky: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2433">[ date ]</a>
<a href="index.html#2433">[ thread ]</a>
<a href="subject.html#2433">[ subject ]</a>
<a href="author.html#2433">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
