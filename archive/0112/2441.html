<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: The inevitability of death, or the death of inevitability?</title>
<meta name="Author" content="Jeff Bone (jbone@jump.net)">
<meta name="Subject" content="Re: The inevitability of death, or the death of inevitability?">
<meta name="Date" content="2001-12-08">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: The inevitability of death, or the death of inevitability?</h1>
<!-- received="Sat Dec 08 19:46:10 2001" -->
<!-- isoreceived="20011209024610" -->
<!-- sent="Sat, 08 Dec 2001 18:37:02 -0600" -->
<!-- isosent="20011209003702" -->
<!-- name="Jeff Bone" -->
<!-- email="jbone@jump.net" -->
<!-- subject="Re: The inevitability of death, or the death of inevitability?" -->
<!-- id="3C12B22E.B4395B24@jump.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3C12A065.A1594C6E@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Jeff Bone (<a href="mailto:jbone@jump.net?Subject=Re:%20The%20inevitability%20of%20death,%20or%20the%20death%20of%20inevitability?"><em>jbone@jump.net</em></a>)<br>
<strong>Date:</strong> Sat Dec 08 2001 - 17:37:02 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2442.html">Gordon Worley: "Re: A more concise and quantifiable definition of Friendliness?"</a>
<li><strong>Previous message:</strong> <a href="2440.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<li><strong>In reply to:</strong> <a href="2439.html">Eliezer S. Yudkowsky: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2440.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2441">[ date ]</a>
<a href="index.html#2441">[ thread ]</a>
<a href="subject.html#2441">[ subject ]</a>
<a href="author.html#2441">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&quot;Eliezer S. Yudkowsky&quot; wrote:
<br>
<p><em>&gt; Ben Goertzel wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; For what it's worth, my intuition agrees with Eli's on this.  We have yet
</em><br>
<em>&gt; &gt; explored only a very small part of the &quot;known universe&quot;, and there are big
</em><br>
<em>&gt; &gt; aspects of particle physics that we don't yet come close to understanding
</em><br>
<em>&gt; &gt; (e.g. quantum gravity, quantum measurement -- yes, there are claims of
</em><br>
<em>&gt; &gt; understanding, but nothing well-substantiated).  To assume that the Big Bang
</em><br>
<em>&gt; &gt; /Big Crunch model or any other fragment of modern science is going to
</em><br>
<em>&gt; &gt; survive untouched 1000 years from now is just plain silly.
</em><br>
<p>And let's be clear, I have not assumed that *either* the Big Bang or the Big
<br>
Crunch model is going to survive untouched for any given length of time.
<br>
<p>There are, however, some logical truisms we can all agree on:  either the timelike
<br>
extent of the universe will be infinite, or it will be finite.  From these logical
<br>
disjunctions, we can begin to reason in a Bayesian manner --- informed by our best
<br>
current understanding of physics --- about the probabilities of certain outcomes.
<br>
<p>Side note:  we're really arguing about priors, here.  In my experience,
<br>
&quot;scientists&quot; (rational actors who build models from observations and seek to
<br>
refine those models through an iterative cycle or prediction / observation /
<br>
modification) who have studied a particular field are (a) the first ones to admit
<br>
how little is actually known in that field, and yet (b) are much more capable of
<br>
yielding accurate predictions in that field --- assuming they stick to the
<br>
scientific framework --- than those who haven't studied the particular field in
<br>
depth.  Given the choice between a prediction of &quot;heat death&quot; by an expert vs. a
<br>
prediction of &quot;universe spontaneously fills up with daisies&quot; from a faith-based
<br>
&quot;reasoner,&quot; I'm willing to grant the scientist the higher level of confidence in
<br>
my Bayesian analysis of various outcomes.  ;-)
<br>
<p><em>&gt; &gt; The same intuition leads me to believe that the notion of &quot;designing
</em><br>
<em>&gt; &gt; Friendly AI&quot; is only slightly relevant to the final outcome of the grand
</em><br>
<em>&gt; &gt; &quot;superhuman AI engineering&quot; experiment.  I agree that it's a worthwhile
</em><br>
<em>&gt; &gt; pursuit, because it has a clearly &gt; 0 chance of making a difference.  But as
</em><br>
<em>&gt; &gt; with fundamental physics, there's a hell of a lot we don't understand about
</em><br>
<em>&gt; &gt; minds...
</em><br>
<em>&gt;
</em><br>
<em>&gt; Well, the CFAI model doesn't require that the creators know everything
</em><br>
<em>&gt; about the human mind.  It requires a certain bounded amount of complexity
</em><br>
<em>&gt; which is used to construct an unambiguous pointer to unknown facts about
</em><br>
<em>&gt; the human mind, facts which may not be known now, but which are expected
</em><br>
<em>&gt; to be accessible to a transhuman intelligence.
</em><br>
<p>I agree with all of that.
<br>
<p><em>&gt; In other words, under the CFAI model, you can say:  &quot;I have this vague
</em><br>
<em>&gt; feeling that liberty and life and love and laughter are important, but I'm
</em><br>
<em>&gt; not sure about it, and I don't know where the feeling comes from.  Count
</em><br>
<em>&gt; that in, okay?&quot;  The physical causation behind this statement - in your
</em><br>
<em>&gt; accumulated experience, in your brainware, in your genes - is in principle
</em><br>
<em>&gt; accessible to a transhuman intelligence, even one that has to extrapolate
</em><br>
<em>&gt; the causes after the event.  The Friendly AI can then intelligently use
</em><br>
<em>&gt; existing philosophical complexity to decide which of these causes are
</em><br>
<em>&gt; valid and should be absorbed.  The Friendly AI can then &quot;repeat&quot; the above
</em><br>
<em>&gt; statement at a higher level of intelligence - that is, having absorbed the
</em><br>
<em>&gt; moral baseline behind the statement, it can re-produce the statement as
</em><br>
<em>&gt; you would have produced it at a higher intelligence level.
</em><br>
<p>And this would be entirely in line with the psuedo-Epicurean ethics I generally
<br>
employ, but it may be inconsistent with other goals such as long-term
<br>
survivability, etc.  Therein lie the aforementioned tradeoffs.
<br>
<p><em>&gt; So what's needed is the threshold level of moral complexity to understand
</em><br>
<em>&gt; how to correctly use pointers like the one described above - not a
</em><br>
<em>&gt; complete diagram of human moral complexity, or a complete understanding of
</em><br>
<em>&gt; transhuman philosophy.  That threshold level of complexity - which is big,
</em><br>
<em>&gt; but bounded, and hopefully accessible to merely human understanding - is
</em><br>
<em>&gt; what CFAI attempts to describe.
</em><br>
<p>...and the point I'm making is that the assumption that this complexity is either
<br>
measurable (big or otherwise) *or* bounded in a context-free way is a qualitative,
<br>
intuitive assessment that is neither defended in the &quot;Friendliness&quot; argument nor
<br>
--- in the absence of such a defense --- provably defensible.  And while I haven't
<br>
done it, it in fact *may* be provably *indefensible.*
<br>
<p>jb
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2442.html">Gordon Worley: "Re: A more concise and quantifiable definition of Friendliness?"</a>
<li><strong>Previous message:</strong> <a href="2440.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<li><strong>In reply to:</strong> <a href="2439.html">Eliezer S. Yudkowsky: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2440.html">Jeff Bone: "Re: The inevitability of death, or the death of inevitability?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2441">[ date ]</a>
<a href="index.html#2441">[ thread ]</a>
<a href="subject.html#2441">[ subject ]</a>
<a href="author.html#2441">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
