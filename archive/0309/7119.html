<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Progress, and One road or many to AI?</title>
<meta name="Author" content="James Rogers (jamesr@best.com)">
<meta name="Subject" content="RE: Progress, and One road or many to AI?">
<meta name="Date" content="2003-09-11">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Progress, and One road or many to AI?</h1>
<!-- received="Thu Sep 11 16:19:42 2003" -->
<!-- isoreceived="20030911221942" -->
<!-- sent="Thu, 11 Sep 2003 14:40:13 -0700" -->
<!-- isosent="20030911214013" -->
<!-- name="James Rogers" -->
<!-- email="jamesr@best.com" -->
<!-- subject="RE: Progress, and One road or many to AI?" -->
<!-- id="003f01c378ad$48768cb0$f200000a@avalon" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="20030911150557.39374.qmail@web11205.mail.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Rogers (<a href="mailto:jamesr@best.com?Subject=RE:%20Progress,%20and%20One%20road%20or%20many%20to%20AI?"><em>jamesr@best.com</em></a>)<br>
<strong>Date:</strong> Thu Sep 11 2003 - 15:40:13 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7120.html">Joshua Hublar: "Re: What so bad"</a>
<li><strong>Previous message:</strong> <a href="7118.html">Eliezer S. Yudkowsky: "Re: My doubts about Libertarianism and volitional morality"</a>
<li><strong>In reply to:</strong> <a href="7116.html">Kwame Porter-Robinson: "Re: Progress, and One road or many to AI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7117.html">Eliezer S. Yudkowsky: "Re: Progress, and One road or many to AI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7119">[ date ]</a>
<a href="index.html#7119">[ thread ]</a>
<a href="subject.html#7119">[ subject ]</a>
<a href="author.html#7119">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Kwame Porter-Robinson wrote:
<br>
<em>&gt; Some more questions, if you can stand them: Since it
</em><br>
<em>&gt; codes patterns in abstract have you tested it against
</em><br>
<em>&gt; &quot;junk&quot; material to ensure a control to compare
</em><br>
<em>&gt; against?
</em><br>
<p><p>Yes.  That is why I have simple generator functions that generate reliable
<br>
mathematically characteristic data streams.  It is how I baseline and profile an
<br>
implementation in the abstract.  A strong PRNG, for example will generate a data
<br>
stream that shouldn't converge but diverge on any computer we can build today.
<br>
Other generator functions produce data streams that converge or diverge at
<br>
different levels of model complexity and at different rates.
<br>
<p>The metrics generated by these tests aren't terribly useful in themselves beyond
<br>
determining the correctness and efficiency of implementation.  What is more
<br>
useful is that they give me something to compare against real-world data streams
<br>
to infer their intrinsic complexity.  There are several levels of complexity
<br>
when interpreting the metrics that are actually being generated.
<br>
<p>It is worth pointing out that &quot;convergence&quot; is an emergent property that is
<br>
essentially a function of the amount of memory/nodes/neurons/whatever that are
<br>
available to the SI engine.  Things that basically don't converge in any
<br>
meaningful sense or even show mild divergence with some small amount of memory
<br>
may show very marked convergence when given 10x or 100x the memory for the
<br>
engine to work with.
<br>
<p>&nbsp;
<br>
<em>&gt; And would it be worth it to run this code upon two
</em><br>
<em>&gt; types of related datasets, such as a code tree and the 
</em><br>
<em>&gt; corresponding documentation? Or perhaps, even upon itself, or 
</em><br>
<em>&gt; would that meaningless?
</em><br>
<p><p>I know what you are getting at, but that is something somewhat different. Any
<br>
highly efficient SI implementation necessarily does deep and exhaustive pattern
<br>
indexing that is highly optimized for pattern matching and manipulation.  There
<br>
are a number of caveats and considerations that make it a more complicated
<br>
issue.
<br>
<p>The importance of the SI implementation efficiency test independent of what you
<br>
are asking is that while you can do reasonably good pattern work with an
<br>
inefficient implementation, it is effectively intractable for higher-order
<br>
patterns.  And if the SI implementation is nearly optimal, then not only are the
<br>
pattern inference/matching/etc capabilities nearly optimal, but they actually
<br>
become tractable for interesting levels of complexity and depth.  That is why
<br>
the SI implementation is the linchpin; if you don't solve that nothing else is
<br>
tractable, and if you do solve it everything else is not only tractable for
<br>
interesting spaces but nearly optimal as a side-effect.  I generally view it as
<br>
a many faceted but nonetheless single problem.
<br>
<p>The machinery has a few more pieces than are strictly required for it to be a
<br>
mere SI implementation, but it was important that no matter what I did to the
<br>
machinery design one of its properties had to be that it was a very efficient SI
<br>
for the purposes of information representation or it could not work.  In
<br>
practice, the current versions of the system contain no real duct tape or narrow
<br>
implementational aspects that need to be tuned (or can be tuned).
<br>
&nbsp;
<br>
&nbsp;
<br>
<em>&gt; Not to offend, but anything can be hacked and there's
</em><br>
<em>&gt; always someone smarter than you, so don't let that
</em><br>
<em>&gt; hold you back. If you had the code tied up in some
</em><br>
<em>&gt; kind hedge investment and legalities prevented you,
</em><br>
<em>&gt; than sure, don't release it.
</em><br>
<p><p>I'm not offended in the least, and I have not yet put any legal encumberances on
<br>
the code (beyond the automatically implied copyright I guess).  There obviously
<br>
will be encumberances on code developed for specific applications.
<br>
<p>While there may be someone smarter than me, I have strong doubts that there is
<br>
likely to be anyone that understands this particular algorithm space better and
<br>
my general code hacking skills are pretty sharp.  And while someone could do
<br>
superficial hacks and tweaks, there isn't much to do on the algorithms
<br>
themselves and the implementation is generally very elegant (and in ways that
<br>
many hackers probably wouldn't even notice).  While there may be many uses for
<br>
the code, there is little need to *hack* the code.
<br>
<p><p><em>&gt; If anyone approaches AGI, but it is funded via some
</em><br>
<em>&gt; kind of commercialization scheme, mankind will not see 
</em><br>
<em>&gt; Singularity from it. It's a catch-22 though cause you want to 
</em><br>
<em>&gt; make money, but would like to move things along towards the 
</em><br>
<em>&gt; Singularity. You have to look at who legally controls the 
</em><br>
<em>&gt; code and decide which is more important; money or Man.
</em><br>
<p><p>Question:  What does code control have to do with the Singularity happening or
<br>
not, as long as the code is running?  From a theoretical standpoint, I would be
<br>
more worried if every slack-jawed yokel and their brother had their own personal
<br>
Seed AIs that they were monkeying with.  I would rather have one or two good
<br>
implementations than thousands of ones of varying quality out in the wild run by
<br>
wealthy people who may be naive, fools, mentally unsound, and/or stupid.
<br>
<p>Part of the problem is that you need lots of money to acquire the kinds of
<br>
machinery that would allow a machine to have super-human intelligence.  Really
<br>
good human level intelligence will run you about a 1-10 Tbyte of usable RAM (my
<br>
best estimate), and the biggest Big Iron today will get you about 0.5 Tbyte.
<br>
(Ten lashes for anyone who says &quot;but a beowulf cluster...&quot; and doesn't
<br>
understand why that won't work.)  And while such a machine would be faster than
<br>
a human, it would not be significantly smarter.
<br>
<p>That would leave me about a few tens of millions of dollars short of where I
<br>
need to be to bootstrap an SAI.  On the other hand, a few tens of millions of
<br>
dollars is chump change to come by for a company with a very slick product.  I
<br>
wouldn't whore myself completely for that much money -- that's dangerous -- but
<br>
I shouldn't really need to.
<br>
<p>I think your conception of what the realistic trajectories are is naive.  If
<br>
Friendliness is a concern (and this *is* SL4), then a closed implementation
<br>
backed by substantial capital resources looks pretty good.  If you have an idea
<br>
that doesn't involve PC clusters and free code/love/beer as a game plan, I'm
<br>
open to suggestions.  But with all due respect, your assertion wasn't
<br>
particularly compelling or constructive as presented.  I'm not a Kool-Aid
<br>
drinker, but I can be swayed by a solid argument.
<br>
<p>Cheers,
<br>
<p>-James Rogers
<br>
&nbsp;<a href="mailto:jamesr@best.com?Subject=RE:%20Progress,%20and%20One%20road%20or%20many%20to%20AI?">jamesr@best.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7120.html">Joshua Hublar: "Re: What so bad"</a>
<li><strong>Previous message:</strong> <a href="7118.html">Eliezer S. Yudkowsky: "Re: My doubts about Libertarianism and volitional morality"</a>
<li><strong>In reply to:</strong> <a href="7116.html">Kwame Porter-Robinson: "Re: Progress, and One road or many to AI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7117.html">Eliezer S. Yudkowsky: "Re: Progress, and One road or many to AI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7119">[ date ]</a>
<a href="index.html#7119">[ thread ]</a>
<a href="subject.html#7119">[ subject ]</a>
<a href="author.html#7119">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:42 MDT
</em></small></p>
</body>
</html>
