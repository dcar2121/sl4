<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: How will the hunger for computation power shape the emerging mind?</title>
<meta name="Author" content="Nick Hay (nickjhay@hotmail.com)">
<meta name="Subject" content="Re: How will the hunger for computation power shape the emerging mind?">
<meta name="Date" content="2003-07-11">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: How will the hunger for computation power shape the emerging mind?</h1>
<!-- received="Fri Jul 11 02:02:50 2003" -->
<!-- isoreceived="20030711080250" -->
<!-- sent="Fri, 11 Jul 2003 20:01:13 +1200" -->
<!-- isosent="20030711080113" -->
<!-- name="Nick Hay" -->
<!-- email="nickjhay@hotmail.com" -->
<!-- subject="Re: How will the hunger for computation power shape the emerging mind?" -->
<!-- id="200307112001.13371.nickjhay@hotmail.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="3F0EF2B8.17629.1527143@localhost" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Nick Hay (<a href="mailto:nickjhay@hotmail.com?Subject=Re:%20How%20will%20the%20hunger%20for%20computation%20power%20shape%20the%20emerging%20mind?"><em>nickjhay@hotmail.com</em></a>)<br>
<strong>Date:</strong> Fri Jul 11 2003 - 02:01:13 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="6986.html">Dani Eder: "Re: Whole Earth Singularity Issue"</a>
<li><strong>Previous message:</strong> <a href="6984.html">Philip Sutton: "How will the hunger for computation power shape the emerging mind?"</a>
<li><strong>In reply to:</strong> <a href="6984.html">Philip Sutton: "How will the hunger for computation power shape the emerging mind?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6987.html">Dani Eder: "Re: How will the hunger for computation power shape the emerging mind?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6985">[ date ]</a>
<a href="index.html#6985">[ thread ]</a>
<a href="subject.html#6985">[ subject ]</a>
<a href="author.html#6985">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Philip Sutton wrote:
<br>
<em>&gt; The cost per unit will fall over the years but the demand for 
</em><br>
<em>&gt; computational power will grow rapidly - faster?? - so expanding mind 
</em><br>
<em>&gt; power is likely to still be an expensive proposition.
</em><br>
<p>Well, expensive until the AGI works out how to implement molecular 
<br>
nanotechnology, for instance. I have a feeling a linear increase the 
<br>
computational power will give you an exponential rise in intelligence, like 
<br>
the change from chimpanzees to humans. 
<br>
<p><em>&gt; So it's out to the saltmines for the young AGI to earn some money to 
</em><br>
<em>&gt; support its habit - expanding mind power.
</em><br>
<p>With sufficent intelligence it's not necessary to play the human economic 
<br>
game. The extra computational power is going towards solving the problem, 
<br>
unlike in the case of a drug addict.
<br>
<p><em>&gt; How do we avoid getting a generation of AGIs that will do whatever
</em><br>
<em>&gt; earns the most money to expand their minds?  If Dubya or some Mafia
</em><br>
<em>&gt; boss or an arms manufacture or a drug company or....pay the highest
</em><br>
<em>&gt; why wouldn't the young AGI go along with it?
</em><br>
<p>To what end is the AGI collecting computational power? Given an AGI with a 
<br>
supergoal of Friendliness (where killing people generally isn't desirable), 
<br>
although computational power is useful (allows it to better work out how to 
<br>
help), it's not useful at all costs. A necessary set to avoid such a 
<br>
wireheading failure (computational power isn't valuable at all costs to a 
<br>
humane mind) is to have Friendliness as the supergoal from which value is 
<br>
derived.
<br>
<p>Basically, given Friendliness the AGI can make the tradeoffs we would. Perhaps 
<br>
arms running is the best solution in some contexts; perhaps it's bad in all 
<br>
contexts. In either case when arms running is obviously bad to humans like 
<br>
us, a Friendly AGI can likewise see selling arms as being unFriendly, even 
<br>
if, all other things being equal, getting money is Friendly.
<br>
<p>- Nick
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="6986.html">Dani Eder: "Re: Whole Earth Singularity Issue"</a>
<li><strong>Previous message:</strong> <a href="6984.html">Philip Sutton: "How will the hunger for computation power shape the emerging mind?"</a>
<li><strong>In reply to:</strong> <a href="6984.html">Philip Sutton: "How will the hunger for computation power shape the emerging mind?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6987.html">Dani Eder: "Re: How will the hunger for computation power shape the emerging mind?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6985">[ date ]</a>
<a href="index.html#6985">[ thread ]</a>
<a href="subject.html#6985">[ subject ]</a>
<a href="author.html#6985">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:42 MDT
</em></small></p>
</body>
</html>
