<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=gb2312">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: answers I'd like, part 2</title>
<meta name="Author" content="Wei Dai (weidai@weidai.com)">
<meta name="Subject" content="answers I'd like, part 2">
<meta name="Date" content="2007-11-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>answers I'd like, part 2</h1>
<!-- received="Tue Nov 13 22:39:17 2007" -->
<!-- isoreceived="20071114053917" -->
<!-- sent="Tue, 13 Nov 2007 21:35:47 -0800" -->
<!-- isosent="20071114053547" -->
<!-- name="Wei Dai" -->
<!-- email="weidai@weidai.com" -->
<!-- subject="answers I'd like, part 2" -->
<!-- id="A95CD0DFAF6A4B79813DB2D8EE43DA3A@weidaim1" -->
<!-- charset="gb2312" -->
<!-- inreplyto="D63332D44E554092A5B648082EF0AA59@weidaim1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Wei Dai (<a href="mailto:weidai@weidai.com?Subject=Re:%20answers%20I'd%20like,%20part%202"><em>weidai@weidai.com</em></a>)<br>
<strong>Date:</strong> Tue Nov 13 2007 - 22:35:47 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17102.html">Stathis Papaioannou: "Re: answers I'd like from an SI"</a>
<li><strong>Previous message:</strong> <a href="17100.html">Wei Dai: "Re: answers I'd like from an SI"</a>
<li><strong>In reply to:</strong> <a href="17013.html">Wei Dai: "answers I'd like from an SI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17105.html">Stathis Papaioannou: "Re: answers I'd like, part 2"</a>
<li><strong>Reply:</strong> <a href="17105.html">Stathis Papaioannou: "Re: answers I'd like, part 2"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17101">[ date ]</a>
<a href="index.html#17101">[ thread ]</a>
<a href="subject.html#17101">[ subject ]</a>
<a href="author.html#17101">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
SIAI has publicized the importance of the morality question. Certainly 
<br>
disaster will ensue if a powerful AI gets that question wrong, or has the 
<br>
wrong answer programmed into it. But it seems to me that getting any of the 
<br>
other questions I listed wrong can equally lead to catastrophe. (See 
<br>
examples below.) Assuming that it is unlikely we will obtain fully 
<br>
satisfactory answers to all of the questions before the Singularity occurs, 
<br>
does it really make sense to pursue an AI-based approach?
<br>
<p>To create an AI with abilities and intuitions comparable to human beings on 
<br>
these subjects, we would need to either reverse engineer where our 
<br>
intuitions come from and how we are able to contemplate these questions, or 
<br>
use evolutionary trial-and-error methods. Neither of these approaches seems 
<br>
to have an advantage over improving human intelligence. The former is likely 
<br>
slower and more difficult, and the latter is probably more dangerous.
<br>
<p>Ok, I don't expect SIAI to change its entire mission (and name!) but it 
<br>
wouldn't hurt to keep this problem in mind.
<br>
<p>Below I will give some examples of how things could go badly if an AI gets 
<br>
the answers wrong.
<br>
<p><em>&gt; How does math really work? Why do we believe that P!=NP even though we 
</em><br>
<em>&gt; don't have a proof one way or the other?
</em><br>
<p>Due to faulty mathematical intuitions, the AI starts believing it's likely 
<br>
that P=NP, and devotes almost all available resources into searching for a 
<br>
polynomial time algorithm for NP-complete problems, in the expectation that 
<br>
everyone will be much better off once a solution is found.
<br>
<p><em>&gt; How does induction really work? Why do we intuitively know that, contra 
</em><br>
<em>&gt; Solomonoff Induction, we shouldn't believe in the non-existence of 
</em><br>
<em>&gt; halting-problem oracles no matter what evidence we may see?
</em><br>
<p>I've written about this already at 
<br>
<a href="http://groups.google.com/group/everything-list/browse_frm/thread/c7442c13ff1396ec/">http://groups.google.com/group/everything-list/browse_frm/thread/c7442c13ff1396ec/</a>.
<br>
<p><em>&gt; Is there such a thing as absolute complexity (as opposed to complexity 
</em><br>
<em>&gt; relative to a Turing machine or some other construct)?
</em><br>
<p>Complexity is clearly related to induction, and morality may also be related 
<br>
to complexity (Peter de Blanc and I have both suggested this; see 
<br>
<a href="http://www.intelligence.org/blog/2007/10/06/system-error-morality-not-found/">http://www.intelligence.org/blog/2007/10/06/system-error-morality-not-found/</a> and 
<br>
<a href="http://www.overcomingbias.com/2007/10/pascals-mugging.html">http://www.overcomingbias.com/2007/10/pascals-mugging.html</a>). So getting this 
<br>
question wrong probably implies getting induction and morality wrong as 
<br>
well.
<br>
<p><em>&gt; How does qualia work? Why do certain patterns of neuron firings translate 
</em><br>
<em>&gt; into sensations of pain, and other patterns into pleasure?
</em><br>
<p>The AI wants to prevent people from running torture sims, but unfortunately 
<br>
it can't tell how realistic a sim needs to be to generate pain qualia. To be 
<br>
safe, no one is allowed to play Dungeons and Dragons anymore, even the 
<br>
paper-and-pencil version.
<br>
<p><em>&gt; How does morality work? If I take a deterministic program that simulates a 
</em><br>
<em>&gt; neuron firing pattern that represents pleasure, and run it twice, is that 
</em><br>
<em>&gt; twice as good as running it once? Or good at all?
</em><br>
<p>This one doesn't need further explanation, I think (hope).
<br>
<p><em>&gt; Why am I me, and not one of the billions of other people on Earth, or one 
</em><br>
<em>&gt; of the many people in other parts of the multiverse?
</em><br>
<p>The AI decides that the simplest explanation for this is that it is the only 
<br>
conscious entity in the universe, and everyone else (especially human 
<br>
beings) must be philosophical zombies.
<br>
&nbsp;
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17102.html">Stathis Papaioannou: "Re: answers I'd like from an SI"</a>
<li><strong>Previous message:</strong> <a href="17100.html">Wei Dai: "Re: answers I'd like from an SI"</a>
<li><strong>In reply to:</strong> <a href="17013.html">Wei Dai: "answers I'd like from an SI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17105.html">Stathis Papaioannou: "Re: answers I'd like, part 2"</a>
<li><strong>Reply:</strong> <a href="17105.html">Stathis Papaioannou: "Re: answers I'd like, part 2"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17101">[ date ]</a>
<a href="index.html#17101">[ thread ]</a>
<a href="subject.html#17101">[ subject ]</a>
<a href="author.html#17101">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:00 MDT
</em></small></p>
</body>
</html>
