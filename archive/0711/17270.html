<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: How to make a slave (many replies )</title>
<meta name="Author" content="Thomas McCabe (pphysics141@gmail.com)">
<meta name="Subject" content="Re: How to make a slave (many replies )">
<meta name="Date" content="2007-11-25">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: How to make a slave (many replies )</h1>
<!-- received="Sun Nov 25 19:36:10 2007" -->
<!-- isoreceived="20071126023610" -->
<!-- sent="Sun, 25 Nov 2007 21:33:56 -0500" -->
<!-- isosent="20071126023356" -->
<!-- name="Thomas McCabe" -->
<!-- email="pphysics141@gmail.com" -->
<!-- subject="Re: How to make a slave (many replies )" -->
<!-- id="b7a9e8680711251833t7c15c893wf4979a38283db47b@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="474A24D5.8010501@acm.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas McCabe (<a href="mailto:pphysics141@gmail.com?Subject=Re:%20How%20to%20make%20a%20slave%20(many%20replies%20)"><em>pphysics141@gmail.com</em></a>)<br>
<strong>Date:</strong> Sun Nov 25 2007 - 19:33:56 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17271.html">Daniel Burfoot: "Re: General summary of FAI theory"</a>
<li><strong>Previous message:</strong> <a href="17269.html">Harry Chesley: "Re: How to make a slave (many replies )"</a>
<li><strong>In reply to:</strong> <a href="17269.html">Harry Chesley: "Re: How to make a slave (many replies )"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17275.html">Harry Chesley: "Re: How to make a slave (many replies )"</a>
<li><strong>Reply:</strong> <a href="17275.html">Harry Chesley: "Re: How to make a slave (many replies )"</a>
<li><strong>Reply:</strong> <a href="17276.html">John K Clark: "Re: How to make a slave (many replies )"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17270">[ date ]</a>
<a href="index.html#17270">[ thread ]</a>
<a href="subject.html#17270">[ subject ]</a>
<a href="author.html#17270">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Nov 25, 2007 8:43 PM, Harry Chesley &lt;<a href="mailto:chesley@acm.org?Subject=Re:%20How%20to%20make%20a%20slave%20(many%20replies%20)">chesley@acm.org</a>&gt; wrote:
<br>
<em>&gt; Thomas McCabe wrote:
</em><br>
<em>&gt; &gt; I have nothing against you posting, but please *read* before you
</em><br>
<em>&gt; &gt; post. If you disagree with everything you read, and then post about
</em><br>
<em>&gt; &gt; it, at least we can have a useful discussion.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I would be curious to hear what you consider the prerequisite reading
</em><br>
<em>&gt; material to be. (I don't mean that at all facetiously. I really would
</em><br>
<em>&gt; like to know.)
</em><br>
<em>&gt;
</em><br>
<em>&gt; But note that not everyone on this list has the same goal or background
</em><br>
<em>&gt; as you do. My own interest is in building AIs. Theoretical speculation
</em><br>
<em>&gt; on things like fundamental limits of intelligence and provably friendly
</em><br>
<em>&gt; AIs is interesting but often pretty irrelevant. It's sort of as if I
</em><br>
<em>&gt; were trying to build a crystal wireless set and you're talking about
</em><br>
<em>&gt; Feynman diagrams. They may be entertaining, and they're certainly
</em><br>
<em>&gt; related in some way, but they don't help me build the radio. Similarly,
</em><br>
<em>&gt; this list has been an occasionally interesting diversion, but I don't
</em><br>
<em>&gt; want to spend inordinate amounts of time reading tangential material.
</em><br>
<p>If you want to build a generally intelligent AI, it had better darn be
<br>
Friendly, or Very Bad Things (tm) are going to happen.
<br>
<p><em>&gt; &gt; We are so used to interacting with a certain type of intelligence
</em><br>
<em>&gt; &gt; (Homo sapiens sapiens) that we would be shocked by the alienness of
</em><br>
<em>&gt; &gt; a generally intelligent AI. Look at how shocked we are by *each
</em><br>
<em>&gt; &gt; other* when we violate cultural norms. And we're all 99.9% identical;
</em><br>
<em>&gt; &gt; we all share the same brain architecture. See
</em><br>
<em>&gt; &gt; <a href="http://www.depaul.edu/~mfiddler/hyphen/humunivers.htm">http://www.depaul.edu/~mfiddler/hyphen/humunivers.htm</a> for a list of
</em><br>
<em>&gt; &gt; things that we have in common and the vast majority of AIs do *not*.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Very true. And one reason we may intentionally build anthropomorphic AIs.
</em><br>
<p>*Why* would anyone build an anthropomorphic AI? It would be a huge
<br>
amount of extra work, for no palpable gain, at a great risk to the
<br>
planet.
<br>
<p><em>&gt; &gt; How is this going to happen? Magic? Osmosis? None of our other
</em><br>
<em>&gt; &gt; computer programs just wake up one day and start displaying parts of
</em><br>
<em>&gt; &gt; a human personality; why would an AGI?
</em><br>
<em>&gt;
</em><br>
<em>&gt; It'll happen by design, of course. You don't think we can program a
</em><br>
<em>&gt; human-like personality into an AI?
</em><br>
<p>No. We'll either realize how useless it is and not try, or try and
<br>
fail. Anyone with the intelligence and determination to implement a
<br>
human-like personality, which is stable under recursive
<br>
self-improvement, has the intelligence and determination to realize
<br>
why it is not a good idea.
<br>
<p><em>&gt; For example, some companies are building companion robots for the
</em><br>
<em>&gt; elderly that very intentionally have personality, and that encourage the
</em><br>
<em>&gt; formation of long-term emotional relationships with their owners.
</em><br>
<p>These aren't AGIs, thank Eru. If they were we wouldn't be here.
<br>
<p><em>&gt; &gt; We can name a long list of things that are definitely
</em><br>
<em>&gt; &gt; anthropomorphic, because they only arise out of specific selection
</em><br>
<em>&gt; &gt; pressures. Love and mating for one thing. Tribal political structures
</em><br>
<em>&gt; &gt; for another.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I don't have your confidence that I know what is and isn't inherent. For
</em><br>
<em>&gt; example, I'm not sure that a group of interacting GAIs would not
</em><br>
<em>&gt; logically employ a system very much like tribal politics.
</em><br>
<p>Where would such a system come from? Without strong selection
<br>
pressure, *why* would such a system arise? If you put a bunch of
<br>
humans together, they'll start politicking. We're human, and so when
<br>
we imagine *any* intelligent entities, we imagine politicking. This is
<br>
not how it actually works.
<br>
<p><em>&gt; (Agoric
</em><br>
<em>&gt; systems come to mind.) Or even love.
</em><br>
<p>Again, love evolved because of strong *selection pressures* towards
<br>
efficient reproduction.
<br>
<p><em>&gt; As I understand it, love evolved
</em><br>
<em>&gt; because it allows two parties to trust each other beyond the initial
</em><br>
<em>&gt; exchange,
</em><br>
<p>No, no, no. Love is not a generic &quot;thingy that allows two
<br>
intelligences to trust each other&quot;. Love is a complex functional
<br>
adaptation, created by billions of years of evolution on organic
<br>
beings. An AGI can trust another AGI, in the sense that another AGI's
<br>
statements are given high confidence in the Bayesian probability
<br>
network. This is not &quot;love&quot;. If you don't believe me, go read the
<br>
cognitive science literature on love, I don't know it in detail but we
<br>
know it is *far* more complex than that.
<br>
<p><em>&gt; which is important for some mutually beneficial contracts
</em><br>
<em>&gt; which would otherwise be unworkable. A similar arrangement might make
</em><br>
<em>&gt; sense in a GAI. If you feel that's impossible because machines can't
</em><br>
<em>&gt; feel, then we have another area of disagreement as I don't see any
</em><br>
<em>&gt; reason they should not if we can.
</em><br>
<p>There is a huge, huge difference between &quot;feeling&quot; and Homo
<br>
economicus-type interaction. One sure as heck does not imply the
<br>
other.
<br>
<p><em>&gt; &gt; Brain simulations and uploads are another thing, I'm talking about
</em><br>
<em>&gt; &gt; built-from-scratch, human-designed AGIs.
</em><br>
<em>&gt;
</em><br>
<em>&gt; You may have been talking only about built-from-scratch GAIs, but we
</em><br>
<em>&gt; weren't. Dare I tell you to read the previous posts before replying?
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<p>I've read all the posts I've responded to, but this thread alone has
<br>
dozens of posts, there's no real point to reading them all.
<br>
<p>&nbsp;- Tom
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17271.html">Daniel Burfoot: "Re: General summary of FAI theory"</a>
<li><strong>Previous message:</strong> <a href="17269.html">Harry Chesley: "Re: How to make a slave (many replies )"</a>
<li><strong>In reply to:</strong> <a href="17269.html">Harry Chesley: "Re: How to make a slave (many replies )"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17275.html">Harry Chesley: "Re: How to make a slave (many replies )"</a>
<li><strong>Reply:</strong> <a href="17275.html">Harry Chesley: "Re: How to make a slave (many replies )"</a>
<li><strong>Reply:</strong> <a href="17276.html">John K Clark: "Re: How to make a slave (many replies )"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17270">[ date ]</a>
<a href="index.html#17270">[ thread ]</a>
<a href="subject.html#17270">[ subject ]</a>
<a href="author.html#17270">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:01 MDT
</em></small></p>
</body>
</html>
