<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: What best evidence for fast AI?</title>
<meta name="Author" content="Peter C. McCluskey (pcm@rahul.net)">
<meta name="Subject" content="Re: What best evidence for fast AI?">
<meta name="Date" content="2007-11-12">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: What best evidence for fast AI?</h1>
<!-- received="Mon Nov 12 13:13:30 2007" -->
<!-- isoreceived="20071112201330" -->
<!-- sent="Mon, 12 Nov 2007 12:10:11 -0800 (PST)" -->
<!-- isosent="20071112201011" -->
<!-- name="Peter C. McCluskey" -->
<!-- email="pcm@rahul.net" -->
<!-- subject="Re: What best evidence for fast AI?" -->
<!-- id="20071112201011.4AD882BFFB@mauve.rahul.net" -->
<!-- inreplyto="47363525.9030906@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Peter C. McCluskey (<a href="mailto:pcm@rahul.net?Subject=Re:%20What%20best%20evidence%20for%20fast%20AI?"><em>pcm@rahul.net</em></a>)<br>
<strong>Date:</strong> Mon Nov 12 2007 - 13:10:11 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17078.html">Jef Allbright: "Re: answers I'd like from an SI"</a>
<li><strong>Previous message:</strong> <a href="17076.html">Matt Mahoney: "Re: answers I'd like from an SI"</a>
<li><strong>In reply to:</strong> <a href="17034.html">Eliezer S. Yudkowsky: "Re: What best evidence for fast AI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17091.html">Stathis Papaioannou: "Re: What best evidence for fast AI?"</a>
<li><strong>Reply:</strong> <a href="17091.html">Stathis Papaioannou: "Re: What best evidence for fast AI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17077">[ date ]</a>
<a href="index.html#17077">[ thread ]</a>
<a href="subject.html#17077">[ subject ]</a>
<a href="author.html#17077">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&nbsp;<a href="mailto:sentience@pobox.com?Subject=Re:%20What%20best%20evidence%20for%20fast%20AI?">sentience@pobox.com</a> (Eliezer S. Yudkowsky) writes:
<br>
<em>&gt;I would begin by asking if there was ever, in the whole history of 
</em><br>
<em>&gt;technology, a single case where someone *first* duplicated a desirable 
</em><br>
<em>&gt;effect by emulating biology at a lower level of organization, without 
</em><br>
<em>&gt;understanding the principles of that effect's production from that low 
</em><br>
<p>&nbsp;Here are a few innovations that happened in a way that resembles uploading
<br>
more than it resembles designing AI based on the principles of intelligence:
<br>
&nbsp;- producing carrots and strawberries that are an order of magnitude
<br>
larger than their wild ancestors. This process appears to have used methods
<br>
of evolution before evolution was understood. Alternatives such as writing
<br>
new genomes from scratch or telling a molecular assembler where to put the
<br>
atoms still look hard.
<br>
&nbsp;- aspirin was created by tweaking an herbal medicine before we began to
<br>
understand how pain surpression works.
<br>
&nbsp;- inoculation as a means of reducing smallpox deaths appears to have
<br>
started about two millenia before there was a clear understanding of
<br>
how it works.
<br>
&nbsp;- molecular modeling via force fields is mostly based on low level
<br>
emulation of the behavior of specific bond types. A much more accurate
<br>
and much more general theory of chemistry was available before those
<br>
force fields were developed, but that general theory of quantum chemistry
<br>
is intractable for many problems unless you use a quantum computer.
<br>
<p><em>&gt;The notion of whole-brain emulation *which preserves intelligence's 
</em><br>
<em>&gt;mysteriousness* seems to me a device to preserve the future's 
</em><br>
<em>&gt;nonabsurdity - to avoid violating the invariant &quot;Intelligence is 
</em><br>
<em>&gt;mysterious&quot; in a futuristic prediction.  But the future is always absurd.
</em><br>
<p>&nbsp;It's not obvious whether brain emulation would preserve the mysteriousness
<br>
of intelligence.
<br>
<pre>
-- 
------------------------------------------------------------------------------
Peter McCluskey         | The road to hell is paved with overconfidence
www.bayesianinvestor.com| in your good intentions. - Stuart Armstrong
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17078.html">Jef Allbright: "Re: answers I'd like from an SI"</a>
<li><strong>Previous message:</strong> <a href="17076.html">Matt Mahoney: "Re: answers I'd like from an SI"</a>
<li><strong>In reply to:</strong> <a href="17034.html">Eliezer S. Yudkowsky: "Re: What best evidence for fast AI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17091.html">Stathis Papaioannou: "Re: What best evidence for fast AI?"</a>
<li><strong>Reply:</strong> <a href="17091.html">Stathis Papaioannou: "Re: What best evidence for fast AI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17077">[ date ]</a>
<a href="index.html#17077">[ thread ]</a>
<a href="subject.html#17077">[ subject ]</a>
<a href="author.html#17077">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:00 MDT
</em></small></p>
</body>
</html>
