<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Why friendly AI (FAI) won't work</title>
<meta name="Author" content="Harry Chesley (chesley@acm.org)">
<meta name="Subject" content="Re: Why friendly AI (FAI) won't work">
<meta name="Date" content="2007-11-28">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Why friendly AI (FAI) won't work</h1>
<!-- received="Wed Nov 28 18:45:40 2007" -->
<!-- isoreceived="20071129014540" -->
<!-- sent="Wed, 28 Nov 2007 17:43:29 -0800" -->
<!-- isosent="20071129014329" -->
<!-- name="Harry Chesley" -->
<!-- email="chesley@acm.org" -->
<!-- subject="Re: Why friendly AI (FAI) won't work" -->
<!-- id="474E1941.5090908@acm.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="20071128183009.GU26917@digitalkingdom.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Harry Chesley (<a href="mailto:chesley@acm.org?Subject=Re:%20Why%20friendly%20AI%20(FAI)%20won't%20work"><em>chesley@acm.org</em></a>)<br>
<strong>Date:</strong> Wed Nov 28 2007 - 18:43:29 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17311.html">Harry Chesley: "Re: Fwd: Why friendly AI (FAI) won't work"</a>
<li><strong>Previous message:</strong> <a href="17309.html">Harry Chesley: "Re: Why friendly AI (FAI) won't work"</a>
<li><strong>In reply to:</strong> <a href="17304.html">Robin Lee Powell: "Re: Why friendly AI (FAI) won't work"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17312.html">Thomas McCabe: "Re: Why friendly AI (FAI) won't work"</a>
<li><strong>Reply:</strong> <a href="17312.html">Thomas McCabe: "Re: Why friendly AI (FAI) won't work"</a>
<li><strong>Reply:</strong> <a href="17321.html">Kaj Sotala: "Re: Why friendly AI (FAI) won't work"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17310">[ date ]</a>
<a href="index.html#17310">[ thread ]</a>
<a href="subject.html#17310">[ subject ]</a>
<a href="author.html#17310">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Robin Lee Powell wrote:
<br>
<em>&gt; On Wed, Nov 28, 2007 at 08:49:39AM -0800, Harry Chesley wrote:
</em><br>
<em>&gt;&gt; First, to be useful, FAI needs to be bullet-proof, with no way for
</em><br>
<em>&gt;&gt; the AI to circumvent it.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If you're talking about circumvention, you've already missed the
</em><br>
<em>&gt; point. An FA no more tries to circumvent its friendliness then you
</em><br>
<em>&gt; have a deep-seated desire to want to slaughter babxes.
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt; This equates to writing a bug-free program, which we all know is
</em><br>
<em>&gt;&gt; next to impossible.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I don't know who &quot;we all&quot; is there, but they are wrong.
</em><br>
<em>&gt; <a href="http://en.wikipedia.org/wiki/Six_Sigma">http://en.wikipedia.org/wiki/Six_Sigma</a>
</em><br>
<em>&gt;
</em><br>
<em>&gt; It's hard, and requires concerted effort, but when was the last time
</em><br>
<em>&gt; you hard of a bug in an air traffic control program? It happens, but
</em><br>
<em>&gt; it's an extremely rare thing isolated to *particular* ATC programs;
</em><br>
<em>&gt; most of them are basically bug free. Same with the space shuttle.
</em><br>
<em>&gt; Same with most hospital equipment.
</em><br>
<p>Those techniques work when you have a very well-defined specification of
<br>
the application you're developing, and when you're willing to put lots
<br>
of resources into making the implementation correct. Do you really
<br>
believe that the AIs created in some random research lab or some garage
<br>
will meet either of those criteria?
<br>
<p><em>&gt;&gt; Second, I believe there are other ways to achieve the same goal,
</em><br>
<em>&gt;&gt; rendering FAI an unnecessary and onerous burden. These include
</em><br>
<em>&gt;&gt; separating input from output, and separating intellect from
</em><br>
<em>&gt;&gt; motivation. In the former, you just don't supply any output
</em><br>
<em>&gt;&gt; channels except ones that can be monitored and edited.
</em><br>
<em>&gt;
</em><br>
<em>&gt; OMFG has that topic been done to death. Read the archives on AI
</em><br>
<em>&gt; boxing.
</em><br>
<p>And nothing that I've read about it has yet convinced me. What I've seen
<br>
seems to come down to one of two arguments: 1) Intelligence is like a
<br>
corrosive substance that will leak out, overflow, or corrode any
<br>
container. This seems too simplistic an argument to me. Intelligence is
<br>
far to complex to be analyzed as a commodity. Or 2) intelligence is
<br>
anthropomorphic in that, like us, it will never stand for being boxed up
<br>
and, being so very smart, will figure out a way out of the box. That
<br>
strikes me as too anthropomorphic. (Anthropomorphism has its place, but
<br>
every part of it is not a required part of every AI.) Nor do I buy the
<br>
argument that a super-AI can talk its way out. (I'll leave out 3) that
<br>
it will take over the world to get more computing power, since, although
<br>
an entertaining thought, I don't see it as a serious scenario, more like
<br>
the plot to a science fiction novel -- oh, wait, it's already been done,
<br>
The God Machine by Martin Caidin.)
<br>
<p><em>&gt; Why should we go to the effort of doing your research for you? How
</em><br>
<em>&gt; arrogant is *that*?
</em><br>
<p>Please don't do any more than you feel like. But please do understand
<br>
that my questions to this list are not just an attempt to stir up the
<br>
ant hill (tempting though that may be). I am actively working on AI, and
<br>
though I'm unlikely create a singularity, I do feel I should worry about
<br>
these issues. At present, my AI architecture has no facilities for FAI
<br>
as discussed here because I think it's a waste of time.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17311.html">Harry Chesley: "Re: Fwd: Why friendly AI (FAI) won't work"</a>
<li><strong>Previous message:</strong> <a href="17309.html">Harry Chesley: "Re: Why friendly AI (FAI) won't work"</a>
<li><strong>In reply to:</strong> <a href="17304.html">Robin Lee Powell: "Re: Why friendly AI (FAI) won't work"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17312.html">Thomas McCabe: "Re: Why friendly AI (FAI) won't work"</a>
<li><strong>Reply:</strong> <a href="17312.html">Thomas McCabe: "Re: Why friendly AI (FAI) won't work"</a>
<li><strong>Reply:</strong> <a href="17321.html">Kaj Sotala: "Re: Why friendly AI (FAI) won't work"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17310">[ date ]</a>
<a href="index.html#17310">[ thread ]</a>
<a href="subject.html#17310">[ subject ]</a>
<a href="author.html#17310">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:01 MDT
</em></small></p>
</body>
</html>
