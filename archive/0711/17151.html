<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI</title>
<meta name="Author" content="Stathis Papaioannou (stathisp@gmail.com)">
<meta name="Subject" content="Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI">
<meta name="Date" content="2007-11-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI</h1>
<!-- received="Mon Nov 19 16:22:09 2007" -->
<!-- isoreceived="20071119232209" -->
<!-- sent="Tue, 20 Nov 2007 10:20:05 +1100" -->
<!-- isosent="20071119232005" -->
<!-- name="Stathis Papaioannou" -->
<!-- email="stathisp@gmail.com" -->
<!-- subject="Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI" -->
<!-- id="f21c22e30711191520l3c758593k39d036bcd24aba60@mail.gmail.com" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="1195492570.18983.3.camel@localhost.localdomain" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Stathis Papaioannou (<a href="mailto:stathisp@gmail.com?Subject=Re:%20Building%20a%20friendly%20AI%20from%20a%20&quot;just%20do%20what%20I%20tell%20you&quot;%20AI"><em>stathisp@gmail.com</em></a>)<br>
<strong>Date:</strong> Mon Nov 19 2007 - 16:20:05 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17152.html">Damien Broderick: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>Previous message:</strong> <a href="17150.html">Thomas McCabe: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>In reply to:</strong> <a href="17147.html">Peter de Blanc: "Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17153.html">Robin Lee Powell: "Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI"</a>
<li><strong>Reply:</strong> <a href="17153.html">Robin Lee Powell: "Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17151">[ date ]</a>
<a href="index.html#17151">[ thread ]</a>
<a href="subject.html#17151">[ subject ]</a>
<a href="author.html#17151">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 20/11/2007, Peter de Blanc &lt;<a href="mailto:peter@spaceandgames.com?Subject=Re:%20Building%20a%20friendly%20AI%20from%20a%20&quot;just%20do%20what%20I%20tell%20you&quot;%20AI">peter@spaceandgames.com</a>&gt; wrote:
<br>
<em>&gt; On Mon, 2007-11-19 at 22:06 +1100, Stathis Papaioannou wrote:
</em><br>
<em>&gt; &gt; An AI need not think in any particular way nor have any particular
</em><br>
<em>&gt; &gt; goal. But if it is superintelligent, figuring out the subtleties of
</em><br>
<em>&gt; &gt; human language and what we call common sense should number amongst its
</em><br>
<em>&gt; &gt; capabilities. If not, then it wouldn't be able to manipulate people
</em><br>
<em>&gt; &gt; and would pose much less of a threat.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Just because an AI can model your goals and thought patterns does not
</em><br>
<em>&gt; mean that they are part of the AI's goal content.
</em><br>
<p>No, but insofar as you have any control over the goals of the AI,
<br>
making it understand you should be on the list before anything else.
<br>
<p>It is often suggested as an extreme example that an AI might destroy
<br>
the world in response to a seemingly benign request from a human. Ask
<br>
it to solve a mathematical problem, and it will convert the world to
<br>
computronium. As a first step towards this end, it will have to
<br>
understand humans well enough to model their behaviour in order to
<br>
wrest control of the world's resources away from them. So you may have
<br>
this situation:
<br>
<p>The AI can be designed to blindly and literally follow a human command.
<br>
<p>The AI cannot be designed to understand the subtleties of human
<br>
language behaviour.
<br>
<p>However, the AI may work out the subtleties of human language and
<br>
behaviour in the course of blindly and literally following the human
<br>
command.
<br>
<p><p><p><p><pre>
-- 
Stathis Papaioannou
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17152.html">Damien Broderick: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>Previous message:</strong> <a href="17150.html">Thomas McCabe: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>In reply to:</strong> <a href="17147.html">Peter de Blanc: "Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17153.html">Robin Lee Powell: "Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI"</a>
<li><strong>Reply:</strong> <a href="17153.html">Robin Lee Powell: "Re: Building a friendly AI from a &quot;just do what I tell you&quot; AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17151">[ date ]</a>
<a href="index.html#17151">[ thread ]</a>
<a href="subject.html#17151">[ subject ]</a>
<a href="author.html#17151">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:00 MDT
</em></small></p>
</body>
</html>
