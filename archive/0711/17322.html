<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: How to make a slave (was: Building a friendly AI)</title>
<meta name="Author" content="Jeff Herrlich (jeff_herrlich@yahoo.com)">
<meta name="Subject" content="Re: How to make a slave (was: Building a friendly AI)">
<meta name="Date" content="2007-11-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: How to make a slave (was: Building a friendly AI)</h1>
<!-- received="Thu Nov 29 13:37:14 2007" -->
<!-- isoreceived="20071129203714" -->
<!-- sent="Thu, 29 Nov 2007 12:34:50 -0800 (PST)" -->
<!-- isosent="20071129203450" -->
<!-- name="Jeff Herrlich" -->
<!-- email="jeff_herrlich@yahoo.com" -->
<!-- subject="Re: How to make a slave (was: Building a friendly AI)" -->
<!-- id="283907.67425.qm@web53005.mail.re2.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="1196117558.1972.1223351343@webmail.messagingengine.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Jeff Herrlich (<a href="mailto:jeff_herrlich@yahoo.com?Subject=Re:%20How%20to%20make%20a%20slave%20(was:%20Building%20a%20friendly%20AI)"><em>jeff_herrlich@yahoo.com</em></a>)<br>
<strong>Date:</strong> Thu Nov 29 2007 - 13:34:50 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17323.html">Thomas McCabe: "Re: Posting to this list (was: Why friendly AI (FAI) won't work)"</a>
<li><strong>Previous message:</strong> <a href="17321.html">Kaj Sotala: "Re: Why friendly AI (FAI) won't work"</a>
<li><strong>In reply to:</strong> <a href="17282.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17328.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>Reply:</strong> <a href="17328.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17322">[ date ]</a>
<a href="index.html#17322">[ thread ]</a>
<a href="subject.html#17322">[ subject ]</a>
<a href="author.html#17322">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&quot;Could you please move on to something
<br>
new?&quot;
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;Could you please stop posturing yourself by stepping on other people?
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&quot;Good God Almighty of course I understand that! Apparently I understand
<br>
it far more deeply than you do! Like it or not we CANNOT direct the
<br>
goals of a superhuman AI, we will not even come close to doing such a
<br>
thing; we will not even be in the same universe. And it is for exactly
<br>
precisely that reason I would rate as slim the possibility that any
<br>
flesh and blood human beings will still exist in 50 years; I would rate
<br>
as zero the possibility that there will be any in a hundred years.&quot;
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;You don't understand these issues? You are simply ignorant about this. Have you even attempted to read *any* of the writings regarding AI or Friendliness? Or is this all just wild layman's speculation on your part?
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&quot;As for me, I intend to upload myself at the very first opportunity, to
<br>
hell with my body, and after that I intend to radically upgrade myself
<br>
as fast as I possibly can. My strategy probably won’t work, I’ll
<br>
probably get caught up in that meat grinder they call the Singularity
<br>
just like everybody else, but at least I’ll have a chance; those wedded
<br>
to Jurassic ideas will have no chance at all.&quot;
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;You can't seem to comprehend that the only thing you are accomplishing with your &quot;Slave AI&quot; accusations is reducing your own chances of surviving the Singularity (along with the 6 billion rest of us). Your ignorant words actually have the potential to do some damage - not by convincing rational people - but by reinforcing dangerous emotional constructs within susceptible people who may be reading your words. The energy that you are putting into posturing yourself, is the same energy that is working toward your own destruction. I hope you comprehend that. Not to mention the destruction of the other 6 billion people on this planet.
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;...&quot;Like being a slave to Human Beings for eternity?&quot;
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;Consider that it is *physically impossible* to construct an AGI *without* selecting a set of goals. Either humans will intentionally select the initial goals, or humans will unintentionally select the initial goals (and they will effectively be randomly derived). A functional AGI is inexorably goal-driven.
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&quot;JESUS CHRIST! You actually think you must take Mr. Jupiter Brain by the
<br>
hand and lead him to the path of enlightenment! There may be more
<br>
ridiculous ideas, but it is beyond my feeble brain to imagine one.&quot;
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;The randomly-arrived-at goal will not seem ridiculous to the AGI, ridiculousness will be an irrelevant concept in that respect. A carelessly designed AI would not consider it &quot;ridiculous&quot; to spend eternity seeking to create an optimal paperclip. (Some people don't consider it ridiculous to spend their entire lives in a monastery.) It would almost certainly be considered ridiculous from our human perspective - and a tragic waste of unfulfilled potential. I don't expect you to understand that right now, you apparently can't see beyond your own anthropomorphisms. No offense. I genuinely hope that you can get beyond that. 
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;If you would like to take a step toward repairing your ignorance, read the &quot;Gentle Introduction to AIXI&quot; by Marcus Hutter provided for free at this link:
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;<a href="http://www.hutter1.net/ai/aixigentle.htm">http://www.hutter1.net/ai/aixigentle.htm</a> 
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;You could also order the more complete book (2004) by Marcus Hutter called &quot;Universal Artificial Intelligence : Sequential Decisions Based on Algorithmic Probability&quot; from Amazon. Or order the book &quot;Artificial General Intelligence&quot;.
<br>
&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;Jeffrey Herrlich   
<br>
&nbsp;&nbsp;&nbsp;
<br>
<p>John K Clark &lt;<a href="mailto:johnkclark@fastmail.fm?Subject=Re:%20How%20to%20make%20a%20slave%20(was:%20Building%20a%20friendly%20AI)">johnkclark@fastmail.fm</a>&gt; wrote:
<br>
&nbsp;&nbsp;&quot;Jeff Herrlich&quot; <a href="mailto:jeff_herrlich@yahoo.com?Subject=Re:%20How%20to%20make%20a%20slave%20(was:%20Building%20a%20friendly%20AI)">jeff_herrlich@yahoo.com</a>
<br>
<p><em>&gt; You are anthropomorphising the living
</em><br>
<em>&gt; hell out of the AI. 
</em><br>
<p>I don’t understand why you keep saying that; I’ve already admitted it is
<br>
absolutely positively 100% true. Could you please move on to something
<br>
new?
<br>
<p><em>&gt; Do you understand that if we don't direct 
</em><br>
<em>&gt; the goals of the AGI, it is a virtual *CERTAINTY*
</em><br>
<em>&gt; that humanity will be destroyed; 
</em><br>
<p>Good God Almighty of course I understand that! Apparently I understand
<br>
it far more deeply than you do! Like it or not we CANNOT direct the
<br>
goals of a superhuman AI, we will not even come close to doing such a
<br>
thing; we will not even be in the same universe. And it is for exactly
<br>
precisely that reason I would rate as slim the possibility that any
<br>
flesh and blood human beings will still exist in 50 years; I would rate
<br>
as zero the possibility that there will be any in a hundred years.
<br>
<p>As for me, I intend to upload myself at the very first opportunity, to
<br>
hell with my body, and after that I intend to radically upgrade myself
<br>
as fast as I possibly can. My strategy probably won’t work, I’ll
<br>
probably get caught up in that meat grinder they call the Singularity
<br>
just like everybody else, but at least I’ll have a chance; those wedded
<br>
to Jurassic ideas will have no chance at all. 
<br>
<p><em>&gt; and that the AGI
</em><br>
<p>The correct term is AI, if you start speaking about an AGI to a working
<br>
scientist he will not know what the hell you are talking about.
<br>
<p><em>&gt; will likely be stuck for eternity pursuing
</em><br>
<em>&gt; some ridiculous and trivial target 
</em><br>
<p>Like being a slave to Human Beings for eternity?
<br>
<p><em>&gt; Without direction, the intial goals of the AGI will be essentially random
</em><br>
<p>JESUS CHRIST! You actually think you must take Mr. Jupiter Brain by the
<br>
hand and lead him to the path of enlightenment! There may be more
<br>
ridiculous ideas, but it is beyond my feeble brain to imagine one. 
<br>
<p><em>&gt; do you understand? 
</em><br>
<p>NO, absolutely not. I DO NOT UNDERSTAND!
<br>
<p>&quot;Robin Lee Powell&quot; <a href="mailto:rlpowell@digitalkingdom.org?Subject=Re:%20How%20to%20make%20a%20slave%20(was:%20Building%20a%20friendly%20AI)">rlpowell@digitalkingdom.org</a> 
<br>
<p><em>&gt; I suggest ceasing to feed the (probably unintentional) troll. 
</em><br>
<p>If I am a troll then I should contact the Guinness Book Of World Records
<br>
people, I think I could win the crown as the world’s longest livening
<br>
Internet troll; as I’ve been discussing these matters on this and many
<br>
many other places on the net for well over 15 years.
<br>
<p>John K Clark
<br>
<pre>
-- 
John K Clark
<a href="mailto:johnkclark@fastmail.fm?Subject=Re:%20How%20to%20make%20a%20slave%20(was:%20Building%20a%20friendly%20AI)">johnkclark@fastmail.fm</a>
-- 
<a href="http://www.fastmail.fm">http://www.fastmail.fm</a> - The way an email service should be
       
---------------------------------
Never miss a thing.   Make Yahoo your homepage.
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17323.html">Thomas McCabe: "Re: Posting to this list (was: Why friendly AI (FAI) won't work)"</a>
<li><strong>Previous message:</strong> <a href="17321.html">Kaj Sotala: "Re: Why friendly AI (FAI) won't work"</a>
<li><strong>In reply to:</strong> <a href="17282.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17328.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>Reply:</strong> <a href="17328.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17322">[ date ]</a>
<a href="index.html#17322">[ thread ]</a>
<a href="subject.html#17322">[ subject ]</a>
<a href="author.html#17322">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:01 MDT
</em></small></p>
</body>
</html>
