<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: How to make a slave (was: Building a friendly AI)</title>
<meta name="Author" content="Thomas McCabe (pphysics141@gmail.com)">
<meta name="Subject" content="Re: How to make a slave (was: Building a friendly AI)">
<meta name="Date" content="2007-11-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: How to make a slave (was: Building a friendly AI)</h1>
<!-- received="Mon Nov 26 16:27:41 2007" -->
<!-- isoreceived="20071126232741" -->
<!-- sent="Mon, 26 Nov 2007 18:25:27 -0500" -->
<!-- isosent="20071126232527" -->
<!-- name="Thomas McCabe" -->
<!-- email="pphysics141@gmail.com" -->
<!-- subject="Re: How to make a slave (was: Building a friendly AI)" -->
<!-- id="b7a9e8680711261525h40187955l876e3d66a4d54476@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="1196117558.1972.1223351343@webmail.messagingengine.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas McCabe (<a href="mailto:pphysics141@gmail.com?Subject=Re:%20How%20to%20make%20a%20slave%20(was:%20Building%20a%20friendly%20AI)"><em>pphysics141@gmail.com</em></a>)<br>
<strong>Date:</strong> Mon Nov 26 2007 - 16:25:27 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17284.html">William Pearson: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>Previous message:</strong> <a href="17282.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>In reply to:</strong> <a href="17282.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17285.html">Ricky Loynd: "RE: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>Reply:</strong> <a href="17285.html">Ricky Loynd: "RE: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>Reply:</strong> <a href="17290.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17283">[ date ]</a>
<a href="index.html#17283">[ thread ]</a>
<a href="subject.html#17283">[ subject ]</a>
<a href="author.html#17283">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Nov 26, 2007 5:52 PM, John K Clark &lt;<a href="mailto:johnkclark@fastmail.fm?Subject=Re:%20How%20to%20make%20a%20slave%20(was:%20Building%20a%20friendly%20AI)">johnkclark@fastmail.fm</a>&gt; wrote:
<br>
<em>&gt; &quot;Jeff Herrlich&quot; <a href="mailto:jeff_herrlich@yahoo.com?Subject=Re:%20How%20to%20make%20a%20slave%20(was:%20Building%20a%20friendly%20AI)">jeff_herrlich@yahoo.com</a>
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; You are anthropomorphising the living
</em><br>
<em>&gt; &gt; hell out of the AI.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I don't understand why you keep saying that; I've already admitted it is
</em><br>
<em>&gt; absolutely positively 100% true. Could you please move on to something
</em><br>
<em>&gt; new?
</em><br>
<p>No. Anthropomorphic reasoning about AGIs is *not valid*. It does not
<br>
work. If you tried to use anthropomorphic reasoning about a 747, or a
<br>
toaster, or a video game, you'd be laughed at. Why should AGI be any
<br>
different? An AGI is not evolved under ancestral-environment
<br>
conditions; it is built by humans, just like all the other stuff I
<br>
mentioned. Hence, it will probably bear more resemblance to, eg., a
<br>
CRT monitor than it does to us.
<br>
<p><em>&gt; &gt; Do you understand that if we don't direct
</em><br>
<em>&gt; &gt; the goals of the AGI, it is a virtual *CERTAINTY*
</em><br>
<em>&gt; &gt; that humanity will be destroyed;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Good God Almighty of course I understand that! Apparently I understand
</em><br>
<em>&gt; it far more deeply than you do! Like it or not we CANNOT direct the
</em><br>
<em>&gt; goals of a superhuman AI,
</em><br>
<p>Do you have any evidence for this, or are you just going to keep
<br>
shouting it until the cows come home?
<br>
<p><em>&gt; we will not even come close to doing such a
</em><br>
<em>&gt; thing; we will not even be in the same universe. And it is for exactly
</em><br>
<em>&gt; precisely that reason I would rate as slim the possibility that any
</em><br>
<em>&gt; flesh and blood human beings will still exist in 50 years; I would rate
</em><br>
<em>&gt; as zero the possibility that there will be any in a hundred years.
</em><br>
<p>Probabilities of zero will give you nonsense in Bayesian probability
<br>
theory. They aren't allowed.
<br>
<p><em>&gt; As for me, I intend to upload myself at the very first opportunity, to
</em><br>
<em>&gt; hell with my body, and after that I intend to radically upgrade myself
</em><br>
<em>&gt; as fast as I possibly can. My strategy probably won't work, I'll
</em><br>
<em>&gt; probably get caught up in that meat grinder they call the Singularity
</em><br>
<em>&gt; just like  everybody else, but at least I'll have a chance; those wedded
</em><br>
<em>&gt; to Jurassic ideas will have no chance at all.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; and that the AGI
</em><br>
<em>&gt;
</em><br>
<em>&gt; The correct term is AI, if you start speaking about an AGI to a working
</em><br>
<em>&gt; scientist he will not know what the hell you are talking about.
</em><br>
<p>If I walked up to some random scientist and began discussing
<br>
Kolmogorov complexity, he probably wouldn't know what the hell I was
<br>
talking about. This does not mean it is an invalid term; science
<br>
nowadays is highly specialized, and you can't expect to know the
<br>
terminology of the other ten bazillion fields.
<br>
<p><em>&gt; &gt; will likely be stuck for eternity pursuing
</em><br>
<em>&gt; &gt; some ridiculous and trivial target
</em><br>
<em>&gt;
</em><br>
<em>&gt; Like being a slave to Human Beings for eternity?
</em><br>
<p>Please, please, please *read the bleepin' literature*. This has
<br>
already been brought up before. A lot. To quote CFAI:
<br>
<p>&quot;2.4: Anthropomorphic political rebellion is absurdity
<br>
<p>By this point, it should go without saying that rebellion is not
<br>
natural except to evolved organisms like ourselves.  An AI that
<br>
undergoes failure of Friendliness might take actions that humanity
<br>
would consider hostile, but the term rebellion has connotations of
<br>
hidden, burning resentment.  This is a common theme in many early SF
<br>
stories, but it's outright silly.  For millions of years, humanity and
<br>
the ancestors of humanity lived in an ancestral environment in which
<br>
tribal politics was one of the primary determinants of who got the
<br>
food and, more importantly, who got the best mates.  Of course we
<br>
evolved emotions to detect exploitation, resent exploitation, resent
<br>
low social status in the tribe, seek to rebel and overthrow the tribal
<br>
chief - or rather, replace the tribal chief - if the opportunity
<br>
presented itself, and so on.
<br>
<p>Even if an AI tries to exterminate humanity, ve won't make
<br>
self-justifying speeches about how humans had their time, but now,
<br>
like the dinosaur, have become obsolete.  Guaranteed.  Only Evil
<br>
Hollywood AIs do that. &quot;
<br>
<p><em>&gt; &gt; Without direction, the intial goals of the AGI will be essentially random
</em><br>
<em>&gt;
</em><br>
<em>&gt; JESUS CHRIST! You actually think you must take Mr. Jupiter Brain by the
</em><br>
<em>&gt; hand and lead him to the path of enlightenment! There may be more
</em><br>
<em>&gt; ridiculous ideas, but it is beyond my feeble brain to imagine one.
</em><br>
<p>The idea is that you program in the goal system *before* the AGI has
<br>
become a Jupiter Brain. Once the Jupiter Brain has already been built,
<br>
you're quite right, it would be hopeless if it wasn't properly
<br>
designed to begin with.
<br>
<p><em>&gt; &gt; do you understand?
</em><br>
<em>&gt;
</em><br>
<em>&gt; NO, absolutely not. I DO NOT UNDERSTAND!
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;Robin Lee Powell&quot; <a href="mailto:rlpowell@digitalkingdom.org?Subject=Re:%20How%20to%20make%20a%20slave%20(was:%20Building%20a%20friendly%20AI)">rlpowell@digitalkingdom.org</a>
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; I suggest ceasing to feed the (probably unintentional) troll.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If I am a troll then I should contact the Guinness Book Of World Records
</em><br>
<em>&gt; people, I think I could win the crown as the world's longest livening
</em><br>
<em>&gt; Internet troll; as I've been discussing these matters on this and many
</em><br>
<em>&gt; many other places on the net for well over 15 years.
</em><br>
<p>Sorry, you lose. :) Mentifex has been around for longer, see
<br>
<a href="http://www.nothingisreal.com/mentifex_faq.html">http://www.nothingisreal.com/mentifex_faq.html</a>.
<br>
<p><em>&gt;  John K Clark
</em><br>
<em>&gt; --
</em><br>
<em>&gt;   John K Clark
</em><br>
<em>&gt;   <a href="mailto:johnkclark@fastmail.fm?Subject=Re:%20How%20to%20make%20a%20slave%20(was:%20Building%20a%20friendly%20AI)">johnkclark@fastmail.fm</a>
</em><br>
<em>&gt;
</em><br>
<em>&gt; --
</em><br>
<em>&gt;
</em><br>
<em>&gt; <a href="http://www.fastmail.fm">http://www.fastmail.fm</a> - The way an email service should be
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<p>&nbsp;- Tom
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17284.html">William Pearson: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>Previous message:</strong> <a href="17282.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>In reply to:</strong> <a href="17282.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17285.html">Ricky Loynd: "RE: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>Reply:</strong> <a href="17285.html">Ricky Loynd: "RE: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>Reply:</strong> <a href="17290.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17283">[ date ]</a>
<a href="index.html#17283">[ thread ]</a>
<a href="subject.html#17283">[ subject ]</a>
<a href="author.html#17283">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:01 MDT
</em></small></p>
</body>
</html>
