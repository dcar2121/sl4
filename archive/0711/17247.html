<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: What is stability in a FAI? (was Re: UCaRtMaAI paper)</title>
<meta name="Author" content="Tim Freeman (tim@fungible.com)">
<meta name="Subject" content="What is stability in a FAI? (was Re: UCaRtMaAI paper)">
<meta name="Date" content="2007-11-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>What is stability in a FAI? (was Re: UCaRtMaAI paper)</h1>
<!-- received="Sat Nov 24 17:08:50 2007" -->
<!-- isoreceived="20071125000850" -->
<!-- sent="Sat, 24 Nov 2007 15:46:29 -0700" -->
<!-- isosent="20071124224629" -->
<!-- name="Tim Freeman" -->
<!-- email="tim@fungible.com" -->
<!-- subject="What is stability in a FAI? (was Re: UCaRtMaAI paper)" -->
<!-- id="20071125000650.63C80D262D@fungible.com" -->
<!-- inreplyto="D0719B5256614765A37C40B628F8477F@weidaim1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Tim Freeman (<a href="mailto:tim@fungible.com?Subject=Re:%20What%20is%20stability%20in%20a%20FAI?%20(was%20Re:%20UCaRtMaAI%20paper)"><em>tim@fungible.com</em></a>)<br>
<strong>Date:</strong> Sat Nov 24 2007 - 15:46:29 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17248.html">Eliezer S. Yudkowsky: "Re: UCaRtMaAI paper"</a>
<li><strong>Previous message:</strong> <a href="17246.html">David Picón Álvarez: "Re: How to make a slave"</a>
<li><strong>In reply to:</strong> <a href="17231.html">Wei Dai: "Re: UCaRtMaAI paper"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17249.html">Stefan Pernar: "Re: What is stability in a FAI? (was Re: UCaRtMaAI paper)"</a>
<li><strong>Reply:</strong> <a href="17249.html">Stefan Pernar: "Re: What is stability in a FAI? (was Re: UCaRtMaAI paper)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17247">[ date ]</a>
<a href="index.html#17247">[ thread ]</a>
<a href="subject.html#17247">[ subject ]</a>
<a href="author.html#17247">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
From: &quot;Wei Dai&quot; &lt;<a href="mailto:weidai@weidai.com?Subject=Re:%20What%20is%20stability%20in%20a%20FAI?%20(was%20Re:%20UCaRtMaAI%20paper)">weidai@weidai.com</a>&gt;
<br>
<em>&gt;To take the simplest example, suppose I get a group of friends together and 
</em><br>
<em>&gt;we all tell the AI, &quot;at the end of this planning period please replace 
</em><br>
<em>&gt;yourself with an AI that serves only us.&quot; The rest of humanity does not know 
</em><br>
<em>&gt;about this, so they don't do anything that would let the AI infer that they 
</em><br>
<em>&gt;would assign this outcome a low utility.
</em><br>
<p>Good example.  It points to the main flaw in the scheme -- I can't
<br>
prove it's stable, and a solution to the Friendly AI problem has to be
<br>
stable.  Here &quot;stability&quot; roughly means that our Friendly AI isn't
<br>
going to construct an unfriendly AI and then allow the new one to take
<br>
over.  However, if I look more closely, I don't know what &quot;stable&quot;
<br>
means.  
<br>
<p>Here's an example.  I can't prove that real humans won't spontaneously
<br>
decide they want to destroy the universe next Tuesday.  If the AI
<br>
stably does what people want, and the real humans decide they want to
<br>
destroy the universe next Tuesday, and the AI therefore irrevocably
<br>
starts the process of destroying the universe next Wednesday, was the
<br>
AI friendly and stable?  If the answer is &quot;yes&quot;, then we have to admit
<br>
that a stable friendly AI might destroy the universe, which seems bad.
<br>
If the answer is &quot;no&quot;, then we seem to be demanding that a friendly AI
<br>
might not perform some action within its power that everyone wants,
<br>
which also seems bad.  The fact that we can't prove any particular
<br>
property about real humans, and the algorithm tries to do what real
<br>
humans want, seems to make it impossible to prove that running the
<br>
algorithm will have any particular good consequences.
<br>
<p>What does it mean to say that our Friendly AI has a stable
<br>
relationship with humans when we don't know that the humans are
<br>
stable?
<br>
<p>Things might work out well for your particular example anyway.  You
<br>
and I know that the rest of humanity won't appreciate some small junta
<br>
having total control after the current planning cycle.  We know it
<br>
because we know that humans generally don't want to be dominated by
<br>
other humans.  The AI can make that general observation too, since for
<br>
it each explanation of the world has one explanation of all human
<br>
nature, rather than independent explanations for each human.  The one
<br>
explanation is the &quot;Compute-Utility&quot; oval at
<br>
<a href="http://www.fungible.com/respect/paper.html#beliefs">http://www.fungible.com/respect/paper.html#beliefs</a>, and it takes a
<br>
person id and a state-of-the-world-outside-everyones-mind as input.
<br>
So, after watching children playing in playgrounds and drug warfare in
<br>
the streets, it might understand human dominance well enough to guess
<br>
that ceding control to a small junta won't be desired by the vast
<br>
majority.
<br>
<p><pre>
-- 
Tim Freeman               <a href="http://www.fungible.com">http://www.fungible.com</a>           <a href="mailto:tim@fungible.com?Subject=Re:%20What%20is%20stability%20in%20a%20FAI?%20(was%20Re:%20UCaRtMaAI%20paper)">tim@fungible.com</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17248.html">Eliezer S. Yudkowsky: "Re: UCaRtMaAI paper"</a>
<li><strong>Previous message:</strong> <a href="17246.html">David Picón Álvarez: "Re: How to make a slave"</a>
<li><strong>In reply to:</strong> <a href="17231.html">Wei Dai: "Re: UCaRtMaAI paper"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17249.html">Stefan Pernar: "Re: What is stability in a FAI? (was Re: UCaRtMaAI paper)"</a>
<li><strong>Reply:</strong> <a href="17249.html">Stefan Pernar: "Re: What is stability in a FAI? (was Re: UCaRtMaAI paper)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17247">[ date ]</a>
<a href="index.html#17247">[ thread ]</a>
<a href="subject.html#17247">[ subject ]</a>
<a href="author.html#17247">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:01 MDT
</em></small></p>
</body>
</html>
