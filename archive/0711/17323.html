<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Posting to this list (was: Why friendly AI (FAI) won't work)</title>
<meta name="Author" content="Thomas McCabe (pphysics141@gmail.com)">
<meta name="Subject" content="Re: Posting to this list (was: Why friendly AI (FAI) won't work)">
<meta name="Date" content="2007-11-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Posting to this list (was: Why friendly AI (FAI) won't work)</h1>
<!-- received="Thu Nov 29 13:46:36 2007" -->
<!-- isoreceived="20071129204636" -->
<!-- sent="Thu, 29 Nov 2007 15:44:34 -0500" -->
<!-- isosent="20071129204434" -->
<!-- name="Thomas McCabe" -->
<!-- email="pphysics141@gmail.com" -->
<!-- subject="Re: Posting to this list (was: Why friendly AI (FAI) won't work)" -->
<!-- id="b7a9e8680711291244i7fcc877fna6f2e9ae84e30598@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="474EEC3B.9030708@acm.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas McCabe (<a href="mailto:pphysics141@gmail.com?Subject=Re:%20Posting%20to%20this%20list%20(was:%20Why%20friendly%20AI%20(FAI)%20won't%20work)"><em>pphysics141@gmail.com</em></a>)<br>
<strong>Date:</strong> Thu Nov 29 2007 - 13:44:34 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17324.html">Jeff Herrlich: "Re: How to make a slave (many replies )"</a>
<li><strong>Previous message:</strong> <a href="17322.html">Jeff Herrlich: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>In reply to:</strong> <a href="17318.html">Harry Chesley: "Re: Posting to this list (was: Why friendly AI (FAI) won't work)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17325.html">Harry Chesley: "Re: Posting to this list"</a>
<li><strong>Reply:</strong> <a href="17325.html">Harry Chesley: "Re: Posting to this list"</a>
<li><strong>Reply:</strong> <a href="../0712/17346.html">Joshua Fox: "Re: Posting to this list (was: Why friendly AI (FAI) won't work)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17323">[ date ]</a>
<a href="index.html#17323">[ thread ]</a>
<a href="subject.html#17323">[ subject ]</a>
<a href="author.html#17323">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; I am working on AI
</em><br>
<p>Whatever you may think of me, SIAI, or this list, *please stop* and
<br>
consider the possible consequences of what you are doing (see
<br>
<a href="http://www.intelligence.org/upload/cognitive-biases.pdf">http://www.intelligence.org/upload/cognitive-biases.pdf</a>,
<br>
<a href="http://www.intelligence.org/upload/artificial-intelligence-risk.pdf">http://www.intelligence.org/upload/artificial-intelligence-risk.pdf</a>).
<br>
Not-very-well-understood AI is a serious threat to the existence of
<br>
the entire planet; we cannot afford to take stupid risks.
<br>
<p><em>&gt; and came to this list looking for discussion and
</em><br>
<em>&gt; feedback on some issues like the morality of experimenting on AIs and
</em><br>
<em>&gt; the need to incorporate FAI principles. These issues seemed well within
</em><br>
<em>&gt; the stated purpose of the list, so I didn't believe I needed to stop and
</em><br>
<em>&gt; study everything that a particular group has done before posting.
</em><br>
<p>&quot;It is the explicit policy of this list not to rehash the basics.  SL4
<br>
is for advanced topics in futurism and technology.  If we've discussed
<br>
it once before, or if it's something we think posters should already
<br>
know, you may be courteously referred to the archives, or to another
<br>
list.&quot; - <a href="http://www.sl4.org/intro.html">http://www.sl4.org/intro.html</a>
<br>
<p><em>&gt; But
</em><br>
<em>&gt; it's not my list, so I'm quite happy to look elsewhere for an
</em><br>
<em>&gt; appropriate discussion forum if these sorts of questions are not welcome
</em><br>
<em>&gt; here.
</em><br>
<p>You might want to check out
<br>
<a href="http://www.transhumanism.org/mailman/listinfo/wta-talk">http://www.transhumanism.org/mailman/listinfo/wta-talk</a> or
<br>
<a href="http://www.agiri.org/email/">http://www.agiri.org/email/</a>.
<br>
<p><em>&gt; Just as a reminder, the stated purpose of the list is: &quot;The SL4 mailing
</em><br>
<em>&gt; list is a refuge for discussion of advanced topics in transhumanism and
</em><br>
<em>&gt; the Singularity, including but not limited to topics such as Friendly
</em><br>
<em>&gt; AI, strategies for handling the emergence of ultra-powerful
</em><br>
<em>&gt; technologies, handling existential risks (planetary risks), strategies
</em><br>
<em>&gt; to accelerate the Singularity or protect its integrity, avoiding the
</em><br>
<em>&gt; military use of nanotechnology and grey goo accidents, methods of human
</em><br>
<em>&gt; intelligence enhancement, self-improving Artificial Intelligence,
</em><br>
<em>&gt; contemporary AI projects that are explicitly trying for genuine
</em><br>
<em>&gt; Artificial Intelligence or even a Singularity, rapid Singularities
</em><br>
<em>&gt; versus slow Singularities, Singularitarian activism, and more.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; As to the specific topic at hand, I've read about FAI to various depths
</em><br>
<em>&gt; for some time, though not enough to be anything vaguely close to an
</em><br>
<em>&gt; expert. The arguments presented have not convinced me that it's a viable
</em><br>
<em>&gt; option. But I could easily be wrong, so I posted my reasons, looking for
</em><br>
<em>&gt; convincing counter-arguments. Which I haven't seen yet. So I'm
</em><br>
<em>&gt; continuing on with my original believe set.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I'm surprised that if you really believe that FAI is essential to the
</em><br>
<em>&gt; future of the human race, you don't try to evangelize it and patiently
</em><br>
<em>&gt; explain it to newbies. You'll get a lot more converts that way that
</em><br>
<em>&gt; arrogantly telling anyone who doesn't agree with you that they don't
</em><br>
<em>&gt; know what they're talking about and obviously haven't read the
</em><br>
<em>&gt; literature or they would agree with you.
</em><br>
<p>This is a good point. We should set up another list for explaining the
<br>
literature, answering newbie questions, etc.
<br>
<p><em>&gt; But I wouldn't worry about me creating a non-friendly AI. There are many
</em><br>
<em>&gt; other groups better funded and with smarter people. Right now, I'd worry
</em><br>
<em>&gt; about Google. (I know, I'm not the first to suggest that.)
</em><br>
<p>The potential negative payoff is so huge that it's worth paying
<br>
attention to risks with tiny probabilities, as long as you take care
<br>
of the ones with large probabilities first.
<br>
<p>&nbsp;- Tom
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17324.html">Jeff Herrlich: "Re: How to make a slave (many replies )"</a>
<li><strong>Previous message:</strong> <a href="17322.html">Jeff Herrlich: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>In reply to:</strong> <a href="17318.html">Harry Chesley: "Re: Posting to this list (was: Why friendly AI (FAI) won't work)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17325.html">Harry Chesley: "Re: Posting to this list"</a>
<li><strong>Reply:</strong> <a href="17325.html">Harry Chesley: "Re: Posting to this list"</a>
<li><strong>Reply:</strong> <a href="../0712/17346.html">Joshua Fox: "Re: Posting to this list (was: Why friendly AI (FAI) won't work)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17323">[ date ]</a>
<a href="index.html#17323">[ thread ]</a>
<a href="subject.html#17323">[ subject ]</a>
<a href="author.html#17323">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:01 MDT
</em></small></p>
</body>
</html>
