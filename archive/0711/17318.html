<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Posting to this list (was: Why friendly AI (FAI) won't work)</title>
<meta name="Author" content="Harry Chesley (chesley@acm.org)">
<meta name="Subject" content="Re: Posting to this list (was: Why friendly AI (FAI) won't work)">
<meta name="Date" content="2007-11-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Posting to this list (was: Why friendly AI (FAI) won't work)</h1>
<!-- received="Thu Nov 29 09:46:06 2007" -->
<!-- isoreceived="20071129164606" -->
<!-- sent="Thu, 29 Nov 2007 08:43:39 -0800" -->
<!-- isosent="20071129164339" -->
<!-- name="Harry Chesley" -->
<!-- email="chesley@acm.org" -->
<!-- subject="Re: Posting to this list (was: Why friendly AI (FAI) won't work)" -->
<!-- id="474EEC3B.9030708@acm.org" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="57141.84360.qm@web27802.mail.ukl.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Harry Chesley (<a href="mailto:chesley@acm.org?Subject=Re:%20Posting%20to%20this%20list%20(was:%20Why%20friendly%20AI%20(FAI)%20won't%20work)"><em>chesley@acm.org</em></a>)<br>
<strong>Date:</strong> Thu Nov 29 2007 - 09:43:39 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17319.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>Previous message:</strong> <a href="17317.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>In reply to:</strong> <a href="17316.html">M T: "Re: Why friendly AI (FAI) won't work"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17323.html">Thomas McCabe: "Re: Posting to this list (was: Why friendly AI (FAI) won't work)"</a>
<li><strong>Reply:</strong> <a href="17323.html">Thomas McCabe: "Re: Posting to this list (was: Why friendly AI (FAI) won't work)"</a>
<li><strong>Reply:</strong> <a href="17326.html">Eliezer S. Yudkowsky: "Re: Posting to this list"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17318">[ date ]</a>
<a href="index.html#17318">[ thread ]</a>
<a href="subject.html#17318">[ subject ]</a>
<a href="author.html#17318">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Let me back off a level. I really don't mean to be arrogant. Indeed, I 
<br>
have a very great sense that I know next to nothing about intelligence, 
<br>
AI, singularities, or how to implement any of the above. It's just that 
<br>
there seems to be so much arrogance on this list that it's hard not to 
<br>
let something similar creep into my replies. Of course, arrogance 
<br>
doesn't mean that the person sporting it isn't right -- in my 
<br>
experience, there's little correlation in either direction. I apologize.
<br>
<p>I am working on AI and came to this list looking for discussion and 
<br>
feedback on some issues like the morality of experimenting on AIs and 
<br>
the need to incorporate FAI principles. These issues seemed well within 
<br>
the stated purpose of the list, so I didn't believe I needed to stop and 
<br>
study everything that a particular group has done before posting. But 
<br>
it's not my list, so I'm quite happy to look elsewhere for an 
<br>
appropriate discussion forum if these sorts of questions are not welcome 
<br>
here.
<br>
<p>Just as a reminder, the stated purpose of the list is: &quot;The SL4 mailing 
<br>
list is a refuge for discussion of advanced topics in transhumanism and 
<br>
the Singularity, including but not limited to topics such as Friendly 
<br>
AI, strategies for handling the emergence of ultra-powerful 
<br>
technologies, handling existential risks (planetary risks), strategies 
<br>
to accelerate the Singularity or protect its integrity, avoiding the 
<br>
military use of nanotechnology and grey goo accidents, methods of human 
<br>
intelligence enhancement, self-improving Artificial Intelligence, 
<br>
contemporary AI projects that are explicitly trying for genuine 
<br>
Artificial Intelligence or even a Singularity, rapid Singularities 
<br>
versus slow Singularities, Singularitarian activism, and more.&quot;
<br>
<p>As to the specific topic at hand, I've read about FAI to various depths 
<br>
for some time, though not enough to be anything vaguely close to an 
<br>
expert. The arguments presented have not convinced me that it's a viable 
<br>
option. But I could easily be wrong, so I posted my reasons, looking for 
<br>
convincing counter-arguments. Which I haven't seen yet. So I'm 
<br>
continuing on with my original believe set.
<br>
<p>I'm surprised that if you really believe that FAI is essential to the 
<br>
future of the human race, you don't try to evangelize it and patiently 
<br>
explain it to newbies. You'll get a lot more converts that way that 
<br>
arrogantly telling anyone who doesn't agree with you that they don't 
<br>
know what they're talking about and obviously haven't read the 
<br>
literature or they would agree with you.
<br>
<p>But I wouldn't worry about me creating a non-friendly AI. There are many 
<br>
other groups better funded and with smarter people. Right now, I'd worry 
<br>
about Google. (I know, I'm not the first to suggest that.)
<br>
<p>On 11/29/2007 4:24 AM, M T wrote:
<br>
<em>&gt; I'm sure I'll regret interfering as usually in this list, but......
</em><br>
<em>&gt;
</em><br>
<em>&gt; Some humbleness is necessary while on this list Harry.
</em><br>
<em>&gt; Or while on any highly focused expert list, for that matter.
</em><br>
<em>&gt; Until you can consider yourself an expert on the field.
</em><br>
<em>&gt; Then you can attempt arrogance, but now you're a moment too soon.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Whatever you are working on regarding AI (or is it AGI?), don't think you can transfer your expertise to FAGI straight away.
</em><br>
<em>&gt; People in the SIAI are pretty much the only group that has been focusing on FAGI for any considerable amount of time.
</em><br>
<em>&gt;
</em><br>
<em>&gt; What makes you think you can do it better right of the bat?
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; ----- Original Message ----
</em><br>
<em>&gt; From: Harry Chesley &lt;<a href="mailto:chesley@acm.org?Subject=Re:%20Posting%20to%20this%20list%20(was:%20Why%20friendly%20AI%20(FAI)%20won't%20work)">chesley@acm.org</a>&gt;
</em><br>
<em>&gt; To: <a href="mailto:sl4@sl4.org?Subject=Re:%20Posting%20to%20this%20list%20(was:%20Why%20friendly%20AI%20(FAI)%20won't%20work)">sl4@sl4.org</a>
</em><br>
<em>&gt; Sent: Thursday, 29 November, 2007 4:26:25 AM
</em><br>
<em>&gt; Subject: Re: Why friendly AI (FAI) won't work
</em><br>
<em>&gt;
</em><br>
<em>&gt; Thomas McCabe wrote:
</em><br>
<em>&gt;   
</em><br>
<em>&gt;&gt; What do you think SIAI is for? To develop an AGI which *is*
</em><br>
<em>&gt;&gt; well-defined and well-built, before some random research lab or
</em><br>
<em>&gt;&gt; garage kills us all.
</em><br>
<em>&gt;&gt;     
</em><br>
<em>&gt;
</em><br>
<em>&gt; Good luck with that. But, frankly, judging from the posts on this list,
</em><br>
<em>&gt; you sounds like exactly the sort of arrogant people who believe they
</em><br>
<em>&gt; know the answer and no one else does who I especially think should
</em><br>
<em>&gt;  *not*
</em><br>
<em>&gt; control the singularity. Hmmm, maybe I should get back to work.
</em><br>
<em>&gt;
</em><br>
<em>&gt;   
</em><br>
<em>&gt;&gt; For the love of &lt;whatever deity you do or do not believe in&gt;, stop
</em><br>
<em>&gt;&gt; working until you get a clear idea of what you've gotten yourself
</em><br>
<em>&gt;&gt; into.
</em><br>
<em>&gt;&gt;     
</em><br>
<em>&gt;
</em><br>
<em>&gt; No thanks.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;       ___________________________________________________________
</em><br>
<em>&gt; Yahoo! Answers - Got a question? Someone out there knows the answer. Try it
</em><br>
<em>&gt; now.
</em><br>
<em>&gt; <a href="http://uk.answers.yahoo.com/">http://uk.answers.yahoo.com/</a> 
</em><br>
<em>&gt;
</em><br>
<em>&gt;   
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17319.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>Previous message:</strong> <a href="17317.html">John K Clark: "Re: How to make a slave (was: Building a friendly AI)"</a>
<li><strong>In reply to:</strong> <a href="17316.html">M T: "Re: Why friendly AI (FAI) won't work"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17323.html">Thomas McCabe: "Re: Posting to this list (was: Why friendly AI (FAI) won't work)"</a>
<li><strong>Reply:</strong> <a href="17323.html">Thomas McCabe: "Re: Posting to this list (was: Why friendly AI (FAI) won't work)"</a>
<li><strong>Reply:</strong> <a href="17326.html">Eliezer S. Yudkowsky: "Re: Posting to this list"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17318">[ date ]</a>
<a href="index.html#17318">[ thread ]</a>
<a href="subject.html#17318">[ subject ]</a>
<a href="author.html#17318">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:01 MDT
</em></small></p>
</body>
</html>
