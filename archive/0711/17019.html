<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: What best evidence for fast AI?</title>
<meta name="Author" content="Rolf Nelson (rolf.h.d.nelson@gmail.com)">
<meta name="Subject" content="Re: What best evidence for fast AI?">
<meta name="Date" content="2007-11-10">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: What best evidence for fast AI?</h1>
<!-- received="Sat Nov 10 10:38:07 2007" -->
<!-- isoreceived="20071110173807" -->
<!-- sent="Sat, 10 Nov 2007 12:35:44 -0500" -->
<!-- isosent="20071110173544" -->
<!-- name="Rolf Nelson" -->
<!-- email="rolf.h.d.nelson@gmail.com" -->
<!-- subject="Re: What best evidence for fast AI?" -->
<!-- id="79ecaa350711100935l4e5d9f56x301f6ef10dbcd2d8@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="0JRA0084QFS2Q6E0@caduceus1.gmu.edu" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Rolf Nelson (<a href="mailto:rolf.h.d.nelson@gmail.com?Subject=Re:%20What%20best%20evidence%20for%20fast%20AI?"><em>rolf.h.d.nelson@gmail.com</em></a>)<br>
<strong>Date:</strong> Sat Nov 10 2007 - 10:35:44 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17020.html">Harry Chesley: "Re: What best evidence for fast AI?"</a>
<li><strong>Previous message:</strong> <a href="17018.html">Jef Allbright: "Re: answers I'd like from an SI"</a>
<li><strong>In reply to:</strong> <a href="17012.html">Robin Hanson: "What best evidence for fast AI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17020.html">Harry Chesley: "Re: What best evidence for fast AI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17019">[ date ]</a>
<a href="index.html#17019">[ thread ]</a>
<a href="subject.html#17019">[ subject ]</a>
<a href="author.html#17019">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; explicitly-coded AI
</em><br>
<p>I'd avoid this terminology if you only mean non-emulated AI, it's confusing
<br>
to me whether seed AI that learns and self-improves fits in your category.
<br>
<p><em>&gt;From a decision-theory perspective, the odds of AGI would have to be
</em><br>
incredibly small to justify the current low level of Friendly AI funding.
<br>
<p>You've probably heard the common arguments for AGI, mostly it's about
<br>
debunking counter-arguments to AGI at this point.
<br>
<p>1. It's already been pointed out that the track-record of human invention to
<br>
match or outdo evolution, when &quot;compactness&quot; is not a criterion, is very
<br>
good. You've heard the flight analogy, allegedly many experts were surprised
<br>
by the Wright Brothers. Is that &quot;cherry-picking&quot;? I say no: ask a child to
<br>
list a few things that animals can do unaided but people can't, and &quot;fly&quot;
<br>
will probably be high on the list.
<br>
<p>2. When invention matches or exceeds evolution, it's usually sudden. We
<br>
didn't spend a decade with powered flight at 1 mph, then 2 mph, and
<br>
gradually work our way up.
<br>
<p>3. Adjust for overconfidence bias, if an expert says 95% confidence that AGI
<br>
won't happen, then it's probably less than that, unless it's part of a
<br>
larger well-calibrated model (which it isn't).
<br>
<p>4. Some people's algorithm seems to be, &quot;if it hasn't happened in the last X
<br>
years, then surely it won't happen in the next X years.&quot; This is a
<br>
*terrible* algorithm. Suppose AGI is destined to happen in 2150. Now the
<br>
year 2140 comes around; you will believe that AGI is 150 years away and be
<br>
caught flat-footed. If the algorithm is invalid in the year 2140, why expect
<br>
it to be valid in the year 1997? To put it another way: are there *specific
<br>
milestones* that we're all waiting for that will at some point scream, &quot;AGI
<br>
is now 30 years away?&quot; If so, what are those milestones? If not, how can we
<br>
be sure that AGI is more than 30 years away?
<br>
<p>5. Another poor algorithm: &quot;If someone predicts X will happen in 50 years,
<br>
and it doesn't happen, then that means it will surely never happen.&quot; If this
<br>
Magical Algorithm is correct, let me predict: &quot;within 50 years, a war will
<br>
destroy mankind.&quot; By this Magical Algorithm, I have now magically guaranteed
<br>
that, if humanity survives past 2057, a time of peace will magically
<br>
descend. Hand over the Nobel Peace Prize, please! To put it another way:
<br>
Alan Turing saying something stupid in 1950 doesn't causally constrain
<br>
events that may or may not happen in the 21st century. It only provides
<br>
evidence that &quot;Computer Science researchers aren't infallible&quot;, which in
<br>
turn paradoxically strengthens point (3).
<br>
<p>-Rolf
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17020.html">Harry Chesley: "Re: What best evidence for fast AI?"</a>
<li><strong>Previous message:</strong> <a href="17018.html">Jef Allbright: "Re: answers I'd like from an SI"</a>
<li><strong>In reply to:</strong> <a href="17012.html">Robin Hanson: "What best evidence for fast AI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17020.html">Harry Chesley: "Re: What best evidence for fast AI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17019">[ date ]</a>
<a href="index.html#17019">[ thread ]</a>
<a href="subject.html#17019">[ subject ]</a>
<a href="author.html#17019">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:00 MDT
</em></small></p>
</body>
</html>
