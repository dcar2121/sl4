<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Collective Volition, next take</title>
<meta name="Author" content="Russell Wallace (russell.wallace@gmail.com)">
<meta name="Subject" content="Re: Collective Volition, next take">
<meta name="Date" content="2005-07-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Collective Volition, next take</h1>
<!-- received="Sat Jul 23 13:14:13 2005" -->
<!-- isoreceived="20050723191413" -->
<!-- sent="Sat, 23 Jul 2005 20:14:10 +0100" -->
<!-- isosent="20050723191410" -->
<!-- name="Russell Wallace" -->
<!-- email="russell.wallace@gmail.com" -->
<!-- subject="Re: Collective Volition, next take" -->
<!-- id="8d71341e05072312143def5711@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="42E292B5.9040308@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Russell Wallace (<a href="mailto:russell.wallace@gmail.com?Subject=Re:%20Collective%20Volition,%20next%20take"><em>russell.wallace@gmail.com</em></a>)<br>
<strong>Date:</strong> Sat Jul 23 2005 - 13:14:10 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11729.html">Russell Wallace: "Re: Collective Volition, next take"</a>
<li><strong>Previous message:</strong> <a href="11727.html">Eliezer S. Yudkowsky: "Re: Collective Volition, next take"</a>
<li><strong>In reply to:</strong> <a href="11725.html">Eliezer S. Yudkowsky: "Re: Collective Volition, next take"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11730.html">Eliezer S. Yudkowsky: "Re: Collective Volition, next take"</a>
<li><strong>Reply:</strong> <a href="11730.html">Eliezer S. Yudkowsky: "Re: Collective Volition, next take"</a>
<li><strong>Reply:</strong> <a href="11749.html">Thomas Buckner: "Re: Collective Volition, next take"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11728">[ date ]</a>
<a href="index.html#11728">[ thread ]</a>
<a href="subject.html#11728">[ subject ]</a>
<a href="author.html#11728">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 7/23/05, Eliezer S. Yudkowsky &lt;<a href="mailto:sentience@pobox.com?Subject=Re:%20Collective%20Volition,%20next%20take">sentience@pobox.com</a>&gt; wrote:
<br>
<em>&gt; I'm not sure what you mean by &quot;moral axioms&quot;.  Human goal systems don't
</em><br>
<em>&gt; decompose cleanly and orthogonally into moral axioms + everything else.  If
</em><br>
<em>&gt; they did, my life would be a lot simpler.
</em><br>
<p>Okay, replace &quot;axioms&quot; with &quot;premises&quot; or &quot;core values&quot; or whatever
<br>
you think doesn't imply such an orthogonal decomposition.
<br>
<p><em>&gt; In CV - which, by the way, I really should have called &quot;Collective
</em><br>
<em>&gt; Extrapolated Volition&quot; - I called for defining a family of enhancements
</em><br>
<em>&gt; applicable to abstractions of human minds and human society, such that the
</em><br>
<em>&gt; extrapolation of abstract interacting enhanced humans could get far enough to
</em><br>
<em>&gt; return a legitimate answer to the question, &quot;What sort of AI would we want if
</em><br>
<em>&gt; we were smarter?&quot;
</em><br>
<p>I know, that's where the problems started.
<br>
<p><em>&gt; Look, from the outside - to anyone who's not on the SIAI programming team -
</em><br>
<em>&gt; what the programmers are doing (forget about how they do it) is supposed to be
</em><br>
<em>&gt; intuitively simple.
</em><br>
<p>Indeed. Remember those lectures you used to give people about the
<br>
whirling razor blades and Nature not being obliged to warn them before
<br>
it kills them? I can't do it quite as eloquently as you did, but the
<br>
fact remains that what you have your shoulder against are the gates of
<br>
Hell; they were there last week even though I hadn't seen them yet,
<br>
and they are there today even though you haven't seen them yet.
<br>
<p><em>&gt; I frankly do not
</em><br>
<em>&gt; understand exactly where you think an error inevitably occurs in this
</em><br>
<em>&gt; framework.
</em><br>
<p>The error occurs at the point where you think smartness compensates
<br>
for trapping everyone in the same sealed box with no moral protection.
<br>
<p><em>&gt; Are you afraid of getting what you want?  Are you afraid that most
</em><br>
<em>&gt; other people want something different (if so, why should SIAI listen to you,
</em><br>
<em>&gt; not them?)  Or are you worried that building a Collective Extrapolated
</em><br>
<em>&gt; Volition as the fleshed-out, real-world implementation of the question mark
</em><br>
<em>&gt; inherently defines 'wanting' in some sense other than the intuitive, the sense
</em><br>
<em>&gt; in which you don't 'want' the future to be a giant ball of worms or whatever?
</em><br>
<em>&gt;   You've got to mean one of those three and it's not clear which.
</em><br>
<p>What people want depends on the circumstances.
<br>
<p>Two people free to walk away may want to chat amicably or engage in
<br>
voluntary trade; trapped in a sealed box for long enough, they may
<br>
want to kill each other. Solution: don't trap them in a sealed box.
<br>
<p>The German people under democracy didn't want to commit genocide;
<br>
under dictatorship they did. The exact same people in both cases, mind
<br>
you. The solution isn't to say &quot;why should the SIAI listen to you, not
<br>
the German people?&quot;, it's to not have dictatorship.
<br>
<p><em>&gt; &gt; In reality, a glut of intelligence/power
</em><br>
<em>&gt; &gt; combined with confinement - a high ratio of force to space - triggers the
</em><br>
<em>&gt; &gt; K-strategist elements of said axiom system, applying selective pressure in
</em><br>
<em>&gt; &gt; favor of memes corresponding to the moral concept of &quot;evil&quot;. (Consider the
</em><br>
<em>&gt; &gt; trend in ratio of lawyers to engineers in the population over the last
</em><br>
<em>&gt; &gt; century for an infinitesimal foreshadowing.)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Dude, what the *heck* are you talking about?
</em><br>
<p>Okay, in plainer language... are you familiar with the K-strategist
<br>
versus r-strategist distinction in biology?
<br>
<p><em>&gt; Is this what you think would inevitably happen if, starting with present human
</em><br>
<em>&gt; society, the average IQ began climbing by three points per year?  At what
</em><br>
<em>&gt; point - which decade, say - do you think humans would be so intelligent, know
</em><br>
<em>&gt; so much and think so quickly, that their society would turn utterly evil?
</em><br>
<p>Starting with present human society, create a world government with
<br>
absolute knowledge and absolute power, capable not only of seeing into
<br>
people's homes a la 1984, but into their very thoughts; with no
<br>
Constitution (you don't want any hardwired protections, after all) and
<br>
no escape, ever (nobody gets to opt out of CV). Don't you find it at
<br>
all reasonable to suggest that society would turn utterly evil very
<br>
quickly?
<br>
<p>- Russell
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11729.html">Russell Wallace: "Re: Collective Volition, next take"</a>
<li><strong>Previous message:</strong> <a href="11727.html">Eliezer S. Yudkowsky: "Re: Collective Volition, next take"</a>
<li><strong>In reply to:</strong> <a href="11725.html">Eliezer S. Yudkowsky: "Re: Collective Volition, next take"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11730.html">Eliezer S. Yudkowsky: "Re: Collective Volition, next take"</a>
<li><strong>Reply:</strong> <a href="11730.html">Eliezer S. Yudkowsky: "Re: Collective Volition, next take"</a>
<li><strong>Reply:</strong> <a href="11749.html">Thomas Buckner: "Re: Collective Volition, next take"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11728">[ date ]</a>
<a href="index.html#11728">[ thread ]</a>
<a href="subject.html#11728">[ subject ]</a>
<a href="author.html#11728">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:51 MDT
</em></small></p>
</body>
</html>
