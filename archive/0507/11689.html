<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: The return of the revenge of qualia, part VI.</title>
<meta name="Author" content="Tennessee Leeuwenburg (hamptonite@gmail.com)">
<meta name="Subject" content="Re: The return of the revenge of qualia, part VI.">
<meta name="Date" content="2005-07-21">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: The return of the revenge of qualia, part VI.</h1>
<!-- received="Thu Jul 21 22:40:36 2005" -->
<!-- isoreceived="20050722044036" -->
<!-- sent="Fri, 22 Jul 2005 14:39:38 +1000" -->
<!-- isosent="20050722043938" -->
<!-- name="Tennessee Leeuwenburg" -->
<!-- email="hamptonite@gmail.com" -->
<!-- subject="Re: The return of the revenge of qualia, part VI." -->
<!-- id="4f293f4050721213973f77d35@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20050722031513.32428.qmail@web26707.mail.ukl.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Tennessee Leeuwenburg (<a href="mailto:hamptonite@gmail.com?Subject=Re:%20The%20return%20of%20the%20revenge%20of%20qualia,%20part%20VI."><em>hamptonite@gmail.com</em></a>)<br>
<strong>Date:</strong> Thu Jul 21 2005 - 22:39:38 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11690.html">Daniel Radetsky: "Re: AI boxing"</a>
<li><strong>Previous message:</strong> <a href="11688.html">Marc Geddes: "Re: AI boxing"</a>
<li><strong>In reply to:</strong> <a href="11686.html">Michael Wilson: "Re: The return of the revenge of qualia, part VI."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11717.html">Chris Capel: "Re: The return of the revenge of qualia, part VI."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11689">[ date ]</a>
<a href="index.html#11689">[ thread ]</a>
<a href="subject.html#11689">[ subject ]</a>
<a href="author.html#11689">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Apologies for bad grammar -- pub lunch today. I think the arguments
<br>
stand, but sometimes I forget to correct my grammer when I change
<br>
perspective.
<br>
<p>On 7/22/05, Michael Wilson &lt;<a href="mailto:mwdestinystar@yahoo.co.uk?Subject=Re:%20The%20return%20of%20the%20revenge%20of%20qualia,%20part%20VI.">mwdestinystar@yahoo.co.uk</a>&gt; wrote:
<br>
<em>&gt; Tennessee Leeuwenburg wrote:
</em><br>
<em>&gt; &gt; I agree with him when he says, &quot;This should be obvious; memorising
</em><br>
<em>&gt; &gt; detailed instructions on how to ride a bicycle does not immediately
</em><br>
<em>&gt; &gt; grant you the ability to ride a bike competently, because you cannot
</em><br>
<em>&gt; &gt; deliberatively modify your neural circuitry with an act of will.&quot;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; But that is precisely what is interesting. A human cannot understand
</em><br>
<em>&gt; &gt; logically everything that they can learn, nor can they describe with
</em><br>
<em>&gt; &gt; phyics everything that is immanent (loosely, &quot;real&quot;) to them. This
</em><br>
<em>&gt; &gt; is, per se, interesting. This is where the debate lies.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Why are you intent on glamourising this relatively straightforward
</em><br>
<em>&gt; cognitive architecture limitation with metaphysics?
</em><br>
<p>In answering that question, I would be implicity accepting your
<br>
believe that I *am* doing that. I reject said belief. I truly believe
<br>
it to be a genuine possibility that an articifial intelligence might
<br>
have no consciousness, or awareness of immanence.
<br>
<p>I am intent on making that claim because I believe it to be true. The
<br>
intention is not glamour, but argument and truth. If that sounds
<br>
pompous, it is only because I am afraid that you actually mean what
<br>
you say, and so I am responding as such.
<br>
<p>Exactly what is invalid about metaphysical questions, and why are they
<br>
irrelevant to questions of cognitive architecture?
<br>
<p><em>&gt; &gt; She can make new qualitative predictions. Even if I were to accept
</em><br>
<em>&gt; &gt; (which I don't), that minds are reducible to brains, perfect physical
</em><br>
<em>&gt; &gt; knowledge could stil only make predictions at the physical level.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This statement is incorrect. If you accept that a brain could be
</em><br>
<em>&gt; simulated to an arbitrary degree of accuracy, then we can look at
</em><br>
<em>&gt; exactly what is going on in the simulation; we can work out what
</em><br>
<em>&gt; the human would report and what the internal sensations would be at
</em><br>
<em>&gt; any desired level of abstraction, in any desired system of
</em><br>
<em>&gt; cateogrisation/quantisation. We can give the human a verbal
</em><br>
<em>&gt; description that we calculate (via more modelling) will generate the
</em><br>
<em>&gt; closest approximation to what they'd actually experience, and in
</em><br>
<em>&gt; principle we can use invasive methods to directly cause the human
</em><br>
<em>&gt; to experience the relevant sensations, bypassing any irrelevant lower
</em><br>
<em>&gt; sensory areas.
</em><br>
<p>Firstly, while I'm happy to accept your tone as being argumentatively
<br>
efficient, the blanket claim &quot;this statement is incorrect&quot; is not
<br>
really the kind of thing which is uncontroversial or proven.
<br>
<p>Let me accept, temporarily, that the brain is capable of perfect
<br>
simulation (and here's the important qualifier) at the physical level.
<br>
All predictions are similarly restricted to the physical level.
<br>
Meaning is not predicted -- only brain state. If the predicting being
<br>
does not understand the meaning of its prediction of physical state,
<br>
then it is a meaningless prediction. (by construction)
<br>
<p>I am happy for the purposes of further argument to accept that brains
<br>
can be perfectly simulated, although in truth I am not convinced that
<br>
physics is truly deterministic. As such, I believe that true
<br>
randomness may introduce errors into any prediction, even though the
<br>
brain response prediction might be perfect.
<br>
<p><em>&gt; We can already do a few of these things, crudely, yet dualists
</em><br>
<em>&gt; persist in ignoring the evidence. I look forward to the wails of
</em><br>
<em>&gt; anguish that will emmenate from them after we develop the capability
</em><br>
<em>&gt; to do truely impressive brain-modelling and self-modification.
</em><br>
<p>I am not a dualist. I believe that mental states do arise from the
<br>
physical nature of the brain, and furthermore that other kinds of
<br>
machines are capable of hosting minds. But I also believe the
<br>
following :
<br>
<p>1) That other kinds of machines are capable of mimicking mental
<br>
behaviour without a mind
<br>
2) That qualia are real, and that physics as such does not capture the
<br>
full meaning of state.
<br>
<p>Perhaps that is a limitation of my imagination, but I believe I can
<br>
argue that I am not otherwise mistaken.
<br>
&nbsp;
<br>
<em>&gt; &gt; Physics, for example, doesn't enable to me understand what language
</em><br>
<em>&gt; &gt; means, nor does merely understanding the grammar and syntax and
</em><br>
<em>&gt; &gt; symbolism of a language allow me to use it.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This is a limit of your inferential capability, not any flaw in the
</em><br>
<em>&gt; materialist position.
</em><br>
<p>Possibly true. Care to point out the specific error? Or do you just
<br>
mean that another person *could* use physics to understand etc etc.
<br>
Let me broaden the claim :: physics, in principle, allows no being or
<br>
potential being, to understand etc etc, where physics is the study of
<br>
matter and its behaviour.
<br>
<p><em>&gt; &gt; If consciousness is our inner life, and qualia is what that
</em><br>
<em>&gt; &gt; consciousness is like, then a machine without qualia is a machine
</em><br>
<em>&gt; &gt; without an inner life.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 'Inner life' is a near-meaningless term for characteristing cognitive
</em><br>
<em>&gt; architectures. An AGI might and probably will lack the kind of
</em><br>
<em>&gt; reflective shortcomings that make human sensation so mysterious;
</em><br>
<em>&gt; whether this translates to a lack of something fundemental and
</em><br>
<em>&gt; important that human sensation has I can't say yet. I agree that
</em><br>
<em>&gt; snuffing out the illusion of qualia /might/ be a really bad thing
</em><br>
<em>&gt; from the standpoint of human morals, and thus may be an ethical
</em><br>
<em>&gt; issue for transhumans.
</em><br>
<p>Indeed -- by definition. I would simply argue that it is important to
<br>
humans that meaning be preserved.
<br>
<p>Cheers,
<br>
-T
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11690.html">Daniel Radetsky: "Re: AI boxing"</a>
<li><strong>Previous message:</strong> <a href="11688.html">Marc Geddes: "Re: AI boxing"</a>
<li><strong>In reply to:</strong> <a href="11686.html">Michael Wilson: "Re: The return of the revenge of qualia, part VI."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11717.html">Chris Capel: "Re: The return of the revenge of qualia, part VI."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11689">[ date ]</a>
<a href="index.html#11689">[ thread ]</a>
<a href="subject.html#11689">[ subject ]</a>
<a href="author.html#11689">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:51 MDT
</em></small></p>
</body>
</html>
