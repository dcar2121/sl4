<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Fighting UFAI</title>
<meta name="Author" content="pdugan (pdugan@vt.edu)">
<meta name="Subject" content="RE: Fighting UFAI">
<meta name="Date" content="2005-07-21">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Fighting UFAI</h1>
<!-- received="Thu Jul 21 11:43:37 2005" -->
<!-- isoreceived="20050721174337" -->
<!-- sent="Thu, 21 Jul 2005 13:42:57 -0400" -->
<!-- isosent="20050721174257" -->
<!-- name="pdugan" -->
<!-- email="pdugan@vt.edu" -->
<!-- subject="RE: Fighting UFAI" -->
<!-- id="43D0B5DD@zathras" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="Fighting UFAI" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> pdugan (<a href="mailto:pdugan@vt.edu?Subject=RE:%20Fighting%20UFAI"><em>pdugan@vt.edu</em></a>)<br>
<strong>Date:</strong> Thu Jul 21 2005 - 11:42:57 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11678.html">Michael Vassar: "Re: AI boxing"</a>
<li><strong>Previous message:</strong> <a href="11676.html">Eliezer S. Yudkowsky: "Magic means large search spaces"</a>
<li><strong>Maybe in reply to:</strong> <a href="11732.html">Phillip Huggan: "Fighting UFAI"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11677">[ date ]</a>
<a href="index.html#11677">[ thread ]</a>
<a href="subject.html#11677">[ subject ]</a>
<a href="author.html#11677">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
My question on the matter is: is a single human mind could be expected to go 
<br>
crazy in a &quot;weird&quot; universe would it be anthropomorphic to suggest a non-human 
<br>
mind would experience the same? If it would be anthropomorphic, than what is 
<br>
it about us anthropos that renders incompatability with strange ontological 
<br>
substrates? If this difficulty of ontological andaptation were investigated 
<br>
perhaps it would shed light on design issues relating to an AGI experiencing 
<br>
philosphical crisis versus and AGI greatly benifiting from the experience and 
<br>
gaining information patterns worthy of being called &quot;wisdom&quot;.
<br>
<p>&nbsp;&nbsp;&nbsp;Of course, if the limits of &quot;knowing everything about something&quot; are so 
<br>
fine grained, then perhaps with the right attitude a human or AGI would be 
<br>
able to take an experience grounded in weird ontology in stride, signifying a 
<br>
much lessened risk of philosophical crisis given radically differing qualia.
<br>
<p>&nbsp;&nbsp;&nbsp;Patrick
<br>
<p><em>&gt;===== Original Message From Chris Capel &lt;<a href="mailto:pdf23ds@gmail.com?Subject=RE:%20Fighting%20UFAI">pdf23ds@gmail.com</a>&gt; =====
</em><br>
<em>&gt;On 7/21/05, Tennessee Leeuwenburg &lt;<a href="mailto:hamptonite@gmail.com?Subject=RE:%20Fighting%20UFAI">hamptonite@gmail.com</a>&gt; wrote:
</em><br>
<em>&gt;&gt; &gt; Eh? What about emotion is so special that it would require anything
</em><br>
<em>&gt;&gt; &gt; more than a Turing machine to implement as part of an GAI? (That begs
</em><br>
<em>&gt;&gt; &gt; the question of whether it's even desirable for Friendliness. That one
</em><br>
<em>&gt;&gt; &gt; seems to be emphatically NO.) How would quantum computing help
</em><br>
<em>&gt;&gt; &gt; anything?
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Allow me to respond to this entirely out-of-context, as this was a
</em><br>
<em>&gt;&gt; debating point against something I didn't stay. Rather, let me pose a
</em><br>
<em>&gt;&gt; thought experiment to you.
</em><br>
<em>&gt;
</em><br>
<em>&gt;[clip thought experiment]
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt; Has she learnt anything new about colour? If you accept that she has,
</em><br>
<em>&gt;&gt; then qualia must be real, because she already knew everything that
</em><br>
<em>&gt;&gt; science could inform her about the world and about colour. There must,
</em><br>
<em>&gt;&gt; therefore, be something real about colour which is not addressed by
</em><br>
<em>&gt;&gt; science.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Well, I read a good essay by Dennet examining this very experiment in
</em><br>
<em>&gt;The Mind's I. Basically, his argument was that the intuition pump is
</em><br>
<em>&gt;misleading because of the phrase &quot;learned everything about
</em><br>
<em>&gt;vision/seeing red&quot;. We really don't know what knowing &quot;everything&quot;
</em><br>
<em>&gt;about this subject would be like, so our intuitive idea of what this
</em><br>
<em>&gt;amount of knowledge is, is approximately what a very accomplished Ph.D
</em><br>
<em>&gt;or two or three would collectively know on the subject. But taken
</em><br>
<em>&gt;literally, it implies almost infinite amounts of knowledge, most of it
</em><br>
<em>&gt;mostly useless. But certainly we can't rule out the possibility that a
</em><br>
<em>&gt;scientist living in a time where the science of the brain is mature
</em><br>
<em>&gt;and mostly complete would be able to use all of the existing
</em><br>
<em>&gt;scientific knowledge, and knowledge of how her own brain is wired, to
</em><br>
<em>&gt;know exactly what visual impression she would receive from a red
</em><br>
<em>&gt;object. In fact, the situation--knowing &quot;everything&quot; about
</em><br>
<em>&gt;something--is so foreign to us that using it as a thought experiment
</em><br>
<em>&gt;is practicing philosophy on rather shaky grounds.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Actually, bringing this back to the original point (did this thought
</em><br>
<em>&gt;experiment bear on that point?), I do lend some credence to the
</em><br>
<em>&gt;existence of qualia, and still I have no trouble believing that they
</em><br>
<em>&gt;could arise on purely non-quantum biological devices, or even
</em><br>
<em>&gt;electronic, devices. Now, I have no reason to believe that they do,
</em><br>
<em>&gt;except that most thought apparently does, and it would be quite an
</em><br>
<em>&gt;exception, and a violation of Occam's Razor, to say that it requires a
</em><br>
<em>&gt;fundamentally different kind of device to support them, and I just
</em><br>
<em>&gt;don't see the evidence, nor the justification. The same way that
</em><br>
<em>&gt;Occam's Razor seems to some to discount the possibility of qualia,
</em><br>
<em>&gt;those who see their primary experience as lending evidence to qualia
</em><br>
<em>&gt;ought to apply Occam's Razor to the idea that qualia are somehow
</em><br>
<em>&gt;exceptional processes in the brain, ones that can't be modeled the
</em><br>
<em>&gt;same way the rest of the brain can.
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt; &gt; I don't quite understand what kind of threat you could see concerning
</em><br>
<em>&gt;&gt; &gt; an AI suddenly understanding a different ontology and going crazy. How
</em><br>
<em>&gt;&gt; &gt; likely would this be?
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; The quote marks indicate that you are replying to me, but in fact I
</em><br>
<em>&gt;&gt; didn't suggest this.
</em><br>
<em>&gt;
</em><br>
<em>&gt;I didn't mean to imply this. But I believe pdugan did suggest, and I
</em><br>
<em>&gt;could be wrong, that there is a danger in the possibility that an AI
</em><br>
<em>&gt;would find some other universe, or some other mode of existing in this
</em><br>
<em>&gt;one, that lends itself to different modalities and a different
</em><br>
<em>&gt;ontology. I was just inquiring as to what he thinks the exact nature
</em><br>
<em>&gt;of the threat that situation would pose is, besides being existential.
</em><br>
<em>&gt;My first impression is that it's rather unlikely, but he didn't do
</em><br>
<em>&gt;much explaining.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Chris Capel
</em><br>
<em>&gt;--
</em><br>
<em>&gt;&quot;What is it like to be a bat? What is it like to bat a bee? What is it
</em><br>
<em>&gt;like to be a bee being batted? What is it like to be a batted bee?&quot;
</em><br>
<em>&gt;-- The Mind's I (Hofstadter, Dennet)
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11678.html">Michael Vassar: "Re: AI boxing"</a>
<li><strong>Previous message:</strong> <a href="11676.html">Eliezer S. Yudkowsky: "Magic means large search spaces"</a>
<li><strong>Maybe in reply to:</strong> <a href="11732.html">Phillip Huggan: "Fighting UFAI"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11677">[ date ]</a>
<a href="index.html#11677">[ thread ]</a>
<a href="subject.html#11677">[ subject ]</a>
<a href="author.html#11677">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:51 MDT
</em></small></p>
</body>
</html>
