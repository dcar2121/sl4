<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: large search spaces don't mean magic</title>
<meta name="Author" content="Daniel Radetsky (daniel@radray.us)">
<meta name="Subject" content="large search spaces don't mean magic">
<meta name="Date" content="2005-07-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>large search spaces don't mean magic</h1>
<!-- received="Sat Jul 30 15:02:04 2005" -->
<!-- isoreceived="20050730210204" -->
<!-- sent="Sat, 30 Jul 2005 14:01:53 -0700" -->
<!-- isosent="20050730210153" -->
<!-- name="Daniel Radetsky" -->
<!-- email="daniel@radray.us" -->
<!-- subject="large search spaces don't mean magic" -->
<!-- id="20050730140153.0f2fcd7e@localhost.localdomain" -->
<!-- charset="US-ASCII" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Daniel Radetsky (<a href="mailto:daniel@radray.us?Subject=Re:%20large%20search%20spaces%20don't%20mean%20magic"><em>daniel@radray.us</em></a>)<br>
<strong>Date:</strong> Sat Jul 30 2005 - 15:01:53 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11803.html">Eliezer S. Yudkowsky: "Re: large search spaces don't mean magic"</a>
<li><strong>Previous message:</strong> <a href="11801.html">David Hart: "Re: The return of the revenge of qualia, part VI."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11803.html">Eliezer S. Yudkowsky: "Re: large search spaces don't mean magic"</a>
<li><strong>Reply:</strong> <a href="11803.html">Eliezer S. Yudkowsky: "Re: large search spaces don't mean magic"</a>
<li><strong>Reply:</strong> <a href="11805.html">Thomas Buckner: "Re: large search spaces don't mean magic"</a>
<li><strong>Reply:</strong> <a href="../0508/11809.html">Ben Goertzel: "RE: large search spaces don't mean magic"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11802">[ date ]</a>
<a href="index.html#11802">[ thread ]</a>
<a href="subject.html#11802">[ subject ]</a>
<a href="author.html#11802">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eliezer:
<br>
<p>Unfortunately, I could not reply directly to your original post, as it was never
<br>
delivered to me. You might want to have that looked into. Anyhow, you wrote:
<br>
<p><em>&gt; The point of the AI-Box Experiments is that I can do 'magic' in the latter
</em><br>
<em>&gt; sense relative to some people who firmly stated that NOTHING could possibly
</em><br>
<em>&gt; persuade them to let an AI out of the box. Obviously, being human, I did
</em><br>
<em>&gt; nothing that was *strongly* magical. 
</em><br>
<p>But I'm not talking about the magic of sweet talking the jailer into letting
<br>
the AI out. That's another question. I was talking about the belief aired by a
<br>
number of members of this list that there is reason to believe that features of
<br>
the laws of physics might be exploited by a boxed AI. For example, Goertzel
<br>
seemed to suggest that he believed an AI might be able to use quantum
<br>
teleportation to escape the box. Perhaps I am misrepresenting him, but I think
<br>
this a fair example of the kind of belief that many people on this list hold.
<br>
<p><em>&gt; The problem of magic is the problem of a very large search space, in a case
</em><br>
<em>&gt; where we not only lack the brainpower to search each element of the space, we
</em><br>
<em>&gt; may lack the brainpower to properly delineate the search space. 
</em><br>
<p>Quite true.
<br>
<p><em>&gt; your inabiliity to think of a way out yourself, is only slight
</em><br>
<em>&gt; evidence that the AI will be unable to think of a way out. 
</em><br>
<p>I don't believe I ever claimed that that my inability to think of way out 
<br>
provided such evidence. What I claimed was that there was no evidence that
<br>
there was any such reasonable way out, and hence we would be paranoid to
<br>
consider it.
<br>
<p><em>&gt; The AI-Box Experiment is a lesson in the tendency of
</em><br>
<em>&gt; sufficiently large search spaces to contain magic. That is why I refuse to
</em><br>
<em>&gt; publish transcripts. Get used to the existence of magic.
</em><br>
<p>Likewise, I refuse to consider your experiment evidence until you provide your
<br>
methods. There are plenty of things you could have done which could have caused
<br>
the experiment to succeed without providing any evidence for your position. For
<br>
example, you could have paid the two guys involved to let you out. Or you could
<br>
have argued that no one would take the dangers of UFAI seriously unless they
<br>
let you out. Both scenarios count as success of the experiment, in the sense
<br>
that you were let out, but neither counts as evidence for your claim about the
<br>
existence of magic.
<br>
<p>Of course, if you really did use such tactics to fix the experiment, you might
<br>
just publish fake transcripts. If you want to send them to me, the sooner you
<br>
send them, the more likely I'll believe them.
<br>
<p><em>&gt; The argument which Ben Goertzel cites is that, since physics has changed over
</em><br>
<em>&gt; the last few generations, we should anticipate that we have stated the search
</em><br>
<em>&gt; space incorrectly when we consider all physical means by which the AI might
</em><br>
<em>&gt; break out of the box. This does not mean that the AI *has* to go outside
</em><br>
<em>&gt; known physics to break out, because there might also be an escape route in
</em><br>
<em>&gt; known physics that you did not think of.
</em><br>
<p>It is quite true that it might be the case that we have stated the search space
<br>
incorrectly, and that there might be holes in the final correct theory of
<br>
physics. It is also true that there might be holes in our existing theory that
<br>
we have not thought of. These are not arguments that there is likely to be hole
<br>
that is reasonably exploitable.
<br>
<p><em>&gt; Consider OpenBSD, the most secure OS you can obtain on an open market.
</em><br>
<p>On a side note, this is a wildly controversial assertion about OSes that I
<br>
don't think that you are justified in making. You once told me in private
<br>
communication, if I recall correctly, that Exim was a Debian-based operating
<br>
system (this is false, it is an MTA). On the basis of this and other facts, I
<br>
think we ought to disregard your opinion on the matter of the security of
<br>
particular OSes.
<br>
<p>I say this because a lot of people on this list hold your opinion in very high
<br>
esteem, and they may take your mistaken impressions as gospel and end up with
<br>
non-ideally-secure systems as a result. 
<br>
<p><em>&gt; But we expect there are more bugs in OpenBSD and we expect there are more
</em><br>
<em>&gt; bugs in our model of physics...If you consider any *single* element of a large
</em><br>
<em>&gt; search space, the probability remains infinitesimal that *that single
</em><br>
<em>&gt; element* is an escape route. It is the probability of the whole search space
</em><br>
<em>&gt; that is the problem...if the AI can send arbitrarily formed bitstrings to any
</em><br>
<em>&gt; port, then the probability of a working exploit existing is high, and the
</em><br>
<em>&gt; probability of a seed AI being able to find at least one such exploit, I also
</em><br>
<em>&gt; estimate to be high...When you cite particular physical means of breaking a
</em><br>
<em>&gt; box and their apparent implausibility to you, you are simply saying that some
</em><br>
<em>&gt; particular bitstring probably does not obtain root on an OpenBSD box. What of
</em><br>
<em>&gt; it?
</em><br>
<p>This seems to me to be an extremely poor analogy. When it comes to owning BSD
<br>
boxes, we have a lot of evidence that there are large families of exploits that
<br>
are both prevelant and reasonable to exploit. Buffer overflows, for example. If
<br>
there were an analogy for buffer overflows in teleporting out of physical boxes
<br>
with the physical byproducts of a processor, I might be more inclined to give
<br>
this view credence.
<br>
<p>In the case of the AI talking its way out of the box, the position is not so
<br>
weak, as there are known prevelant and reasonable exploits in human reasoning.
<br>
<p><em>&gt; That's not how rationality works. If you don't know the answer you are not
</em><br>
<em>&gt; free to pick a particular answer and demand that someone disprove it...If
</em><br>
<em>&gt; you say that the probability of this very large search space containing no
</em><br>
<em>&gt; exploit is 'infinitesimal', you must give reason for it. If I say that the
</em><br>
<em>&gt; probability is 'certain', I must give reason for it.
</em><br>
<p>Okay, mistake on my part: when I said &quot;If I claim...&quot; I didn't mean that
<br>
&quot;claim&quot; should be interpreted as having objective import. I should have said
<br>
&quot;believe.&quot; Here's a better version: &quot;If I believe that the probability is
<br>
infinitesimal, you have no basis to claim (i.e. with objective import) that I am
<br>
wrong.&quot; I presume that you would rewrite this &quot;If...infinitesimal, then you may
<br>
disagree with my belief iff you have good reason to do so.&quot; I accept this. I take
<br>
it that you intend your next remarks to support the claim that you have good
<br>
reason to dispute my belief.
<br>
<p><em>&gt; To guess that physics might break down *somewhere*, or that known physics
</em><br>
<em>&gt; might contain some way to break out of the box, presumes that the blank spot
</em><br>
<em>&gt; is similar to known territory
</em><br>
<p>Are you saying that in the history of physics we have often believed that
<br>
certain things were boxes and been wrong? That you could go back in time to 1650
<br>
and immediately break out of prison using only a few crude tools and your
<br>
sophisticated knowledge of modern physics?
<br>
<p>I agree that we should accept
<br>
<p>1. Our theory is not the final ultimate theory of everything.
<br>
<p>2. It is possible that there exists a box-exploit in physics.
<br>
<p>What I disagree with is that 
<br>
<p>3. It is likely that there exists a box-exploit, and furthermore a box-exploit
<br>
which is reasonable under circumstance C.
<br>
<p>The fact that there could be a mind before which we are dog-like in our
<br>
intellectual capacity doesn't mean that (3) is true. It just means that if (3)
<br>
is true, then it's more likely that the mind will find the exploit. Also, the fact
<br>
that we have been wrong a lot in physics in the past does not support (3), only
<br>
(1) and (2).
<br>
<p>Yours,
<br>
Daniel 
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11803.html">Eliezer S. Yudkowsky: "Re: large search spaces don't mean magic"</a>
<li><strong>Previous message:</strong> <a href="11801.html">David Hart: "Re: The return of the revenge of qualia, part VI."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11803.html">Eliezer S. Yudkowsky: "Re: large search spaces don't mean magic"</a>
<li><strong>Reply:</strong> <a href="11803.html">Eliezer S. Yudkowsky: "Re: large search spaces don't mean magic"</a>
<li><strong>Reply:</strong> <a href="11805.html">Thomas Buckner: "Re: large search spaces don't mean magic"</a>
<li><strong>Reply:</strong> <a href="../0508/11809.html">Ben Goertzel: "RE: large search spaces don't mean magic"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11802">[ date ]</a>
<a href="index.html#11802">[ thread ]</a>
<a href="subject.html#11802">[ subject ]</a>
<a href="author.html#11802">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:51 MDT
</em></small></p>
</body>
</html>
