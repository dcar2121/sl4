<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Collective Volition, next take</title>
<meta name="Author" content="Chris Capel (pdf23ds@gmail.com)">
<meta name="Subject" content="Re: Collective Volition, next take">
<meta name="Date" content="2005-07-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Collective Volition, next take</h1>
<!-- received="Sat Jul 23 14:37:14 2005" -->
<!-- isoreceived="20050723203714" -->
<!-- sent="Sat, 23 Jul 2005 15:37:12 -0500" -->
<!-- isosent="20050723203712" -->
<!-- name="Chris Capel" -->
<!-- email="pdf23ds@gmail.com" -->
<!-- subject="Re: Collective Volition, next take" -->
<!-- id="737b61f3050723133758927fff@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="8d71341e05072311123b1be271@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Chris Capel (<a href="mailto:pdf23ds@gmail.com?Subject=Re:%20Collective%20Volition,%20next%20take"><em>pdf23ds@gmail.com</em></a>)<br>
<strong>Date:</strong> Sat Jul 23 2005 - 14:37:12 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11736.html">Eliezer S. Yudkowsky: "Re: Collective Volition, next take"</a>
<li><strong>Previous message:</strong> <a href="11734.html">Russell Wallace: "Re: Collective Volition, next take"</a>
<li><strong>In reply to:</strong> <a href="11722.html">Russell Wallace: "Re: Collective Volition, next take"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11740.html">Russell Wallace: "Re: Collective Volition, next take"</a>
<li><strong>Reply:</strong> <a href="11740.html">Russell Wallace: "Re: Collective Volition, next take"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11735">[ date ]</a>
<a href="index.html#11735">[ thread ]</a>
<a href="subject.html#11735">[ subject ]</a>
<a href="author.html#11735">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 7/23/05, Russell Wallace &lt;<a href="mailto:russell.wallace@gmail.com?Subject=Re:%20Collective%20Volition,%20next%20take">russell.wallace@gmail.com</a>&gt; wrote:
<br>
<em>&gt; The deadliest flaw in CV (actually it's far worse than merely deadly,
</em><br>
<em>&gt; as will be seen) is that it's still chasing the ghost of
</em><br>
<em>&gt; universe-dictated morality, that in simpler form was the source of
</em><br>
<em>&gt; Eliezer's and my first subjunctive planet kills.
</em><br>
<p>What were those?
<br>
<p><em>&gt; It throws vast
</em><br>
<em>&gt; resources of intelligence - information-processing ability - behind
</em><br>
<em>&gt; moral axioms evolved for survival on the plains of Africa, and then -
</em><br>
<em>&gt; this is the problem - proceeds as though with unlimited power comes
</em><br>
<em>&gt; unlimited moral authority. In reality, a glut of intelligence/power
</em><br>
<em>&gt; combined with confinement - a high ratio of force to space - triggers
</em><br>
<em>&gt; the K-strategist elements of said axiom system, applying selective
</em><br>
<em>&gt; pressure in favor of memes corresponding to the moral concept of
</em><br>
<em>&gt; &quot;evil&quot;. (Consider the trend in ratio of lawyers to engineers in the
</em><br>
<em>&gt; population over the last century for an infinitesimal foreshadowing.)
</em><br>
<em>&gt;
</em><br>
<em>&gt; In pursuit of a guiding light that isn't there,
</em><br>
<p>&quot;Guiding light&quot; here being the overall convergence of volition? So
<br>
you're claiming that volition wouldn't really converge?
<br>
<p><em>&gt; the RPOP would
</em><br>
<em>&gt; extrapolate the interaction between K-strategist genes and parasite
</em><br>
<em>&gt; memes and force the result, with utter indifference to the
</em><br>
<em>&gt; consequences, on the entire human race. There will be no goal system
</em><br>
<em>&gt; for any element of the Collective but power - not clean power over the
</em><br>
<em>&gt; material world (which will effectively have ceased to exist except as
</em><br>
<em>&gt; the RPOP's substrate) but power always and only over others - a regime
</em><br>
<em>&gt; of the most absolute, perfectly distilled evil ever contemplated by
</em><br>
<em>&gt; the human mind. (Watch an old movie called &quot;Zardoz&quot; for a little more
</em><br>
<em>&gt; foreshadowing.)
</em><br>
<p>I really don't understand this. What axiom system, and how is it
<br>
K-strategist? Grasping at your analogy, I guess that you mean to say
<br>
that human society has tended toward power-grasping, power
<br>
conglomeration, and that CV would extrapolate this tendency and
<br>
cause--who?--to be placed in absolute power over everyone else.
<br>
Doesn't this idea seem to go against the idea of CV giving each
<br>
sentience equal weight (or perhaps weight corresponding to their level
<br>
of awareness) in determining what the CV of humanity is? Or maybe you
<br>
mean to say that each individual human, when they gain knowledge and
<br>
awareness, tend to lust for power? But I think that most power-hungry
<br>
people are abberant in this sense. In any case, there's a fundamental
<br>
incoherence in trying to find the convergence in two people's desire
<br>
to hold power over each other. Because each's idea is that they
<br>
themself are the one in power, and so the intersection of those two
<br>
desires is very small. Then again, the effects of gravity on a huge
<br>
number of individual particles gives rise to planets and suns. Each
<br>
particle in a planet attracts each other particle, yet the effect
<br>
doesn't cancel out completely and lead to no gravity. In sum, it
<br>
causes large amounts of pressure to be exerted on the core of the
<br>
planet. Perhaps this is a good metaphor for the CV dystopia you have
<br>
in mind?
<br>
<p>I'm less trying to criticize your post than to give you food for
<br>
thought, so you might perhaps be able to make clearer the exact nature
<br>
of the danger you see.
<br>
<p>You mention parasitic memes. This gives me an idea about a criticism
<br>
of collective volition that may or may not be what you're saying.
<br>
<p>There could be some dangerous and very powerful memes that haven't yet
<br>
evolved that could eventually do so and lead to some sort of dystopia,
<br>
and the CV process might recognize their eventual inevitability and
<br>
thus choose their effects as the direction to lead humanity.
<br>
Alternatively, in a non-singularity timeline of history, memetic
<br>
organisms could eventually evolve such complexity that sentience
<br>
actually begins to be more properly described as belonging to the meme
<br>
system than the humans themselves. From a human perspective, this
<br>
organism might resemble such severe dystopias as seen in fiction like
<br>
The Matrix. The human becomes so subservient to the memetic complex
<br>
that there is no sense of individuality at all, and perhaps not even
<br>
conscious experience. Humans might be merely cells in a multicellular
<br>
organism. Then again, it's unknown to what extent the state of global
<br>
society would presently yield to this interpretation, and thus what
<br>
kind of memetic organisms are currently in existence, and what their
<br>
complexity is, so speculation in this matter is particularly
<br>
difficult. But put abstractly, in an extrapolation of humanity's
<br>
future, a particular meme could be so powerful that it acts an
<br>
attractor in phase-space toward a particular dystopia. How does CV
<br>
treat this possibility?
<br>
<p>A more coherent objection might follow these lines. The human mind, as
<br>
Eliezer himself has said, is an unstable thing. It's prone to get
<br>
itself into states that other humans call psychological disorders.
<br>
Things like sociopathy, narciccism, manic depression, anorexia,
<br>
schizophrenia. As &quot;normal&quot;, &quot;healthy&quot; humans, we regard these states
<br>
as aberrant. But society here can have a huge effect on what we regard
<br>
as normal. When extrapolating an individual's volition had they more
<br>
intelligence, more interaction with society, their volition could vary
<br>
greatly in what new knoweldge one presumes the extrapolated individual
<br>
would have acquired, and what patterns of interactions they partake
<br>
of. Smarter individuals fit into society differently, and a society of
<br>
smarter people is a different kind of society. Not to mention the
<br>
effect of different systems of belief. One person who is introduced to
<br>
belief systems in one particular order will tend to accept certain
<br>
combinations of these belief systems and resist accepting new ones. A
<br>
scientologist is extremely hard to convince of the truth of anything
<br>
that conflicts with their belief system. So does the AI extrapolate
<br>
using the knowledge in a person's head, simply subjectively increasing
<br>
their IQ? Or does it introduce new knowledge to the person? How does
<br>
the AI present the knowledge in a fairminded, non-biased way? One
<br>
person's bias is another's dogma is another's obvious truth. Given
<br>
that a superintelligence could convince pretty much anyone of the
<br>
truth of anything, the prospect of educating people seems more to
<br>
resemble painting pictures on a blank canvas than it does conveying
<br>
information to an active listener. It seems that it's very difficult
<br>
for the AI to play a truly secondary role in this &quot;extrapolation&quot;
<br>
process. When extrapolating an individual's beliefs could lead in
<br>
directions ranging from complete irrationality and dogmatic
<br>
closmindedness to enlightened and balanced open-mindedness, depending
<br>
on what information the person is fed in what order, it becomes
<br>
obvious that we need a standard for communicating information
<br>
neutrally. I don't think it's possible to communicate information
<br>
neutrally, though. Any communication, without exception, is, in the
<br>
simplest view of it, the attempt to persuade the recepient of the
<br>
communication to adopt a certain attitude toward a certain object or
<br>
idea. This is inherently biased and sided.
<br>
<p>So, let me say it again, hopefully more simply. The process of
<br>
extrapolating a human's desire if they were smarter implicitly
<br>
includes extrapolating the human's desire if certain events were to
<br>
take place affecting them in a way that we judge increases their
<br>
intelligence, or their maturity, or whatever. This simulation of the
<br>
human's developmental reaction to events is a necessary part of any
<br>
such extrapolation. The choice of which events are necessary to bring
<br>
about the desired developmental changes is a /hopelessly/ biased and
<br>
observer-centric choice, as are the developmental changes suggested. A
<br>
particularly relevant observation here is that there are certain
<br>
events that greatly increase a person's self-reported maturity and
<br>
enlightenment but in particularly malicious ways (e.g. being converted
<br>
to Scientology). There are many such different events that lead people
<br>
in entirely different directions, many of which lead in directions
<br>
most people would regard as real growth, and many of which lead to
<br>
what most people would regard as craziness. There is no way to avoid
<br>
the persistent programmer influence in this choice.
<br>
<p>Chris Capel
<br>
<pre>
-- 
&quot;What is it like to be a bat? What is it like to bat a bee? What is it
like to be a bee being batted? What is it like to be a batted bee?&quot;
-- The Mind's I (Hofstadter, Dennet)
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11736.html">Eliezer S. Yudkowsky: "Re: Collective Volition, next take"</a>
<li><strong>Previous message:</strong> <a href="11734.html">Russell Wallace: "Re: Collective Volition, next take"</a>
<li><strong>In reply to:</strong> <a href="11722.html">Russell Wallace: "Re: Collective Volition, next take"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11740.html">Russell Wallace: "Re: Collective Volition, next take"</a>
<li><strong>Reply:</strong> <a href="11740.html">Russell Wallace: "Re: Collective Volition, next take"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11735">[ date ]</a>
<a href="index.html#11735">[ thread ]</a>
<a href="subject.html#11735">[ subject ]</a>
<a href="author.html#11735">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:51 MDT
</em></small></p>
</body>
</html>
