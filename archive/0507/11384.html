<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: &quot;Supergoal&quot; considered harmful; New term: &quot;Quality Function&quot;</title>
<meta name="Author" content="Thomas Buckner (tcbevolver@yahoo.com)">
<meta name="Subject" content="&quot;Supergoal&quot; considered harmful; New term: &quot;Quality Function&quot;">
<meta name="Date" content="2005-07-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>&quot;Supergoal&quot; considered harmful; New term: &quot;Quality Function&quot;</h1>
<!-- received="Sun Jul 17 02:08:57 2005" -->
<!-- isoreceived="20050717080857" -->
<!-- sent="Sun, 17 Jul 2005 01:08:54 -0700 (PDT)" -->
<!-- isosent="20050717080854" -->
<!-- name="Thomas Buckner" -->
<!-- email="tcbevolver@yahoo.com" -->
<!-- subject="&quot;Supergoal&quot; considered harmful; New term: &quot;Quality Function&quot;" -->
<!-- id="20050717080854.75550.qmail@web60017.mail.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="42D9BFDA.1020101@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas Buckner (<a href="mailto:tcbevolver@yahoo.com?Subject=Re:%20&quot;Supergoal&quot;%20considered%20harmful;%20New%20term:%20&quot;Quality%20Function&quot;"><em>tcbevolver@yahoo.com</em></a>)<br>
<strong>Date:</strong> Sun Jul 17 2005 - 02:08:54 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11385.html">Michael Wilson: "Flashback to 1975"</a>
<li><strong>Previous message:</strong> <a href="11383.html">Eliezer S. Yudkowsky: "Re: &quot;Supergoal&quot; considered harmful"</a>
<li><strong>In reply to:</strong> <a href="11383.html">Eliezer S. Yudkowsky: "Re: &quot;Supergoal&quot; considered harmful"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11390.html">pdugan: "RE: &quot;Supergoal&quot; considered harmful; New term: &quot;Quality Function&quot;"</a>
<li><strong>Maybe reply:</strong> <a href="11390.html">pdugan: "RE: &quot;Supergoal&quot; considered harmful; New term: &quot;Quality Function&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11384">[ date ]</a>
<a href="index.html#11384">[ thread ]</a>
<a href="subject.html#11384">[ subject ]</a>
<a href="author.html#11384">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- &quot;Eliezer S. Yudkowsky&quot; &lt;<a href="mailto:sentience@pobox.com?Subject=Re:%20&quot;Supergoal&quot;%20considered%20harmful;%20New%20term:%20&quot;Quality%20Function&quot;">sentience@pobox.com</a>&gt;
<br>
wrote:
<br>
<p><em>&gt; Should the AI be a good predictor, it will
</em><br>
<em>&gt; systematically steer reality into 
</em><br>
<em>&gt; regions which its utility function assigns high
</em><br>
<em>&gt; utilities.  Thus, the term 
</em><br>
<em>&gt; &quot;supergoal&quot; that I used in CFAI means simply
</em><br>
<em>&gt; &quot;utility function&quot;.  And if the 
</em><br>
<em>&gt; AI is a good predictor, its utility function
</em><br>
<em>&gt; also serves as a good description 
</em><br>
<em>&gt; of the target of the optimization process, the
</em><br>
<em>&gt; regions of reality into which 
</em><br>
<em>&gt; the AI does in fact steer the future.
</em><br>
<p>I think this is an appropriate time to apply my
<br>
previous post about the NLP method of identifying
<br>
'values' in the sense of 'what does this utility
<br>
function achieve?' Perhaps for sl4 purposes a new
<br>
word is needed, since mathematicians already mean
<br>
something else by the word 'values', and it's
<br>
apparently too late to decide that 'supergoal'
<br>
can fill this function.
<br>
<p>So let me propose &quot;quality function&quot; as the new
<br>
term; it implies 'qualia' since (frothy, dodgy
<br>
word though it is) we can agree that pleasant
<br>
qualia are what we humans are hoping to get from
<br>
FAI; it also implies 'quality' in the sense of
<br>
'quality of life' which, again, we are hoping to
<br>
get from FAI. 
<br>
<p>I propose this since you (Eliezer, and perhaps
<br>
others) seem to have punted the question of &quot;What
<br>
is the optimum utility function *in humans* that
<br>
the FAI utility function is supposed to achieve?&quot;
<br>
It seems to me that you have found flaws with all
<br>
pre-existing ideas about what this ultimate human
<br>
goal or set of goals could be, which presents a
<br>
seemingly intractable Alphonse-and-Gaston dilemma
<br>
(You first! No, you first! No, I insist, sir! And
<br>
so on.) The seed AI programmer dare not make any
<br>
assumptions beforehand about CV without first
<br>
letting the superior mind of the AI judge the
<br>
likelihood of success, but if the AI gets ahead
<br>
of the human programmer, ve may not be Friendly
<br>
or fully informed about the needs of humans, and
<br>
offer wrong answers, and around and around we go.
<br>
<p>So, like it or not, we need more confidence that
<br>
we understand the quality function, from which we
<br>
derive the AI's utility function.
<br>
<p>I'm thinking of Monty Python and the Holy Grail.
<br>
King Arthur, at the end, are convinced that the
<br>
French knights in the castle have the Grail, and
<br>
one of their failed gambits is the building of a
<br>
wooden rabbit, which is catapulted back and
<br>
crushes one or two Englishmen. A nested view of
<br>
their utility functions (UF), with each step
<br>
intended to achieve the next, higher value, might
<br>
run as follows:
<br>
<p>UF Build wooden rabbit =&gt; UF infiltrate castle =&gt;
<br>
UF overpower French knights =&gt; UF search castle
<br>
=&gt; UF find Grail =&gt; QF serve Greater Glory of
<br>
God.
<br>
<p>Fans of the film will know that the plan broke
<br>
down at the second step, due to the failure to
<br>
put anybody in the wooden rabbit (obviously, any
<br>
utility function might depend on more than one
<br>
lower function, so the actual nested view could
<br>
be a tree converging on a single trunk function;
<br>
when you are down to one trunk or a set of equal
<br>
and indispensable trunks, you've found your QF).
<br>
But there were many assumptions underlying the
<br>
English plan; once inside, they might have lost
<br>
the fight; the French might not really have had
<br>
the Grail; Jehovah's original geas to go find the
<br>
Grail might have been a mass hallucination!
<br>
Perhaps, in order to serve the highest quality
<br>
function (Greater Glory of God), Arthur and his
<br>
knights should have just gone home and helped
<br>
feed the poor.
<br>
<p>This is a point where I think I misunderstood
<br>
Eliezer all along; when he wrote 'supergoal (UF)'
<br>
I thought he was talking about something a lot
<br>
closer to 'supergoal (QF)'.
<br>
<p>Now I expect Eliezer to fill my backside with
<br>
buckshot for proposing a quality function that
<br>
floats atop the utility function with no
<br>
mathematical means of support, but it can't be
<br>
helped (yet?) The quality function, in the end,
<br>
would be what all discussion of CV, domain
<br>
protection, singularity fun theory, and so on,
<br>
are intended to produce: a
<br>
mathematically/logically sturdy formulation of
<br>
what it is that the utility function is meant *by
<br>
us* to achieve. A paperclip maximizer, in this
<br>
light, is an AI that performs the utility
<br>
function flawlessly but makes a total wreck of
<br>
the quality function (or punishes us for not
<br>
having nailed down the quality function in time
<br>
for the AI to make use of it).
<br>
<p>Tom Buckner
<br>
<p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
____________________________________________________
<br>
Start your day with Yahoo! - make it your home page 
<br>
<a href="http://www.yahoo.com/r/hs">http://www.yahoo.com/r/hs</a> 
<br>
&nbsp;
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11385.html">Michael Wilson: "Flashback to 1975"</a>
<li><strong>Previous message:</strong> <a href="11383.html">Eliezer S. Yudkowsky: "Re: &quot;Supergoal&quot; considered harmful"</a>
<li><strong>In reply to:</strong> <a href="11383.html">Eliezer S. Yudkowsky: "Re: &quot;Supergoal&quot; considered harmful"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11390.html">pdugan: "RE: &quot;Supergoal&quot; considered harmful; New term: &quot;Quality Function&quot;"</a>
<li><strong>Maybe reply:</strong> <a href="11390.html">pdugan: "RE: &quot;Supergoal&quot; considered harmful; New term: &quot;Quality Function&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11384">[ date ]</a>
<a href="index.html#11384">[ thread ]</a>
<a href="subject.html#11384">[ subject ]</a>
<a href="author.html#11384">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:22:57 MST
</em></small></p>
</body>
</html>
