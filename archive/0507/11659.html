<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI boxing</title>
<meta name="Author" content="Daniel Radetsky (daniel@radray.us)">
<meta name="Subject" content="Re: AI boxing">
<meta name="Date" content="2005-07-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI boxing</h1>
<!-- received="Wed Jul 20 23:22:58 2005" -->
<!-- isoreceived="20050721052258" -->
<!-- sent="Wed, 20 Jul 2005 22:22:59 -0700" -->
<!-- isosent="20050721052259" -->
<!-- name="Daniel Radetsky" -->
<!-- email="daniel@radray.us" -->
<!-- subject="Re: AI boxing" -->
<!-- id="20050720222259.2a6ccc8f@localhost.localdomain" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="JNEIJCJJHIEAILJBFHILGEFFFCAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Daniel Radetsky (<a href="mailto:daniel@radray.us?Subject=Re:%20AI%20boxing"><em>daniel@radray.us</em></a>)<br>
<strong>Date:</strong> Wed Jul 20 2005 - 23:22:59 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11660.html">Ben Goertzel: "RE: AI boxing"</a>
<li><strong>Previous message:</strong> <a href="11658.html">Tennessee Leeuwenburg: "Re: Fighting UFAI"</a>
<li><strong>In reply to:</strong> <a href="11651.html">Ben Goertzel: "RE: AI boxing"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11660.html">Ben Goertzel: "RE: AI boxing"</a>
<li><strong>Reply:</strong> <a href="11660.html">Ben Goertzel: "RE: AI boxing"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11659">[ date ]</a>
<a href="index.html#11659">[ thread ]</a>
<a href="subject.html#11659">[ subject ]</a>
<a href="author.html#11659">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Thu, 21 Jul 2005 00:22:54 -0400
<br>
&quot;Ben Goertzel&quot; &lt;<a href="mailto:ben@goertzel.org?Subject=Re:%20AI%20boxing">ben@goertzel.org</a>&gt; wrote:
<br>
<p><em>&gt; How about the argument that every supposedly final and correct theory of
</em><br>
<em>&gt; physics we humans have come up with, has turned out to be drastically
</em><br>
<em>&gt; wrong....
</em><br>
<p>This provides an infinitesimal degree of support to the claim that the real
<br>
final and correct theory would permit magic. 
<br>
<p><em>&gt; We now know that not every classical-physics box is really a totally solid
</em><br>
<em>&gt; box due to quantum tunnelling -- something that pre-quantum-era physicists
</em><br>
<em>&gt; would have found basically unthinkable.
</em><br>
<p>I don't know what quantum tunnelling is, but I'll grant that there is a way in
<br>
which some classical box is not really solid. The questions is, is the way in
<br>
which this classical box is nonsolid a way which is reasonably exploitable, and
<br>
if so what is necessary for it to be reasonably exploitable.
<br>
<p>For example, we might say that the AI might be able to manipulate its hardware
<br>
in such a way as to create electromagnetic fields (or some such thing) and
<br>
&quot;break the box.&quot; Given the AI's degree of flexibility in the hardware, there is
<br>
some chance that it will succeed. If the chance is vanishingly small, we say
<br>
that this exploit in the box's solidity is not reasonably exploitable.
<br>
<p>So, I want to know why you believe there is a exploit which is reasonably
<br>
exploitable. 
<br>
<p><em>&gt; How can you assess the probability that a superhuman AI will develop a novel
</em><br>
<em>&gt; theory of unified physics (that no human would ever be smart enough to hit
</em><br>
<em>&gt; upon) and figure out how to teleport out of its box?
</em><br>
<p>I can't, but I submit that no one on this list has any basis to assess the
<br>
probability either. So if I claim that the probability is infinitesimal, then
<br>
your only basis for disagreement is pure paranoia, which I feel comfortable
<br>
dismissing.
<br>
<p><em>&gt; How do you know we're not like a bunch of dogs who have never seen or
</em><br>
<em>&gt; imagined machine guns, and are convinced there is no way in hell a single
</em><br>
<em>&gt; human is going to outfight 20 dogs... so they attack an armed man with
</em><br>
<em>&gt; absolute confidence...
</em><br>
<p>How do you know the analogy is relevant? Maybe an evil demon is tricking you
<br>
into believing that it is.
<br>
<p><em>&gt; The probability that superhuman AI, if supplied with knowledge of physics
</em><br>
<em>&gt; theory and data, would come up with radically superior physics theories is
</em><br>
<em>&gt; pretty high.  
</em><br>
<p>I have this sinking suspicion that it would need to be supplied with an
<br>
experimental apparatus as well.
<br>
<p><em>&gt; So it would seem we'd be wise not to teach our AI-in-the-box
</em><br>
<em>&gt; too much physics.  Let it read postmodern philosophy instead, then it'll
</em><br>
<em>&gt; just confuse itself eternally and will lose all DESIRE to get out of the box
</em><br>
<em>&gt; ... appreciating instead the profound existential beauty of being boxed-in
</em><br>
<p>Similarly, for this proposal, I suspect that after a short while processing, 
<br>
say, Derrida, it would print out something like &quot;Error 37: conclusion does not
<br>
follow from premises (begs question?)&quot;
<br>
<p>Daniel
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11660.html">Ben Goertzel: "RE: AI boxing"</a>
<li><strong>Previous message:</strong> <a href="11658.html">Tennessee Leeuwenburg: "Re: Fighting UFAI"</a>
<li><strong>In reply to:</strong> <a href="11651.html">Ben Goertzel: "RE: AI boxing"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11660.html">Ben Goertzel: "RE: AI boxing"</a>
<li><strong>Reply:</strong> <a href="11660.html">Ben Goertzel: "RE: AI boxing"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11659">[ date ]</a>
<a href="index.html#11659">[ thread ]</a>
<a href="subject.html#11659">[ subject ]</a>
<a href="author.html#11659">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:51 MDT
</em></small></p>
</body>
</html>
