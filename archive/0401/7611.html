<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: An essay I just wrote on the Singularity.</title>
<meta name="Author" content="Michael Anissimov (altima@yifan.net)">
<meta name="Subject" content="Re: An essay I just wrote on the Singularity.">
<meta name="Date" content="2004-01-04">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: An essay I just wrote on the Singularity.</h1>
<!-- received="Sun Jan  4 19:58:59 2004" -->
<!-- isoreceived="20040105025859" -->
<!-- sent="Sun, 04 Jan 2004 18:36:43 -0800" -->
<!-- isosent="20040105023643" -->
<!-- name="Michael Anissimov" -->
<!-- email="altima@yifan.net" -->
<!-- subject="Re: An essay I just wrote on the Singularity." -->
<!-- id="3FF8CDBB.1070003@yifan.net" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20040102013532.78967deb.samantha@objectent.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Anissimov (<a href="mailto:altima@yifan.net?Subject=Re:%20An%20essay%20I%20just%20wrote%20on%20the%20Singularity."><em>altima@yifan.net</em></a>)<br>
<strong>Date:</strong> Sun Jan 04 2004 - 19:36:43 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7612.html">J. Andrew Rogers: "Re: An essay I just wrote on the Singularity."</a>
<li><strong>Previous message:</strong> <a href="7610.html">Lawrence Foard: "Re: An essay I just wrote on the Singularity."</a>
<li><strong>In reply to:</strong> <a href="7461.html">Samantha Atkins: "Re: An essay I just wrote on the Singularity."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7429.html">Giu1i0 Pri5c0: "RE: An essay I just wrote on the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7611">[ date ]</a>
<a href="index.html#7611">[ thread ]</a>
<a href="subject.html#7611">[ subject ]</a>
<a href="author.html#7611">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Samantha Atkins wrote:
<br>
<p><em>&gt;On Wed, 31 Dec 2003 09:40:08 -0800
</em><br>
<em>&gt;Michael Anissimov &lt;<a href="mailto:altima@yifan.net?Subject=Re:%20An%20essay%20I%20just%20wrote%20on%20the%20Singularity.">altima@yifan.net</a>&gt; wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt;  
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt;Robin, this is an interesting and entertaining essay!  Congratulations 
</em><br>
<em>&gt;&gt;on getting the motivation to write down some of your ideas and reasoning 
</em><br>
<em>&gt;&gt;regarding the world-shaking issue of how humanity ought to approach the 
</em><br>
<em>&gt;&gt;Singularity.  I disagree with the way you present/argue some things 
</em><br>
<em>&gt;&gt;though, so here I go with all the comments:
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;1.  Why do you call Singularitarianism your &quot;new religion&quot;?  I know it's 
</em><br>
<em>&gt;&gt;basically all in jest, but thousands of people have already 
</em><br>
<em>&gt;&gt;misinterpreted the Singularity as a result of the &quot;Singularity = 
</em><br>
<em>&gt;&gt;Rapture&quot; meme, and I don't think they need any more encouragement.  I 
</em><br>
<em>&gt;&gt;would personally prefer that Singularitarians have the reputation of 
</em><br>
<em>&gt;&gt;being extremely atheistic and humanistic. 
</em><br>
<em>&gt;&gt;    
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;I don't see what believe in God or gods has to do or not do with it actually.  Saying it is &quot;extremely atheistic&quot; is as out of place as considering it to be a religion or an aspect of one.  The term &quot;humanistic&quot; implies even less to a massively greater than human intelligence in part making possible the transcending of much of what we now consider as characteristic of &quot;human&quot;.
</em><br>
<em>&gt;
</em><br>
Extreme atheism opens the doorway for an intense personal interest in 
<br>
science and rationality.  Although calling Singularitarianism 
<br>
specifically &quot;extremely atheistic&quot; does seem somewhat out of place, it 
<br>
seems worth mentioning those who readily link together the Singularity 
<br>
with the Rapture, due to an extremely superficial similarity and having 
<br>
more past experience and easy-access knowledge of the latter.  Those who 
<br>
take Singularitarianism on faith, should, as Perry suggests, drop it 
<br>
immediately.  Why pursue something on faith when you can have a concrete 
<br>
positive impact by doing something you view as credible?
<br>
<p><em>&gt;&gt;2.  Like Tommy McCabe, I too have a problem with the &quot;FAI means being 
</em><br>
<em>&gt;&gt;nice to humans&quot; line.  This gives a lot of people the mistaken 
</em><br>
<em>&gt;&gt;impression that FAI is going to be anthropocentric, unfortunately.
</em><br>
<em>&gt;&gt;    
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;Well, the first level goal is that it be &quot;nice&quot; to humans lest we commit a very intricate form of species suicide in giving birth to it.  Friendliness is not limited to humans necessarily just because it includes &quot;being nice to humans&quot;. 
</em><br>
<em>&gt;  
</em><br>
<em>&gt;
</em><br>
Right, but my past experience suggests that this is a common mistake, or 
<br>
that we're hardwiring &quot;be nice to humanity&quot; as an Asimov Law.  Just a 
<br>
precaution I take and suggest for others to take as well.
<br>
<p><em>&gt;&gt;Anyway, congratulations again on writing something.  Politics is indeed 
</em><br>
<em>&gt;&gt;largely irrelevant.  This becomes clear around high SL2, as a matter of 
</em><br>
<em>&gt;&gt;fact.  At the very least, politics is something we cannot influence 
</em><br>
<em>&gt;&gt;unless we pursue high-leverage goals, like devoting our lives to 
</em><br>
<em>&gt;&gt;politics, or, far better yet, building a Friendly AI.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;    
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;If the political events between now and takeoff result in an extremely oppressive government that shuts down the research and much or communcation or if it devolves into universal war, terror and teror of terror, then politics is very much relevant.   A certain amount of freedom and stability is required.  Also, spinning what technology can do to solve current crises given the vision and will may well bring us more stability and more funding as well.  
</em><br>
<em>&gt;  
</em><br>
<em>&gt;
</em><br>
This is completely true, no question about it.  But I can only influence 
<br>
the path of the government if I devote my life to it; but there isn't 
<br>
enough time, and I don't plan to, so I view government as a system I am 
<br>
constrained to work within (like the laws of physics and human 
<br>
psychology) rather than something I can actually influence.  For various 
<br>
reasons, it seems far more likely that the average person can influence 
<br>
the outcome of &quot;FAI vs. UFAI&quot; more than &quot;oppressive vs. democratic&quot; 
<br>
governments.  Knowledge regarding the former is much more scarce than 
<br>
the latter, for one, making it more valuable.
<br>
<p><em>&gt;Some days it feels as if FAI can be a rationalization for not wanting to deal with the messy human stuff.  It is the ultimate geek out.  We create the seed of that which is massively smarter than humanity and massively less fucked up and it fixes everything to the degree it can be fixed thus saving us the trouble.   Sweet! But some days it doesn't smell quite right.  
</em><br>
<em>&gt;  
</em><br>
<em>&gt;
</em><br>
I'm going to be dealing with the messy human stuff until the day I die 
<br>
or the Singularity comes to pass, whether I like it or not.  No big 
<br>
deal. I came to my current conclusions due to the reasons in 
<br>
<a href="http://www.intelligence.org/CFAI/policy.html">http://www.intelligence.org/CFAI/policy.html</a>, along with my own thinking - 
<br>
just pure, boring, rational-as-possible cost-benefit analysis of what 
<br>
seems worth doing in this place that I happened to be born into; 
<br>
maximizing personal choice for everyone and such.  Just as pragmatic as 
<br>
military strategy.  Nothing really geeky about it, except the 
<br>
strategizing is about recursively self-improving AIs rather than tanks 
<br>
and bombs, and the prize is our planet's future rather than some honor 
<br>
and a medal.  Perhaps you should read or reread &quot;Ethical Issues in 
<br>
Advanced Artificial Intelligence&quot; or &quot;Nanotechnology and International 
<br>
Security&quot; if you want to read up on what some other &quot;geeks&quot; have to say 
<br>
about these things.
<br>
<p>Happy 2004,
<br>
Michael
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7612.html">J. Andrew Rogers: "Re: An essay I just wrote on the Singularity."</a>
<li><strong>Previous message:</strong> <a href="7610.html">Lawrence Foard: "Re: An essay I just wrote on the Singularity."</a>
<li><strong>In reply to:</strong> <a href="7461.html">Samantha Atkins: "Re: An essay I just wrote on the Singularity."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7429.html">Giu1i0 Pri5c0: "RE: An essay I just wrote on the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7611">[ date ]</a>
<a href="index.html#7611">[ thread ]</a>
<a href="subject.html#7611">[ subject ]</a>
<a href="author.html#7611">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:43 MDT
</em></small></p>
</body>
</html>
