<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Darwinian dynamics unlikely to apply to superintelligence</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Darwinian dynamics unlikely to apply to superintelligence">
<meta name="Date" content="2004-01-04">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Darwinian dynamics unlikely to apply to superintelligence</h1>
<!-- received="Sun Jan  4 21:40:39 2004" -->
<!-- isoreceived="20040105044039" -->
<!-- sent="Sun, 04 Jan 2004 23:40:26 -0500" -->
<!-- isosent="20040105044026" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Darwinian dynamics unlikely to apply to superintelligence" -->
<!-- id="3FF8EABA.8050706@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="874qvbtf7u.fsf@snark.piermont.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Darwinian%20dynamics%20unlikely%20to%20apply%20to%20superintelligence"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Sun Jan 04 2004 - 21:40:26 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7627.html">Perry E. Metzger: "Re: An essay I just wrote on the Singularity."</a>
<li><strong>Previous message:</strong> <a href="7625.html">Perry E. Metzger: "Re: Darwinian dynamics unlikely to apply to superintelligence"</a>
<li><strong>In reply to:</strong> <a href="7588.html">Perry E. Metzger: "Re: Darwinian dynamics unlikely to apply to superintelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7548.html">Tommy McCabe: "Re: An essay I just wrote on the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7626">[ date ]</a>
<a href="index.html#7626">[ thread ]</a>
<a href="subject.html#7626">[ subject ]</a>
<a href="author.html#7626">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Perry E. Metzger wrote:
<br>
<em> &gt;
</em><br>
<em> &gt;&gt;THEN you have a noticeable amount of selection pressure
</em><br>
<em> &gt;
</em><br>
<em> &gt; Before we continue, might I ask you why you have such an astounding
</em><br>
<em> &gt; vitriolic reaction to the idea that evolution might continue?
</em><br>
<p>For much the same reason that Drexler has such a vitriolic reaction to the 
<br>
idea that nanotechnology requires Smalley fingers; I've been arguing it 
<br>
too damn long.
<br>
<p>People all and for their individual stupid reasons really really want to 
<br>
believe that AIs are just like humans in some facet or another.  Sometimes 
<br>
it's a technophobe who wants to argue that all generic optimization 
<br>
processes possess the emotion of resentment and will make self-justifying 
<br>
speeches to human captives, just like in &quot;The Matrix&quot;.  Sometimes it's a 
<br>
technophile who wants to argue that all AIs are necessarily helpful. 
<br>
Sometimes the motive doesn't have anything to do with it; it's just a 
<br>
question of people making up interesting-sounding tall tales about the 
<br>
future, predicting the actions of generic intelligences using their human 
<br>
empathy brainware to imagine what they would do &quot;in those shoes&quot;. 
<br>
Anthropomorphism.  Just about every damn error I have ever seen made about 
<br>
AI amounts to anthropomorphism.  Even the people who think they're 
<br>
inventing aliens just invent emotionally repressed humans, or humans who 
<br>
are more strictly selfish, and so on.  Sometimes it's because people want 
<br>
to believe, and sometimes it's because people don't have the technical 
<br>
knowledge to see the strict assumptions underlying their own minds, 
<br>
choices, all the systemic behaviors of the world as we know it.
<br>
<p>And when it comes time to challenge that anthropomorphism, it usually 
<br>
consists of pointing out how the human case of something is a particular 
<br>
instance of a particular kind of natural selection at work.
<br>
<p>And then the person says, &quot;Oh, but AIs will be designed by natural selection&quot;.
<br>
<p>Now natural selection is a deep deep deep topic.  This is not widely 
<br>
appreciated.  Scientifically literate people spend too much time arguing 
<br>
with creationists about whether evolution happens at all; a very simple 
<br>
argument which can be resolved through very easy, intuitive evidence.  But 
<br>
there is more depth to evolutionary theory than this, far more depth, and 
<br>
yes math as well, and predictions exceedingly precise, beautifully and 
<br>
sharply matched by observation.  It is not just that humans evolved as 
<br>
proven by the fossil evidence, but that when I look at the human being, I 
<br>
see a pattern formed and created, in every shape and element constrained, 
<br>
not by some generic vague force called &quot;evolution&quot;, but by evolution under 
<br>
particular circumstances, natural selection with particular dynamics, so 
<br>
that if a wise alien came across a human being floating alone in space, 
<br>
that human would be known as an evolved thing, and a most particular 
<br>
evolved thing.
<br>
<p>Human beings are one particular case of natural selection.  If we ran the 
<br>
entire process over again, keeping all the dynamics exactly the same, 
<br>
there's no guarantee things would come out the same.  Whatever happened 
<br>
would be tightly constrained to bear the signature of our particular 
<br>
dynamics, but that itself is a large area of configuration space... not 
<br>
all the variables are constrained.  You might think of a really huge 
<br>
volume of possibilities, and natural selection constraining the answer to 
<br>
be within one very unusual and memorable and distinctly identifiable 
<br>
bubble, but there still being room for variation inside the bubble.
<br>
<p>If we changed the dynamics things would definitely not come out the same. 
<br>
&nbsp;&nbsp;They couldn't.  There'd be room inside the constrained bubble, but it'd 
<br>
be a different bubble.
<br>
<p>There is not one AI scenario I have ever seen proposed that would not 
<br>
DEEPLY change practically ALL of the dynamics from the human ancestral 
<br>
environment.
<br>
<p>People don't see the dependencies.
<br>
<p>But then they still want to infer all the warm and fuzzy, or occasionally, 
<br>
evil and cunning, but at any rate blatantly anthropomorphic, properties 
<br>
that started the argument in the first place.
<br>
<p>So they try to deductively infer evolution from anything that can be 
<br>
described as reproduction, then infer absurdly exact similarities to 
<br>
humans from the supposed presence of &quot;evolution&quot;, for a grand double fallacy.
<br>
<p>Now, Belldandy knows that these are just my innocent fellow humans, trying 
<br>
to get through the day.  Belldandy knows I've committed much worse 
<br>
theoretical errors in the past, if formulating an intention that would 
<br>
have wiped out the human species if carried through is considered &quot;bad&quot;, 
<br>
so they're ahead of me on points no matter how you count them.
<br>
<p>But I'm still annoyed, because I'm not Belldandy, and I've been arguing 
<br>
this too long.
<br>
<p>Now maybe you, Perry, do not commit these particular fallacies - though, 
<br>
down below, you commit one of the classics.  And perhaps there are people 
<br>
who use the word &quot;Friendly AI&quot; correctly and rigorously, who do not happen 
<br>
to be posting on that topic at the present time, but if you see it misused 
<br>
enough, you will eventually come to dislike the concept itself, yes?  The 
<br>
strength of an idea is the strength of its strongest proponents; it may be 
<br>
fun to go around attacking weaker proponents, or strategically wise in 
<br>
politics, but it is not part of the process of social rationality.
<br>
<p>And perhaps one day someone will come along who makes a rigorous argument 
<br>
for natural selection applying to SI scenarios, and who derives from this 
<br>
an argument about the properties of most SIs.  I am not licensed to rule 
<br>
this out from hearing it argued incorrectly so many times.  The world's 
<br>
greatest fool may say the sun is shining; that doesn't make it dark outside.
<br>
<p>But that day has not yet come.
<br>
<p><em>&gt;&gt;No, so long as you have limited resources
</em><br>
<em>&gt;&gt;AND frequent death to free up resources
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Nope. Many species of single celled organisms don't have appreciably
</em><br>
<em>&gt; limited life spans, and yet they still evolve. Besides, though, one
</em><br>
<em>&gt; assumes that death will continue to be frequent in the future,
</em><br>
<em>&gt; especially when less prepared entities meet more prepared ones.
</em><br>
<p>Perry, something has to die, frequently, to free up resources, or there is 
<br>
no selection pressure.  It doesn't mean there's an upper limit on 
<br>
individual lifespans.  It means that there's frequent death or there is no 
<br>
appreciable selection pressure.  It is required by the math, so you can be 
<br>
sure that if those single celled organisms are evolving, then they, or 
<br>
something that they eat, is dying.  Frequently.
<br>
<p><em>&gt;&gt;AND multiple competing phenotypes with heritable characteristics
</em><br>
<em>&gt; 
</em><br>
<em>&gt; As soon as you get a change of any sort, you have multiple classes of
</em><br>
<em>&gt; entities competing.
</em><br>
<p>The heritable characteristics must be preserved with fidelity from 
<br>
generation to generation; any loss of fidelity is factored into the math 
<br>
and reduces the selection pressure, perhaps sharply.  For selection 
<br>
pressure to add up over 20 generations there must be fidelity of 
<br>
inheritance over 20 generations; to add up over 1000 generations there 
<br>
must be fidelity over 1000 generations.
<br>
<p><em>&gt;&gt;AND substantial variation in those characteristics
</em><br>
<em>&gt; 
</em><br>
<em>&gt; That will arise with time.
</em><br>
<p>Pardon me, but this appears to be a statement of pure faith, or of blind 
<br>
generalization from DNA-based organisms.  I have already spoken about the 
<br>
advantage to generic utilitarian optimizing processes to pay the cost (not 
<br>
that it even looks all that costly) to exactly preserve their utility 
<br>
function, both locally and in offspring.
<br>
<p><em>&gt; You only need a little variation at the start
</em><br>
<p>What?  This is untrue even of DNA-based organisms, which require a 
<br>
continuing source of variation.
<br>
<p><em>&gt; -- and even the variation of experience histories of multiple
</em><br>
<em>&gt; entities can be sufficient to provide for advantages
</em><br>
<p>How much of an advantage?  A substantial variation in reproductive fitness?
<br>
<p><em>&gt;&gt;AND substantial variation in reproductive fitness
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It doesn't need to be substantial. Even slight advantages lead to big
</em><br>
<em>&gt; long term changes. Call it the &quot;compound interest effect&quot;.
</em><br>
<p>Slight advantages can be fixed in a population pool *if* they are 
<br>
persistent and *if* they are iterated over hundreds or thousands of 
<br>
generations.  The slighter the advantage, the more iterated generations 
<br>
you need.
<br>
<p><em>&gt;&gt;AND correlation between heritable characteristics and fitness
</em><br>
<em>&gt; 
</em><br>
<em>&gt; In the DNA world, that's crucial. In the pseudo-lamarkian world of the
</em><br>
<em>&gt; future, it is unlikely to be nearly as obvious an issue. Presumably,
</em><br>
<em>&gt; entities will construct descendents using design rather than blind
</em><br>
<em>&gt; mutation of a blueprint.
</em><br>
<p>And at this point you have tossed away your entire argument without 
<br>
realizing it, like a theist remarking, &quot;Well, at this point you have to 
<br>
take the argument on faith; now, the next point is that...&quot;
<br>
<p>The patterns we have learned from natural selection as it exists in the 
<br>
world today are the results of particular dynamics, like the distribution 
<br>
of heat in an iron plate is the result of particular physics equations, 
<br>
and if you toss away the dynamics the result does not hang around.
<br>
<p>What you have just said is:
<br>
<p>&quot;The dynamics of the future are so absolutely different from those of 
<br>
natural selection that no generalization of any kind can be made from 
<br>
natural selection as we know it, unless the arguments are re-derived from 
<br>
scratch.&quot;
<br>
<p><em>&gt;&gt;AND this is iterated for many generations
</em><br>
<em>&gt; 
</em><br>
<em>&gt; What are &quot;many generations&quot;? People have been able to artificially
</em><br>
<em>&gt; induce astounding changes in animals in a half dozen to dozen
</em><br>
<em>&gt; generations. See, for example, the Russian experiments on
</em><br>
<em>&gt; domesticating wild animals during the middle of the last century.
</em><br>
<p>If you use much sharper selection pressures - artificially inducing huge 
<br>
variations in reproductive success - then you can get by with fewer 
<br>
generations.  And also generations are not always integers; they are 
<br>
measured in the percentage of resources freed up and retaken per unit 
<br>
time.  So, like I said before, you require a large global death rate, 
<br>
inherent limitations on individual lifespan or not.
<br>
<p><em>&gt;&gt;Natural selection feeds on variation and, in feeding on it, uses it
</em><br>
<em>&gt;&gt;up.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &quot;Feeding on it&quot;? &quot;Uses it up&quot;? I don't see that in the real world. I
</em><br>
<em>&gt; see billions of species.
</em><br>
<p>One, this is a standard proverb in evolutionary biology, though I have 
<br>
paraphrased it.
<br>
<p>Two, mutation, copying errors, strand-swapping and sexual recombination 
<br>
are continually producing *new* variation in the real world.  The point is 
<br>
that once a particular lucky allele becomes fixed in the population as the 
<br>
result of selection, it doesn't vary anymore.
<br>
<p><em>&gt;&gt;Intelligence is a vastly faster optimization process -
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Evolution doesn't require genetic material and literal inheritance to
</em><br>
<em>&gt; work. Companies evolve, societies evolve, investment strategies
</em><br>
<em>&gt; evolve.
</em><br>
<p>Again, you've just tossed away your entire argument without realizing it. 
<br>
&nbsp;&nbsp;It's like saying, &quot;Well, planets move in ellipses because of physics... 
<br>
and there are all kinds of physics, quantum physics, relativistic 
<br>
physics... but as long as things move because of physics they will go in 
<br>
ellipses.&quot;
<br>
<p><em>&gt; Intelligence will doubtless guide much of the design change of
</em><br>
<em>&gt; the future -- but it will also doubtless be tempered with the
</em><br>
<em>&gt; selection pressure that competition and limited resources bring. I see
</em><br>
<em>&gt; no reason to expect that in this regard the future will be any
</em><br>
<em>&gt; different from the present.
</em><br>
<p>It looks to me like intelligence can easily chew up all the variation 
<br>
available to evolution before evolution gets a chance to feed on it.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7627.html">Perry E. Metzger: "Re: An essay I just wrote on the Singularity."</a>
<li><strong>Previous message:</strong> <a href="7625.html">Perry E. Metzger: "Re: Darwinian dynamics unlikely to apply to superintelligence"</a>
<li><strong>In reply to:</strong> <a href="7588.html">Perry E. Metzger: "Re: Darwinian dynamics unlikely to apply to superintelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7548.html">Tommy McCabe: "Re: An essay I just wrote on the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7626">[ date ]</a>
<a href="index.html#7626">[ thread ]</a>
<a href="subject.html#7626">[ subject ]</a>
<a href="author.html#7626">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:43 MDT
</em></small></p>
</body>
</html>
