<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Friendliness and blank-slate goal bootstrap</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Friendliness and blank-slate goal bootstrap">
<meta name="Date" content="2004-01-11">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Friendliness and blank-slate goal bootstrap</h1>
<!-- received="Sun Jan 11 07:25:31 2004" -->
<!-- isoreceived="20040111142531" -->
<!-- sent="Sun, 11 Jan 2004 09:25:27 -0500" -->
<!-- isosent="20040111142527" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Friendliness and blank-slate goal bootstrap" -->
<!-- id="BAEAIIMDCMDAEKHBFGFKOEDGCJAA.ben@goertzel.org" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="20040110235902.76d07735.samantha@objectent.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Friendliness%20and%20blank-slate%20goal%20bootstrap"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sun Jan 11 2004 - 07:25:27 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7741.html">Paul Fidika: "Re: What exactly is &quot;panpsychism&quot;?"</a>
<li><strong>Previous message:</strong> <a href="7739.html">Metaqualia: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>In reply to:</strong> <a href="7735.html">Samantha Atkins: "Re: Friendliness and blank-slate goal bootstrap"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7742.html">Philip Sutton: "RE: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7742.html">Philip Sutton: "RE: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7745.html">Metaqualia: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7751.html">Samantha Atkins: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7767.html">John Stick: "Re: Friendliness and blank-slate goal bootstrap"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7740">[ date ]</a>
<a href="index.html#7740">[ thread ]</a>
<a href="subject.html#7740">[ subject ]</a>
<a href="author.html#7740">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Good morning fellow SL4-oids...
<br>
<p>I think Metaqualia is raising an important perspective, and I find the
<br>
reactions to his posts a bit severe overall.
<br>
<p>We need to guard against this list becoming a philosophical orthodoxy!
<br>
<p>On this list, it tends to be assumed that &quot;Friendliness to humans&quot; is an
<br>
immensely important value to be transmitted to the superintelligent AI's we
<br>
create...
<br>
<p>Metaqualia is questioning this &quot;orthodoxy&quot; -- which should be permitted,
<br>
right? -- and proposing that, perhaps, we humans aren't so all-important
<br>
after all ... that, perhaps, we should seek to inculcate a more *abstract*
<br>
form of morality in our AGI's, and then let them, with their deep abstract
<br>
morality and powerful intelligence, make their own judgment about the
<br>
particular configurations of matter known as &quot;humans&quot;...
<br>
<p>I note that, in my own AGI work, I intend to basically follow the SL4
<br>
orthodoxy and inculcate &quot;Friendliness to humans and other sentients&quot; as a
<br>
core value in my own AGI systems (once they get advanced enough for this to
<br>
be meaningful).
<br>
<p>However, I also intend to remain open to the questioning of all values, even
<br>
those that seem extremely basic and solid to me -- even the SL4
<br>
orthodoxy....
<br>
<p>One problem I have with Metaqualia's perspective is the slipperiness of this
<br>
hypothesized abstract morality.  Friendliness to humans is slippery enough.
<br>
His proposed abstract morality ---- about the balance between positive and
<br>
negative qualia ---- is orders of magnitude slipperier, since it relies on
<br>
&quot;qualia&quot; which we don't really know how to quantify ... nor do we know if
<br>
qualia can be reliably categorized as positive vs. negative, etc.
<br>
<p>Even if IN PRINCIPLE it makes sense to create AGI's with the right abstract
<br>
morality rather than a concrete Friendly-to-humans-and-sentients morality,
<br>
this seems in practice very hard because of the difficulty of formalizing
<br>
and &quot;pinning down&quot; abstract morality....
<br>
<p>I also note that the gap between Metaqualia and the SL4 orthodoxy may not be
<br>
so big as it appears.
<br>
<p>If you replace &quot;Friendly to humans&quot; with &quot;Friendly to humans and sentients&quot;
<br>
in the SL4 orthodox goal system, then you have something a bit closer to
<br>
Metaqualia's &quot;increase positive qualia&quot; -- IF you introduce the hypothesis
<br>
that sentients have more qualia or more intense qualia than anything else.
<br>
Right?
<br>
<p>And when you try to quantify what &quot;Friendly to X&quot; means, you have two
<br>
choices
<br>
<p>-- encouraging positive qualia on the part of X
<br>
-- obeying what X's volition requests, insofar as possible
<br>
<p>But these need to be balanced in any case, because human volition is famous
<br>
for requesting more than is possible.  In choosing which of the
<br>
mutually-contradictory requests of human volition to fulfill, our
<br>
hypothetical superhuman AI must make judgments based on some criterion other
<br>
than volition, e.g. based on which of a human's contradictory volitions will
<br>
lead to more positive qualia in that human or in the cosmos...
<br>
<p>THIS, to me, is a subtle point of morality ---- balancing the desire to
<br>
promote positive qualia with the desire to allow sentients to control their
<br>
destinies.  I face this point of morality all the time as a parent, and a
<br>
superhuman AGI will face it vastly more so....
<br>
<p>Note that I have spoken about &quot;abstract morality&quot; not &quot;objective morality.&quot;
<br>
About &quot;objective morality&quot; -- I guess there could emerge something in the
<br>
future that would seem to superintelligent AI's to be an &quot;objective
<br>
morality.&quot;  But something that appears to rational, skeptical *humans* as an
<br>
objective morality -- well, that seems very, very doubtful to ever emerge.
<br>
The very concept of &quot;morality&quot; appears to contain subjectivity within
<br>
itself -- when analyzed as a part of human psychology....  Even if a
<br>
superintelligent AI discovers an &quot;objective morality&quot; (in its view), we
<br>
skeptical rationalist humans won't be able to fully appreciate why it thinks
<br>
it's so &quot;objective.&quot;  We have a certain element of irrepressible
<br>
anti-absolutist skepticism wired into our hearts, it's part of what makes us
<br>
&quot;human.&quot;  Just ask the &quot;Underground  Man&quot; ;-)
<br>
<p>-- Ben G
<br>
<p><p><p><p><p><p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Friendliness%20and%20blank-slate%20goal%20bootstrap">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Friendliness%20and%20blank-slate%20goal%20bootstrap">owner-sl4@sl4.org</a>]On Behalf Of Samantha
</em><br>
<em>&gt; Atkins
</em><br>
<em>&gt; Sent: Sunday, January 11, 2004 2:59 AM
</em><br>
<em>&gt; To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Friendliness%20and%20blank-slate%20goal%20bootstrap">sl4@sl4.org</a>
</em><br>
<em>&gt; Subject: Re: Friendliness and blank-slate goal bootstrap
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; On Sat, 10 Jan 2004 16:06:59 +0900
</em><br>
<em>&gt; &quot;Metaqualia&quot; &lt;<a href="mailto:metaqualia@mynichi.com?Subject=RE:%20Friendliness%20and%20blank-slate%20goal%20bootstrap">metaqualia@mynichi.com</a>&gt; wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; &gt; Be very careful here! The easiest way to reduce undesirable
</em><br>
<em>&gt; qualia is to
</em><br>
<em>&gt; &gt; &gt; kill off everyone who has the potential for experiencing them.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I want someone who is superintelligent, and that takes my basic
</em><br>
<em>&gt; premises as
</em><br>
<em>&gt; &gt; temporary truths, and who recursively improves himself, and who
</em><br>
<em>&gt; understands
</em><br>
<em>&gt; &gt; qualia in and out, to decide whether everyone should be killed. If you
</em><br>
<em>&gt; &gt; consider this eventuality (global extermination) and rule it
</em><br>
<em>&gt; out based on
</em><br>
<em>&gt; &gt; your current beliefs and intelligence, you are not being modest
</em><br>
<em>&gt; in front of
</em><br>
<em>&gt; &gt; massive superintelligence.
</em><br>
<em>&gt;
</em><br>
<em>&gt; No, it is not &quot;modest&quot;.  However, as an evolved sentient being, I
</em><br>
<em>&gt; have an overwhelming supergoal of survival and the survival of my
</em><br>
<em>&gt; kind.  So I will asked to be excused from lining up for the no
</em><br>
<em>&gt; doubt &quot;humane&quot; extermination of humanity if the ever so
</em><br>
<em>&gt; inscrutable SAI decides it must be so.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;I do not rule out that killing everyone off could
</em><br>
<em>&gt; &gt; be a good idea.
</em><br>
<em>&gt;
</em><br>
<em>&gt; In that case I will not help you with any project you may
</em><br>
<em>&gt; undertake.  By this statement you are a potential major enemy to
</em><br>
<em>&gt; much I hold dear.   Please take your high-falutin intellectual
</em><br>
<em>&gt; stance down to the level of real people if you don't mind.  Such
</em><br>
<em>&gt; things profit from periodic grounding.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; Death is morally neutral. Only suffering is evil.
</em><br>
<em>&gt;
</em><br>
<em>&gt; So you would run humane death camps?  I am sooo relieved!
</em><br>
<em>&gt;
</em><br>
<em>&gt; &lt;snip&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; I take the moral law I have chosen to its logical extreme, and
</em><br>
<em>&gt; won't take it
</em><br>
<em>&gt; &gt; back when it starts feeling uncomfortable. If the universe is
</em><br>
<em>&gt; evil overall
</em><br>
<em>&gt; &gt; and unfixable, it must be destroyed together with everything it
</em><br>
<em>&gt; contains.
</em><br>
<em>&gt; &gt; I'd need very good proof of this obviously but i do not discount the
</em><br>
<em>&gt; &gt; possibility.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; If reality is &quot;evil&quot; (whatever *you* take that to mean) and
</em><br>
<em>&gt; &quot;unfixable&quot; then you will work to detroy it?  Exactly how the
</em><br>
<em>&gt; heck do you think you, a part of reality, can go about destroying
</em><br>
<em>&gt; reality itself??
</em><br>
<em>&gt;
</em><br>
<em>&gt; - s
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7741.html">Paul Fidika: "Re: What exactly is &quot;panpsychism&quot;?"</a>
<li><strong>Previous message:</strong> <a href="7739.html">Metaqualia: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>In reply to:</strong> <a href="7735.html">Samantha Atkins: "Re: Friendliness and blank-slate goal bootstrap"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7742.html">Philip Sutton: "RE: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7742.html">Philip Sutton: "RE: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7745.html">Metaqualia: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7751.html">Samantha Atkins: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7767.html">John Stick: "Re: Friendliness and blank-slate goal bootstrap"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7740">[ date ]</a>
<a href="index.html#7740">[ thread ]</a>
<a href="subject.html#7740">[ subject ]</a>
<a href="author.html#7740">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:45 MDT
</em></small></p>
</body>
</html>
