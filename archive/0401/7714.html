<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-2022-jp">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Friendliness and blank-slate goal bootstrap</title>
<meta name="Author" content="Metaqualia (metaqualia@mynichi.com)">
<meta name="Subject" content="Re: Friendliness and blank-slate goal bootstrap">
<meta name="Date" content="2004-01-10">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Friendliness and blank-slate goal bootstrap</h1>
<!-- received="Sat Jan 10 00:08:31 2004" -->
<!-- isoreceived="20040110070831" -->
<!-- sent="Sat, 10 Jan 2004 16:06:59 +0900" -->
<!-- isosent="20040110070659" -->
<!-- name="Metaqualia" -->
<!-- email="metaqualia@mynichi.com" -->
<!-- subject="Re: Friendliness and blank-slate goal bootstrap" -->
<!-- id="06ef01c3d748$580ab620$1101a8c0@curziolaptop" -->
<!-- charset="iso-2022-jp" -->
<!-- inreplyto="3FFF69BD.608@earthlink.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Metaqualia (<a href="mailto:metaqualia@mynichi.com?Subject=Re:%20Friendliness%20and%20blank-slate%20goal%20bootstrap"><em>metaqualia@mynichi.com</em></a>)<br>
<strong>Date:</strong> Sat Jan 10 2004 - 00:06:59 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7715.html">Metaqualia: "Re: What exactly is &quot;panpsychism&quot;?"</a>
<li><strong>Previous message:</strong> <a href="7713.html">Samantha Atkins: "Re: Recursive self-improvement curves"</a>
<li><strong>In reply to:</strong> <a href="7710.html">Charles Hixson: "Re: Friendliness and blank-slate goal bootstrap"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7716.html">Rafal Smigrodzki: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7716.html">Rafal Smigrodzki: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7725.html">Mark Waser: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7735.html">Samantha Atkins: "Re: Friendliness and blank-slate goal bootstrap"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7714">[ date ]</a>
<a href="index.html#7714">[ thread ]</a>
<a href="subject.html#7714">[ subject ]</a>
<a href="author.html#7714">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; Be very careful here! The easiest way to reduce undesirable qualia is to
</em><br>
<em>&gt; kill off everyone who has the potential for experiencing them.
</em><br>
<p>I want someone who is superintelligent, and that takes my basic premises as
<br>
temporary truths, and who recursively improves himself, and who understands
<br>
qualia in and out, to decide whether everyone should be killed. If you
<br>
consider this eventuality (global extermination) and rule it out based on
<br>
your current beliefs and intelligence, you are not being modest in front of
<br>
massive superintelligence. I do not rule out that killing everyone off could
<br>
be a good idea. Death is morally neutral. Only suffering is evil. Of course
<br>
a transhuman ai could do better than that by keeping everyone alive and
<br>
happy, which will reduce negative qualia and also create huge positive ones,
<br>
so I do have good hopes that we won't be killed. What if the universe was
<br>
really an evil machine and there was no way of reversing this truth? What
<br>
if, in every process you care to imagine, all interpretations of the process
<br>
in which conscious observers were contained, were real to these observers
<br>
just like the physical world is real to us? What if there existed infinite
<br>
hells where ultrasentient ultrasensitive beings were kept enslaved without
<br>
the possibility to die? Is this not one universe that can be simulated and
<br>
by virtue of this interpreted out of any sufficiently complex process (or
<br>
simpler processes: read moravec's simulation/consciousness/existence)?
<br>
<p>I take the moral law I have chosen to its logical extreme, and won't take it
<br>
back when it starts feeling uncomfortable. If the universe is evil overall
<br>
and unfixable, it must be destroyed together with everything it contains.
<br>
I'd need very good proof of this obviously but i do not discount the
<br>
possibility.
<br>
<p><em>&gt; It seems to me that a person's method for determining the desireable
</em><br>
<em>&gt; morality is based partially on instincts, partially on training, and
</em><br>
<p>we are talking about different things, i have answered this previously.
<br>
<p><em>&gt; ... are you sure about that? Just how heavily do you want the AI to
</em><br>
<em>&gt; weigh it's self interest? Do you want it to be able to justify
</em><br>
<p>its self interest? at zero obviously, other than the fact that the universe
<br>
is likely to contain a lot more positive qualia than negative ones if the
<br>
moral transhuman AI stays alive, so in the end its own survival would be
<br>
more important than the survival of humans, if you consider the million
<br>
worlds with biologically evolved beings that may be out there and in need of
<br>
salvation. So at a certain point the best it could do morally to work toward
<br>
the goals we have agreed could be exactly exterminating humans.
<br>
<p><em>&gt; &gt;Remember, friendliness isn't Friendliness. The former would involve
</em><br>
something
<br>
<em>&gt; &gt;like making an AI friend, the latter is nothing like it. Where he says
</em><br>
<em>&gt; &gt;&quot;Friendliness should be the supergoal&quot; it means something more like
</em><br>
&quot;Whatever
<br>
<em>&gt; &gt;is really right should be the supergoal&quot;. Friendliness is an external
</em><br>
<p>Is Friendliness creating a machine that wouldn't do something we wouldn't
<br>
like? Or is Friendliness creating a machine that wouldn't do something we
<br>
wouldn't like if we were as intelligent and altruistic as it is?
<br>
<p><em>&gt; This is assuming that &quot;right&quot; has some absolute meaning, but this is
</em><br>
<em>&gt; only true in the context of a certain set of axioms (call them
</em><br>
<p>I am proposing qualia as universal parameters to which every sentient (at
<br>
least evolved ones) can relate. That was the whole purpose, so we don't get
<br>
into this &quot;relativity&quot; argument which seems to justify things that I am not
<br>
ready to accept because they just feel very wrong at a level of
<br>
introspection that is as close as it could be to reality and cannot be
<br>
further decomposed (negative qualia).
<br>
<p><p>mq
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7715.html">Metaqualia: "Re: What exactly is &quot;panpsychism&quot;?"</a>
<li><strong>Previous message:</strong> <a href="7713.html">Samantha Atkins: "Re: Recursive self-improvement curves"</a>
<li><strong>In reply to:</strong> <a href="7710.html">Charles Hixson: "Re: Friendliness and blank-slate goal bootstrap"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7716.html">Rafal Smigrodzki: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7716.html">Rafal Smigrodzki: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7725.html">Mark Waser: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7735.html">Samantha Atkins: "Re: Friendliness and blank-slate goal bootstrap"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7714">[ date ]</a>
<a href="index.html#7714">[ thread ]</a>
<a href="subject.html#7714">[ subject ]</a>
<a href="author.html#7714">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:43 MDT
</em></small></p>
</body>
</html>
