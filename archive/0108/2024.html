<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Floppy take-off</title>
<meta name="Author" content="James Higgins (jameshiggins@earthlink.net)">
<meta name="Subject" content="Re: Floppy take-off">
<meta name="Date" content="2001-08-01">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Floppy take-off</h1>
<!-- received="Wed Aug 01 20:31:17 2001" -->
<!-- isoreceived="20010802023117" -->
<!-- sent="Wed, 01 Aug 2001 17:40:05 -0700" -->
<!-- isosent="20010802004005" -->
<!-- name="James Higgins" -->
<!-- email="jameshiggins@earthlink.net" -->
<!-- subject="Re: Floppy take-off" -->
<!-- id="4.3.2.7.2.20010801172920.00b61e78@mail.earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="000e01c11a81$c7a70640$0400a8c0@mshome.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Higgins (<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20Floppy%20take-off"><em>jameshiggins@earthlink.net</em></a>)<br>
<strong>Date:</strong> Wed Aug 01 2001 - 18:40:05 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2025.html">James Higgins: "Re: Floppy take-off"</a>
<li><strong>Previous message:</strong> <a href="2023.html">James Higgins: "Re: Floppy take-off"</a>
<li><strong>In reply to:</strong> <a href="1995.html">Joaquim Almgren Gândara: "Re: Floppy take-off"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2062.html">Dan Clemmensen: "Re: Floppy take-off"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2024">[ date ]</a>
<a href="index.html#2024">[ thread ]</a>
<a href="subject.html#2024">[ subject ]</a>
<a href="author.html#2024">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
At 02:02 PM 8/1/2001 +0200, you wrote:
<br>
<em>&gt;Seriously speaking, you didn't adress the other possibility. What if
</em><br>
<em>&gt;it needs to be seven times as smart as a human in order to improve its
</em><br>
<em>&gt;own code? Let's assume that there is no codic cortex. Let us also
</em><br>
<em>&gt;assume that Ben or Eli manage to create a human-level AI. What if it
</em><br>
<em>&gt;looks at it own code, just goes &quot;Oh, wow, you've done some really cool
</em><br>
<em>&gt;stuff here&quot; and then ~can't~ improve the code? If it takes two or more
</em><br>
<em>&gt;~intelligent~ people to create an AI equivalent to the ~average~
</em><br>
<em>&gt;human, what's to say that the AI can create a ~trans-human~ AI? Isn't
</em><br>
<em>&gt;that a leap of faith?
</em><br>
<p>Personally, I'm thinking it should be on the level of Ben, Eli or similar 
<br>
AI researcher.  I believe I stated that it needs to be equivalent to 1 AI 
<br>
researcher.  So it may need to be somewhat more intelligent than the 
<br>
average human, but its hard to say.  I believe it will fail if it is less 
<br>
intelligent than that, however.
<br>
<p>It doesn't need to understand absolutely everything, and it certainly 
<br>
doesn't need to know how to make massive improvements.  But it would be in 
<br>
a unique position to make minor changes and experience the 
<br>
difference.  Then, though practice and continued study it would get 
<br>
better.  It would start making minor improvements, which would then make it 
<br>
smarter or at least faster.  These improvements would help it make further 
<br>
improvements, and the effect would snowball.
<br>
<p><p><em>&gt;Gordon Worley:
</em><br>
<em>&gt; &gt; I'm willing to bet that, given enough time, Ben
</em><br>
<em>&gt; &gt; could keep making improvements, though as
</em><br>
<em>&gt; &gt; time goes on it will be harder. Of course, for
</em><br>
<em>&gt; &gt; an AI this isn't a problem since it's dynamic
</em><br>
<em>&gt; &gt; [...]
</em><br>
<em>&gt;
</em><br>
<em>&gt;As time goes on, it will be harder, I agree. So hard, in fact, that it
</em><br>
<em>&gt;might prove to be impossible for humans to create an intelligence
</em><br>
<em>&gt;seven times smarter than themselves. Of course, if we can get the
</em><br>
<em>&gt;positive feedback loop started, there's no telling how intelligent an
</em><br>
<em>&gt;AI can get. But how do we start it if the AI takes one look at its own
</em><br>
<em>&gt;code and just gives up?
</em><br>
<p>I find this highly unlikely.  It would at least start trying things, most 
<br>
if which would probably fail.  By the way, has anyone given serious thought 
<br>
as to how the AI is going to experiment on itself?  It is going to need, at 
<br>
least, some method to automatically restore its previous state for when it 
<br>
really screws up.  I might suggest something like how the resolution 
<br>
settings work in Windows.  You make changes, hit apply, it brings up the 
<br>
new settings with a dialog that says &quot;keep these?&quot; and if there is no 
<br>
response in some period of time it restores the old settings.
<br>
<p><em>&gt;I realise that if I'm right, humanity is doomed, which is why I want
</em><br>
<em>&gt;someone to very clearly state why I'm wrong.
</em><br>
<p>Your wrong, because if you were right we would all be doomed.  And, humans 
<br>
having the nature that we will, we won't give up until we succeed.
<br>
<p>It won't take an AI that is 7 times smarter than the average human to 
<br>
succeed.  If that were the case, we would never get the original AI up and 
<br>
running.  At most we need to get an AI equivalent to smarter humans who do 
<br>
AI research.  If the AI is not very fast, we could network together many of 
<br>
them to work as a team.  As long as we can in fact create a general 
<br>
intelligence at least as smart as a human, we will succeed.  Of course, 
<br>
this is all just based off my personal opinion.  There won't be any 
<br>
supporting facts until after we succeed.  ;)
<br>
<p>James Higgins
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2025.html">James Higgins: "Re: Floppy take-off"</a>
<li><strong>Previous message:</strong> <a href="2023.html">James Higgins: "Re: Floppy take-off"</a>
<li><strong>In reply to:</strong> <a href="1995.html">Joaquim Almgren Gândara: "Re: Floppy take-off"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2062.html">Dan Clemmensen: "Re: Floppy take-off"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2024">[ date ]</a>
<a href="index.html#2024">[ thread ]</a>
<a href="subject.html#2024">[ subject ]</a>
<a href="author.html#2024">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
