<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Augmenting humans is a better way</title>
<meta name="Author" content="James Higgins (jameshiggins@earthlink.net)">
<meta name="Subject" content="Re: Augmenting humans is a better way">
<meta name="Date" content="2001-08-02">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Augmenting humans is a better way</h1>
<!-- received="Thu Aug 02 13:17:32 2001" -->
<!-- isoreceived="20010802191732" -->
<!-- sent="Thu, 02 Aug 2001 09:15:51 -0700" -->
<!-- isosent="20010802161551" -->
<!-- name="James Higgins" -->
<!-- email="jameshiggins@earthlink.net" -->
<!-- subject="Re: Augmenting humans is a better way" -->
<!-- id="4.3.2.7.2.20010802085311.023030e8@mail.earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="026c01c11b5f$30d82800$6301a8c0@iliade.nacretechnologies.co m" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Higgins (<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20Augmenting%20humans%20is%20a%20better%20way"><em>jameshiggins@earthlink.net</em></a>)<br>
<strong>Date:</strong> Thu Aug 02 2001 - 10:15:51 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2048.html">James Higgins: "RE: Article: The coming superintelligence: who will be in control?"</a>
<li><strong>Previous message:</strong> <a href="2046.html">Gordon Worley: "RE: Article: The coming superintelligence: who will be in control?"</a>
<li><strong>Maybe in reply to:</strong> <a href="../0107/1857.html">Jack Richardson: "Re: Augmenting humans is a better way"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2049.html">Arona Ndiaye: "Re: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="2049.html">Arona Ndiaye: "Re: Augmenting humans is a better way"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2047">[ date ]</a>
<a href="index.html#2047">[ thread ]</a>
<a href="subject.html#2047">[ subject ]</a>
<a href="author.html#2047">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I have to ask, did you bother to REALLY read my posts?  All of the below 
<br>
quotes are out of context.  Your replies to my statements are as if you saw 
<br>
my text, quoted out of context as below, and replied in kind.
<br>
<p>At 05:51 AM 8/2/2001 +0200, you wrote:
<br>
<em>&gt;Quoting James Higgins:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt;But it becomes a really fine line beyond the very basics as to what
</em><br>
<em>&gt;is moral and what isn't
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;You said abolutely nothing in that sentence. Where is there not a fine line
</em><br>
<em>&gt;? That is what makes us human, good or bad, that is the way it is. Same
</em><br>
<em>&gt;(very fine line) applies to what is dangerous, good, bad, sexy, groovy
</em><br>
<em>&gt;etc... which is why X persons die every day. *smile*
</em><br>
<p>I think you just made my point for me, thanks.
<br>
<p><em>&gt;P.S. If you aren't the solution, you're the problem. Who's side are you on ?
</em><br>
<p>Excuse me?
<br>
<p><p>At 06:01 AM 8/2/2001 +0200, you wrote:
<br>
<em>&gt;Quoting James Higgins:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt;As for Real AI, when someone gets one working then we can talk.
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;The whole point is to do the talking before and get it 'right'. &quot;then we can
</em><br>
<em>&gt;talk&quot; is a pipe dream if whoever creates the 1st Real AI gets it wrong,
</em><br>
<em>&gt;which is likely to happen as long as ppl have the attitude that you do have
</em><br>
<em>&gt;about it. I can understand that you are not conviced. What I cannot grasp
</em><br>
<em>&gt;are your 'technical', 'architectural', 'design' etc... reasons.
</em><br>
<em>&gt;Just saying it won't happen for whatever reason is sweet but that's all it
</em><br>
<em>&gt;is =)
</em><br>
<p>The context here was talking about time lines for AI 
<br>
development.  Certainly many people have ideas on how to develop Real AI, 
<br>
but they are different and some/many of them may not work.  And thus, while 
<br>
we can estimate how much time any of them may take, we can not estimate how 
<br>
long it will take until we have the first running Real AI.  This discussion 
<br>
has been concluded and I do not wish to reopen it, I state this here for 
<br>
clarification only.
<br>
<p><em>&gt; &gt;&gt;
</em><br>
<em>&gt;The fact is that no one knows what Real AI is going to require
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;*cough*
</em><br>
<em>&gt;Did you really read FAI ? Did you read all of the material on Low Beyond ?
</em><br>
<em>&gt;Did you read the SL4 archives ? If you did (****and understood it****) and
</em><br>
<em>&gt;still believe the sentence above, well... either nothing will ever convince
</em><br>
<em>&gt;you or your understanding of intelligence is quite different from the
</em><br>
<em>&gt;understanding most people have of it on this list. Should it be the 2nd
</em><br>
<em>&gt;case, please enlighten us =)
</em><br>
<p>Can you or anyone else guarantee me 100% that Eli's plans for Real AI will 
<br>
work?  Simply implement his design and bingo we have Real AI?  Sounds nice, 
<br>
but others have thought the same but did not succeed.  I'm not saying he 
<br>
won't succeed, I'm just saying it would be irresponsible to hang our hopes 
<br>
on any one (or even several) possible solutions since all solutions to date 
<br>
have failed.
<br>
<p><em>&gt; &gt;&gt;
</em><br>
<em>&gt;.  As for destructive technologies, nothing.  My personal belief
</em><br>
<em>&gt;is that either super intelligence will promote friendliness or we're doomed.
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;We are doomed already. SIAI is the exit as far as certain persons are
</em><br>
<em>&gt;concerned.  =)
</em><br>
<p>I agree that we are most likely doomed if we don't develop an SI, or at 
<br>
least a very smart AI that can help us develop FTL travel, space 
<br>
colonization, etc.  Just some of the reasons I support SI 
<br>
development.  However, I still feel that if SIs are not inherently friendly 
<br>
(to at least a reasonable degree) then we are probably doomed anyway.
<br>
<p><p>At 07:10 AM 8/2/2001 +0200, you wrote:
<br>
<em>&gt;Greetings to each and everyone =)
</em><br>
<em>&gt;
</em><br>
<em>&gt;Quoting James Higgins:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt;I don't have to examine the Webmind design or code because no one can in
</em><br>
<em>&gt;fact define exactly what Real AI is.
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;Oh, oh, oh !! But you can define exactly how my brains work ? Where is what
</em><br>
<em>&gt;etc... If not, where would RNIs be safer, faster, better than SIAI, Fai or
</em><br>
<em>&gt;whatever ? You seem to be pretty closed-minded on the whole issue. I can
</em><br>
<em>&gt;feel you biased but I do not know why. _yet_ =)
</em><br>
<p>You really didn't read my posts, did you?  I NEVER SAID, ANYWHERE that RNIs 
<br>
were going to be faster, cheaper, better, or any such thing.  I was 
<br>
pointing out that the argument that RNIs would definitely arrive after AI 
<br>
is an unsupportable argument!  There is not enough fact known about the 
<br>
exact development of either in order to create a realistic future time line.
<br>
<p>And I take that as a serious insult, by the way.  Calling someone 
<br>
closed-minded is very rude.
<br>
<p><em>&gt; &gt;&gt;
</em><br>
<em>&gt;Given a fully functioning General AI, the availability of strong nanotech,
</em><br>
<em>&gt;and that this AI has access to nanotech (I find this VERY unlikely), then
</em><br>
<em>&gt;yes.  But what fool is going to give a seed AI access to nanotech?  And
</em><br>
<em>&gt;this still requires a functioning General AI that we still have no idea how
</em><br>
<em>&gt;to build.
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;The same type of fool that believe that fully intelligent (same level as
</em><br>
<em>&gt;FAI, self optimizing, etc....) RNIs will be here before SIAI or that RNIs
</em><br>
<em>&gt;are more/less advanced. They are both far away, with pros and cons.
</em><br>
<em>&gt;Which fruit is more a fruit than the other one ? The orange or the pear ?
</em><br>
<em>&gt;None, they both are fruits, period.
</em><br>
<em>&gt;Will all due respect, to me, you and that fool, do look
</em><br>
<em>&gt;quite similar. Go take that Vision interface, come here and make it work on
</em><br>
<em>&gt;my shattered knee caps =), then we'll talk =) By then FAI will be all over
</em><br>
<em>&gt;the place =)
</em><br>
<p>Ok, I'm done replying to your posts.  If your not going to bother reading 
<br>
my posts thoroughly enough to make intelligent replies, but instead just 
<br>
reply to insult me what is the point.  The only thing your doing is 
<br>
lowering the quality of this list with pointless bantering tripe in order 
<br>
to insult me.  If you wish to continue this behavior please take this to 
<br>
one of the thousands of pointless lists that exist out there.
<br>
<p>Thank you,
<br>
James Higgins
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2048.html">James Higgins: "RE: Article: The coming superintelligence: who will be in control?"</a>
<li><strong>Previous message:</strong> <a href="2046.html">Gordon Worley: "RE: Article: The coming superintelligence: who will be in control?"</a>
<li><strong>Maybe in reply to:</strong> <a href="../0107/1857.html">Jack Richardson: "Re: Augmenting humans is a better way"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2049.html">Arona Ndiaye: "Re: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="2049.html">Arona Ndiaye: "Re: Augmenting humans is a better way"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2047">[ date ]</a>
<a href="index.html#2047">[ thread ]</a>
<a href="subject.html#2047">[ subject ]</a>
<a href="author.html#2047">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
