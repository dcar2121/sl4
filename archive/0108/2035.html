<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Article: The coming superintelligence: who will be in control?</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Re: Article: The coming superintelligence: who will be in control?">
<meta name="Date" content="2001-08-01">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Article: The coming superintelligence: who will be in control?</h1>
<!-- received="Thu Aug 02 03:02:19 2001" -->
<!-- isoreceived="20010802090219" -->
<!-- sent="Thu, 02 Aug 2001 01:19:05 -0400" -->
<!-- isosent="20010802051905" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Re: Article: The coming superintelligence: who will be in control?" -->
<!-- id="3B68E2C9.D29552FE@posthuman.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="NFBBLBPNELPPDGOGAIEBOEFADDAA.amara@kurzweilai.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Article:%20The%20coming%20superintelligence:%20who%20will%20be%20in%20control?"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Wed Aug 01 2001 - 23:19:05 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2036.html">Amara D. Angelica: "RE: Article: The coming superintelligence: who will be in control?"</a>
<li><strong>Previous message:</strong> <a href="2034.html">Josh Yotty: "Re: Motivation; was Dumbasses vs. AI researchers"</a>
<li><strong>In reply to:</strong> <a href="2022.html">Amara D. Angelica: "RE: Article: The coming superintelligence: who will be in control?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2036.html">Amara D. Angelica: "RE: Article: The coming superintelligence: who will be in control?"</a>
<li><strong>Reply:</strong> <a href="2036.html">Amara D. Angelica: "RE: Article: The coming superintelligence: who will be in control?"</a>
<li><strong>Reply:</strong> <a href="2042.html">Ben Goertzel: "RE: Article: The coming superintelligence: who will be in control?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2035">[ date ]</a>
<a href="index.html#2035">[ thread ]</a>
<a href="subject.html#2035">[ subject ]</a>
<a href="author.html#2035">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&quot;Amara D. Angelica&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Brian, an intriguing idea. Can you or anyone else elaborate?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; -----Original Message-----
</em><br>
<em>&gt; &gt; From: <a href="mailto:owner-sl4@sysopmind.com?Subject=Re:%20Article:%20The%20coming%20superintelligence:%20who%20will%20be%20in%20control?">owner-sl4@sysopmind.com</a> [mailto:<a href="mailto:owner-sl4@sysopmind.com?Subject=Re:%20Article:%20The%20coming%20superintelligence:%20who%20will%20be%20in%20control?">owner-sl4@sysopmind.com</a>]On Behalf
</em><br>
<em>&gt; &gt; Of Brian Atkins
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; going beyond trend tracking and guessing what will happen. I'd like to see
</em><br>
<em>&gt; &gt; people take the issue farther and try to figure out a) can we manipulate
</em><br>
<em>&gt; &gt; the timing and character of the Singularity significantly b) if so, should
</em><br>
<em>&gt; &gt; we accelerate it?
</em><br>
<p>I'm not sure if you wanted me to elaborate on the fact that no one is
<br>
talking about this issue, or to elaborate on possible answers to A and B.
<br>
I'll do the former, because as you can see below I think Ray and the
<br>
people on this list have already decided for themselves that the answer
<br>
to B is Yes. The answer to A IMO is Yes, and I think Ray would also agree
<br>
with that at least to a limited extent. What I am frustrated by is seeing
<br>
people realize that both A and B are Yes, but then not helping to push the
<br>
Singularity closer to us in time. So I'd like to get the word out about
<br>
this issue, since (again IMO) this is even more important than simply
<br>
realizing a Singularity is coming. Once you see it's coming then you have
<br>
to go a step farther and &quot;pick a side&quot;. Sitting on the fence like a reporter
<br>
(no offense :-) is not a rational choice in this situation. If you believe
<br>
the Singularity will be good (and I mean good in the sense of saving your
<br>
life, not in the sense of whether congress lowers your tax rate 3%) for you
<br>
then you should try to advance it. If you believe the Singularity will be
<br>
bad for you, then you should try to prevent it. This is a world changing
<br>
bit of history.
<br>
<p>Here's some examples of the &quot;blindspot&quot; that I'm talking about. Go look at
<br>
part 4 of the Extro-5 Kurzweil talk here:
<br>
<p><a href="http://www.kurzweilai.net/meme/frame.html?main=/articles/art0235.html">http://www.kurzweilai.net/meme/frame.html?main=/articles/art0235.html</a> 
<br>
<p>skip ahead to around 13:15 at which point Eliezer asks Ray something
<br>
along the lines of &quot;Well, you've described the Singularity and our
<br>
progress to it so far, but you haven't said what kind of Singularity
<br>
you would like to see or what time you would /prefer/ it to happen&quot;.
<br>
Then Ray sits there for like 7 seconds (which makes me think he might
<br>
not have thought about this much) before someone in the back says
<br>
something that causes him to then go off on a tangent without answering
<br>
the question. Very frustrating since that was the one question I wanted
<br>
an answer to! :-)
<br>
<p>If you or anyone else here has ever seen him address this I'd like to
<br>
know about it. He seems to have chosen a clinical observer style when
<br>
it comes to the Singularity, which lets him make predictions about what
<br>
the future might be like, but yet not consider the fact that someone
<br>
with his excellent grasp of the situation would be exactly the right
<br>
kind of person to help guide and support the actual development. Here's
<br>
a quote from his book precis:
<br>
<p>&quot;Technology will remain a double edged sword, and the story of the Twenty
<br>
&nbsp;First century has not yet been written. It represents vast power to be
<br>
&nbsp;used for all humankind's purposes. We have no choice but to work hard to
<br>
&nbsp;apply these quickening technologies to advance our human values, despite
<br>
&nbsp;what often appears to be a lack of consensus on what those values should
<br>
&nbsp;be.&quot;
<br>
<p>Confusing to say the least, unless he's running a secret AI or brain
<br>
scanning project we don't know about :-) He advocates working to achieve the
<br>
Singularity, and points out that the history is not made yet, but provides
<br>
no advice (outside of some possible future scenarios) on what might be the
<br>
best way to achieve it, whether we should try to accelerate the arrival of
<br>
it (is it &quot;ethical&quot; to accelerate the Singularity), and how we might do so
<br>
if we do decide we want to accelerate it.
<br>
<p>He goes on to talk about the purpose of life which he sees as evolving
<br>
to the Singularity. He says that, but then almost immediately goes back
<br>
towards pointing out that the real reason the Singularity will happen
<br>
is due to economics. However, if he really feels like achieving a
<br>
Singularity is the goal of life, then I'd like to ask him: what are your
<br>
plans for after you finish your book? How will you help to achieve this
<br>
goal? I don't see any answers to that, or even anyone else asking this
<br>
question of themselves (besides people who hang around here) or Ray.
<br>
<p>He ends his precis with the admonition that we all should &quot;stick around
<br>
so you might see the Singularity&quot;. Which really clenches it for me- if
<br>
he had really internalized the &quot;Singularity is the goal of life&quot; idea
<br>
then he would instead be telling people to go out and help get the
<br>
Singularity here more quickly so that even more people now living will
<br>
be able to survive to see it.
<br>
<p>Now I don't want to look like I'm stuck on Ray. He just is the most
<br>
glaring example to me because I've read so much of his stuff lately.
<br>
He also is the biggest proponent of the Singularity in the mainstream
<br>
world, and yet still seems to be missing the final pieces of the picture.
<br>
<pre>
-- 
Brian Atkins
Director, Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2036.html">Amara D. Angelica: "RE: Article: The coming superintelligence: who will be in control?"</a>
<li><strong>Previous message:</strong> <a href="2034.html">Josh Yotty: "Re: Motivation; was Dumbasses vs. AI researchers"</a>
<li><strong>In reply to:</strong> <a href="2022.html">Amara D. Angelica: "RE: Article: The coming superintelligence: who will be in control?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2036.html">Amara D. Angelica: "RE: Article: The coming superintelligence: who will be in control?"</a>
<li><strong>Reply:</strong> <a href="2036.html">Amara D. Angelica: "RE: Article: The coming superintelligence: who will be in control?"</a>
<li><strong>Reply:</strong> <a href="2042.html">Ben Goertzel: "RE: Article: The coming superintelligence: who will be in control?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2035">[ date ]</a>
<a href="index.html#2035">[ thread ]</a>
<a href="subject.html#2035">[ subject ]</a>
<a href="author.html#2035">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
