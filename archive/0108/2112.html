<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Opting out of the Sysop scenario?</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Re: Opting out of the Sysop scenario?">
<meta name="Date" content="2001-08-11">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Opting out of the Sysop scenario?</h1>
<!-- received="Sat Aug 11 13:32:46 2001" -->
<!-- isoreceived="20010811193246" -->
<!-- sent="Sat, 11 Aug 2001 12:15:28 -0400" -->
<!-- isosent="20010811161528" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Re: Opting out of the Sysop scenario?" -->
<!-- id="3B755A20.F21E4941@posthuman.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="4.3.2.7.2.20010811021026.022a65c0@mail.earthlink.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Opting%20out%20of%20the%20Sysop%20scenario?"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Sat Aug 11 2001 - 10:15:28 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="2113.html">John Stick: "Re: Sysops, volition, and opting out"</a>
<li><strong>Previous message:</strong> <a href="2111.html">Ben Goertzel: "Learning to intelligently self-modify..."</a>
<li><strong>In reply to:</strong> <a href="2109.html">James Higgins: "Re: Opting out of the Sysop scenario?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2116.html">Durant Schoon: "Re: Opting out of the Sysop scenario?"</a>
<li><strong>Reply:</strong> <a href="2116.html">Durant Schoon: "Re: Opting out of the Sysop scenario?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2112">[ date ]</a>
<a href="index.html#2112">[ thread ]</a>
<a href="subject.html#2112">[ subject ]</a>
<a href="author.html#2112">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
James Higgins wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; At 11:17 AM 8/6/2001 -0700, you wrote:
</em><br>
<em>&gt; &gt;Perhaps we can think about it as a legal system. We all agree to obey
</em><br>
<em>&gt; &gt;the rules for our own protection, vs. reverting to anarchy. This is
</em><br>
<em>&gt; &gt;a starting point however, because any technologically deficient Legal
</em><br>
<em>&gt; &gt;System can't statisfy everyone. The current U.S. system violates the
</em><br>
<em>&gt; &gt;volition of, say, murderers and adults who want to have sex with
</em><br>
<em>&gt; &gt;children. It allows humans to slaughter animals which really annoys
</em><br>
<em>&gt; &gt;members of PETA. It allows abortions which really annoys the Christian
</em><br>
<em>&gt; &gt;Right. It prevents you from growing certain natural plants and
</em><br>
<em>&gt; &gt;smoking them.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The thing with current systems is that if they don't work, you can
</em><br>
<em>&gt; remove/change/overthrow them.  In fact, the founding fathers of the US
</em><br>
<em>&gt; tried to ensure that the citizens would always have the ability to
</em><br>
<em>&gt; overthrow their own government if it became tyrannical.  If nothing else,
</em><br>
<em>&gt; you can leave as there are many countries all with their own
</em><br>
<em>&gt; governments.  So you get to pick and choose.  If the one you are in goes to
</em><br>
<em>&gt; hell, you can move.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; There will be no choice in the Sysop's realm.  And if things go bad (this
</em><br>
<p>I have patiently explained that if the Citizens tell the Sysop to go away,
<br>
it will. No different than a standard revolution, except it's a lot easier.
<br>
<p><em>&gt; is always a possibility, no matter how small) everyone is stuck and thus
</em><br>
<em>&gt; possibly screwed.
</em><br>
<em>&gt; 
</em><br>
<p>Wishing that all the atoms don't end up under the influence of something
<br>
in the end doesn't make it likely to happen (sorry, but the bellyaching
<br>
gets old... I still don't hear an alternate solution other than wishful
<br>
thinking). If the Sysop doesn't take control, someone or something else
<br>
(much more likely to be worse) will. All that matter floating around the
<br>
solar system is like the ultimate resource, and believe me people and
<br>
unFriendly AIs will seriously covet it.
<br>
<p><em>&gt; &gt;In a VR enhanced society with Friendliness, we can live
</em><br>
<em>&gt; &gt;out our fantasies, whatever they are, in complete safety with respect
</em><br>
<em>&gt; &gt;to other sentient beings. A lowest level prevention mechanism of a
</em><br>
<em>&gt; &gt;physical operating system would prevent one sentient from actually
</em><br>
<em>&gt; &gt;harming another.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Not exactly.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Acting out your fantasies might be incredibly difficult.  According to the
</em><br>
<em>&gt; suggested rules you can't simulate people in VR.  If they are a &quot;real&quot;
</em><br>
<em>&gt; person you are simulating, acting out your fantasies with a simulation of
</em><br>
<p>Again you have misunderstood. The whole &quot;can't sim people&quot; only applies
<br>
when you are outside the Sysop. That is why it wouldn't want to let you
<br>
go outside of it, or conversely why it would want to extend itself with
<br>
you wherever you go. Inside the Sysop it can protect the sims just as
<br>
easily as it protects your wishes.
<br>
<p><em>&gt; them is deemed to violate them.  Second, if you create a simulation of a
</em><br>
<em>&gt; person it becomes a citizen, permanently get assigned the computing
</em><br>
<em>&gt; resources you allocated to it and gets its own full volition.  Thus you
</em><br>
<em>&gt; can't simulate anything.
</em><br>
<p>You can simulate anything that doesn't become a Citizen, or as you say
<br>
you can share some of your resources with whatever you create. It's just
<br>
like making a real baby, you have to provide for it :-) Again, I don't
<br>
see why you're complaining about not being able to create a real Citizen
<br>
and then keep it imprisoned. That's just not cool... I bet the Sysop
<br>
could whip up for you some very intelligent seeming VR &quot;people&quot; that
<br>
just skirt under the line of what is Citizen-worthy.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; Which means if you want to act out your fantasies, your going to need other
</em><br>
<em>&gt; &quot;real&quot; people to cooperate.  This has all sorts of problems.  First, the
</em><br>
<em>&gt; way it sounds is that the sysop warns you not to read any incoming messages
</em><br>
<em>&gt; from people you don't trust.  So it will be very hard to meet new
</em><br>
<p>Actually no, the Sysop should only warn you when a particular message
<br>
contains something you said you want it to warn you about. For instance
<br>
a nasty-gram from a higher level Power that has the potential to infect
<br>
you with some memes you don't want. Normal, nice, messages will flow
<br>
freely.
<br>
<p><em>&gt; people.  Second, any &quot;VR&quot; type setting better be a private setting.  If you
</em><br>
<em>&gt; wanted to go to the mall in VR, for example, you would need hundreds or
</em><br>
<em>&gt; more individuals to play along.  Try getting an individual to play at being
</em><br>
<em>&gt; a sales clerk, chef, waiter, butler, etc.
</em><br>
<p>Well if you and some friends really had a fetish for 20th century malls, and
<br>
Sysop-generated/controlled non-Citizen actors wouldn't cut if for some
<br>
reason, you could always break down and pay other Citizens to act for you.
<br>
They might want some of the atoms in your &quot;bank account&quot;, or maybe you
<br>
would have to agree to act for them sometime.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt;This &quot;prevention&quot; though, is a form of &quot;control&quot;. There seems no way
</em><br>
<em>&gt; &gt;around it. It is the *feeling* of being under another's control that
</em><br>
<em>&gt; &gt;is bitterly rejected. Perhaps one way out of the contradiction is to
</em><br>
<em>&gt; &gt;voluntarily live in a make believe world where we &quot;think&quot; we have
</em><br>
<em>&gt; &gt;complete free will and then periodically are &quot;revived&quot;, reminded
</em><br>
<em>&gt; &gt;that we, ourselves, set ourselves up to believe this fake reality for
</em><br>
<em>&gt; &gt;our own peace of mind and are given the choice of continuing the
</em><br>
<em>&gt; &gt;simulation or not.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Actually, its more about sealing the human race into a logical cell with no
</em><br>
<em>&gt; way of escape in an emergency.
</em><br>
<p>I have also patiently stated that should an emergency occur that the Sysop
<br>
can't handle, it will appeal to the Citizens to either help out or flee.
<br>
<p>The only REAL possible downside of the Sysop is if it goes unFriendly.
<br>
Everything flows from that. The only way to avoid this possibility
<br>
completely is to never ever in the history of the Universe develop an AI.
<br>
Otherwise all you can do is reduce the risks. We have studied the
<br>
risks of various scenarios, and found the AI one to have the least
<br>
risk/most reducible risks compared to the others.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt;Would you be willing to take &quot;The Illusion of Freedom with Periodic
</em><br>
<em>&gt; &gt;Resuscitation&quot; as a compromise? ;-) If not you could always stay
</em><br>
<em>&gt; &gt;on old Earth OR try to travel faster than the galactically
</em><br>
<em>&gt; &gt;spreading Sysop...you'll have those real choices at least. The other
</em><br>
<em>&gt; &gt;way is to deactive your &quot;need&quot; to feel free of the Operating System,
</em><br>
<em>&gt; &gt;but for some reason, I don't think you'd want to do that.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I'd take the &quot;try to travel faster than the galactically spreading sysop&quot;
</em><br>
<em>&gt; option (for at least 1 copy of myself), but I don't think the powers that
</em><br>
<em>&gt; be on this list want to even offer that option to anyone.
</em><br>
<em>&gt; 
</em><br>
<p>Ever read Hanson's &quot;Autarky&quot; paper? Search Google for Robin Hanson Autarky.
<br>
Sometimes his machine is down so you have to read the cached google version.
<br>
<p>To sum up, without some kind of AI building your ship for you, you will
<br>
never have one unless you become way richer than Bill Gates. And even then
<br>
if you left the system before the Sysop you would still be unlikely to
<br>
outrun it since it will have the full resources of itself and all the
<br>
Citizens who want to help it. The dream of running away on a ship by
<br>
yourself is not very likely. It might be somewhat feasible if you uploaded
<br>
yourself, enhanced your intelligence significantly and mastered nanotech.
<br>
But I still think the Sysop would outrun you due to the much more powerful
<br>
resources it will have to help it out.
<br>
<p>You do have one thing I guess in your favor (possibly), and that is the
<br>
Fermi Paradox. If we aren't the only ones in this galaxy then you'd figure
<br>
this all would have happened already and we'd have a Sysop hanging around
<br>
here. So perhaps either all Singularity attempts fail, or Sysops end up
<br>
deciding to hang out only in their home solar system, or we are living
<br>
in a sim, or for some very strange reason we are not in a sim but we are
<br>
also the first people in the galaxy to get to this point.
<br>
<pre>
-- 
Brian Atkins
Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="2113.html">John Stick: "Re: Sysops, volition, and opting out"</a>
<li><strong>Previous message:</strong> <a href="2111.html">Ben Goertzel: "Learning to intelligently self-modify..."</a>
<li><strong>In reply to:</strong> <a href="2109.html">James Higgins: "Re: Opting out of the Sysop scenario?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="2116.html">Durant Schoon: "Re: Opting out of the Sysop scenario?"</a>
<li><strong>Reply:</strong> <a href="2116.html">Durant Schoon: "Re: Opting out of the Sysop scenario?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2112">[ date ]</a>
<a href="index.html#2112">[ thread ]</a>
<a href="subject.html#2112">[ subject ]</a>
<a href="author.html#2112">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
