<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)</title>
<meta name="Author" content="Samantha Atkins (sjatkins@gmail.com)">
<meta name="Subject" content="Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)">
<meta name="Date" content="2008-04-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)</h1>
<!-- received="Sat Apr 26 14:07:57 2008" -->
<!-- isoreceived="20080426200757" -->
<!-- sent="Sat, 26 Apr 2008 13:06:07 -0700" -->
<!-- isosent="20080426200607" -->
<!-- name="Samantha Atkins" -->
<!-- email="sjatkins@gmail.com" -->
<!-- subject="Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)" -->
<!-- id="948b11e0804261306n7597850cy77e849cc98a9f2e9@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="eeec289b0804260806u5330920ep2018bc549068b3d4@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:sjatkins@gmail.com?Subject=Re:%20AGI%20investment%20(Re:%20What%20are%20&quot;AGI-first'ers&quot;%20expecting%20AGI%20will%20teach%20us%20about%20FAI?)"><em>sjatkins@gmail.com</em></a>)<br>
<strong>Date:</strong> Sat Apr 26 2008 - 14:06:07 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="18709.html">Lee Corbin: "Re: Unbounded happiness"</a>
<li><strong>Previous message:</strong> <a href="18707.html">Rebecca: "The chinese finger trap"</a>
<li><strong>In reply to:</strong> <a href="18700.html">Byrne Hobart: "Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18726.html">Stuart Armstrong: "Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)"</a>
<li><strong>Reply:</strong> <a href="18726.html">Stuart Armstrong: "Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18708">[ date ]</a>
<a href="index.html#18708">[ thread ]</a>
<a href="subject.html#18708">[ subject ]</a>
<a href="author.html#18708">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Whether there would be any trading at all seems to me to be a very different
<br>
question than what the worth of an AI is or, as implied by the original
<br>
question, what its worth would be from our current pre-AGI perspective.
<br>
Even AGIs will find some means of deciding what to devote limited time and
<br>
capacity to.   That can be modeled as a price structure.  The relative value
<br>
of an hour (objective) of AGI labor would certainly dwarf many thousands of
<br>
hours of skilled human labor in some problem domains.   Some problems the
<br>
AGI can tackle are beyond the capabilities of all humans combined.  From
<br>
that POV an AGI is priceless.
<br>
<p>That said, the relative price offered will be a function of the agreed
<br>
valuable assets (money or goods) availabled to be traded, the value of that
<br>
which is to be produced to those who wish to receive it, and  the cost to
<br>
produce it.   The cost for many items we value will fall rapidly toward zero
<br>
given MNT.  AGIs competing to trade for values held by humans or simply
<br>
benevolent to humans are unlikely to charge exorbitant prices for things
<br>
cheap and easy to produce.
<br>
<p>On Sat, Apr 26, 2008 at 8:06 AM, Byrne Hobart &lt;<a href="mailto:bhobart@gmail.com?Subject=Re:%20AGI%20investment%20(Re:%20What%20are%20&quot;AGI-first'ers&quot;%20expecting%20AGI%20will%20teach%20us%20about%20FAI?)">bhobart@gmail.com</a>&gt; wrote:
<br>
<p><em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; On Sat, Apr 26, 2008 at 4:14 AM, Samantha Atkins &lt;<a href="mailto:sjatkins@gmail.com?Subject=Re:%20AGI%20investment%20(Re:%20What%20are%20&quot;AGI-first'ers&quot;%20expecting%20AGI%20will%20teach%20us%20about%20FAI?)">sjatkins@gmail.com</a>&gt;
</em><br>
<em>&gt; wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;  If AGI enables machines to do all the work that humans would otherwise
</em><br>
<em>&gt; &gt; &gt; be paid
</em><br>
<em>&gt; &gt; &gt; to do, then how much would it be worth?
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Nothing (or 42) as monetary valuation in its former terms would
</em><br>
<em>&gt; &gt; disappear along with most existential scarcity.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Do you expect the AIs to be precisely identical in terms of skills, goals,
</em><br>
<em>&gt; and circumstances? You would have to prove that assertion to demonstrate
</em><br>
<em>&gt; that they wouldn't want to trade. To prove that they would want to trade,
</em><br>
<em>&gt; but not to denominate it in currencies, you'd have to explain how that's any
</em><br>
<em>&gt; different from having a 'barter' system of measurement: &quot;How far away is
</em><br>
<em>&gt; Cleveland, Ohio?&quot; &quot;It is the number of seconds since the last sunset,
</em><br>
<em>&gt; multiplied by the length of Freud's first cat on its eighth birthday.&quot; Why
</em><br>
<em>&gt; oh why oh why would we stop converting things to standard measurements to
</em><br>
<em>&gt; compare them more easily?
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="18709.html">Lee Corbin: "Re: Unbounded happiness"</a>
<li><strong>Previous message:</strong> <a href="18707.html">Rebecca: "The chinese finger trap"</a>
<li><strong>In reply to:</strong> <a href="18700.html">Byrne Hobart: "Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18726.html">Stuart Armstrong: "Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)"</a>
<li><strong>Reply:</strong> <a href="18726.html">Stuart Armstrong: "Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18708">[ date ]</a>
<a href="index.html#18708">[ thread ]</a>
<a href="subject.html#18708">[ subject ]</a>
<a href="author.html#18708">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:02 MDT
</em></small></p>
</body>
</html>
