<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)</title>
<meta name="Author" content="Matt Mahoney (matmahoney@yahoo.com)">
<meta name="Subject" content="Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)">
<meta name="Date" content="2008-04-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)</h1>
<!-- received="Sun Apr 13 17:53:50 2008" -->
<!-- isoreceived="20080413235350" -->
<!-- sent="Sun, 13 Apr 2008 16:49:03 -0700 (PDT)" -->
<!-- isosent="20080413234903" -->
<!-- name="Matt Mahoney" -->
<!-- email="matmahoney@yahoo.com" -->
<!-- subject="Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)" -->
<!-- id="673770.34955.qm@web51907.mail.re2.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="b7a9e8680804131437s5dd47c86rd93c39925e6aa5e2@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Matt Mahoney (<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20AGI%20investment%20(Re:%20What%20are%20&quot;AGI-first'ers&quot;%20expecting%20AGI%20will%20teach%20us%20about%20FAI?)"><em>matmahoney@yahoo.com</em></a>)<br>
<strong>Date:</strong> Sun Apr 13 2008 - 17:49:03 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="18470.html">Lee Corbin: "Re: Another Take on Ethical Concerns"</a>
<li><strong>Previous message:</strong> <a href="18468.html">Nick Tarleton: "Re: Bounded population (was Re: Bounded utility)"</a>
<li><strong>In reply to:</strong> <a href="18467.html">Thomas McCabe: "Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18477.html">John K Clark: "AI investment (was: AGI investment)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18469">[ date ]</a>
<a href="index.html#18469">[ thread ]</a>
<a href="subject.html#18469">[ subject ]</a>
<a href="author.html#18469">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- Thomas McCabe &lt;<a href="mailto:pphysics141@gmail.com?Subject=Re:%20AGI%20investment%20(Re:%20What%20are%20&quot;AGI-first'ers&quot;%20expecting%20AGI%20will%20teach%20us%20about%20FAI?)">pphysics141@gmail.com</a>&gt; wrote:
<br>
<p><em>&gt; On Sun, Apr 13, 2008 at 4:44 PM, Matt Mahoney &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20AGI%20investment%20(Re:%20What%20are%20&quot;AGI-first'ers&quot;%20expecting%20AGI%20will%20teach%20us%20about%20FAI?)">matmahoney@yahoo.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt; --- Nick Tarleton &lt;<a href="mailto:nickptar@gmail.com?Subject=Re:%20AGI%20investment%20(Re:%20What%20are%20&quot;AGI-first'ers&quot;%20expecting%20AGI%20will%20teach%20us%20about%20FAI?)">nickptar@gmail.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;  &gt; Global economic output over the next 30 years, at constant growth,
</em><br>
<em>&gt; &gt;  &gt; will be $4.6 quadrillion (my calculation from CIA World Factbook
</em><br>
<em>&gt; &gt;  &gt; numbers). That nearly a quarter of the world economy will be invested
</em><br>
<em>&gt; &gt;  &gt; in AGI over that time is hideously implausible.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;  If AGI enables machines to do all the work that humans would otherwise be
</em><br>
<em>&gt; paid
</em><br>
<em>&gt; &gt;  to do, then how much would it be worth?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;  -- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20AGI%20investment%20(Re:%20What%20are%20&quot;AGI-first'ers&quot;%20expecting%20AGI%20will%20teach%20us%20about%20FAI?)">matmahoney@yahoo.com</a>
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; These sorts of calculations require a much higher level of rationality
</em><br>
<em>&gt; than the general public usually possesses. Even on SL4, how many
</em><br>
<em>&gt; people donate almost a quarter of their income to AGI development?
</em><br>
<em>&gt; Where did you get the $1 quadrillion figure in the first place?
</em><br>
<p>My estimate is based on the size of the world economy (US $66 trillion per
<br>
year and growing at 5%) assuming that a significant fraction (more than 1/4,
<br>
and approaching 100%) will be invested in AGI over the next 30 years.  Most of
<br>
this will be indirect, in the same way that the development of the technology
<br>
that enabled the internet (TCP/IP, HTML, HTTP, etc) was a tiny fraction of the
<br>
overall value of the internet (tens of trillions).  Most of the value is in
<br>
content and equipment (Google, Yahoo, various ISPs, your computer, etc).
<br>
<p>I expect the development costs of AI algorithms to be a tiny fraction of the
<br>
value of AI.  Most of the value will be in the form of computational resources
<br>
and knowledge.  Most of the work will be indirect.  For example, viewing a
<br>
porn site would help train an AI to generate better images.
<br>
<p>One can argue that the cost of AI could be a tiny fraction of its value.  I
<br>
argue that given a choice we would prefer to have AI sooner at higher cost.
<br>
<p>My figure of 30 years is just a guess how long it will take to achieve
<br>
recursive self improvement.  One could use Moore's Law to project when an
<br>
artificial brain will cost less than hiring a natural one if we knew how much
<br>
computing power we need.  But we don't really know this.  I am estimating the
<br>
cost of development prior to achieving RSI because once we do, a singularity
<br>
will quickly follow.
<br>
<p><em>&gt; If someone gave you $1 quadrillion tomorrow, what would you spend it on?
</em><br>
<p>I wouldn't.  AGI will emerge from the internet as people pursue their own
<br>
goals.  Paying people to do anything else would just be counterproductive.  A
<br>
centralized effort would kill it.
<br>
<p><p>-- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20AGI%20investment%20(Re:%20What%20are%20&quot;AGI-first'ers&quot;%20expecting%20AGI%20will%20teach%20us%20about%20FAI?)">matmahoney@yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="18470.html">Lee Corbin: "Re: Another Take on Ethical Concerns"</a>
<li><strong>Previous message:</strong> <a href="18468.html">Nick Tarleton: "Re: Bounded population (was Re: Bounded utility)"</a>
<li><strong>In reply to:</strong> <a href="18467.html">Thomas McCabe: "Re: AGI investment (Re: What are &quot;AGI-first'ers&quot; expecting AGI will teach us about FAI?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18477.html">John K Clark: "AI investment (was: AGI investment)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18469">[ date ]</a>
<a href="index.html#18469">[ thread ]</a>
<a href="subject.html#18469">[ subject ]</a>
<a href="author.html#18469">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:02 MDT
</em></small></p>
</body>
</html>
