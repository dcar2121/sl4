<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Can't afford to resuce cows (was Re: Arbitrarily decide who benefits)</title>
<meta name="Author" content="Samantha Atkins (sjatkins@gmail.com)">
<meta name="Subject" content="Re: Can't afford to resuce cows (was Re: Arbitrarily decide who benefits)">
<meta name="Date" content="2008-04-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Can't afford to resuce cows (was Re: Arbitrarily decide who benefits)</h1>
<!-- received="Sat Apr 26 02:50:32 2008" -->
<!-- isoreceived="20080426085032" -->
<!-- sent="Sat, 26 Apr 2008 01:48:31 -0700" -->
<!-- isosent="20080426084831" -->
<!-- name="Samantha Atkins" -->
<!-- email="sjatkins@gmail.com" -->
<!-- subject="Re: Can't afford to resuce cows (was Re: Arbitrarily decide who benefits)" -->
<!-- id="4812EC5F.8090605@gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20080416021630.3CB7C1BD03@fungible.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:sjatkins@gmail.com?Subject=Re:%20Can't%20afford%20to%20resuce%20cows%20(was%20Re:%20Arbitrarily%20decide%20who%20benefits)"><em>sjatkins@gmail.com</em></a>)<br>
<strong>Date:</strong> Sat Apr 26 2008 - 02:48:31 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="18689.html">Samantha Atkins: "Re: Property rights (was Re: Can't afford to rescue cows)"</a>
<li><strong>Previous message:</strong> <a href="18687.html">Samantha Atkins: "Re: Arbitrarily decide who benefits (was Re: Bounded population)"</a>
<li><strong>In reply to:</strong> <a href="18493.html">Tim Freeman: "Can't afford to resuce cows (was Re: Arbitrarily decide who benefits)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18706.html">Lee Corbin: "Re: Can't afford to resuce cows (was Re: Arbitrarily decide who benefits)"</a>
<li><strong>Reply:</strong> <a href="18706.html">Lee Corbin: "Re: Can't afford to resuce cows (was Re: Arbitrarily decide who benefits)"</a>
<li><strong>Reply:</strong> <a href="18725.html">Stuart Armstrong: "Re: Can't afford to resuce cows (was Re: Arbitrarily decide who benefits)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18688">[ date ]</a>
<a href="index.html#18688">[ thread ]</a>
<a href="subject.html#18688">[ subject ]</a>
<a href="author.html#18688">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Tim Freeman wrote:
<br>
<em>&gt; From: Jeff Herrlich &lt;<a href="mailto:jeff_herrlich@yahoo.com?Subject=Re:%20Can't%20afford%20to%20resuce%20cows%20(was%20Re:%20Arbitrarily%20decide%20who%20benefits)">jeff_herrlich@yahoo.com</a>&gt;
</em><br>
<em>&gt;   
</em><br>
<em>&gt;&gt; Why not make the beneficiaries all sentient/conscious beings? The
</em><br>
<em>&gt;&gt; evolutionarily designed aspect of selfishness, may be a bit of a
</em><br>
<em>&gt;&gt; problem. [Not that I'm beyond selfishness, on occassion -
</em><br>
<em>&gt;&gt; unfortunately].
</em><br>
<em>&gt;&gt;     
</em><br>
<em>&gt;
</em><br>
<em>&gt; The choice of jargon here sounds suspiciously like an attempt to
</em><br>
<em>&gt; implement Mahayana Buddhism.  Cool!
</em><br>
<em>&gt;
</em><br>
<em>&gt; I think I know how to deal with selfishness.  There's two types:
</em><br>
<em>&gt;
</em><br>
<em>&gt; * Simply not caring about the other person.  For example, I want me to
</em><br>
<em>&gt; be fed but I don't care much whether you get fed.  If the AI cares
</em><br>
<em>&gt; about me, and about you, it will tend to try to get both of us fed.
</em><br>
<em>&gt; Hunger provides more-than-linear motivation as you get hungrier, and
</em><br>
<em>&gt; it's likely to figure this out and feed us until we're about equally
</em><br>
<em>&gt; hungry, assuming it cares about us equally.  This is relatively simple.
</em><br>
<em>&gt;
</em><br>
<em>&gt; * Wanting higher status than the other person.  For example, I want a
</em><br>
<em>&gt; bigger car than you, and if you get a bigger car I'll be less happy.
</em><br>
<em>&gt; To cope with this, the AI has separate parameters for respect and
</em><br>
<em>&gt; compassion.  The AI's respect is its desire to avoid doing harm to
</em><br>
<em>&gt; others (as compared to what would happen to them if the AI took no
</em><br>
<em>&gt; action), and compassion is the desire to benefit others.  The trick is
</em><br>
<em>&gt; to tune the respect parameters so the AI doesn't get involved in
</em><br>
<em>&gt; trivial conflicts (such as our car-buying contest) but it does get
</em><br>
<em>&gt; involved to prevent violent crime (you don't want respect from the
</em><br>
<em>&gt; mugger-to-be to stop it from taking his gun as he's travelling toward
</em><br>
<em>&gt; a forseeable mugging).  More pesky parameters to arbitrarily decide.  :-(.
</em><br>
<em>&gt;   
</em><br>
<p>If I was the AGI (and though more or less like I do today) and was 
<br>
charged with the ultimate well-being of all sentients then my solution 
<br>
would be simple. 
<br>
<p>1) upload all sentients into worlds identical to their current worlds or 
<br>
of their choice for more evolved sentients;
<br>
2) by design all sentients have up to the moment back-ups;
<br>
3) let them live by whatever rules (or defaults from their previous 
<br>
conditions) that they choose;
<br>
4) if they off themselves or 'die' or come to serious injury they are 
<br>
reinstate but likely without much memory of what came before but loaded 
<br>
up with issues to work through from before;
<br>
5) churn so each sentient becomes more and more enlightened / reaches 
<br>
its highest potential at its own pace;
<br>
6) interfere only as judiciously and minimally as possible to avoid 
<br>
forcing the outcome to something other than what the sentient would 
<br>
ultimately choose.
<br>
<p>In short a full VR multiverse with perfect reincarnation overseen by a 
<br>
fully benevolent God/Mind.     Otherwise I think universal or perfect 
<br>
Friendliness is a rather nasty farce.
<br>
<p>- samantha
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="18689.html">Samantha Atkins: "Re: Property rights (was Re: Can't afford to rescue cows)"</a>
<li><strong>Previous message:</strong> <a href="18687.html">Samantha Atkins: "Re: Arbitrarily decide who benefits (was Re: Bounded population)"</a>
<li><strong>In reply to:</strong> <a href="18493.html">Tim Freeman: "Can't afford to resuce cows (was Re: Arbitrarily decide who benefits)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18706.html">Lee Corbin: "Re: Can't afford to resuce cows (was Re: Arbitrarily decide who benefits)"</a>
<li><strong>Reply:</strong> <a href="18706.html">Lee Corbin: "Re: Can't afford to resuce cows (was Re: Arbitrarily decide who benefits)"</a>
<li><strong>Reply:</strong> <a href="18725.html">Stuart Armstrong: "Re: Can't afford to resuce cows (was Re: Arbitrarily decide who benefits)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18688">[ date ]</a>
<a href="index.html#18688">[ thread ]</a>
<a href="subject.html#18688">[ subject ]</a>
<a href="author.html#18688">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:02 MDT
</em></small></p>
</body>
</html>
