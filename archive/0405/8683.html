<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Volitional Morality and Action Judgement</title>
<meta name="Author" content="Robin Lee Powell (rlpowell@digitalkingdom.org)">
<meta name="Subject" content="Re: Volitional Morality and Action Judgement">
<meta name="Date" content="2004-05-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Volitional Morality and Action Judgement</h1>
<!-- received="Mon May 24 11:01:01 2004" -->
<!-- isoreceived="20040524170101" -->
<!-- sent="Mon, 24 May 2004 10:00:58 -0700" -->
<!-- isosent="20040524170058" -->
<!-- name="Robin Lee Powell" -->
<!-- email="rlpowell@digitalkingdom.org" -->
<!-- subject="Re: Volitional Morality and Action Judgement" -->
<!-- id="20040524170058.GB10536@chain.digitalkingdom.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="02e801c441a1$558c88b0$6401a8c0@ZOMBIETHUSTRA" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Robin Lee Powell (<a href="mailto:rlpowell@digitalkingdom.org?Subject=Re:%20Volitional%20Morality%20and%20Action%20Judgement"><em>rlpowell@digitalkingdom.org</em></a>)<br>
<strong>Date:</strong> Mon May 24 2004 - 11:00:58 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8684.html">fudley: "Re: Volitional Morality and Action Judgement"</a>
<li><strong>Previous message:</strong> <a href="8682.html">Philip Sutton: "RE: Volitional Morality and Action Judgement"</a>
<li><strong>In reply to:</strong> <a href="8680.html">Ben Goertzel: "RE: Volitional Morality and Action Judgement"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8698.html">Eliezer Yudkowsky: "Re: Volitional Morality and Action Judgement"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8683">[ date ]</a>
<a href="index.html#8683">[ thread ]</a>
<a href="subject.html#8683">[ subject ]</a>
<a href="author.html#8683">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Mon, May 24, 2004 at 11:11:04AM -0400, Ben Goertzel wrote:
<br>
<em>&gt; &gt; Ben Goertzel wrote:
</em><br>
<em>&gt; &gt; &gt; 
</em><br>
<em>&gt; &gt; &gt; We've had this discussion before, but I can't help pointing out
</em><br>
<em>&gt; &gt; &gt; once more: We do NOT know enough about self-modifying AI systems
</em><br>
<em>&gt; &gt; &gt; to estimate accurately that there's a &quot;zero chance of accidental
</em><br>
<em>&gt; &gt; &gt; success&quot; in building an FAI.  Do you have a new proof of this that
</em><br>
<em>&gt; &gt; &gt; you'd like to share?  Or just the old hand-wavy attempts at
</em><br>
<em>&gt; &gt; &gt; arguments? ;-)
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; Ben?  Put yourself in my shoes for a moment and ask yourself the
</em><br>
<em>&gt; &gt; question: &quot;How do I prove to a medieval alchemist that there is no
</em><br>
<em>&gt; &gt; way to concoct an immortality serum by mixing random chemicals
</em><br>
<em>&gt; &gt; together?&quot;  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Pardon my skepticism, but I don't believe that the comparison of
</em><br>
<em>&gt; 
</em><br>
<em>&gt; A) your depth of knowledge about FAI, compared to mine
</em><br>
<em>&gt; 
</em><br>
<em>&gt; with
</em><br>
<em>&gt; 
</em><br>
<em>&gt; B) modern chemical, physical and biological science, versus the
</em><br>
<em>&gt; medieval state of knowledge about these things
</em><br>
<em>&gt; 
</em><br>
<em>&gt; is a good one.
</em><br>
<p>That would be true, if it was what he was comparing.
<br>
<p>What he's actually comparing is belief in the possibility of
<br>
accidentally creating FAI with belief in the possibility of accidentally
<br>
creating an immortality serum.  Actually, he wasn't even comparing even
<br>
that: he was comparing the risk factors associated with acting as though
<br>
each of those beliefs mirrored reality.
<br>
<p>We now know the latter is impossible (or at least we think we know it).
<br>
At this point, we have no idea if the former is possible or not; that
<br>
doesn't change the fact that *trying* to acheive the former is a very,
<br>
very bad idea, which is what the 90% of his example that you snipped was
<br>
talking about.
<br>
<p><em>&gt; Next, a note on terminology.  When you said &quot;it's impossible to create
</em><br>
<em>&gt; a FAI by accident&quot; I saw there were two possible interpretations
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 1) it's impossible to create an FAI without a well-worked-out theory
</em><br>
<em>&gt; of AI Friendliness, just by making a decently-designed AGI and
</em><br>
<em>&gt; teaching it
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 2) it's impossible to create an FAI without trying at all, e.g. by
</em><br>
<em>&gt; closing one's eyes and randomly typing code into the C compiler
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Of course, 2 is almost true, just like a monkey typing Shakespeare is
</em><br>
<em>&gt; extremely unlikely.  Since this interpretation of your statement is
</em><br>
<em>&gt; very uninteresting, I assumed you meant something like 1.  My
</em><br>
<em>&gt; statement is that, so far as I know, it's reasonably likely that
</em><br>
<em>&gt; building a decently-designed AGI and teaching it to be nice will lead
</em><br>
<em>&gt; to FAI.  
</em><br>
<p>You've just added a condition to your base conditions and used the
<br>
modified statement as a logical outgrowth of the base conditions,
<br>
without any chain of reasoning at all.  Your base conditions do *not*
<br>
say anything about teaching it to be nice.
<br>
<p>-Robin
<br>
<p><pre>
-- 
<a href="http://www.digitalkingdom.org/~rlpowell/">http://www.digitalkingdom.org/~rlpowell/</a>  ***  I'm a *male* Robin.
&quot;Many philosophical problems are caused by such things as the simple
inability to shut up.&quot; -- David Stove, liberally paraphrased.
<a href="http://www.lojban.org/">http://www.lojban.org/</a>  ***  loi pimlu na srana .i ti rokci morsi
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8684.html">fudley: "Re: Volitional Morality and Action Judgement"</a>
<li><strong>Previous message:</strong> <a href="8682.html">Philip Sutton: "RE: Volitional Morality and Action Judgement"</a>
<li><strong>In reply to:</strong> <a href="8680.html">Ben Goertzel: "RE: Volitional Morality and Action Judgement"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8698.html">Eliezer Yudkowsky: "Re: Volitional Morality and Action Judgement"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8683">[ date ]</a>
<a href="index.html#8683">[ thread ]</a>
<a href="subject.html#8683">[ subject ]</a>
<a href="author.html#8683">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
