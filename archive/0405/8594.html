<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: ethics</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: ethics">
<meta name="Date" content="2004-05-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: ethics</h1>
<!-- received="Wed May 19 23:25:12 2004" -->
<!-- isoreceived="20040520052512" -->
<!-- sent="Thu, 20 May 2004 01:25:07 -0400" -->
<!-- isosent="20040520052507" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: ethics" -->
<!-- id="40AC4133.2000102@pobox.com" -->
<!-- charset="windows-1252" -->
<!-- inreplyto="1085026893.10584.196814399@webmail.messagingengine.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20ethics"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Wed May 19 2004 - 23:25:07 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8595.html">Samantha Atkins: "Re: ethics"</a>
<li><strong>Previous message:</strong> <a href="8593.html">Samantha Atkins: "Re: ethics"</a>
<li><strong>In reply to:</strong> <a href="8590.html">fudley: "Re: ethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8601.html">fudley: "Re: ethics"</a>
<li><strong>Reply:</strong> <a href="8601.html">fudley: "Re: ethics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8594">[ date ]</a>
<a href="index.html#8594">[ thread ]</a>
<a href="subject.html#8594">[ subject ]</a>
<a href="author.html#8594">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
fudley wrote:
<br>
<p><em>&gt; On Wed, 19 May 2004 18:05:29 -0400, &quot;Eliezer S. Yudkowsky&quot;
</em><br>
<em>&gt; &lt;<a href="mailto:sentience@pobox.com?Subject=Re:%20ethics">sentience@pobox.com</a>&gt; said:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;I tried to reason about the incomprehensibility of superintelligence without 
</em><br>
<em>&gt;&gt;understanding where the incomprehensibility came from
</em><br>
<em>&gt; 
</em><br>
<em>&gt; There are 2 reasons people don’t understand something, too little
</em><br>
<em>&gt; information and too much complexity. In the case of an AI you have both
</em><br>
<em>&gt; problems.
</em><br>
<p>Too little information about something I build?  And the abstract 
<br>
invariant may generate &quot;unpredictable&quot; huge complexity, but it will be 
<br>
complexity guaranteed not to violate the invariant.
<br>
<p><em>&gt;&gt;*potentially* enables a human to fully understand some optimization 
</em><br>
<em>&gt;&gt;processes, including, I think, optimization processes with arbitrarily 
</em><br>
<em>&gt;&gt;large amounts of computing power. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; We’re talking about a brain the size of a planet but even retarded
</em><br>
<em>&gt; children retain the ability to surprise us, some can paint beautiful
</em><br>
<em>&gt; pictures, some can multiply enormous numbers in their head, and some like
</em><br>
<em>&gt; to cut people up with chain saws. And the fact that with just a few lines
</em><br>
<em>&gt; of code I can write a program that behaves in ways you can not predict
</em><br>
<em>&gt; does not bode well for the success of your enterprise. 
</em><br>
<p>Why?  I don't need to predict an arbitrary program you wrote.  I need to 
<br>
choose a dynamic process that predictably flows within certain invariants.
<br>
<p><em>&gt;&gt;The essential law of Friendly AI is that you cannot build an AI to 
</em><br>
<em>&gt;&gt;accomplish any end for which you do not possess a well-specified 
</em><br>
<em>&gt;&gt;*abstract* description. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Any intelligence worthy of the name will eventually start to set its own
</em><br>
<em>&gt; goals; being happy seems like a reasonable one to set, and nobody knows
</em><br>
<em>&gt; where that will lead. 
</em><br>
<p>Hence the talking about &quot;optimization processes&quot;.  You are making all 
<br>
sorts of statements about &quot;intelligences&quot; &quot;worthy of the name&quot; that are as 
<br>
orthogonal to Friendly AI as they are orthogonal to natural selection.
<br>
<p><em>&gt;&gt;You may be thinking that &quot;intelligences&quot; have self-centered &quot;best interests&quot;.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I do indeed.
</em><br>
<p>If we are talking about things likely to pop up in the real world, rather 
<br>
than the space of things that are worthy of names, then you are making a 
<br>
rather large error.  The fruits of anthropomorphism; using human empathy 
<br>
to model things that aren't human.
<br>
<p>Didn't you just get through saying to me that you didn't understand 
<br>
&quot;intelligences&quot;?  How are you making all these wonderful predictions about 
<br>
them?  By putting yourself in their shoes, and expecting them to behave 
<br>
like other things you know.  That trick flat-out doesn't work, period.
<br>
<p><em>&gt;&gt;Rather than arguing about intelligence, I would prefer to talk
</em><br>
<em>&gt;&gt;about optimization processes
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I’m confused, do you want to make an artificial intelligence or an
</em><br>
<em>&gt; artificial optimization process.
</em><br>
<p>I want to embody a kind of dynamic called a Friendly AI.  An FAI is 
<br>
definitely an optimization process.  I have no idea what you think 
<br>
&quot;intelligence&quot; is, except that you claim not to be able to understand it 
<br>
when you add computing power to it, and that you think it will have a 
<br>
self-centered goal system.
<br>
<p><em>&gt;&gt;Optimization processes direct futures into small targets in phase space. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Then what you call optimization processes are just a low rent version of
</em><br>
<em>&gt; inelegance incapable of producing novelty.  Why even bother to build one? 
</em><br>
<p>Not true.  An optimization process can have complicated ends, and can find 
<br>
novel means to those ends.  What I would guarantee is that they will be 
<br>
good ends, and that the novel means will not stomp on those ends.  This I 
<br>
think I can do within an optimization process, whatever you believe about 
<br>
&quot;intelligence&quot;.
<br>
<p><em>&gt;&gt;An FAI ain't a &quot;hugely complicated program&quot;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Huh?!
</em><br>
<p>An FAI doesn't share the characteristics of &quot;hugely complicated programs&quot; 
<br>
as you know them.  It may be a complex dynamic, but it's not a computer 
<br>
program as you know it.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8595.html">Samantha Atkins: "Re: ethics"</a>
<li><strong>Previous message:</strong> <a href="8593.html">Samantha Atkins: "Re: ethics"</a>
<li><strong>In reply to:</strong> <a href="8590.html">fudley: "Re: ethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8601.html">fudley: "Re: ethics"</a>
<li><strong>Reply:</strong> <a href="8601.html">fudley: "Re: ethics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8594">[ date ]</a>
<a href="index.html#8594">[ thread ]</a>
<a href="subject.html#8594">[ subject ]</a>
<a href="author.html#8594">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
