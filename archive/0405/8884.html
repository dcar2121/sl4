<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: FAI: Collective Volition</title>
<meta name="Author" content="Aubrey de Grey (ag24@gen.cam.ac.uk)">
<meta name="Subject" content="Re: FAI: Collective Volition">
<meta name="Date" content="2004-05-31">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: FAI: Collective Volition</h1>
<!-- received="Mon May 31 10:08:45 2004" -->
<!-- isoreceived="20040531160845" -->
<!-- sent="Mon, 31 May 2004 17:08:28 +0100" -->
<!-- isosent="20040531160828" -->
<!-- name="Aubrey de Grey" -->
<!-- email="ag24@gen.cam.ac.uk" -->
<!-- subject="Re: FAI: Collective Volition" -->
<!-- id="E1BUpKu-0001H0-00@ag24.gen.cam.ac.uk" -->
<!-- inreplyto="FAI: Collective Volition" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Aubrey de Grey (<a href="mailto:ag24@gen.cam.ac.uk?Subject=Re:%20FAI:%20Collective%20Volition"><em>ag24@gen.cam.ac.uk</em></a>)<br>
<strong>Date:</strong> Mon May 31 2004 - 10:08:28 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8885.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<li><strong>Previous message:</strong> <a href="8883.html">Mark Waser: "Re: One or more AIs??"</a>
<li><strong>Maybe in reply to:</strong> <a href="8881.html">Eliezer Yudkowsky: "FAI: Collective Volition"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8885.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<li><strong>Reply:</strong> <a href="8885.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8884">[ date ]</a>
<a href="index.html#8884">[ thread ]</a>
<a href="subject.html#8884">[ subject ]</a>
<a href="author.html#8884">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eli, many thanks for writing this extremely clear and thorough piece.
<br>
I will never think of the islets of Langerhans in quite the same way
<br>
again....
<br>
<p><em>&gt;From your mention at many points in the essay of controlled shutdown,
</em><br>
it seems to me that you are gravitating rather rapidly to the position
<br>
that I instinctively have on FAI, which is that a true FAI will do very
<br>
little indeed in the way of altering our environment but will concern
<br>
itself strictly with pre-empting events that cause huge loss of life.
<br>
Any &quot;interference&quot; in more minor matters will be seen (by it, if not
<br>
in advance by its designers) as having drawbacks in terms of our wish
<br>
for collective self-determination that outweigh its benefits.  [It may
<br>
go even further than that, of course -- e.g., it may decide that the
<br>
very presence of a super-human intelligence, i.e. it, detracts from
<br>
humanity's self-image so much that it shuts itself down and leaves us
<br>
to our own devices.  But I digress.]
<br>
<p>If we assume the above, the question that would seem to be epistatic to
<br>
all others is whether the risks to life inherent in attempting to build
<br>
a FAI (because one might build an unfriendly one) outweigh the benefits
<br>
that success would give in reducing other risks to life.  So, what are
<br>
those benefits? -- how would the FAI actually pre-empt loss of life?
<br>
Browsing Nick Bostrom's essay on existential risks, and in particular
<br>
the &quot;bangs&quot; category, has confirmed my existing impression that bangs
<br>
involving human action are far more likely than ones only involving
<br>
human inaction (such as asteroid impacts).  Hence, the FAI's job is to
<br>
stop humans from doing risky things.  Here's where I get stuck: how
<br>
does the FAI have the physical (as opposed to the cognitive) ability
<br>
to do this?  Surely only by advising other humans on what actions THEY
<br>
should take to stop the risky actions: any other method would involve
<br>
stopping us doing things without our agreeing on their riskiness, which
<br>
violates the self-determination criterion.  But surely that is a big
<br>
gaping hole in the whole idea, because the humans who obtain the FAI's
<br>
advice can take it or leave it, just as Kennedy could take or leave the
<br>
advice he received during the Cuba missile crisis.  The whole edifice
<br>
relies, surely, on people voting for people who respect the advice of
<br>
the FAI more than that of human advisors.  That may well happen, but it
<br>
might not be very well publicised, to say the least.
<br>
<p>What is wrong with this scenario?
<br>
<p>Aubrey de Grey
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8885.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<li><strong>Previous message:</strong> <a href="8883.html">Mark Waser: "Re: One or more AIs??"</a>
<li><strong>Maybe in reply to:</strong> <a href="8881.html">Eliezer Yudkowsky: "FAI: Collective Volition"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8885.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<li><strong>Reply:</strong> <a href="8885.html">Eliezer Yudkowsky: "Re: FAI: Collective Volition"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8884">[ date ]</a>
<a href="index.html#8884">[ thread ]</a>
<a href="subject.html#8884">[ subject ]</a>
<a href="author.html#8884">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
