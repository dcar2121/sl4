<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Dangers of human self-modification</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Dangers of human self-modification">
<meta name="Date" content="2004-05-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Dangers of human self-modification</h1>
<!-- received="Wed May 26 08:39:19 2004" -->
<!-- isoreceived="20040526143919" -->
<!-- sent="Wed, 26 May 2004 10:39:04 -0400" -->
<!-- isosent="20040526143904" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Dangers of human self-modification" -->
<!-- id="057501c4432f$31dff020$6401a8c0@ZOMBIETHUSTRA" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="40B536A1.17403.19CE493@localhost" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Dangers%20of%20human%20self-modification"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Wed May 26 2004 - 08:39:04 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8715.html">Jef Allbright: "Re: Dangers of human self-modification"</a>
<li><strong>Previous message:</strong> <a href="8713.html">Philip Sutton: "RE: Dangers of human self-modification"</a>
<li><strong>In reply to:</strong> <a href="8713.html">Philip Sutton: "RE: Dangers of human self-modification"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8716.html">Philip Sutton: "RE: Dangers of human self-modification"</a>
<li><strong>Reply:</strong> <a href="8716.html">Philip Sutton: "RE: Dangers of human self-modification"</a>
<li><strong>Reply:</strong> <a href="8717.html">fudley: "RE: Dangers of human self-modification"</a>
<li><strong>Reply:</strong> <a href="8827.html">Samantha Atkins: "Re: Dangers of human self-modification"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8714">[ date ]</a>
<a href="index.html#8714">[ thread ]</a>
<a href="subject.html#8714">[ subject ]</a>
<a href="author.html#8714">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; If you could find a way to plug massive accurate modelling 
</em><br>
<em>&gt; capacity in 
</em><br>
<em>&gt; biological humans by figuring out how we could grow a neo-neo-cortex 
</em><br>
<em>&gt; (or whatever) and how we can grow links between minds to achieve 
</em><br>
<em>&gt; stable and reliable distributed mentation - then this sort of 
</em><br>
<em>&gt; modification 
</em><br>
<em>&gt; might make a difference!
</em><br>
<em>&gt; 
</em><br>
<em>&gt; But I don't think this breakthrough (in physical enhancement of 
</em><br>
<em>&gt; humans) is all that critical as we can get nearly the same effect if 
</em><br>
<em>&gt; people and machine modelling intelligences work together using 
</em><br>
<em>&gt; telecommunications as the glue.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Cheers, Philip
</em><br>
<p>Philip, I understand your point but I don't agree with it.  I'm much
<br>
more pessimistic about human nature.
<br>
<p>Two things could come from genetically engineering of wise humans:
<br>
<p>1) a vastly greater incidence of individuals as wise as the
<br>
maximally-wise humans on Earth today
<br>
<p>2) the creation of humans who are 2 or 10 times as wise (yeah I know, we
<br>
have measurement problems here) as any human alive today
<br>
<p>Either one of these would make a big difference, eh?
<br>
<p>I just have very little faith in the ability of sociocultural change to
<br>
elevate the wisdom level of the race.
<br>
<p>In fact, I have little faith that genetic engineering will be used to
<br>
create ultrawise beings either -- I reckon it will be used first to
<br>
create superintelligent killing machines.  And my bet is still that
<br>
superhuman AGI will come before any of these things, due to the slower
<br>
pace of experimentation in human genetic engineering enforced by
<br>
society's ethical concerns about experimentation on humans.
<br>
<p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8715.html">Jef Allbright: "Re: Dangers of human self-modification"</a>
<li><strong>Previous message:</strong> <a href="8713.html">Philip Sutton: "RE: Dangers of human self-modification"</a>
<li><strong>In reply to:</strong> <a href="8713.html">Philip Sutton: "RE: Dangers of human self-modification"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8716.html">Philip Sutton: "RE: Dangers of human self-modification"</a>
<li><strong>Reply:</strong> <a href="8716.html">Philip Sutton: "RE: Dangers of human self-modification"</a>
<li><strong>Reply:</strong> <a href="8717.html">fudley: "RE: Dangers of human self-modification"</a>
<li><strong>Reply:</strong> <a href="8827.html">Samantha Atkins: "Re: Dangers of human self-modification"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8714">[ date ]</a>
<a href="index.html#8714">[ thread ]</a>
<a href="subject.html#8714">[ subject ]</a>
<a href="author.html#8714">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
