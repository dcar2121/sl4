<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: ethics</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: ethics">
<meta name="Date" content="2004-05-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: ethics</h1>
<!-- received="Wed May 19 23:42:24 2004" -->
<!-- isoreceived="20040520054224" -->
<!-- sent="Wed, 19 May 2004 22:42:22 -0700" -->
<!-- isosent="20040520054222" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: ethics" -->
<!-- id="77676108-AA20-11D8-86D4-000A95B1AFDE@objectent.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="40ABC916.4050904@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20ethics"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Wed May 19 2004 - 23:42:22 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8597.html">Samantha Atkins: "Re: ethics"</a>
<li><strong>Previous message:</strong> <a href="8595.html">Samantha Atkins: "Re: ethics"</a>
<li><strong>In reply to:</strong> <a href="8583.html">Eliezer S. Yudkowsky: "Re: ethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8606.html">Thomas Buckner: "Re: ethics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8596">[ date ]</a>
<a href="index.html#8596">[ thread ]</a>
<a href="subject.html#8596">[ subject ]</a>
<a href="author.html#8596">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On May 19, 2004, at 1:52 PM, Eliezer S. Yudkowsky wrote:
<br>
<p><em>&gt; Christopher Healey wrote:
</em><br>
<em>&gt;&gt; John,
</em><br>
<em>&gt;&gt; My quote was truncated.  it should read:
</em><br>
<em>&gt;&gt;&gt; any black-box emergent-complexity solution is to be avoided &gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; almost without exception &lt;&lt;&lt;
</em><br>
<em>&gt;&gt; The primary point I was supporting is that if you CAN choose, ALWAYS
</em><br>
<em>&gt;&gt; choose the more predictable path UNLESS the potential risk of NOT 
</em><br>
<em>&gt;&gt; doing
</em><br>
<em>&gt;&gt; so is greater.  Under a known race-to-singularity situation, it may be
</em><br>
<em>&gt;&gt; the more rational choice to trade off a relative amount of
</em><br>
<em>&gt;&gt; predictability for first-to-take-off status.  This modifier to the
</em><br>
<em>&gt;&gt; rule, while valid, seems more likely to be used as an &quot;end justifies
</em><br>
<em>&gt;&gt; means&quot; rationalization by those who would act irresponsibly, so I'd be
</em><br>
<em>&gt;&gt; suprised if the SIAI focuses on that part of it in their pop campaign.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I would presently support the flat general rule that things which look 
</em><br>
<em>&gt; like minor problems, but which you don't quite understand, are blocker 
</em><br>
<em>&gt; problems until fathomed completely.  Mostly because of the number of 
</em><br>
<em>&gt; things I have encountered which looked like minor problems, and which 
</em><br>
<em>&gt; I didn't quite understand, and which - as it turned out, after I 
</em><br>
<em>&gt; learned the rules - I desperately needed to understand.
</em><br>
<em>&gt;
</em><br>
<p>If you really follow this approach I do not believe you will ever build 
<br>
a working SAI.  There are problems involved  and complexities of 
<br>
possible solutions as they unfold over time that no human brain, not 
<br>
even yours, is capable of fathoming completely.   I am quite certain 
<br>
you know this.
<br>
<p><p><em>&gt; I don't think there will be a good reason for using probabilistic 
</em><br>
<em>&gt; self-modification techniques, ever.  Deductive self-modification 
</em><br>
<em>&gt; should be quite sufficient.  There's a difference between hope and 
</em><br>
<em>&gt; creating a system that can be rationally predicted to work, and the 
</em><br>
<em>&gt; difference is that hope doesn't help.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The part about the &quot;rational tradeoff&quot; ignores the fact that until you 
</em><br>
<em>&gt; understand something, you have no idea how much you need to understand 
</em><br>
<em>&gt; it; you are simply guessing.  Every time I see someone try to get away 
</em><br>
<em>&gt; with this guess, including my memories of my past self, they are 
</em><br>
<em>&gt; lethally wrong.  To build an FAI you must aspire to a higher level of 
</em><br>
<em>&gt; understanding than poking around in design space until you find 
</em><br>
<em>&gt; something that appears to work.
</em><br>
<em>&gt;
</em><br>
<p>Given the capacity of the human mind there is no way not to make 
<br>
educated guesses beyond a certain point.  That point comes more quickly 
<br>
than any of us would like.  We must aspire to the highest level of 
<br>
understand we can achieve.  But there is no sense lying to ourselves 
<br>
that we can always take the time to fully understand or that any 
<br>
conceivable amount of time will bring full understanding of all the 
<br>
problems given our mental limitations.
<br>
<p><em>&gt; I do not expect anyone who *actually* understands FAI to *ever* use 
</em><br>
<em>&gt; the argument of &quot;We don't understand this, but we'll use it anyway 
</em><br>
<em>&gt; because of &lt;nitwit utilitarian argument&gt;.&quot;  The nitwit argument only 
</em><br>
<em>&gt; applies because the speaker is too ignorant to realize that they have 
</em><br>
<em>&gt; *no* chance of success, that the *only* reason they think they can 
</em><br>
<em>&gt; build an FAI without understanding is that they lack the understanding 
</em><br>
<em>&gt; to know this is impossible.
</em><br>
<em>&gt;
</em><br>
<p>You are painting yourself into a corner.
<br>
<p>- samantha
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8597.html">Samantha Atkins: "Re: ethics"</a>
<li><strong>Previous message:</strong> <a href="8595.html">Samantha Atkins: "Re: ethics"</a>
<li><strong>In reply to:</strong> <a href="8583.html">Eliezer S. Yudkowsky: "Re: ethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8606.html">Thomas Buckner: "Re: ethics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8596">[ date ]</a>
<a href="index.html#8596">[ thread ]</a>
<a href="subject.html#8596">[ subject ]</a>
<a href="author.html#8596">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
