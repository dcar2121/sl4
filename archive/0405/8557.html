<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Volitional Morality and Action Judgement</title>
<meta name="Author" content="Thomas Buckner (tcbevolver@yahoo.com)">
<meta name="Subject" content="Re: Volitional Morality and Action Judgement">
<meta name="Date" content="2004-05-16">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Volitional Morality and Action Judgement</h1>
<!-- received="Sun May 16 01:14:35 2004" -->
<!-- isoreceived="20040516071435" -->
<!-- sent="Sun, 16 May 2004 00:14:12 -0700 (PDT)" -->
<!-- isosent="20040516071412" -->
<!-- name="Thomas Buckner" -->
<!-- email="tcbevolver@yahoo.com" -->
<!-- subject="Re: Volitional Morality and Action Judgement" -->
<!-- id="20040516071412.33209.qmail@web60003.mail.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="CC332456-A579-11D8-84B2-000A95A0F1E8@randallsquared.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas Buckner (<a href="mailto:tcbevolver@yahoo.com?Subject=Re:%20Volitional%20Morality%20and%20Action%20Judgement"><em>tcbevolver@yahoo.com</em></a>)<br>
<strong>Date:</strong> Sun May 16 2004 - 01:14:12 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8558.html">Keith Henson: "Re: Volitional Morality and Action Judgement"</a>
<li><strong>Previous message:</strong> <a href="8556.html">Thomas Buckner: "Re: Volitional Morality and Action Judgement"</a>
<li><strong>In reply to:</strong> <a href="8536.html">Randall Randall: "Re: Volitional Morality and Action Judgement"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8558.html">Keith Henson: "Re: Volitional Morality and Action Judgement"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8557">[ date ]</a>
<a href="index.html#8557">[ thread ]</a>
<a href="subject.html#8557">[ subject ]</a>
<a href="author.html#8557">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; &gt;Suppose I know I
</em><br>
<em>&gt; will be probably
</em><br>
<em>&gt; &gt; ruined if I continue gambling, but I decide to do
</em><br>
<em>&gt; it anyway. I'm then
</em><br>
<em>&gt; &gt; doing what is not in my best interest to do. I'm
</em><br>
<em>&gt; then acting
</em><br>
<em>&gt; &gt; irrationally. Eliezer's maxim, then, becomes
</em><br>
<em>&gt; inapplicable. To assess 
</em><br>
<em>&gt; &gt; the
</em><br>
<em>&gt; &gt; agent's behavior we must look for an alternative
</em><br>
<em>&gt; rationale.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Either you are using the term &quot;best interest&quot; for
</em><br>
<em>&gt; something I would
</em><br>
<em>&gt; not use that term for, or you are making the mistake
</em><br>
<em>&gt; of assuming
</em><br>
<em>&gt; that a single objective &quot;best interest&quot; exists which
</em><br>
<em>&gt; can be determined
</em><br>
<em>&gt; by an outside observer.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; In order to determine a person's best interest, you
</em><br>
<em>&gt; would have to
</em><br>
<em>&gt; weigh their options against their goal system (not
</em><br>
<em>&gt; yours!) and
</em><br>
<em>&gt; choose the best option which is consistent with that
</em><br>
<em>&gt; goal system.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Unless you are intelligent enough to closely
</em><br>
<em>&gt; simulate that person,
</em><br>
<em>&gt; however (and no human currently is), you are
</em><br>
<em>&gt; unlikely to be able
</em><br>
<em>&gt; to make such a determination, so you must accept the
</em><br>
<em>&gt; person's own
</em><br>
<em>&gt; decisions as the closest approximation to their
</em><br>
<em>&gt; &quot;best interest&quot;
</em><br>
<em>&gt; that you can find.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; --
</em><br>
<em>&gt; Randall Randall
</em><br>
<em>&gt; &lt;<a href="mailto:randall@randallsquared.com?Subject=Re:%20Volitional%20Morality%20and%20Action%20Judgement">randall@randallsquared.com</a>&gt; (706) 536-2674
</em><br>
<em>&gt; Remote administration -- web applications --
</em><br>
<em>&gt; consulting
</em><br>
<em>&gt; 
</em><br>
I can see a partial line of attack on that problem, as
<br>
follows:
<br>
You offer the example that an excessive gambler may be
<br>
'ruined', but the ramifications are not laid out in
<br>
the detail an AI might want. The ethical outcomes
<br>
vary, and thus the ethical imperatives.
<br>
Will the gambler ruin several (or many) other lives in
<br>
hir excess? Then hes should be impeded for the good of
<br>
other sentient beings.
<br>
<p>Will the gambler physically die? Then, again, an AI
<br>
may choose to intervene (there's a word for this
<br>
process: it's called an intervention!) and take
<br>
various means of persuasion or coercion to keep a
<br>
fellow sentient from self-destructing out of sheer
<br>
thoughtlessness. This is like your relatives hiding
<br>
your cigarettes: perhaps you 'know' they're bad for
<br>
your body but have an addiction to that nicotine (and
<br>
a 'tomorrow never gets here' sort of rationalizing
<br>
attitude; but it does get here, you know...)This is
<br>
the sort of unconscious suicide we see all around us,
<br>
almost daily if your town's big enough.
<br>
<p>Does the gambler know that death may follow, and
<br>
choose this risk (or certainty) while offering a good
<br>
rational ethical defense of hir choice? Then the AI
<br>
ought to at least consider staying out of the way, as
<br>
should we.
<br>
Your example implies strongly that you may have a
<br>
hidden supergoal which IS served by self-destruction.
<br>
If you cannot articulate it, it's unlikely that you
<br>
can defend it rationally. You may only assert that you
<br>
have an intuition, that your destruction will somehow
<br>
serve a goal larger than your continued conscious
<br>
existence. I am not saying your sincerity might not
<br>
somehow convince a SAI, but my belief is that ve will
<br>
tend to want to keep you around.
<br>
The alternative form of being 'ruined' is that you do
<br>
not die, nor create misery or death for others, but
<br>
simply have some bad experiences of your own. Perhaps
<br>
they are very, very bad experiences, but the
<br>
possibility will still remain that you have survived
<br>
and learned something from your travails. An SAI might
<br>
find that very acceptable, as long as it gets to
<br>
watch.
<br>
To continue the smoking metaphor, it might insist on
<br>
keeping you alive while everything but your brain
<br>
shrivels, if you're that stubborn, and then restoring
<br>
you when you turn over that new leaf.
<br>
OR...
<br>
It might actively interfere with the debt process. You
<br>
might (post-FAI) find yourself in a reality tunnel
<br>
where you never lose at cards, or wake up rich even
<br>
after losing; where you never get a hangover or run
<br>
out of whiskey; where your lungs feel fine after a
<br>
night of smoking railway ties, and you can eat lead
<br>
out of stained glass windows like it was beef jerky,
<br>
and not get poisoned; a dream world, an anthroparium.
<br>
Hmmm, that'd work. Remember, a SAI that could emulate
<br>
you could keep you like a museum display under glass,
<br>
and you'd never notice.
<br>
<p>=====
<br>
<p><p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
__________________________________
<br>
Do you Yahoo!?
<br>
SBC Yahoo! - Internet access at a great low price.
<br>
<a href="http://promo.yahoo.com/sbc/">http://promo.yahoo.com/sbc/</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8558.html">Keith Henson: "Re: Volitional Morality and Action Judgement"</a>
<li><strong>Previous message:</strong> <a href="8556.html">Thomas Buckner: "Re: Volitional Morality and Action Judgement"</a>
<li><strong>In reply to:</strong> <a href="8536.html">Randall Randall: "Re: Volitional Morality and Action Judgement"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8558.html">Keith Henson: "Re: Volitional Morality and Action Judgement"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8557">[ date ]</a>
<a href="index.html#8557">[ thread ]</a>
<a href="subject.html#8557">[ subject ]</a>
<a href="author.html#8557">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
