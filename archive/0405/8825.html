<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Volitional Morality and Action Judgement</title>
<meta name="Author" content="Michael Roy Ames (michaelroyames@yahoo.com)">
<meta name="Subject" content="Re: Volitional Morality and Action Judgement">
<meta name="Date" content="2004-05-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Volitional Morality and Action Judgement</h1>
<!-- received="Sat May 29 16:36:33 2004" -->
<!-- isoreceived="20040529223633" -->
<!-- sent="Sat, 29 May 2004 15:36:09 -0700" -->
<!-- isosent="20040529223609" -->
<!-- name="Michael Roy Ames" -->
<!-- email="michaelroyames@yahoo.com" -->
<!-- subject="Re: Volitional Morality and Action Judgement" -->
<!-- id="09a901c445cd$569ba670$6401a8c0@mra02" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="00c501c445ab$901f48b0$0100a8c0@FamilyRoom" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Roy Ames (<a href="mailto:michaelroyames@yahoo.com?Subject=Re:%20Volitional%20Morality%20and%20Action%20Judgement"><em>michaelroyames@yahoo.com</em></a>)<br>
<strong>Date:</strong> Sat May 29 2004 - 16:36:09 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8826.html">Thomas Buckner: "RE: Volitional Morality and Action Judgement"</a>
<li><strong>Previous message:</strong> <a href="8824.html">Paul Hughes: "Re: Indeterminacy and Intelligence"</a>
<li><strong>In reply to:</strong> <a href="8823.html">Mark Waser: "Re: Volitional Morality and Action Judgement"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8828.html">Philip Sutton: "One or more FAIs??"</a>
<li><strong>Reply:</strong> <a href="8828.html">Philip Sutton: "One or more FAIs??"</a>
<li><strong>Reply:</strong> <a href="8829.html">Mark Waser: "Re: Volitional Morality and Action Judgement"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8825">[ date ]</a>
<a href="index.html#8825">[ thread ]</a>
<a href="subject.html#8825">[ subject ]</a>
<a href="author.html#8825">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Mark Waser,
<br>
<p>You wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; Once Eliezer is no longer willing to engage with
</em><br>
<em>&gt; an individual who is probably closest to him in
</em><br>
<em>&gt; terms of understanding/drive/etc., then,
</em><br>
<em>&gt; &lt;italicized&gt;in my way of looking at things&lt;/italics&gt;
</em><br>
<em>&gt; Eliezer has forfeited a huge chunk of his
</em><br>
<em>&gt; responsibility/moral authority/effectiveness/whatever.
</em><br>
<em>&gt;
</em><br>
<p>Being unwilling to engage another in debate forfeits nothing, except the
<br>
engagement.
<br>
<p><p><em>&gt;
</em><br>
<em>&gt; I also think that there are a number of missed
</em><br>
<em>&gt; opportunities both in the theory and in the attempt
</em><br>
<em>&gt; at spreading the meme.
</em><br>
<em>&gt;
</em><br>
<p>Could you detail those opportunities and why you consider them missed?
<br>
<p><p><em>&gt;
</em><br>
<em>&gt; 1.  Why do you believe that a single FAI is the best strategy?
</em><br>
<em>&gt;
</em><br>
<p>a) It is simpler to create.
<br>
<p>b) Having one being around with the capability of destroying humanity is
<br>
less risk than having more than one, in the same way as having one human
<br>
being with a Pocket Planetary Destruct (TM) device is less risky than having
<br>
more than one.
<br>
<p><p><em>&gt;
</em><br>
<em>&gt; To me, it's a single point of failure or like a
</em><br>
<em>&gt; mono-culture of crops in agriculture. One mistake
</em><br>
<em>&gt; or one disease and POOF! smiley faces everywhere.
</em><br>
<em>&gt;
</em><br>
<p>This is a false analogy.  With crops there are many species and varieties
<br>
that will approach the desired result more or less closely.  Choosing a
<br>
variety that doesn't produce well doesn't end humanity.  With an RSI AI the
<br>
outcome becomes binary: some sort of continued life, or annihilation.  This
<br>
is not a false dichotomy; life/death is about as binary as you can get.
<br>
<p><p><em>&gt;
</em><br>
<em>&gt; Why do you think that NASA uses multiply redundant
</em><br>
<em>&gt; systems?
</em><br>
<em>&gt;
</em><br>
<p>The multiply redundant systems for NASA's launch vehicles were created
<br>
because having them reduces the overall risk of failure.  This is not true
<br>
of RSI AI.  An RSI AI is analogous to an entire launch vehicle that might
<br>
kill you.  If launching the first one doesn't kill you, then you might try
<br>
again, but otherwise you're dead.
<br>
<p><p><em>&gt;
</em><br>
<em>&gt; 2.  Why do you believe that relying on Eliezer and
</em><br>
<em>&gt; only Eliezer is a good strategy.
</em><br>
<em>&gt;
</em><br>
<p>It is a lousy idea.  I don't believe MW ever said it was a good idea.
<br>
<p><p><em>&gt;
</em><br>
<em>&gt; [snip] I do expect serious engagement with the most
</em><br>
<em>&gt; seriously engaged other participants.
</em><br>
<em>&gt;
</em><br>
<p>It *is* always enjoyable when that happens, and often informative, but
<br>
perhaps you shouldn't always expect it.  Sometimes people simply disagree
<br>
about ideas, we *are* all running on slightly different brainware and
<br>
different knowledge bases.  Once an idea has been beaten to death, with
<br>
little progress on either side, then it is sometimes worthwhile to
<br>
disengage.
<br>
<p><p><em>&gt;
</em><br>
<em>&gt; Eliezer has devolved to &quot;everything is too dangerous&quot;
</em><br>
<em>&gt; but &quot;I'm much too busy to discuss it or even write it
</em><br>
<em>&gt; up for anybody&quot; and I think that is a REALLY BAD
</em><br>
<em>&gt; THING(tm).
</em><br>
<em>&gt;
</em><br>
<p>I suspect this is a REALLY BAD THING(tm) to you because you may be relying
<br>
on Eliezer.  My advice is: don't.  One of SIAI's stated goals is to grow its
<br>
programmer team, and with that team improve and develop FAI.  Either
<br>
donating yourself, or persuading others to donate would help tremendously
<br>
toward that goal.  And part of that goal is: &quot;making it so that Eliezer is
<br>
neither considered to be nor in fact a failure point or bottleneck.&quot;
<br>
<p>In the Ben vs. Eliezer debates each party has a set of cognitive models they
<br>
are using to reason about the ideas.  Ben's model projects outcomes along
<br>
one trajectory, Eliezer's along another.  The models are complex, and would
<br>
not be easy to communicate using human language, even if both parties had
<br>
perfect introspection, which they do not.  The parties may never agree until
<br>
one of them builds a working AI and points at it saying: &quot;There. That's what
<br>
I'm talking about.&quot;
<br>
<p><p>Michael Roy Ames
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8826.html">Thomas Buckner: "RE: Volitional Morality and Action Judgement"</a>
<li><strong>Previous message:</strong> <a href="8824.html">Paul Hughes: "Re: Indeterminacy and Intelligence"</a>
<li><strong>In reply to:</strong> <a href="8823.html">Mark Waser: "Re: Volitional Morality and Action Judgement"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8828.html">Philip Sutton: "One or more FAIs??"</a>
<li><strong>Reply:</strong> <a href="8828.html">Philip Sutton: "One or more FAIs??"</a>
<li><strong>Reply:</strong> <a href="8829.html">Mark Waser: "Re: Volitional Morality and Action Judgement"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8825">[ date ]</a>
<a href="index.html#8825">[ thread ]</a>
<a href="subject.html#8825">[ subject ]</a>
<a href="author.html#8825">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
