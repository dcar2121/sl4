<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Dangers of human self-modification</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Dangers of human self-modification">
<meta name="Date" content="2004-05-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Dangers of human self-modification</h1>
<!-- received="Mon May 24 14:25:47 2004" -->
<!-- isoreceived="20040524202547" -->
<!-- sent="Mon, 24 May 2004 16:25:37 -0400" -->
<!-- isosent="20040524202537" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Dangers of human self-modification" -->
<!-- id="034701c441cd$46ec5110$6401a8c0@ZOMBIETHUSTRA" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="40B25760.1030904@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Dangers%20of%20human%20self-modification"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Mon May 24 2004 - 14:25:37 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8692.html">Keith Henson: "Re: Volitional Morality and Action Judgement"</a>
<li><strong>Previous message:</strong> <a href="8690.html">Eliezer Yudkowsky: "Re: Dangers of human self-modification"</a>
<li><strong>In reply to:</strong> <a href="8690.html">Eliezer Yudkowsky: "Re: Dangers of human self-modification"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8709.html">Samantha Atkins: "Re: Dangers of human self-modification"</a>
<li><strong>Reply:</strong> <a href="8709.html">Samantha Atkins: "Re: Dangers of human self-modification"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8691">[ date ]</a>
<a href="index.html#8691">[ thread ]</a>
<a href="subject.html#8691">[ subject ]</a>
<a href="author.html#8691">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Fudley,
<br>
<p>Put concisely, one of the main problems is: If you're modifying a human
<br>
brain to be twice as smart, how can you be sure your modification won't
<br>
have the side-effect of causing that human brain to feel like
<br>
irresponsibly creating dangerous seed AI's or gray-goo-producing
<br>
nanotech?  
<br>
<p>Human brain mods that don't increase intelligence dramatically are
<br>
relatively safe in existential terms, but human brain modes that do
<br>
increase intelligence dramatically are potentially dangerous by virtue
<br>
of the dangerous tech that smart humans may play with.  
<br>
<p>I'm not saying that smart humans will necessarily become evil or
<br>
careless -- in fact I think the opposite is more closely true -- but
<br>
it's clear that it will be hard to predict the ethical inclinations and
<br>
quality-of-judgment of intelligence-enhanced humans.
<br>
<p>-- Ben
<br>
<p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Dangers%20of%20human%20self-modification">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Dangers%20of%20human%20self-modification">owner-sl4@sl4.org</a>] On Behalf 
</em><br>
<em>&gt; Of Eliezer Yudkowsky
</em><br>
<em>&gt; Sent: Monday, May 24, 2004 4:13 PM
</em><br>
<em>&gt; To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Dangers%20of%20human%20self-modification">sl4@sl4.org</a>
</em><br>
<em>&gt; Subject: Re: Dangers of human self-modification
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; fudley wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; On Sun, 23 May 2004 &quot;Eliezer Yudkowsky&quot; &lt;<a href="mailto:sentience@pobox.com?Subject=RE:%20Dangers%20of%20human%20self-modification">sentience@pobox.com</a>&gt; said:
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt;&gt;I think it might literally take considerably more caution to tweak 
</em><br>
<em>&gt; &gt;&gt;yourself than it would take to build a Friendly AI
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; Why wouldn't your seed AI run into the same problem when it 
</em><br>
<em>&gt; tries to 
</em><br>
<em>&gt; &gt; improve itself?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Because I would have designed that mind to handle those problems, in 
</em><br>
<em>&gt; exactly the way that natural selection did *not* design human 
</em><br>
<em>&gt; beings to 
</em><br>
<em>&gt; handle those problems.  Self-modification prefers a mind 
</em><br>
<em>&gt; designed to handle 
</em><br>
<em>&gt; self-modification, just as swimming in the core of the sun 
</em><br>
<em>&gt; prefers a body 
</em><br>
<em>&gt; designed to swim in the core of the sun.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -- 
</em><br>
<em>&gt; Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
</em><br>
<em>&gt; Research Fellow, Singularity Institute for Artificial Intelligence
</em><br>
<em>&gt; 
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8692.html">Keith Henson: "Re: Volitional Morality and Action Judgement"</a>
<li><strong>Previous message:</strong> <a href="8690.html">Eliezer Yudkowsky: "Re: Dangers of human self-modification"</a>
<li><strong>In reply to:</strong> <a href="8690.html">Eliezer Yudkowsky: "Re: Dangers of human self-modification"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8709.html">Samantha Atkins: "Re: Dangers of human self-modification"</a>
<li><strong>Reply:</strong> <a href="8709.html">Samantha Atkins: "Re: Dangers of human self-modification"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8691">[ date ]</a>
<a href="index.html#8691">[ thread ]</a>
<a href="subject.html#8691">[ subject ]</a>
<a href="author.html#8691">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
