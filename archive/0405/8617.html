<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: ethics</title>
<meta name="Author" content="Aubrey de Grey (ag24@gen.cam.ac.uk)">
<meta name="Subject" content="Re: ethics">
<meta name="Date" content="2004-05-21">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: ethics</h1>
<!-- received="Fri May 21 05:35:03 2004" -->
<!-- isoreceived="20040521113503" -->
<!-- sent="Fri, 21 May 2004 12:33:24 +0100" -->
<!-- isosent="20040521113324" -->
<!-- name="Aubrey de Grey" -->
<!-- email="ag24@gen.cam.ac.uk" -->
<!-- subject="Re: ethics" -->
<!-- id="E1BR8HE-0003rK-00@ag24.gen.cam.ac.uk" -->
<!-- inreplyto="ethics" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Aubrey de Grey (<a href="mailto:ag24@gen.cam.ac.uk?Subject=Re:%20ethics"><em>ag24@gen.cam.ac.uk</em></a>)<br>
<strong>Date:</strong> Fri May 21 2004 - 05:33:24 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8618.html">Philip Sutton: "Re: Dangers of human self-modification"</a>
<li><strong>Previous message:</strong> <a href="8616.html">Eliezer Yudkowsky: "Dangers of human self-modification"</a>
<li><strong>Maybe in reply to:</strong> <a href="../0512/13225.html">Phillip Huggan: "ethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8627.html">Eliezer Yudkowsky: "Re: ethics"</a>
<li><strong>Reply:</strong> <a href="8627.html">Eliezer Yudkowsky: "Re: ethics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8617">[ date ]</a>
<a href="index.html#8617">[ thread ]</a>
<a href="subject.html#8617">[ subject ]</a>
<a href="author.html#8617">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eliezer Yudkowsky wrote:
<br>
<p><em>&gt; &gt;&gt;I would presently support the flat general rule that things which look 
</em><br>
<em>&gt; &gt;&gt;like minor problems, but which you don't quite understand, are blocker 
</em><br>
<em>&gt; &gt;&gt;problems until fathomed completely.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; I'm very heartened at this, because I agree 100%.  My difficulty is with
</em><br>
<em>&gt; &gt; the idea that the path to this total understanding is (or even might be)
</em><br>
<em>&gt; &gt; finite, let alone tractable, in length.  But then, most biogerontologists
</em><br>
<em>&gt; &gt; still think that about curing aging, so I remain wide open to persuasion!
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This is possibly a good analogy; curing aging would be extremely difficult 
</em><br>
<em>&gt; if we needed to fathom biomedical symptoms of aging one by one and treat 
</em><br>
<em>&gt; them (correct me if I'm mistaken).
</em><br>
<p>You're quite correct.
<br>
<p><em>&gt; Curing aging looks much easier if you 
</em><br>
<em>&gt; suppose there might be a small library of underlying causes, and easier 
</em><br>
<em>&gt; still if you just reprogram all the cells using nanotech.  In the last 
</em><br>
<em>&gt; case we deal not with the problem of comprehending aging, but simply with 
</em><br>
<em>&gt; the problem of creating youth.
</em><br>
<p>This is not so correct.  My first thought was to defer discussion of this,
<br>
but actually a further exploration of the analogy seems to lead me to see
<br>
what still troubles me in FAI, so I'll elaborate.  Either with or without
<br>
sophistcated nanotech, by my &quot;SENS&quot; approach we do indeed avoid the problem
<br>
of comprehending aging, but we don't so much &quot;create youth&quot; as clear away
<br>
the barriers that our metabolism increasingly experiences to maintaining
<br>
(or restoring) youth itself.  This is an important distinction, because it
<br>
means that we can get away with not only not understanding aging but also
<br>
not understanding metabolism!  (Note: I use metabolism in its strict and
<br>
rather general sense here, to mean the entire network of biochemical and
<br>
cellular processes that keep us alive from one day to the next.)  These
<br>
barriers are of metabolism's own adventitious making, of course, but that
<br>
isn't relevant here -- what matters is that metabolism is a system to
<br>
keep us alive, indefinitely (because it's a state machine), just not a
<br>
perfect such system.  So, by analogy:
<br>
<p><em>&gt; Similarly, FAI doesn't require that I understand an existing biological 
</em><br>
<em>&gt; system, or that I understand an arbitrarily selected nonhuman system, but 
</em><br>
<em>&gt; that I build a system with the property of understandability.  Or to be 
</em><br>
<em>&gt; more precise, that I build an understandable system with the property of 
</em><br>
<em>&gt; predictable niceness/Friendliness, for a well-specified abstract predicate 
</em><br>
<em>&gt; thereof.  Just *any* system that's understandable wouldn't be enough.
</em><br>
<p>What I would like to see is an argument that there can, in principle, be
<br>
a system with the property of understandability (by at least a few 21st
<br>
century humans) and also with the property of considerably greater than
<br>
human cognitive function.  (I avoid &quot;intelliigence&quot; because I want to try
<br>
to focus the discussion on function, and thence on the reasons why we may
<br>
find these machines worth making, leaving aside for the moment the idea
<br>
that we need to invent FAI before anyone invents unfriendly AI.)
<br>
<p>Now, I accept readily that it is not correct that complex systems are
<br>
*always* effectively incomprehensible to less complex systems.  I have
<br>
no probelm with the idea that &quot;self-centredness&quot; may be avoidable.  But
<br>
as I understand it you are focusing on the development of a system with
<br>
the capacity for essentially indefinite cognitive self-enhancement.  I
<br>
can't see how a system so open-ended as that can be constrained in the
<br>
way you so cogently point out is necessary, and I also can't see how
<br>
any system *without* the capacity for essentially indefinite cognitive
<br>
self-enhancement will be any use in pre-empting the development of one
<br>
that does have that capacity, which as I understand it is one of your
<br>
primary motivations for creating FAI in the first place.  (In contrast,
<br>
I would like to see machines autonomous enough to free humans from the
<br>
need to engage in menial tasks like manufacturing and mining, but not
<br>
anything beyond that -- though I'm open to persuasion as I said.)
<br>
<p>What surprises me most here is the apparently widespread presence of
<br>
this concern in the community subscribed to this list -- the reasons
<br>
for my difficulty in seeing how FAI can even in principle be created
<br>
have been rehearsed by others and I have nothing to add at this point.
<br>
It seems that I am one of many who feel that this should be SIAI FAQ
<br>
number 1.  Have you addressed it in detail online anywhere?
<br>
<p>I'm also fairly sure that SIAI FAQ #2 or thereabouts should be the one
<br>
I asked aerlier and no one has yet answered: namely, how about treating
<br>
AI in general as a WMD, something to educate people not to think they
<br>
can build safely and to entice people not to want to build?
<br>
<p>Thanks for your time on this.
<br>
<p>Aubrey de Grey
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8618.html">Philip Sutton: "Re: Dangers of human self-modification"</a>
<li><strong>Previous message:</strong> <a href="8616.html">Eliezer Yudkowsky: "Dangers of human self-modification"</a>
<li><strong>Maybe in reply to:</strong> <a href="../0512/13225.html">Phillip Huggan: "ethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8627.html">Eliezer Yudkowsky: "Re: ethics"</a>
<li><strong>Reply:</strong> <a href="8627.html">Eliezer Yudkowsky: "Re: ethics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8617">[ date ]</a>
<a href="index.html#8617">[ thread ]</a>
<a href="subject.html#8617">[ subject ]</a>
<a href="author.html#8617">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
