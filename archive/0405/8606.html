<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: ethics</title>
<meta name="Author" content="Thomas Buckner (tcbevolver@yahoo.com)">
<meta name="Subject" content="Re: ethics">
<meta name="Date" content="2004-05-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: ethics</h1>
<!-- received="Thu May 20 19:26:19 2004" -->
<!-- isoreceived="20040521012619" -->
<!-- sent="Thu, 20 May 2004 18:26:17 -0700 (PDT)" -->
<!-- isosent="20040521012617" -->
<!-- name="Thomas Buckner" -->
<!-- email="tcbevolver@yahoo.com" -->
<!-- subject="Re: ethics" -->
<!-- id="20040521012617.43596.qmail@web60005.mail.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="40ABC916.4050904@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas Buckner (<a href="mailto:tcbevolver@yahoo.com?Subject=Re:%20ethics"><em>tcbevolver@yahoo.com</em></a>)<br>
<strong>Date:</strong> Thu May 20 2004 - 19:26:17 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8607.html">Damien Broderick: "Re: those darn uber computers"</a>
<li><strong>Previous message:</strong> <a href="8605.html">fudley: "Re: those darn uber computers"</a>
<li><strong>In reply to:</strong> <a href="8583.html">Eliezer S. Yudkowsky: "Re: ethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8610.html">Michael Roy Ames: "Re: ethics"</a>
<li><strong>Reply:</strong> <a href="8610.html">Michael Roy Ames: "Re: ethics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8606">[ date ]</a>
<a href="index.html#8606">[ thread ]</a>
<a href="subject.html#8606">[ subject ]</a>
<a href="author.html#8606">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- &quot;Eliezer S. Yudkowsky&quot; &lt;<a href="mailto:sentience@pobox.com?Subject=Re:%20ethics">sentience@pobox.com</a>&gt;
<br>
wrote:
<br>
<em>&gt; I would presently support the flat general rule that
</em><br>
<em>&gt; things which look 
</em><br>
<em>&gt; like minor problems, but which you don't quite
</em><br>
<em>&gt; understand, are blocker 
</em><br>
<em>&gt; problems until fathomed completely.  Mostly because
</em><br>
<em>&gt; of the number of 
</em><br>
<em>&gt; things I have encountered which looked like minor
</em><br>
<em>&gt; problems, and which I 
</em><br>
<em>&gt; didn't quite understand, and which - as it turned
</em><br>
<em>&gt; out, after I learned the 
</em><br>
<em>&gt; rules - I desperately needed to understand.
</em><br>
(...)
<br>
<em>&gt; I do not expect anyone who *actually* understands
</em><br>
<em>&gt; FAI to *ever* use the 
</em><br>
<em>&gt; argument of &quot;We don't understand this, but we'll use
</em><br>
<em>&gt; it anyway because of 
</em><br>
<em>&gt; &lt;nitwit utilitarian argument&gt;.&quot;  The nitwit argument
</em><br>
<em>&gt; only applies because 
</em><br>
<em>&gt; the speaker is too ignorant to realize that they
</em><br>
<em>&gt; have *no* chance of 
</em><br>
<em>&gt; success, that the *only* reason they think they can
</em><br>
<em>&gt; build an FAI without 
</em><br>
<em>&gt; understanding is that they lack the understanding to
</em><br>
<em>&gt; know this is impossible.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -- 
</em><br>
<em>&gt; Eliezer S. Yudkowsky                         
</em><br>
<em>&gt; <a href="http://intelligence.org/">http://intelligence.org/</a>
</em><br>
<em>&gt; Research Fellow, Singularity Institute for
</em><br>
<em>&gt; Artificial Intelligence
</em><br>
<p>We have a classic blocker problem hanging with
<br>
human-level intelligence, and if we can't solve it at
<br>
human-level, we may not have enough to go on for
<br>
anything beyond. I am referring to the fact that we
<br>
haven't beaten Failure of Friendliness among
<br>
ourselves, even among the most intelligent humans.
<br>
If we confine the inquiry only to those of proven high
<br>
intelligence, we get a range of behavioral models. We
<br>
get rapacious businessmen, renowned artists,
<br>
scientists who care how society will use their work,
<br>
others who don't, manipulative politicians, no-parole
<br>
murderers, and some few, approximately the ideal we
<br>
hope for in the FAI, are saintly types.
<br>
Even those who make a mark with their intellects make
<br>
moral choices that are good, bad, and indifferent, and
<br>
they do so with almost identical neural hardware and
<br>
cultural experiences.
<br>
Often different observers cannot even agree on whether
<br>
a given high-intelligence human is more or less
<br>
Friendly, i.e. ethical toward others. Like an
<br>
UnFriendly AI, some of society's pillars can fool
<br>
lesser intellects into seeing a Friendliness that is
<br>
not really there, and for far longer than seems
<br>
possible. Even nonhuman entities not created by
<br>
computer scientists (gasp!) can pursue complex
<br>
strategies of UnFriendliness far too baroque to have
<br>
been sired by one human brain. If I go into detail
<br>
about this assertion I will be accused of irrelevant
<br>
forays into geopolitics that are not germane to this
<br>
discussion. You'd be wrong, of course, but I
<br>
anticipate the objection.
<br>
This is connected to what I like to call the Sgt.
<br>
Schultz Principle. On the old TV show Hogan's Heroes,
<br>
a group of POWs would sneak around at will behind
<br>
their jailers' backs. There might have been
<br>
intelligent people among their captors, but they
<br>
relied heavily on the folly of Schultz, the very
<br>
stupidest and laziest guard in the camp. A bad AI may
<br>
not fool Eliezer, but if Eliezer is not the only
<br>
programmer in the lab, then it will simply find one it
<br>
can fool, and a majority is even better. What would
<br>
Eliezer do if shouted down by a quorum of dupes who
<br>
trusted the Bad AI?
<br>
A bad government could not rise or long stand if
<br>
everyone in the country saw through the deceptions it
<br>
needed to justify its grasp on power. That bad
<br>
governments exist in the world shows that bad leaders
<br>
have found ways to make some portion of the populace
<br>
believe that they are the best of the best.
<br>
An inner core of criminal minds who know, deep down,
<br>
that they are in the wrong, will surround the talented
<br>
sociopaths at the center of a dictatorship. But that's
<br>
simply not enough people to take over a nation. The
<br>
UnFriendly cadre must invariably surround itself with
<br>
millions of ordinary people who can be brainwashed.
<br>
Even if they lose their jobs, their sons, their
<br>
pensions and their clean water, these good sheep will
<br>
comply. As Machiavelli noted, the possession of power
<br>
confers a glamour of legitimacy. A mad, bloody king is
<br>
still the King. See also Wilhelm Reich's classic Mass
<br>
Psychology of Fascism.
<br>
These dupes trust the Bad Intellect at the center of a
<br>
dictatorship, and if an Eliezer tries to point out the
<br>
disconnect between word and deed, they would shout him
<br>
down (and maybe jail him). An inverse principle is in
<br>
play: the most brainwashed citizen feels himself to
<br>
least brainwashed, while one who worries that he may
<br>
be brainwashed is already halfway out of the hall of
<br>
mirrors.
<br>
There is plenty of psychological knowhow in use among
<br>
those who mold opinion. For example, TV producers can
<br>
put one candidate at a subtle disadvantage by
<br>
arranging for his image to appear (say) half an inch
<br>
lower on the screen during a debate. This might be
<br>
done simply by raising the camera a bit, or image
<br>
manipulation in postproduction. Another example, used
<br>
in the infamous push telephone polls in South
<br>
Carolina's 2000 Republican primary, is 'poisoning the
<br>
well' by spreading false accusations which are known
<br>
to have a negative effect even when disproved. (The
<br>
only way researchers have found to render this sort of
<br>
attack completely ineffective is to explain the
<br>
psychologial effect at the same time, using the false
<br>
accusation as an example).
<br>
How, in such an atmosphere, can we trust our own
<br>
ethical judgment when we are not even sure who is
<br>
telling the truth? What if you try to expose a Bad AI
<br>
and it calls you a glue-sniffing liar? What if it
<br>
hints that you're a mole from a competing firm, trying
<br>
to sabotage the project?
<br>
Even not-terribly bright humans can play this game,
<br>
and we haven't found a way to make them stop.
<br>
<p><p>=====
<br>
<p><p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
__________________________________
<br>
Do you Yahoo!?
<br>
Yahoo! Domains – Claim yours for only $14.70/year
<br>
<a href="http://smallbusiness.promotions.yahoo.com/offer">http://smallbusiness.promotions.yahoo.com/offer</a> 
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8607.html">Damien Broderick: "Re: those darn uber computers"</a>
<li><strong>Previous message:</strong> <a href="8605.html">fudley: "Re: those darn uber computers"</a>
<li><strong>In reply to:</strong> <a href="8583.html">Eliezer S. Yudkowsky: "Re: ethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8610.html">Michael Roy Ames: "Re: ethics"</a>
<li><strong>Reply:</strong> <a href="8610.html">Michael Roy Ames: "Re: ethics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8606">[ date ]</a>
<a href="index.html#8606">[ thread ]</a>
<a href="subject.html#8606">[ subject ]</a>
<a href="author.html#8606">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
