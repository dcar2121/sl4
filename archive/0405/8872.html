<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: One or more AIs??</title>
<meta name="Author" content="Mark Waser (mwaser@cox.net)">
<meta name="Subject" content="Re: One or more AIs??">
<meta name="Date" content="2004-05-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: One or more AIs??</h1>
<!-- received="Sun May 30 17:12:31 2004" -->
<!-- isoreceived="20040530231231" -->
<!-- sent="Sun, 30 May 2004 19:13:01 -0400" -->
<!-- isosent="20040530231301" -->
<!-- name="Mark Waser" -->
<!-- email="mwaser@cox.net" -->
<!-- subject="Re: One or more AIs??" -->
<!-- id="00a501c4469b$a7801200$0100a8c0@FamilyRoom" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="0a3f01c4468e$a07e5230$6401a8c0@mra02" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Mark Waser (<a href="mailto:mwaser@cox.net?Subject=Re:%20One%20or%20more%20AIs??"><em>mwaser@cox.net</em></a>)<br>
<strong>Date:</strong> Sun May 30 2004 - 17:13:01 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8873.html">Thomas Buckner: "RE: One or more AIs??"</a>
<li><strong>Previous message:</strong> <a href="8871.html">Michael Roy Ames: "Re: One or more AIs??"</a>
<li><strong>In reply to:</strong> <a href="8869.html">Michael Roy Ames: "Re: One or more AIs??"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8873.html">Thomas Buckner: "RE: One or more AIs??"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8872">[ date ]</a>
<a href="index.html#8872">[ thread ]</a>
<a href="subject.html#8872">[ subject ]</a>
<a href="author.html#8872">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; The problem seems to be that you haven't factored in what (significantly)
</em><br>
<em>&gt; more intelligence buys you.
</em><br>
<p>No, the problem is that I'm UNWILLING to assume sufficiently more
<br>
intelligence on the part of the Borg Hive that I'm willing to allow you to
<br>
claim that Tiny Tim is irrelevant.  Your claim reduces to:  Given the
<br>
premise that being one is sufficiently intelligent that it will never make
<br>
an error that being two can avoid THEN being two is irrelevant.  Well, duh!
<br>
<p><em>&gt; Having the 'Borg Hive' consult with 'Tiny Tim' doesn't
</em><br>
<em>&gt; reduce the probability of error, in the same way that me consulting my 4
</em><br>
<em>&gt; year old nephew doesn't reduce my probability of error.
</em><br>
<p>Of course, I suspect that I could successfully argue that your 4 year old
<br>
nephew probably could teach you (or most other adults) something about
<br>
happiness . . . .
<br>
<p><em>&gt; We already know
</em><br>
<em>&gt; that more relevant information improves decision making, and you have
</em><br>
<em>&gt; already acknowledged that this is not the point you are arguing.
</em><br>
<p>It depends upon what you mean by relevant information.  If you mean
<br>
immediate relevant information, then I agree with your statement.  However,
<br>
there is a huge amount of foundational information behind all of any
<br>
intelligence's compiled &quot;knowledge&quot;.  And different intelligences acquire
<br>
knowledge according to their tastes as to what is important.  Two
<br>
intelligences are quite likely to diverge fairly quickly in terms of what
<br>
foundational knowledge they have and pay attention to.  Also, most
<br>
&quot;learning&quot; algorithms show the behavior that different concept structures
<br>
may well be formed based upon the order in which data is presented or
<br>
concepts are taught.  How do you intend to eliminate &quot;bias&quot; in a single
<br>
entity?
<br>
<p><em>&gt; The fact
</em><br>
<em>&gt; that 'Tiny Tim' has an independent process to reason about what it knows
</em><br>
is
<br>
<em>&gt; only useful for avoiding errors in so far as that process reaches correct
</em><br>
<em>&gt; conclusions AND that process is not evaluated-by or a-subset-of a more
</em><br>
<em>&gt; intelligent process.
</em><br>
<p>The fact that Tiny Tim is an independent process is relevant because that
<br>
process has compiled a different knowledge structure.  A larger process that
<br>
attempts to supersume Tiny Tim will not compile the same knowledge structure
<br>
unless it completely suppresses all of it's knowledge when it is modelling
<br>
Tiny Tim (a case where, arguably, Tiny Tim is still a separate individual).
<br>
If it doesn't suppress all of it's knowledge, an incorrect bias caused by
<br>
previous incorrect information may cause it to miss something that Tiny Tim
<br>
would have gotten correct.
<br>
<p>There is a definite bias problem that I believe that y'all are overlooking .
<br>
. . .
<br>
<p><em>&gt; The almost magically wonderful aspect of a significantly greater
</em><br>
<em>&gt; intelligence is that it gets the correct answer reliably more often than a
</em><br>
<em>&gt; lesser intelligence.  Not only that, but I would suggest that any fully
</em><br>
<em>&gt; specified question that can be correctly answered by a lesser intelligence
</em><br>
<em>&gt; can always be correctly answered by a greater intelligence, given the same
</em><br>
<em>&gt; information.
</em><br>
<p>On small problems, sure.  With incomplete knowledge and the different
<br>
intelligences getting different information due to what they are and what
<br>
biases they've developed. . . . we've wandered outside the bounds of your
<br>
hypothesis . . . .
<br>
<p><em>&gt; Having multiple different FAIs is necessarily a bad idea, but it would be
</em><br>
<em>&gt; more work, and would not reduce the risk of failure.
</em><br>
<p>I assume that you mean that &quot;Having multiple different FAIs is NOT
<br>
necessarily a bad idea&quot;.  I would also argue that the amount of additional
<br>
work is more than offset by the dramatically increased safety.
<br>
<p><em>&gt; You have not yet
</em><br>
<em>&gt; provided a convincing argument to the contrary.
</em><br>
<p>I'm seeing arguments that FAIs might be dangerous because they might make
<br>
mistakes that your 4 year old nephew wouldn't make (paper-clipping the
<br>
universe).  Then, I'm seeing arguments that FAIs are so smart that they
<br>
won't make any mistake that a lesser intelligence (i.e. humans) won't make.
<br>
If your AI is smart enough that it won't make a mistake that a human can
<br>
avoid and if you set your initial Friendliness goals correctly, I would
<br>
argue that you're not going to have a problem at all.  The problem is that
<br>
your AI is NOT going to start off intelligent enough to be able to avoid
<br>
mistakes that humans can avoid.
<br>
<p>My convincing argument is that you're betting the human race on a single
<br>
roll of the dice and I'm betting the human race on the belief that a team of
<br>
AIs will be able recognize and avoid the mistakes that a single AI will
<br>
make.  I haven't seen a convincing argument to the contrary on your side
<br>
that doesn't assume something that simply doesn't exist.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;Mark
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8873.html">Thomas Buckner: "RE: One or more AIs??"</a>
<li><strong>Previous message:</strong> <a href="8871.html">Michael Roy Ames: "Re: One or more AIs??"</a>
<li><strong>In reply to:</strong> <a href="8869.html">Michael Roy Ames: "Re: One or more AIs??"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8873.html">Thomas Buckner: "RE: One or more AIs??"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8872">[ date ]</a>
<a href="index.html#8872">[ thread ]</a>
<a href="subject.html#8872">[ subject ]</a>
<a href="author.html#8872">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:47 MDT
</em></small></p>
</body>
</html>
