<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Designing human participation in the AI ascent</title>
<meta name="Author" content="James Higgins (jameshiggins@earthlink.net)">
<meta name="Subject" content="Re: Designing human participation in the AI ascent">
<meta name="Date" content="2001-06-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Designing human participation in the AI ascent</h1>
<!-- received="Sat Jun 30 15:16:38 2001" -->
<!-- isoreceived="20010630211638" -->
<!-- sent="Sat, 30 Jun 2001 12:20:48 -0700" -->
<!-- isosent="20010630192048" -->
<!-- name="James Higgins" -->
<!-- email="jameshiggins@earthlink.net" -->
<!-- subject="Re: Designing human participation in the AI ascent" -->
<!-- id="4.3.2.7.2.20010630121041.022093e0@mail.earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="002101c10190$6bdabbe0$228c90c6@oemcomputer" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Higgins (<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20Designing%20human%20participation%20in%20the%20AI%20ascent"><em>jameshiggins@earthlink.net</em></a>)<br>
<strong>Date:</strong> Sat Jun 30 2001 - 13:20:48 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1684.html">Eliezer S. Yudkowsky: "Re: SI Jail"</a>
<li><strong>Previous message:</strong> <a href="1682.html">James Higgins: "Re: SI Jail"</a>
<li><strong>In reply to:</strong> <a href="1681.html">Jack Richardson: "Re: Designing human participation in the AI ascent"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1676.html">gabriel C: "Re: Designing human participation in the AI ascent"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1683">[ date ]</a>
<a href="index.html#1683">[ thread ]</a>
<a href="subject.html#1683">[ subject ]</a>
<a href="author.html#1683">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
This is by far the *most* dangerous suggestion I think I've read on this 
<br>
list.  See below.
<br>
<p>At 02:13 PM 6/30/2001 -0400, Jack Richardson wrote:
<br>
<em>&gt;Eliezer:
</em><br>
<em>&gt;
</em><br>
<em>&gt;Thanks for your response to my message.
</em><br>
<em>&gt;
</em><br>
<em>&gt;The idea I'm presenting for consideration is the importance of human
</em><br>
<em>&gt;participation in the ascent towards the Singularity. I'm suggesting that
</em><br>
<em>&gt;there may be an alternative to building the AI while we remain just as we
</em><br>
<em>&gt;are.
</em><br>
<p>Nice idea.
<br>
<p><em>&gt;One issue here is whether the ascent can be sufficiently controlled so that
</em><br>
<em>&gt;we can follow as best we can what is going on. One way to do this is to have
</em><br>
<em>&gt;the AI itself have as a part of its architecture not just the communication
</em><br>
<em>&gt;of what changes it is making to its code, but providing a
</em><br>
<em>&gt;human-understandable explanation as to what it is doing and what it expects
</em><br>
<em>&gt;the next steps will be. One control might be that it would have to get a
</em><br>
<em>&gt;positive response from its programmers that they have sufficient
</em><br>
<em>&gt;understanding before it could proceed to the next iteration of its
</em><br>
<em>&gt;processing.
</em><br>
<p>What is to prevent the AI from misleading its inspectors in this 
<br>
regard?  If you've done much programming you know how dangerous inaccurate 
<br>
source code comments are.  The comment says &quot;The following block does X 
<br>
because of Y&quot;, which is exactly what the programmer reviewing/modifying the 
<br>
code wants.  So they spend countless time trying to figure out why it 
<br>
doesn't work.  Eventually they figure out that the actual code doesn't 
<br>
match the comment as they whack themselves in the head for missing 
<br>
something obvious.
<br>
<p>Granting the AI an ability to explain its code in English makes it vastly 
<br>
more likely that it could fool the programmers.
<br>
<p><em>&gt;Another area for consideration is whether the AI in its advanced but still
</em><br>
<em>&gt;pre-singularity mode could make recommendations as to what enhancements to
</em><br>
<em>&gt;human intellectual capacity would work best to allow us to follow it further
</em><br>
<em>&gt;on its path. The advanced pre-singularity phase is a key point where a lot
</em><br>
<em>&gt;of useful things might be done, and I'm suggesting that the architecture of
</em><br>
<em>&gt;the AI be designed in a way that we could all get the benefit of this phase.
</em><br>
<p>Having an AI suggest modifications for the minds of humans is 
<br>
dangerous.  Even more so when it is for the purpose of better understanding 
<br>
the AI.  Who needs SI magic when the AI is asked to modify the minds of its 
<br>
programmers.  Without the ability to prove that the AI is in fact friendly, 
<br>
this is most certainly a recipe for disaster.
<br>
<p><em>&gt;It is certainly true that after the Singularity occurs all bets are off.
</em><br>
<em>&gt;This is why controlling the advanced phase is crucial. If we don't have near
</em><br>
<em>&gt;total confidence in the friendliness of the AI, we should never let it get
</em><br>
<em>&gt;beyond this point. Being able to extensively interact with it during this
</em><br>
<em>&gt;phase, even with the risk that someone else might create one first, is
</em><br>
<em>&gt;necessary to establish that confidence.
</em><br>
<p>How could we have any confidence in anything after letting the AI explain 
<br>
itself to us, much less modify our minds?  Familiar with Keepers from 
<br>
Babylon 5?  I could just imagine screaming internally &quot;no, this is wrong, 
<br>
it is not friendly&quot;, as a modified or extended part of my mind gives the 
<br>
all clear...
<br>
<p><em>&gt;Regards,
</em><br>
<em>&gt;Jack
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1684.html">Eliezer S. Yudkowsky: "Re: SI Jail"</a>
<li><strong>Previous message:</strong> <a href="1682.html">James Higgins: "Re: SI Jail"</a>
<li><strong>In reply to:</strong> <a href="1681.html">Jack Richardson: "Re: Designing human participation in the AI ascent"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1676.html">gabriel C: "Re: Designing human participation in the AI ascent"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1683">[ date ]</a>
<a href="index.html#1683">[ thread ]</a>
<a href="subject.html#1683">[ subject ]</a>
<a href="author.html#1683">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
