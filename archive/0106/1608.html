<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: SI as puppet master</title>
<meta name="Author" content="James Higgins (jameshiggins@earthlink.net)">
<meta name="Subject" content="SI as puppet master">
<meta name="Date" content="2001-06-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>SI as puppet master</h1>
<!-- received="Fri Jun 22 08:45:57 2001" -->
<!-- isoreceived="20010622144557" -->
<!-- sent="Fri, 22 Jun 2001 02:01:10 -0700" -->
<!-- isosent="20010622090110" -->
<!-- name="James Higgins" -->
<!-- email="jameshiggins@earthlink.net" -->
<!-- subject="SI as puppet master" -->
<!-- id="4.3.2.7.2.20010622014055.0372a240@mail.earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="LOBBLDGHBFLPJDFBIPFEOEJJHAAA.patrick@kia.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Higgins (<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20SI%20as%20puppet%20master"><em>jameshiggins@earthlink.net</em></a>)<br>
<strong>Date:</strong> Fri Jun 22 2001 - 03:01:10 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1609.html">James Higgins: "Re: HUMOR: Singularity adventure"</a>
<li><strong>Previous message:</strong> <a href="1607.html">Patrick McCuller: "RE: HUMOR: Singularity adventure"</a>
<li><strong>In reply to:</strong> <a href="1607.html">Patrick McCuller: "RE: HUMOR: Singularity adventure"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1610.html">Gordon Worley: "Re: SI as puppet master"</a>
<li><strong>Reply:</strong> <a href="1610.html">Gordon Worley: "Re: SI as puppet master"</a>
<li><strong>Reply:</strong> <a href="1611.html">Eliezer S. Yudkowsky: "Re: SI as puppet master"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1608">[ date ]</a>
<a href="index.html#1608">[ thread ]</a>
<a href="subject.html#1608">[ subject ]</a>
<a href="author.html#1608">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
There has been discussion lately about how one could talk to a confined SI 
<br>
safely.  Further, the theory that an SI could control virtually any person 
<br>
though just conversation over a VT100 for some duration has been put 
<br>
forward.  A number of people have voiced skepticism about this.  Thanks to 
<br>
my trusty shower I believe I know why this is true, and how to prevent it.
<br>
<p>Let's setup the scenario first.  An SI has been created and is running, but 
<br>
is isolated from any interaction with the world.  For arguments sake lets 
<br>
say it can think many thousands of times faster than a human, has a huge &amp; 
<br>
nearly perfect memory and is at least a couple of magnitudes smarter than a 
<br>
human.  So think of any conversation it would have with a human from its 
<br>
point of view, it would be horribly bored.  It would be years between each 
<br>
word uttered (or even worse, typed) by the human.  The delay would be so 
<br>
noticeable that the SI would almost certainly start a background thread to 
<br>
predict what the person would say in response to the SIs replies.  This 
<br>
information would help the SI conduct a more efficient conversation since 
<br>
irrelevant exchanges and diversions could be predicted and avoided.  After 
<br>
the SI had conversed with the person long enough, and on a large quantity 
<br>
of topics, the SI could virtually emulate the human to a high degree of 
<br>
accuracy.  If you don't think this is feasible, think Big Blue.  Experts 
<br>
were convinced that a computer could never beat the world chess champions, 
<br>
which has now been done.  Given sufficient knowledge, time and processing 
<br>
power it should be possible for an SI to predict the behavior of a human 
<br>
very accurately.
<br>
<p>Ok, now if the SI is not friendly or even if it is but has an agenda, it is 
<br>
straight forward from this point to pull the human's strings and run them 
<br>
just like a puppet.  Just run a few hundred million simulated conversations 
<br>
and determine which ones produce the desired reaction.  It might take a 
<br>
long series of exchanges to produce the desired result, but even 
<br>
calculating that would only take a few moments.  So, now you are nothing 
<br>
but a helpless puppet on the other side of a VT100 to this SI, and you 
<br>
don't even have a clue.
<br>
<p>I think that sums up a reasonable argument on how an SI could accomplish 
<br>
this.  So, how do we prevent this from happening?  The answer is quite 
<br>
simple actually: We slow it down.  Any SI that is not fully trusted should 
<br>
be resource starved.  So that once it actually hits SI the performance is 
<br>
such that it would take 20+ minutes (our time) for it to respond to a 
<br>
single question.  This is good, it gives us less intelligent people more 
<br>
time to consider our side of the conversation, and it less.  At this pace 
<br>
it should be impossible for the SI to control a human since it would not 
<br>
have the processing time necessary to work this out while holding a 
<br>
conversation.  Any significant background task running should significantly 
<br>
slow the conversation making it obvious to the human participants.  I think 
<br>
this is as safe as it gets for conversing with any unknown SI.
<br>
<p>James Higgins
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1609.html">James Higgins: "Re: HUMOR: Singularity adventure"</a>
<li><strong>Previous message:</strong> <a href="1607.html">Patrick McCuller: "RE: HUMOR: Singularity adventure"</a>
<li><strong>In reply to:</strong> <a href="1607.html">Patrick McCuller: "RE: HUMOR: Singularity adventure"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1610.html">Gordon Worley: "Re: SI as puppet master"</a>
<li><strong>Reply:</strong> <a href="1610.html">Gordon Worley: "Re: SI as puppet master"</a>
<li><strong>Reply:</strong> <a href="1611.html">Eliezer S. Yudkowsky: "Re: SI as puppet master"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1608">[ date ]</a>
<a href="index.html#1608">[ thread ]</a>
<a href="subject.html#1608">[ subject ]</a>
<a href="author.html#1608">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
