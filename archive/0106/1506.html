<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Effective(?) AI Jail</title>
<meta name="Author" content="Gordon Worley (redbird@rbisland.cx)">
<meta name="Subject" content="Re: Effective(?) AI Jail">
<meta name="Date" content="2001-06-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Effective(?) AI Jail</h1>
<!-- received="Wed Jun 13 11:10:27 2001" -->
<!-- isoreceived="20010613171027" -->
<!-- sent="Wed, 13 Jun 2001 10:18:23 -0400" -->
<!-- isosent="20010613141823" -->
<!-- name="Gordon Worley" -->
<!-- email="redbird@rbisland.cx" -->
<!-- subject="Re: Effective(?) AI Jail" -->
<!-- id="f0510030ab74d2270095b@[10.0.1.2]" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="20010613024140.B24981@aristotle.bomis.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Gordon Worley (<a href="mailto:redbird@rbisland.cx?Subject=Re:%20Effective(?)%20AI%20Jail"><em>redbird@rbisland.cx</em></a>)<br>
<strong>Date:</strong> Wed Jun 13 2001 - 08:18:23 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1507.html">Eliezer S. Yudkowsky: "Re: Effective(?) AI Jail"</a>
<li><strong>Previous message:</strong> <a href="1505.html">Christian L.: "Re: Extro5 talk - feedback requested"</a>
<li><strong>In reply to:</strong> <a href="1503.html">Jimmy Wales: "Re: Effective(?) AI Jail"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1516.html">Gordon Worley: "Re: Effective(?) AI Jail"</a>
<li><strong>Reply:</strong> <a href="1516.html">Gordon Worley: "Re: Effective(?) AI Jail"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1506">[ date ]</a>
<a href="index.html#1506">[ thread ]</a>
<a href="subject.html#1506">[ subject ]</a>
<a href="author.html#1506">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
At 2:41 AM -0500 6/13/01, Jimmy Wales wrote:
<br>
<em>&gt;Brian Atkins wrote:
</em><br>
<em>&gt;&gt;  Well here you run into the familiar (should be familiar to you by now)
</em><br>
<em>&gt;&gt;  problem of existential risks. We most likely can't know the answer to this
</em><br>
<em>&gt;&gt;  issue either way until we actually could test such a situation out. And
</em><br>
<em>&gt;&gt;  even then you run a big risk if it turns out that Jimmy/James is wrong. So
</em><br>
<em>&gt;&gt;  what I'm trying to say (along with Eliezer) is you have to be conservative
</em><br>
<em>&gt;&gt;  when it comes to these kinds of risks, and make choices based more on what
</em><br>
<em>&gt;&gt;  can go wrong, even if the perceived probabilities are low.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Sure, but we also have to be aware that Pascal's argument for the
</em><br>
<em>&gt;existence of God (which has the same structure) is fallacious.
</em><br>
<p>Not trying to get into a religious debate with you (and Powers know 
<br>
that I don't want to do that ;-)), Pascal didn't exactly have any 
<br>
rational evidence for the existance of god and he knew it, too.  We, 
<br>
on other hand, have rational reasons and suggestive evidence (we 
<br>
don't want actual evidence, because that means us getting hosed) that 
<br>
an unFriendly AI would be the end of us all.
<br>
<p><em>&gt;Conservatism is one thing -- but being paranoid to the point that we
</em><br>
<em>&gt;fail to act is quite another.
</em><br>
<em>&gt;
</em><br>
<em>&gt;If we're that worried about it, perhaps we should stop being advocates
</em><br>
<em>&gt;for the singularity and start a terrorist organization to do everything
</em><br>
<em>&gt;we can do stop technological progress, right?
</em><br>
<p>Who would you prefer to trust:  the (Luddite) or the (idiot with 
<br>
technology)?  I'll take the Luddite any day.  We must do our best to 
<br>
be intelligent when it comes to technology and risk assessment until 
<br>
such time that we develop something smart enough to handle bigger 
<br>
risks.
<br>
<p>Also, in case you were wondering, terrorism isn't very Friendly, so I 
<br>
don't think we'd do that.  Maybe just tell people politely that 
<br>
technological progess is not in their best interests.  ;-P
<br>
<p>Now, on the experiment, if you really want an AI cadaver to look at, 
<br>
this might work, but we have to kill the human upon vis exit from the 
<br>
black box.  Otherwise, ve may one day, even if we lock him up in a 
<br>
jail and try to keep him away from computers, get access and program 
<br>
an unFriendly AI.  I don't think you'll find many people willing to 
<br>
die for such a useless cause as being able to see what an unFriendly 
<br>
AI looks like.
<br>
<p>Wait, I'll respond to your reply right now:  but it's not useless 
<br>
blah blah.  Yes, it is.  There are a couple of reasons.  One is that 
<br>
it won't help a Friendly AI learn anything.  If our FAI can't handle 
<br>
an UFAI when ve runs into one.  The other is that we can't look at 
<br>
the code, because the UFAI might learn vis purpose to us and use vis 
<br>
code to convert us into UFAI makers.
<br>
<pre>
-- 
Gordon Worley
<a href="http://www.rbisland.cx/">http://www.rbisland.cx/</a>
mailto:<a href="mailto:redbird@rbisland.cx?Subject=Re:%20Effective(?)%20AI%20Jail">redbird@rbisland.cx</a>
PGP Fingerprint:  C462 FA84 B811 3501 9010  20D2 6EF3 77F7 BBD3 B003
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1507.html">Eliezer S. Yudkowsky: "Re: Effective(?) AI Jail"</a>
<li><strong>Previous message:</strong> <a href="1505.html">Christian L.: "Re: Extro5 talk - feedback requested"</a>
<li><strong>In reply to:</strong> <a href="1503.html">Jimmy Wales: "Re: Effective(?) AI Jail"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1516.html">Gordon Worley: "Re: Effective(?) AI Jail"</a>
<li><strong>Reply:</strong> <a href="1516.html">Gordon Worley: "Re: Effective(?) AI Jail"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1506">[ date ]</a>
<a href="index.html#1506">[ thread ]</a>
<a href="subject.html#1506">[ subject ]</a>
<a href="author.html#1506">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
