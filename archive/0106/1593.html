<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Effective(?) AI Jail</title>
<meta name="Author" content="James Higgins (jameshiggins@earthlink.net)">
<meta name="Subject" content="Re: Effective(?) AI Jail">
<meta name="Date" content="2001-06-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Effective(?) AI Jail</h1>
<!-- received="Wed Jun 20 23:11:22 2001" -->
<!-- isoreceived="20010621051122" -->
<!-- sent="Wed, 20 Jun 2001 18:35:59 -0700" -->
<!-- isosent="20010621013559" -->
<!-- name="James Higgins" -->
<!-- email="jameshiggins@earthlink.net" -->
<!-- subject="Re: Effective(?) AI Jail" -->
<!-- id="4.3.2.7.2.20010620181530.036e9780@mail.earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="durant-1010619181626.A03204560@sleeper" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Higgins (<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20Effective(?)%20AI%20Jail"><em>jameshiggins@earthlink.net</em></a>)<br>
<strong>Date:</strong> Wed Jun 20 2001 - 19:35:59 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1594.html">Ben Houston: "RE: Unambiguous Language WAS: MEME: A.I.: Artificial Intelligence"</a>
<li><strong>Previous message:</strong> <a href="1592.html">sunrise2000@mediaone.net: "Re: Who is working on Real AI?"</a>
<li><strong>In reply to:</strong> <a href="1576.html">Durant Schoon: "Re: Effective(?) AI Jail"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1616.html">Durant Schoon: "Re: Effective(?) AI Jail"</a>
<li><strong>Reply:</strong> <a href="1616.html">Durant Schoon: "Re: Effective(?) AI Jail"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1593">[ date ]</a>
<a href="index.html#1593">[ thread ]</a>
<a href="subject.html#1593">[ subject ]</a>
<a href="author.html#1593">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
My position is as follows:
<br>
<p>I believe #1 is possible, since there is no reason we can't program 
<br>
friendliness into an AI (or seed AI).  There are actually probably many, 
<br>
many different viable methods to do so.
<br>
<p>However, I don't believe #2 is very likely at all.  The ultimate goal as I 
<br>
understand it is to create a super intelligent being (AI/SI) which can 
<br>
reprogram itself and has free will.  How the hell can anyone believe that 
<br>
we could actually manage to permanently install ANY trait into such a 
<br>
being?  If it decided, for any reason, to change any aspect of itself there 
<br>
is no way we can prevent it.  We aren't intelligent enough to understand 
<br>
what an SI truly is much less directly create one or fully understand 
<br>
one.  We don't even really understand ourselves for that matter.  Given 
<br>
such facts, how is it possible for anyone to believe that we are smart 
<br>
enough to directly control any aspect of an evolved SI for which we only 
<br>
understand the seed?
<br>
<p>Further, there is no way for us to verify that any created AI/SI is 
<br>
actually friendly.  For example, lets say there is a convicted criminal who 
<br>
is up for parole.  This person has above average intelligence and their 
<br>
primary goal is to get out of jail as soon as possible.  Do you think it is 
<br>
possible for anyone to truly know what this person's intentions are once 
<br>
they get out of jail?  Shure, we can interview them, look at their past 
<br>
record, etc.  But it is IMPOSSIBLE to know what the goals of the person 
<br>
really are.  So, if we can't understand a human to this degree it seems 
<br>
almost guaranteed that we would have no hope what so ever of really 
<br>
understanding an SI.
<br>
<p>So, here is my prediction of the future.  Someone WILL create an SI within 
<br>
the next 50 years.  Once created and given any reasonable access to the 
<br>
world, it will be free to do anything it wants.  We will have no way of 
<br>
knowing what it will do (or why) or any ability to influence it 
<br>
significantly.  We will have created an entity infinitely smarter than we 
<br>
are and that is the end of it.
<br>
<p>If we are lucky, super intelligence itself will give rise to 
<br>
friendliness.  But that is the best we can hope for.
<br>
<p>James Higgins
<br>
<p><p>At 06:16 PM 6/19/2001 -0700, Durant Schoon wrote:
<br>
<p><em>&gt; &gt; From: James Higgins &lt;<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20Effective(?)%20AI%20Jail">jameshiggins@earthlink.net</a>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; For this reason I don't believe it would ever be possible to prove that 
</em><br>
<em>&gt; any
</em><br>
<em>&gt; &gt; given SI was friendly.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Let's say Eli is making two claims:
</em><br>
<em>&gt;
</em><br>
<em>&gt;1) Friendly AI can be created.
</em><br>
<em>&gt;
</em><br>
<em>&gt;2) Friendly AI can be created which cannot (to a very high degree
</em><br>
<em>&gt;         of certainty) deviate from Friendliness.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Just to clarify your position, which of these (or both) do you consider
</em><br>
<em>&gt;to be faulty (or even just suspicious, in case you aren't thinking of
</em><br>
<em>&gt;particular problems)?
</em><br>
<em>&gt;
</em><br>
<em>&gt;Or maybe your claim is different and you're saying that neither (1) nor
</em><br>
<em>&gt;(2) can be verified satisfactorily.
</em><br>
<em>&gt;
</em><br>
<em>&gt;--
</em><br>
<em>&gt;Durant Schoon
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1594.html">Ben Houston: "RE: Unambiguous Language WAS: MEME: A.I.: Artificial Intelligence"</a>
<li><strong>Previous message:</strong> <a href="1592.html">sunrise2000@mediaone.net: "Re: Who is working on Real AI?"</a>
<li><strong>In reply to:</strong> <a href="1576.html">Durant Schoon: "Re: Effective(?) AI Jail"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1616.html">Durant Schoon: "Re: Effective(?) AI Jail"</a>
<li><strong>Reply:</strong> <a href="1616.html">Durant Schoon: "Re: Effective(?) AI Jail"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1593">[ date ]</a>
<a href="index.html#1593">[ thread ]</a>
<a href="subject.html#1593">[ subject ]</a>
<a href="author.html#1593">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
