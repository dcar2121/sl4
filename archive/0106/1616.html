<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Effective(?) AI Jail</title>
<meta name="Author" content="Durant Schoon (durant@ilm.com)">
<meta name="Subject" content="Re: Effective(?) AI Jail">
<meta name="Date" content="2001-06-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Effective(?) AI Jail</h1>
<!-- received="Fri Jun 22 15:55:00 2001" -->
<!-- isoreceived="20010622215500" -->
<!-- sent="Fri, 22 Jun 2001 12:52:48 -0700 (PDT)" -->
<!-- isosent="20010622195248" -->
<!-- name="Durant Schoon" -->
<!-- email="durant@ilm.com" -->
<!-- subject="Re: Effective(?) AI Jail" -->
<!-- id="durant-1010622125248.A0E213619@sleeper" -->
<!-- inreplyto="4.3.2.7.2.20010620181530.036e9780@mail.earthlink.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Durant Schoon (<a href="mailto:durant@ilm.com?Subject=Re:%20Effective(?)%20AI%20Jail"><em>durant@ilm.com</em></a>)<br>
<strong>Date:</strong> Fri Jun 22 2001 - 13:52:48 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1617.html">Durant Schoon: "RE: Unambiguous Language WAS: MEME: A.I.: Artificial Intelligence"</a>
<li><strong>Previous message:</strong> <a href="1615.html">Durant Schoon: "Re: Unambiguous Language WAS: MEME: A.I.: Artificial Intelligence"</a>
<li><strong>In reply to:</strong> <a href="1593.html">James Higgins: "Re: Effective(?) AI Jail"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1531.html">Carl Feynman: "Re: Effective(?) AI Jail"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1616">[ date ]</a>
<a href="index.html#1616">[ thread ]</a>
<a href="subject.html#1616">[ subject ]</a>
<a href="author.html#1616">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;2) Friendly AI can be created which cannot (to a very high degree
</em><br>
<em>&gt;         of certainty) deviate from Friendliness.
</em><br>
<p><em>&gt; From: James Higgins &lt;<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20Effective(?)%20AI%20Jail">jameshiggins@earthlink.net</a>&gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; My position is as follows:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; However, I don't believe #2 is very likely at all.  The ultimate goal as I 
</em><br>
<em>&gt; understand it is to create a super intelligent being (AI/SI) which can 
</em><br>
<em>&gt; reprogram itself and has free will.  How the hell can anyone believe that 
</em><br>
<em>&gt; we could actually manage to permanently install ANY trait into such a 
</em><br>
<em>&gt; being?  If it decided, for any reason, to change any aspect of itself there 
</em><br>
<em>&gt; is no way we can prevent it.  We aren't intelligent enough to understand 
</em><br>
<em>&gt; what an SI truly is much less directly create one or fully understand 
</em><br>
<em>&gt; one.  We don't even really understand ourselves for that matter.  Given 
</em><br>
<em>&gt; such facts, how is it possible for anyone to believe that we are smart 
</em><br>
<em>&gt; enough to directly control any aspect of an evolved SI for which we only 
</em><br>
<em>&gt; understand the seed?
</em><br>
<p>Good. I had the same objection. See the &quot;When Subgoals Attack Thread&quot;:
<br>
<p><a href="http://sysopmind.com/archive-sl4/0012/0061.html">http://sysopmind.com/archive-sl4/0012/0061.html</a>
<br>
<p>Basically, if you design the SI to prioritize being Friendly and also
<br>
to prioritize Remaining Friendly (and do it right), your AI will apply
<br>
all of ver mental effort toward never drifting away. So even if you or
<br>
I or Eliezer has any idea how to keep the system in check, the AI 
<br>
*verself* should do the task. That's a powerful thought. Let it sink in.
<br>
<p><em>&gt; Further, there is no way for us to verify that any created AI/SI is 
</em><br>
<em>&gt; actually friendly. 
</em><br>
<p>You're probably right. But again we can (or have to, depending on how
<br>
you see it) rely on the AI doing the reliance measurements. If we get
<br>
it wrong, we're probably toast. If we get it right, we totally win.
<br>
<p><em>&gt; If we are lucky, super intelligence itself will give rise to 
</em><br>
<em>&gt; friendliness.  But that is the best we can hope for.
</em><br>
<p>I disagree. Following Eli's line of reasoning we can and should try to
<br>
do much better.
<br>
<p><pre>
--
Durant Schoon
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1617.html">Durant Schoon: "RE: Unambiguous Language WAS: MEME: A.I.: Artificial Intelligence"</a>
<li><strong>Previous message:</strong> <a href="1615.html">Durant Schoon: "Re: Unambiguous Language WAS: MEME: A.I.: Artificial Intelligence"</a>
<li><strong>In reply to:</strong> <a href="1593.html">James Higgins: "Re: Effective(?) AI Jail"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1531.html">Carl Feynman: "Re: Effective(?) AI Jail"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1616">[ date ]</a>
<a href="index.html#1616">[ thread ]</a>
<a href="subject.html#1616">[ subject ]</a>
<a href="author.html#1616">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
