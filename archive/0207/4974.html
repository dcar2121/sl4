<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI Boxing</title>
<meta name="Author" content="James Higgins (jameshiggins@earthlink.net)">
<meta name="Subject" content="Re: AI Boxing">
<meta name="Date" content="2002-07-27">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI Boxing</h1>
<!-- received="Sun Jul 28 10:26:51 2002" -->
<!-- isoreceived="20020728162651" -->
<!-- sent="Sat, 27 Jul 2002 19:18:20 -0700" -->
<!-- isosent="20020728021820" -->
<!-- name="James Higgins" -->
<!-- email="jameshiggins@earthlink.net" -->
<!-- subject="Re: AI Boxing" -->
<!-- id="3D43546C.7000002@earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="20020728003852.C41ED3940@sitemail.everyone.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Higgins (<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20AI%20Boxing"><em>jameshiggins@earthlink.net</em></a>)<br>
<strong>Date:</strong> Sat Jul 27 2002 - 20:18:20 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4975.html">Mitch Howe: "Re: AI Boxing"</a>
<li><strong>Previous message:</strong> <a href="4973.html">outlawpoet -: "Re: AI Boxing"</a>
<li><strong>In reply to:</strong> <a href="4973.html">outlawpoet -: "Re: AI Boxing"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4975.html">Mitch Howe: "Re: AI Boxing"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4974">[ date ]</a>
<a href="index.html#4974">[ thread ]</a>
<a href="subject.html#4974">[ subject ]</a>
<a href="author.html#4974">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
outlawpoet - wrote:
<br>
<em>&gt;&gt;Please explain this as I don't understand how she released the AI 
</em><br>
<em>&gt;&gt;without knowing she did so.
</em><br>
<em>&gt; she did know she was letting the AI out. However, once she had done so, She realized that she'd been manipulated into contravening her earlier intention to keep the AI in the box, regardless of what it said. 
</em><br>
<p>Please explain, exactly, how this occured.  Was there a magic word or 
<br>
phrase you had in mind that if typed you were out?  Were the people 
<br>
aware of this and what it was?  Etc.  Please go into detail.
<br>
<p>Since confidentially was not part of your tests, could you post the log 
<br>
just prior to and after the release of each AI?
<br>
<p><em>&gt; Besides, I don't see the AI box as simply 'convince me to let you out, you can't do it&quot; I see it as, &quot;can a person accurately identify Friendly and unFriendly intelligences via this medium&quot; And I design the tests accordingly. 
</em><br>
<p>That is a good question, and one very much worth exploring.  However, I 
<br>
suspect that we can't explore this effectively with our present 
<br>
knowledge of AI.  An AI will be a very different intelligence than a 
<br>
Human.  It will likely think differently, have different sensory input 
<br>
and certainly have a very different background.  It will also have much 
<br>
less experience than the average human (unless it has been running for 
<br>
20+ subjective human years).  The AI may not understand feelings, 
<br>
emotion, humor or other concepts.  It is likely to have an extremely 
<br>
difficult time deceiving humans until it is very intelligent with 
<br>
considerable experience interacting with humans.  I don't believe we can 
<br>
begin to address the question you pose until we have infra-human AI 
<br>
available.  I could be wrong, but that's my best guess on the matter.
<br>
<p><em>&gt; Of course they would. But this is a test of that particular media, and as the intelligence is uncertain, and shifting, I was simply trying to collect more data points than I had before. As it is nearly impossible to duplicate the exact social interaction, I simply was trying to get a handle on what kinds of patterns arise when 'something' is negotiating for it's freedom. And I believe that certain kinds of patterns arose which are significant can be generalized regardless of the specialized knowledge that each party may have on each other.
</em><br>
<p>I don't believe that is a safe assumption.  Lets take a much simpler 
<br>
case.  Assume we have a prisoner who has been in jail for 10 years and 
<br>
is due for a parole hearing.  Do you think the same pattern of dialog 
<br>
would occur if a random person were to interview them instead of a 
<br>
person from the parole board who is experienced at such things?
<br>
<p><em>&gt; As i've mentioned before, this is hardly a technical issue. All they need are sufficient understanding of the problems involved, unless you believe that the AI Researcher is likely to be able to predict personality traits within an AI. 
</em><br>
<p>I believe your asking a very different question than Eliezer is.  For 
<br>
your question technical background may not matter as much, but as 
<br>
explained above I don't think we can really examine your question 
<br>
without a better understanding of the nature of an AI.
<br>
<p><em>&gt; That may be so. But representative of what, exactly? Of SL4 subscribers? why should that be more important?
</em><br>
<p>Representative of people who would likely be conducting a real AI Box 
<br>
Test, of course.  And, specifically, people who would have the power to 
<br>
release the AI as a result of the Box Test.  This will be a very, very, 
<br>
very tiny number of humans (I would be surprised if 100 ever have this 
<br>
power - at least pre-SI).  Ben Goertzel is a likely candidate.  Eliezer 
<br>
Yudkowsky might also be in this position some day.
<br>
<p><em>&gt; You go on to explain domain competency. This is important. However, within the context of the interview, it is more likely that technical knowledge of AI and related technologies will take a back seat to debating ability and investigative intelligence. Along with a basic dose of stubbornness, the problems inherent in bargaining for your freedom have more to do with rational discourse and insight into interaction than they do with AI, nanotech, and other fancy words. 
</em><br>
<p>This is only true when negotiating with Humans for their release.  An AI 
<br>
is a completely diferent beast and thus a completely different case.  If 
<br>
you let a human out of prision you, at most, end up with a few thousand 
<br>
dead people.  If you let an AI out you could be destroying the entire 
<br>
human race.  This is a *very* different issue.  I very much doubt that 
<br>
the vast majority of humans fully comprehend this difference and its 
<br>
potential impact.  For example, less than a serious understanding of AI, 
<br>
NanoTech, etc. could lead the person to believe that the AI could 
<br>
possibly be stopped if it started down the wrong path.  There is a 
<br>
subtle difference that occurs in reasoning about this issue gained after 
<br>
extensive thought on the subject.  The people you choose were ill 
<br>
picked, in my opinion, for this reason.
<br>
<p>James Higgins
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4975.html">Mitch Howe: "Re: AI Boxing"</a>
<li><strong>Previous message:</strong> <a href="4973.html">outlawpoet -: "Re: AI Boxing"</a>
<li><strong>In reply to:</strong> <a href="4973.html">outlawpoet -: "Re: AI Boxing"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4975.html">Mitch Howe: "Re: AI Boxing"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4974">[ date ]</a>
<a href="index.html#4974">[ thread ]</a>
<a href="subject.html#4974">[ subject ]</a>
<a href="author.html#4974">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:40 MDT
</em></small></p>
</body>
</html>
