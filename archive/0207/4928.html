<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Intelligence and wisdom</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Intelligence and wisdom">
<meta name="Date" content="2002-07-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Intelligence and wisdom</h1>
<!-- received="Wed Jul 17 23:04:38 2002" -->
<!-- isoreceived="20020718050438" -->
<!-- sent="Wed, 17 Jul 2002 15:49:22 -0600" -->
<!-- isosent="20020717214922" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Intelligence and wisdom" -->
<!-- id="LAEGJLOGJIOELPNIOOAJOEAGCNAA.ben@goertzel.org" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="174114120196.20020717171351@earthlink.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Intelligence%20and%20wisdom"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Wed Jul 17 2002 - 15:49:22 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4929.html">Emil Gilliam: "Cognitive complexity from so few genes?"</a>
<li><strong>Previous message:</strong> <a href="4927.html">Samantha Atkins: "Re: FAI means no programmer-sensitive AI morality"</a>
<li><strong>In reply to:</strong> <a href="4926.html">Cliff Stabbert: "Re: Intelligence and wisdom"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4930.html">Rafal Smigrodzki: "RE: Intelligence and wisdom"</a>
<li><strong>Reply:</strong> <a href="4930.html">Rafal Smigrodzki: "RE: Intelligence and wisdom"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4928">[ date ]</a>
<a href="index.html#4928">[ thread ]</a>
<a href="subject.html#4928">[ subject ]</a>
<a href="author.html#4928">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
hi,
<br>
<p><em>&gt; I wonder if in these discussions of intelligence vs. wisdom, we're not
</em><br>
<em>&gt; leaving out an essential component of the distinction: namely, human
</em><br>
<em>&gt; psychology with its conscious vs. subconscious, id/ego/superego,
</em><br>
<em>&gt; shadows, complexes, anima and all the rest of it.
</em><br>
<p>Of course, these aspects contribute to keeping some intelligent humans from
<br>
being wise, and help some relatively unintelligent humans to be surprisingly
<br>
wise.
<br>
<p>But their relevance to AI psychology is not direct, tho there are
<br>
connections.
<br>
<p><em>&gt; Perhaps when we say of someone that they're intelligent but not (yet)
</em><br>
<em>&gt; wise we really are referring to a lack of congruence between their
</em><br>
<em>&gt; explicit stated goals and their &quot;actual&quot; (subconscious) goals, as
</em><br>
<em>&gt; evidenced by their behaviour.  I put &quot;actual&quot; between quotes because
</em><br>
<em>&gt; the situation is of course far more complex than that.
</em><br>
<p>This gets at a subtle aspect of the definition of intelligence as &quot;achieving
<br>
complex goals in complex environments.&quot;
<br>
<p>If the system thinks it is (or tries to) achieve one complex goal, but
<br>
actually achieves another, this still counts!
<br>
<p><em>&gt; Question: would you predict that an AI at some point during its
</em><br>
<em>&gt; moral evolution will 'have' some similar substrate for internal
</em><br>
<em>&gt; struggle?
</em><br>
<em>&gt;
</em><br>
<em>&gt; I am presuming most expect a super AI to be perfectly
</em><br>
<em>&gt; congruent*, with no internal contradictions, but am asking a question
</em><br>
<em>&gt; about how it gets to that point.
</em><br>
<p>As Eliezer has pointed out quite nicely in CFAI, most of the contradictions
<br>
we humans experience can be traced clearly to our evolutionary heritage.
<br>
<p>There may be some contradictoriness necessary in any pragmatically
<br>
constructible mind.  I don't think that perfect mathematical consistency is
<br>
pragmatically possible in any mind given realistic resource constraints.
<br>
However, the human mind clearly has WAY more inconsistency than is imposed
<br>
on it by its resource limitations.
<br>
<p><em>&gt; There appear,
</em><br>
<em>&gt; to me, to be fundamental reasons why self-consciousness of necessity
</em><br>
<em>&gt; cannot include the whole system.
</em><br>
<p>This is an old point, but a weak one, because it doesn't show why a system
<br>
can't come *extremely close* to complete self-understanding.
<br>
<p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4929.html">Emil Gilliam: "Cognitive complexity from so few genes?"</a>
<li><strong>Previous message:</strong> <a href="4927.html">Samantha Atkins: "Re: FAI means no programmer-sensitive AI morality"</a>
<li><strong>In reply to:</strong> <a href="4926.html">Cliff Stabbert: "Re: Intelligence and wisdom"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4930.html">Rafal Smigrodzki: "RE: Intelligence and wisdom"</a>
<li><strong>Reply:</strong> <a href="4930.html">Rafal Smigrodzki: "RE: Intelligence and wisdom"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4928">[ date ]</a>
<a href="index.html#4928">[ thread ]</a>
<a href="subject.html#4928">[ subject ]</a>
<a href="author.html#4928">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:40 MDT
</em></small></p>
</body>
</html>
