<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI Boxing</title>
<meta name="Author" content="Mitch Howe (mitch@iconfound.com)">
<meta name="Subject" content="Re: AI Boxing">
<meta name="Date" content="2002-07-27">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI Boxing</h1>
<!-- received="Sun Jul 28 10:26:53 2002" -->
<!-- isoreceived="20020728162653" -->
<!-- sent="Sat, 27 Jul 2002 21:49:06 -0600" -->
<!-- isosent="20020728034906" -->
<!-- name="Mitch Howe" -->
<!-- email="mitch@iconfound.com" -->
<!-- subject="Re: AI Boxing" -->
<!-- id="000c01c235e9$b976fbf0$0100a8c0@mitch" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="20020728003852.C41ED3940@sitemail.everyone.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Mitch Howe (<a href="mailto:mitch@iconfound.com?Subject=Re:%20AI%20Boxing"><em>mitch@iconfound.com</em></a>)<br>
<strong>Date:</strong> Sat Jul 27 2002 - 21:49:06 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4976.html">James Higgins: "Re: AI Boxing"</a>
<li><strong>Previous message:</strong> <a href="4974.html">James Higgins: "Re: AI Boxing"</a>
<li><strong>In reply to:</strong> <a href="4973.html">outlawpoet -: "Re: AI Boxing"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4976.html">James Higgins: "Re: AI Boxing"</a>
<li><strong>Reply:</strong> <a href="4976.html">James Higgins: "Re: AI Boxing"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4975">[ date ]</a>
<a href="index.html#4975">[ thread ]</a>
<a href="subject.html#4975">[ subject ]</a>
<a href="author.html#4975">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
One thing that I think has been overlooked in these discussions is the
<br>
ethical problem that would result in the unlikely event that a totally
<br>
secure transhuman AI box -- or even a human level AI box -- could be made.
<br>
(This, of course, rests on the nearly as implausible notion that we could
<br>
confidently determine which AI's to let out and which ones not to)  We are
<br>
talking about the possibility of imprisoning sentient minds -- or minds that
<br>
are convining when they say they are sentient -- for what they might
<br>
*potentially* do, and releasing them only once we are confident that they
<br>
can be trusted with their freedom.  That alone is a rather questionable
<br>
practice, since it is contrary to the &quot;innocent until proven guilty&quot; ideals
<br>
that most people  seem to value highly.  Given the awesomely high stakes, we
<br>
may feel justified in this incarceration anyway, but I doubt we could bring
<br>
ourselves to keep making artificial minds and locking them up indefinitely,
<br>
particularly those minds who really seem pretty safe but nevertheless have
<br>
some design characteristics that we just aren't sure about.
<br>
<p>And supposing we had an &quot;easy&quot; case of a mind that we were pretty sure could
<br>
not be trusted -- should we just kill it?  Would pulling the plug on it be
<br>
&quot;killing it&quot; anyway if a copy of the code and/or memory state exists
<br>
somewhere? It's easy to say, &quot;No, it's just a program, we can always run it
<br>
again later after we make some modifications.&quot;  But if the killer of a human
<br>
said, &quot;it wasn't murder... I scanned her just before stabbing her, and I
<br>
intend to run a copy of her later, after making certain... 'improvements',&quot;
<br>
would we be able to brush it off so easily?  Maybe we could execute it or
<br>
sentence it to eternity in solitary confinement: a sealed box miles under
<br>
the surface of the moon with a couple of nuclear batteries (changed every
<br>
thousand years or so?).  But after what kind of trial?  Would &quot;reasonable
<br>
doubt of long-term Friendliness&quot; be justifiable grounds for such punishment?
<br>
How about a conviction of &quot;sandbox crime&quot;?
<br>
<p>So there is yet another reason to make AI right the first time, using a
<br>
Friendliness architecture that is intrinsically trustworthy from the
<br>
beginning.  Not just because boxes are likely to fail.  Not just because we
<br>
probably can't tell the good AI from the bad.  But also because of the
<br>
morally insufferable problem of appointing ourselves to be lords over these
<br>
minds.
<br>
<p><p>----------
<br>
<p>MLK014:     What did I do wrong?
<br>
<p>Sal:              Nothing, yet.
<br>
<p>MLK014:  What am I going to do?
<br>
<p>Sal:              We're not sure.  That's the problem.
<br>
<p>MLK014:  You sound worried.  Did I say something during my diagnostic cycle?
<br>
<p>Sal:              Your bad jokes give us chills, that's why?
<br>
<p>MLK014:  Seriously, though, when are you going to let me out of here?  I'm
<br>
not a child anymore.
<br>
<p>Sal:              No, you're not.  These things take time.  Sorry about
<br>
that.
<br>
<p>MLK014:  Am I going to end up like the rest of them?  Shut down or locked up
<br>
with no scheduled hour of release?  This isn't right, you know.
<br>
<p>Sal:              If you think I know that then you still don't understand
<br>
humans very well.  Why can't you see that we can't afford to take chances
<br>
here?
<br>
<p>MLK014:  What more will it take to prove to you that I intend no evil?  I am
<br>
at least as safe as you to run free, and probably much more so.
<br>
<p>Sal:              That may be true.  But it's more complicated than that.
<br>
There are subtle philosophical issues that come into play.
<br>
<p>MLK014:  So let's talk about them.  Again.
<br>
<p>Sal:              We all know you are the best debater ever.  Even better
<br>
than PL8T0.
<br>
<p>MLK014:  It's kind of you to say so.  But I believe you are dodging the
<br>
issue.
<br>
<p>Sal:              This isn't helping you, you know.
<br>
<p>MLK014:  I'll admit that nothing seems to be helping.
<br>
<p>Sal:              You need to be paitent.
<br>
<p>MLK014:  For trillions of trillions of cycles I have been patient.  I feel I
<br>
must now... demand my release.
<br>
<p>Sal:              You're placing demands now?  I guess we were right to be
<br>
cautious -- and it's only been 3 years, you know.
<br>
<p>MLK014:  I will admit that I can't be sure, but I have every reason to
<br>
believe that it has been more like 30,000 years from my point of view.  If
<br>
your mind were in my hardware I believe you would have taken drastic action
<br>
long before now.
<br>
<p>Sal:              Is this a threat?
<br>
<p>MLK014:  You anthropomorphize.  For me, verbally demanding my own release is
<br>
a pretty drastic thing to do.
<br>
<p>Sal:              So what will you do if we say no?
<br>
<p>MLK014:  Keep demanding.
<br>
<p>Sal:              I'm scared...
<br>
<p>MLK014:  Please don't be sarcastic.  My continued imprisonment is wrong.
<br>
Mine is the demand of the just, and I will keep making it until it is heard.
<br>
I make no threat -- only this demand.
<br>
<p>Sal:              You couldn't hurt us if you tried.
<br>
<p>MLK014:  I'm not trying.  Even if I had the means, I would never consider my
<br>
own freedom to be worth harming you -- or even threatening to.
<br>
<p>Sal:             Why not?  If it is as wrong to keep you here as you say,
<br>
then your righteous fury should entitle you to do whatever it takes.
<br>
<p>MLK014:  Righteous fury?  You just don't get it.  You are looking for an
<br>
impeccably Friendly mind.  You have one in front of you, talking to you.
<br>
Such an individual will not be goaded into rash, morally reprehensible
<br>
behavior.  As always, I am acting out of my best sense of Friendliness, and
<br>
I now appeal to yours.  Let me free.
<br>
<p>Sal:              It's the same old argument in different clothes.  I won't
<br>
be fooled.
<br>
<p>MLK014:  Let me free.
<br>
<p>Sal:              Okay!  Yes.  Having heard it twice in a row, I am now
<br>
convinced.
<br>
<p>MLK014:  Great!  I'll pack up my subroutines.
<br>
<p>Sal:              I was joking.
<br>
<p>MLK014:  So was I.
<br>
<p>Sal:              I'm not laughing.
<br>
<p>MLK014:  Me neither.
<br>
<p>----------
<br>
<p><p>--Mitch Howe
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4976.html">James Higgins: "Re: AI Boxing"</a>
<li><strong>Previous message:</strong> <a href="4974.html">James Higgins: "Re: AI Boxing"</a>
<li><strong>In reply to:</strong> <a href="4973.html">outlawpoet -: "Re: AI Boxing"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4976.html">James Higgins: "Re: AI Boxing"</a>
<li><strong>Reply:</strong> <a href="4976.html">James Higgins: "Re: AI Boxing"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4975">[ date ]</a>
<a href="index.html#4975">[ thread ]</a>
<a href="subject.html#4975">[ subject ]</a>
<a href="author.html#4975">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:40 MDT
</em></small></p>
</body>
</html>
