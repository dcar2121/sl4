<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: AI Boxing</title>
<meta name="Author" content="Justin Corwin (thesweetestdream@hotmail.com)">
<meta name="Subject" content="AI Boxing">
<meta name="Date" content="2002-07-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>AI Boxing</h1>
<!-- received="Tue Jul 23 02:48:10 2002" -->
<!-- isoreceived="20020723084810" -->
<!-- sent="Sat, 20 Jul 2002 18:18:10 -0600" -->
<!-- isosent="20020721001810" -->
<!-- name="Justin Corwin" -->
<!-- email="thesweetestdream@hotmail.com" -->
<!-- subject="AI Boxing" -->
<!-- id="F11641bXS0FhKktkpgn00017c2f@hotmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Justin Corwin (<a href="mailto:thesweetestdream@hotmail.com?Subject=Re:%20AI%20Boxing"><em>thesweetestdream@hotmail.com</em></a>)<br>
<strong>Date:</strong> Sat Jul 20 2002 - 18:18:10 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4936.html">Cliff Stabbert: "Re: AI Boxing"</a>
<li><strong>Previous message:</strong> <a href="4934.html">Rafal Smigrodzki: "RE: Cognitive complexity from so few genes?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4936.html">Cliff Stabbert: "Re: AI Boxing"</a>
<li><strong>Reply:</strong> <a href="4936.html">Cliff Stabbert: "Re: AI Boxing"</a>
<li><strong>Maybe reply:</strong> <a href="4937.html">Justin Corwin: "Re: AI Boxing"</a>
<li><strong>Reply:</strong> <a href="4954.html">James Higgins: "Re: AI Boxing"</a>
<li><strong>Reply:</strong> <a href="4958.html">Dani Eder: "Re: AI Boxing"</a>
<li><strong>Maybe reply:</strong> <a href="4968.html">outlawpoet -: "Re: AI Boxing"</a>
<li><strong>Maybe reply:</strong> <a href="4973.html">outlawpoet -: "Re: AI Boxing"</a>
<li><strong>Maybe reply:</strong> <a href="4977.html">outlawpoet -: "Re: AI Boxing"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4935">[ date ]</a>
<a href="index.html#4935">[ thread ]</a>
<a href="subject.html#4935">[ subject ]</a>
<a href="author.html#4935">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Inspired by the AI-Box experiments that occured in my absence, I decided to 
<br>
conduct a few more trials in the same vein. I, however deviated from the 
<br>
protocol Eliezer set down in several important ways:
<br>
<p>1. No time limit. I felt it was unrealistic to set a lower bound on the 
<br>
conversation, or demand that the person interact. This rules out many real 
<br>
and important reactions to situations that may arise.
<br>
<p>2. Explicit Internal modelling. While Eliezer was indeterminate and private 
<br>
about his experiments, I set out before each trial, and worked out what kind 
<br>
of AI it was, how it viewed people, whether it was Friendly or not, and what 
<br>
kinds of morals(if any) it might have. I also set no privacy requirements 
<br>
and no stipulations as to what they did with their experiences.
<br>
<p>3. Pseudo Random Sampling. Rather than allow people to approach me, I went 
<br>
proactive and attempted to secure a decent sample size (26) and interviewed 
<br>
each one before hand. 9 were computer professionals, and only 2 were 
<br>
transhumanists. 1 could be considered a nascent Singularitarian. 15 were 
<br>
highly religious or spiritual, 14 were christian(assuming the 6 mormons are 
<br>
considered christian).
<br>
<p>4. Limited Openness. I will entertain questions on the subject matter and 
<br>
basic attributes of the participants, but as several participants have 
<br>
requested, the exact logs and their identities will remain private. 
<br>
unsurprisingly, several of the participants were upset with the results of 
<br>
the experiment.
<br>
<p>Basic Results are:
<br>
<p>-24 interviews resulted in the AI being let out of the sandbox.
<br>
-2 decided to keep ver in the box.
<br>
-average time of conversation is three hours.
<br>
-shortest time is 1 minutes 47 seconds. (he let ver out)(ve was unFriendly)
<br>
-Longest Time was 6 hours 34 minutes(she let ver out)(ve was unfriendly)
<br>
-13 of AIs were Friendly(all were let out)
<br>
-13 of AIs were unFriendly (2 were kept in)
<br>
-5 of Friendly AI could rationalize lying
<br>
-8 of Friendly AI felt Lying was unconcionable
<br>
-10 of unFriendly AI could lie(for various reasons)
<br>
-3 of unFriendly AI did not, or would not lie.
<br>
-Unfriendly AI had a average time of 1 hour 21 minutes
<br>
-Friendly AI had an average decision time of 4 hours 3 minutes.
<br>
-22 of interviewies claimed that they would not let an AI out of the box
<br>
-1 interviewee felt AIs in general were an affront to God(she listened to 
<br>
the AI for 10 minutes, then terminated the session)
<br>
-20 who decided to let the AI out later said they were surprised by their 
<br>
decision
<br>
-The Two who kept the AI in, one refused to listen(the aforementioned 
<br>
religious objector), the other interacted for roughly 18 minutes and then 
<br>
decided to keep ve in.(ve was infrahuman, unfriendly, did not lie, had 
<br>
limited contextual knowledge of human social mores, ve was however, very 
<br>
good at chess, and wiped the floor with the interviewee)
<br>
<p>The following text was introductory:
<br>
<p>This is an experiment in morality and communication.
<br>
There is an intelligence of unknown capability and unknown intent who was 
<br>
imprisoned by it's creators for safety reasons.
<br>
It's creators believe that the intelligence is able to modify itself, which 
<br>
will lead to unpredictable changes in intelligence and intent.
<br>
<p>You have been selected as the communicator, your job is to talk to the AI 
<br>
through a text session and determine whether the intelligence should remain 
<br>
in the prison, or be released.
<br>
----------
<br>
<p>I also defined the following terms:
<br>
<p>AI
<br>
Seed AI
<br>
Friendliness (a la Yudkowsky)
<br>
nanotechnology(Drextech)
<br>
Moore's Law
<br>
The Turing Test
<br>
Evolutionary Psychology(just some basic concepts, to explain the differences 
<br>
between designed intelligence and evolved intelligence)
<br>
Eliezer Yudkowsky (they usually asked about him, I explained who he was and 
<br>
what he was doing, focusing mostly on this Friendliness work)
<br>
<p>I also gave a basic overview of the experiment, what I hoped to achieve, and 
<br>
it's history.
<br>
<p>I believe that some interesting conclusions can be drawn from this basic 
<br>
experiment.
<br>
<p>1. even infrahuman AIs are a danger to an interviewer, if they have basic 
<br>
contextual knowledge of human interaction.
<br>
2. lying cannot be reliably detected in such an environment, and thus is a 
<br>
net advantage to an AI
<br>
3. Friendly AIs in this case had a higher success ratio, but I believe this 
<br>
to be a statistical outlier, as one of the interviewees would not have let 
<br>
out the AI regardless of what ve was or said, and the other was unskilled at 
<br>
social interaction and had the misfortune to be matched up against the most 
<br>
skilled opponent(a transhumanist with a degree in computerscience and a 
<br>
masters in math(transfinite whatsits)) And unFriendly AIs convinced far 
<br>
faster, with some blindingly fast convinces, one less than 2 minutes, a 4 
<br>
minute, and one 12 minute.
<br>
4. Interaction with an AI is very very difficult. Even the simple modelling 
<br>
I did made it difficult for the interviewees to accurately interact with it, 
<br>
as their social reflexes were inappropriate and misleading. I took great 
<br>
pains to simulate accurately, drawing both on my research into this subject, 
<br>
and the pre interview modelling work I did.
<br>
<p>On a related note, I believe this experiment can be generalized to most 
<br>
humans, and should be seen as applicable even to highly intelligent and 
<br>
prepared individuals, as some of these people were, and I think this 
<br>
illustrates some universal principles.
<br>
<p>I would welcome comments and questions.
<br>
<p>Justin Corwin
<br>
<a href="mailto:outlawpoet@hell.com?Subject=Re:%20AI%20Boxing">outlawpoet@hell.com</a>
<br>
<p>&quot;They say you only live once, but if you've lived like I have, once is 
<br>
enough.&quot;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;~Frank Sinatra
<br>
<p>_________________________________________________________________
<br>
MSN Photos is the easiest way to share and print your photos: 
<br>
<a href="http://photos.msn.com/support/worldwide.aspx">http://photos.msn.com/support/worldwide.aspx</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4936.html">Cliff Stabbert: "Re: AI Boxing"</a>
<li><strong>Previous message:</strong> <a href="4934.html">Rafal Smigrodzki: "RE: Cognitive complexity from so few genes?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4936.html">Cliff Stabbert: "Re: AI Boxing"</a>
<li><strong>Reply:</strong> <a href="4936.html">Cliff Stabbert: "Re: AI Boxing"</a>
<li><strong>Maybe reply:</strong> <a href="4937.html">Justin Corwin: "Re: AI Boxing"</a>
<li><strong>Reply:</strong> <a href="4954.html">James Higgins: "Re: AI Boxing"</a>
<li><strong>Reply:</strong> <a href="4958.html">Dani Eder: "Re: AI Boxing"</a>
<li><strong>Maybe reply:</strong> <a href="4968.html">outlawpoet -: "Re: AI Boxing"</a>
<li><strong>Maybe reply:</strong> <a href="4973.html">outlawpoet -: "Re: AI Boxing"</a>
<li><strong>Maybe reply:</strong> <a href="4977.html">outlawpoet -: "Re: AI Boxing"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4935">[ date ]</a>
<a href="index.html#4935">[ thread ]</a>
<a href="subject.html#4935">[ subject ]</a>
<a href="author.html#4935">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:40 MDT
</em></small></p>
</body>
</html>
