<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Intelligence and wisdom</title>
<meta name="Author" content="Gordon Worley (redbird@rbisland.cx)">
<meta name="Subject" content="Re: Intelligence and wisdom">
<meta name="Date" content="2002-07-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Intelligence and wisdom</h1>
<!-- received="Wed Jul 17 12:26:21 2002" -->
<!-- isoreceived="20020717182621" -->
<!-- sent="Wed, 17 Jul 2002 12:20:19 -0400" -->
<!-- isosent="20020717162019" -->
<!-- name="Gordon Worley" -->
<!-- email="redbird@rbisland.cx" -->
<!-- subject="Re: Intelligence and wisdom" -->
<!-- id="16A71E8E-99A1-11D6-92B7-000A27B4DEFC@rbisland.cx" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="001f01c22d46$8d3d9860$0100a8c0@mitch" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Gordon Worley (<a href="mailto:redbird@rbisland.cx?Subject=Re:%20Intelligence%20and%20wisdom"><em>redbird@rbisland.cx</em></a>)<br>
<strong>Date:</strong> Wed Jul 17 2002 - 10:20:19 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4923.html">Dani Eder: "RE: Catholics and the Singularity"</a>
<li><strong>Previous message:</strong> <a href="4921.html">jg nlb: "Re: Why do we seek to transcend ourselves?"</a>
<li><strong>In reply to:</strong> <a href="4914.html">Mitch Howe: "Re: Intelligence and wisdom"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4926.html">Cliff Stabbert: "Re: Intelligence and wisdom"</a>
<li><strong>Reply:</strong> <a href="4926.html">Cliff Stabbert: "Re: Intelligence and wisdom"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4922">[ date ]</a>
<a href="index.html#4922">[ thread ]</a>
<a href="subject.html#4922">[ subject ]</a>
<a href="author.html#4922">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Wednesday, July 17, 2002, at 12:00  AM, Mitch Howe wrote:
<br>
<p><em>&gt; I'll admit that I am assuming, but I don't see any AI programmers 
</em><br>
<em>&gt; valuing
</em><br>
<em>&gt; Kirk's human side over Spock's vulcan logic to the point they are 
</em><br>
<em>&gt; expressly
</em><br>
<em>&gt; working irrational behavior into their designs.  But, in the event that 
</em><br>
<em>&gt; such
</em><br>
<em>&gt; programming did occur, whether intentional or otherwise, then such an AI
</em><br>
<em>&gt; would be acting at times in ways that do not correlate with its own
</em><br>
<em>&gt; goals/values -- even if these goals were good, even if it had adequate
</em><br>
<em>&gt; information available, and even if it had the intelligence/time to 
</em><br>
<em>&gt; make a
</em><br>
<em>&gt; good decision.  This is either a broken, buggy, or intentionally 
</em><br>
<em>&gt; dangerous
</em><br>
<em>&gt; AI, and, by my definition, foolish.  I cannot think of any other 
</em><br>
<em>&gt; situation
</em><br>
<em>&gt; that would earn an AI this description.
</em><br>
<p>Irrational thought is the result of obeying the wrong goals using those 
<br>
goals to rationalize why you shouldn't change your goal to the more 
<br>
rational goal X.  Whatever any mind does is in accordance with it's 
<br>
goals (that's how it decides what to do; it can't act against its own 
<br>
goals without changing them, in which case it's not acting against it's 
<br>
current goals).  It can act against what it knows to be in its best 
<br>
interests (i.e. what it thinks it's goals ought to be), though, but 
<br>
those are only `goals' in a loose sense.
<br>
<p><em>&gt; d)An SI possessing all of the knowledge you do currently, plus a lot 
</em><br>
<em>&gt; more,
</em><br>
<em>&gt; after what amounts to 10 human years of reflection. (10 actual seconds)
</em><br>
<em>&gt;
</em><br>
<em>&gt; e)An SI possessing all of the knowledge you do currently, plus a lot 
</em><br>
<em>&gt; more,
</em><br>
<em>&gt; after what amounts to 5 million human years of reflection. (57.9 actual
</em><br>
<em>&gt; days)
</em><br>
<p>This isn't quite right.  For any given problem, there is some limit on 
<br>
how much useful thought can be done towards solving it.  For example, I 
<br>
can find the answer to 2 + 2 pretty quickly (I have it memorized, so I 
<br>
don't even do the math anymore, but assuming I didn't and I had to do 
<br>
all of the work from scratch assuming a basic knowledge of counting) and 
<br>
spend some time proving this.  But, after a few hours at most, there 
<br>
aren't really any more proofs or experiments that I can run to prove 
<br>
that the answer is 4.  Plus, there is likely some penalty for not 
<br>
answering quickly, so I won't run a ton of experiments and write a lot 
<br>
of proofs; I'll find some optimal number that gives a satisfiable answer 
<br>
within a margin of error that is small enough not to be statistically 
<br>
significant.
<br>
<p>Also, an SI's thought processes don't work down to X years of human 
<br>
thought.  An SI can think things that a human would never think (just as 
<br>
a human can think things a dog would never think).  Maybe 10 seconds of 
<br>
SI thought is overkill for your `deep' philosophical question.  Maybe it 
<br>
only takes 2, or 0.5.  For any question we ask an SI, there is a time 
<br>
penalty of mistakes we'll make until we have the answer.  For some 
<br>
problems this isn't a big deal, but if we ask the SI to solve the 
<br>
uploading problem then we don't want this to take too long because in 
<br>
the mean time people will die or we might blow ourselves up.
<br>
<p>The SI will take however much time is required to find the answer.  Same 
<br>
goes for the human options:  no need to spend any fixed amount of time, 
<br>
just the right amount of time.
<br>
<p>To be fair, knowing what the right amount of time may not always be 
<br>
obvious.  It takes having a deep understanding of the issues involved in 
<br>
solving the problem to know if you've really got the answer or not.
<br>
<p><pre>
--
Gordon Worley                     `When I use a word,' Humpty Dumpty
<a href="http://www.rbisland.cx/">http://www.rbisland.cx/</a>            said, `it means just what I choose
<a href="mailto:redbird@rbisland.cx?Subject=Re:%20Intelligence%20and%20wisdom">redbird@rbisland.cx</a>                it to mean--neither more nor less.'
PGP:  0xBBD3B003                                  --Lewis Carroll
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4923.html">Dani Eder: "RE: Catholics and the Singularity"</a>
<li><strong>Previous message:</strong> <a href="4921.html">jg nlb: "Re: Why do we seek to transcend ourselves?"</a>
<li><strong>In reply to:</strong> <a href="4914.html">Mitch Howe: "Re: Intelligence and wisdom"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4926.html">Cliff Stabbert: "Re: Intelligence and wisdom"</a>
<li><strong>Reply:</strong> <a href="4926.html">Cliff Stabbert: "Re: Intelligence and wisdom"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4922">[ date ]</a>
<a href="index.html#4922">[ thread ]</a>
<a href="subject.html#4922">[ subject ]</a>
<a href="author.html#4922">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:40 MDT
</em></small></p>
</body>
</html>
