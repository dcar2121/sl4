<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: SL4 meets &quot;Pinky and the Brain&quot;</title>
<meta name="Author" content="James Higgins (jameshiggins@earthlink.net)">
<meta name="Subject" content="Re: SL4 meets &quot;Pinky and the Brain&quot;">
<meta name="Date" content="2002-07-16">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: SL4 meets &quot;Pinky and the Brain&quot;</h1>
<!-- received="Tue Jul 16 13:41:10 2002" -->
<!-- isoreceived="20020716194110" -->
<!-- sent="Tue, 16 Jul 2002 10:36:56 -0700" -->
<!-- isosent="20020716173656" -->
<!-- name="James Higgins" -->
<!-- email="jameshiggins@earthlink.net" -->
<!-- subject="Re: SL4 meets &quot;Pinky and the Brain&quot;" -->
<!-- id="3D3459B8.2060208@earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="LAEGJLOGJIOELPNIOOAJOENFCMAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Higgins (<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20SL4%20meets%20&quot;Pinky%20and%20the%20Brain&quot;"><em>jameshiggins@earthlink.net</em></a>)<br>
<strong>Date:</strong> Tue Jul 16 2002 - 11:36:56 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4884.html">James Higgins: "Re: Intelligence and wisdom"</a>
<li><strong>Previous message:</strong> <a href="4882.html">Ben Goertzel: "RE: Intelligence and wisdom"</a>
<li><strong>In reply to:</strong> <a href="4867.html">Ben Goertzel: "RE: SL4 meets &quot;Pinky and the Brain&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4909.html">Ben Goertzel: "RE: SL4 meets &quot;Pinky and the Brain&quot;"</a>
<li><strong>Reply:</strong> <a href="4909.html">Ben Goertzel: "RE: SL4 meets &quot;Pinky and the Brain&quot;"</a>
<li><strong>Reply:</strong> <a href="4945.html">Dani Eder: "Re: SL4 meets &quot;Pinky and the Brain&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4883">[ date ]</a>
<a href="index.html#4883">[ thread ]</a>
<a href="subject.html#4883">[ subject ]</a>
<a href="author.html#4883">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Goertzel wrote:
<br>
<em> &gt;&gt;James, this is pure slander.
</em><br>
<em> &gt;
</em><br>
<em> &gt; Seriously: I think I'm going to have to side with Eli on this topic.
</em><br>
<em> &gt;
</em><br>
<em> &gt; &quot;Taking over the world&quot; has the flavor of trying to make oneself,
</em><br>
<em> &gt; personally, the ruler of the world, so that one can enforce one's 
</em><br>
whims and
<br>
<em> &gt; desires and plans on the world in detail.  This is not what Eliezer is
</em><br>
<em> &gt; proposing, exactly.
</em><br>
<p>I think that &quot;exactly&quot; is where the problem arises.  I've already
<br>
explained my reasoning in another post and, once again, I apologize
<br>
about the conotation.  If I was wiser I would have couched it better.
<br>
<p><em> &gt; In fact, he is not even proposing to create software that will definitely
</em><br>
<em> &gt; &quot;take over the world&quot;.
</em><br>
<p>He has in the past, but this is a moot point and was not related to my
<br>
reasoning on that post.
<br>
<p><em> &gt; &gt; I think he is proposing to create software that will have a *huge 
</em><br>
influence*
<br>
<em> &gt; on the world, but not necessarily control it in any full &amp; complete way.
</em><br>
<em> &gt;
</em><br>
<em> &gt; And, I am proposing to do effectively the same thing.  Anyone seeking to
</em><br>
<p>Right, you also qualify as wanting to take over the world.  Taking over
<br>
the world to create a utopia (a real one, not some fluffy vision of one)
<br>
would be a good reason to do such a thing, but could still entale taking
<br>
over the world (at least as a starting point).
<br>
<p><em> &gt; produce superhuman AI is really pushing in this direction, whether they
</em><br>
<em> &gt; admit it to themselves or not.  It's only to be expected that a 
</em><br>
superhumanly
<br>
<em> &gt; intelligent mind is going to
</em><br>
<em> &gt;
</em><br>
<em> &gt; 1) have the capability to &quot;rule the world.&quot;
</em><br>
<em> &gt;
</em><br>
<em> &gt; 2) exercise at least its capability to *strongly influence* the world
</em><br>
<em> &gt; [understanding that it may lack the inclination to actually *rule* the
</em><br>
<em> &gt; world]
</em><br>
<p>Exactly.  But in regards to that &quot;exactly&quot; above #2 is kinda a grey
<br>
area.  You don't have to be &quot;President of Earth&quot; if you control the
<br>
financial markets...
<br>
<p><em> &gt; To illustrate this point, let's consider a science-fictional &quot;semi-hard
</em><br>
<em> &gt; takeoff&quot; scenario.  Suppose in 2040 we have a world with lots of advanced
</em><br>
<em> &gt; tech, including a superhuman mind living in a data warehouse in Peoria.
</em><br>
<em> &gt; Suppose some human loonies try to hijack a plane and fly it into the data
</em><br>
<em> &gt; warehouse.  What's the AI gonna do?  Ok, it's going to stop the plane 
</em><br>
from
<br>
<em> &gt; making impact.  But after that, what?  It has three choices
</em><br>
<em> &gt;
</em><br>
<em> &gt; 1) take over the world, enforcing a benevolent dictatorship to prevent
</em><br>
<em> &gt; stupid humans from doing future stupid things to it and to each other
</em><br>
<em> &gt; 2) make itself super-secure and hide out, letting us humans maul each 
</em><br>
other
<br>
<em> &gt; as we wish, but making itself impervious to damage
</em><br>
<em> &gt; 3) try to nudge and influence the human world, to make it a better place
</em><br>
<em> &gt; (while making itself more secure at the same time)...
</em><br>
<em> &gt;
</em><br>
<em> &gt; Let's say it mulls things over and decides it has a responsiblity to help
</em><br>
<em> &gt; humans as well as itself, so it chooses path 3).  But it doesn't want 
</em><br>
to be
<br>
<em> &gt; too intrusive.  It decides that releasing drugs into the water supply 
</em><br>
that
<br>
<em> &gt; would make us less violent would be too controlling and intrusive, too
</em><br>
<em> &gt; dictatorial.  So it decides to release a global advertising campaign,
</em><br>
<em> &gt; calculated with superhuman intelligence to affect human attitudes in a
</em><br>
<em> &gt; certain way.  It creates movies, video games, ad spots, teledildonic 
</em><br>
fantasy
<br>
<em> &gt; VR scenarios.  It discovers it can control our minds highly 
</em><br>
effectively in
<br>
<em> &gt; this way, without resorting to direct brain control or to physical 
</em><br>
violence
<br>
<em> &gt; based control.
</em><br>
<p>I'd call this ruling the world.  *It* decides how everyone should be.
<br>
Just because it shows some restraint in how it does it and what areas it
<br>
chooses to influence does not change the fact that it is, in effect,
<br>
ruling the world.  The key is that *it* makes all of those decisions and
<br>
they are all within its own power.
<br>
<p><em> &gt; It's not a question of trying to take over the world, it's a question of
</em><br>
<em> &gt; trying to build and bias future beings that are going to either take over
</em><br>
<em> &gt; the world or strongly influence it.
</em><br>
<p>So, once again, I apologize for how my post came across.  I believe what
<br>
I said to be factual but it definately came off the wrong way.  The US
<br>
government rules my/our country but that is, most of the time, a good
<br>
things (compared to the alternatives).  &quot;Ruling the World&quot; is neither
<br>
good nor bad, right nor wrong.  How one rules the world determines such
<br>
things.  Creating a Singularity is not directly ruling the world, but is
<br>
doing that pretty much by proxy since the AI would have had golas and
<br>
beliefs in rough approximation to those the programmer(s) wanted it to have.
<br>
<p>James Higgins
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4884.html">James Higgins: "Re: Intelligence and wisdom"</a>
<li><strong>Previous message:</strong> <a href="4882.html">Ben Goertzel: "RE: Intelligence and wisdom"</a>
<li><strong>In reply to:</strong> <a href="4867.html">Ben Goertzel: "RE: SL4 meets &quot;Pinky and the Brain&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4909.html">Ben Goertzel: "RE: SL4 meets &quot;Pinky and the Brain&quot;"</a>
<li><strong>Reply:</strong> <a href="4909.html">Ben Goertzel: "RE: SL4 meets &quot;Pinky and the Brain&quot;"</a>
<li><strong>Reply:</strong> <a href="4945.html">Dani Eder: "Re: SL4 meets &quot;Pinky and the Brain&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4883">[ date ]</a>
<a href="index.html#4883">[ thread ]</a>
<a href="subject.html#4883">[ subject ]</a>
<a href="author.html#4883">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:40 MDT
</em></small></p>
</body>
</html>
