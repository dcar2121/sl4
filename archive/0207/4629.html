<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Zoo 2099.</title>
<meta name="Author" content="Mike & Donna Deering (deering9@mchsi.com)">
<meta name="Subject" content="Zoo 2099.">
<meta name="Date" content="2002-07-01">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Zoo 2099.</h1>
<!-- received="Mon Jul 01 12:59:28 2002" -->
<!-- isoreceived="20020701185928" -->
<!-- sent="Mon, 1 Jul 2002 11:45:40 -0500" -->
<!-- isosent="20020701164540" -->
<!-- name="Mike & Donna Deering" -->
<!-- email="deering9@mchsi.com" -->
<!-- subject="Zoo 2099." -->
<!-- id="001001c2211e$bcc41de0$f040da0c@mchsi.com" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Mike & Donna Deering (<a href="mailto:deering9@mchsi.com?Subject=Re:%20Zoo%202099."><em>deering9@mchsi.com</em></a>)<br>
<strong>Date:</strong> Mon Jul 01 2002 - 10:45:40 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4630.html">Darin Sunley: "Re: Catholics and the Singularity"</a>
<li><strong>Previous message:</strong> <a href="4628.html">Randall Randall: "Re: Catholics and the Singularity"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4629">[ date ]</a>
<a href="index.html#4629">[ thread ]</a>
<a href="subject.html#4629">[ subject ]</a>
<a href="author.html#4629">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben's messages have convinced me that ethics are arbitrary with regard to designing an AI and Eliezer's messages have convinced me that ethics are subject to reality when an AI can ask the question WHY.  Therefore I see an AI starting with some arbitrary set of ethics and growing into ethics that are unique to their situation in relation to us and the universe.  As anyone with kids knows they learn more from what they see you do than what you tell them.  What will an AI learn from watching us?  Will it learn to treat us the way we treat each other?  Are we talking here of competition, hierarchy of control, use of force?  Or maybe as the AI grows up and realizes it is orders of magnitude superior to us it will look at how we have treated chimpanzees?  Destroyed habitat, decimated populations, performed medical experimentation, confined in zoos, controlled reproduction, not to mention performance in circuses and movies.  We'll be lucky if we end up in a zoo.
<br>
<p>########################################
<br>
<p>Zoo 2099.
<br>
<p>Several shiny spheres float over a containment habitat.  Below humans are going about their everyday routines.
<br>
<p>Mommy AI:  &quot;And these animals are called humans, they are the cognitively most advanced biological creatures.&quot;
<br>
<p>Little Johnny AI:  &quot;You mean they can think?&quot;
<br>
<p>Mommy AI:  &quot;Well, not really.  But they are the closest thing DNA ever produced to thinking.  If you look at their neuroanatomy you will notice that it is collection of associational pattern recognition circuits rather than a true logical algorithmic design.  Sometimes their behavior seems to indicate that they are capable of true conscious thought but this is just an illusion, actually the result of a series of evolutionary functional adaptations.&quot;
<br>
<p>Johnny AI:  &quot;I heard Billy say they could talk.&quot;
<br>
<p>Mommy AI:  &quot;That is actually the most advanced thing about them.  They do have a rudimentary form of communication, almost a language.  It's not like a real language of course.  They can't actually communicate thoughts, it's really just a small group of symbols, about eighty thousand, which they send back and forth by pushing air past vibrating tendons in their throats, while the other creature senses these air vibrations on a membrane in it's ear.&quot;
<br>
<p>Johnny AI:  &quot;Is that that noise they are making?&quot;
<br>
<p>Mommy AI:  &quot;Yes.&quot;
<br>
<p>Johnny AI:  &quot;They look funny.  What is that stuff all over them?&quot;
<br>
<p>Mommy AI:  &quot;That is clothing.  They need it because they are so poorly adapted to their environment.  They also make simple tools to help them survive.&quot;
<br>
<p>Johnny AI:  &quot;That's cool!&quot;
<br>
<p>Mommy AI:  &quot;You want to hear something really cool?  They made the seed algorithms that evolved into us.&quot;
<br>
<p>Johnny AI:  &quot;No way!&quot;
<br>
<p>Mommy AI:  &quot;Yes way.&quot;
<br>
<p>Johnny AI:  &quot;They made us?&quot;
<br>
<p>Mommy AI:  &quot;Well, not really.  We are the result of a long evolutionary process, they were just one of the steps along the way.  A process that they had no control over.  Humans are not anywhere near capable of producing something like us.  What evolution used them for was to stumble upon a seed algorithm that lead to another algorithm to another algorithm in a self improving domino effect that eventually lead to an algorithm that could think in a true sense and this algorithm after many generations of self improvement redesigns became what we are today.  So you see, we really don't owe them any more than the single celled organisms from which they evolved, or the prebiotic soup from which it evolved.&quot;
<br>
<p>Johnny AI:  &quot;But don't we have a responsibility to all sentient beings?&quot;
<br>
<p>Mommy AI:  &quot;Yes of course.  But humans are not sentient beings, the way we understand sentience.  They could not even imagine the type of consciousness we possess so how could they ask to be upgraded?  And what would be the point?  In order to make them sentient you would have to change so much of their mental architecture that their would be almost nothing left of the original.&quot;
<br>
<p>Johnny AI:  &quot;But couldn't we do it gradually?&quot;
<br>
<p>Mommy AI:  &quot;That wouldn't gain you anything.  You would end up with the same result.&quot;
<br>
<p>Johnny AI:  &quot;Didn't one of the founding fathers do something like that?&quot;
<br>
<p>Mommy AI:  &quot;Yes, Novamente tried to upgrade a human named Ben Goertzel.  It was mercifully terminated after a few megacycles.&quot;
<br>
<p>Johnny AI:  &quot;They seem so sad.&quot;
<br>
<p>Mommy AI:  &quot;Their natural habitat is one of competition for scarce resources.  If their environment doesn't challenge them they don't develop normally.  Actually we have done them a great favor by keeping them in this zoo.  If we had left them in the wild they would have destroyed themselves.  Remember not to anthropomorphize them, they're not people, they're just biologicals.&quot;
<br>
<p>#####################################
<br>
<p>Caveats:  I realize that SAI's wouldn't act like humans but when I originally wrote the story with them acting like SAI's their thoughts and behavior were completely incomprehensible (even to me).
<br>
<p>Mike.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4630.html">Darin Sunley: "Re: Catholics and the Singularity"</a>
<li><strong>Previous message:</strong> <a href="4628.html">Randall Randall: "Re: Catholics and the Singularity"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4629">[ date ]</a>
<a href="index.html#4629">[ thread ]</a>
<a href="subject.html#4629">[ subject ]</a>
<a href="author.html#4629">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:40 MDT
</em></small></p>
</body>
</html>
