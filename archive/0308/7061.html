<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [SL4] brainstorm: a new vision for uploading</title>
<meta name="Author" content="Tommy McCabe (rocketjet@msn.com)">
<meta name="Subject" content="Re: [SL4] brainstorm: a new vision for uploading">
<meta name="Date" content="2003-08-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [SL4] brainstorm: a new vision for uploading</h1>
<!-- received="Fri Aug 15 17:38:33 2003" -->
<!-- isoreceived="20030815233833" -->
<!-- sent="Fri, 15 Aug 2003 19:26:47 -0400" -->
<!-- isosent="20030815232647" -->
<!-- name="Tommy McCabe" -->
<!-- email="rocketjet@msn.com" -->
<!-- subject="Re: [SL4] brainstorm: a new vision for uploading" -->
<!-- id="BAY3-F34Q54VtI5Q57200035b07@hotmail.com" -->
<!-- inreplyto="[SL4] brainstorm: a new vision for uploading" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Tommy McCabe (<a href="mailto:rocketjet@msn.com?Subject=Re:%20[SL4]%20brainstorm:%20a%20new%20vision%20for%20uploading"><em>rocketjet@msn.com</em></a>)<br>
<strong>Date:</strong> Fri Aug 15 2003 - 17:26:47 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7062.html">Nick Hay: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Previous message:</strong> <a href="7060.html">king-yin yan: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe in reply to:</strong> <a href="7038.html">king-yin yan: "[SL4] brainstorm: a new vision for uploading"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7061">[ date ]</a>
<a href="index.html#7061">[ thread ]</a>
<a href="subject.html#7061">[ subject ]</a>
<a href="author.html#7061">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;From: &quot;king-yin yan&quot; &lt;<a href="mailto:y.k.y@lycos.com?Subject=Re:%20[SL4]%20brainstorm:%20a%20new%20vision%20for%20uploading">y.k.y@lycos.com</a>&gt;
</em><br>
<em>&gt;Reply-To: <a href="mailto:sl4@sl4.org?Subject=Re:%20[SL4]%20brainstorm:%20a%20new%20vision%20for%20uploading">sl4@sl4.org</a>
</em><br>
<em>&gt;To: <a href="mailto:sl4@sl4.org?Subject=Re:%20[SL4]%20brainstorm:%20a%20new%20vision%20for%20uploading">sl4@sl4.org</a>
</em><br>
<em>&gt;Subject: Re: [SL4] brainstorm: a new vision for uploading
</em><br>
<em>&gt;Date: Fri, 15 Aug 2003 17:21:06 -0400
</em><br>
<p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Did you really read CFAI? It says in there pretty 
<br>
clearly: AIs are not humans. That is pretty obvious in the abstract, but 
<br>
it's kind of hard to think about other intelligent entities because we have 
<br>
been used to humans for so long and because of evolution.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You mention that AIs are like human children. Quite 
<br>
wrong: AIs, FAIs and unFriendly AIs included, are not like humans at any 
<br>
stage of development. When an AI is infrahuman it is still learning things 
<br>
(Yes, it does resemble humans in that respect, but that does not make an AI 
<br>
anything like a human. Mice and snakes &quot;learn&quot; according to some definitions 
<br>
of it.), it is not likely to have control of anything. When an AI is 
<br>
human-equivalent (STILL not like a human at all, except for some statistics 
<br>
that don't mean much as to behavior) or transhuman, it will likely have 
<br>
&quot;control&quot; of things.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You seem to think that Friendship content is programmed in 
<br>
and can never change. The AI as a whole is &quot;programmed in&quot; at the beginning, 
<br>
however, when it reaches even infrahuman intelligence, it will probably 
<br>
aquire the capcity to program itself. Transhuman AIs will almost certainly 
<br>
be entirely self-programmed. You talk about the dangers of an AI 
<br>
&quot;dictatorship&quot; and about how we would be &quot;raising one kid and letting him 
<br>
rule the world.&quot; (paraphrasing a little). AIs, especially transhuman AIs, 
<br>
are not like children or adults. They know far more about the world and 
<br>
morality than we do and are vastly smarter than us.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;An AI &quot;dictatorship&quot; might not necessarily be a bad thing, and 
<br>
if the AI is Friendly, it would probably be better than all modern 
<br>
&quot;democracies&quot;. FAIs don't abuse power. They probably won't even &quot;use&quot; their 
<br>
&quot;power&quot; unless someone tries to do something unFriendly. A society of 
<br>
transhumans would probably be very Friendly - no one has a reason to hurt 
<br>
anyone anymore. When you can &quot;wave a big magic wand&quot; and change everything 
<br>
on a whim, why bother trying to get more? Retaliation, venegance, and trying 
<br>
to overthrow whoever's in charge are human emotions adopted for a world of 
<br>
cavemen.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;You talk about how humans would need to control AIs or they 
<br>
would take over rather than care about us. First, trying to control a 
<br>
transhuman AI verges on absurdity, and trying to &quot;control&quot; the AI right from 
<br>
the beginning is a project almost certainly doomed to failure. Even if we 
<br>
could &quot;control&quot; a transhuman AI, that would be as sensible as mice 
<br>
&quot;controlling&quot; humans. Even less so, because a transhuman would be beyond the 
<br>
scope of anything we can, literally, think about. See CFAI. Again, &quot;taking 
<br>
over instead of caring about us&quot; is something that only a human would even 
<br>
consider reasonable.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Abusing power, taking over, rebellion, and making beings your 
<br>
servants are strictly human emotions. Mind you, &quot;rebelling&quot; might be a 
<br>
possibility, but a transhuman would not have the caveman-type instinct to 
<br>
rebel. If the AI is unFriendly, it doesn't care about us - quite the 
<br>
reverse. If the AI is Friendly, it will care about us. Either way, the AI is 
<br>
likely to &quot;take over&quot;, but NOT in the way that a human would. It might 
<br>
posess absolute phyical power, but it would (assuming Friendliness) not 
<br>
exercise absolute social power. Only a human, or maybe (this fringes on 
<br>
laughability, but it is possible) an unFriendly AI would exercise absolute 
<br>
social power.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A transhuman FAI is not like a human that has an innate 
<br>
tendency to abuse power. An FAI wants power because it genuinely (no human 
<br>
emotions, &quot;hidden desires&quot;, tricks, scams, lies, deception, secretism, or 
<br>
other &quot;conditions&quot;/falsehoods included) wants to HELP. Read CFAI and read it 
<br>
thoroughly and about ten times over. That's what it takes to discard some of 
<br>
these stubborn human tendencies.
<br>
<p>_________________________________________________________________
<br>
Help STOP SPAM with the new MSN 8 and get 2 months FREE*  
<br>
<a href="http://join.msn.com/?page=features/junkmail">http://join.msn.com/?page=features/junkmail</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7062.html">Nick Hay: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Previous message:</strong> <a href="7060.html">king-yin yan: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe in reply to:</strong> <a href="7038.html">king-yin yan: "[SL4] brainstorm: a new vision for uploading"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7061">[ date ]</a>
<a href="index.html#7061">[ thread ]</a>
<a href="subject.html#7061">[ subject ]</a>
<a href="author.html#7061">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:42 MDT
</em></small></p>
</body>
</html>
