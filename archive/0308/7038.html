<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: [SL4] brainstorm: a new vision for uploading</title>
<meta name="Author" content="king-yin yan (y.k.y@lycos.com)">
<meta name="Subject" content="[SL4] brainstorm: a new vision for uploading">
<meta name="Date" content="2003-08-12">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>[SL4] brainstorm: a new vision for uploading</h1>
<!-- received="Tue Aug 12 17:31:18 2003" -->
<!-- isoreceived="20030812233118" -->
<!-- sent="Tue, 12 Aug 2003 19:30:55 -0400" -->
<!-- isosent="20030812233055" -->
<!-- name="king-yin yan" -->
<!-- email="y.k.y@lycos.com" -->
<!-- subject="[SL4] brainstorm: a new vision for uploading" -->
<!-- id="HHEMEAPPBIDMFCAA@mailcity.com" -->
<!-- charset="us-ascii" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> king-yin yan (<a href="mailto:y.k.y@lycos.com?Subject=Re:%20[SL4]%20brainstorm:%20a%20new%20vision%20for%20uploading"><em>y.k.y@lycos.com</em></a>)<br>
<strong>Date:</strong> Tue Aug 12 2003 - 17:30:55 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7039.html">Mitchell Porter: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Previous message:</strong> <a href="7037.html">Tyler Emerson: "ACC2003, Final Early Bird Deadline"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7039.html">Mitchell Porter: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7039.html">Mitchell Porter: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Reply:</strong> <a href="7040.html">Nick Hay: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7042.html">Mitchell Porter: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7047.html">Joshua Hublar: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7054.html">king-yin yan: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7059.html">king-yin yan: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7060.html">king-yin yan: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7061.html">Tommy McCabe: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7038">[ date ]</a>
<a href="index.html#7038">[ thread ]</a>
<a href="subject.html#7038">[ subject ]</a>
<a href="author.html#7038">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hello Everyone
<br>
<p>I have been thinking about uploading for a long time, especially the
<br>
gradual uploading approach, which I like. But this approach brings up
<br>
one issue which is the &quot;continuity of the soul&quot; problem. People who
<br>
opt for a destructive upload would gain a &quot;first-move&quot; advantage
<br>
over others. So I started to look at the Singularity to see if it
<br>
offers any solution.
<br>
<p>(By the way I have personally convinced myself that uploading is
<br>
achievable around 20-30 years from now.)
<br>
<p>I think Eliezer's vision of a single superAI is rather problematic. I
<br>
think a diversity of specific-purpose AI's is the more likely scenario.
<br>
The reasons are as follows:
<br>
<p>1. The definition of Friendliness is a political issue. There is no such
<br>
thing as value-free, &quot;objective&quot; morality; the Friendly AI can only
<br>
*inherit* the moral system of its creators and share-holders (if done
<br>
right at all!) and the Friendly-AI-as-a-God-like-moral-figure is unsound.
<br>
The debate about Friendliness will itself start a political war, rather
<br>
than solve all political problems.
<br>
<p>2. One may argue that superAI will be very powerful and everyone
<br>
would want to be on &quot;our&quot; side. But this also is an unlikely scenario
<br>
because it does not resolve the problem of *who* will have more
<br>
power within our &quot;party&quot;. Once again this would depend on the
<br>
definition of Friendliness and thus start a war. (I'm actually quite
<br>
pacifist by the way =))
<br>
<p>3. Safety. It is better to diversify the risk by building several AIs
<br>
so in case one goes awry the others (perhaps many others) will be
<br>
able to suppress it -- fault-tolerance of distributive systems. It
<br>
seems the best way is to let a whole lot of people augment their
<br>
intelligence via uploading or *cyborganization*.
<br>
<p>4. The superAI is unfathomable (hence unpredictable) to us, so
<br>
what's the difference between this and other techno-catastrophies?
<br>
<p>5. Even if we have FAI, it probably will not stop some people from
<br>
uploading themselves destructively (They have their rights). This will
<br>
still create inequality between uploaders and those remaining
<br>
flesh-and-blood.
<br>
<p>Therefore the superAI scenario will not happen UNLESS there are
<br>
some compelling reasons to build it. The fear is that destructive
<br>
uploading will create too much of a first-move advantage to the
<br>
effect that everyone would be compelled to follow suit immediately.
<br>
<p>So the goal should be clear: Create a technology for humans that
<br>
would allow them to be on-par with uploads. And I think that
<br>
answer would be: &quot;personal AI&quot;. The PAI starts off like a baby
<br>
and shares the users experience, like a dual existence. By the
<br>
time cyborganization is available, the cyborganization process
<br>
would be like merging with one's personal AI.
<br>
<p>Thus, the rights to transhuman intelligence is distributed to all
<br>
those who can afford it. If you think about it, that is probably
<br>
the only sensible way to deal with computational power
<br>
explosion... ie to create a broadly distributed balance-of-power.
<br>
<p>It doesn't matter that many people may not be techno-savy
<br>
enough to use the AI -- that depends on user-friendliness and
<br>
the best AI should be quite transparent and easy to use.
<br>
<p>Well, this still sounds very vague and difficult, but it's more
<br>
plausible than the superAI scenario already (I think).
<br>
<p>One last problem that remains is poverty. I predict that
<br>
some people will be maginalized from cyborganization, rather
<br>
inevitable. Who am I to save humanity? We have to accept
<br>
this and the next best thing is to maximize availability
<br>
through education and perhaps redistribution of wealth,
<br>
creation of more jobs etc.
<br>
<p>Hope to hear your comments =)
<br>
Yan King Yin
<br>
<p><p><p>____________________________________________________________
<br>
Get advanced SPAM filtering on Webmail or POP Mail ... Get Lycos Mail!
<br>
<a href="http://login.mail.lycos.com/r/referral?aid=27005">http://login.mail.lycos.com/r/referral?aid=27005</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7039.html">Mitchell Porter: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Previous message:</strong> <a href="7037.html">Tyler Emerson: "ACC2003, Final Early Bird Deadline"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7039.html">Mitchell Porter: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7039.html">Mitchell Porter: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Reply:</strong> <a href="7040.html">Nick Hay: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7042.html">Mitchell Porter: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7047.html">Joshua Hublar: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7054.html">king-yin yan: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7059.html">king-yin yan: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7060.html">king-yin yan: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<li><strong>Maybe reply:</strong> <a href="7061.html">Tommy McCabe: "Re: [SL4] brainstorm: a new vision for uploading"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7038">[ date ]</a>
<a href="index.html#7038">[ thread ]</a>
<a href="subject.html#7038">[ subject ]</a>
<a href="author.html#7038">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:42 MDT
</em></small></p>
</body>
</html>
