<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Deliver Us from Evil...?</title>
<meta name="Author" content="Christian L. (n95lundc@hotmail.com)">
<meta name="Subject" content="Re: Deliver Us from Evil...?">
<meta name="Date" content="2001-03-27">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Deliver Us from Evil...?</h1>
<!-- received="Tue Mar 27 18:31:43 2001" -->
<!-- isoreceived="20010328013143" -->
<!-- sent="Tue, 27 Mar 2001 23:13:04 -0000" -->
<!-- isosent="20010327231304" -->
<!-- name="Christian L." -->
<!-- email="n95lundc@hotmail.com" -->
<!-- subject="Re: Deliver Us from Evil...?" -->
<!-- id="F65jqueolj8Jecd92bX00001413@hotmail.com" -->
<!-- inreplyto="Deliver Us from Evil...?" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Christian L. (<a href="mailto:n95lundc@hotmail.com?Subject=Re:%20Deliver%20Us%20from%20Evil...?"><em>n95lundc@hotmail.com</em></a>)<br>
<strong>Date:</strong> Tue Mar 27 2001 - 16:13:04 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0816.html">Dale Johnstone: "Re: Deliver Us from Evil...?"</a>
<li><strong>Previous message:</strong> <a href="0814.html">Christian L.: "Re: Deliver Us from Evil...?"</a>
<li><strong>Maybe in reply to:</strong> <a href="0776.html">Christian L.: "Deliver Us from Evil...?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0104/0893.html">Samantha Atkins: "Re: Deliver Us from Evil...?"</a>
<li><strong>Reply:</strong> <a href="../0104/0893.html">Samantha Atkins: "Re: Deliver Us from Evil...?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#815">[ date ]</a>
<a href="index.html#815">[ thread ]</a>
<a href="subject.html#815">[ subject ]</a>
<a href="author.html#815">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Dale Johnstone wrote:
<br>
<em>&gt;
</em><br>
<em>&gt;Christian L. wrote:
</em><br>
<em>&gt; &gt;When I first started subscribing to this mailing list, I thought that the
</em><br>
<em>&gt; &gt;goal of SingInst was to build a transhuman AI. I was wrong. The goal is
</em><br>
<em>&gt; &gt;obviously to build a Utopia where Evil as defined by the members of the 
</em><br>
<em>&gt;list
</em><br>
<em>&gt; &gt;will be banished. The AI would be a means to that end, a Santa-machine 
</em><br>
<em>&gt;who
</em><br>
<em>&gt; &gt;uses his intelligence to serve mankind.
</em><br>
<em>&gt;
</em><br>
<em>&gt;I can't speak for SingInst but as someone who's working towards the same 
</em><br>
<em>&gt;goal, I'm in it because I see a possible way to do away with death and 
</em><br>
<em>&gt;misery once and for all. Although I'm obsessed with AI, I'd switch to 
</em><br>
<em>&gt;collecting detergent coupons if that would do any good. Unfortunately it 
</em><br>
<em>&gt;doesn't. Building a transhuman AI though does.
</em><br>
<em>&gt;
</em><br>
<p>It might, yes. I agree.
<br>
<p><p><em>&gt;List members do *not* get to define what is evil and what is banished.
</em><br>
<p>Oops. This has already been done:
<br>
<p>&quot;To eliminate all INVOLUNTARY pain, death, coercion, and stupidity from
<br>
the Universe.&quot;
<br>
<p><p><em>&gt;Basically, the idea is to build a really smart mind, and help it to 
</em><br>
<em>&gt;*understand* us and our common desire for a better world in the same way 
</em><br>
<em>&gt;that we do - not by some rigid laws cast in stone, but by thoroughly 
</em><br>
<em>&gt;understanding the subtleties and details. If we've done our job correctly, 
</em><br>
<em>&gt;it will eventually understand this even better that we do. Think of it as 
</em><br>
<em>&gt;raising a child if you prefer.
</em><br>
<em>&gt;
</em><br>
<p>Even if it understands us and our desires, I don't see why it would 
<br>
automatically become our servant. We might understand the desires of an 
<br>
ant-colony, but if we need the place, we remove the anthill.
<br>
<p><p><em>&gt;Okay, next step is to have it create an even better version of itself - 
</em><br>
<em>&gt;actually it will want to do this all by itself because it's such a good 
</em><br>
<em>&gt;idea. It's up to it to choose how to do this, but because it's Friendly and 
</em><br>
<em>&gt;smarter than we are; it'll make its successor (or a modified version of 
</em><br>
<em>&gt;itself) Friendly too. The mark2 version will also do the same, only better. 
</em><br>
<em>&gt;This is what I refer to as the Friendliness attractor. Each successive 
</em><br>
<em>&gt;generation is better able to understand us and better able to help us.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Okay, now for the SysOp idea. This is what Eliezer and many on the list 
</em><br>
<em>&gt;think the AI will come up with in order to be as Friendly and as fair to us 
</em><br>
<em>&gt;as possible. We can't say for sure, but it's the current favourite. We 
</em><br>
<em>&gt;don't get to decide this, the AI does. If the AI eventually thinks of 
</em><br>
<em>&gt;something better then that's what'll happen.
</em><br>
<em>&gt;
</em><br>
<p>My point exactly. I can think of a lot of better things for it to do than 
<br>
serving us. Again, I will try to avoid debating Friendliness until I have 
<br>
read FAI.
<br>
<p><p><em>&gt; &gt;If you organize yourself in a &quot;pack&quot; and follow the rules set up there, 
</em><br>
<em>&gt;you
</em><br>
<em>&gt; &gt;can get personal protection and greater means of achieving your goals 
</em><br>
<em>&gt;(they
</em><br>
<em>&gt; &gt;normally coincide with those of the pack). When you interact with another
</em><br>
<em>&gt; &gt;pack-member, you can be pretty sure that he/she will not break the rules 
</em><br>
<em>&gt;and
</em><br>
<em>&gt; &gt;risk exclusion from the pack. This can be called trust. The rules that 
</em><br>
<em>&gt;the
</em><br>
<em>&gt; &gt;pack sets up can be called ethics.
</em><br>
<em>&gt;
</em><br>
<em>&gt;This is all well and fine in the jungle when about the worst I could do was 
</em><br>
<em>&gt;hit you with a stick. However, pretty soon nanotechnology is going to 
</em><br>
<em>&gt;become readily available and it's practically impossible to defend yourself 
</em><br>
<em>&gt;against it.
</em><br>
If any single individual has the ability to turn the crust into bubbling 
<br>
slag - you can bet your life some crazy nut will do it, either deliberately 
<br>
or by accident.
<br>
<em>&gt;
</em><br>
<p>Probably, yes. That's why it is important to get on with the AI-programming.
<br>
<p><p><em>&gt;The world by and large hasn't woke up to the facts yet. It's clear that 
</em><br>
<em>&gt;things aren't going to get any better by themselves. I hope you can now 
</em><br>
<em>&gt;understand the urgency in our desire to apply a little transhuman 
</em><br>
<em>&gt;intelligence to the problem.
</em><br>
<em>&gt;
</em><br>
<p>I assure you, I did understand it before. I just don't see the point in idle 
<br>
speculation about the actions of eventual SIs. It will do as it pleases. If 
<br>
we manage to program it into Friendliness, it will be Friendly. Maybe it 
<br>
will ignore humans. Maybe it will kill us. I don't know.
<br>
My interests lie in getting to the Singularity. After that, the SI is 
<br>
calling the shots. I don't think that you can plan ahead beyond the 
<br>
singularity, and I certainly am not going to. You can do your best in trying 
<br>
to program a Friendly AI, but in the end, the AI will be in charge.
<br>
<p>Only time will tell what happens after that.
<br>
<p><p><p>/Christian
<br>
<p><p>_________________________________________________________________________
<br>
Get Your Private, Free E-mail from MSN Hotmail at <a href="http://www.hotmail.com">http://www.hotmail.com</a>.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0816.html">Dale Johnstone: "Re: Deliver Us from Evil...?"</a>
<li><strong>Previous message:</strong> <a href="0814.html">Christian L.: "Re: Deliver Us from Evil...?"</a>
<li><strong>Maybe in reply to:</strong> <a href="0776.html">Christian L.: "Deliver Us from Evil...?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0104/0893.html">Samantha Atkins: "Re: Deliver Us from Evil...?"</a>
<li><strong>Reply:</strong> <a href="../0104/0893.html">Samantha Atkins: "Re: Deliver Us from Evil...?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#815">[ date ]</a>
<a href="index.html#815">[ thread ]</a>
<a href="subject.html#815">[ subject ]</a>
<a href="author.html#815">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
