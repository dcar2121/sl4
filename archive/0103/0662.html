<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: How To Live In A Simulation</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: How To Live In A Simulation">
<meta name="Date" content="2001-03-14">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: How To Live In A Simulation</h1>
<!-- received="Wed Mar 14 16:42:01 2001" -->
<!-- isoreceived="20010314234201" -->
<!-- sent="Wed, 14 Mar 2001 16:04:20 -0500" -->
<!-- isosent="20010314210420" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: How To Live In A Simulation" -->
<!-- id="3AAFDCD4.D4BD9775@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="4.3.2.7.2.20010314145654.04926958@nlb28.mail.yale.edu" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20How%20To%20Live%20In%20A%20Simulation"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Wed Mar 14 2001 - 14:04:20 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0663.html">Carl Feynman: "Re: How to Live in a Simulation"</a>
<li><strong>Previous message:</strong> <a href="0661.html">Gordon Worley: "Re: How to Live in a Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0665.html">Durant Schoon: "Re: How To Live In A Simulation"</a>
<li><strong>Reply:</strong> <a href="0665.html">Durant Schoon: "Re: How To Live In A Simulation"</a>
<li><strong>Reply:</strong> <a href="0666.html">Nick Bostrom: "Re: How To Live In A Simulation"</a>
<li><strong>Reply:</strong> <a href="0668.html">arona1: "Concerning &quot;Human engineered earthquakes&quot;"</a>
<li><strong>Maybe reply:</strong> <a href="0671.html">Eliezer S. Yudkowsky: "Re: How To Live In A Simulation"</a>
<li><strong>Maybe reply:</strong> <a href="0702.html">Christopher Barton: "Re: How To Live In A Simulation"</a>
<li><strong>Maybe reply:</strong> <a href="0705.html">gabriel C: "Re: How To Live In A Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#662">[ date ]</a>
<a href="index.html#662">[ thread ]</a>
<a href="subject.html#662">[ subject ]</a>
<a href="author.html#662">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Nick Bostrom wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Steve Nichols wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt;But logically I feel  Nick is *wrong* ... since he fails to omit 4. That we
</em><br>
<em>&gt; &gt;could be the ancestors leading the original lives on which any future
</em><br>
<em>&gt; &gt;simulations are based!
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I show that 4 has negligible probability.
</em><br>
<p>Ah, yes, but it doesn't have negligible moral weight.  Suppose that
<br>
there's one original Eliezer and a billion imitators.  The chance that I'm
<br>
the original is only one-billionth; however, the actions of that original
<br>
would carry a billion times as much weight.  The original still
<br>
necessarily exists, and we wouldn't want that original to be misled by the
<br>
original Nick Bostrom, right?  Ergo, the whole possibility may cancel
<br>
right out of the moral equation...
<br>
<p>Even if it doesn't cancel out, this apparent world of the true Eliezer,
<br>
where the whole Singularity is at stake, weighs far more in my
<br>
calculations than whatever reasons a hypothetical exoself could have for
<br>
wanting to relive my life - even if the probability of being the original
<br>
is a billion to one.
<br>
<p>Right now, I am Eliezer, whether or not I started out that way.  I have
<br>
Eliezer's memories and personality.  And Eliezer doesn't give a damn about
<br>
the pathetic entertainments of citizens who are hanging back and reliving
<br>
other people's lives instead of joining the greater transhuman community. 
<br>
If this is a simulation, then bringing other citizens to that realization
<br>
was probably the reason the post-Singularity Eliezer licensed out vis
<br>
human life in the first place, if ve did.
<br>
<p>So as far as I'm concerned, the possibility that this is all a simulation
<br>
doesn't move me.  Who gives a damn if my exoself winds up being unhappy? 
<br>
I didn't force ver to license these memories.  As far as I'm concerned,
<br>
the actions of the original Eliezer and my current actions at this moment
<br>
are isomorphic.  I, in my capacity as the original Eliezer or a mental
<br>
isomorph of him, attach negligible moral weight to the happiness or
<br>
unhappiness of any future folk who want to rerun my life in simulation; if
<br>
they wanted to be happy, they should have modified the simulation
<br>
accordingly.
<br>
<p>Furthermore, if this is a simulation, it seems pretty likely that I'm
<br>
living out the exact and original life of Eliezer, as best it could be
<br>
reconstructed from his emails or even memories - which means that *this*
<br>
email, this *exact* line of reasoning, would have appeared back in the
<br>
original pre-Singularity world!  Obviously, then, whatever thoughts I am
<br>
having right now appear in the original pre-Singularity moral equation,
<br>
where they vastly outweigh the consequences to any volunteer exoselves who
<br>
only survived in the first place because someone successfully brought off
<br>
the original Singularity.
<br>
<p>Besides which, I still think this world is probably the real one.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0663.html">Carl Feynman: "Re: How to Live in a Simulation"</a>
<li><strong>Previous message:</strong> <a href="0661.html">Gordon Worley: "Re: How to Live in a Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0665.html">Durant Schoon: "Re: How To Live In A Simulation"</a>
<li><strong>Reply:</strong> <a href="0665.html">Durant Schoon: "Re: How To Live In A Simulation"</a>
<li><strong>Reply:</strong> <a href="0666.html">Nick Bostrom: "Re: How To Live In A Simulation"</a>
<li><strong>Reply:</strong> <a href="0668.html">arona1: "Concerning &quot;Human engineered earthquakes&quot;"</a>
<li><strong>Maybe reply:</strong> <a href="0671.html">Eliezer S. Yudkowsky: "Re: How To Live In A Simulation"</a>
<li><strong>Maybe reply:</strong> <a href="0702.html">Christopher Barton: "Re: How To Live In A Simulation"</a>
<li><strong>Maybe reply:</strong> <a href="0705.html">gabriel C: "Re: How To Live In A Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#662">[ date ]</a>
<a href="index.html#662">[ thread ]</a>
<a href="subject.html#662">[ subject ]</a>
<a href="author.html#662">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
