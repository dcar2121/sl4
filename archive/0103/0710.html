<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: How To Live In A Simulation</title>
<meta name="Author" content="James Higgins (jameshiggins@earthlink.net)">
<meta name="Subject" content="Re: How To Live In A Simulation">
<meta name="Date" content="2001-03-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: How To Live In A Simulation</h1>
<!-- received="Tue Mar 20 03:56:03 2001" -->
<!-- isoreceived="20010320105603" -->
<!-- sent="Tue, 20 Mar 2001 00:55:47 -0700" -->
<!-- isosent="20010320075547" -->
<!-- name="James Higgins" -->
<!-- email="jameshiggins@earthlink.net" -->
<!-- subject="Re: How To Live In A Simulation" -->
<!-- id="4.3.2.7.2.20010320003420.00b36ae8@mail.earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="028601c0b04a$bef57640$3d53f7a5@computer" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Higgins (<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20How%20To%20Live%20In%20A%20Simulation"><em>jameshiggins@earthlink.net</em></a>)<br>
<strong>Date:</strong> Tue Mar 20 2001 - 00:55:47 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0711.html">James Higgins: "Re: How To Live In A Simulation"</a>
<li><strong>Previous message:</strong> <a href="0709.html">Spudboy100@aol.com: "Re: JOIN: Carl Feynman"</a>
<li><strong>In reply to:</strong> <a href="0700.html">Brian Phillips: "Re: How To Live In A Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0714.html">Eliezer S. Yudkowsky: "Re: How To Live In A Simulation"</a>
<li><strong>Reply:</strong> <a href="0714.html">Eliezer S. Yudkowsky: "Re: How To Live In A Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#710">[ date ]</a>
<a href="index.html#710">[ thread ]</a>
<a href="subject.html#710">[ subject ]</a>
<a href="author.html#710">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
At 03:00 AM 3/19/2001 -0500, Brian Phillips wrote:
<br>
<em>&gt;   Something else I would like to point out....
</em><br>
<em>&gt;  It's obvious reading the writings of the &quot;singularity's friends&quot;
</em><br>
<em>&gt;that they tend to think in terms of &quot;Before Singularity&quot; and
</em><br>
<em>&gt;&quot;After Singularity&quot;. What's motivating this &quot;discrete point&quot;
</em><br>
<em>&gt;vision of the transhuman future? shouldn't the perception be
</em><br>
<em>&gt;a steepening CURVE?
</em><br>
<em>&gt;   The only thing I can think of which might produce a &quot;single
</em><br>
<em>&gt;point&quot; style &quot;event horizon&quot; is the invention of Eli's hyper-evolving
</em><br>
<em>&gt;transhuman AI, and only then in a world lacking competitors.
</em><br>
<em>&gt;   The inclusion of infosystems directly into the cortex of humanity
</em><br>
<em>&gt;will be a gradual process (taking at least a few years, at least)
</em><br>
<em>&gt;(imagine that as a nanoprank...everybody wakes up with neurojacks!).
</em><br>
<em>&gt;   Similarly nano-heaven (a la Diaspora or what have you) doesn't arrive
</em><br>
<em>&gt;the moment the first general purpose assembler comes on line.
</em><br>
<em>&gt;   All these things may happen extremely quickly by the standards of
</em><br>
<em>&gt;past human history...but the curve is still extant, just abbreviated into
</em><br>
<em>&gt;decades or even years producing unrecognizable change.
</em><br>
<em>&gt;
</em><br>
<em>&gt;just a thought,
</em><br>
<em>&gt;brian
</em><br>
<p>The singularity as a point in time comes from self-improving AI.  That is 
<br>
why it is essentially called the singularity, in fact.  If you really sit 
<br>
down and start looking at the numbers, it all pretty much happens in a 
<br>
couple of seconds.  I did a fairly complex spreadsheet on this because I 
<br>
had a hard time believing it.  Espicially when you consider that it takes 
<br>
time to actually manufacture new hardware &amp; upgrade the physical computer 
<br>
the AI is running on.  I did this purely based on &quot;faster&quot; AI (not 
<br>
smarter), that essentially just continuously makes faster and faster CPUs 
<br>
for itself.  Assuming a subjective 18 month development time, 6 month 
<br>
real-world manufacturing &amp; 1 month real-world upgrade time.  I then reduced 
<br>
the manufacturing &amp; upgrade time per iteration by like 5% (assume that some 
<br>
research had been spent on improving this process also).  With all of this, 
<br>
it took exactly 2 years to go infinite, which happened in the final seconds 
<br>
of the last year.  When I graphed it out it is near-flat until the end, at 
<br>
which point it goes vertical.  I realize this will never be truly accurate 
<br>
and does not prove anything, but it is interesting in any case.
<br>
<p>The reason it goes infinite, even considering the manufacturing delays, is 
<br>
due to iterations.  In later stages the AI is able to churn through many 
<br>
iterations that never even make it to manufacturing.  I assume that the 
<br>
last completed version whet to manufacturing every 6 months.
<br>
<p>So this single AI goes infinite in a single second, but how does that 
<br>
effect the world, right?  Well, I believe it is further assumed that this 
<br>
AI will have control over Nanotech (which may reduce the manufacturing 
<br>
time, btw).  If this is the case, this single AI could essentially upload 
<br>
all of humanity within a very short period of time (a week or two?).
<br>
<p>However, I believe I have thought of a good way to actually make the 
<br>
upload.  But I'm certain this group can put some holes into it, so here goes.
<br>
<p>FYI: I assume that the AI goes infinite when it has access to Nanotech.
<br>
<p>The AI would start by undertaking a project to move all of humanity into 
<br>
VR, producing nanobots specifically for this purpose.  It would use 
<br>
whatever method it decided was best, of course.  But for my purposes, I'm 
<br>
thinking about the emulation model.  A nanobot attaches it self to every 
<br>
neuron in a person.  Once the person can be modeled exactly, they can be 
<br>
uploaded to VR.  When everyone is in this state, the AI would &quot;move&quot; 
<br>
everyone into VR at the exact same time.  The VR world would then exactly 
<br>
mirror our current one, so they would not realize anything had 
<br>
occurred.  Step 1.
<br>
<p>Now that everyone is virtual, the rules are changed a bit.  It becomes 
<br>
impossible to either die or become pregnant.  The human race would be 
<br>
informed (I am not clever enough to write this speech) of the current 
<br>
state.  A time line would also be established for allowing transcendence, 
<br>
say 20 years.  This gives enough time for everyone to be at least 20 years 
<br>
old.  Maybe 30, 40 or even 50 years would be better to allow for more 
<br>
psychological adjustment (that is not for me to decide).  In the VR time 
<br>
is, of course, subjective.  So these 20+ years could occur in a much 
<br>
shorter &quot;real&quot; time.  Once the time had come, it would be possible to 
<br>
transcend.  Maybe phone booth type structures would appear that, when 
<br>
entered, uploaded the individual.  This provides people to progress of 
<br>
their own free will beyond this point.
<br>
<p>Eventually, I imagine, everyone would transcend and the simulation would 
<br>
vanish.
<br>
<p>So, any comments on that?
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0711.html">James Higgins: "Re: How To Live In A Simulation"</a>
<li><strong>Previous message:</strong> <a href="0709.html">Spudboy100@aol.com: "Re: JOIN: Carl Feynman"</a>
<li><strong>In reply to:</strong> <a href="0700.html">Brian Phillips: "Re: How To Live In A Simulation"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0714.html">Eliezer S. Yudkowsky: "Re: How To Live In A Simulation"</a>
<li><strong>Reply:</strong> <a href="0714.html">Eliezer S. Yudkowsky: "Re: How To Live In A Simulation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#710">[ date ]</a>
<a href="index.html#710">[ thread ]</a>
<a href="subject.html#710">[ subject ]</a>
<a href="author.html#710">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
