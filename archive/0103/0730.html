<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Envisioning sysop scenarios Re: Universal Uplift as an alternative to  the Sysop scenario</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Envisioning sysop scenarios Re: Universal Uplift as an alternative to  the Sysop scenario">
<meta name="Date" content="2001-03-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Envisioning sysop scenarios Re: Universal Uplift as an alternative to  the Sysop scenario</h1>
<!-- received="Wed Mar 21 00:56:09 2001" -->
<!-- isoreceived="20010321075609" -->
<!-- sent="Wed, 21 Mar 2001 00:47:10 -0500" -->
<!-- isosent="20010321054710" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Envisioning sysop scenarios Re: Universal Uplift as an alternative to  the Sysop scenario" -->
<!-- id="3AB8405E.AB57F6D2@posthuman.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="20010320235519.C11812@cluebot.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Envisioning%20sysop%20scenarios%20Re:%20Universal%20Uplift%20as%20an%20alternative%20to%20%20the%20Sysop%20scenario"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Tue Mar 20 2001 - 22:47:10 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0731.html">Ben Goertzel: "OFF-TOPIC:  Webmind Inc. may need some help..."</a>
<li><strong>Previous message:</strong> <a href="0729.html">Chris Cooper: "off topic; Sorry about the HTML"</a>
<li><strong>In reply to:</strong> <a href="0727.html">Declan McCullagh: "Re: Universal Uplift as an alternative to the Sysop scenario"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#730">[ date ]</a>
<a href="index.html#730">[ thread ]</a>
<a href="subject.html#730">[ subject ]</a>
<a href="author.html#730">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
A sandbox is indeed a good way to envision that particular scenario. The
<br>
sysop monitors things, and simply prevents (&quot;throws an exception&quot;) certain
<br>
things (a bullet being fired out of the gun when you try to kill some poor
<br>
human) from happening since it inhabits/controls the matter.
<br>
<p>Another possibility would be to have a &quot;guardian angel&quot; style, rather than
<br>
a hard sandbox. This depends on certain feasibility issues (can the sysop
<br>
arbitrarily protect you from everything in the area of its control), but
<br>
might be more appealing to the average person. So, someone can fire a bullet
<br>
at you, but you have a choice and it either bounces off or is otherwise not
<br>
effective at hurting you.
<br>
<p>In either case the sysop must control the matter. If someone was allowed
<br>
to both create a competitor SI to the sysop, AND it was allowed to gain
<br>
control of the matter then it's all over for Sysop #1.
<br>
<p>Is it possible to have other scenarios where the sysop does not infect
<br>
all the mass in the solar system, while still ending all evil? I think it
<br>
could be done through heavy surveillance, including both real and virtual
<br>
realities. But this would be more dangerous IMO since if someone escapes
<br>
the surveillance, and builds a competitor SI that then infects all the matter
<br>
then you've got problems.
<br>
<p>Declan McCullagh wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Is it just me, or do other folks think of a Java applet when
</em><br>
<em>&gt; people talk about a Friendly superintelligence letting us play
</em><br>
<em>&gt; in a sandbox? :)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -Declan
</em><br>
<em>&gt; 
</em><br>
<em>&gt; On Mon, Mar 19, 2001 at 01:13:56PM -0800, Mitchell Porter wrote:
</em><br>
<em>&gt; &gt; Eliezer says occasionally that the Sysop scenario
</em><br>
<em>&gt; &gt; is just a *guess* as to what a Friendly super-AI
</em><br>
<em>&gt; &gt; would choose to do. I think people would be more
</em><br>
<em>&gt; &gt; likely to remember this if there was another
</em><br>
<em>&gt; &gt; scenario on offer, and in fact my own default
</em><br>
<em>&gt; &gt; picture of a Friendly Singularity is this other
</em><br>
<em>&gt; &gt; one, of Universal Uplift.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; The basic meaning is presumably clear, although
</em><br>
<em>&gt; &gt; variations on it are possible (uplift sentients
</em><br>
<em>&gt; &gt; of Earth; uplift non-sentients as well; uplift
</em><br>
<em>&gt; &gt; all sentients ever within reach, whether alien
</em><br>
<em>&gt; &gt; or Earth-evolved). The essential idea: if
</em><br>
<em>&gt; &gt; everyone is a Friendly superintelligence, who
</em><br>
<em>&gt; &gt; needs a Sysop? Only the non-sentient, the newly
</em><br>
<em>&gt; &gt; sentient, and the not yet uplifted.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; The obvious criticism of Universal Uplift is
</em><br>
<em>&gt; &gt; a Borg-like imposition; which is why I think of
</em><br>
<em>&gt; &gt; it working by enticement rather than imposition.
</em><br>
<em>&gt; &gt; In effect, the uplifter leaves a trail of
</em><br>
<em>&gt; &gt; crumbs for the upliftee to follow, and by the
</em><br>
<em>&gt; &gt; time you reach the end of the trail, you're a
</em><br>
<em>&gt; &gt; Friendly superintelligence.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; __________________________________________________
</em><br>
<em>&gt; &gt; Do You Yahoo!?
</em><br>
<em>&gt; &gt; Get email at your own domain with Yahoo! Mail.
</em><br>
<em>&gt; &gt; <a href="http://personal.mail.yahoo.com/">http://personal.mail.yahoo.com/</a>
</em><br>
<p><pre>
-- 
Brian Atkins
Director, Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0731.html">Ben Goertzel: "OFF-TOPIC:  Webmind Inc. may need some help..."</a>
<li><strong>Previous message:</strong> <a href="0729.html">Chris Cooper: "off topic; Sorry about the HTML"</a>
<li><strong>In reply to:</strong> <a href="0727.html">Declan McCullagh: "Re: Universal Uplift as an alternative to the Sysop scenario"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#730">[ date ]</a>
<a href="index.html#730">[ thread ]</a>
<a href="subject.html#730">[ subject ]</a>
<a href="author.html#730">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
