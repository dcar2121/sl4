<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: AI testing and containment Re: [SL4] Programmed morality</title>
<meta name="Author" content="Dale Johnstone (dalejohnstone@email.com)">
<meta name="Subject" content="RE: AI testing and containment Re: [SL4] Programmed morality">
<meta name="Date" content="2000-07-09">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: AI testing and containment Re: [SL4] Programmed morality</h1>
<!-- received="Sun Jul 09 15:26:27 2000" -->
<!-- isoreceived="20000709212627" -->
<!-- sent="Sun, 9 Jul 2000 15:25:57 -0400 (EDT)" -->
<!-- isosent="20000709192557" -->
<!-- name="Dale Johnstone" -->
<!-- email="dalejohnstone@email.com" -->
<!-- subject="RE: AI testing and containment Re: [SL4] Programmed morality" -->
<!-- id="384704848.963170757201.JavaMail.root@web586-ec.mail.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="AI testing and containment Re: [SL4] Programmed morality" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Dale Johnstone (<a href="mailto:dalejohnstone@email.com?Subject=RE:%20AI%20testing%20and%20containment%20Re:%20[SL4]%20Programmed%20morality"><em>dalejohnstone@email.com</em></a>)<br>
<strong>Date:</strong> Sun Jul 09 2000 - 13:25:57 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0016.html">Eliezer S. Yudkowsky: "Re: AI testing and containment Re: [SL4] Programmed morality"</a>
<li><strong>Previous message:</strong> <a href="0014.html">Dale Johnstone: "Re: [SL4] Programmed morality"</a>
<li><strong>Maybe in reply to:</strong> <a href="0012.html">Brian Atkins: "AI testing and containment Re: [SL4] Programmed morality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0016.html">Eliezer S. Yudkowsky: "Re: AI testing and containment Re: [SL4] Programmed morality"</a>
<li><strong>Reply:</strong> <a href="0016.html">Eliezer S. Yudkowsky: "Re: AI testing and containment Re: [SL4] Programmed morality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15">[ date ]</a>
<a href="index.html#15">[ thread ]</a>
<a href="subject.html#15">[ subject ]</a>
<a href="author.html#15">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<body>
<tt>
Brian Atkins wrote:<BR>
&gt;<BR>
&gt;petervoss1 wrote:<BR>
&lt;snip&gt;<BR>
&gt;&gt; 1) General machine intelligence will invariably be connected to <BR>
&gt;&gt; the Web during development &amp; learning.<BR>
&gt;&gt; 2) It seems that the only effective way to get true AI going is <BR>
&gt;&gt; the seed route. In this scenario, there may not be a community of <BR>
&gt;&gt; (roughly equal) AIs. Only one will bootstrap to superior <BR>
&gt;&gt; intelligence.<BR>
&gt;&gt; <BR>
&gt;&gt; I am very concerned about the risks of run-away AI (unlike Eli I <BR>
&gt;&gt; *do* care what happens to me). I'm desperately searching for ways<BR>
&gt;&gt; of trying to predict (with whatever limited certainty) what goal<BR>
&gt;&gt; system an AI might choose. Any ideas?<BR>
&gt;&gt; <BR>
&gt;<BR>
&gt;I would like to say two things, first off I don't agree with #1. <BR>
&gt;Storage will be so cheap by the time we are ready to try running the <BR>
&gt;first seed that we can store a huge chunk of the WWW (if not all of <BR>
&gt;it- could this be a new business opportunity in the future, selling <BR>
&gt;copies of the WWW?) locally and run the seed completely offline.<BR>
<BR>
This is worth doing purely from a bandwidth point of view. Besides anything clocking faster than a human will *really* hate the world wide wait :)<BR>
<BR>
&gt;Secondly I agree with #2... I prefer some way of testing out slightly<BR>
&gt;different seeds. However to really test what an AI will do once it is<BR>
&gt;&quot;loose&quot; you would have to provide it with a quite awesome simulation<BR>
&gt;of the real world (Matrix-like) and then see what it does to the <BR>
&gt;humans. I don't think we will be able to do that even if we had the <BR>
&gt;hardware. So I would be interested to know of other possible ways to <BR>
&gt;test what the AI would do.<BR>
<BR>
What if the grass is pink, not green? Will it matter? What if there's no grass at all? What if there's only one small town, or maybe just one house? Could you tell a good AI from a bad AI that grew up indoors? I think so. You could certainly tell a mad one from a sane one.<BR>
<BR>
A completely accurate simulation of the world is unnecessary. However I think that *some* simulation of a world is necessary to provide rich enough sensory input &amp; a level of interactivity that an AI can learn from. This can be done with today's desktop PCs (see Collision Detection &amp; Rigid-Body Dynamics) and is something I'll be doing from September all being well.<BR>
<BR>
Regards,<BR>
Dale Johnstone<BR>
-----------------------------------------------<BR>
FREE! The World's Best Email Address @email.com<BR>
Reserve your name now at <a href="http://www.email.com">http://www.email.com</a><BR>
<BR>
<BR>
</tt>

<!-- |**|begin egp html banner|**| -->


<hr>
<!-- |@|begin eGroups banner|@| runid: 6235 crid: 3263 -->
<a target="_blank" href="http://click.egroups.com/1/6235/12/_/626675/_/963170759/"><center>
<img width="468" height="60"
  border="0"
  alt="ICplanet - Connecting Businessess and Independent Consultants, worldwide"
  src="http://adimg.egroups.com/img/6235/12/_/626675/_/963170759/stocks2.gif"></center><center><font color="black"></font></center></a>
<!-- |@|end eGroups banner|@| -->
<hr>

<!-- |**|end egp html banner|**| -->


</body>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0016.html">Eliezer S. Yudkowsky: "Re: AI testing and containment Re: [SL4] Programmed morality"</a>
<li><strong>Previous message:</strong> <a href="0014.html">Dale Johnstone: "Re: [SL4] Programmed morality"</a>
<li><strong>Maybe in reply to:</strong> <a href="0012.html">Brian Atkins: "AI testing and containment Re: [SL4] Programmed morality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0016.html">Eliezer S. Yudkowsky: "Re: AI testing and containment Re: [SL4] Programmed morality"</a>
<li><strong>Reply:</strong> <a href="0016.html">Eliezer S. Yudkowsky: "Re: AI testing and containment Re: [SL4] Programmed morality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15">[ date ]</a>
<a href="index.html#15">[ thread ]</a>
<a href="subject.html#15">[ subject ]</a>
<a href="author.html#15">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
