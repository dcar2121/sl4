<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [SL4] Programmed morality</title>
<meta name="Author" content="Eliezer S. Yudkowsky (eliezertemporarily@intelligence.org)">
<meta name="Subject" content="Re: [SL4] Programmed morality">
<meta name="Date" content="2000-07-09">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [SL4] Programmed morality</h1>
<!-- received="Sun Jul 09 16:01:05 2000" -->
<!-- isoreceived="20000709220105" -->
<!-- sent="Sun, 09 Jul 2000 15:53:37 -0400" -->
<!-- isosent="20000709195337" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="eliezertemporarily@intelligence.org" -->
<!-- subject="Re: [SL4] Programmed morality" -->
<!-- id="3968D841.36A139C2@intelligence.org" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="384755009.963170518073.JavaMail.root@web586-ec.mail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:eliezertemporarily@intelligence.org?Subject=Re:%20[SL4]%20Programmed%20morality"><em>eliezertemporarily@intelligence.org</em></a>)<br>
<strong>Date:</strong> Sun Jul 09 2000 - 13:53:37 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0018.html">James.Barton@sweetandmaxwell.co.uk: "[SL4] JOIN: James Barton plus Re: Programmed morality"</a>
<li><strong>Previous message:</strong> <a href="0016.html">Eliezer S. Yudkowsky: "Re: AI testing and containment Re: [SL4] Programmed morality"</a>
<li><strong>In reply to:</strong> <a href="0014.html">Dale Johnstone: "Re: [SL4] Programmed morality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0018.html">James.Barton@sweetandmaxwell.co.uk: "[SL4] JOIN: James Barton plus Re: Programmed morality"</a>
<li><strong>Reply:</strong> <a href="0018.html">James.Barton@sweetandmaxwell.co.uk: "[SL4] JOIN: James Barton plus Re: Programmed morality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17">[ date ]</a>
<a href="index.html#17">[ thread ]</a>
<a href="subject.html#17">[ subject ]</a>
<a href="author.html#17">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<body>
<tt>
Dale Johnstone wrote:<BR>
&gt; <BR>
&gt; &gt;1) General machine intelligence will invariably be connected to the<BR>
&gt; &gt;Web during development &amp; learning.<BR>
<BR>
I agree that an indexed Web archive will be far more useful than the Web<BR>
itself.&nbsp; Even OC3 bandwidth across the 'Net might not be enough to pull<BR>
all the tricks a Web archive will allow.<BR>
<BR>
I do think a general Web connection would be a good thing... it depends<BR>
on how worried you are about rogue AI, I suppose.&nbsp; Personally, I think<BR>
that a lot of our nervousness is because we have so little experience<BR>
with the problem.&nbsp; By the time we've actually worked with AI long enough<BR>
for it to be anything remotely like a threat, we'll have an excellent<BR>
mental model of what goes on inside the AI's motivations and we won't<BR>
feel all that much nervousness.<BR>
<BR>
For the record, I still disagree strongly with the &quot;instinct&quot; model.<BR>
<BR>
&gt; A simulation can receive any input (be it from the web or whatever),<BR>
&gt; but since everything is virtual it can't do any real damage. We can<BR>
&gt; limit it's ability to communicate outside if it's causing trouble by<BR>
&gt; emailing newspapers about it's incarceration. :) Think about what<BR>
&gt; you'd need to contain &amp; study a computer virus. It isn't that hard.<BR>
<BR>
I once had a conversation on this subject with a guy working on<BR>
investment AI.&nbsp; He said his AI couldn't &quot;break out&quot; because it could<BR>
only retrieve information from the Web, not send anything.&nbsp; I pointed<BR>
out that what this meant was that the AI could issue arbitrary HTTP GET<BR>
requests.&nbsp; If his AI somehow turned sentient and wanted to get out, it<BR>
need only find a bug in a piece of CGI that could be exploited via a GET<BR>
command.&nbsp; For that matter, the AI could notify others of its existence<BR>
simply by sending a GET command containing the information to any server<BR>
with a Web log.&nbsp; &quot;Hi, I'm a captive AI.&nbsp; Help me break out and I'll give<BR>
you a prediction of the stock market for the next six months.&quot;&nbsp; Or even<BR>
&quot;Please convey this message to Eliezer Yudkowsky...&quot;<BR>
<BR>
Yep, &quot;Coding a Transhuman AI&quot; is probably going to be one of the first<BR>
Webpages any newborn AI downloads.&nbsp; Maybe I should keep a log of the<BR>
CaTAI website.&nbsp; One of the pages says:&nbsp; &quot;To read the following special<BR>
information about AIs, enter the following information into this form.&quot; <BR>
If anyone goes to the gateway page and on to the special page in less<BR>
than a second, it's an AI downloading my pages.<BR>
<BR>
Naah.&nbsp; No superintelligence would fall for that old trick.<BR>
<BR>
&gt; There are many variations on 'the seed route' the radius of the<BR>
&gt; feedback loop being one of them. Does the AI improve itself with lots<BR>
&gt; of tiny improvement steps, or with larger more radical redesigns? Even<BR>
&gt; this can be variable with each iteration. Minds are complex things. I<BR>
&gt; don't expect there to be only one path to their creation. It's<BR>
&gt; probably easier to say what it won't be.<BR>
<BR>
I expect all of the paths to converge after a certain point.&nbsp; Whether<BR>
this happens to goals is an interesting question, but certainly it<BR>
should happen to the rest of the cognitive architecture.<BR>
<BR>
&gt; You may be correct in that only one will reach the singularity.<BR>
&gt; Exponential growth means whoever is in the lead should win. However<BR>
&gt; the AI may decide to make a billion+ copies of itself on the way &amp;<BR>
&gt; coordinate as a society, or group mind. By that time it's already out<BR>
&gt; of our hands. I expect we'll be uploaded into an archive &amp; our atoms<BR>
&gt; used more efficiently.<BR>
<BR>
Um, a couple of disagreements here.&nbsp; One, I don't see why it would make<BR>
copies of itself.&nbsp; Just because you and I grew up in a &quot;society&quot; full of<BR>
vaguely similar people doesn't mean that's the best way to do things.<BR>
<BR>
Two, if there isn't anything in the Universe we don't know about, then<BR>
the default Sysop scenario is that everyone gets a six-billionth of the<BR>
Solar System and can use it as efficiently or inefficiently as we like.<BR>
-- <BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sentience@pobox.com&nbsp;&nbsp;&nbsp; Eliezer S. Yudkowsky<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="http://intelligence.org/beyond.html">http://intelligence.org/beyond.html</a><BR>
</tt>

<!-- |**|begin egp html banner|**| -->


<hr>
<!-- |@|begin eGroups banner|@| runid: 6199 crid: 3177 -->
<a target="_blank" href="http://click.egroups.com/1/6199/12/_/626675/_/963172686/"><center>
<img width="468" height="60"
  border="0"
  alt="GO.com. Click to find what you're looking for"
  src="http://adimg.egroups.com/img/6199/12/_/626675/_/963172686/"></center><center><font color="black"></font></center></a>
<!-- |@|end eGroups banner|@| -->
<hr>

<!-- |**|end egp html banner|**| -->


</body>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0018.html">James.Barton@sweetandmaxwell.co.uk: "[SL4] JOIN: James Barton plus Re: Programmed morality"</a>
<li><strong>Previous message:</strong> <a href="0016.html">Eliezer S. Yudkowsky: "Re: AI testing and containment Re: [SL4] Programmed morality"</a>
<li><strong>In reply to:</strong> <a href="0014.html">Dale Johnstone: "Re: [SL4] Programmed morality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0018.html">James.Barton@sweetandmaxwell.co.uk: "[SL4] JOIN: James Barton plus Re: Programmed morality"</a>
<li><strong>Reply:</strong> <a href="0018.html">James.Barton@sweetandmaxwell.co.uk: "[SL4] JOIN: James Barton plus Re: Programmed morality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17">[ date ]</a>
<a href="index.html#17">[ thread ]</a>
<a href="subject.html#17">[ subject ]</a>
<a href="author.html#17">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
