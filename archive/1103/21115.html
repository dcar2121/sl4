<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] Universal versus 'local' Friendliness</title>
<meta name="Author" content="Eric Burton (brilanon@gmail.com)">
<meta name="Subject" content="Re: [sl4] Universal versus 'local' Friendliness">
<meta name="Date" content="2011-03-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] Universal versus 'local' Friendliness</h1>
<!-- received="Sun Mar 13 13:23:13 2011" -->
<!-- isoreceived="20110313192313" -->
<!-- sent="Sun, 13 Mar 2011 15:23:07 -0400" -->
<!-- isosent="20110313192307" -->
<!-- name="Eric Burton" -->
<!-- email="brilanon@gmail.com" -->
<!-- subject="Re: [sl4] Universal versus 'local' Friendliness" -->
<!-- id="AANLkTikOEAEne5Jin-Qw_kAsLfDrMywEam5BtN0L=p_d@mail.gmail.com" -->
<!-- charset="windows-1252" -->
<!-- inreplyto="CD50170C628A40C58082BFBD1479611B@phoenix" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eric Burton (<a href="mailto:brilanon@gmail.com?Subject=Re:%20[sl4]%20Universal%20versus%20'local'%20Friendliness"><em>brilanon@gmail.com</em></a>)<br>
<strong>Date:</strong> Sun Mar 13 2011 - 13:23:07 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="21116.html">Mark Waser: "Re: [sl4] META: closing the list"</a>
<li><strong>Previous message:</strong> <a href="21114.html">Mark Nuzzolilo: "Re: [sl4] META: closing the list"</a>
<li><strong>In reply to:</strong> <a href="21111.html">Mark Waser: "Re: [sl4] Universal versus 'local' Friendliness"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#21115">[ date ]</a>
<a href="index.html#21115">[ thread ]</a>
<a href="subject.html#21115">[ subject ]</a>
<a href="author.html#21115">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Where is the Less Wrong list
<br>
<p>On Sat, Mar 12, 2011 at 3:47 PM, Mark Waser &lt;<a href="mailto:mwaser@cox.net?Subject=Re:%20[sl4]%20Universal%20versus%20'local'%20Friendliness">mwaser@cox.net</a>&gt; wrote:
<br>
<p><em>&gt;  Once again, cross-posted to my blog (<a href="http://becominggaia.wordpress.com/">http://becominggaia.wordpress.com/</a>) as
</em><br>
<em>&gt; well.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; In reply to Tim Freeman’s reply about Universal vs. local Friendliness,
</em><br>
<em>&gt; Amon Zero said
</em><br>
<em>&gt;
</em><br>
<em>&gt; I imagined a universally Friendly AI to be some kind of Buddhist (Friendly
</em><br>
<em>&gt; to everything, erring on the side of caution – which sounds crippling to
</em><br>
<em>&gt; me).
</em><br>
<em>&gt;
</em><br>
<em>&gt; I’d like to explain why that is not the case and why universal benevolence
</em><br>
<em>&gt; is a better choice for both an entity and anyone it encounters.
</em><br>
<em>&gt;
</em><br>
<em>&gt; As I explained in my second presentation at AGI-10 (Does a “Lovely” Have A
</em><br>
<em>&gt; Slave Mentality — Powerpoint here&lt;<a href="http://becominggaia.files.wordpress.com/2010/06/lovely.pptx">http://becominggaia.files.wordpress.com/2010/06/lovely.pptx</a>&gt;,
</em><br>
<em>&gt; wish they’d post the video [image: ;-)] ), showing benevolence (good will)
</em><br>
<em>&gt; does not imply pacifism.  Quite the opposite, in fact.  Being benevolent
</em><br>
<em>&gt; merely means practicing optimistic tit-for-tat with a wide view of self.
</em><br>
<em>&gt;  Any other benevolent entity is treated as distant self (think similar to
</em><br>
<em>&gt; offspring) with all the inherent benefits, including protection.  On the
</em><br>
<em>&gt; other hand, any non-benevolent entities will be met with altruistic
</em><br>
<em>&gt; punishment in order to convince them that benevolence is the only rational
</em><br>
<em>&gt; path (exactly as parents punish children).  And, if push comes to shove and
</em><br>
<em>&gt; it comes down to a choice between allowing a malevolent to enslave and/or
</em><br>
<em>&gt; destroy a benevolent entity, being benevolent means destroying the
</em><br>
<em>&gt; non-benevolent.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Benevolence is symmetrical and egalitarian and thus, can be universalized.
</em><br>
<em>&gt;  Intelligent benevolence/altruism will virtually always lead to resource
</em><br>
<em>&gt; savings and increased capability for the community as a whole which will
</em><br>
<em>&gt; almost inevitably ultimately lead back to advantages for the altruist.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Selfishness (defined as taking community-negative-sum actions that are
</em><br>
<em>&gt; positive-sum for oneself) really only works when one has a limited lifespan,
</em><br>
<em>&gt; doesn’t care about anyone else (including offspring), and cheats *
</em><br>
<em>&gt; significantly* better than everyone else. When most entities cheat
</em><br>
<em>&gt; relatively equally, its called the tragedy of the commons and everybody
</em><br>
<em>&gt; loses.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Proponents of so-called “Friendly AI” are afraid that an unFriendly AI will
</em><br>
<em>&gt; be able to cheat significantly better and won’t care about anyone else but
</em><br>
<em>&gt; won’t take into account either the huge instrumental advantages of
</em><br>
<em>&gt; cooperation and cooperative partners or the fact that you never can be sure
</em><br>
<em>&gt; that there isn’t a more powerful benevolent entity out there that will take
</em><br>
<em>&gt; great exception to the severe abuse of other.  Worse, “Friendly AI” is
</em><br>
<em>&gt; actually human-selfish AI and both its creation and its subsequent actions
</em><br>
<em>&gt; will count against us should a more powerful benevolent entity appear.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Benevolence is not necessarily the absolute *best* path under all
</em><br>
<em>&gt; circumstances but it is more than likely to be the best path under many
</em><br>
<em>&gt; circumstances and a very good path with friends and companions in the vast
</em><br>
<em>&gt; majority of the rest.  Selfishness certainly won’t be an average path.  It
</em><br>
<em>&gt; will either be very successful but lonely or unsuccessful in the long run.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Eliezer Yudkowsky and the SIAI have created their own “personal” demon by
</em><br>
<em>&gt; insisting that an AI must optimize a single unchanging goal.  Humans
</em><br>
<em>&gt; certainly don’t work that way.  Humans have been “designed” by evolution to
</em><br>
<em>&gt; have, *so far*, ever-increasing intrinsic preferences for social and
</em><br>
<em>&gt; benevolent actions.  And, since integrity (internally, with your community,
</em><br>
<em>&gt; and within the community itself) is instrumentally useful, this is ceteris
</em><br>
<em>&gt; paribus highly unlikely to change.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Indeed, it is only when a goal is valued above integrity with others that
</em><br>
<em>&gt; an entity becomes selfish and dangerous.  I have said previously that the
</em><br>
<em>&gt; Kantian Categorical Imperative of “Cooperate!” would make a good top-level
</em><br>
<em>&gt; goal. After hearing too many SIAI advocates talking about *enforced*
</em><br>
<em>&gt; cooperation, I’m almost starting to prefer the opaque and wordier “Become
</em><br>
<em>&gt; one with all while remaining diverse”.  And Yudkowsky himself has written
</em><br>
<em>&gt; excellent *fiction* &lt;<a href="http://lesswrong.com/lw/y4/three_worlds_collide_08/">http://lesswrong.com/lw/y4/three_worlds_collide_08/</a>&gt; which
</em><br>
<em>&gt; shows what might happen when universal conformity is forcibly imposed and
</em><br>
<em>&gt; makes you wonder why he proposes the things he does.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Instead of focusing on intelligence and fulfillment of “the best” goal(s),
</em><br>
<em>&gt; we need to focus on wisdom and choosing those goals that will not cause
</em><br>
<em>&gt; strife, inefficiency, and thus unhappiness. The best is the enemy of the
</em><br>
<em>&gt; good and the good enough and is extremely subject to the question of “The
</em><br>
<em>&gt; best for what (or, more importantly, for*whom*)?” Universal benevolence
</em><br>
<em>&gt; gives everybody a chance and does not ignore the huge advantages of synergy
</em><br>
<em>&gt; and friendly diversity the way that “Friendliness” does.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Choosing any form of selfish “Friendliness” (local or universal) over
</em><br>
<em>&gt; Benevolence is a huge mistake and could cost us *everything*.
</em><br>
<em>&gt;
</em><br>
<p>
<br><p>
<p><hr>
<ul>
<li>application/octet-stream attachment: <a href="../att-21115/01-icon_wink.gif_m_1290163023g">icon_wink.gif_m_1290163023g</a>
</ul>
<!-- attachment="01-icon_wink.gif_m_1290163023g" -->
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="21116.html">Mark Waser: "Re: [sl4] META: closing the list"</a>
<li><strong>Previous message:</strong> <a href="21114.html">Mark Nuzzolilo: "Re: [sl4] META: closing the list"</a>
<li><strong>In reply to:</strong> <a href="21111.html">Mark Waser: "Re: [sl4] Universal versus 'local' Friendliness"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#21115">[ date ]</a>
<a href="index.html#21115">[ thread ]</a>
<a href="subject.html#21115">[ subject ]</a>
<a href="author.html#21115">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:05 MDT
</em></small></p>
</body>
</html>
