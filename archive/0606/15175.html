<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: I am a moral, intelligent being (was Re: Two draft papers: AI and existentia</title>
<meta name="Author" content="Michael Vassar (michaelvassar@hotmail.com)">
<meta name="Subject" content="Re: I am a moral, intelligent being (was Re: Two draft papers: AI and existentia">
<meta name="Date" content="2006-06-06">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: I am a moral, intelligent being (was Re: Two draft papers: AI and existentia</h1>
<!-- received="Tue Jun  6 23:38:09 2006" -->
<!-- isoreceived="20060607053809" -->
<!-- sent="Wed, 07 Jun 2006 01:37:58 -0400" -->
<!-- isosent="20060607053758" -->
<!-- name="Michael Vassar" -->
<!-- email="michaelvassar@hotmail.com" -->
<!-- subject="Re: I am a moral, intelligent being (was Re: Two draft papers: AI and existentia" -->
<!-- id="BAY101-F57DC39BBCCD437A2B7CF4AC8A0@phx.gbl" -->
<!-- inreplyto="5.1.0.14.0.20060606213257.026acbf8@pop.bloor.is.net.cable.rogers.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Vassar (<a href="mailto:michaelvassar@hotmail.com?Subject=Re:%20I%20am%20a%20moral,%20intelligent%20being%20(was%20Re:%20Two%20draft%20papers:%20AI%20and%20existentia"><em>michaelvassar@hotmail.com</em></a>)<br>
<strong>Date:</strong> Tue Jun 06 2006 - 23:37:58 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="15176.html">Michael Vassar: "Re: [agi] Two draft papers: AI and existential risk; heuristics and biases"</a>
<li><strong>Previous message:</strong> <a href="15174.html">Eliezer S. Yudkowsky: "Re: [agi] Two draft papers: AI and existential risk; heuristics and biases"</a>
<li><strong>In reply to:</strong> <a href="15171.html">Keith Henson: "Re: I am a moral, intelligent being (was Re: Two draft papers: AI and existential risk; heuristics and biases)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15181.html">Keith Henson: "Cats, was I am a moral, intelligent being"</a>
<li><strong>Reply:</strong> <a href="15181.html">Keith Henson: "Cats, was I am a moral, intelligent being"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15175">[ date ]</a>
<a href="index.html#15175">[ thread ]</a>
<a href="subject.html#15175">[ subject ]</a>
<a href="author.html#15175">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Yes analogies are always suspect...
<br>
And existance proofs really do always demonstrate possibility...
<br>
So so long as the existance proof is valid and people really *can* want to 
<br>
remain moral and become more intelligent the analogy is simply a waste of 
<br>
our time.
<br>
<p>If you want to get serious, at the very least you have to make a serious 
<br>
case that the robustness of human morality under carefully considered and 
<br>
bias corrected self-modification has not been adequately demonstrated (or 
<br>
that human morality is not robust under bias correction) and give us some 
<br>
reason for seriously doubting it.  Succeed in that and you still won't have 
<br>
prooved that Friendlyness is impossible, you will just be in a position 
<br>
analogous to those who claimed that heavier than air flying machines capable 
<br>
of lifting humans are impossible rather than that of those who claim that NO 
<br>
object of any size or with any other characteristics can fly.
<br>
<p><em>&gt;From: Keith Henson &lt;<a href="mailto:hkhenson@rogers.com?Subject=Re:%20I%20am%20a%20moral,%20intelligent%20being%20(was%20Re:%20Two%20draft%20papers:%20AI%20and%20existentia">hkhenson@rogers.com</a>&gt;
</em><br>
<em>&gt;Reply-To: <a href="mailto:sl4@sl4.org?Subject=Re:%20I%20am%20a%20moral,%20intelligent%20being%20(was%20Re:%20Two%20draft%20papers:%20AI%20and%20existentia">sl4@sl4.org</a>
</em><br>
<em>&gt;To: <a href="mailto:sl4@sl4.org?Subject=Re:%20I%20am%20a%20moral,%20intelligent%20being%20(was%20Re:%20Two%20draft%20papers:%20AI%20and%20existentia">sl4@sl4.org</a>
</em><br>
<em>&gt;Subject: Re: I am a moral, intelligent being (was Re: Two draft papers:  AI 
</em><br>
<em>&gt;and existential risk; heuristics and biases)
</em><br>
<em>&gt;Date: Tue, 06 Jun 2006 21:53:24 -0400
</em><br>
<em>&gt;
</em><br>
<em>&gt;At 09:46 AM 6/6/2006 -0700, robin wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt;snip
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt;It blows my mind that any intelligent and relevantly-knowledgeable
</em><br>
<em>&gt;&gt;person would have failed to perform this thought experiment on
</em><br>
<em>&gt;&gt;themselves to validate, as proof-by-existence, that an intelligent
</em><br>
<em>&gt;&gt;being that both wants to become more intelligent *and* wants to
</em><br>
<em>&gt;&gt;remain kind and moral is possible.
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt;Really bizarre and, as I said, starting to become offensive to me,
</em><br>
<em>&gt;&gt;because it seems to imply that my morality is fragile.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Analogy is always suspect, but consider cats.  We treat them as morally as 
</em><br>
<em>&gt;we can.
</em><br>
<em>&gt;
</em><br>
<em>&gt;The dire reality is that reproduction cannot be unlimited in a limited 
</em><br>
<em>&gt;world--so we go *SNIP* to cat gonads.  This is good from the moral 
</em><br>
<em>&gt;viewpoint of a substantial majority of humans.
</em><br>
<em>&gt;
</em><br>
<em>&gt;But I have my doubts about how the cats feel about it.  At least it is my 
</em><br>
<em>&gt;observation that intact cats have more interesting personalities.
</em><br>
<em>&gt;
</em><br>
<em>&gt;I &quot;solved&quot; this problem in the fiction I have been writing by putting rules 
</em><br>
<em>&gt;on the AIs that they would analyze as being such a good idea they would not 
</em><br>
<em>&gt;want to do otherwise.  Namely, no reproduction inside uploaded simulations 
</em><br>
<em>&gt;and no food production by the AIs outside the simulations.
</em><br>
<em>&gt;
</em><br>
<em>&gt;And the simulations were so attractive compared to the real world that the 
</em><br>
<em>&gt;big problem was getting enough people to have children in the physical 
</em><br>
<em>&gt;world to keep up a remnant population.
</em><br>
<em>&gt;
</em><br>
<em>&gt;(The AIs were constructed without the desire to reproduce and were only 
</em><br>
<em>&gt;brought into existence by physical state humans.)
</em><br>
<em>&gt;
</em><br>
<em>&gt;Keith Henson
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="15176.html">Michael Vassar: "Re: [agi] Two draft papers: AI and existential risk; heuristics and biases"</a>
<li><strong>Previous message:</strong> <a href="15174.html">Eliezer S. Yudkowsky: "Re: [agi] Two draft papers: AI and existential risk; heuristics and biases"</a>
<li><strong>In reply to:</strong> <a href="15171.html">Keith Henson: "Re: I am a moral, intelligent being (was Re: Two draft papers: AI and existential risk; heuristics and biases)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15181.html">Keith Henson: "Cats, was I am a moral, intelligent being"</a>
<li><strong>Reply:</strong> <a href="15181.html">Keith Henson: "Cats, was I am a moral, intelligent being"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15175">[ date ]</a>
<a href="index.html#15175">[ thread ]</a>
<a href="subject.html#15175">[ subject ]</a>
<a href="author.html#15175">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
