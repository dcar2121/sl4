<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Let's resolve it with a thought experiment</title>
<meta name="Author" content="James MacAulay (jmacaulay@gmail.com)">
<meta name="Subject" content="Re: Let's resolve it with a thought experiment">
<meta name="Date" content="2006-06-05">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Let's resolve it with a thought experiment</h1>
<!-- received="Mon Jun  5 11:15:25 2006" -->
<!-- isoreceived="20060605171525" -->
<!-- sent="Mon, 5 Jun 2006 13:15:09 -0400" -->
<!-- isosent="20060605171509" -->
<!-- name="James MacAulay" -->
<!-- email="jmacaulay@gmail.com" -->
<!-- subject="Re: Let's resolve it with a thought experiment" -->
<!-- id="284A5D19-57BF-40F3-B7E2-6D95DD8B94EE@gmail.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="007c01c688b6$6c0cc740$5f0a4e0c@MyComputer" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James MacAulay (<a href="mailto:jmacaulay@gmail.com?Subject=Re:%20Let's%20resolve%20it%20with%20a%20thought%20experiment"><em>jmacaulay@gmail.com</em></a>)<br>
<strong>Date:</strong> Mon Jun 05 2006 - 11:15:09 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="15136.html">Richard Loosemore: "Re: Let's resolve it with a thought experiment"</a>
<li><strong>Previous message:</strong> <a href="15134.html">Robin Lee Powell: "Re: Two draft papers: AI and existential risk; heuristics and biases"</a>
<li><strong>In reply to:</strong> <a href="15133.html">John K Clark: "Re: Let's resolve it with a thought experiment"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15140.html">John K Clark: "Re: Let's resolve it with a thought experiment"</a>
<li><strong>Reply:</strong> <a href="15140.html">John K Clark: "Re: Let's resolve it with a thought experiment"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15135">[ date ]</a>
<a href="index.html#15135">[ thread ]</a>
<a href="subject.html#15135">[ subject ]</a>
<a href="author.html#15135">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 5-Jun-06, at 11:40 AM | Jun 5, John K Clark wrote:
<br>
<em>&gt; The Friendly race look just like human
</em><br>
<em>&gt; beings except they are a bit more beautiful, they have a boiling  
</em><br>
<em>&gt; water IQ
</em><br>
<em>&gt; and they are incapable of disobeying any order given by a human  
</em><br>
<em>&gt; being and
</em><br>
<em>&gt; always placed human well being over his own. Would you be  
</em><br>
<em>&gt; comfortable with
</em><br>
<em>&gt; that?
</em><br>
<p>That's not analogous to Friendly AI at all, though; you're just  
<br>
talking about something like Asimov's laws. A Friendly AI would  
<br>
disobey lots of orders from humans if it determined that those orders  
<br>
were unethical, with those ethics derived from the ethics we would  
<br>
have if we were the people we wished ourselves to be. Likewise, I can  
<br>
think of a lot of believable situations where a Friendly AI would not  
<br>
place a human being's life before its own, especially if it is  
<br>
immensely powerful.
<br>
<p>If you've got a Friendly Jupiter Brain that has vastly helped the  
<br>
lives of all beings in the solar system, and which knows that it  
<br>
could continue to help those billions of lives in countless and  
<br>
unpredictable ways, then I can't imagine it sacrificing itself to  
<br>
save any non-substantial number of human beings who it knows *aren't*  
<br>
integral for the continued well being of all those minds. And it  
<br>
probably wouldn't entertain the silly whims of humans who wanted it  
<br>
to do nothing but calculate digits of pi for a day when it could  
<br>
better be spending that time improving people's lives, or improving  
<br>
itself so that it can improve people's lives more efficiently, or  
<br>
both, or whatever.
<br>
<p>So whether or not I think your hypothetical being would be a slave, I  
<br>
certainly don't think an FAI would be.
<br>
<p>James
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="15136.html">Richard Loosemore: "Re: Let's resolve it with a thought experiment"</a>
<li><strong>Previous message:</strong> <a href="15134.html">Robin Lee Powell: "Re: Two draft papers: AI and existential risk; heuristics and biases"</a>
<li><strong>In reply to:</strong> <a href="15133.html">John K Clark: "Re: Let's resolve it with a thought experiment"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15140.html">John K Clark: "Re: Let's resolve it with a thought experiment"</a>
<li><strong>Reply:</strong> <a href="15140.html">John K Clark: "Re: Let's resolve it with a thought experiment"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15135">[ date ]</a>
<a href="index.html#15135">[ thread ]</a>
<a href="subject.html#15135">[ subject ]</a>
<a href="author.html#15135">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
