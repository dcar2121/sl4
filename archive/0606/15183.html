<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Cats, was I am a moral, intelligent being</title>
<meta name="Author" content="Michael Vassar (michaelvassar@hotmail.com)">
<meta name="Subject" content="RE: Cats, was I am a moral, intelligent being">
<meta name="Date" content="2006-06-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Cats, was I am a moral, intelligent being</h1>
<!-- received="Wed Jun  7 09:39:30 2006" -->
<!-- isoreceived="20060607153930" -->
<!-- sent="Wed, 07 Jun 2006 11:39:09 -0400" -->
<!-- isosent="20060607153909" -->
<!-- name="Michael Vassar" -->
<!-- email="michaelvassar@hotmail.com" -->
<!-- subject="RE: Cats, was I am a moral, intelligent being" -->
<!-- id="BAY101-F58DC4FAF3AD4DA3B6D763AC8A0@phx.gbl" -->
<!-- inreplyto="5.1.0.14.0.20060607040535.04da8360@pop.bloor.is.net.cable.rogers.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Vassar (<a href="mailto:michaelvassar@hotmail.com?Subject=RE:%20Cats,%20was%20I%20am%20a%20moral,%20intelligent%20being"><em>michaelvassar@hotmail.com</em></a>)<br>
<strong>Date:</strong> Wed Jun 07 2006 - 09:39:09 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="15184.html">John K Clark: "Re: Let's resolve it with a thought experiment"</a>
<li><strong>Previous message:</strong> <a href="15182.html">Eliezer S. Yudkowsky: "Re: [agi] Two draft papers: AI and existential risk; heuristics and biases"</a>
<li><strong>In reply to:</strong> <a href="15181.html">Keith Henson: "Cats, was I am a moral, intelligent being"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15197.html">Martin Striz: "Re: Cats, was I am a moral, intelligent being"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15183">[ date ]</a>
<a href="index.html#15183">[ thread ]</a>
<a href="subject.html#15183">[ subject ]</a>
<a href="author.html#15183">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
It seems to me that all that you are saying is that FAI cannot grant all of 
<br>
the possible desires of biologically and culturally unmodified humans 
<br>
forever.  Lack of omnipotence-in-principle is not a failure of Friendlyness.
<br>
<p><em>&gt;From: Keith Henson &lt;<a href="mailto:hkhenson@rogers.com?Subject=RE:%20Cats,%20was%20I%20am%20a%20moral,%20intelligent%20being">hkhenson@rogers.com</a>&gt;
</em><br>
<em>&gt;Reply-To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Cats,%20was%20I%20am%20a%20moral,%20intelligent%20being">sl4@sl4.org</a>
</em><br>
<em>&gt;To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Cats,%20was%20I%20am%20a%20moral,%20intelligent%20being">sl4@sl4.org</a>
</em><br>
<em>&gt;CC: ExI chat list &lt;<a href="mailto:extropy-chat@lists.extropy.org?Subject=RE:%20Cats,%20was%20I%20am%20a%20moral,%20intelligent%20being">extropy-chat@lists.extropy.org</a>&gt;
</em><br>
<em>&gt;Subject: Cats, was I am a moral, intelligent being Date: Wed, 07 Jun 2006 
</em><br>
<em>&gt;05:06:04 -0400
</em><br>
<em>&gt;
</em><br>
<em>&gt;At 01:37 AM 6/7/2006 -0400, Michael Vassar wrote:
</em><br>
<em>&gt;&gt;Yes analogies are always suspect...
</em><br>
<em>&gt;&gt;And existance proofs really do always demonstrate possibility...
</em><br>
<em>&gt;&gt;So so long as the existance proof is valid and people really *can* want to 
</em><br>
<em>&gt;&gt;remain moral and become more intelligent the analogy is simply a waste of 
</em><br>
<em>&gt;&gt;our time.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;If you want to get serious, at the very least you have to make a serious 
</em><br>
<em>&gt;&gt;case that the robustness of human morality under carefully considered and 
</em><br>
<em>&gt;&gt;bias corrected self-modification has not been adequately demonstrated (or 
</em><br>
<em>&gt;&gt;that human morality is not robust under bias correction) and give us some 
</em><br>
<em>&gt;&gt;reason for seriously doubting it.  Succeed in that and you still won't 
</em><br>
<em>&gt;&gt;have prooved that Friendlyness is impossible, you will just be in a 
</em><br>
<em>&gt;&gt;position analogous to those who claimed that heavier than air flying 
</em><br>
<em>&gt;&gt;machines capable of lifting humans are impossible rather than that of 
</em><br>
<em>&gt;&gt;those who claim that NO object of any size or with any other 
</em><br>
<em>&gt;&gt;characteristics can fly.
</em><br>
<em>&gt;
</em><br>
<em>&gt;I am sorry to say I don't understand the basis of your complaint against my 
</em><br>
<em>&gt;post.
</em><br>
<em>&gt;
</em><br>
<em>&gt;&quot;The dire reality is that reproduction cannot be unlimited in a limited 
</em><br>
<em>&gt;world--so we go *SNIP* to cat gonads.  This is good from the moral 
</em><br>
<em>&gt;viewpoint of a substantial majority of humans.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt;(I should correct the above to a substantial fraction of western culture 
</em><br>
<em>&gt;members.)
</em><br>
<em>&gt;
</em><br>
<em>&gt;My point was that more intelligent AIs or upgraded humans may have a 
</em><br>
<em>&gt;different view of what is moral as we have a different view of what is 
</em><br>
<em>&gt;moral compared to cats.  If you upgraded a cat to human level intelligence 
</em><br>
<em>&gt;would it think controlling the population of regular cats the way we do was 
</em><br>
<em>&gt;moral?  (I have no idea.)
</em><br>
<em>&gt;
</em><br>
<em>&gt;I certainly had no intent to prove Friendlyness impossible either.  I would 
</em><br>
<em>&gt;be more inclined to attempt to prove it possible or even likely.  But I do 
</em><br>
<em>&gt;think Friendly AIs will have to make some hard decisions if unmodified 
</em><br>
<em>&gt;humans remain in the world--analogous to the decisions we make about cats 
</em><br>
<em>&gt;and for the same reason.
</em><br>
<em>&gt;
</em><br>
<em>&gt;I think you may be objecting to my word use.   The word &quot;solved&quot; (in 
</em><br>
<em>&gt;quotes) was in the literary device sense i.e., for the story.  I make no 
</em><br>
<em>&gt;claims at all about this being a solution for the real world outside the 
</em><br>
<em>&gt;story.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Though it does have the flavor of what we do with cats . . . .
</em><br>
<em>&gt;
</em><br>
<em>&gt;Keith Henson
</em><br>
<em>&gt;
</em><br>
<em>&gt;PS.  If the list snippers clip it, we should move this to the extopy-chat 
</em><br>
<em>&gt;list.  In preparation I will cc that list.
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt;&gt;From: Keith Henson &lt;<a href="mailto:hkhenson@rogers.com?Subject=RE:%20Cats,%20was%20I%20am%20a%20moral,%20intelligent%20being">hkhenson@rogers.com</a>&gt;
</em><br>
<em>&gt;&gt;&gt;Reply-To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Cats,%20was%20I%20am%20a%20moral,%20intelligent%20being">sl4@sl4.org</a>
</em><br>
<em>&gt;&gt;&gt;To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Cats,%20was%20I%20am%20a%20moral,%20intelligent%20being">sl4@sl4.org</a>
</em><br>
<em>&gt;&gt;&gt;Subject: Re: I am a moral, intelligent being (was Re: Two draft papers:  
</em><br>
<em>&gt;&gt;&gt;AI and existential risk; heuristics and biases)
</em><br>
<em>&gt;&gt;&gt;Date: Tue, 06 Jun 2006 21:53:24 -0400
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;At 09:46 AM 6/6/2006 -0700, robin wrote:
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;snip
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;&gt;It blows my mind that any intelligent and relevantly-knowledgeable
</em><br>
<em>&gt;&gt;&gt;&gt;person would have failed to perform this thought experiment on
</em><br>
<em>&gt;&gt;&gt;&gt;themselves to validate, as proof-by-existence, that an intelligent
</em><br>
<em>&gt;&gt;&gt;&gt;being that both wants to become more intelligent *and* wants to
</em><br>
<em>&gt;&gt;&gt;&gt;remain kind and moral is possible.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;&gt;Really bizarre and, as I said, starting to become offensive to me,
</em><br>
<em>&gt;&gt;&gt;&gt;because it seems to imply that my morality is fragile.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;Analogy is always suspect, but consider cats.  We treat them as morally 
</em><br>
<em>&gt;&gt;&gt;as we can.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;The dire reality is that reproduction cannot be unlimited in a limited 
</em><br>
<em>&gt;&gt;&gt;world--so we go *SNIP* to cat gonads.  This is good from the moral 
</em><br>
<em>&gt;&gt;&gt;viewpoint of a substantial majority of humans.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;But I have my doubts about how the cats feel about it.  At least it is my 
</em><br>
<em>&gt;&gt;&gt;observation that intact cats have more interesting personalities.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;I &quot;solved&quot; this problem in the fiction I have been writing by putting 
</em><br>
<em>&gt;&gt;&gt;rules on the AIs that they would analyze as being such a good idea they 
</em><br>
<em>&gt;&gt;&gt;would not want to do otherwise.  Namely, no reproduction inside uploaded 
</em><br>
<em>&gt;&gt;&gt;simulations and no food production by the AIs outside the simulations.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;And the simulations were so attractive compared to the real world that 
</em><br>
<em>&gt;&gt;&gt;the big problem was getting enough people to have children in the 
</em><br>
<em>&gt;&gt;&gt;physical world to keep up a remnant population.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;(The AIs were constructed without the desire to reproduce and were only 
</em><br>
<em>&gt;&gt;&gt;brought into existence by physical state humans.)
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;Keith Henson
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="15184.html">John K Clark: "Re: Let's resolve it with a thought experiment"</a>
<li><strong>Previous message:</strong> <a href="15182.html">Eliezer S. Yudkowsky: "Re: [agi] Two draft papers: AI and existential risk; heuristics and biases"</a>
<li><strong>In reply to:</strong> <a href="15181.html">Keith Henson: "Cats, was I am a moral, intelligent being"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15197.html">Martin Striz: "Re: Cats, was I am a moral, intelligent being"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15183">[ date ]</a>
<a href="index.html#15183">[ thread ]</a>
<a href="subject.html#15183">[ subject ]</a>
<a href="author.html#15183">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
