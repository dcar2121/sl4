<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: analytical rigor</title>
<meta name="Author" content="Richard Loosemore (rpwl@lightlink.com)">
<meta name="Subject" content="Re: analytical rigor">
<meta name="Date" content="2006-06-28">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: analytical rigor</h1>
<!-- received="Wed Jun 28 10:10:34 2006" -->
<!-- isoreceived="20060628161034" -->
<!-- sent="Wed, 28 Jun 2006 12:07:55 -0400" -->
<!-- isosent="20060628160755" -->
<!-- name="Richard Loosemore" -->
<!-- email="rpwl@lightlink.com" -->
<!-- subject="Re: analytical rigor" -->
<!-- id="44A2A95B.2020308@lightlink.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="3ad827f30606261019w6bef5ba4v760c3fc2a486dd67@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Richard Loosemore (<a href="mailto:rpwl@lightlink.com?Subject=Re:%20analytical%20rigor"><em>rpwl@lightlink.com</em></a>)<br>
<strong>Date:</strong> Wed Jun 28 2006 - 10:07:55 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="15337.html">Robin Lee Powell: "Re: Cold-War Disarmament Activism"</a>
<li><strong>Previous message:</strong> <a href="15335.html">Joshua Fox: "Cold-War Disarmament Activism"</a>
<li><strong>In reply to:</strong> <a href="15320.html">justin corwin: "Re: analytical rigor"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15313.html">Chris Capel: "Re: analytical rigor"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15336">[ date ]</a>
<a href="index.html#15336">[ thread ]</a>
<a href="subject.html#15336">[ subject ]</a>
<a href="author.html#15336">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Justin
<br>
<p>The below message was written immediately after I got your post that is 
<br>
analysed in it:  a problem with my ISP prevented me from sending it for 
<br>
a couple of days, and then, when I got access to outgoing mail, I forgot 
<br>
that it was still unsent.
<br>
<p>So, in reply to your recent message in which you complain of getting no 
<br>
answers, in this case you deserve an apology for lateness.
<br>
<p>My mistake.
<br>
<p>Richard Loosemore
<br>
<p><p><p><p><p><p><p><p><p>There are many people who know about the history of AI, and who also
<br>
know about the relationship between &quot;experimental mathematics&quot; and
<br>
nonlinear systems research, and who know about the way that
<br>
non-scientific factors shape scientific research, who would not have had
<br>
any trouble understanding exactly what I was talking about when I made
<br>
my original comments.
<br>
<p>You are clearly not one of those people, but if you had started out your
<br>
message by expressing interest and asking for clarification, instead of
<br>
dispensing insults and taking every opportunity to be patronizing, I'd
<br>
have cheerfully taken the time to elaborate on my remarks and make them
<br>
more accessible.
<br>
<p>I've responded to some of your specific charges below, but I can't say I
<br>
have much enthusiasm to write an extended essay.
<br>
<p>justin corwin wrote:
<br>
<em>&gt; Ah, another Monday morning coming back to mischaracterizations:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; On 6/25/06, Richard Loosemore &lt;<a href="mailto:rpwl@lightlink.com?Subject=Re:%20analytical%20rigor">rpwl@lightlink.com</a>&gt; wrote:
</em><br>
<em>&gt;&gt; You may be mistaking fuzziness in your own understanding of the issues
</em><br>
<em>&gt;&gt; for fuzziness in the issues themselves.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Lets be clear here. You had a quote by Strogatz, where he quotes Ulam
</em><br>
<em>&gt; explaining that there are a lot of nonlinear systems. Then you went on
</em><br>
<em>&gt; for two paragraphs about 'vast' areas and 'tiny piles of analytically
</em><br>
<em>&gt; tractable systems' and &quot;Outer Darkness&quot; You characterize this
</em><br>
<em>&gt; situation as a very obvious and important divide between linear and
</em><br>
<em>&gt; nonlinear systems. You do, of course, neglect to reference anything
</em><br>
<em>&gt; more than a quote of a casual quote, mention any specific claims of
</em><br>
<em>&gt; intractability, or reference any &quot;impossible&quot; problems that have stood
</em><br>
<em>&gt; for the &quot;centuries&quot; you're broadly painting.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; That's what I mean by fuzziness. If you /mean/ something specific,
</em><br>
<em>&gt; then by all means correct me. As far as I can tell, your point thus
</em><br>
<em>&gt; far in your first two paragraphs and subsequent responses is to assert
</em><br>
<em>&gt; that there are lots and lots of nonlinear systems, most of which are
</em><br>
<em>&gt; insoluble, and that all of mathematics (and presumably other sciences)
</em><br>
<em>&gt; has resulted in very little progress in this space, on the basis of a
</em><br>
<em>&gt; quote and a lot of adjectives.
</em><br>
<p>The statement about nonlinear systems is so obvious to a mathematician
<br>
that nobody in their right mind would ask for references.  You are as
<br>
good as asking a person who mentions that &quot;gravity makes things fall&quot; to
<br>
give some references to experiments that have substantiated this fact.
<br>
<p>Like I say, you mistake your own lack of knowledge for something else.
<br>
<p><p><p><p><em>&gt;&gt; If Stephen Strogatz could
</em><br>
<em>&gt;&gt; understand these points well enough to write about them in his book, and
</em><br>
<em>&gt;&gt; if he has not yet lost his job or his status as a world-class
</em><br>
<em>&gt;&gt; mathematician specializing in nonlinear systems, and if I repeat them
</em><br>
<em>&gt;&gt; here, applied to AGI issues, then it begins to look like the points I
</em><br>
<em>&gt;&gt; made actually have a great deal of depth, whereas your criticism
</em><br>
<em>&gt;&gt; contains nothing that indicates understanding, only complaints.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Yes, a well respected author is evidence for some depth in a debate 
</em><br>
<em>&gt; somewhere.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt; Are you claiming that the SL4 list imagines the
</em><br>
<em>&gt;&gt; &gt; world is a linear place? Did you think that the statement &quot;most claims
</em><br>
<em>&gt;&gt; &gt; of impossibility usually turn out to be unreliable&quot; applied largely to
</em><br>
<em>&gt;&gt; &gt; mathematical claims of intractability(which it doesn't, as far as I
</em><br>
<em>&gt;&gt; &gt; can tell, it refers to specific technological achievement, deriving
</em><br>
<em>&gt;&gt; &gt; from the older quote &quot;If a respected elder scientist says something is
</em><br>
<em>&gt;&gt; &gt; possible, he is very likely right, if he says something is impossible,
</em><br>
<em>&gt;&gt; &gt; he is very likely wrong&quot;, deriving from older embarassing anecdotes
</em><br>
<em>&gt;&gt; &gt; about Lord Kelvin, who was very prone to declarative statements.)
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; I can't think of anything more vague and fuzzy than the idiotic quote
</em><br>
<em>&gt;&gt; about elder scientists.  I am not operating at that level, I am talking
</em><br>
<em>&gt;&gt; about deep methodological issues.  I wouldn't dream of wasting my time
</em><br>
<em>&gt;&gt; on debating whether or not old scientists talk garbage.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This is nice. Respond to the sub note, it's the most important part of
</em><br>
<em>&gt; this paragraph. Do you have an answer to either question? To me, it
</em><br>
<em>&gt; seems like you're twisting the definition of 'impossibility' (and the
</em><br>
<em>&gt; applicability of the quote) to make a vague point about the big and
</em><br>
<em>&gt; scary world of Complex systems.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Who are you talking about? What are you accusing them of?
</em><br>
<p>Now you are asking me to interpret my post because you are apparently
<br>
not clear about what exactly I was refering to:  I am trying to point
<br>
out that you could have done that without launching an ad hominem attack
<br>
first.
<br>
<p><p><p><em>&gt; &lt;snip&gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt; Oh, please:  let's keep &quot;conspiracy&quot; talk out of this.  I didn't say or
</em><br>
<em>&gt;&gt; imply anything about conspiracies, so it would helpe if you didn't put
</em><br>
<em>&gt;&gt; words into my mouth.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; You are accusing unknown persons of having a 'stranglehold' on 'AI
</em><br>
<em>&gt; research'. I'll use a different word if it makes you feel better.
</em><br>
<p>A stranglehold can be had without there being a consiracy of any sort
<br>
whatsoever.  By trying to imply that I was talking about a conspiracy,
<br>
you were attempting to mock the claim I was making.
<br>
<p><p><p><p><em>&gt;&gt; This is a ridiculously naive view of what science is actually like.  Get
</em><br>
<em>&gt;&gt; out there and talk to some real scientists about biasses and funding
</em><br>
<em>&gt;&gt; bandwagons and prejudices and power centers.  Or, if you can't do that,
</em><br>
<em>&gt;&gt; read some books by people who study how science works.  Failing that, at
</em><br>
<em>&gt;&gt; least don't say anything about it.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; What 'view' would you say that paragraph was espousing? Did I claim
</em><br>
<em>&gt; any mechanism or make, in fact, any claims about 'what science is
</em><br>
<em>&gt; actually like'? All I said was that scientists don't care about what
</em><br>
<em>&gt; you do. And have no motivation to interfere with your work.
</em><br>
<p><em>&gt;&gt; You could trying to read about the role played by Behaviorists in the
</em><br>
<em>&gt;&gt; psychology community.  That situation is closely analogous to the
</em><br>
<em>&gt;&gt; present situation in AI.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Luckily, I've already been interested in psychology a long time, and I
</em><br>
<em>&gt; am familiar with the dominance of the Behaviorist model. It's true
</em><br>
<em>&gt; that a lot of good research didn't get done because it did not fit the
</em><br>
<em>&gt; Behaviorist paradigm. Unfortunately for your point, a lot of
</em><br>
<em>&gt; scientists continued with what they were doing anyway, on their own
</em><br>
<em>&gt; tenure, or in private research, or even outside established science.
</em><br>
<em>&gt; That's why psychology has moved on. Certainly if the majority view is
</em><br>
<em>&gt; 'wrong', and that view is being taught to students, then less people
</em><br>
<em>&gt; will be doing science the 'right' way. That's not an active force
</em><br>
<em>&gt; preventing anything.
</em><br>
<p>But - this is just factually incorrect!
<br>
<p>How can I discuss this with you when you can make such a distorted
<br>
statement?  I mean, where do I begin?
<br>
<p>Cognitive scientists consider that entire period an almost complete
<br>
waste of time.  They speak of the behaviorists as dogmatically and
<br>
ruthlessly suppressing any other kinds of research.  If you tried to get
<br>
published doing cognitive science in those days, you simply couldn't get
<br>
a job.
<br>
<p>Sure, a few people carried on (especially in Europe), but if I go to the
<br>
nearest academic library from where I currently sit, I could take 90% of
<br>
all the psychology books  -  about 200 linear feet of shelf space  -
<br>
and put them though a shredder without making any diminution in the
<br>
quality of their collection.  That's how bad it was.
<br>
<p><p><em>&gt;&gt; It would have been nicer if, anywhere in your message, you had addressed
</em><br>
<em>&gt;&gt; a single, solitary grain of the issues I raised, or asked questions to
</em><br>
<em>&gt;&gt; clarify some aspect of what I said, so you could go further and talk
</em><br>
<em>&gt;&gt; about the issues.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I objected to your argument on the grounds that you weren't making any
</em><br>
<em>&gt; concrete points, and challenged you to make some specific claims.
</em><br>
<em>&gt; That's a valid criticism, under whatever philosophy of science you
</em><br>
<em>&gt; follow. Also, I asked three questions, although the last was partly
</em><br>
<em>&gt; rhetorical:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Are you claiming that the SL4 list imagines the
</em><br>
<em>&gt; world is a linear place?
</em><br>
<p>I don't know why you speak of the &quot;SL4 list&quot;.  I am a member of the SL4
<br>
list as well.  I was talking about a particular approach to AI research.
<br>
&nbsp;&nbsp;This list is dominated by that view, but it is not exclusive.
<br>
<p>I was talking about a particular, extended meaning of the word &quot;linear&quot;
<br>
that is prevalent in mathematics.  This has to do with the way that
<br>
systems can be composed in such a way that local mechanisms DO NOT
<br>
combine so that the system as a whole has structured behavior that is
<br>
not analytically derivable from the local mechanisms.  That is &quot;linear&quot;
<br>
in the extended sense.
<br>
<p>There are some researchers for whom the structure and behavior of AI
<br>
systems are linear enough that analytic proofs of the behavior of those
<br>
AI systems are possible.  More importantly there is an *attitude*
<br>
towards the structure of AI systems that tries to make the system
<br>
components look as much *like* cleanly decomposable, linear systems as
<br>
possible.  There are some for whom the only viable structures are ones
<br>
about which proofs can be made, and it manifests itself in many ways, 
<br>
like the emphasis on logical reasoning, the emphasis on symbols with
<br>
objective or compositional semantics, the possibility of detaching 
<br>
learning mechanisms from thinking mechanisms, the neglect or 
<br>
postponement of issues about grounding symbols in the real world, the 
<br>
pursuit of analytic types of neural network learning algorithms, etc etc 
<br>
etc ..... Are any of these issues meaningfull to you, and do you 
<br>
understand them in depth?  Do you need me to provide further 
<br>
clarification of what they mean?
<br>
<p>One of the ways it comes out is in what Alan Bundy called &quot;theorem
<br>
envy&quot;.  The desire to do something that looks, feels or smells like
<br>
analytic mathematics because that gives a superficial feeling of validation.
<br>
<p>When and if you understand the subtlety of this meaning of &quot;linear&quot;
<br>
(which would be familiar to people like Strogatz), you will understand
<br>
what I was referring to.  My comments were directed at people already
<br>
very familiar with mathematics and AI, who might have some hope of
<br>
comprehending the implications of that difference between the
<br>
tractability of linear and nonlinear systems.
<br>
<p><p><em>&gt; Did you think that the statement &quot;most claims
</em><br>
<em>&gt; of impossibility usually turn out to be unreliable&quot; applied largely to
</em><br>
<em>&gt; mathematical claims of intractability?
</em><br>
<p>In the original context, people were heard complaining that it was a
<br>
waste of time to attempt to prove this or that aspect of the behavior of
<br>
an AGI, because such analytic proofs were &quot;impossible&quot;.  The reply (in
<br>
the form of a reference to Scott Aaronson's dispute with a physicist)
<br>
was that some foolish people like to dismiss proofs as &quot;impossible&quot;, but
<br>
in the long run these fools usually turn out to be wrong  ...... hence
<br>
the phrase &quot;most claims of impossibility usually turn out to be unreliable&quot;.
<br>
<p>MY point was that this was a silly thing to say, set against the claims
<br>
of impossibility of finding analytic solutions to the behavior of
<br>
nonlinear systems.  Those particular claims of impossibility (which
<br>
directly relate to our issues regarding the structure of AGI systems)
<br>
are as robust as any, and they are vast in number.
<br>
<p><p><p><em>&gt; I'm sorry you don't like what most scientists are doing, so
</em><br>
<em>&gt; what?
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt; The fact that you did not, but instead just complained about nebulous
</em><br>
<em>&gt;&gt; faults that you imagined you saw, is part of the collective abdication
</em><br>
<em>&gt;&gt; of scientific responsibility I was talking about in the first place:
</em><br>
<em>&gt;&gt; you avoided the issue.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; You filled an email with unspecific adjective-laden sentences,
</em><br>
<em>&gt; accusing unnamed persons of being self-deluded, of obstructing AI
</em><br>
<em>&gt; research, of not recognizing some grand truth about the
</em><br>
<em>&gt; incomprehensibility of the world. I felt that you were sniping
</em><br>
<em>&gt; opportunistically, writing without specific claims, making dramatic
</em><br>
<em>&gt; points without support. I don't have a case to prove, you do.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; If you think all AI research is missing something, what is that? You
</em><br>
<em>&gt; refuse to specifically point to errors or approaches, or make any
</em><br>
<em>&gt; specific predictions. You write about what stupid, naive, blinded folk
</em><br>
<em>&gt; we are, and are aggravated when someone points out that you are just
</em><br>
<em>&gt; asserting so with big words. I don't even have a clear idea who or
</em><br>
<em>&gt; what theories or community you are slandering, only that they're
</em><br>
<em>&gt; holding back all progress. So, by induction, since I think I'm making
</em><br>
<em>&gt; progress, and part of 'the establishment' by virtue of having a job in
</em><br>
<em>&gt; AI, I assume I must be part of the problem. So, where to begin
</em><br>
<em>&gt; correcting my many faults?
</em><br>
<em>&gt; What, in fact, is your issue that I'm avoiding?
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="15337.html">Robin Lee Powell: "Re: Cold-War Disarmament Activism"</a>
<li><strong>Previous message:</strong> <a href="15335.html">Joshua Fox: "Cold-War Disarmament Activism"</a>
<li><strong>In reply to:</strong> <a href="15320.html">justin corwin: "Re: analytical rigor"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15313.html">Chris Capel: "Re: analytical rigor"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15336">[ date ]</a>
<a href="index.html#15336">[ thread ]</a>
<a href="subject.html#15336">[ subject ]</a>
<a href="author.html#15336">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
