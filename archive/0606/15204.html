<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Singularity awareness</title>
<meta name="Author" content="Charles D Hixson (charleshixsn@earthlink.net)">
<meta name="Subject" content="Re: Singularity awareness">
<meta name="Date" content="2006-06-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Singularity awareness</h1>
<!-- received="Wed Jun  7 16:42:36 2006" -->
<!-- isoreceived="20060607224236" -->
<!-- sent="Wed, 07 Jun 2006 15:41:21 -0700" -->
<!-- isosent="20060607224121" -->
<!-- name="Charles D Hixson" -->
<!-- email="charleshixsn@earthlink.net" -->
<!-- subject="Re: Singularity awareness" -->
<!-- id="44875611.9080308@earthlink.net" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="44D799C5@zathras" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Charles D Hixson (<a href="mailto:charleshixsn@earthlink.net?Subject=Re:%20Singularity%20awareness"><em>charleshixsn@earthlink.net</em></a>)<br>
<strong>Date:</strong> Wed Jun 07 2006 - 16:41:21 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="15205.html">J. Andrew Rogers: "Re: I am a moral, intelligent being (was Re: Two draft papers: AI and existential risk; heuristics and biases)"</a>
<li><strong>Previous message:</strong> <a href="15203.html">Peter C. McCluskey: "Re: Two draft papers: AI and existential risk; heuristics and biases"</a>
<li><strong>In reply to:</strong> <a href="15103.html">pdugan: "RE: Singularity awareness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15220.html">pdugan: "RE: Singularity awareness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15204">[ date ]</a>
<a href="index.html#15204">[ thread ]</a>
<a href="subject.html#15204">[ subject ]</a>
<a href="author.html#15204">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
pdugan wrote:
<br>
<em>&gt;&gt; ===== Original Message From Charles D Hixson &lt;<a href="mailto:charleshixsn@earthlink.net?Subject=Re:%20Singularity%20awareness">charleshixsn@earthlink.net</a>&gt; 
</em><br>
<em>&gt;&gt;     
</em><br>
<em>&gt; =====
</em><br>
<em>&gt;   
</em><br>
<em>&gt;&gt; pdugan wrote:
</em><br>
<em>&gt;&gt;     
</em><br>
<em>&gt;&gt;&gt; I think the release of a serious simulation or commercial game of adequete
</em><br>
<em>&gt;&gt;&gt; craft and marketing could cause 2 or 3 to happen, respectively. What better
</em><br>
<em>&gt;&gt;&gt; way to get people to grok the singularity than have them interact with a
</em><br>
<em>&gt;&gt;&gt; computer that simulates and/or represents the core ideas?
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; Patrick Dugan
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;       
</em><br>
<em>&gt;&gt;&gt;&gt; ===== Original Message From Joshua Fox &lt;<a href="mailto:joshua@joshuafox.com?Subject=Re:%20Singularity%20awareness">joshua@joshuafox.com</a>&gt; =====
</em><br>
<em>&gt;&gt;&gt;&gt; Anyone want to venture a guess on the public awareness of the
</em><br>
<em>&gt;&gt;&gt;&gt; Singularity in, say, 2010 or 2015?
</em><br>
<em>&gt;&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;&gt; I'm wondering if the Singularity will
</em><br>
<em>&gt;&gt;&gt;&gt; (1) remain the province of a few hundred or a few thousand
</em><br>
<em>&gt;&gt;&gt;&gt; super-technologically-aware types (like, e.g., hints of possibilities
</em><br>
<em>&gt;&gt;&gt;&gt; for faster-than-light spaceflight today);
</em><br>
<em>&gt;&gt;&gt;&gt; (2) or spread into the awareness of hundreds of thousands or millions of
</em><br>
<em>&gt;&gt;&gt;&gt; educated people (like, e.g. private space travel or nanotech today);
</em><br>
<em>&gt;&gt;&gt;&gt; (3) or become a major social issue followed by tens or hundreds of
</em><br>
<em>&gt;&gt;&gt;&gt; millions (like, e.g., genetically engineered food or nuclear power today).
</em><br>
<em>&gt;&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;&gt; Any thoughts?
</em><br>
<em>&gt;&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;&gt; Joshua
</em><br>
<em>&gt;&gt;&gt;&gt;         
</em><br>
<em>&gt;&gt; One way to acquire sufficient computational resources would be to
</em><br>
<em>&gt;&gt; publish an on-line game (or community?  2nd Life?) in which much of the
</em><br>
<em>&gt;&gt; computation was done by what is essentially voluntary participants in a
</em><br>
<em>&gt;&gt; bot-net.  This would be even better if the game could be so structured
</em><br>
<em>&gt;&gt; that portions of the game score depended on solving challenges that were
</em><br>
<em>&gt;&gt; those needed by the program's operation.  (Since these would be &quot;high
</em><br>
<em>&gt;&gt; level&quot; challenges, they should have high rewards attached to them.
</em><br>
<em>&gt;&gt; There would, after all, be a large probability of failure.)
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Is this feasible?  ??  Is 2nd Life involved in such a scenario?  ??  (I
</em><br>
<em>&gt;&gt; tend to think not.)  But do note that a lot of the time in these games
</em><br>
<em>&gt;&gt; the computer is essentially waiting for the user to react.  This time
</em><br>
<em>&gt;&gt; represents available CPU cycles that don't need to be merely discarded.
</em><br>
<em>&gt;&gt; (Of course, with a lot of designs the OS already uses them for
</em><br>
<em>&gt;&gt; background processing.)
</em><br>
<em>&gt;&gt;     
</em><br>
<em>&gt;
</em><br>
<em>&gt; Actually I was thinking of something more along the lines of a &quot;massively 
</em><br>
<em>&gt; single-player&quot; game where users different reactions to a partially simulated, 
</em><br>
<em>&gt; but mostly representational hard take-off would yeild different post-singular 
</em><br>
<em>&gt; futures, so that the end-game is, to an extend, user created content. Then 
</em><br>
<em>&gt; people could put this stuff up and compare notes and singularity awareness 
</em><br>
<em>&gt; would generally improve for the better. The upcoming Spore might have the same 
</em><br>
<em>&gt; effect on people's awarenss of xenobiology concepts.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Second Life isn't really a challenge oriented user environment; the only real 
</em><br>
<em>&gt; goals are aesthetic, with the result being a heterogeneous environment of user 
</em><br>
<em>&gt; created content. Since a desirable post-singular future could probably be 
</em><br>
<em>&gt; described as a heterogeneous environment of user created content, it makes 
</em><br>
<em>&gt; sense to see a soft take-off being facilitated and &quot;padded&quot; by successive 
</em><br>
<em>&gt; generations of such platforms. I don't know if designing a system that used 
</em><br>
<em>&gt; human play to teach an AGI (if that's what you're getting at) is desirable or 
</em><br>
<em>&gt; feasible. Its not feasible because if the virtual world doesn't have 
</em><br>
<em>&gt; commercial entertianment appeal, you'll never get funding for it short of 
</em><br>
<em>&gt; DARPA taking a very serious and creative stance on AGI, and its not 
</em><br>
<em>&gt; nessecarily desirable because AGI pattern recognition isn't going to be mature 
</em><br>
<em>&gt; enough to handle such an environment in early stages.
</em><br>
<em>&gt;   
</em><br>
Well, that wasn't what I meant...but it's an interesting model for a
<br>
more advanced version.  Create the entity as a character in the game or
<br>
community, and have it interact with the community to practice
<br>
interacting with people.  This clearly depends on an environment where
<br>
there are lots of people acting rather &quot;normally&quot;.
<br>
<p>But what I was actually thinking of was using the game in the same way
<br>
that &quot;bot-networks&quot; use the computers that they zombify.  The
<br>
differences would be that you would only do this while they were
<br>
playing/participating, and that you would be doing this with the full
<br>
knowledge of the players.  I don't see this as requiring that the &quot;game&quot;
<br>
be challenge oriented.  A community seems, if anything, a better
<br>
environment.  It might even facilitate the learning of the meanings of
<br>
words:  the entity would &quot;hear&quot; the words being used in a context that
<br>
it would be fully informed about.  There are even precedents, NPCs, that
<br>
have lowered the expectations so that if the NPC acted in ways that
<br>
weren't too intelligent, then this would be accepted, and as it learned
<br>
to act more intelligently and more helpfully, THIS would be accepted.  
<br>
A NPC &quot;passing&quot; for a player would be a kind of a milestone.  (But don't
<br>
take that too seriously, remember that Eliza once fooled a professor
<br>
into mistaking it for a human...resulting a a very angry professor.)
<br>
<em>&gt; Using a infra-human AGI to both direct and learn from such an environment as 
</em><br>
<em>&gt; part of its sensory modality isn't a bad idea though, something to consider 
</em><br>
<em>&gt; maybe five years down the line.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I'm not sure if Ben's optimism regarding parrallel hardware is accurate or 
</em><br>
<em>&gt; not, but I don't think human support can make up for raw computation, but 
</em><br>
<em>&gt; human support can aid pattern learning significantly.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Patrick
</em><br>
Parallel hardware is very important, but you pay a high price.  Syncing
<br>
up costs a lot, so you need to be very careful how you divide things. 
<br>
If you are doing neural networks, I presume that there is some more
<br>
obvious approach, but for me ... justifying a forked process is a tough
<br>
thing to do on my current system.  Forking is relatively expensive, and
<br>
I only have a couple of processors anyway.  But if you chose your fork
<br>
points properly you don't lose much.  Low level parallelism, however,
<br>
becomes very inefficient on standard processors.  I suspect that any
<br>
approach that depends on it is going to need to structure itself
<br>
hierarchically, though each &quot;level&quot; of nodes will need lots of sideway
<br>
communication within it's local group (ganglion?  column?).  Then you
<br>
need error checks, etc.  Predictions help here.  If you don't see what
<br>
you predicted you would see, then you need to check for errors.  If you
<br>
do, you can probably skip that step.  (This is sometimes a mistake...but
<br>
people seem to work that way, so it's probably a reasonable cost to pay.)
<br>
<p>Note that one of the main functions of the clustering is to limit the
<br>
amount of interprocessor communication required in a parallel system. 
<br>
If parallel systems weren't VERY important, there's no way that anybody
<br>
would pay for this kind of overhead.
<br>
<p>However, silicon chips are a LOT faster than wetware...and a lot more
<br>
expensive .. and emit more heat.  This probably implies that the ideal
<br>
design will be different, with more processing at each &quot;cell&quot;, and less
<br>
parallelism.  NOT none.  And this is a design decision that is sensitive
<br>
to the costs of various ways of doing things, so if CPU prices plunge,
<br>
and massively parallel systems become more common, the &quot;best choice&quot;
<br>
will be different.  It would, however, require a very unexpected
<br>
technology change to make the fastest AI design look much like the
<br>
design of the human brain.  (Parallelism, yes, but there are reasonable
<br>
limitations.)
<br>
<p>OTOH, we already know that at least one neural network design can
<br>
reliably produce intelligent behavior.  There's a certain amount of
<br>
sense in going with something that you have good reason to believe will
<br>
work.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="15205.html">J. Andrew Rogers: "Re: I am a moral, intelligent being (was Re: Two draft papers: AI and existential risk; heuristics and biases)"</a>
<li><strong>Previous message:</strong> <a href="15203.html">Peter C. McCluskey: "Re: Two draft papers: AI and existential risk; heuristics and biases"</a>
<li><strong>In reply to:</strong> <a href="15103.html">pdugan: "RE: Singularity awareness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15220.html">pdugan: "RE: Singularity awareness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15204">[ date ]</a>
<a href="index.html#15204">[ thread ]</a>
<a href="subject.html#15204">[ subject ]</a>
<a href="author.html#15204">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
