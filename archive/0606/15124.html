<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Two draft papers: AI and existential risk; heuristics and biases</title>
<meta name="Author" content="Olie Lamb (neomorphy@gmail.com)">
<meta name="Subject" content="Re: Two draft papers: AI and existential risk; heuristics and biases">
<meta name="Date" content="2006-06-05">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Two draft papers: AI and existential risk; heuristics and biases</h1>
<!-- received="Mon Jun  5 01:37:31 2006" -->
<!-- isoreceived="20060605073731" -->
<!-- sent="Mon, 5 Jun 2006 17:37:02 +1000" -->
<!-- isosent="20060605073702" -->
<!-- name="Olie Lamb" -->
<!-- email="neomorphy@gmail.com" -->
<!-- subject="Re: Two draft papers: AI and existential risk; heuristics and biases" -->
<!-- id="f3afeba0606050037i66f9a7een835bbaaad2ed4626@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="004101c6881a$fe9199c0$680a4e0c@MyComputer" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Olie Lamb (<a href="mailto:neomorphy@gmail.com?Subject=Re:%20Two%20draft%20papers:%20AI%20and%20existential%20risk;%20heuristics%20and%20biases"><em>neomorphy@gmail.com</em></a>)<br>
<strong>Date:</strong> Mon Jun 05 2006 - 01:37:02 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="15125.html">BillK: "Re: Singularity awareness"</a>
<li><strong>Previous message:</strong> <a href="15123.html">John K Clark: "Re: Two draft papers: AI and existential risk; heuristics and biases"</a>
<li><strong>In reply to:</strong> <a href="15114.html">John K Clark: "Re: Two draft papers: AI and existential risk; heuristics and biases"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15122.html">Ben Goertzel: "Re: Two draft papers: AI and existential risk; heuristics and biases"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15124">[ date ]</a>
<a href="index.html#15124">[ thread ]</a>
<a href="subject.html#15124">[ subject ]</a>
<a href="author.html#15124">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 6/5/06, John K Clark &lt;<a href="mailto:jonkc@att.net?Subject=Re:%20Two%20draft%20papers:%20AI%20and%20existential%20risk;%20heuristics%20and%20biases">jonkc@att.net</a>&gt; wrote:
<br>
<em>&gt; (You) think that the very definition of a good AI is one that is enslaved to
</em><br>
<em>&gt; do exactly precisely what the colossally stupid human beings wants to be
</em><br>
<em>&gt; done. That is evil, I'm sorry there is no other word for it.
</em><br>
<p>Whether a powerful intelligence allows humans to do things, or does
<br>
things for them makes for a pretty small consequential difference.
<br>
<p>Humans want to do a lot of things that aren't very nice.
<br>
<p>Whether a powerful intellgence does them for the humans, or allows the
<br>
humans to do them, works out much the same (even if it might be a tiny
<br>
bit ethically different)
<br>
<p>Most people wish violence (etc) on others at some point.  Usually,
<br>
it's for indirect and defensible-under-certain-context reasons like
<br>
revenge / punishment / keeping societal order.
<br>
<p>Occasionally it's for direct reasons such as pleasure.
<br>
<p>A sysop could remove some indirect motivations for violence, by
<br>
*effectively apologising* for people's past indescretions, preventing
<br>
further acts that necessitate revenge, and could also make some direct
<br>
reasons for violence obsolete, such as through the simulation of
<br>
violent acts.
<br>
<p>However, where humans are inclined to violence for stupid reasons, a
<br>
Sysop would either have to interfere with their actions (making them
<br>
unhappy), or interfere with their motivations.  Or I've not thought of
<br>
an option.
<br>
<p>If interfering with motivations is cool... worry.
<br>
If making people unhappy is cool... be concerned.
<br>
<p>I've been writing a piece of fiction that looks into this problem.
<br>
Unfortunately, given a number of things, it will probably never be
<br>
finished.
<br>
<p>The conditions are this:  The protagonist wishes to harm someone else,
<br>
just because they want to do it.  They aren't looking for the pleasure
<br>
of the experience, so a simulation would not satisfy the desire.  They
<br>
want to really harm someone.
<br>
<p>Also: the protagonist has very strong views about personal integrity.
<br>
He does not wish to be uploaded, drugged, plugged into anything.  He
<br>
just wants to be left in peace.  To hurt people.
<br>
<p>How can a more powerful entity (not a real sysop...) make this person
<br>
satisfied, without breaching his personal integrity?
<br>
<p>It's a tricky problem.
<br>
<p>(My &quot;solution&quot; is to use methods that the violent man doesn't see as
<br>
breaching integrity to try to convince him to change his motivations.
<br>
That is, working to maki him net-happy, but forcing some degree of
<br>
unhappy.  A story needs some resolution, dagnabbit.)
<br>
<p>-- Olie
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="15125.html">BillK: "Re: Singularity awareness"</a>
<li><strong>Previous message:</strong> <a href="15123.html">John K Clark: "Re: Two draft papers: AI and existential risk; heuristics and biases"</a>
<li><strong>In reply to:</strong> <a href="15114.html">John K Clark: "Re: Two draft papers: AI and existential risk; heuristics and biases"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15122.html">Ben Goertzel: "Re: Two draft papers: AI and existential risk; heuristics and biases"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15124">[ date ]</a>
<a href="index.html#15124">[ thread ]</a>
<a href="subject.html#15124">[ subject ]</a>
<a href="author.html#15124">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
