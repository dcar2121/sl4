<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Risks of distributed AI (was Re: Investing in FAI research: now vs. later)</title>
<meta name="Author" content="Matt Mahoney (matmahoney@yahoo.com)">
<meta name="Subject" content="Re: Risks of distributed AI (was Re: Investing in FAI research: now vs. later)">
<meta name="Date" content="2008-02-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Risks of distributed AI (was Re: Investing in FAI research: now vs. later)</h1>
<!-- received="Fri Feb 22 09:03:12 2008" -->
<!-- isoreceived="20080222160312" -->
<!-- sent="Fri, 22 Feb 2008 07:59:12 -0800 (PST)" -->
<!-- isosent="20080222155912" -->
<!-- name="Matt Mahoney" -->
<!-- email="matmahoney@yahoo.com" -->
<!-- subject="Re: Risks of distributed AI (was Re: Investing in FAI research: now vs. later)" -->
<!-- id="882884.5481.qm@web51911.mail.re2.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="eafe728f0802211805p20f9d306s706ff18abb634914@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Matt Mahoney (<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20Risks%20of%20distributed%20AI%20(was%20Re:%20Investing%20in%20FAI%20research:%20now%20vs.%20later)"><em>matmahoney@yahoo.com</em></a>)<br>
<strong>Date:</strong> Fri Feb 22 2008 - 08:59:12 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="17671.html">Rolf Nelson: "Re: Investing in FAI research: now vs. later"</a>
<li><strong>Previous message:</strong> <a href="17669.html">Daniel Burfoot: "Re: Risks of distributed AI (was Re: Investing in FAI research: now vs. later)"</a>
<li><strong>In reply to:</strong> <a href="17669.html">Daniel Burfoot: "Re: Risks of distributed AI (was Re: Investing in FAI research: now vs. later)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17665.html">Bryan Bishop: "Re: Investing in FAI research: now vs. later"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17670">[ date ]</a>
<a href="index.html#17670">[ thread ]</a>
<a href="subject.html#17670">[ subject ]</a>
<a href="author.html#17670">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- Daniel Burfoot &lt;<a href="mailto:daniel.burfoot@gmail.com?Subject=Re:%20Risks%20of%20distributed%20AI%20(was%20Re:%20Investing%20in%20FAI%20research:%20now%20vs.%20later)">daniel.burfoot@gmail.com</a>&gt; wrote:
<br>
<p><em>&gt; On Fri, Feb 22, 2008 at 2:30 AM, Matt Mahoney &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20Risks%20of%20distributed%20AI%20(was%20Re:%20Investing%20in%20FAI%20research:%20now%20vs.%20later)">matmahoney@yahoo.com</a>&gt; wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; I described one possible design in <a href="http://www.mattmahoney.net/agi.html">http://www.mattmahoney.net/agi.html</a> and
</em><br>
<em>&gt; &gt; did my thesis work to show that a very abstract model of this architecture
</em><br>
<em>&gt; &gt; is robust and scalable.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This is a nice idea - I hope you pursue it further.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; The idea that AI could fall into the &quot;wrong hands&quot; is like the Internet
</em><br>
<em>&gt; &gt; falling  into the wrong hands.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Consider the following scenario. A pseudo-AI capable of high performance
</em><br>
<em>&gt; computer vision understanding, speech recognition, and natural language
</em><br>
<em>&gt; comprehension is developed and made widely available (perhaps a descendant
</em><br>
<em>&gt; of PAQ).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Individuals with the semi-intelligent system can do all kinds of neat
</em><br>
<em>&gt; things. They can build robots to fetch them coffee. They can teach their
</em><br>
<em>&gt; cars how to drive. They can program face-recognition security systems that
</em><br>
<em>&gt; protect their houses from burglars.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The government can do all of these little tricks too. However, the
</em><br>
<em>&gt; government also has access to the following physical infrastructure:
</em><br>
<em>&gt; 1) visual surveillance systems in all public places
</em><br>
<em>&gt; 2) apparatus to monitor electronic communications across the globe
</em><br>
<em>&gt; 3) robotic soldiers
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It seems to me that:
</em><br>
<em>&gt; P(semi-intelligence) &lt;&lt; P(semi-intelligence + physical infrastructure)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; where P(..) is the &quot;power function&quot; - the amount of power/capability/utility
</em><br>
<em>&gt; that a technological system makes available to its controller.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; In our current system, there is a delicate balance of power between
</em><br>
<em>&gt; individuals and the state. Many people would argue that the balance is
</em><br>
<em>&gt; currently tilted too far towards the state. Regardless, the introduction of
</em><br>
<em>&gt; semi-intelligence would seem to dramatically upset the balance of power,
</em><br>
<em>&gt; even if it is made widely available, because of the way semi-intelligence
</em><br>
<em>&gt; interacts with the pre-existing physical infrastructure the government has.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; If you basically trust the government, then the above scenario shouldn't
</em><br>
<em>&gt; worry you too much. I do not trust the government. We have no foolproof way
</em><br>
<em>&gt; to guarantee that the reins of government power do not fall into the hands
</em><br>
<em>&gt; of evil men. Tyranny has plagued humanity since the beginning of
</em><br>
<em>&gt; civilization.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Dan
</em><br>
<em>&gt; 
</em><br>
<p>If you look at the different countries today you'll notice an inverse
<br>
correlation between technological advancement and government corruption.  An
<br>
infrastructure that allows free communication between people makes it harder
<br>
for government officials to keep secrets.  I did not design distributed AI
<br>
with a political agenda, but this is a system that would be implemented
<br>
worldwide, not controlled by any group, but by all its users, allowing
<br>
messages to go anywhere without restriction on content or who can send or
<br>
receive them.  The protocol requires that messages be associated only with the
<br>
sender's reply address, which can be temporary and anonymous.  Some
<br>
governments could see this as threatening and try to restrict it, but I think
<br>
they would lose the race for technological advancement in the same way they
<br>
would if they cut off internet and phone access.
<br>
<p>My bigger concern is that people are increasingly depending on computers to
<br>
deal with the complexity that computers help create.  When machines do
<br>
everything for us including think for us, our role in shaping the future is
<br>
diminished.  My design does not solve this problem.
<br>
<p><p>-- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20Risks%20of%20distributed%20AI%20(was%20Re:%20Investing%20in%20FAI%20research:%20now%20vs.%20later)">matmahoney@yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="17671.html">Rolf Nelson: "Re: Investing in FAI research: now vs. later"</a>
<li><strong>Previous message:</strong> <a href="17669.html">Daniel Burfoot: "Re: Risks of distributed AI (was Re: Investing in FAI research: now vs. later)"</a>
<li><strong>In reply to:</strong> <a href="17669.html">Daniel Burfoot: "Re: Risks of distributed AI (was Re: Investing in FAI research: now vs. later)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="17665.html">Bryan Bishop: "Re: Investing in FAI research: now vs. later"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#17670">[ date ]</a>
<a href="index.html#17670">[ thread ]</a>
<a href="subject.html#17670">[ subject ]</a>
<a href="author.html#17670">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:02 MDT
</em></small></p>
</body>
</html>
