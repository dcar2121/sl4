<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Revising a Friendly AI</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Revising a Friendly AI">
<meta name="Date" content="2000-12-12">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Revising a Friendly AI</h1>
<!-- received="Wed Dec 13 00:44:28 2000" -->
<!-- isoreceived="20001213074428" -->
<!-- sent="Wed, 13 Dec 2000 00:44:18 -0500" -->
<!-- isosent="20001213054418" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Revising a Friendly AI" -->
<!-- id="3A370CB2.D2E512F2@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="NDBBIBGFAPPPBODIPJMMOEKIEOAA.ben@intelligenesis.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Revising%20a%20Friendly%20AI"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Tue Dec 12 2000 - 22:44:18 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0384.html">Eliezer S. Yudkowsky: "Re: Diaspora, the future of AI &amp; value systems, etc."</a>
<li><strong>Previous message:</strong> <a href="0382.html">Ben Goertzel: "RE: Revising a Friendly AI"</a>
<li><strong>In reply to:</strong> <a href="0382.html">Ben Goertzel: "RE: Revising a Friendly AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0385.html">Ben Goertzel: "RE: Revising a Friendly AI"</a>
<li><strong>Reply:</strong> <a href="0385.html">Ben Goertzel: "RE: Revising a Friendly AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#383">[ date ]</a>
<a href="index.html#383">[ thread ]</a>
<a href="subject.html#383">[ subject ]</a>
<a href="author.html#383">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Goertzel wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; &gt; Do you really believe that you can alter someone's level of intelligence
</em><br>
<em>&gt; &gt; without altering the set of supergoals they tend to come up with?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Sometimes....  Surely, I know some very intelligent people whose supergoals
</em><br>
<em>&gt; are the same as those of much less intelligent people (Beer, T&amp;A, ...  ;)
</em><br>
<p>Well, I wanted to avoid bringing this up, since it does sometimes creep
<br>
people out, but I don't drink, do drugs, smoke, fight, have sex, overeat,
<br>
or gamble.
<br>
<p><em>&gt; &gt; And overriding evolution's supergoals with a verbally transferred
</em><br>
<em>&gt; &gt; supergoal (as your schema would seem to have it?) is an evolutionary
</em><br>
<em>&gt; &gt; advantage because?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Because culture can adapt faster than biological evolution, I suppose.
</em><br>
<p>There are two ways to look at this.
<br>
<p>One way is that it's an evolutionary advantage to have a *limited* supply
<br>
of mental energy that you can use to override immediate desires in favor
<br>
of long-term goals or to avoid long-term consequences.  (Actually, what we
<br>
have is not a quantitative supply per se, but a situation in which
<br>
expenditure of mental energy becomes increasingly painful, and
<br>
increasingly difficult, which makes it useful to use the quantitative
<br>
analogies of exhausting patience or replenishing energy.)
<br>
<p>Another way of looking at it is that all actual decisions, as in the ones
<br>
that eventually get sent to motor control, are made by verbal thoughts. 
<br>
Our emotions tie into our verbal thoughts through a complex interface that
<br>
lets them influence, but not control, these decisions.  I don't fully
<br>
understand the core of this interface, but I think that it ultimately
<br>
grounds in feelings of pleasure (or pain) reinforcing (or negatively
<br>
reinforcing) the thought-level reflexes that we build up in infancy.  In
<br>
the beginning, thoughts that cause pain, or thoughts that are projected to
<br>
lead to pain, are actually damped out on the neural level, and other
<br>
thoughts take their place.  Over time, the landscape of the mind is
<br>
dominated by thought sequences that don't cause pain, real or projected -
<br>
that dance around it.  This is who we are.  This is what a &quot;human being&quot;
<br>
is.  We are governed by what I call &quot;flinchback&quot;; the mental reflexes that
<br>
direct our minds away from certain thoughts, or rather, mental images. 
<br>
Our focus of attention shifts; a new thought is loaded in; we naturally
<br>
segue into thinking of a way to avoid, or minimize, the problem.
<br>
<p><em>&gt;From this perspective, the ability to do a verbal override is not
</em><br>
necessarily an evolutionary advantage.  It is an inevitable consequence of
<br>
our underlying cognitive architecture.  Our cognitive architecture is a
<br>
huge evolutionary advantage compared to nonconsciousness; thus, remaining
<br>
Neanderthal is not an option.  But, from the genes' perspectives, the
<br>
first conscious architecture that happened to arise, while crushing the
<br>
Neanderthals, has its own problems.  Such as allowing verbal overrides -
<br>
and therefore, memetic overrides - of the built-in desires.  This is a
<br>
&quot;problem&quot; from the perspective of the genes, anyway.
<br>
<p>The genes have probably been trying to seduce this system, but have not
<br>
yet succeeded in making it completely obedient, thank Ifni.  Larry Niven
<br>
and Jerry Pournelle, in &quot;The Mote in God's Eye&quot;, paint a chilling picture
<br>
of an alien race trapped by a cosmological bottleneck in its home system
<br>
for millions of years, long enough for genetic motives to leave a far
<br>
deeper footprint on the process of intelligence.
<br>
<p>As for the idea that instincts and emotions themselves become obsolete
<br>
fast enough for cultural replacement to be an advantage, I just don't see
<br>
it.  Maybe in the last ten thousand years, but that's not long enough to
<br>
make a difference.  It would have to make a REALLY HUGE difference to make
<br>
up for the increased vulnerability to all the anti-survival and
<br>
anti-reproductive memes floating around... though that, too, may be a
<br>
historically recent innovation.  But the actual emotions seem to be
<br>
hardware-supported and human-invariant, so cultural or parental
<br>
conditioning should have no influence whatever on the instincts you
<br>
sometimes label as supergoals (&quot;beer, T&amp;A&quot;) - though verbal thoughts and
<br>
experiences can certainly control how those chunks of hardware interface
<br>
with the rest of the mind.
<br>
<p>I regard none of this as a factor in my picture of how a mind *should*
<br>
work.
<br>
<p><pre>
--
	&quot;You have the power to compel me,&quot; echoed Archive back, flat.
	It was lying.
	It remembered the pain, but in the way something live'd remember the
weather.  Pain didn't matter to Archive.  No matter how much Archangel
hurt Archive, it wouldn't matter.  Ever.
	Archangel thought he could break Archive's will, but he was wrong.  A
Library doesn't have a will any more than a stardrive does.  It has a
what-it-does, not a will, and if you break it you don't have a Library
that will do what you want.  You have a broken chop-logic.
	
	-- Eluki bes Shahar, &quot;Archangel Blues&quot;, p. 127
--              --              --              --              -- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0384.html">Eliezer S. Yudkowsky: "Re: Diaspora, the future of AI &amp; value systems, etc."</a>
<li><strong>Previous message:</strong> <a href="0382.html">Ben Goertzel: "RE: Revising a Friendly AI"</a>
<li><strong>In reply to:</strong> <a href="0382.html">Ben Goertzel: "RE: Revising a Friendly AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0385.html">Ben Goertzel: "RE: Revising a Friendly AI"</a>
<li><strong>Reply:</strong> <a href="0385.html">Ben Goertzel: "RE: Revising a Friendly AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#383">[ date ]</a>
<a href="index.html#383">[ thread ]</a>
<a href="subject.html#383">[ subject ]</a>
<a href="author.html#383">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
