<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: When Subgoals Attack</title>
<meta name="Author" content="Gordon Worley (redbird@rbisland.cx)">
<meta name="Subject" content="Re: When Subgoals Attack">
<meta name="Date" content="2000-12-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: When Subgoals Attack</h1>
<!-- received="Wed Dec 13 15:05:09 2000" -->
<!-- isoreceived="20001213220509" -->
<!-- sent="Wed, 13 Dec 2000 14:45:17 -0500" -->
<!-- isosent="20001213194517" -->
<!-- name="Gordon Worley" -->
<!-- email="redbird@rbisland.cx" -->
<!-- subject="Re: When Subgoals Attack" -->
<!-- id="f05001900b65d77ddd650@[10.50.227.33]" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="durant-1001213102831.A03810675@sleeper" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Gordon Worley (<a href="mailto:redbird@rbisland.cx?Subject=Re:%20When%20Subgoals%20Attack"><em>redbird@rbisland.cx</em></a>)<br>
<strong>Date:</strong> Wed Dec 13 2000 - 12:45:17 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0392.html">Gordon Worley: "Re: When Subgoals Attack"</a>
<li><strong>Previous message:</strong> <a href="0390.html">Eliezer S. Yudkowsky: "Re: When Subgoals Attack"</a>
<li><strong>In reply to:</strong> <a href="0387.html">Durant Schoon: "When Subgoals Attack"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0397.html">Durant Schoon: "Re: When Subgoals Attack"</a>
<li><strong>Reply:</strong> <a href="0397.html">Durant Schoon: "Re: When Subgoals Attack"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#391">[ date ]</a>
<a href="index.html#391">[ thread ]</a>
<a href="subject.html#391">[ subject ]</a>
<a href="author.html#391">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
At 10:28 AM -0800 12/13/2000, Durant Schoon wrote:
<br>
<em>&gt;When Subgoals Attack
</em><br>
<em>&gt;--------------------
</em><br>
<p>See this FOX special presentation at 8 tonight from the creators of 
<br>
'When Nanobots Attack' and 'When Quantum Tunneling Attacks'.  :-)
<br>
<p><em>&gt;Observation: In modern human minds, these subgoals are often not
</em><br>
<em>&gt;              intelligent and do not constitute a sentience in and
</em><br>
<em>&gt;              of themselves. Thirst-&gt;drink-&gt;pick up glass of milk-&gt;...
</em><br>
<p>Off the top of my head, I can think of no basic goal of survival 
<br>
which forces sentience.  Humans could get along with out it, but 
<br>
knowing that they are alive probably makes it easier to survive 
<br>
better, since they care more about surviving if they know they could 
<br>
be in another state (i.e. dead).
<br>
<p><em>&gt;          So the problem is this: what would stop subgoals from
</em><br>
<em>&gt;          overthrowing supergoals. How might this happen? The subgoal
</em><br>
<em>&gt;          might determine that to satisfy the supergoal, a coup is
</em><br>
<em>&gt;          just the thing. Furthermore, the subgoal determines that to
</em><br>
<em>&gt;          successfully supplant the supergoal, the supergoal process
</em><br>
<em>&gt;          must not know that &quot;overthrow&quot; has become part the
</em><br>
<em>&gt;          subgoal's agenda. The subgoal might know or learn that its
</em><br>
<em>&gt;          results will influence the supergoal. The subgoal might
</em><br>
<em>&gt;          know of learn that it can influence other subgoals in
</em><br>
<em>&gt;          secret, so a conspiracy may form. Maybe not a lot of the
</em><br>
<em>&gt;          time, but maybe once every hundred billion years or so.
</em><br>
<p>I'm trying to think of a subgoal that would want to overthrow a 
<br>
supergoal, but am having a hard time.  Something like getting a glass 
<br>
of water overriding the goal of not killing other intelligences 
<br>
because they are worth more alive than dead is very unlikely to 
<br>
happen and only under *very* extreme circumstances.  This does not 
<br>
mean it can be discounted, since beings with transhuman and greater 
<br>
intelligences are much more dangerous than the average human, but for 
<br>
the time being this small problem can be overlooked.
<br>
<p>Let's take a page from Ayn Rand's objectivism and suppose that the 
<br>
supermost goal is selfishness.  Then, somewhere deep in the hierarchy 
<br>
of goals is an emotional urge for altruism, directly opposing the 
<br>
supermost goal.  Personally, I have heard some emotional stories that 
<br>
swell the altruism's power, but the supermost goal has been powerful 
<br>
enough to keep from getting displaced, even if I did temporarily get 
<br>
altruistic and give a few dollars to a charity that wasn't going to 
<br>
help me in any way.  Now that I think about it, the metagoal is 
<br>
survival, so altruism opposes the metagoal as well, since a 
<br>
completely altruistic being would give up vis life to feed others or 
<br>
do work for them or whatever.  So, as long as the subgoal opposes the 
<br>
metagoal, it cannot take over, and if it does, the intelligence has 
<br>
just signed vis own death warrant and doesn't stay around long enough 
<br>
to make other intelligences do the same thing.
<br>
<p><em>&gt;	    Many animals exhibit a kind of social hierarchy. Groups
</em><br>
<em>&gt;	    of weaker, well organized primates are known to
</em><br>
<em>&gt;	    overthrow the alpha male on occasion (I hope I'm getting
</em><br>
<em>&gt;	    this right, I don't have a reference). I'm wondering
</em><br>
<em>&gt;	    what precautions a superintelligence can take against
</em><br>
<em>&gt;	    this *ever* happening.
</em><br>
<p>If it happens in my Rand example, then the intelligence is dead and 
<br>
the problem is over.  Taken in a different light, though, this is 
<br>
like claiming that the citizens of a nation will die if the 
<br>
government is overthrown.  In North America, all 3 nations have 
<br>
overthrown their government in one way or another (Canada to least 
<br>
extent), yet all continue to exist.  The subgoals of the societies 
<br>
became more important than the supergoals of the state, so that state 
<br>
fell and was replaced.  The same would happen in your monkey example. 
<br>
Persnonally, though, I would like it better if the mindset of people 
<br>
changed and we had anarchy, but, from this discussion thus far, it 
<br>
seems that goals are top down, not bottom up, so the order of power 
<br>
is wrong to support an anarchy, and it would not be favorible to be 
<br>
controled by low level goals like contract leg muscles instead of 
<br>
high level ones like survive and be selfish.
<br>
<p><em>&gt;	   The follow up questions are: How stable are any of these
</em><br>
<em>&gt;	   situations? And can you ever really be 100% sure that an
</em><br>
<em>&gt;            overthrow never happens?
</em><br>
<p>An overthrow might not be bad, depending on what level it happens. 
<br>
Overthowing the metagoal would be bad, as would a supergoal like 
<br>
selfishness, but overthrowing a goal like pleasure in the interest of 
<br>
getting work done would probably be good.  Part of the complexity 
<br>
arises from the hierarchy of goals, and being a person who prefers 
<br>
anarchies, it is making my head hurt just to think about all these 
<br>
relationships.  Maybe there is nothing to overthrow, only goals which 
<br>
fit the metagoal less well than others.
<br>
<pre>
-- 
Gordon Worley
<a href="http://www.rbisland.cx/">http://www.rbisland.cx/</a>
mailto:<a href="mailto:redbird@rbisland.cx?Subject=Re:%20When%20Subgoals%20Attack">redbird@rbisland.cx</a>
PGP:  C462 FA84 B811 3501 9010  20D2 6EF3 77F7 BBD3 B003
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0392.html">Gordon Worley: "Re: When Subgoals Attack"</a>
<li><strong>Previous message:</strong> <a href="0390.html">Eliezer S. Yudkowsky: "Re: When Subgoals Attack"</a>
<li><strong>In reply to:</strong> <a href="0387.html">Durant Schoon: "When Subgoals Attack"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0397.html">Durant Schoon: "Re: When Subgoals Attack"</a>
<li><strong>Reply:</strong> <a href="0397.html">Durant Schoon: "Re: When Subgoals Attack"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#391">[ date ]</a>
<a href="index.html#391">[ thread ]</a>
<a href="subject.html#391">[ subject ]</a>
<a href="author.html#391">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
