<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Is generalisation a limit to intelligence?</title>
<meta name="Author" content="James Rogers (jamesr@best.com)">
<meta name="Subject" content="RE: Is generalisation a limit to intelligence?">
<meta name="Date" content="2000-12-03">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Is generalisation a limit to intelligence?</h1>
<!-- received="Mon Dec 04 01:08:47 2000" -->
<!-- isoreceived="20001204080847" -->
<!-- sent="Sun, 3 Dec 2000 19:09:16 -0800" -->
<!-- isosent="20001204030916" -->
<!-- name="James Rogers" -->
<!-- email="jamesr@best.com" -->
<!-- subject="RE: Is generalisation a limit to intelligence?" -->
<!-- id="00120319101600.06556@tachyon" -->
<!-- inreplyto="NDBBIBGFAPPPBODIPJMMOEAKEOAA.ben@intelligenesis.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Rogers (<a href="mailto:jamesr@best.com?Subject=RE:%20Is%20generalisation%20a%20limit%20to%20intelligence?"><em>jamesr@best.com</em></a>)<br>
<strong>Date:</strong> Sun Dec 03 2000 - 20:09:16 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0351.html">Ben Goertzel: "RE: Is generalisation a limit to intelligence?"</a>
<li><strong>Previous message:</strong> <a href="0349.html">Joaquim Almgren Gândara: "Re: Is generalisation a limit to intelligence?"</a>
<li><strong>In reply to:</strong> <a href="0347.html">Ben Goertzel: "RE: Is generalisation a limit to intelligence?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0351.html">Ben Goertzel: "RE: Is generalisation a limit to intelligence?"</a>
<li><strong>Reply:</strong> <a href="0351.html">Ben Goertzel: "RE: Is generalisation a limit to intelligence?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#350">[ date ]</a>
<a href="index.html#350">[ thread ]</a>
<a href="subject.html#350">[ subject ]</a>
<a href="author.html#350">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;&gt; Generally speaking, given a finite amount of memory and an
</em><br>
<em>&gt;&gt; arbitrarily long sequence of data (generated by any finite state machine
</em><br>
<em>&gt;&gt; no matter how complex), it is possible to attain the minimum possible
</em><br>
<em>&gt;&gt; predictive error rate using universal prediction schemes.
</em><br>
<em>&gt;
</em><br>
<em>&gt; However, this kind of &quot;in principle&quot; calculation is not very useful in practice,
</em><br>
<em>&gt; now is it?  only in very narrow domains, like text compression...
</em><br>
<p><p>Yes and no, depending on your assumptions.  I actually agree with
<br>
you to the extent that you really don't need to know exactly what
<br>
the minimum predictive error rate is as long as your algorithms
<br>
approach them reasonably quickly.  Most of the limits are
<br>
computational -- doable, but very expensive for unrestricted domains.
<br>
However, I wouldn't (and don't) try to apply these calculations to a
<br>
single complex domain (no need to rehash the same old problems of AI).
<br>
Rather I have algorithms that automatically and adaptively partition
<br>
domains (in a manner that preserves all heirarchical, associative,
<br>
etc. context) such that good prediction remains computationally
<br>
tractable for any given domain space without significantly impacting
<br>
prediction error rates for the complex virtual domain (query) that it
<br>
is currently operating on; in fact, the decision of a node to
<br>
partition itself is driven largely by recognizing when a domain has
<br>
become computationally inefficient in the sense that good results
<br>
require excessive CPU churn (itself a relatively complex algorithm).
<br>
It is really just a matter of getting around the computational
<br>
complexity of the core computation without significantly sacrificing
<br>
results.
<br>
<p>The better text compression algorithms, such as Lempel-Ziv and
<br>
arithmetic coding, actually are based on universal prediction schemes
<br>
(entropy and prediction being closely related), and are therefore
<br>
applicable to any sequence of data, not just text, though that is
<br>
where it is most commonly used. LZ is not actually an optimal
<br>
universal prediction scheme, but is an excellent universal predictor
<br>
for systems with very finite amounts of memory (frequently the
<br>
textbook example in fact). Optimal universal predictors asymptotically
<br>
approach theoretical error rates very quickly, but also tend to have
<br>
exponential memory consumption, giving rapidly diminishing returns.
<br>
Therefore, for many finite memory applications, non-optimal predictors
<br>
can actually produce better results in the given amount of resource
<br>
space even if they approach the theoretical minimum error rates much
<br>
more slowly.
<br>
<p>My own experience indicates that it doesn't really matter if you use
<br>
an optimal universal predictor.  However, there is a very broad
<br>
spectrum in performance for universal predictors such that if you
<br>
choose a poor one, it is likely to be essentially worthless for
<br>
real-world problem spaces.  A well-designed system with poor
<br>
prediction functions will appear to have poor intelligence during
<br>
your lifetime even though the prediction functions may converge enough
<br>
to give good performance at some time far in the future.
<br>
<p><p><em>&gt; Then, if the system has enough time to learn, EC (or more simply,
</em><br>
<em>&gt; Monte Carlo search over program space), will cause the system to
</em><br>
<em>&gt; arrive at a program that can achieve its goals optimally
</em><br>
<p><p>And I thought my methods were computationally expensive... :^)
<br>
<p><p><em>&gt; Since none of these conditions obtain, we need something much  more
</em><br>
<em>&gt; specialized and more complicated than EC inside our thinking
</em><br>
<em>&gt; machine...
</em><br>
<p><p>I'm not a big fan of EC as a means of generating a thinking machine.
<br>
Aside from the arguable inelegance of the result (depending on your
<br>
point of view), there necessarily must exist a large number of cleaner
<br>
and more efficient methods, though requiring more specialized
<br>
architecture.
<br>
<p><p><em>&gt;&gt; In short, it has been demonstrated that for any finite
</em><br>
<em>&gt;&gt; state machine, it is possible to ascertain the minimum possible
</em><br>
<em>&gt;&gt; predictive error rate for any data sequence given any finite amount
</em><br>
<em>&gt;&gt; of memory.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Yes, but this method will not perform adequately under the
</em><br>
<em>&gt; conditions under which a real intelligent systems have to operate.
</em><br>
<p><p>I would disagree; it depends on how you use it.
<br>
<p><p><em>&gt; The problem is that the prediction schemes that are &quot;optimal&quot; under
</em><br>
<em>&gt; standard mathematical assumptions, are NOT optimal given the
</em><br>
<em>&gt; real-world conditions under which organisms operate.
</em><br>
<p><p>Pretty much by definition, an &quot;optimal&quot; universal predictor is
<br>
impervious to real-world conditions, whatever those may be, hence the
<br>
term &quot;universal&quot;. The algorithms are model independent.  A truly
<br>
optimal predictor would of course require infinite memory. However, it
<br>
is possible to have universal predictors that are optimal for any
<br>
given resource configuration. Even &quot;good&quot; universal predictors will do
<br>
the job, they just take longer to converge.
<br>
<p><p><em>&gt; Yes, it answers the question under the glaringly false assumption
</em><br>
<em>&gt; that minds embody general optimal predictive schemes
</em><br>
<p><p>Optimality is not required for good predictive performance, it merely
<br>
sets the standard for how good the performance can get.
<br>
<p><p><em>&gt; These experiments certainly do not demonstrate that humans are
</em><br>
<em>&gt; finite-state machines. There are many  many other explanations for
</em><br>
<em>&gt; this data.  I won't bore you by reciting them.
</em><br>
<p><p>I never claimed that this was a proof.  The problem is that it can't
<br>
be disproved that the human mind is a finite-state machine. Humans
<br>
have a knack for getting mathematically classified as FS machines via
<br>
their information theoretic behavior.  It doesn't matter to me one way
<br>
of the other, it was merely an observation.
<br>
<p><p><em>&gt; Most of what makes real minds interesting is NOT about optimal
</em><br>
<em>&gt; prediction or modeling, but about pretty good ways of achieving
</em><br>
<em>&gt; pretty good intelligence within very limited space and time
</em><br>
<em>&gt; resources. This is a whole different story from information theory.
</em><br>
<p><p>Obviously my original post came across as incomplete (the hazards of
<br>
sending email at 2am), but I was talking about theoretical limits
<br>
of prediction for any finite amount of resources i.e. given a certain
<br>
amount of memory and processor, how accurately can a program predict
<br>
for any arbitrary model. That sounds a lot like predicting the limits
<br>
of intelligence in any finite resource space.
<br>
<p><p><em>&gt; For example, in the area of computational linguistics, Denis Yuret's
</em><br>
<em>&gt; excellent MIT PhD thesis from a few years back uses information
</em><br>
<em>&gt; theory to model language (&quot;lexical attraction&quot; he calls it).  All
</em><br>
<em>&gt; well and good.  It doesn't help you deal with the translation of
</em><br>
<em>&gt; language into meaning.  I think I know how to do the latter, but not
</em><br>
<em>&gt; using information theory explicitly....
</em><br>
<p><p>I have a small pile of links and papers on this topic that admittedly
<br>
I haven't read for the most part.  However, it was my understanding
<br>
that these language models offer the best context inference
<br>
performance of any other language analysis methodology to date, and by
<br>
a good margin. However, I don't really construe &quot;meaning&quot; to be much
<br>
different than &quot;context&quot;, which you may not.
<br>
<p>I should probably start reading these...
<br>
<p><p><em>&gt; I mean, how do you construct a mind given current computational
</em><br>
<em>&gt; resources and real-time learning constraints, inspired primarily by
</em><br>
<em>&gt; information theory?
</em><br>
<p><p>First of all, the architecture looks a lot like many other modern
<br>
architectures, but uses information theory to fill in some holes and
<br>
resolve some hard problems; information theory is not fundamental to
<br>
the architecture, only fundamental to the way some components of the
<br>
architecture behave.
<br>
<p>Scalability is a serious issue given current day hardware constraints,
<br>
but I've personally minimized that to the maximum extent possible. The
<br>
kernel layer, which effectively acts as an operating system for the
<br>
mind, is a highly scalable database kernel (borrowed from past
<br>
experience) that is both SMP and cluster optimized, but which has
<br>
been tuned and modified for this particular application. This supports
<br>
an arbitrarily large address space, transparent thread/process
<br>
migration over the network, full state recovery for both single-node
<br>
and total system failures, load management, and a bunch of other
<br>
features that are nice to have.  Standard stuff for the most part.
<br>
<p>At the application level, you have a multitude of &quot;agents&quot;, between
<br>
which are a complex network of associative and heirarchical
<br>
relationships.  Each agent is effectively a single domain (and quite a
<br>
bit more, being active, sometimes goal-oriented components).  Nothing
<br>
to special in this aspect.
<br>
<p>Under load, domains actively partition themselves into multiple
<br>
agents/domains in realtime to minimize theoretical prediction error
<br>
rates as a function of resource usage and few other things while still
<br>
maintaining informational integrity. This is probably the most
<br>
critical info theory driven feature and it saves a *lot* of clock
<br>
cycles while delivering superior results. Queries against the
<br>
entire system also require info theory derived algorithms and
<br>
mathematics, but I'll skip over that topic here.  In the
<br>
simplest case, you can start out with a single empty domain, start
<br>
shoving information into it, and then let the network build itself.
<br>
The resulting system, while containing everything fed to it will by
<br>
its nature extract all the context and information to within fairly
<br>
close to the theoretical limit, with some good weighting/noise
<br>
reduction thrown in. It isn't so important here, but how the data
<br>
organizes itself allows queries against the system to be computed
<br>
quickly and with a low predictive error rate that is pretty close
<br>
to the theoretical limits. Against a system that did not organize
<br>
itself in something closely approximating this manner, queries with a
<br>
similar predictive efficiency would become computationally
<br>
intractable.  How the domains actually partition is driven to a
<br>
certain extent by how the system is queried and used, as this can help
<br>
define certain types of computation efficiency. The primary benefit of
<br>
this kind of automatic and adaptive partitioning (other than keeping
<br>
the domain spaces clean and computationally efficient) is that it
<br>
allows the system to handle dirty and raucous data sources quickly and
<br>
gracefully without human intervention or serious system pollution. The
<br>
adaptive partitioning scheme was originally a noise reduction
<br>
algorithm I developed for data-mining purposes, but has proven to be
<br>
very versatile across a broad number of spaces (interestingly, it is
<br>
algorithmically similar to high-end noise reduction algorithms in
<br>
signal processing).
<br>
<p>I glossed over a lot, but as you can see, info theory largely governs
<br>
organizational behaviors to allow high predictive efficiency in a
<br>
computationally reasonable manner and to weed out garbage.  Other than
<br>
that, it mostly looks like yet another giant network of motivated
<br>
super-neurons, albeit optimized for silicon.
<br>
<p>Cheers,
<br>
<p>-James Rogers
<br>
&nbsp;<a href="mailto:jamesr@best.com?Subject=RE:%20Is%20generalisation%20a%20limit%20to%20intelligence?">jamesr@best.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0351.html">Ben Goertzel: "RE: Is generalisation a limit to intelligence?"</a>
<li><strong>Previous message:</strong> <a href="0349.html">Joaquim Almgren Gândara: "Re: Is generalisation a limit to intelligence?"</a>
<li><strong>In reply to:</strong> <a href="0347.html">Ben Goertzel: "RE: Is generalisation a limit to intelligence?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0351.html">Ben Goertzel: "RE: Is generalisation a limit to intelligence?"</a>
<li><strong>Reply:</strong> <a href="0351.html">Ben Goertzel: "RE: Is generalisation a limit to intelligence?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#350">[ date ]</a>
<a href="index.html#350">[ thread ]</a>
<a href="subject.html#350">[ subject ]</a>
<a href="author.html#350">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
