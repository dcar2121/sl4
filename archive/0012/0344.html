<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=Windows-1252">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Is generalisation a limit to intelligence?</title>
<meta name="Author" content="Ben Goertzel (ben@intelligenesis.net)">
<meta name="Subject" content="RE: Is generalisation a limit to intelligence?">
<meta name="Date" content="2000-12-02">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Is generalisation a limit to intelligence?</h1>
<!-- received="Sat Dec 02 21:41:39 2000" -->
<!-- isoreceived="20001203044139" -->
<!-- sent="Sat, 2 Dec 2000 21:31:40 -0500" -->
<!-- isosent="20001203023140" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@intelligenesis.net" -->
<!-- subject="RE: Is generalisation a limit to intelligence?" -->
<!-- id="NDBBIBGFAPPPBODIPJMMGEAFEOAA.ben@intelligenesis.net" -->
<!-- charset="Windows-1252" -->
<!-- inreplyto="000a01c05cb2$32d7a020$0300a8c0@sodom" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@intelligenesis.net?Subject=RE:%20Is%20generalisation%20a%20limit%20to%20intelligence?"><em>ben@intelligenesis.net</em></a>)<br>
<strong>Date:</strong> Sat Dec 02 2000 - 19:31:40 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0345.html">Eliezer S. Yudkowsky: "Re: Is generalisation a limit to intelligence?"</a>
<li><strong>Previous message:</strong> <a href="0343.html">Ben Goertzel: "RE: Is generalisation a limit to intelligence?"</a>
<li><strong>In reply to:</strong> <a href="0341.html">Joaquim Almgren Gândara: "Re: Is generalisation a limit to intelligence?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0349.html">Joaquim Almgren Gândara: "Re: Is generalisation a limit to intelligence?"</a>
<li><strong>Reply:</strong> <a href="0349.html">Joaquim Almgren Gândara: "Re: Is generalisation a limit to intelligence?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#344">[ date ]</a>
<a href="index.html#344">[ thread ]</a>
<a href="subject.html#344">[ subject ]</a>
<a href="author.html#344">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; &gt; But, the refutation: A sufficiently intelligent, self-aware system is
</em><br>
<em>&gt; &gt; quite capable of modifying itself to make itself MORE ERROR-PRONE if it
</em><br>
<em>&gt; &gt; finds through experimentation that this makes it more intelligent ;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Yes, but that isn't necessarily a solution. You might find that
</em><br>
<em>&gt; it will get
</em><br>
<em>&gt; stuck in a loop where it is at first too error-prone to realise that it's
</em><br>
<em>&gt; intelligent, and when it works out all the glitches it realises
</em><br>
<em>&gt; that it needs to
</em><br>
<em>&gt; be more error-prone, which brings it back to the beginning.
</em><br>
<p>Obviously, this only will happen with a system that is very bad at
<br>
self-optimization
<br>
while in its maximally intelligent mode
<br>
<p>It doesn't seem like a likely occurrence, though of course anything's
<br>
possible...
<br>
<p><em>&gt; &gt; What I mean is that even if there is a LOT of data, and it's
</em><br>
<em>&gt; highly varied,
</em><br>
<em>&gt; &gt; there is still a certain amount of overfitting that is inevitable.
</em><br>
<em>&gt;
</em><br>
<em>&gt; That can't be right. Take a single perceptron -- a very basic artificial
</em><br>
<em>&gt; neuron -- that classifies a set of points of types A and B,
</em><br>
<em>&gt; nearly linearly
</em><br>
<em>&gt; separable, in 2D space using a single line. With a lot of varied
</em><br>
<em>&gt; data in your
</em><br>
<em>&gt; training set, you can't get any overfitting using just a single neuron.
</em><br>
<em>&gt; Overfitting isn't inherent in all generalisations, it's just a
</em><br>
<em>&gt; result of having
</em><br>
<em>&gt; too sophisticated soft-/hardware to solve a certain problem. It's
</em><br>
<em>&gt; like trying
</em><br>
<em>&gt; too hard. The solution is just to not try at all or use minimal
</em><br>
<em>&gt; effort, in which
</em><br>
<em>&gt; case you'll have an acceptable generalisation.
</em><br>
<p>You're right, if the model you're fitting has very few free parameters
<br>
and the data is complex, you won't overfit.  My statement was confused.
<br>
<p>My statement only holds true for complex models and, as you point out,
<br>
complexity is relative to the data itself here.
<br>
<p>On the other hand, in all real intelligent systems I've worked with --
<br>
human or AI -- overfitting does occur.  There is ample psychological
<br>
research showing that humans tend to jump to conclusions too much compared
<br>
to what rationality would suggest.  And this is also the story of AI
<br>
in the financial domain.
<br>
<p>Ultimately one wants a model with as many free parameters as there are
<br>
&quot;implicit in the data.&quot;  But this is not always known, or even well-defined!
<br>
<p><em>&gt; &gt; On the other hand, the more memory you have, the more of this
</em><br>
<em>&gt; data you can
</em><br>
<em>&gt; &gt; keep in mind for use for new model-building rounds based on new
</em><br>
<em>&gt; data combined
</em><br>
<em>&gt; &gt; with the old.  So the maximum-memory system will achieve the
</em><br>
<em>&gt; minimum amount
</em><br>
<em>&gt; &gt; of possible overfitting given the data.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I can't grasp this either. It goes totally against my concept of
</em><br>
<em>&gt; overfitting. I
</em><br>
<em>&gt; always thought that the more sophisticated method of
</em><br>
<em>&gt; generalisation, the worse
</em><br>
<em>&gt; results for easy problems.
</em><br>
<p>This isn't really true.  The problem is with intermediate levels of
<br>
sophistication.
<br>
I don't think I was confused here.
<br>
<p>For example, in market prediction, one can assume a special boolean form for
<br>
trading
<br>
rules, in which case one has only a small number of rules to search through,
<br>
and overfitting
<br>
to one's data is not so likely.
<br>
<p>Or, one can assume trading rules are general boolean functions, in which
<br>
case it's possible to
<br>
overfit one's data very badly.  (Using this more sophisticated
<br>
generalization method.)
<br>
<p>On the other hand, if one searches over the space of general boolean
<br>
functions for trading rules,
<br>
and does this VERY WELL, according to a criterion that balances
<br>
profitability and simplicity,
<br>
then one can get rules that perform better out-of-sample, on average, than
<br>
the results of assuming
<br>
special simple forms.
<br>
<p>So in this case, which is a real-life example, sophisticated generalization
<br>
methods provide more
<br>
OPPORTUNITY for overfitting, but also provide the opportunity to avoid
<br>
overfitting by doing the
<br>
sophisticated analysis &quot;right&quot;
<br>
<p>ben
<br>
<p><p><em>&gt;Which is why I think it's a limit to
</em><br>
<em>&gt; intelligence.
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0345.html">Eliezer S. Yudkowsky: "Re: Is generalisation a limit to intelligence?"</a>
<li><strong>Previous message:</strong> <a href="0343.html">Ben Goertzel: "RE: Is generalisation a limit to intelligence?"</a>
<li><strong>In reply to:</strong> <a href="0341.html">Joaquim Almgren Gândara: "Re: Is generalisation a limit to intelligence?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0349.html">Joaquim Almgren Gândara: "Re: Is generalisation a limit to intelligence?"</a>
<li><strong>Reply:</strong> <a href="0349.html">Joaquim Almgren Gândara: "Re: Is generalisation a limit to intelligence?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#344">[ date ]</a>
<a href="index.html#344">[ thread ]</a>
<a href="subject.html#344">[ subject ]</a>
<a href="author.html#344">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
