<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Diaspora, the future of AI &amp; value systems, etc.</title>
<meta name="Author" content="Ben Goertzel (ben@webmind.com)">
<meta name="Subject" content="RE: Diaspora, the future of AI &amp; value systems, etc.">
<meta name="Date" content="2000-12-11">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Diaspora, the future of AI &amp; value systems, etc.</h1>
<!-- received="Mon Dec 11 16:30:49 2000" -->
<!-- isoreceived="20001211233049" -->
<!-- sent="Mon, 11 Dec 2000 16:26:48 -0500" -->
<!-- isosent="20001211212648" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@webmind.com" -->
<!-- subject="RE: Diaspora, the future of AI &amp; value systems, etc." -->
<!-- id="JBEPKOGDDIKKAHFPOEFIOEEGCDAA.ben@webmind.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="f05001902b65aee4f09c0@[10.50.227.43]" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@webmind.com?Subject=RE:%20Diaspora,%20the%20future%20of%20AI%20&amp;%20value%20systems,%20etc."><em>ben@webmind.com</em></a>)<br>
<strong>Date:</strong> Mon Dec 11 2000 - 14:26:48 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0372.html">Ben Goertzel: "RE: Diaspora, the future of AI &amp; value systems, etc."</a>
<li><strong>Previous message:</strong> <a href="0370.html">Eliezer S. Yudkowsky: "Re: Diaspora, the future of AI &amp; value systems, etc."</a>
<li><strong>In reply to:</strong> <a href="0369.html">Gordon Worley: "RE: Diaspora, the future of AI &amp; value systems, etc."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0379.html">Eliezer S. Yudkowsky: "Re: Diaspora, the future of AI &amp; value systems, etc."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#371">[ date ]</a>
<a href="index.html#371">[ thread ]</a>
<a href="subject.html#371">[ subject ]</a>
<a href="author.html#371">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
It seems that this conversation is doomed to get strangled by wording
<br>
issues...
<br>
<p>No, I didn't mean to literally say that conscience is an &quot;inner voice.&quot;
<br>
Having in fact &quot;heard
<br>
voices&quot; on a few occasions, I know the difference between that and
<br>
conscience.  It's just a
<br>
very common metaphorical expression.  Similarly, in case you were wondering,
<br>
&nbsp;when people refer to the &quot;the voice of the people,&quot; it's not referring to
<br>
some really bizarre collective
<br>
acoustic wave formation, it's just another metaphor.
<br>
<p>In order to avoid this kind of confusion, we could agree to communicate only
<br>
in formal mathematics,
<br>
but that does get kind of awkward after a while (and most mathematics isn't
<br>
as formal as people like
<br>
to think; see www.mizar.org for some truly formalized, unambiguous
<br>
mathematics...)
<br>
<p>Anyway, I don't feel like spending time arguing that conscience is a
<br>
widespread psychological
<br>
phenomenon among human beings....  This is sufficiently amply documented
<br>
that it's silly to argue about it.
<br>
<p>However, I have to take issue with the obvious silliness of the statement
<br>
that conscience may be just another
<br>
way of reasoning about possible consequences.
<br>
<p>Don't you see that reasoning, like all mathematics, is just a way of
<br>
transforming statements into
<br>
equivalent statements (with a greater or lesser degree of certitude, in the
<br>
case of probabilistic
<br>
reasoning)....  Reasoning doesn't give a system goals and motivations, it's
<br>
a method for figuring out
<br>
how to fulfill its goals and feelings, etc.  It can split goals into
<br>
subgoals, or merge them into
<br>
supergoals, but it must have something to begin with.
<br>
<p>Physical survival of the individual is the source of some of our human
<br>
goals.  Conscience is another --
<br>
we have the goal not to do what is &quot;culturally perceived as bad.&quot;  Maybe you
<br>
don't have this goal, or
<br>
maybe you do and just don't want to admit it ... but anyway, my point was
<br>
about humans in general, not
<br>
about super-evolved ubermenschen such as populate this list ;&gt;
<br>
<p>ben
<br>
<p><p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sysopmind.com?Subject=RE:%20Diaspora,%20the%20future%20of%20AI%20&amp;%20value%20systems,%20etc.">owner-sl4@sysopmind.com</a> [mailto:<a href="mailto:owner-sl4@sysopmind.com?Subject=RE:%20Diaspora,%20the%20future%20of%20AI%20&amp;%20value%20systems,%20etc.">owner-sl4@sysopmind.com</a>]On Behalf
</em><br>
<em>&gt; Of Gordon Worley
</em><br>
<em>&gt; Sent: Monday, December 11, 2000 4:09 PM
</em><br>
<em>&gt; To: <a href="mailto:sl4@sysopmind.com?Subject=RE:%20Diaspora,%20the%20future%20of%20AI%20&amp;%20value%20systems,%20etc.">sl4@sysopmind.com</a>
</em><br>
<em>&gt; Subject: RE: Diaspora, the future of AI &amp; value systems, etc.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; At 2:42 PM -0500 12/11/2000, Ben Goertzel wrote:
</em><br>
<em>&gt; &gt;Is it only because they're afraid of what will happen when
</em><br>
<em>&gt; they're caught?
</em><br>
<em>&gt;
</em><br>
<em>&gt; Yes.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;No, we have consciences, which are the &quot;internal voices of society.&quot;  The
</em><br>
<em>&gt; &gt;inner urge or will to
</em><br>
<em>&gt; &gt;kill the other person is counteracted by another inner
</em><br>
<em>&gt; voice/feeling telling
</em><br>
<em>&gt; &gt;you that it's
</em><br>
<em>&gt; &gt;bad to kill someone.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If I ever start hearing voices, I'm on my way to a doctor.  I think
</em><br>
<em>&gt; things through, consider the trade offs, and then make a decision.  I
</em><br>
<em>&gt; have never felt the urge to kill anyone, and doubt that I would
</em><br>
<em>&gt; unless there were a good reason to do it.  Even then I would only act
</em><br>
<em>&gt; on it after thinking about it.  It is not a matter of getting caught,
</em><br>
<em>&gt; but all consequences.  Maybe voices are just another way of looking
</em><br>
<em>&gt; at the reasoning process, whereby one considers the situation from
</em><br>
<em>&gt; different angles before arriving at a decision.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;The conscience is often viewed as an &quot;internal voice of one's
</em><br>
<em>&gt; parents.&quot;  An
</em><br>
<em>&gt; &gt;AI won't have any parents
</em><br>
<em>&gt; &gt;in the strict sense.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I'm not buying this conscience thing.  It is true that parents
</em><br>
<em>&gt; propagate memes to their children, and that children then use those
</em><br>
<em>&gt; memes when making decisions.  I don't, though, hear the voices of my
</em><br>
<em>&gt; parents in my head.  Just because an AI won't be born of anyone,
</em><br>
<em>&gt; doesn't mean that ve won't adopt memes of its creators.  The only
</em><br>
<em>&gt; difference between a natural child and an AI is that the AI doesn't
</em><br>
<em>&gt; have parents, but other means of getting memes.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;We are evolutionarily programmed to pass along values and morals
</em><br>
<em>&gt; or whatever
</em><br>
<em>&gt; &gt;you like to call them,
</em><br>
<em>&gt; &gt;to our children.  I.e., our genes cause us to propagate certain memes.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I would rather think that it is a meme that makes us propagate memes,
</em><br>
<em>&gt; since otherwise we might try to propagate memes, even if we have none.
</em><br>
<em>&gt;
</em><br>
<em>&gt; --
</em><br>
<em>&gt; Gordon Worley
</em><br>
<em>&gt; <a href="http://www.rbisland.cx/">http://www.rbisland.cx/</a>
</em><br>
<em>&gt; mailto:<a href="mailto:redbird@rbisland.cx?Subject=RE:%20Diaspora,%20the%20future%20of%20AI%20&amp;%20value%20systems,%20etc.">redbird@rbisland.cx</a>
</em><br>
<em>&gt; PGP:  C462 FA84 B811 3501 9010  20D2 6EF3 77F7 BBD3 B003
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0372.html">Ben Goertzel: "RE: Diaspora, the future of AI &amp; value systems, etc."</a>
<li><strong>Previous message:</strong> <a href="0370.html">Eliezer S. Yudkowsky: "Re: Diaspora, the future of AI &amp; value systems, etc."</a>
<li><strong>In reply to:</strong> <a href="0369.html">Gordon Worley: "RE: Diaspora, the future of AI &amp; value systems, etc."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0379.html">Eliezer S. Yudkowsky: "Re: Diaspora, the future of AI &amp; value systems, etc."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#371">[ date ]</a>
<a href="index.html#371">[ thread ]</a>
<a href="subject.html#371">[ subject ]</a>
<a href="author.html#371">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
