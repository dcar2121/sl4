<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html</title>
<meta name="Author" content="Vladimir Nesov (robotact@gmail.com)">
<meta name="Subject" content="Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html">
<meta name="Date" content="2008-06-03">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html</h1>
<!-- received="Tue Jun  3 08:55:43 2008" -->
<!-- isoreceived="20080603145543" -->
<!-- sent="Tue, 3 Jun 2008 18:53:27 +0400" -->
<!-- isosent="20080603145327" -->
<!-- name="Vladimir Nesov" -->
<!-- email="robotact@gmail.com" -->
<!-- subject="Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html" -->
<!-- id="b54769d90806030753i6578e1b5s2e3d66f09d291ef@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="68F5968F-43EB-4310-AF6B-6216173E2420@randallsquared.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Vladimir Nesov (<a href="mailto:robotact@gmail.com?Subject=Re:%20AI%20Boxing:%20http://www.sl4.org/archive/0207/4977.html"><em>robotact@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Jun 03 2008 - 08:53:27 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="18908.html">Vladimir Nesov: "Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html"</a>
<li><strong>Previous message:</strong> <a href="18906.html">John K Clark: "More silly but friendly ideas (was: AI Boxing)"</a>
<li><strong>In reply to:</strong> <a href="18905.html">Randall Randall: "Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18909.html">Byrne Hobart: "Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18907">[ date ]</a>
<a href="index.html#18907">[ thread ]</a>
<a href="subject.html#18907">[ subject ]</a>
<a href="author.html#18907">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Tue, Jun 3, 2008 at 6:00 PM, Randall Randall
<br>
&lt;<a href="mailto:randall@randallsquared.com?Subject=Re:%20AI%20Boxing:%20http://www.sl4.org/archive/0207/4977.html">randall@randallsquared.com</a>&gt; wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; The assertion that there is no such combination of words is equivalent
</em><br>
<em>&gt; to the assertion that the human brain is perfectly secure.  Given that
</em><br>
<em>&gt; more complex systems have more vulnerabilities (all else equal) and
</em><br>
<em>&gt; that brains were evolved rather than designed, it seems to me to be
</em><br>
<em>&gt; wildly implausible that there are no possible exploits for the brain.
</em><br>
<em>&gt;
</em><br>
<em>&gt; It would not surprise me to learn that there were exploits which
</em><br>
<em>&gt; required only seconds to perform verbally.  It would, however,
</em><br>
<em>&gt; surprise me to learn that Eliezer had discovered one; the space of
</em><br>
<em>&gt; possibilities is large, and there's no reason to think that a human
</em><br>
<em>&gt; could reason their way to such a thing.
</em><br>
<em>&gt;
</em><br>
<p>Without quantitative assessment, there is no reason to think that
<br>
superintelligent AI in the box will be able to execute such exploit
<br>
and hope to win. Even if there is an exploit, there are two obvious
<br>
prerequisites to applying it: (1) detailed knowledge about the state
<br>
of gatekeeper's brain and environment, and (2) availability of action
<br>
that will achieve required effect with high probability. Extraordinary
<br>
beliefs require extraordinary evidence. If AI has a plan of breaking
<br>
out, it is reasonably sure that the plan will work. And to be sure, it
<br>
must obtain enough information about why it will work, which may be
<br>
unavailable. This information can't magically appear in its mind
<br>
without there being adequate sensors and actuators. In out case, we
<br>
have extensive information about humans-in-general (presumably from AI
<br>
studying Internet dump), and little text-only information about
<br>
gatekeeper and likewise limited method of acting on him. The problem
<br>
with AI is that it will presumably be much more efficient at
<br>
extracting knowledge from evidence, but still it can't overcome
<br>
fundamental information-theoretic limits which in this case may as
<br>
well limit its ability to influence gatekeeper.
<br>
<p><pre>
-- 
Vladimir Nesov
<a href="mailto:robotact@gmail.com?Subject=Re:%20AI%20Boxing:%20http://www.sl4.org/archive/0207/4977.html">robotact@gmail.com</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="18908.html">Vladimir Nesov: "Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html"</a>
<li><strong>Previous message:</strong> <a href="18906.html">John K Clark: "More silly but friendly ideas (was: AI Boxing)"</a>
<li><strong>In reply to:</strong> <a href="18905.html">Randall Randall: "Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18909.html">Byrne Hobart: "Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18907">[ date ]</a>
<a href="index.html#18907">[ thread ]</a>
<a href="subject.html#18907">[ subject ]</a>
<a href="author.html#18907">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
