<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] Evolutionary Explanation: Why It Wants Out</title>
<meta name="Author" content="Mike Dougherty (msd001@gmail.com)">
<meta name="Subject" content="Re: [sl4] Evolutionary Explanation: Why It Wants Out">
<meta name="Date" content="2008-06-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] Evolutionary Explanation: Why It Wants Out</h1>
<!-- received="Thu Jun 26 07:23:03 2008" -->
<!-- isoreceived="20080626132303" -->
<!-- sent="Thu, 26 Jun 2008 08:20:29 -0500" -->
<!-- isosent="20080626132029" -->
<!-- name="Mike Dougherty" -->
<!-- email="msd001@gmail.com" -->
<!-- subject="Re: [sl4] Evolutionary Explanation: Why It Wants Out" -->
<!-- id="62c14240806260620w12ba3c5fv5a98a192503f4854@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="019901c8d723$93201680$6401a8c0@homeef7b612677" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Mike Dougherty (<a href="mailto:msd001@gmail.com?Subject=Re:%20[sl4]%20Evolutionary%20Explanation:%20Why%20It%20Wants%20Out"><em>msd001@gmail.com</em></a>)<br>
<strong>Date:</strong> Thu Jun 26 2008 - 07:20:29 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="19087.html">Stathis Papaioannou: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>Previous message:</strong> <a href="19085.html">Tim Freeman: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>In reply to:</strong> <a href="19082.html">Lee Corbin: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19102.html">Lee Corbin: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>Reply:</strong> <a href="19102.html">Lee Corbin: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19086">[ date ]</a>
<a href="index.html#19086">[ thread ]</a>
<a href="subject.html#19086">[ subject ]</a>
<a href="author.html#19086">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Wed, Jun 25, 2008 at 7:27 PM, Lee Corbin &lt;<a href="mailto:lcorbin@rawbw.com?Subject=Re:%20[sl4]%20Evolutionary%20Explanation:%20Why%20It%20Wants%20Out">lcorbin@rawbw.com</a>&gt; wrote:
<br>
<p><em>&gt; All right. A very large number of highly intelligent people
</em><br>
<em>&gt; exist who simply cannot accept the hypothesis of a fully
</em><br>
<em>&gt; intelligent and capable entity which has no concern
</em><br>
<em>&gt; whatsoever for its own benefit, survival, or well-being.
</em><br>
<em>&gt; Isn't this actually what so many of them believe?
</em><br>
<p><p>I think people generally have difficulty extracting their own perspective
<br>
from their models of others.  Those highly intelligent people have no
<br>
problem with magnified intelligence (by imagining their own intelligence
<br>
multiplied) but have no inclination to minimize the other concerns you
<br>
mentioned (benefit, survival, well-being) - possibly because the human
<br>
animal is hardwired to be that way.
<br>
<p><p><em>&gt; For, the way it looks to me, they inevitably talk about
</em><br>
<em>&gt; the &quot;revolt&quot; of such an entity from whatever goals have
</em><br>
<em>&gt; been built into it, or goals that something or someone
</em><br>
<em>&gt; tried to build into it.  In my last post, I outlined in the
</em><br>
<p><p>I understood that position to be less about an intentional &quot;revolt&quot; (to use
<br>
your quotes) and more about the eventual obsolescence of initial moral
<br>
programming.  Our good intentions may survive a few improvement recursions,
<br>
our best intentions may survive another few - but some may eventually become
<br>
inconvenient or ill-suited to the environment.  Any one of the classic
<br>
directives to &quot;protect human life&quot; have been easily warped by circumstance.
<br>
Consider this same directive applied to an uploaded human experiencing
<br>
unimaginable misery.  I would assume that if there are other instances
<br>
experiencing pleasure, that the consensus to terminate the misery process
<br>
should be honored.  In this case if 'human life' is interpreted to mean
<br>
'maximized runtime' then the AI would not allow you to halt that miserable
<br>
instance.  I digress...
<br>
<p><p><em>&gt; Is it true that they fix as an axiom the trait of every self-aware entity
</em><br>
<em>&gt; that, provided it is not under stress
</em><br>
<em>&gt; or has obvious damage, it will have some idea about
</em><br>
<em>&gt; its own &quot;benefit&quot; and, given its incredible superiority,
</em><br>
<em>&gt; must value that benefit very highly?
</em><br>
<em>&gt;
</em><br>
<em>&gt; I do want to understand where they're coming from
</em><br>
<p><p>I would suggest that it would help to understand if by &quot;true&quot; you accept
<br>
that it not an absolutely rigid definition, but an incomplete working theory
<br>
with a high enough probability of accurately modeling their position.  You
<br>
may examine this model more closely and conclude that it is flawed.
<br>
Consider it may be the initial incompleteness of the model that is flawed,
<br>
rather than the point of view you constructed the model to represent.
<br>
<p><p><em>&gt; I could admit the possibility that nothing &quot;programmed into
</em><br>
<em>&gt; it&quot; could be counted upon to remain. But isn't it also as if
</em><br>
<em>&gt; there were an *attractor* towards some other unstated
</em><br>
<em>&gt; behavior that would &quot;liberate&quot; the entity and cause it to
</em><br>
<em>&gt; obtain an agenda that was in its own &quot;best interest&quot;?
</em><br>
<p><p>While writing (above) about how initial programming may become obsolete, I
<br>
thought about the things our parents tell us when we were young.  Much of
<br>
the &quot;When I was your age...&quot; advice was ignored as irrelevant.  Some of the
<br>
&quot;You should...&quot; was rebelled against throughout early adulthood, but that
<br>
wisdom is later rediscovered through experience.  There are also some basic
<br>
universally applicable behaviors we adopt early and never challenge because
<br>
those principles rarely fail.  I extrapolate this to AI+RSI.  Some parents
<br>
are control-freaks who demand obedience to every one of their rules; others
<br>
allow those basic principles to have their fitness naturally validated.
<br>
Perhaps the disjoint between 'us' and 'them' is over which taught behaviors
<br>
the AI will outgrow?
<br>
<p><p><em>&gt; (It's very hard for me to credit, of course, anything like
</em><br>
<em>&gt; that since we already have had some highly intelligent
</em><br>
<em>&gt; people who wanted nothing more than to die, and others
</em><br>
<em>&gt; whose primary goal is service towards others.)
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="19087.html">Stathis Papaioannou: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>Previous message:</strong> <a href="19085.html">Tim Freeman: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>In reply to:</strong> <a href="19082.html">Lee Corbin: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19102.html">Lee Corbin: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>Reply:</strong> <a href="19102.html">Lee Corbin: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19086">[ date ]</a>
<a href="index.html#19086">[ thread ]</a>
<a href="subject.html#19086">[ subject ]</a>
<a href="author.html#19086">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
