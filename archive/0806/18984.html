<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Paper: Artificial Intelligence will Kill our Grandchildren</title>
<meta name="Author" content="Thomas McCabe (pphysics141@gmail.com)">
<meta name="Subject" content="Re: Paper: Artificial Intelligence will Kill our Grandchildren">
<meta name="Date" content="2008-06-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Paper: Artificial Intelligence will Kill our Grandchildren</h1>
<!-- received="Fri Jun 13 21:19:05 2008" -->
<!-- isoreceived="20080614031905" -->
<!-- sent="Fri, 13 Jun 2008 23:16:27 -0400" -->
<!-- isosent="20080614031627" -->
<!-- name="Thomas McCabe" -->
<!-- email="pphysics141@gmail.com" -->
<!-- subject="Re: Paper: Artificial Intelligence will Kill our Grandchildren" -->
<!-- id="b7a9e8680806132016u144474a6oefd25a661c12fe36@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="7.0.1.0.2.20080614115641.051075b0@SpreadsheetDetective.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas McCabe (<a href="mailto:pphysics141@gmail.com?Subject=Re:%20Paper:%20Artificial%20Intelligence%20will%20Kill%20our%20Grandchildren"><em>pphysics141@gmail.com</em></a>)<br>
<strong>Date:</strong> Fri Jun 13 2008 - 21:16:27 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="18985.html">Giu1i0 Pri5c0: "Silvermoon Meeting: Launch of the Order of Cosmic Engineers in World of Warcraft"</a>
<li><strong>Previous message:</strong> <a href="18983.html">Stathis Papaioannou: "Re: More silly but friendly ideas"</a>
<li><strong>In reply to:</strong> <a href="18982.html">Anthony Berglas: "Paper: Artificial Intelligence will Kill our Grandchildren"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18986.html">Vladimir Nesov: "Re: Paper: Artificial Intelligence will Kill our Grandchildren"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18984">[ date ]</a>
<a href="index.html#18984">[ thread ]</a>
<a href="subject.html#18984">[ subject ]</a>
<a href="author.html#18984">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Fri, Jun 13, 2008 at 10:11 PM, Anthony Berglas &lt;<a href="mailto:anthony@berglas.org?Subject=Re:%20Paper:%20Artificial%20Intelligence%20will%20Kill%20our%20Grandchildren">anthony@berglas.org</a>&gt; wrote:
<br>
<em>&gt; Having scanned the literature, I decided to write a paper on the dangers of
</em><br>
<em>&gt; intelligence.  I have tried to keep it short, sharp and very focused.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I took the trouble to write it because I could not find any other paper that
</em><br>
<em>&gt; put it all together succinctly without philosophical, technical, egotistical
</em><br>
<em>&gt; and other distractions.  There are a few ideas in it that I have not seen in
</em><br>
<em>&gt; Singularity community such as DNA size and brain size/speech understanding.
</em><br>
<em>&gt;  But the main purpose of the paper is to be succinct and convincing.
</em><br>
<em>&gt;
</em><br>
<em>&gt; It mainly addresses issues raised in discussions with &quot;ordinary&quot; people and
</em><br>
<em>&gt; software engineers -- that is the target audience.   In particular,
</em><br>
<em>&gt; &quot;computers obviously can never be intelligent&quot;.  &quot;They would just do what we
</em><br>
<em>&gt; tell them&quot;.  &quot;They would be just like us but smarter&quot;.  And &quot;but what about
</em><br>
<em>&gt; global warming, biotechnology, nanotechnology and other distractions&quot;.
</em><br>
<em>&gt;
</em><br>
<em>&gt; So all comments most welcome, especially as to what the paper does not need
</em><br>
<em>&gt; to say.
</em><br>
<em>&gt;
</em><br>
<em>&gt; <a href="http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html">http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html</a>
</em><br>
<em>&gt;
</em><br>
<em>&gt; Anthony
</em><br>
<em>&gt;
</em><br>
<em>&gt; Dr Anthony Berglas, <a href="mailto:anthony@berglas.org?Subject=Re:%20Paper:%20Artificial%20Intelligence%20will%20Kill%20our%20Grandchildren">anthony@berglas.org</a>       Mobile: +61 4 4838 8874
</em><br>
<em>&gt; Just because it is possible to push twigs along the ground with ones nose
</em><br>
<em>&gt; does not necessarily mean that is the best way to collect firewood.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<p>With reference to this excerpt:
<br>
<p>&quot;What is certain is that an intelligence that was good at world
<br>
domination would be good at world domination.   So if there were a
<br>
large number artificial intelligences, and just one of them wanted to
<br>
and was capable of dominating the world, then it would.  That is just
<br>
Darwin's evolution taken to the next level.  The pen is mightier than
<br>
the sword, and the best intelligence has the best pen.  It is also
<br>
difficult to see why an AI would want humans around competing for
<br>
resources and threatening the planet.&quot;
<br>
<p>You don't explain where the AI gets the motive for world domination.
<br>
See <a href="http://intelligence.org/upload/futuresalon.pdf">http://intelligence.org/upload/futuresalon.pdf</a>.
<br>
<p>&quot;For evolution consumes all that is good and noble in mankind and
<br>
reduces it to base impulses that have simply been found to be
<br>
effective for breeding children.&quot;
<br>
<p>All of our impulses were generated by evolution, not just the bad
<br>
ones. Altruism is a result of evolution, just as much as the urge to
<br>
reproduce is. See
<br>
<a href="http://www.overcomingbias.com/2007/11/adaptation-exec.html">http://www.overcomingbias.com/2007/11/adaptation-exec.html</a>,
<br>
<a href="http://www.overcomingbias.com/2007/11/evolutionary-ps.html">http://www.overcomingbias.com/2007/11/evolutionary-ps.html</a>,
<br>
<a href="http://www.overcomingbias.com/2007/11/thou-art-godsha.html">http://www.overcomingbias.com/2007/11/thou-art-godsha.html</a>.
<br>
<p>&quot;We maintain an illusion of immortality because we need to live to
<br>
breed, and our thirst for knowledge helps provide us with material
<br>
resources to do that. &quot;
<br>
<p>You're confusing the goals of evolution with the desires of evolved
<br>
organisms. We *know* that it's an evolutionary advantage for everyone
<br>
to not simply pump out kids as fast as possible. Indeed, we've had
<br>
cultures where anyone who was caught not pumping out kids was stoned
<br>
to death, and even in the presence of this extreme selection pressure,
<br>
some people resume not pumping out kids a few generations after the
<br>
pressure is gone.
<br>
<p>&quot;And we seek explanations for death and the unknowable, and invent God.&quot;
<br>
<p>We invented God (er, well, not the modern God, but the idea of a
<br>
divine being) over ten thousand years ago, comfortably predating
<br>
modern communication and contraception.
<br>
<p>&quot;After all, 10 mega hertz/1 mega byte is about the power computers had
<br>
in 1990, and those computers were very functional.&quot;
<br>
<p>It isn't really important, but this isn't accurate. The Intel 286
<br>
(introduced 1982) could address 16 MB of RAM and was later clocked up
<br>
to around 25 MHz. These enhancements were, admittedly, expensive and
<br>
unwieldy, so they weren't generally used by the mass market.
<br>
<p>&quot;The force of evolution is just too strong.&quot;
<br>
<p>There is no evolution without reproduction over large numbers of
<br>
successive generations. See
<br>
<a href="http://www.overcomingbias.com/2007/11/no-evolution-fo.html">http://www.overcomingbias.com/2007/11/no-evolution-fo.html</a>.
<br>
<p><pre>
-- 
 - Tom
<a href="http://www.acceleratingfuture.com/tom">http://www.acceleratingfuture.com/tom</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="18985.html">Giu1i0 Pri5c0: "Silvermoon Meeting: Launch of the Order of Cosmic Engineers in World of Warcraft"</a>
<li><strong>Previous message:</strong> <a href="18983.html">Stathis Papaioannou: "Re: More silly but friendly ideas"</a>
<li><strong>In reply to:</strong> <a href="18982.html">Anthony Berglas: "Paper: Artificial Intelligence will Kill our Grandchildren"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18986.html">Vladimir Nesov: "Re: Paper: Artificial Intelligence will Kill our Grandchildren"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18984">[ date ]</a>
<a href="index.html#18984">[ thread ]</a>
<a href="subject.html#18984">[ subject ]</a>
<a href="author.html#18984">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
