<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] Re: More silly but friendly ideas</title>
<meta name="Author" content="Stuart Armstrong (dragondreaming@googlemail.com)">
<meta name="Subject" content="Re: [sl4] Re: More silly but friendly ideas">
<meta name="Date" content="2008-06-25">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] Re: More silly but friendly ideas</h1>
<!-- received="Wed Jun 25 02:55:43 2008" -->
<!-- isoreceived="20080625085543" -->
<!-- sent="Wed, 25 Jun 2008 10:52:52 +0200" -->
<!-- isosent="20080625085252" -->
<!-- name="Stuart Armstrong" -->
<!-- email="dragondreaming@googlemail.com" -->
<!-- subject="Re: [sl4] Re: More silly but friendly ideas" -->
<!-- id="38f493f10806250152r1f013cem67d657e469d8a920@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="200806242244.04379.kanzure@gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Stuart Armstrong (<a href="mailto:dragondreaming@googlemail.com?Subject=Re:%20[sl4]%20Re:%20More%20silly%20but%20friendly%20ideas"><em>dragondreaming@googlemail.com</em></a>)<br>
<strong>Date:</strong> Wed Jun 25 2008 - 02:52:52 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="19071.html">Stuart Armstrong: "Re: [sl4] Re: Signaling after a singularity"</a>
<li><strong>Previous message:</strong> <a href="19069.html">Bryan Bishop: "[sl4] [Hplusroadmap] [SL4] Re: Paper: Artificial Intelligence will Kill our Grandchildren"</a>
<li><strong>In reply to:</strong> <a href="19065.html">Bryan Bishop: "[sl4] Re: More silly but friendly ideas"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19076.html">Bryan Bishop: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Reply:</strong> <a href="19076.html">Bryan Bishop: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Reply:</strong> <a href="19078.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19070">[ date ]</a>
<a href="index.html#19070">[ thread ]</a>
<a href="subject.html#19070">[ subject ]</a>
<a href="author.html#19070">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;&gt; Well, yes. The options seem to be
</em><br>
<em>&gt;&gt; 1) A slave AI.
</em><br>
<em>&gt;&gt; 2) No AI.
</em><br>
<em>&gt;&gt; 3) The extinction of humanity by a non-friendly AI.
</em><br>
<em>&gt;
</em><br>
<em>&gt; #3 is bullshit. Just escape the situation. Yes, change sucks. Yes,
</em><br>
<em>&gt; there's the Vingean ai that chases after you, but not running just
</em><br>
<em>&gt; because it might eventually catch you is kind of stupid. Kind of
</em><br>
<em>&gt; deadly.
</em><br>
<p>Are you saying that we shouldn't worry about starting a nuclear war,
<br>
because we can try and run away from the blasts?
<br>
<p><em>&gt;&gt; Since &quot;no AI&quot; doesn't seem politically viable, the slave AI is the
</em><br>
<em>&gt;&gt; way to go.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Way to go for what? Are you thinking that ai is something that can only
</em><br>
<em>&gt; appear once on the planet here? That's completely absurd. Look at the
</em><br>
<em>&gt; trillions of organisms (ignore the silly single-ancestor hypotheses).
</em><br>
<p>I refer to Eliezer's papers, and various others that argue that a high
<br>
level AI will so dominate the planet that other AI's will only come
<br>
into existence with its consent. You can argue that they are wrong;
<br>
but if you want to do that, do that. The idea is not intrinsically
<br>
absurd; and if the speed of inteligence increase, as well as the
<br>
return on intelligence, is what they claim it is, then the idea is
<br>
true.
<br>
<p><em>&gt;&gt; Of course there may be grey areas beyond those three posibilities -
</em><br>
<em>&gt;&gt; but hideously smart and knowledgeable people argue that there are no
</em><br>
<em>&gt;&gt; such grey areas. Even if there are, a non-lethal AI would be much
</em><br>
<em>&gt;&gt; closer to &quot;slave&quot; than &quot;non-friendly&quot;.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Are they then hideously smart?
</em><br>
<p>Yes.
<br>
<p><em>&gt;&gt; &gt; To hell with this goal crap. Nothing that even approaches
</em><br>
<em>&gt;&gt; &gt; intelligence has ever been observed to operate according to a rigid
</em><br>
<em>&gt;&gt; &gt; goal hierocracy, and there are excellent reasons from pure
</em><br>
<em>&gt;&gt; &gt; mathematics for thinking the idea is inherently ridiculous.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Ah! Can you tell me these? (don't worry about the level of the
</em><br>
<em>&gt;&gt; conversation, I'm a mathematician). I'm asking seriously; any
</em><br>
<em>&gt;&gt; application of maths to the AI problem is fascinating to me.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Have you seen the name Bayes thrown around here yet?
</em><br>
<p>Yes, I've seen it thrown around a lot. The name &quot;Bayes&quot; that is; the
<br>
mathematics of it never seem to darken this list at all. Can you
<br>
explain how a method for updating probability estimates based on
<br>
observations is incompatible with a rigid goal structure?
<br>
<p>And unless you are quoting current cutting edge research in the area,
<br>
my level of knowledge is enough to understand all the maths, so don't
<br>
hold back!
<br>
<p>Stuart
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="19071.html">Stuart Armstrong: "Re: [sl4] Re: Signaling after a singularity"</a>
<li><strong>Previous message:</strong> <a href="19069.html">Bryan Bishop: "[sl4] [Hplusroadmap] [SL4] Re: Paper: Artificial Intelligence will Kill our Grandchildren"</a>
<li><strong>In reply to:</strong> <a href="19065.html">Bryan Bishop: "[sl4] Re: More silly but friendly ideas"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19076.html">Bryan Bishop: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Reply:</strong> <a href="19076.html">Bryan Bishop: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Reply:</strong> <a href="19078.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19070">[ date ]</a>
<a href="index.html#19070">[ thread ]</a>
<a href="subject.html#19070">[ subject ]</a>
<a href="author.html#19070">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
