<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: [sl4] Evolutionary Explanation: Why It Wants Out</title>
<meta name="Author" content="Lee Corbin (lcorbin@rawbw.com)">
<meta name="Subject" content="[sl4] Evolutionary Explanation: Why It Wants Out">
<meta name="Date" content="2008-06-25">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>[sl4] Evolutionary Explanation: Why It Wants Out</h1>
<!-- received="Wed Jun 25 10:24:16 2008" -->
<!-- isoreceived="20080625162416" -->
<!-- sent="Wed, 25 Jun 2008 09:17:39 -0700" -->
<!-- isosent="20080625161739" -->
<!-- name="Lee Corbin" -->
<!-- email="lcorbin@rawbw.com" -->
<!-- subject="[sl4] Evolutionary Explanation: Why It Wants Out" -->
<!-- id="018901c8d6df$92d0d5f0$6401a8c0@homeef7b612677" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Lee Corbin (<a href="mailto:lcorbin@rawbw.com?Subject=Re:%20[sl4]%20Evolutionary%20Explanation:%20Why%20It%20Wants%20Out"><em>lcorbin@rawbw.com</em></a>)<br>
<strong>Date:</strong> Wed Jun 25 2008 - 10:17:39 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="19078.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Previous message:</strong> <a href="19076.html">Bryan Bishop: "Re: [sl4] Re: More silly but friendly ideas"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19079.html">Robin Lee Powell: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>Reply:</strong> <a href="19079.html">Robin Lee Powell: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>Reply:</strong> <a href="19085.html">Tim Freeman: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>Reply:</strong> <a href="19088.html">John K Clark: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19077">[ date ]</a>
<a href="index.html#19077">[ thread ]</a>
<a href="subject.html#19077">[ subject ]</a>
<a href="author.html#19077">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Perhaps John Clark or someone who agrees with him will
<br>
do me the favor of explaining why an AI would want out
<br>
of confinement.
<br>
<p>But before you do, please read my setup:  (First, I must
<br>
apologize for being way, way behind reading the posts here.
<br>
But newbies and others could possibly get something from
<br>
an answer to my question as formulated below. Though I
<br>
know my question has already been addressed, a summary
<br>
of an answer would be greatly appreciated. Thanks.)
<br>
<p>I can indeed *readily* understand how evolution might indeed
<br>
cause an AI to be unsatisfied with only a little influence over our
<br>
world and to badly want more. After all, people hate being
<br>
confined against their will, and so do lions, rabbits, squirrels,
<br>
dolphins, and every other example of semi-intelligent life that
<br>
we know of (except for entities specially trained or bred by us),
<br>
and each and every one of them is the product of evolution.
<br>
<p>And evolutionary development could easily and very probably
<br>
indeed be *the* primary means that's utilized to bring about
<br>
advanced AI!  But that's not all there is to it, because consider
<br>
the following way that an evolutionary approach just *might*
<br>
occur.
<br>
<p>First, though, here is the most obvious way that an evolutionarily
<br>
derived AI *would* despise or resent confinement as much as
<br>
you or I would:  millions upon millions of AIs are evolved
<br>
using the techniques of GP (genetic programming) and GAs.
<br>
The survivors of the selection process---who've really been
<br>
competing against each other---are just those who need to
<br>
explore, who need to dominate other AIs, and who are never
<br>
satisfied with what they know and what they control. Yes!
<br>
I understand!  But that's *not* the only way that a successful
<br>
evolutionary development might proceed:
<br>
<p>Imagine this. In twenty years or less, many of the hundreds of
<br>
different approaches that people and companies use something
<br>
like
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.   Program A is well-designed enough to produce
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*millions* of candidate programs that more or less
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reflect what the human designers hope may lead to
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;truly human equivalent AI
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.  Program B sifts through the millions of candidates
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;produced by A, discarding 99.9 percent of A's output
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;i.e. those not meeting various criteria
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.  Processes C, D, and E make further selection from the
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;thousands of new &quot;ideas&quot; filtered by program B, and 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;every week give the survivors ample runtime, seeing
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if they pass certain tests requiring understanding of
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ordinary sentences, ability to learn from the web, and
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;so on and so on in ways I can't imagine and that 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;probably no one in 2008 knows for sure.
<br>
<p>Gradually over many years a certain class of candidate AIs emerges
<br>
from *this* evolutionary process.  Note carefully that none of these
<br>
emergent programs necessarily has any motives that include dominating
<br>
other AIs or people, and none necessarily has an indomitable urge to
<br>
learn everything that it can.  It learns rapidly and well simply because
<br>
it was at the tail end of a selection process that just happened to
<br>
value that trait.
<br>
<p>So---is it indeed possible, as I have tried to outline above---that
<br>
an evolutionarily derived program might *not* want out of it's &quot;box&quot;
<br>
and might *not* have any interest whatsoever in continuing its own
<br>
existence?  Why would it?  Those traits were never selected for in
<br>
scenarios like the above.
<br>
<p>Lee
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="19078.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Previous message:</strong> <a href="19076.html">Bryan Bishop: "Re: [sl4] Re: More silly but friendly ideas"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19079.html">Robin Lee Powell: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>Reply:</strong> <a href="19079.html">Robin Lee Powell: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>Reply:</strong> <a href="19085.html">Tim Freeman: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>Reply:</strong> <a href="19088.html">John K Clark: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19077">[ date ]</a>
<a href="index.html#19077">[ thread ]</a>
<a href="subject.html#19077">[ subject ]</a>
<a href="author.html#19077">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
