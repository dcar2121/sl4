<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html</title>
<meta name="Author" content="Vladimir Nesov (robotact@gmail.com)">
<meta name="Subject" content="Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html">
<meta name="Date" content="2008-06-03">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html</h1>
<!-- received="Tue Jun  3 01:53:48 2008" -->
<!-- isoreceived="20080603075348" -->
<!-- sent="Tue, 3 Jun 2008 11:51:12 +0400" -->
<!-- isosent="20080603075112" -->
<!-- name="Vladimir Nesov" -->
<!-- email="robotact@gmail.com" -->
<!-- subject="Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html" -->
<!-- id="b54769d90806030051h7e4e2aa6n9bab281c6443244a@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="b54769d90805310227q6e2e46cfx279b2ac0377a60ea@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Vladimir Nesov (<a href="mailto:robotact@gmail.com?Subject=Re:%20AI%20Boxing:%20http://www.sl4.org/archive/0207/4977.html"><em>robotact@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Jun 03 2008 - 01:51:12 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="18901.html">Vladimir Nesov: "Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html"</a>
<li><strong>Previous message:</strong> <a href="../0805/18899.html">Christopher Drane: "Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html"</a>
<li><strong>In reply to:</strong> <a href="../0805/18897.html">Vladimir Nesov: "Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18944.html">Peter C. McCluskey: "Oracle AI"</a>
<li><strong>Reply:</strong> <a href="18944.html">Peter C. McCluskey: "Oracle AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18900">[ date ]</a>
<a href="index.html#18900">[ thread ]</a>
<a href="subject.html#18900">[ subject ]</a>
<a href="author.html#18900">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Sat, May 31, 2008 at 1:27 PM, Vladimir Nesov &lt;<a href="mailto:robotact@gmail.com?Subject=Re:%20AI%20Boxing:%20http://www.sl4.org/archive/0207/4977.html">robotact@gmail.com</a>&gt; wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; I feel that the conclusion of that old discussion, which I didn't have
</em><br>
<em>&gt; a chance to participate in, is rather misguided. However obvious it
</em><br>
<em>&gt; may be, if AI locked in the box is sane enough to understand a complex
</em><br>
<em>&gt; request like &quot;create a simple theory of Friendliness and hand it
</em><br>
<em>&gt; over&quot;, it can be used for this purpose. This AI is not intended to be
</em><br>
<em>&gt; released at all, at least before the Friendly one build according to
</em><br>
<em>&gt; that design, if design proves reasonable, assumes the position of
</em><br>
<em>&gt; SysOp or the like. Even if building an AI that can actually understand
</em><br>
<em>&gt; what you mean by requesting Friendliness theory is 99.999% of the way
</em><br>
<em>&gt; there, the actual step of using a boxed setup to create a reliable
</em><br>
<em>&gt; system may still be needed.
</em><br>
<em>&gt;
</em><br>
<p>In recent post on Overcoming Bias, Eliezer told that Nick Bostrom
<br>
suggested the same setup years ago (see
<br>
<a href="http://www.overcomingbias.com/2008/06/the-rhythm-of-d.html">http://www.overcomingbias.com/2008/06/the-rhythm-of-d.html</a> ). In that
<br>
description, sane-enough-AI-in-the-box is called Oracle AI, which is
<br>
used to help with building a theory of actual Friendly AI. Here is a
<br>
relevant passage:
<br>
<p><em>&gt; Nick Bostrom, however, once asked whether it would make sense to
</em><br>
<em>&gt; build an Oracle AI, one that only answered questions, and ask it our
</em><br>
<em>&gt; questions about Friendly AI.  I explained some of the theoretical
</em><br>
<em>&gt; reasons why this would be just as difficult as building a Friendly
</em><br>
<em>&gt; AI:  The Oracle AI still needs an internal goal system to allocate
</em><br>
<em>&gt; computing resources efficiently, and it has to have a goal of
</em><br>
<em>&gt; answering questions and updating your mind, so it's not harmless
</em><br>
<em>&gt; unless it knows what side effects shouldn't happen.  It also needs
</em><br>
<em>&gt; to implement or interpret a full meta-ethics before it can answer
</em><br>
<em>&gt; our questions about Friendly AI.  So the Oracle AI is not
</em><br>
<em>&gt; necessarily any simpler, theoretically, than a Friendly AI.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Nick didn't seem fully convinced of this.  I knew that Nick knew
</em><br>
<em>&gt; that I'd been thinking about the problem for years, so I knew he
</em><br>
<em>&gt; wasn't just disregarding me; his continued disagreement meant
</em><br>
<em>&gt; something.  And I also remembered that Nick had spotted the problem
</em><br>
<em>&gt; of Friendly AI itself, at least two years before I had (though I did
</em><br>
<em>&gt; not realize this until later, when I was going back and reading some
</em><br>
<em>&gt; of Nick's older work).  So I pondered Nick's idea further.  Maybe,
</em><br>
<em>&gt; whatever the theoretical arguments, an AI that was supposed to only
</em><br>
<em>&gt; answer questions, and designed to the full standards of Friendly AI
</em><br>
<em>&gt; without skipping any of the work, could end up a pragmatically safer
</em><br>
<em>&gt; starting point.  Every now and then I prod Nick's Oracle AI in my
</em><br>
<em>&gt; mind, to check the current status of the idea relative to any
</em><br>
<em>&gt; changes in my knowledge.  I remember Nick has been right on previous
</em><br>
<em>&gt; occasions where I doubted his rightness; and if I am an expert, so
</em><br>
<em>&gt; is he.
</em><br>
<p><pre>
-- 
Vladimir Nesov
<a href="mailto:robotact@gmail.com?Subject=Re:%20AI%20Boxing:%20http://www.sl4.org/archive/0207/4977.html">robotact@gmail.com</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="18901.html">Vladimir Nesov: "Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html"</a>
<li><strong>Previous message:</strong> <a href="../0805/18899.html">Christopher Drane: "Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html"</a>
<li><strong>In reply to:</strong> <a href="../0805/18897.html">Vladimir Nesov: "Re: AI Boxing: http://www.sl4.org/archive/0207/4977.html"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18944.html">Peter C. McCluskey: "Oracle AI"</a>
<li><strong>Reply:</strong> <a href="18944.html">Peter C. McCluskey: "Oracle AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18900">[ date ]</a>
<a href="index.html#18900">[ thread ]</a>
<a href="subject.html#18900">[ subject ]</a>
<a href="author.html#18900">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
