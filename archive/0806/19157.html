<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] End to violence and government [Was:Signaling after a singularity]</title>
<meta name="Author" content="Bryan Bishop (kanzure@gmail.com)">
<meta name="Subject" content="Re: [sl4] End to violence and government [Was:Signaling after a singularity]">
<meta name="Date" content="2008-06-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] End to violence and government [Was:Signaling after a singularity]</h1>
<!-- received="Mon Jun 30 11:49:36 2008" -->
<!-- isoreceived="20080630174936" -->
<!-- sent="Mon, 30 Jun 2008 12:47:20 -0500" -->
<!-- isosent="20080630174720" -->
<!-- name="Bryan Bishop" -->
<!-- email="kanzure@gmail.com" -->
<!-- subject="Re: [sl4] End to violence and government [Was:Signaling after a singularity]" -->
<!-- id="55ad6af70806301047y193752dbyeb0385b5f0ef45be@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="38f493f10806301001r5f195868x3aeabdf629764f71@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Bryan Bishop (<a href="mailto:kanzure@gmail.com?Subject=Re:%20[sl4]%20End%20to%20violence%20and%20government%20[Was:Signaling%20after%20a%20singularity]"><em>kanzure@gmail.com</em></a>)<br>
<strong>Date:</strong> Mon Jun 30 2008 - 11:47:20 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="19158.html">Lee Corbin: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Previous message:</strong> <a href="19156.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>In reply to:</strong> <a href="19155.html">Stuart Armstrong: "Re: [sl4] End to violence and government [Was:Signaling after a singularity]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0807/19181.html">Lee Corbin: "Re: [sl4] End to violence and government"</a>
<li><strong>Reply:</strong> <a href="../0807/19181.html">Lee Corbin: "Re: [sl4] End to violence and government"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19157">[ date ]</a>
<a href="index.html#19157">[ thread ]</a>
<a href="subject.html#19157">[ subject ]</a>
<a href="author.html#19157">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Mon, Jun 30, 2008 at 12:01 PM, Stuart Armstrong
<br>
&lt;<a href="mailto:dragondreaming@googlemail.com?Subject=Re:%20[sl4]%20End%20to%20violence%20and%20government%20[Was:Signaling%20after%20a%20singularity]">dragondreaming@googlemail.com</a>&gt; wrote:
<br>
<em>&gt;&gt; Is that what this was getting at? I've lost track of how this 'small
</em><br>
<em>&gt;&gt; cost' is done away with by a government -- you can just as easily
</em><br>
<em>&gt;&gt; consider the ai or the government as a damaging entity who does you
</em><br>
<em>&gt;&gt; harm in one way or another.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The cost (small and large) is done away by the government because the
</em><br>
<em>&gt; government offers the possibility of retatilation on anyone threatning
</em><br>
<em>&gt; or using violence - so they don't do it. And of course the AI or
</em><br>
<p>You're just replacing one sharp stick with another.
<br>
<p><em>&gt; government can become a highly damaging entity; that's why the present
</em><br>
<em>&gt; model is to have a liberal democracy with strongish property rights
</em><br>
<em>&gt; and individual rights. This seems to be the best model so far in
</em><br>
<p>Most of the ai scenarios that I remember reading in the literature,
<br>
the ones that sounded like ai domnination takeover scenarios, involved
<br>
computer hacking and the 'illegal' downloading of information, and yet
<br>
here we see that it's supposed to obey such copyrights and property
<br>
rights and individual rights and whatever else? That's a peculiar
<br>
contradiction, but I'm just pointing this out. It's not the big issue
<br>
at stake here.
<br>
<p>I don't see how &quot;property rights&quot; has any hold over a hot stick.
<br>
&quot;Property rights&quot; is a social construct that bacteria, for instance,
<br>
do not need to uphold, simply because property rights are of human
<br>
society and are based off of human thoughts and so on. So, the same
<br>
with ai and in fact the same with humans and thus how we are able to
<br>
have thieves, modern pirates of the black market of financial
<br>
transactions circulating the globe (or at least other parts of the
<br>
globe, I haven't seen signs of them hanging out in North America
<br>
much).
<br>
<p>So, the model is wrong. Now, allow me to go strawman for a few
<br>
seconds. I suppose that you will follow up with an argument about the
<br>
social pressures that could be induced either as they are in modern
<br>
society by making the cost of getting caught too high, or via ai
<br>
know-it-all scenarios. In the case of increasing the cost of thievery,
<br>
that's only a selective pressure on catching thieves and doesn't
<br>
actually solve the fundamental problem in the first place -- that
<br>
people have stuff, and they'd really prefer to keep it. You're just
<br>
going to make sure that all of the thieves are going to get wickedly
<br>
good at avoiding security. As for the ai know-it-all scenarios, where
<br>
they are able to make everyone not thieve because everybody's desires
<br>
are known, you're assuming that the sharp stick (the ai) is able to
<br>
make arrangements for the extraordinary demands that some might make.
<br>
Now, in alternative situations, these guys would be left on their own
<br>
to make it happen, perhaps with the support of some fellow ai systems
<br>
that they instantiate or come across, perhaps not. Anyway, the ai of
<br>
course couldn't &quot;give the world on a silver platter&quot; to somebody,
<br>
since that's obviously in conflict with all of the other wonderful
<br>
things that the ai domination game would supposedly involve. Etc. The
<br>
model is wrong -- it doesn't actually address the physical systems and
<br>
the possibilities that we find in existence, and it's really a royal
<br>
pain. Let's fix this.
<br>
<p><em>&gt; practice, for enforcing contracts, maintaining law, and causing the
</em><br>
<em>&gt; minimum of suffering to the population. There might be superior models
</em><br>
<em>&gt; after a singularity, but I still don't see how you can do without the
</em><br>
<em>&gt; basic outline of a government.
</em><br>
<p>I am now considering that I might not have been as elaborate as I
<br>
should have been in the past, so I'm going to walk another few limbs
<br>
and point out what a singularity means and how governments, especially
<br>
nation-states and so on, wouldn't be the only solutions, and I am
<br>
going to babble, a lot :-). Now, we're not going all anissimovic here,
<br>
and a singularitty is in general where we have the exponential
<br>
explosion of growth that in one way or another allows the explosion of
<br>
physically implemented artificial intelligence. So what does that
<br>
mean? You have lots of hardware, and lots of software, and lots of
<br>
interfaces and all sorts of interesting tools that you can now play
<br>
with. There are many functions that a government serves, many of which
<br>
can already be replaced with the technological advances of the past
<br>
hundred years but that haven't quite made it all the way back to the
<br>
beginning. And in the case of a singularity, suddenly the amount of
<br>
information and new technology that could be used to update the
<br>
system? That becomes truly amazing. I'm not saying that the amazing
<br>
factor is what necessitates the reconsideration of the government,
<br>
although it certainly does help on the emotional scale of things.
<br>
Rationally, anything more efficient for getting the same goals done
<br>
and so on are well worth the consideration, so what about all of these
<br>
technologies that allow us to communicate and diffuse information now?
<br>
And what about all of the tools and technologies that allow us to
<br>
manage our own lives to an even greater extent? Suppose, for instance,
<br>
that we are worried about health care. Heh, government-provided health
<br>
care? When talking about a singularity? Hell, just build a
<br>
robot-scientist/doctor and load it up with ai, what's the problem? The
<br>
government isn't needed any more in that case, you have a robotic
<br>
doctor, a walking encyclopedia of knowledge, tools and methodology
<br>
that doesn't need to be paid. And what about all of the need for
<br>
protection and security? There are many possibilities that have been
<br>
developed over the past century. Because of advancements in
<br>
manufacturing, it would be possible for everyone to have personal
<br>
automatic immune systems on a larger scale, perhaps for their entire
<br>
(maybe mobile) homes? And so on, and so forth. Massive amounts of
<br>
information and programs can be compressed down into small computers
<br>
to support an individual with the thosuands of years of civilization's
<br>
development, and so suddenly we have people walking around that are
<br>
more informed, more up to date, and more capable than the government.
<br>
Should they happen to need space or land in which to live, for some
<br>
random reason, why would it have to go through the government? Just
<br>
hook up to the local astrophysical DNS, go find some unused materials,
<br>
and start processing them. In that case, the person has successfully
<br>
escaped somebody on the planet's surface that was threatening them,
<br>
etc. So in that case, the government wasn't needed. Truthfully,
<br>
everyone knows when they are feeling pain, and I suspect an
<br>
interesting strategy to try out would be to let people manage their
<br>
pain intake. In other words, if you're in pain, the hospitals already
<br>
give you access to a morphine pump, you just press the little button.
<br>
No, I'm not talking about letting everyone get high on drugs. Rather,
<br>
I'm talking about letting them manage their bodies *as they already
<br>
do* so that they can get their work done, whatever it is that they
<br>
want to do. I see little reason for a government strategy here since
<br>
everyone is minimizing their own suffering in the first place. And
<br>
what happens when there are disputes? In the case of social disputes,
<br>
there's little stopping anyone from just spawning a new society, just
<br>
as they already do. This would become especially more easy and more
<br>
possible with the vasts amount of ai floating around, the knowledge
<br>
databases, the flat-out knowhow. There's already some projects that
<br>
are interested in establishing this functionality, like some of the
<br>
space pod projects.
<br>
<p>Hrm. I have dumped a lot of random crap on you, but I hope it will
<br>
help. Please digest and tell me more about sharp stick theory. :-)
<br>
<p>- Bryan
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="19158.html">Lee Corbin: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Previous message:</strong> <a href="19156.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>In reply to:</strong> <a href="19155.html">Stuart Armstrong: "Re: [sl4] End to violence and government [Was:Signaling after a singularity]"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0807/19181.html">Lee Corbin: "Re: [sl4] End to violence and government"</a>
<li><strong>Reply:</strong> <a href="../0807/19181.html">Lee Corbin: "Re: [sl4] End to violence and government"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19157">[ date ]</a>
<a href="index.html#19157">[ thread ]</a>
<a href="subject.html#19157">[ subject ]</a>
<a href="author.html#19157">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
