<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] Re: Signaling after a singularity</title>
<meta name="Author" content="Bryan Bishop (kanzure@gmail.com)">
<meta name="Subject" content="Re: [sl4] Re: Signaling after a singularity">
<meta name="Date" content="2008-06-25">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] Re: Signaling after a singularity</h1>
<!-- received="Wed Jun 25 08:16:45 2008" -->
<!-- isoreceived="20080625141645" -->
<!-- sent="Wed, 25 Jun 2008 09:18:44 -0500" -->
<!-- isosent="20080625141844" -->
<!-- name="Bryan Bishop" -->
<!-- email="kanzure@gmail.com" -->
<!-- subject="Re: [sl4] Re: Signaling after a singularity" -->
<!-- id="200806250918.45000.kanzure@gmail.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="38f493f10806250212q40933d9cl83c080b31bd27493@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Bryan Bishop (<a href="mailto:kanzure@gmail.com?Subject=Re:%20[sl4]%20Re:%20Signaling%20after%20a%20singularity"><em>kanzure@gmail.com</em></a>)<br>
<strong>Date:</strong> Wed Jun 25 2008 - 08:18:44 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="19076.html">Bryan Bishop: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Previous message:</strong> <a href="19074.html">Bryan Bishop: "Re: [sl4] Paper: Artificial Intelligence will Kill our Grandchildren"</a>
<li><strong>In reply to:</strong> <a href="19071.html">Stuart Armstrong: "Re: [sl4] Re: Signaling after a singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19094.html">Stuart Armstrong: "Re: [sl4] Re: Signaling after a singularity"</a>
<li><strong>Reply:</strong> <a href="19094.html">Stuart Armstrong: "Re: [sl4] Re: Signaling after a singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19075">[ date ]</a>
<a href="index.html#19075">[ thread ]</a>
<a href="subject.html#19075">[ subject ]</a>
<a href="author.html#19075">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Wednesday 25 June 2008, Stuart Armstrong wrote:
<br>
<em>&gt; &gt;&gt; The aspect of a post-singularity world I'd like to look at is the
</em><br>
<em>&gt; &gt;&gt; absence of signalling. If we had an advanced AI, it should be able
</em><br>
<em>&gt; &gt;&gt; to fully understand the personality and abilities of an individual
</em><br>
<em>&gt; &gt;&gt; human. If it would accept to reveal this information to humans,
</em><br>
<em>&gt; &gt;&gt; then we would live in a society with perfect understanding of each
</em><br>
<em>&gt; &gt;&gt; other.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I suppose you're taking the AI-only-approach (Anissimovic)
</em><br>
<em>&gt; &gt; singularity. I don't know what an understanding of personality
</em><br>
<em>&gt; &gt; would entail. The idea of personality is pop psychology anyway, so
</em><br>
<em>&gt; &gt; saying something like this makes me wonder if you know what the ai
</em><br>
<em>&gt; &gt; would be knowing in the first place.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Personality may be pop psychology, but it's not a concept devoid of
</em><br>
<em>&gt; information. It's useful in assigning certain people to certain jobs,
</em><br>
<p>It /is/ devoid of information. It's folk psych. You need to be 
<br>
addressing the basis of the brain and what allows the variation that is 
<br>
allowed (or not allowed) by the architectures and such, not going the 
<br>
other way around. Think of it this way. Reverse engineering a 
<br>
microprocessor, with a few billion transistors and 128 bits of i/o, 
<br>
takes something like 2^128 different states of input to test, and then 
<br>
that's only for one state, what about multiple states? And in multiple 
<br>
combinations? So that quickly gets to something like (84 different 
<br>
lines of code)^(2^(128)). Same thing with pop psych. Instead of doing 
<br>
it that way, try looking at the schematics, and in the case of biology 
<br>
usually this is done via mutational studies since the mapping between 
<br>
DNA, protein, and overall result is unclear.
<br>
<p><em>&gt; for instance. Assuming the AI could not just brute force the problem
</em><br>
<em>&gt; and predict everyone's actions in every circumstances (chaos would
</em><br>
<em>&gt; probably forbid this), then the AI would have to rely on some
</em><br>
<em>&gt; simplified model that gives it enough information to make decisions.
</em><br>
<p>Make what decisions? I suspect you are going back to the idea of a 
<br>
dictatorship of an ai? I don't understand. :-/ More on this below.
<br>
<p><em>&gt; &quot;Personality&quot; is one of our simplified model's (&quot;abilities&quot; is
</em><br>
<em>&gt; another); the AI's simplified models would be much better, but we can
</em><br>
<em>&gt; still call &quot;Personality&quot; as a shorthand.
</em><br>
<p>Ok, I can give you that.
<br>
<p><em>&gt; &gt; As for the economy, just ignore it. As for the culture, I don't
</em><br>
<em>&gt; &gt; see what you mean. Would the information be deleted for some
</em><br>
<em>&gt; &gt; reason?
</em><br>
<em>&gt;
</em><br>
<em>&gt; The old culture would still be there; it's whether there would be new
</em><br>
<em>&gt; ongoing cultures that I'm wondering.
</em><br>
<p>Perhaps on another planet? Not that I'm saying on earth it would not be 
<br>
so.
<br>
<p><em>&gt; &gt; Why would dictators be the best way to govern?
</em><br>
<em>&gt;
</em><br>
<em>&gt; I'm not saying they would; I'm just saying that all the assumptions
</em><br>
<em>&gt; on what system of government is the best may have to rexamined, and
</em><br>
<em>&gt; what we take for granted now (democracy best) may not be true after a
</em><br>
<em>&gt; singularity.
</em><br>
<p>Looks like you're assuming a spectrum with democracy and dictatorship at 
<br>
two opposite ends of the line. That doesn't sound truly reconsidered. 
<br>
And I don't see why you're even putting an ai into those 
<br>
considerations, but I'm willing to discuss alternative forms of living 
<br>
and having lots of people around, but again it doesn't necessarily 
<br>
involve a giant Holy Ai at the head of the whole beehive. I don't know 
<br>
where this idea comes from.
<br>
<p><em>&gt; As for why governing, there will still be a finite (though huge)
</em><br>
<em>&gt; amount of ressources available to anyone, and there will still be the
</em><br>
<em>&gt; problem of violence/coercion between agents. Some system of
</em><br>
<p>Maybe. But that violence can be solved. It's a singularity, not a pot 
<br>
luck dinner. Instead of having one copy of yourself running around, try 
<br>
having some redundancy and backups so that if something malacious does 
<br>
happen to you, you're not dead. It's just good practice. Many 
<br>
programmers already do these practices. Daily backups and such. 
<br>
Repositories. Keeping track of diff's. etc. So calling for an ai in 
<br>
that case doesn't seem like a good idea. Just make sure people are 
<br>
informed and give them the tech. Since it's a singularity, I'm sure 
<br>
giving them a kinematic self-replicating machine will not be a problem.
<br>
<p><em>&gt; government would still be needed to adjudicate conflicts. And this
</em><br>
<p>Eh?
<br>
<p><em>&gt; system must have access to a higher level of violence than any
</em><br>
<em>&gt; individual agent, if there is any chance that agent could misbehave.
</em><br>
<p>My stick is bigger than yours? That's the best we can come up with?
<br>
<p><em>&gt; It might be a collaberative, communal hippy government, or it might
</em><br>
<em>&gt; be an AI dictatorship, but it would still be a government.
</em><br>
<p>No, it could be no government at all. Have you considered that these 
<br>
technologies are liberating ? That they don't force us to rely on 
<br>
governments? That they allow us to live our lives without the 
<br>
restrictions that governments used to be there to help face up to? etc.
<br>
<p>- Bryan
<br>
________________________________________
<br>
<a href="http://heybryan.org/">http://heybryan.org/</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="19076.html">Bryan Bishop: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Previous message:</strong> <a href="19074.html">Bryan Bishop: "Re: [sl4] Paper: Artificial Intelligence will Kill our Grandchildren"</a>
<li><strong>In reply to:</strong> <a href="19071.html">Stuart Armstrong: "Re: [sl4] Re: Signaling after a singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19094.html">Stuart Armstrong: "Re: [sl4] Re: Signaling after a singularity"</a>
<li><strong>Reply:</strong> <a href="19094.html">Stuart Armstrong: "Re: [sl4] Re: Signaling after a singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19075">[ date ]</a>
<a href="index.html#19075">[ thread ]</a>
<a href="subject.html#19075">[ subject ]</a>
<a href="author.html#19075">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
