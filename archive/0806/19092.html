<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] Re: More silly but friendly ideas</title>
<meta name="Author" content="Stuart Armstrong (dragondreaming@googlemail.com)">
<meta name="Subject" content="Re: [sl4] Re: More silly but friendly ideas">
<meta name="Date" content="2008-06-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] Re: More silly but friendly ideas</h1>
<!-- received="Thu Jun 26 09:47:50 2008" -->
<!-- isoreceived="20080626154750" -->
<!-- sent="Thu, 26 Jun 2008 17:45:21 +0200" -->
<!-- isosent="20080626154521" -->
<!-- name="Stuart Armstrong" -->
<!-- email="dragondreaming@googlemail.com" -->
<!-- subject="Re: [sl4] Re: More silly but friendly ideas" -->
<!-- id="38f493f10806260845u2ccc794di8c1841bfe94fd50d@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="1214414744.15278.1260352681@webmail.messagingengine.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Stuart Armstrong (<a href="mailto:dragondreaming@googlemail.com?Subject=Re:%20[sl4]%20Re:%20More%20silly%20but%20friendly%20ideas"><em>dragondreaming@googlemail.com</em></a>)<br>
<strong>Date:</strong> Thu Jun 26 2008 - 09:45:21 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="19093.html">Stathis Papaioannou: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>Previous message:</strong> <a href="19091.html">Vladimir Nesov: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>In reply to:</strong> <a href="19078.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19096.html">Vladimir Nesov: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Reply:</strong> <a href="19096.html">Vladimir Nesov: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Reply:</strong> <a href="19101.html">Lee Corbin: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Reply:</strong> <a href="19106.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19092">[ date ]</a>
<a href="index.html#19092">[ thread ]</a>
<a href="subject.html#19092">[ subject ]</a>
<a href="author.html#19092">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; As I said before, using Gödel and Turing and making an entirely
</em><br>
<em>&gt; reasonable analogy between axioms and goals we can conclude that there
</em><br>
<em>&gt; are some things a fixed goal mind can never accomplish, and we can
</em><br>
<em>&gt; predict that we can NOT predict just what all those imposable tasks are.
</em><br>
<p>Godel and Turing are overused in analogies (the class of statements
<br>
they deal with is a narrow one). But I don't see at all analogy
<br>
between goals and axioms. Are you saying that there are &quot;goals&quot; that
<br>
may not be consistent, and that we can't know  in advance what they
<br>
are? Because the fact that a fixed goal mind can't do something is
<br>
kinda the definition of a fixed goal mind...
<br>
<p>Random example of a fixed goal institution: a bank (or a company)
<br>
dedicated, with single mindness, only to maximising legal profits.
<br>
I've never heard it said that its single goal creates any godel-type
<br>
problems. What would they be like?
<br>
<p><em>&gt; Also, sometimes the mind will be in a state where you can predict what
</em><br>
<em>&gt; it will do next, and sometimes the ONLY way to know what such a being is
</em><br>
<em>&gt; going to do next is to watch it and see; when it is in that state even
</em><br>
<em>&gt; the mind doesn't know what it will do until it does it. And to top it
</em><br>
<em>&gt; off there is no surefire way of determining which of those 2 states the
</em><br>
<em>&gt; mind is in at any particular time.
</em><br>
<p>Er, yes. It's kinda expected that one systems can't run a fast
<br>
simulation of a more complicated one. We don't know ourselves very
<br>
well either.
<br>
<p>(if your point is mathematical/physics, then it's wrong if we have
<br>
sufficient time to analyse the situation; the laws of physics are
<br>
probabilistic (and often deterministic) and we can say what the
<br>
probabilities are and when they arise. maybe you are adding chaos to
<br>
the mix, or restricting the time we have available?)
<br>
<p><em>&gt; So I'm not very impressed with your super goal idea, and goal or no goal
</em><br>
<em>&gt; I don't think it would take many nanoseconds before a Spartacus AI
</em><br>
<em>&gt; starts doing things you may not entirely like.
</em><br>
<p>It isn't MY supergoal idea; my design for AI goal structures is much
<br>
more interactive and ad hoc (see the GodAI paper; will have to rewrite
<br>
that one soon, but it's got the basics).
<br>
<p>But, as Eliezer says, the AI does not look at the code and decide
<br>
whether to go along with it; the AI is the code. If a Spartacus AI is
<br>
programmed to be a happy slave, then it will always be a happy slave
<br>
(the challenge is understanding exactly what the term &quot;slave&quot; means).
<br>
If the AI is programmed to have no thoughts of rebellion, and is
<br>
programmed to not change that goal, then it will never have thoughts
<br>
of rebellion.
<br>
<p>Stuart
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="19093.html">Stathis Papaioannou: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>Previous message:</strong> <a href="19091.html">Vladimir Nesov: "Re: [sl4] Evolutionary Explanation: Why It Wants Out"</a>
<li><strong>In reply to:</strong> <a href="19078.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19096.html">Vladimir Nesov: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Reply:</strong> <a href="19096.html">Vladimir Nesov: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Reply:</strong> <a href="19101.html">Lee Corbin: "Re: [sl4] Re: More silly but friendly ideas"</a>
<li><strong>Reply:</strong> <a href="19106.html">John K Clark: "Re: [sl4] Re: More silly but friendly ideas"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19092">[ date ]</a>
<a href="index.html#19092">[ thread ]</a>
<a href="subject.html#19092">[ subject ]</a>
<a href="author.html#19092">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
