<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-2022-jp">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Friendliness and blank-slate goal bootstrap</title>
<meta name="Author" content="Nick Hay (nickjhay@hotmail.com)">
<meta name="Subject" content="Re: Friendliness and blank-slate goal bootstrap">
<meta name="Date" content="2003-10-04">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Friendliness and blank-slate goal bootstrap</h1>
<!-- received="Sat Oct  4 06:06:04 2003" -->
<!-- isoreceived="20031004120604" -->
<!-- sent="Sun, 5 Oct 2003 00:02:16 +1200" -->
<!-- isosent="20031004120216" -->
<!-- name="Nick Hay" -->
<!-- email="nickjhay@hotmail.com" -->
<!-- subject="Re: Friendliness and blank-slate goal bootstrap" -->
<!-- id="200310050002.16703.nickjhay@hotmail.com" -->
<!-- charset="iso-2022-jp" -->
<!-- inreplyto="004401c38a41$6987f150$0b01a8c0@curziolaptop" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Nick Hay (<a href="mailto:nickjhay@hotmail.com?Subject=Re:%20Friendliness%20and%20blank-slate%20goal%20bootstrap"><em>nickjhay@hotmail.com</em></a>)<br>
<strong>Date:</strong> Sat Oct 04 2003 - 06:02:16 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7178.html">Metaqualia: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Previous message:</strong> <a href="7176.html">Simon Gordon: "Re: HUMOR: Friendly AI Critical Failure Table"</a>
<li><strong>In reply to:</strong> <a href="7175.html">Metaqualia: "Re: Friendliness and blank-slate goal bootstrap"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7178.html">Metaqualia: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7178.html">Metaqualia: "Re: Friendliness and blank-slate goal bootstrap"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7177">[ date ]</a>
<a href="index.html#7177">[ thread ]</a>
<a href="subject.html#7177">[ subject ]</a>
<a href="author.html#7177">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Metaqualia wrote:
<br>
<em>&gt; I agree with many of your points, and not with others.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;Why have a blank slate moral system?&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Actually it was just an idea, it doesn't really matter whether it is blank
</em><br>
<em>&gt; or not to start with.
</em><br>
<em>&gt; If we are making a recursively improving AI, it should have a recursively
</em><br>
<em>&gt; improving moral system.
</em><br>
<p>Right, that's one of the main points of Friendliness. Note: &quot;Friendliness&quot; != 
<br>
&quot;friendliness&quot; -- it's not about the human concept of friendliness. More 
<br>
about &quot;what's really good and meaningful?&quot;, &quot;how can we create a mind that 
<br>
understands and can develope humane morality?&quot;, &quot;how can we create a mind 
<br>
that can go back and make sure we made it in the right way?&quot;
<br>
<p>Try 24 definitions of Friendliness for more on this kind of thing: 
<br>
<a href="http://intelligence.org/intro/friendly.html">http://intelligence.org/intro/friendly.html</a>
<br>
<p><em>&gt; Start it up with some basic human morality, or start with a blank goal
</em><br>
<em>&gt; system, whichever is easiest.
</em><br>
<em>&gt; The important thing is to allow the AI not to remain stuck in one place but
</em><br>
<em>&gt; to keep improving.
</em><br>
<p>It is important for the AI not to be stuck. We don't do this by leaving out 
<br>
our evolved moral hardware (the stuff that makes human moral philosophy more 
<br>
complex than the pseudo-moralities of other primate, what allows us to start 
<br>
from and infant mind and create an adult, what allows people to argue about 
<br>
moral issues, etc) starting with a very simple AI, but by giving the AI all 
<br>
we can to help it.  Simplicity is a good criterion, but not in this way.
<br>
<p><em>&gt; I think that just as a visual cortex is important for evolving concepts of
</em><br>
<em>&gt; under/enclosed/occluded, having qualia for pain/pleasure in all their
</em><br>
<em>&gt; psychological variation is important for evolving concepts of
</em><br>
<em>&gt; wrong/right/painful/betrayal.
</em><br>
<p>I suspect qualia is not necessary for this kind of thing -- you seem to be 
<br>
identifying morality, something which seems easily tracable to some kind of 
<br>
neural process in the brain, with the ever confusing (at least for me!) 
<br>
notion of qualia. Where's the connection? The actual feeling of pain - the 
<br>
quale - is separate from the other cognitive processes that go along with 
<br>
this: sequiturs forming thoughts like &quot;how can I get stop this pain?&quot;, the 
<br>
formation of episodic memories, later recollection of the pain projected onto 
<br>
others via empathy, and other processes that seem much easier to explain. Or 
<br>
however it works :)
<br>
<p>I think &quot;betrayal&quot;, in the human sense, is unnecessary for a truly altruisitic 
<br>
mind, especially a superintelligence. Seems like an evolved hack appropriate 
<br>
in a human environment, where you want to increase inclusive fitness. Doesn't 
<br>
seem like a meaningful emotion. Although this, really, is a side issue.
<br>
<p><em>&gt; The AI, without a visual cortex, and if it had access to the outside world
</em><br>
<em>&gt; (nanotechnology?) could still run physics experiments, infer the existence
</em><br>
<em>&gt; of electromagnetic waves, create an array of pixels, and develop a visual
</em><br>
<em>&gt; cortex on its own.
</em><br>
<p>Right.
<br>
<p><em>&gt; But would an AI without qualia and with access to the outside world ever
</em><br>
<em>&gt; stumble upon qualia? I don't know.
</em><br>
<p>Not sure. It'd stumble on morality, and understand human morality (afaict), 
<br>
but of course that's very different from actually *having* a human-like (or 
<br>
better) morality. In so much as qualia actually affect physical processes, or 
<br>
are physical processes, the AI can trace back the causal chain to find the 
<br>
source, or the gap. For instance, look at exactly what happens in a human 
<br>
brain when people experience pain and say &quot;now there's an uncomfortable 
<br>
quale!&quot;, for instance.
<br>
<p><em>&gt; While we can stand to have a temporarily blind AI we can't afford to have a
</em><br>
<em>&gt; temporarily selfish/unfriendly AI on the loose. So IF we could incorporate
</em><br>
<em>&gt; some kind of qualia-system in the AI (of course making sure that it had
</em><br>
<em>&gt; complete control over these &quot;emotions&quot;, unlike a human) wouldn't it be a
</em><br>
<em>&gt; good thing?
</em><br>
<p>I guess so, but I don't really understand qualia and what they do. I think 
<br>
it's better to be thinking about simpler things, like what physical process 
<br>
allows a human infant to develop a morality, the adaptations we use to reason 
<br>
and argue about morality between humans, etc. Solve more tractable, and 
<br>
definitely essential, problems.
<br>
<p><em>&gt; However we don't have a clue how to create a qualia module, so that is why
</em><br>
<em>&gt; I wrote that garbage about trusting humans (or better, the basic set of
</em><br>
<em>&gt; human moral laws, as you said) until qualia are developed in _some_ way.
</em><br>
<p>I think we can do better than this, and CFAI goes into this. If you've only 
<br>
read this once, I recommend rereading this. I certainly didn't understand it 
<br>
first time round. Shaper/anchor semantics, for instance, would be relevant 
<br>
here. 
<br>
<p><em>&gt; 1. Absorb a refined version of the human moral code until you have qualia
</em><br>
<em>&gt; 2. Then, create your own moral code
</em><br>
<p>Not sure about the &quot;until you have qualia&quot;, and I think the steps are closely 
<br>
integrated, although that does capture the rough progression. Step 1, for 
<br>
insatnce, is a *huge* step! It takes a lot to create a mind capable of 
<br>
absorbing human moral codes, and the tools we unconsciously use to reason 
<br>
about and use them. CFAI goes into this a lot :)
<br>
<p><em>&gt; does this make sense?
</em><br>
<p>Mostly :) Although I have the strong suspicion qualia only make things more 
<br>
confusing. Can you explain more on what you mean by the term, and what makes 
<br>
you think they're centrally important?
<br>
<p>- Nick
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7178.html">Metaqualia: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Previous message:</strong> <a href="7176.html">Simon Gordon: "Re: HUMOR: Friendly AI Critical Failure Table"</a>
<li><strong>In reply to:</strong> <a href="7175.html">Metaqualia: "Re: Friendliness and blank-slate goal bootstrap"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7178.html">Metaqualia: "Re: Friendliness and blank-slate goal bootstrap"</a>
<li><strong>Reply:</strong> <a href="7178.html">Metaqualia: "Re: Friendliness and blank-slate goal bootstrap"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7177">[ date ]</a>
<a href="index.html#7177">[ thread ]</a>
<a href="subject.html#7177">[ subject ]</a>
<a href="author.html#7177">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:42 MDT
</em></small></p>
</body>
</html>
