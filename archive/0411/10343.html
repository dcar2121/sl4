<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: English translation of French article about SIAI</title>
<meta name="Author" content="Edmund Schaefer (edmund.schaefer@gmail.com)">
<meta name="Subject" content="English translation of French article about SIAI">
<meta name="Date" content="2004-11-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>English translation of French article about SIAI</h1>
<!-- received="Mon Nov 22 13:56:27 2004" -->
<!-- isoreceived="20041122205627" -->
<!-- sent="Mon, 22 Nov 2004 15:56:24 -0500" -->
<!-- isosent="20041122205624" -->
<!-- name="Edmund Schaefer" -->
<!-- email="edmund.schaefer@gmail.com" -->
<!-- subject="English translation of French article about SIAI" -->
<!-- id="e6ee0419041122125648cb9679@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Edmund Schaefer (<a href="mailto:edmund.schaefer@gmail.com?Subject=Re:%20English%20translation%20of%20French%20article%20about%20SIAI"><em>edmund.schaefer@gmail.com</em></a>)<br>
<strong>Date:</strong> Mon Nov 22 2004 - 13:56:24 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10344.html">Keith Henson: "Wired"</a>
<li><strong>Previous message:</strong> <a href="10342.html">Metaqualia: "Re: Yehuda Yudkowsky, 1985-2004"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10344.html">Keith Henson: "Wired"</a>
<li><strong>Reply:</strong> <a href="10344.html">Keith Henson: "Wired"</a>
<li><strong>Reply:</strong> <a href="10345.html">Damien Broderick: "Re: Wired"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10343">[ date ]</a>
<a href="index.html#10343">[ thread ]</a>
<a href="subject.html#10343">[ subject ]</a>
<a href="author.html#10343">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
This is just a quickie translation I put together, so it retains a bit
<br>
of French pompousness and awkwardness in parts (you'll quickly notice
<br>
the French passion for really long sentences), but at least it's fully
<br>
grammatical and thus easier to read than what the Babelfish puts out.
<br>
<p>Original URL:
<br>
<a href="http://www.automatesintelligents.com/labo/2004/sep/singularity.html">http://www.automatesintelligents.com/labo/2004/sep/singularity.html</a>
<br>
<p>L'Institut pour la Singularité
<br>
Singularity Institute 
<br>
<p>by J. P. Baquiast and C. Jacquemin 19 September 2004
<br>
translated from the French by Edmund Schaefer 22 November 2004
<br>
<p>We don't try in this review to ignore a phenomenon that some consider
<br>
maybe marginal, but which to us appears revealing of that which will
<br>
undoubtedly become a tidal wave, if humanity doesn't break down by
<br>
then in physical and intellectual underdevelopment: the likelihood, in
<br>
a relatively short time, of super-intelligences and of post- or
<br>
transhumans. Lots of people are talking about it, mostly in the United
<br>
States. Some in terms as scientific as possible, others mixing without
<br>
hesitation science fiction and dreams that are more or less New Age
<br>
or sectarian.
<br>
<p>Among those that offer a perspective on it that could be
<br>
scientifically qualified, we must announce the existence of a project
<br>
launched by some young scientific Americains that are certainly a bit
<br>
visionary, destined to produce an artificial intelligence (AI) of a
<br>
new type, able to renew the bases of human intelligence and to
<br>
self-improve itself almost automatically. The promoters of this
<br>
project have created an Institute, very modest with regard to members
<br>
and means, but endowed with immense ambition, the Singularity
<br>
Institute, [Singularity Institute]. This Institute wants to be
<br>
entirely visible across the web. It offers incidentally a mailing
<br>
list, to which we subscribed ourselves, with nothing to lose, for the
<br>
evolution of the project. The best way to study this is to go to the
<br>
site intelligence.org which proposes a very complete dossier concerning
<br>
the motivations and the objectives pursued. The authors display a true
<br>
desire to share knowledge, which is necessary to praise in an epoch
<br>
where all the world barricades itself behind copyrights. Admittedly,
<br>
they seek by doing this to procure memberships (and material support),
<br>
but they take the reader seriously in supplying him the maximum of
<br>
possible explainations, opportunely for a theme that isn't easy. If
<br>
all university professors made this much effort to go to the front of
<br>
the public, in easily understandable terms, we wouldn't be at the
<br>
level of scientific inculture at which we find ourselves.
<br>
<p>The collection of this work, which is considerable, seems to discharge
<br>
from the original intuitions of a very young researcher, partially
<br>
self-educated, Eliezer S. Yudkowsky, of whom one can only admire the
<br>
precocity and penetration. One of our correspondants, Jacque de
<br>
Pasquier, informed us of the French translation, published on the site
<br>
Transition, of an article of his, written mainly in 1996, that is to
<br>
say at the age of 16: Staring into the Singularity:
<br>
<a href="http://dtext.com/transition/yudkowsky/yudkowsky1.html">http://dtext.com/transition/yudkowsky/yudkowsky1.html</a>. One finds the
<br>
principal elements of this article, presented in a scientific fashion,
<br>
in the pages published by the site. Eliezer Yudkowsky is today
<br>
employed full-time by the Singularity Institute. He develops
<br>
conceptions there that will drive in the near future to the take off
<br>
of the aforementioned computer engineering project.
<br>
<p>Of what does the project consist?
<br>
<p>First, what is the Singularity? The page [What is the Singularity]
<br>
<a href="http://www.intelligence.org/what-singularity.html">http://www.intelligence.org/what-singularity.html</a> defines it as the
<br>
creation by technological means of an intelligence more than human, or
<br>
super-intelligence. The authors of the project don't innovate on this
<br>
point. They continue the previsions made by American futurist
<br>
information technology specialists that we've often cited in our
<br>
review: Ray Kurzweil, Hans Moravec notably. The coming years will see
<br>
(excluding catastrophe) the capacities of components, networks, and
<br>
software continue to augment to the rythm summarized by Moore's famous
<br>
law (performance doubling every 18 to 24 months and corresponding
<br>
prices falling). It follows that computer and robots, provided such
<br>
resources, will be possible in a few years (10 to 15 years),
<br>
theoretically, of performances at least equal to that of the current
<br>
human brain.
<br>
<p>Moreover, starting from a certain concentration of resources in time
<br>
and space, one will see probably the organization of self-improving
<br>
phenomena uniformly accelerated. In the material domain will appear
<br>
mixed systems, artificial and biological, able to remedy themselves
<br>
only of their defects, to repair themselves, and later to assemble
<br>
themselves, as life knew how to do after millions of years of
<br>
evolution. It will be the same for software. Successive generations of
<br>
programs will appear in rapid rythm, constantly better adapted,
<br>
constantly more improved in cognitive contents. In other words, the
<br>
slow rythms of genetic evolution and natural culture will be replaced
<br>
by continuously accelerated artificial evolution. Hence the term
<br>
Singularity. Just as, following the cosmological singularity that
<br>
preceded the Big Bang, the universe as we know it developed in a few
<br>
billions years, likewise, following this new founding event that will
<br>
be the technological Singularity thus described, a new type of
<br>
markedly artificial evolution will appear on Earth, before scattering
<br>
eventually in the Cosmos.
<br>
<p>What then for humanity? In good logic, the humans will not remain at
<br>
their current mental and phsyical level. They will be able to join the
<br>
events happening following the artificial Singularity, since they will
<br>
be able to obtain bodies and brains of considerably augmented
<br>
capacities. Hence the concepts of posthumanity or transhumanity. The
<br>
pessimists fear that psychologies, determined by still-unchanged
<br>
heredity, will not improve as far, which will open rather sinister
<br>
perspectives, not only for humanity but for life on Earth. For the
<br>
optimists, on the contrary, humans thus augmented will apply their
<br>
super-intelligence and their super-ordinary forms to the improvement
<br>
of life on Earth, to the benefit not only of the whole of humanity to
<br>
the whole of living species and the great ecological equilibria.
<br>
<p>But, for this favorable result to be conceivable, it will be necessary
<br>
for humans to use some common sense. If the evolution of primary
<br>
technologies appears in the classical Darwinian style, that is, in the
<br>
style of chance and selection, all sorts of psychological and physical
<br>
organizations might appear. If, on the contrary, humans try from
<br>
maintaining the orientation of evolution in function of values that
<br>
they consider must be saved or made to appear, posthumanity could mark
<br>
progress compared to present humanity.
<br>
<p>It is consequently necessary, without waiting, to engage in the way of
<br>
practical work, taking hold of the fact that technological evolution
<br>
doesn't wait but on the contrary accelerates, as indicated above. It
<br>
is here that the proposals of the Singularity Institute intervene.
<br>
<p>Two domains of research are already open: that of physical systems:
<br>
electronic components, networks, diverse materials; and that of
<br>
software. The first will largely call upon nanotechnologies and later
<br>
quantum computers. But the investments for producing auto-adaptive and
<br>
auto-reproductive systems will be considerable, out of reach of small
<br>
organizations. In the domain of software, with computational resources
<br>
relatively reduced, it is on the contrary possible to develop more and
<br>
more ambitious applications and systems. Several technologies could be
<br>
used to this end: direct interfaces between brain and machine, genetic
<br>
engineering permitting the obtainment of more efficient brains. They
<br>
will improve the speed of information processing, the number of the
<br>
active neurons, the extent of connections between cerebral lobes, the
<br>
performance of sensorimotor input-output. But seeing the risks and
<br>
difficulties that these technologies present today, one conceives that
<br>
the promoters of the project prefer to stay with AI. It is
<br>
nevertheless necessary that this will be truly in breaking with the
<br>
current AI, very centered on utilitarian applications of an industrial
<br>
nature. It's necessary to define an AI that can become as budding, as
<br>
auto-complexifying as natural intelligence -- but this in a time of
<br>
several years and not steps to the course of a process of several
<br>
millions of years. Several technologies exist at the interior of AI.
<br>
It seems that the authors of the project favor those of multi-agent
<br>
systems incorporated on networks of microcomputers. It's the easiest
<br>
to implement.
<br>
<p>Work of this nature obliges, as we have known for a long time, to
<br>
question in profoundness what intelligence and consciousness are in
<br>
nature, in order to make what follows better than what precedes. AI
<br>
being a creation of human intelligence, it can thus in turn improve
<br>
human intelligence, in a cycle repeated without end. This supposes an
<br>
analysis of what intelligence is today. The page
<br>
<a href="http://www.intelligence.org/LOGI/">http://www.intelligence.org/LOGI/</a> proposes the first elements of such an
<br>
analysis, in distinguishing the principal levels hierarchically
<br>
encased, relative to the treatment of elementary information, of the
<br>
sensorial messages, of concepts, of ideas and finally of reasoning or
<br>
discourse. This has nothing in itself of originality, but that which
<br>
is interesting is the fashion in which the type of AI proposed could
<br>
improve natural cognitive processes.
<br>
<p>Can human intelligence today conceive of an improved, or simply
<br>
different, intelligence? More generally, can it conceive of an
<br>
improved society, such in complexity as in functionalities and
<br>
rendered services, by relation to society today? The exercises of
<br>
science-fiction show therein a distressing lack of imagination. One is
<br>
restricted to extrapolate to the ridicule of current features. The
<br>
pre-hominid primates would not have been able to imagine our
<br>
contemporary society, nor would our grandfathers for that matter. It
<br>
is therefore necessary to put in place an auto-adaptive device of
<br>
development that permanently revises its ambitions and its means in
<br>
function of continually obtained results.
<br>
<p>We will not go into the details of the method being implemented by the
<br>
work of the Institute. The page
<br>
<a href="http://www.intelligence.org/LOGI/seedAI.html">http://www.intelligence.org/LOGI/seedAI.html</a> specifies it and the reader
<br>
will have to adjourn to there. One can translate [Seed AI] as
<br>
auto-generating or seminal AI, in the sense that its developments give
<br>
rise to themselves through repetition of experience.
<br>
<p>Let us add that the promoters of the project often insist that these
<br>
developments remain controled by a volition constantly readjusted to
<br>
humanism. It's necessary to make an AI friendly, or [friendly]. This
<br>
aims to disarm increasingly frequent criticisms expressed with regard
<br>
to uncontrolled devlopment of technologies and systems, whether it is
<br>
in regard to nanotechnologies, robotics, or bionics. The page
<br>
[Friendly AI] <a href="http://intelligence.org/friendly/">http://intelligence.org/friendly/</a> describes in great detail
<br>
the technical and functional specifications of the project. We leave
<br>
the reader to the computer scientists. On the qualifier of [friendly],
<br>
friendly, one can't help but be a bit sceptical. Nothing is ever
<br>
absolutely friendly in the world, including software. There's always a
<br>
bit of predation mixed in. But one cannot deny to the authors of the
<br>
project a displayed will of sharing knowledge, put to the service of a
<br>
certain number of objectives aiming to improve inter-human relations.
<br>
<p>The site is constantly in evolution and refinement, which gives much
<br>
to think about concerning the strong work ethic of its principal
<br>
author, E. Yudkovsky [sic]. The latest text available to the date of
<br>
writing of May 2004 is entitled [Collective Volition]
<br>
<a href="http://intelligence.org/friendly/collective-volition.html">http://intelligence.org/friendly/collective-volition.html</a>. The author
<br>
anounced he prefers from now on, to the term of [Friendly AI], that of
<br>
[Friendly Really Powerful Optimization Process]... which needs no
<br>
translation.
<br>
<p>What to think of it?
<br>
<p>The sceptics will see all of this to be an illusion of some
<br>
impassioned youths, to be a machine for acquiring a bit of fame and
<br>
money, to be one of many products of an intoxication campaign looking
<br>
to convince the world that America continues to lay out a substantial
<br>
intellectual advance permitting it to claim leadership of the world.
<br>
We will not give way to these facilities. Due to lack of time and
<br>
means, we don't pretend to appraise the technical quality of these
<br>
documents and abundant information,  further than the first
<br>
impressions which appear promising. It would seem to us nevertheless
<br>
necessary to look there more closely because, as we said, the
<br>
enterprise could take a great range, scientific but also political.
<br>
<p>The project consisting of attempts to develop an advanced or very
<br>
advanced version of AI appears excellent to us, and to come at its
<br>
time. AI today takes pleasure in research that is compartmentalized,
<br>
utilitarian, without care to communicate with the public, entirely
<br>
without vision. This is especially the case in France. Reading the
<br>
documents supplied by the Singularity Institute represent in this
<br>
regard a true fountain of youth. We realize this could be a great AI
<br>
program able to optimize constantly enriched resources provided by
<br>
technology. We see equally that such a great program would undoubtedly
<br>
require a considerable budget. Many small teams working in network
<br>
could rapidly obtain important results, as long as they had made good
<br>
organizational decisions. We also think that at least at the
<br>
beginning, much work would have to be made benevolently by the
<br>
programmers putting  some resources in common in the grid style,
<br>
parallel to their professional activities. If it will have to still
<br>
wait for public or private financing to commence working, nothing
<br>
would ever be done. That's a little lesson gained from the example
<br>
given by the Singularity Institute.
<br>
<p>But, to suppose that in Europe (or even in France) some AI specialists
<br>
are interested in such an initiative, what should they do? Two views
<br>
are possible, after a serious evaluation of scientific loading of the
<br>
steps and documents proposed by the Institute.
<br>
- to make contact with E. Yudkowsky's team, as the site invites, and
<br>
negotiate a possible collaboration (necessarily in teleprocessing)
<br>
- on identical specifications or very close relations, develop only
<br>
original solutions, which does not impede upon maintaining contact
<br>
with the Institute.
<br>
<p>Let us add, for those who are not specialists in the developments of
<br>
AI in the United States, that various researchers have undertaken for
<br>
several years, in the academic framework, developing ambitious
<br>
versions of AI. It is also, evidently, a gamble for the security and
<br>
defense systems, but information is rarely available.
<br>
<p>In any event, if some of our readers want to deepen this perspective
<br>
and wish to make it known, we would be happy to publish their comments
<br>
and proposals.
<br>
<p>© Automates Intelligents 2004
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10344.html">Keith Henson: "Wired"</a>
<li><strong>Previous message:</strong> <a href="10342.html">Metaqualia: "Re: Yehuda Yudkowsky, 1985-2004"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10344.html">Keith Henson: "Wired"</a>
<li><strong>Reply:</strong> <a href="10344.html">Keith Henson: "Wired"</a>
<li><strong>Reply:</strong> <a href="10345.html">Damien Broderick: "Re: Wired"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10343">[ date ]</a>
<a href="index.html#10343">[ thread ]</a>
<a href="subject.html#10343">[ subject ]</a>
<a href="author.html#10343">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
