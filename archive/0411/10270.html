<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Calculemus</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Calculemus">
<meta name="Date" content="2004-11-10">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Calculemus</h1>
<!-- received="Wed Nov 10 09:01:42 2004" -->
<!-- isoreceived="20041110160142" -->
<!-- sent="Wed, 10 Nov 2004 11:01:35 -0500" -->
<!-- isosent="20041110160135" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Calculemus" -->
<!-- id="JNEIJCJJHIEAILJBFHILEEBKCMAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="41920497.9020007@or.uni-bonn.de" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Calculemus"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Wed Nov 10 2004 - 09:01:35 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10271.html">Keith Henson: "Re: META: Memes and War [was: Tomorrow is a new day]"</a>
<li><strong>Previous message:</strong> <a href="10269.html">Christian Szegedy: "Re: Calculemus"</a>
<li><strong>In reply to:</strong> <a href="10269.html">Christian Szegedy: "Re: Calculemus"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10272.html">Christian Szegedy: "Re: Calculemus"</a>
<li><strong>Reply:</strong> <a href="10272.html">Christian Szegedy: "Re: Calculemus"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10270">[ date ]</a>
<a href="index.html#10270">[ thread ]</a>
<a href="subject.html#10270">[ subject ]</a>
<a href="author.html#10270">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi Christian,
<br>
<p><em>&gt; I don't try to pretend being an expert in this area. I do *not*
</em><br>
<em>&gt; have my own
</em><br>
<em>&gt; answer to AI, the Universe and Everything.
</em><br>
<em>&gt; However, Hutters and Schmidhubers works are good examples of such
</em><br>
<em>&gt; approaches. I do not want to suggest that the &quot;Goedel machine&quot; is
</em><br>
<em>&gt; practical (I expressed my critiques on this list), still I think that the
</em><br>
<em>&gt; direction is right.
</em><br>
<p>OK, that's reasonable.  I disagree but, well, time will tell...
<br>
<p>I think their work is beautiful theoretically but isn't going to lead to
<br>
anything practical, ever... I think that huge-resources AI and
<br>
pragmatic-resources AI are very significantly different problems...
<br>
<p><em>&gt; There are  other randomized approaches: for example the
</em><br>
<em>&gt; famous, deep and surprising  PCP-Theorem states that
</em><br>
<em>&gt; every mathematical proof can be checked in polynomial
</em><br>
<em>&gt; tiime with arbitrary high probability by looking at only a
</em><br>
<em>&gt; *constant number* of bits of a sufficiently transformed form of
</em><br>
<em>&gt; the proof (the transformation can be performed in polynomial time).
</em><br>
<em>&gt; That is, for every epsilon, there is an N such that you have to look
</em><br>
<em>&gt; at only N randomly chosen bits of the proof to be able to say
</em><br>
<em>&gt; with 1-epsilon probability that it is correct.
</em><br>
<em>&gt; Keep in mind that  the proof can be arbitrarily long!
</em><br>
<p>This is interesting indeed, but I don't know of any work that makes this
<br>
practically useful, do you?  If so I'd love to hear about it.
<br>
<p>Do you think this will ever be usable as a practical basis for AI work?
<br>
<p>It's all a question of how big the constant number of bits N is, and how big
<br>
the polynomial is, right?
<br>
<p>Suppose epsilon = .01, then do you know what is N (for some standard model
<br>
of computation), and do you have a bound on the polynomial?
<br>
<p><em>&gt; My point is that approximative and stochastic methods are not
</em><br>
<em>&gt; incompatible with theoretically justified mathematics and this applies
</em><br>
<em>&gt; to formal deduction too, since theorem-proving can also be formulated
</em><br>
<em>&gt; as a discrete optimization problem.
</em><br>
<p>In principle, this is true, but so far as I know the theoretically justified
<br>
math is not of any use for making practical algorithms for general AI right
<br>
now.
<br>
<p>I'd be happy to be proved wrong, for sure.
<br>
<p>For instance, we make a lot of use of a variant of Martin Pelikan's
<br>
&quot;Bayesian Optimization Algorithm&quot; in Novamente.  We apply a BOA variant to
<br>
combinatory logic expressions using a special set of supercombinators.  It
<br>
seems to work well, and we have reason to hope this method can be a key part
<br>
of a general AI.
<br>
<p>But theoretical math doesn't seem useful yet for answering the really
<br>
essential questions we have, such as: &quot;For problems of some particular
<br>
character (e.g. recognizing objects among a set of pictures, learning
<br>
procedures to carry out certain actions in certain environments, etc.), how
<br>
long will BOA take to converge to an answer that's within epsilon of
<br>
optimal, based on a population size of N candidate instances?&quot;  We've used
<br>
some nice though fairly shallow math to do stuff like prove that simplified
<br>
combinator-expression formats have general power, but contemporary math
<br>
seems impotent to even start addressing the questions that really interest
<br>
us.
<br>
<p>Contemporary math has failed even to probe the interesting questions about
<br>
the behavior of the simple genetic algorithm. David Goldberg has done some
<br>
nice stuff that's restricted to particular fitness functions, and Michael
<br>
Vose gave a beautiful treatment of the GA as population size tends to
<br>
infinity (much improving on a 1993 paper of mine on the topic), but this
<br>
stuff doesn't really touch the important questions of how big a pop size you
<br>
need and how many generations it takes to get convergence to a near-optimal
<br>
solution on practical problems.
<br>
<p><em>&gt; I also think that the gap between timeless and stateful problems are
</em><br>
<em>&gt; not so huge as you suggest. The control-theory is also a very well
</em><br>
<em>&gt; established area of mathematical optimization and it deals exaclty
</em><br>
<em>&gt; with these type of problems.
</em><br>
<p>Yeah, but control theory totally falls apart when you start dealing with
<br>
situations of significant complexity.  For instance, control theory helps
<br>
for fixed-arm robots but it's almost useless for mobile robotics, where
<br>
everyone consequently relies on heuristic methods.
<br>
<p><em>&gt;  From a formalist point of view, the  functional programming
</em><br>
<em>&gt; community developed the notion of monads which allows
</em><br>
<em>&gt; to embed stateful computations into completely
</em><br>
<em>&gt; statelessly defined (purely functional) programs. This simplifies
</em><br>
<em>&gt; the reasoning about the correctness of programs with side-effects
</em><br>
<em>&gt; and allows to look at such computations in a stateless way.
</em><br>
<em>&gt; (In fact, that state is not complitely eliminated, but merely made
</em><br>
<em>&gt; explicit.)
</em><br>
<em>&gt;
</em><br>
<em>&gt; A nice thing about functional programming is that it narrows the
</em><br>
<em>&gt; gap between programs and logic (formal reasoning).: Functional
</em><br>
<em>&gt; programs can be viewed as mathematical formulas and can be
</em><br>
<em>&gt; manipulated, reasoned about and executed at the same time.
</em><br>
<em>&gt; The drawback, of course, is that the resource-usage is hard
</em><br>
<em>&gt; to argue about. As the saying goes: &quot;A LISP programmer knows
</em><br>
<em>&gt; the value of everything and the cost of nothing.&quot; I think that
</em><br>
<em>&gt; this is not necessary and one could extend the type-sysytem of
</em><br>
<em>&gt; functional programs to incorporate information about the resource
</em><br>
<em>&gt; usage of functions. This is of course a hard topic, since it would
</em><br>
<em>&gt; need more sopisticated formal reasoning tools to make it feasible.
</em><br>
<p>Yeah, we've actually done something like this with Novamente and it's
<br>
cool -- our representation of complex procedures and patterns is based on a
<br>
beefed-up version of combinatory logic (which is the math underlying some
<br>
functional programming compilers).
<br>
<p><em>&gt; I would mostly agree, but I would stress that sufficient interaction
</em><br>
<em>&gt; between formal deduction and optimization could be of great relevance.
</em><br>
<em>&gt; I believe that this interaction must be mutual: the deduction subsystem
</em><br>
<em>&gt; should make use of the optimization methods and argue about their
</em><br>
<em>&gt; efficiency at the same time.  It should be able to access the practical
</em><br>
<em>&gt; performance results of the optimization and also rewrite itself.
</em><br>
<em>&gt; A formal reasonong system should be able to perform experients
</em><br>
<em>&gt; and formulate hypotheses. The usage of functional programming could
</em><br>
<em>&gt; be practically useful in this reagrd, since it narrows the gap between
</em><br>
<em>&gt; formulas and programs.
</em><br>
<p>Yes! our intuitions agree here, and this is very close to what we're doing
<br>
in Novamente...
<br>
<p>We do deduction using a probabilistic inference framework called
<br>
Probabilistic Term Logic (PTL), and we do optimization using the Bayesian
<br>
Optimization Algorithm.  So they two can be glued together using the common
<br>
language of probability theory.
<br>
<p>This week we are actually merging the PTL branch of Novamente's codebase
<br>
with the BOA branch for the first time ;-)
<br>
<p><p><em>&gt; To test these ideas, I have designed an extremely simple
</em><br>
<em>&gt; yet powerful  fully reflective functional programming language
</em><br>
<em>&gt; (I called it *BLess*, which stands for &quot;Be less!&quot;) It is currently
</em><br>
<em>&gt; being implemented in OCaml. (A first preview very rudimentary
</em><br>
<em>&gt; version without type-checking is available.)
</em><br>
<p>Interesting -- more parallels with our own work.
<br>
<p>As syntactic sugar, we are working with our own language called Sasha,
<br>
designed by Luke Kaiser.  Sasha is a derivative of the language Nemerle that
<br>
Luke and his friends wrote in 2002-2003, and Nemerle is itself a derivative
<br>
of OCaml.  So for short, we have an OCaml-type language that compiles into
<br>
combinator trees, which in turn can be loaded into NOvamente to form
<br>
internal &quot;Novamente nodes and links&quot;...
<br>
<p><p><em>&gt; The current proof of concept (not yet ready) implementation is
</em><br>
<em>&gt; a very  inefficient interpreter, I have plans to compile BLess
</em><br>
<em>&gt; programs to OCaml code, which can be compiled to efficient
</em><br>
<em>&gt; native assemble.
</em><br>
<p>Very cool!  Is there more online information about Bless somewhere?
<br>
<p>If you can compile Bless to OCaml, then you could probably compile it to
<br>
Sasha as well, and Bless programs could then be loaded into Novamente as
<br>
combinator expressions ;-)
<br>
<p>-- Ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10271.html">Keith Henson: "Re: META: Memes and War [was: Tomorrow is a new day]"</a>
<li><strong>Previous message:</strong> <a href="10269.html">Christian Szegedy: "Re: Calculemus"</a>
<li><strong>In reply to:</strong> <a href="10269.html">Christian Szegedy: "Re: Calculemus"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10272.html">Christian Szegedy: "Re: Calculemus"</a>
<li><strong>Reply:</strong> <a href="10272.html">Christian Szegedy: "Re: Calculemus"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10270">[ date ]</a>
<a href="index.html#10270">[ thread ]</a>
<a href="subject.html#10270">[ subject ]</a>
<a href="author.html#10270">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
