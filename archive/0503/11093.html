<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Lojban and AI</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Lojban and AI">
<meta name="Date" content="2005-03-14">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Lojban and AI</h1>
<!-- received="Mon Mar 14 04:59:37 2005" -->
<!-- isoreceived="20050314115937" -->
<!-- sent="Mon, 14 Mar 2005 06:59:06 -0500" -->
<!-- isosent="20050314115906" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Lojban and AI" -->
<!-- id="JNEIJCJJHIEAILJBFHILKELGEDAA.ben@goertzel.org" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="470a3c5205031321255eea2035@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Lojban%20and%20AI"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Mon Mar 14 2005 - 04:59:06 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11094.html">Eliezer S. Yudkowsky: "Re: Overconfidence and meta-rationality"</a>
<li><strong>Previous message:</strong> <a href="11092.html">Tennessee Leeuwenburg: "Evolution and (human) Morality"</a>
<li><strong>In reply to:</strong> <a href="11091.html">Giu1i0 Pri5c0: "Re: Lojban and AI"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11093">[ date ]</a>
<a href="index.html#11093">[ thread ]</a>
<a href="subject.html#11093">[ subject ]</a>
<a href="author.html#11093">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; I have been interested in Lojban for a long time but I never found the
</em><br>
<em>&gt; time to learn more. I remember reading that Lojban was explicitly
</em><br>
<em>&gt; designed with applications to AI in mind.
</em><br>
<em>&gt; Of course if Lojban is used to interface with AIs on the basis that
</em><br>
<em>&gt; its easier to parse for the AI, we are moving a difficult issue from
</em><br>
<em>&gt; the computational system to the external world (documents have to be
</em><br>
<em>&gt; translated in Lojban and operators have to be trained in Lojban), and
</em><br>
<em>&gt; it is not very clear to me why this makes sense. Of course if parsing
</em><br>
<em>&gt; natural language proves really beyond our skills, and parsing Lojban
</em><br>
<em>&gt; does not, then it makes perfect sense.
</em><br>
<p>It is clear to me that teaching an AI natural language is NOT fundamentally
<br>
&quot;beyond our skills.&quot;
<br>
<p>I am in the following position.
<br>
<p>I believe I have a correct design for an AGI system, but I also believe it
<br>
will take a substantial amount of work -- including programming, testing,
<br>
tuning, algorithm-tweaking and *teaching* -- to turn this design into a
<br>
working AGI system with human-level intelligence.
<br>
<p>I currently have close to zero funding oriented toward this AGI project (and
<br>
am grateful to those who have invested or donated a little, so that the
<br>
amount isn't exactly zero...).
<br>
<p>I've been trying to get the job done &quot;along the way&quot; by reusing tools built
<br>
for commercial narrow-AI projects, but this hasn't worked out as well as
<br>
hoped.  We have built plenty of tools useful for both narrow AI and AGI, but
<br>
what we're left with now is a big chunk of pure-AGI work that can't be done
<br>
under the guise of any commercial narrow-AI project.
<br>
<p>So I'm thinking hard about ways to reduce the amount of man-years required
<br>
to get from here (AGI design + software framework + useful collection of
<br>
tools within that framework) to there (working AGI that can think like a
<br>
human toddler, for a start).  I know I can't reduce it that close to zero,
<br>
but the smaller the better ... every little bit helps.
<br>
<p>My assumption is that once we have created an AI with human-toddler-level
<br>
intelligence, the next stage will be a lot easier from an AI-science
<br>
perspective, and the nasty issues will be the ones Eliezer has often focused
<br>
on -- control, ethics, and so forth.
<br>
<p>So, my current estimation is that the quickest path to a AI system with
<br>
human-toddler-level intelligence may well be to make a system that interacts
<br>
with humans in a 3D simulation-world (Ari Heljakka is currently building us
<br>
a nice open-source one, using the CrystalSpace game-world toolkit), and
<br>
communicates with humans about what it's doing using Lojban.
<br>
<p>This is not because using English instead of Lojban is fundamentally
<br>
difficult.  It's because -- if one wants to take an approach where one
<br>
&quot;seeds&quot; experiential language learning with some hard-wired linguistic
<br>
knowledge -- then there's a lot more of English knowledge to wire in, since
<br>
English is a much more complex language.  Which means a lot more for the AI
<br>
to unlearn/adapt as its language understanding gradually becomes more
<br>
experientially grounded, thru its interactions with humans.
<br>
<p>As I keep saying, this is a pragmatic point rather than a fundamental point.
<br>
<p><em>&gt;From my point of view, if I can shave say 5-10 man-years of
</em><br>
development/tuning/teaching from the path to toddler-level AI by doing the
<br>
first teaching in Lojban rather than English, this is very worthwhile.
<br>
<p>Compared to making an AI toddler fluent in ANY human language (including
<br>
Lojban), teaching an AI toddler a second language is gonna be a piece of
<br>
cake...
<br>
<p>The only really good counterargument I can see to the perspective I'm
<br>
presenting here would be the following:
<br>
<p>a) the whole idea of a hybrid approach (wiring in some linguistic knowledge
<br>
to seed experiential learning) is wrong: everything has to be done via
<br>
experiential learning
<br>
<p>b) if an AI is too dumb to learn English rapidly and easily, then it's too
<br>
dumb to learn to think anyway, even if it *is* smart enough to learn some
<br>
Lojban basics due to Lojban's simplicity
<br>
<p>I don't really agree with this counter-perspective, but I don't have a
<br>
convincing disproof.
<br>
<p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11094.html">Eliezer S. Yudkowsky: "Re: Overconfidence and meta-rationality"</a>
<li><strong>Previous message:</strong> <a href="11092.html">Tennessee Leeuwenburg: "Evolution and (human) Morality"</a>
<li><strong>In reply to:</strong> <a href="11091.html">Giu1i0 Pri5c0: "Re: Lojban and AI"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11093">[ date ]</a>
<a href="index.html#11093">[ thread ]</a>
<a href="subject.html#11093">[ subject ]</a>
<a href="author.html#11093">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
