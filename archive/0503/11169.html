<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: There is No Altruism</title>
<meta name="Author" content="Keith Henson (hkhenson@rogers.com)">
<meta name="Subject" content="RE: There is No Altruism">
<meta name="Date" content="2005-03-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: There is No Altruism</h1>
<!-- received="Thu Mar 24 18:51:47 2005" -->
<!-- isoreceived="20050325015147" -->
<!-- sent="Thu, 24 Mar 2005 20:49:54 -0500" -->
<!-- isosent="20050325014954" -->
<!-- name="Keith Henson" -->
<!-- email="hkhenson@rogers.com" -->
<!-- subject="RE: There is No Altruism" -->
<!-- id="5.1.0.14.0.20050324195051.0339aec0@pop.brntfd.phub.net.cable.rogers.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="JNEIJCJJHIEAILJBFHILOEMKEEAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Keith Henson (<a href="mailto:hkhenson@rogers.com?Subject=RE:%20There%20is%20No%20Altruism"><em>hkhenson@rogers.com</em></a>)<br>
<strong>Date:</strong> Thu Mar 24 2005 - 18:49:54 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11170.html">Keith Henson: "Re: There is No Altruism"</a>
<li><strong>Previous message:</strong> <a href="11168.html">entropy@farviolet.com: "RE: There is No Altruism"</a>
<li><strong>In reply to:</strong> <a href="11162.html">Ben Goertzel: "RE: There is No Altruism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11167.html">Keith Henson: "Re: There is No Altruism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11169">[ date ]</a>
<a href="index.html#11169">[ thread ]</a>
<a href="subject.html#11169">[ subject ]</a>
<a href="author.html#11169">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
At 12:21 PM 24/03/05 -0500, you wrote:
<br>
<p><em>&gt; &gt; I don't think I'd take oblivion for any purpose, even
</em><br>
<em>&gt; &gt; to save ten other people. Although I'd really love to
</em><br>
<em>&gt; &gt; be that philosophical, I just can't pay my life for
</em><br>
<em>&gt; &gt; ideals like utilitarianism.
</em><br>
<em>&gt;
</em><br>
<em>&gt;I believe you.
</em><br>
<em>&gt;
</em><br>
<em>&gt;However, some feel differently.  I know several individuals, each of whom
</em><br>
<em>&gt;*would* trade their lives in order to save 10 random strangers with whom
</em><br>
<em>&gt;they have minimal genetic relatedness -- an action that would go against the
</em><br>
<em>&gt;interest of their selfish genome as well as their selfish organism.
</em><br>
<p>That's actually to be expected, but if you look deeper, it isn't so much 
<br>
against the gene's interest after all, particularly in the environment in 
<br>
which we evolved.
<br>
<p>One factor is that people in those days didn't jump off cliffs to certain 
<br>
death to save relatives, they took risks in an attempt to save close 
<br>
relatives and/or less related people.
<br>
<p>If you take a serious risk and come out alive, your status is enhanced 
<br>
(even if you die, the status of your relatives may be enhanced enough to 
<br>
partly make up for your loss--consider Todd Beamer, the guy who led the 
<br>
attack on the Flight 93 hijackers).  Now in the days in which most of our 
<br>
evolution occurred, status was highly associated with improved reproductive 
<br>
success, so taking the right kind of risks was rewarded by more children.
<br>
<p>Thus we are left with the psychological traits to take some kinds of risks 
<br>
for others.  (And in the days when this was selected, the people you were 
<br>
around were also your more or less close relatives.)
<br>
<p>And it certainly works.  My status has been enhanced by times I have taken 
<br>
risks to save people or property from fires.  My brother's was enhanced by 
<br>
saving a guy from drowning in rough surf off Hawaii.  (My brother is a 
<br>
really level headed guy.  He had rescue training and took as little risk as 
<br>
possible.  He tells me that if he had not been able to find proper gear, 
<br>
the guy would have drowned.  As he put it, there was no point in both of 
<br>
them dying.)
<br>
<p><em>&gt;You could argue this isn't &quot;true altruism&quot; because their goal may be
</em><br>
<em>&gt;personal satisfaction or personal ego-boosting or something, rather than
</em><br>
<em>&gt;&quot;pure altruism&quot; -- but I don't tend to find such arguments very meaningful.
</em><br>
<p>I am in agreement about the arguments lacking meaning.  Even if you do 
<br>
understand the reason people are heros, it's not like they ran a spread 
<br>
sheet on the pros and cons of saving someone, there just isn't time even if 
<br>
you could quantify all the factors.  And the fact that hero genes do better 
<br>
(or at least *did* do better) does not make them any less worthy of our 
<br>
respect.
<br>
<p>However, the theory problem with &quot;pure altruism&quot; is that psychological 
<br>
traits that only depress your &quot;inclusive fitness&quot; while enhancing unrelated 
<br>
others just don't close the evolution/selection loop.
<br>
<p><em>&gt;As far as I'm concerned, this is an example of genuine altruism, and it's
</em><br>
<em>&gt;not explained via the neo-Darwinist orthodoxy very well.  It's explained by
</em><br>
<em>&gt;the variant of evolutionary theory that emphasizes self-organization and
</em><br>
<em>&gt;dynamical attractors.
</em><br>
<p>As far as I know, neo-Darwin theory is &quot;dynamical attractors,&quot; shaped by 
<br>
millions of years as hunter gatherer tribes who got along in good times and 
<br>
killed each other when bad times were a-coming.
<br>
<p><em>&gt;Altruism (in the sense I'm using it here) is a psychological attractor, and
</em><br>
<em>&gt;the quasi-altruism that the selfish genome promotes has pushed some human
</em><br>
<em>&gt;brains toward that attractor.  Guiding AGI's into this psychological
</em><br>
<em>&gt;attractor will be an important topic in AGI psychology...
</em><br>
<p>There is also the need to clearly understand what's involved in the origin 
<br>
of human altruism.
<br>
<p>Of course, if you do understand it and talk about it you can expect to take 
<br>
a lot of flack.  For the most part people are very uncomfortable talking 
<br>
about the parts of our minds that are usually hidden from us.
<br>
<p>Keith Henson
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11170.html">Keith Henson: "Re: There is No Altruism"</a>
<li><strong>Previous message:</strong> <a href="11168.html">entropy@farviolet.com: "RE: There is No Altruism"</a>
<li><strong>In reply to:</strong> <a href="11162.html">Ben Goertzel: "RE: There is No Altruism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11167.html">Keith Henson: "Re: There is No Altruism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11169">[ date ]</a>
<a href="index.html#11169">[ thread ]</a>
<a href="subject.html#11169">[ subject ]</a>
<a href="author.html#11169">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:51 MDT
</em></small></p>
</body>
</html>
