<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Eliezer: unconvinced by your objection to safe boxing of &quot;Minerva AI&quot;</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Eliezer: unconvinced by your objection to safe boxing of &quot;Minerva AI&quot;">
<meta name="Date" content="2005-03-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Eliezer: unconvinced by your objection to safe boxing of &quot;Minerva AI&quot;</h1>
<!-- received="Mon Mar  7 23:55:49 2005" -->
<!-- isoreceived="20050308065549" -->
<!-- sent="Mon, 07 Mar 2005 22:55:29 -0800" -->
<!-- isosent="20050308065529" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Eliezer: unconvinced by your objection to safe boxing of &quot;Minerva AI&quot;" -->
<!-- id="422D4C61.1010203@pobox.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="033f01c5239b$6e40a300$8001a8c0@iter" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Eliezer:%20unconvinced%20by%20your%20objection%20to%20safe%20boxing%20of%20&quot;Minerva%20AI&quot;"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Mon Mar 07 2005 - 23:55:29 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10868.html">Daniel Radetsky: "Re: Eliezer: unconvinced by your objection to safe boxing of &quot;Minerva AI&quot;"</a>
<li><strong>Previous message:</strong> <a href="10866.html">Tennessee Leeuwenburg: "Re: My top-down strategy is now 100% complete."</a>
<li><strong>In reply to:</strong> <a href="10864.html">Peter de Blanc: "Re: Eliezer: unconvinced by your objection to safe boxing of &quot;Minerva AI&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10874.html">Daniel Radetsky: "Re: Eliezer: unconvinced by your objection to safe boxing of &quot;Minerva AI&quot;"</a>
<li><strong>Reply:</strong> <a href="10874.html">Daniel Radetsky: "Re: Eliezer: unconvinced by your objection to safe boxing of &quot;Minerva AI&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10867">[ date ]</a>
<a href="index.html#10867">[ thread ]</a>
<a href="subject.html#10867">[ subject ]</a>
<a href="author.html#10867">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Peter de Blanc wrote:
<br>
<em>&gt; Hi,
</em><br>
<em>&gt; 
</em><br>
<em>&gt; you seem to be saying that your AI has this concept of a mind, which it
</em><br>
<em>&gt; assumes must be a Bayesian rationalist, and so when it encounters a human
</em><br>
<em>&gt; being, it will not have anticipated a mind which is irrational. What seems
</em><br>
<em>&gt; more likely to me is that a mind-in-general would view a mind-in-general as
</em><br>
<em>&gt; just another type of system which can be manipulated into a desired state.
</em><br>
<p>*nod*
<br>
<p><em>&gt; You also asked for examples of what an AI could infer about humans from
</em><br>
<em>&gt; looking at its source code. Here are some, off the top of my head:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; - Look at the last modified dates. Humans take a long time to write code.
</em><br>
<em>&gt; - Human-written code contains many lengthy, ignorable comments; humans do
</em><br>
<em>&gt; not think in code.
</em><br>
<em>&gt; - Humans use long variable names; they need to be constantly reminded of
</em><br>
<em>&gt; what each variable is for.
</em><br>
<em>&gt; - Human code is highly modular, to the detriment of performance. By this and
</em><br>
<em>&gt; the above, humans have a small short-term memory.
</em><br>
<p>Depending on whether the code is compiled or interpreted, the first 
<br>
three items may not be available.
<br>
<p>But the last item will be available, and it and other structural cues 
<br>
are sufficient information (given sufficient computing power) to deduce 
<br>
that humans are fallible, quite possibly even that humans evolved by 
<br>
natural selection.
<br>
<p>We know a tremendous amount about natural selection on the basis of (a) 
<br>
looking at its handiwork (b) thinking about the math of evolutionary 
<br>
biology that systematizes the evidence, given the nudge from the evidence.
<br>
<p>One can equally well imagine a Minerva superintelligence (that is, a 
<br>
fully functional transhuman AGI created as pure code without any 
<br>
real-time interaction between the programmer and running AGI code) that 
<br>
studies its own archived original source code.  This is a smaller corpus 
<br>
than terrestrial biology, but studiable in far greater detail and much 
<br>
more tractable to its intelligence than is DNA to our own intelligence. 
<br>
&nbsp;&nbsp;I would not be surprised to see the Minerva SI devise a theory of 
<br>
human intelligence that was correct on all major points and sufficient 
<br>
to manipulation.
<br>
<p>The point is probably irrelevant.  A Minerva FAI seems to me to be three 
<br>
sigma out beyond humanly impossible.  I can just barely conceive of a 
<br>
Minerva AGI, but I would still call it humanly impossible.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10868.html">Daniel Radetsky: "Re: Eliezer: unconvinced by your objection to safe boxing of &quot;Minerva AI&quot;"</a>
<li><strong>Previous message:</strong> <a href="10866.html">Tennessee Leeuwenburg: "Re: My top-down strategy is now 100% complete."</a>
<li><strong>In reply to:</strong> <a href="10864.html">Peter de Blanc: "Re: Eliezer: unconvinced by your objection to safe boxing of &quot;Minerva AI&quot;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10874.html">Daniel Radetsky: "Re: Eliezer: unconvinced by your objection to safe boxing of &quot;Minerva AI&quot;"</a>
<li><strong>Reply:</strong> <a href="10874.html">Daniel Radetsky: "Re: Eliezer: unconvinced by your objection to safe boxing of &quot;Minerva AI&quot;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10867">[ date ]</a>
<a href="index.html#10867">[ thread ]</a>
<a href="subject.html#10867">[ subject ]</a>
<a href="author.html#10867">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:22:54 MST
</em></small></p>
</body>
</html>
