<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Overconfidence and meta-rationality</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Overconfidence and meta-rationality">
<meta name="Date" content="2005-03-10">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Overconfidence and meta-rationality</h1>
<!-- received="Thu Mar 10 18:54:18 2005" -->
<!-- isoreceived="20050311015418" -->
<!-- sent="Thu, 10 Mar 2005 17:53:38 -0800" -->
<!-- isosent="20050311015338" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Overconfidence and meta-rationality" -->
<!-- id="4230FA22.6030607@pobox.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20050311005314.492DA57EE8@finney.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Overconfidence%20and%20meta-rationality"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Thu Mar 10 2005 - 18:53:38 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10885.html">Jeff Medina: "SIAI Volunteer Meeting on Sunday, March 20, 3pm EST"</a>
<li><strong>Previous message:</strong> <a href="10883.html">maru: "Re: Overconfidence and meta-rationality"</a>
<li><strong>Maybe in reply to:</strong> <a href="../0502/10764.html">Eliezer S. Yudkowsky: "Re: Overconfidence and meta-rationality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10889.html">Eliezer S. Yudkowsky: "Re: Overconfidence and meta-rationality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10884">[ date ]</a>
<a href="index.html#10884">[ thread ]</a>
<a href="subject.html#10884">[ subject ]</a>
<a href="author.html#10884">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hal Finney wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt;&gt;The modesty argument is important in one respect.  I agree that when two 
</em><br>
<em>&gt;&gt;humans disagree and have common knowledge of each other's opinion (or a 
</em><br>
<em>&gt;&gt;human approximation of common knowledge which does not require logical 
</em><br>
<em>&gt;&gt;omniscience), *at least one* human must be doing something wrong.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I'd put it a little differently.  There's nothing necessarily wrong
</em><br>
<em>&gt; when two humans disagree and have common knowledge.  You have to add one
</em><br>
<em>&gt; more ingredient.  The people have to both be rational and honest, and,
</em><br>
<em>&gt; most importantly, they each have to believe that the other is rational
</em><br>
<em>&gt; and honest (and, I think, this has to be common knowledge).
</em><br>
<p>Suppose that one party is not rational.  I would call this, &quot;doing 
<br>
something wrong&quot;.
<br>
<p>We presume that both parties are honest because otherwise they are not 
<br>
&quot;disagreeing&quot; in the sense that I mean it, i.e., assigning different 
<br>
truth values.
<br>
<p>Suppose that one party is rational and the other party fails to realize 
<br>
this.  Then the second party has failed to arrive to the correct answer 
<br>
on a question of fact.  Again, &quot;something wrong&quot;.
<br>
<p>If they just haven't figured it out yet, then they aren't necessarily 
<br>
doing something wrong.  They may be doing something right that takes 
<br>
time to accumulate evidence and computationally process it.  If they 
<br>
take too long or demand too much evidence, the beisutsukai sensei shouts 
<br>
&quot;Too slow!&quot; and whacks them on the head with a stick.  Speed matters in 
<br>
any martial art, including rationality, the martial art of thinking.
<br>
<p><em>&gt; I would imagine that many cases of disagreement can be explained by
</em><br>
<em>&gt; each party privately concluding that the other is being irrational.
</em><br>
<em>&gt; They're just too polite to say so.  When they say, I guess we'll have
</em><br>
<em>&gt; to agree to disagree, they mean, you're being unreasonable and I don't
</em><br>
<em>&gt; want to argue with you any more because there's no point.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; But actually, we can sharpen Aumann's result.  It doesn't require
</em><br>
<em>&gt; assumptions about two people.  It is enough for one person to satisfy
</em><br>
<em>&gt; the conditions.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Aumann basically says (neglecting the part about priors) that it is
</em><br>
<em>&gt; impossible for a rational person to believe that he has a persistent
</em><br>
<em>&gt; disagreement with another person whom he believes to be rational, where
</em><br>
<em>&gt; the other person also believes the first person is rational.
</em><br>
<p>I am not sure this is correct.  Maybe there is an extension of Aumann 
<br>
that says this, but it's not in Aumann's original result, which presumes 
<br>
rationality (i.e., irrationality is not considered as an option). 
<br>
Aumann-ish results, as far as I can see, tend to be about Bayesians 
<br>
treating other Bayesian's opinions as bearing a specific evidential 
<br>
relationship to the question at hand - the signals wouldn't have to be 
<br>
beliefs; they could as easily be flags that waved with a certain 
<br>
likelihood ratio.  In fact, what else is a Bayesian's belief, but a kind 
<br>
of cognitive flag that waves at only the right time?
<br>
<p><em>&gt; Aumann is giving us a non-obvious piece of logic which we can follow in
</em><br>
<em>&gt; our own thought processes, independent of what anyone else does.  I can't
</em><br>
<em>&gt; fool myself into believing that I can agree to disagree with another
</em><br>
<em>&gt; person, while respecting him as a rational and honest person who offers
</em><br>
<em>&gt; the same respect towards me.  For me to hold this set of beliefs is a
</em><br>
<em>&gt; logical contradiction.  That's the lesson I draw from this set of results.
</em><br>
<p>I agree.  But I regard rationality as quantitative, not qualitative.  I 
<br>
can respect an above-average rationalist while still occasionally 
<br>
wanting to shout &quot;Too slow!&quot; and whack him with a stick.
<br>
<p><em>&gt; In a way, then, Aumann can be read as giving you license to feel
</em><br>
<em>&gt; contempt for others.  He's saying that it is mental hypocrisy (if that
</em><br>
<em>&gt; means anything!) to try to adopt that generous and polite stance I just
</em><br>
<em>&gt; described.  When we try to convince ourselves that we really believe
</em><br>
<em>&gt; this noble fiction (that the other person is rational and honest), we are
</em><br>
<em>&gt; lying to ourselves.  It's another case of self-deception.  The truth is,
</em><br>
<em>&gt; we don't respect the other person as rational and honest.  If we did,
</em><br>
<em>&gt; we wouldn't be ignoring his beliefs!  We think he's a fool or a knave.
</em><br>
<em>&gt; Probably both.  We're not so damn nice as we try to pretend to be,
</em><br>
<em>&gt; as we try to convince ourselves we are.
</em><br>
<p>Or you think that he's good and you're better.  That is also a 
<br>
self-consistent position to hold.  And if that is your position, you'd 
<br>
best not hide it from yourself - though based on my experience so far, I 
<br>
can't claim there will be any benefits forthcoming from public honesty 
<br>
about it.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10885.html">Jeff Medina: "SIAI Volunteer Meeting on Sunday, March 20, 3pm EST"</a>
<li><strong>Previous message:</strong> <a href="10883.html">maru: "Re: Overconfidence and meta-rationality"</a>
<li><strong>Maybe in reply to:</strong> <a href="../0502/10764.html">Eliezer S. Yudkowsky: "Re: Overconfidence and meta-rationality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10889.html">Eliezer S. Yudkowsky: "Re: Overconfidence and meta-rationality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10884">[ date ]</a>
<a href="index.html#10884">[ thread ]</a>
<a href="subject.html#10884">[ subject ]</a>
<a href="author.html#10884">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:22:54 MST
</em></small></p>
</body>
</html>
