<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: [SL4] AI Ethics &amp; Banning the Future.</title>
<meta name="Author" content="Patrick McCuller (pmcculler@kia.net)">
<meta name="Subject" content="RE: [SL4] AI Ethics &amp; Banning the Future.">
<meta name="Date" content="2000-02-16">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: [SL4] AI Ethics &amp; Banning the Future.</h1>
<!-- received="Wed Feb 16 22:04:14 2000" -->
<!-- isoreceived="20000217050414" -->
<!-- sent="Wed, 16 Feb 2000 22:08:34 -0500" -->
<!-- isosent="20000217030834" -->
<!-- name="Patrick McCuller" -->
<!-- email="pmcculler@kia.net" -->
<!-- subject="RE: [SL4] AI Ethics &amp; Banning the Future." -->
<!-- id="LOBBLDGHBFLPJDFBIPFEAELFELAA.pmcculler@kia.net" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="38AB467A.3E3FBEBF@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Patrick McCuller (<a href="mailto:pmcculler@kia.net?Subject=RE:%20[SL4]%20AI%20Ethics%20&amp;%20Banning%20the%20Future."><em>pmcculler@kia.net</em></a>)<br>
<strong>Date:</strong> Wed Feb 16 2000 - 20:08:34 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="21245.html">Marc Forrester: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>Previous message:</strong> <a href="21243.html">Eliezer S. Yudkowsky: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>In reply to:</strong> <a href="21241.html">Eliezer S. Yudkowsky: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="21245.html">Marc Forrester: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>Reply:</strong> <a href="21245.html">Marc Forrester: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#21244">[ date ]</a>
<a href="index.html#21244">[ thread ]</a>
<a href="subject.html#21244">[ subject ]</a>
<a href="author.html#21244">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
From: &quot;Patrick McCuller&quot; &lt;<a href="mailto:pmcculler@kia.net?Subject=RE:%20[SL4]%20AI%20Ethics%20&amp;%20Banning%20the%20Future.">pmcculler@kia.net</a>&gt;
<br>
<p><p><em>&gt; From: &quot;Eliezer S. Yudkowsky&quot; &lt;<a href="mailto:sentience@pobox.com?Subject=RE:%20[SL4]%20AI%20Ethics%20&amp;%20Banning%20the%20Future.">sentience@pobox.com</a>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;Tortured Norns&quot;
</em><br>
<em>&gt; <a href="http://www.geocities.com/SiliconValley/Park/2495/">http://www.geocities.com/SiliconValley/Park/2495/</a>
</em><br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The more I think about this, the less happy I am. Humans aren't terribly
<br>
moral to begin with; in a consequence-free environment, there is an
<br>
opportunity for great evil.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I tend to think that the first strong AI will have in the neighborhood of
<br>
10^9 lines of code, and require significant parallel processing. With any
<br>
luck, most people won't have access to enough hardware to be able to torture
<br>
strong AIs. This doesn't solve the fundamental problem though...
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Richard Dawkins recently voiced his support for the Humanist Manifesto 2000
<br>
(in the most recent issue of Reason Magazine.) He did so with an objection:
<br>
that it focused entirely on human beings and was, as he put it, speciest. He
<br>
wants to see a humanist morality that's more of a 'moral gradient' from
<br>
humans down to, I suppose, mold. Thus it is wrong to torture cats, but more
<br>
wrong to torture chimpanzees, and so on.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Presumably we could apply this moral gradient to software. I don't think I
<br>
could torture Visual Cafe (it sure tortures me), but integrated weak AIs
<br>
emulating, for instance, kittens, would count.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://foobar.starlab.net/~degaris/robokoneko/index.html">http://foobar.starlab.net/~degaris/robokoneko/index.html</a>
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Though I gather 'emulating' isn't exactly the right word.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In biological organisms, sufficient damage will cause death, and death is
<br>
usually permanent. In software, nobody can hear you scream. Over and over.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I think most humans could eventually be convinced not to hurt machine
<br>
intelligences, but some humans you might have to torture to death a few
<br>
times before it sinks in.
<br>
<p><p>Patrick McCuller
<br>
<p><p>--------------------------- ONElist Sponsor ----------------------------
<br>
<p>GET A NEXTCARD VISA, in 30 seconds.  Get rates as low as 0.0 percent 
<br>
Intro or 9.9 percent Fixed APR and no hidden fees. Apply NOW. 
<br>
&lt;a href=&quot; <a href="http://clickme.onelist.com/ad/NextcardCreative5">http://clickme.onelist.com/ad/NextcardCreative5</a> &quot;&gt;Click Here&lt;/a&gt;
<br>
<p>------------------------------------------------------------------------
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="21245.html">Marc Forrester: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>Previous message:</strong> <a href="21243.html">Eliezer S. Yudkowsky: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>In reply to:</strong> <a href="21241.html">Eliezer S. Yudkowsky: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="21245.html">Marc Forrester: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>Reply:</strong> <a href="21245.html">Marc Forrester: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#21244">[ date ]</a>
<a href="index.html#21244">[ thread ]</a>
<a href="subject.html#21244">[ subject ]</a>
<a href="author.html#21244">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:06 MDT
</em></small></p>
</body>
</html>
