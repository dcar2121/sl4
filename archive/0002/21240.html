<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: [SL4] AI Ethics &amp; Banning the Future.</title>
<meta name="Author" content="Marc Forrester (A1200@mharr.f9.co.uk)">
<meta name="Subject" content="[SL4] AI Ethics &amp; Banning the Future.">
<meta name="Date" content="2000-02-16">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>[SL4] AI Ethics &amp; Banning the Future.</h1>
<!-- received="Wed Feb 16 18:50:35 2000" -->
<!-- isoreceived="20000217015035" -->
<!-- sent="Wed, 16 Feb 2000 22:09:03 +0000" -->
<!-- isosent="20000216220903" -->
<!-- name="Marc Forrester" -->
<!-- email="A1200@mharr.f9.co.uk" -->
<!-- subject="[SL4] AI Ethics &amp; Banning the Future." -->
<!-- id="yam8081.162.1078412128@relay.f9.net.uk" -->
<!-- inreplyto="LOBBLDGHBFLPJDFBIPFEMEKOELAA.pmcculler@earthlink.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Marc Forrester (<a href="mailto:A1200@mharr.f9.co.uk?Subject=Re:%20[SL4]%20AI%20Ethics%20&amp;%20Banning%20the%20Future."><em>A1200@mharr.f9.co.uk</em></a>)<br>
<strong>Date:</strong> Wed Feb 16 2000 - 15:09:03 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="21241.html">Eliezer S. Yudkowsky: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>Previous message:</strong> <a href="21239.html">Patrick McCuller: "[SL4] AI &amp; the religious right"</a>
<li><strong>In reply to:</strong> <a href="21239.html">Patrick McCuller: "[SL4] AI &amp; the religious right"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="21241.html">Eliezer S. Yudkowsky: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>Reply:</strong> <a href="21241.html">Eliezer S. Yudkowsky: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#21240">[ date ]</a>
<a href="index.html#21240">[ thread ]</a>
<a href="subject.html#21240">[ subject ]</a>
<a href="author.html#21240">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
From: Marc Forrester &lt;<a href="mailto:A1200@mharr.f9.co.uk?Subject=Re:%20[SL4]%20AI%20Ethics%20&amp;%20Banning%20the%20Future.">A1200@mharr.f9.co.uk</a>&gt;
<br>
<p>Patrick McCuller: Wednesday 16-Feb-00
<br>
<em>&gt; Ever since the public reaction to Dolly, something's been itching at me:
</em><br>
<em>&gt; the legality of AI. The legal and moral implications of machine
</em><br>
intelligence
<br>
<em>&gt; need entire volumes to consider, but what concerns me from a developmental
</em><br>
<em>&gt; perspective is the possibility of an outright ban on strong AI research.
</em><br>
<p>Regarding the moral implications of machine intelligence,
<br>
what do we think they are?  Seems to me that we need to get
<br>
them very clear in our minds before we start messing about,
<br>
because there's no way we can rely on our sense of empathy
<br>
here - look how we as a species react to, say, Furbies and
<br>
lab rats.  Ass about face?  I think so.
<br>
<p>OTOH, the Hacker subset of humanity tends to vivisect
<br>
Furbies and treat rats with respect and often affection,
<br>
so maybe this isn't a disaster waiting to happen.. ?
<br>
<p>Hypothesis: You have a piece of software, running on a
<br>
massively parallel machine utterly unlike anything cast
<br>
in silicon today, but software nonetheless, an ephemeral
<br>
contruct of flickering patterns of numbers.
<br>
<p>It seems to have the intelligence of an advanced animal,
<br>
able to communicate through simple language and solve
<br>
puzzles for reward.
<br>
<p>What are the implications of:
<br>
<p>Stopping the program?
<br>
Deleting the program?
<br>
Pausing the program?
<br>
Making copies?
<br>
Rewinding its memory?
<br>
Creating its world?
<br>
Editing its mind?
<br>
<p>Well..  At least we really -are- playing god this time.
<br>
Is that a bad thing?  I move that it depends wether
<br>
you're intelligent enough to treat play seriously.
<br>
<p><em>&gt; I know this sounds a little silly,
</em><br>
<p>&quot;I'm sorry about this, I know it's a bit silly.&quot; [HAL 9000 :]
<br>
<p><em>&gt; When the (direct) possibility of strong AI becomes obvious,
</em><br>
<em>&gt; the religious right may go absolutely bonkers.  I think they
</em><br>
<em>&gt; will see AI as an enormous invasion of turf.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Any thoughts?
</em><br>
<p>Well..  I don't think it's just the Christpolitik bureau,
<br>
they take advantage of the FUD to grab power wherever they can,
<br>
but they're not creating it, people are genuinely getting scared
<br>
about the future.  Individually, most of the people I've met
<br>
seem to be in denial, but as societies, they seem to be aware,
<br>
because everyone's trying to put the brakes on.  Food and drug
<br>
administrations are given the power to dictate what people can
<br>
do with their own biochemistry, human fertility authorities
<br>
think they own your DNA, encryption software is classed as
<br>
firearms and everyone wants the Internet shut down and
<br>
replaced with an interactive Disney Channel.
<br>
<p>Fortunately, there's no central intelligence driving all this,
<br>
and so it amounts more to a mesh of annoying tripwires than a
<br>
brick wall.  If the Internet -is- ever closed down, we'll just
<br>
build a new one.  You can only halt progress by burning all
<br>
the books and killing all the smart people, and look what
<br>
happens to that kind of society in the long run.
<br>
<p>So: Yes, I think there will be massive popular resistance
<br>
to machine intelligence, I think the world's lawmakers and
<br>
institutions will create all kinds of difficulties and
<br>
inconveniences, but what I don't think is that it'll have
<br>
any real effect.  Loopholes = Legislation squared, and all
<br>
authorities have their perceived areas of jurisdiction,
<br>
outside which you can do entirely as you will.
<br>
<p>And there's a whole universe outside to play in.
<br>
<p>Maybe more.
<br>
<p><p>--------------------------- ONElist Sponsor ----------------------------
<br>
<p>Get what you deserve with NextCard Visa. Rates as low as 2.9 percent 
<br>
Intro or 9.9 percent Fixed APR, online balance transfers, Rewards 
<br>
credit you deserve! Apply now! Get your NextCard Visa at
<br>
&lt;a href=&quot; <a href="http://clickme.onelist.com/ad/NextcardCreative2">http://clickme.onelist.com/ad/NextcardCreative2</a> &quot;&gt;Click Here&lt;/a&gt;
<br>
<p>------------------------------------------------------------------------
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="21241.html">Eliezer S. Yudkowsky: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>Previous message:</strong> <a href="21239.html">Patrick McCuller: "[SL4] AI &amp; the religious right"</a>
<li><strong>In reply to:</strong> <a href="21239.html">Patrick McCuller: "[SL4] AI &amp; the religious right"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="21241.html">Eliezer S. Yudkowsky: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>Reply:</strong> <a href="21241.html">Eliezer S. Yudkowsky: "Re: [SL4] AI Ethics &amp; Banning the Future."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#21240">[ date ]</a>
<a href="index.html#21240">[ thread ]</a>
<a href="subject.html#21240">[ subject ]</a>
<a href="author.html#21240">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:06 MDT
</em></small></p>
</body>
</html>
