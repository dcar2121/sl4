<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [SL4] AI Ethics &amp; Banning the Future.</title>
<meta name="Author" content="Marc Forrester (SL4@mharr.force9.co.uk)">
<meta name="Subject" content="Re: [SL4] AI Ethics &amp; Banning the Future.">
<meta name="Date" content="2000-02-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [SL4] AI Ethics &amp; Banning the Future.</h1>
<!-- received="Tue Feb 22 15:59:45 2000" -->
<!-- isoreceived="20000222225945" -->
<!-- sent="Tue, 22 Feb 2000 21:01:00 +0000" -->
<!-- isosent="20000222210100" -->
<!-- name="Marc Forrester" -->
<!-- email="SL4@mharr.force9.co.uk" -->
<!-- subject="Re: [SL4] AI Ethics &amp; Banning the Future." -->
<!-- id="yam8087.10.1077546232@relay.f9.net.uk" -->
<!-- inreplyto="LOBBLDGHBFLPJDFBIPFEOENIELAA.pmcculler@kia.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Marc Forrester (<a href="mailto:SL4@mharr.force9.co.uk?Subject=Re:%20[SL4]%20AI%20Ethics%20&amp;%20Banning%20the%20Future."><em>SL4@mharr.force9.co.uk</em></a>)<br>
<strong>Date:</strong> Tue Feb 22 2000 - 14:01:00 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="21250.html">Patrick McCuller: "RE: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>Previous message:</strong> <a href="21248.html">Patrick McCuller: "RE: [SL4] AI Ethics"</a>
<li><strong>In reply to:</strong> <a href="21247.html">Patrick McCuller: "RE: [SL4] AI Ethics &amp; Banning the Future."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="21250.html">Patrick McCuller: "RE: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>Reply:</strong> <a href="21250.html">Patrick McCuller: "RE: [SL4] AI Ethics &amp; Banning the Future."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#21249">[ date ]</a>
<a href="index.html#21249">[ thread ]</a>
<a href="subject.html#21249">[ subject ]</a>
<a href="author.html#21249">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
From: Marc Forrester &lt;<a href="mailto:SL4@mharr.force9.co.uk?Subject=Re:%20[SL4]%20AI%20Ethics%20&amp;%20Banning%20the%20Future.">SL4@mharr.force9.co.uk</a>&gt;
<br>
<p>Patrick McCuller: Saturday 19-Feb-00
<br>
<em>&gt; I extrapolated assuming a first generation strong AI in 2010.
</em><br>
<em>&gt; I believe typical estimates of available processing power per
</em><br>
<em>&gt; cost unit still roughly follow Moore's law through 2010
</em><br>
<em>&gt; (give an order of magnitude to be safe.)
</em><br>
<p>Moore's law is the rate at which computers advance in the absence of major
<br>
paradigm shifts, such as replacing valves with transistors, or integrating
<br>
transistors into microcircuit chips.  The next shift will be from single
<br>
central processing units to massive parallel-processing on one chip,
<br>
the question is wether this happens before the arrival of strong AI,
<br>
or after it.  I think the global entertainment industry has the
<br>
resources to make it before.  Call it a 50/50 chance.
<br>
<p>You never know when the transistor will suddenly be replaced, either.
<br>
Moore's law tells us what -minimum- rate of progress we should expect and
<br>
plan for if things are conservative and status quo.  I wouldn't bet on the
<br>
future not turning out to be even faster than that, though.
<br>
<p><em>&gt;&gt;&gt; Though I gather 'emulating' isn't exactly the right word.
</em><br>
<em>&gt;&gt; That would be upload, wouldn't it?  How about 'imitating'?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; How about 'synthetic', or 'synthesizing'?
</em><br>
<p>It's a question of wether it actually proves to be a kind of cat,
<br>
artficial, synthetic, robo- or whatever, or is a completely new
<br>
kind of creature with some similarities on a superficial level.
<br>
<p>How about 'para-something'?  In the sense that paraphrase
<br>
is to mean the same thing using different language..
<br>
This might be a creature that acts the same way as
<br>
a cat using different thoughts.
<br>
<p><em>&gt; Who's to say an AI won't have a hundred
</em><br>
<em>&gt; million generations of descendants?
</em><br>
<p>Well, therein lies the singularity stuff.  For that to happen, the
<br>
generations need a world millions of times faster than our physical
<br>
one to grow up in, and our technology is nowhere near being able to
<br>
provide such things.  Theirs could be, but if it is they hardly
<br>
need worry about oppression from the likes of us. :)
<br>
<p><em>&gt; What is pain, anyway?
</em><br>
<p>Pain is any sensory qualia that induces a feeling of suffering.
<br>
<p>Suffering is something else entirely, and it is quite seperate.
<br>
Minds can suffer without pain, (Although human minds tend to
<br>
experience hallucinatory pain as a result of such suffering,
<br>
another result of our long and messy evolution) and they can
<br>
experience pain without suffering.
<br>
<p>Pain, as the mechanism through which a creature suffers as a
<br>
direct result of injury, is not necessary, and may be discarded,
<br>
if physical injury is nothing more than an inconvenience.
<br>
I believe that it is through inflicting physical pain that
<br>
most of the primitive and thoughtless people we are worrying
<br>
about would seek to torment animal level AI toys for kicks.
<br>
<p><em>&gt; The best treatment I've read on machines &amp; pain is Dennett's
</em><br>
<em>&gt; 'Why You Can't Build a Computer That Feels Pain', which can be
</em><br>
<em>&gt; found in 'BrainStorms'.  Interestingly, the essay's title isn't
</em><br>
<em>&gt; a good indicator of his conclusions.
</em><br>
<p>It seems that this god-play may lead us to find answers to the
<br>
ancient theological question of suffering. (Not that we claim to
<br>
be omnibenevolent, of course.)  It may well prove to be necessary
<br>
for an intelligent mind to suffer, in order that it might have
<br>
desires.  Or it may prove possible to create minds that never
<br>
suffer, but are simply more euphoric at some times than others.
<br>
<p>I would guess that the latter is psychically possible,
<br>
but vanishingly unlikely to arise naturally from a
<br>
process of unguided evolution.
<br>
<p><em>&gt; Philosophy aside, intentionally damaging an AI's
</em><br>
<em>&gt; cognitive processes would constitute torture.
</em><br>
<p>That doesn't sound right..  If someone opened up my brain and
<br>
intentionally damaged my cognitive processes I'd certaily call
<br>
that grevious assault, but torture?  That would apply more to
<br>
the physical process of sawing my head open.  Then again, if I
<br>
was aware of the whole thing I doubt I'd be comfortable with
<br>
the experience whatever the physical pain involved.
<br>
<p>Perhaps torture is the act of forcing an experience on a creature
<br>
against its will, with the intent to cause suffering.  That way it
<br>
doesn't matter what pain and suffering actually mean from the
<br>
victim's pespective, it is the intent to cause it that makes
<br>
the act one of torture.
<br>
<p><p>------------------------------------------------------------------------
<br>
Get what you deserve with NextCard Visa! Rates as low as 2.9% 
<br>
Intro or 9.9% Fixed APR, online balance transfers, Rewards Points, 
<br>
no hidden fees, and much more! Get NextCard today and get the 
<br>
credit youdeserve! Apply now! Get your NextCard Visa at:
<br>
<a href="http://click.egroups.com/1/912/3/_/_/_/951254569/">http://click.egroups.com/1/912/3/_/_/_/951254569/</a>
<br>
------------------------------------------------------------------------
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="21250.html">Patrick McCuller: "RE: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>Previous message:</strong> <a href="21248.html">Patrick McCuller: "RE: [SL4] AI Ethics"</a>
<li><strong>In reply to:</strong> <a href="21247.html">Patrick McCuller: "RE: [SL4] AI Ethics &amp; Banning the Future."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="21250.html">Patrick McCuller: "RE: [SL4] AI Ethics &amp; Banning the Future."</a>
<li><strong>Reply:</strong> <a href="21250.html">Patrick McCuller: "RE: [SL4] AI Ethics &amp; Banning the Future."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#21249">[ date ]</a>
<a href="index.html#21249">[ thread ]</a>
<a href="subject.html#21249">[ subject ]</a>
<a href="author.html#21249">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:06 MDT
</em></small></p>
</body>
</html>
