<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Is complex emergence necessary for AGI?</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Is complex emergence necessary for AGI?">
<meta name="Date" content="2005-09-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Is complex emergence necessary for AGI?</h1>
<!-- received="Tue Sep 20 06:59:48 2005" -->
<!-- isoreceived="20050920125948" -->
<!-- sent="Tue, 20 Sep 2005 08:59:49 -0400" -->
<!-- isosent="20050920125949" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Is complex emergence necessary for AGI?" -->
<!-- id="JNEIJCJJHIEAILJBFHILMENNGDAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="20050920100811.49403.qmail@web26701.mail.ukl.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Is%20complex%20emergence%20necessary%20for%20AGI?"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Tue Sep 20 2005 - 06:59:49 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12405.html">Stephen Reed: "Re: Guidelines on Friendly AI"</a>
<li><strong>Previous message:</strong> <a href="12403.html">Michael Wilson: "RE: Is complex emergence necessary for AGI?"</a>
<li><strong>In reply to:</strong> <a href="12403.html">Michael Wilson: "RE: Is complex emergence necessary for AGI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12406.html">Eliezer S. Yudkowsky: "Re: Is complex emergence necessary for AGI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12404">[ date ]</a>
<a href="index.html#12404">[ thread ]</a>
<a href="subject.html#12404">[ subject ]</a>
<a href="author.html#12404">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Michael,
<br>
<p>Thanks for the very clear overview of the your position, which generally
<br>
seems reasonable to me.
<br>
<p>In fact your approach does not seem all that different than my own,
<br>
although our AI approaches are different.
<br>
<p>My main difference with Eli in terms of the philosophy of AGI
<br>
development seems to be that I have little faith in the power of
<br>
pure theory to tell us how to make a safe AI; and I tend to believe that
<br>
experimentation with &quot;AI children&quot; in simulated environments is going
<br>
to teach us a lot that will be useful in figuring out how to make a
<br>
safe AI.
<br>
<p>However, since you (like me) are actually working on an AI system now
<br>
in parallel with your theory efforts, it seems your attitude in practice
<br>
is a little bit closer to my own.
<br>
<p>It's not just that I &quot;want to get to the fun part of  making an AGI&quot;
<br>
like you suggest, it's that I'm skeptical that the pure-theory approach
<br>
will work for resolving these issues, and I think there is more to be
<br>
learned via a combination of theory and experiment.
<br>
<p><em>&gt; 5. Any system compatible with the known approaches to strong verification
</em><br>
<em>&gt; of Friendliness will need to be consistently rational, which is to say
</em><br>
<em>&gt; Bayesian from the ground up and have the structural property of being
</em><br>
<em>&gt; 'causally clean', although not necessarily driven by expected utility.
</em><br>
<em>&gt; When I first accepted these constraints, they seemed onerous to the point
</em><br>
<em>&gt; of making a tractabale architecture impossible; all the 'powerful'
</em><br>
<em>&gt; techniques I knew of (improved GAs, stochastic codelets, dynamic-toplogy
</em><br>
<em>&gt; NNs, agent systems etc) were thoroughly probabilistic* and hence difficult
</em><br>
<em>&gt; to use or completely unusable. But after a period of research I now
</em><br>
<em>&gt; believe that there are acceptable and even superior replacements for all
</em><br>
<em>&gt; of these that are compatible with strong verification of Friendliness.
</em><br>
<em>&gt; I'm not going to defend that as anything more than a personal opinion at
</em><br>
<em>&gt; this time.
</em><br>
<p>Well, your penultimate sentence is a big claim indeed.
<br>
<p>I will add this though: I know how to make a Novamente system &quot;causally
<br>
clean&quot; at the cost of dramatically increasing its memory and speed
<br>
requirements.  Basically, you just need to make it keep a complete
<br>
record of every inference it does internally on a cognitive level, so it
<br>
can be run as (to oversimplify) a reversible inference engine coupled with
<br>
a nonreversible evolutionary hypothesis generator.  Then it can apply its
<br>
own reasoning capability to reason about the causes and consequences
<br>
of all its actions, and can  maintain a causally clean goal system.
<br>
<p>However, running a Novamente like this in the near term would make
<br>
testing almost impossible as it would vastly increase the amount of
<br>
RAM and the number of computers required.
<br>
<p>In this regard, the question from a Novamente perspective is how close
<br>
you could come to causal cleanliness via retaining and studying only a
<br>
limited portion of inferential history.  But that is not what we are
<br>
focusing now because we are focusing on getting the system to be at all
<br>
intelligent in the first place.
<br>
<p><em>&gt; 12. Finally, my objection to claims about the value of Complexity theory
</em><br>
<em>&gt; were summed up by one critic's comment that &quot;Wolfram's 'A New Kind of
</em><br>
<em>&gt; Science' would have been fine if it had been called 'Fun With Graph
</em><br>
<em>&gt; Paper'&quot;. The field has produced a vast amount of hype, a small amount
</em><br>
<em>&gt; of interesting maths and very few useful predictive theories in other
</em><br>
<em>&gt; domains. Its proponents are quick to claim that their ideas apply to
</em><br>
<em>&gt; virtually everything, when in practice they seem to have been actually
</em><br>
<em>&gt; useful in rather few cases. This opinion is based on coverage in the
</em><br>
<em>&gt; science press and would be easy to change via evidence, but to date
</em><br>
<em>&gt; no-one has responded to Eliezer's challenge with real examples of
</em><br>
<em>&gt; complexity theory doing something useful. That said, general opinions
</em><br>
<em>&gt; such as this are a side issue; the specifics of AGI are the important
</em><br>
<em>&gt; part.
</em><br>
<p>In fact I did respond to that email of his, weeks ago, but I do't feel like
<br>
digging up my old response ;)
<br>
<p>I am a big fan of complexity science and not a huge fan of Wolfram's book; I
<br>
agree with that criticism of the latter.
<br>
<p>ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12405.html">Stephen Reed: "Re: Guidelines on Friendly AI"</a>
<li><strong>Previous message:</strong> <a href="12403.html">Michael Wilson: "RE: Is complex emergence necessary for AGI?"</a>
<li><strong>In reply to:</strong> <a href="12403.html">Michael Wilson: "RE: Is complex emergence necessary for AGI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12406.html">Eliezer S. Yudkowsky: "Re: Is complex emergence necessary for AGI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12404">[ date ]</a>
<a href="index.html#12404">[ thread ]</a>
<a href="subject.html#12404">[ subject ]</a>
<a href="author.html#12404">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
