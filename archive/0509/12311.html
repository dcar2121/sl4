<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Immorally optimized? - alternate observation points</title>
<meta name="Author" content="H C (lphege@hotmail.com)">
<meta name="Subject" content="Re: Immorally optimized? - alternate observation points">
<meta name="Date" content="2005-09-09">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Immorally optimized? - alternate observation points</h1>
<!-- received="Fri Sep  9 20:07:07 2005" -->
<!-- isoreceived="20050910020707" -->
<!-- sent="Sat, 10 Sep 2005 02:07:05 +0000" -->
<!-- isosent="20050910020705" -->
<!-- name="H C" -->
<!-- email="lphege@hotmail.com" -->
<!-- subject="Re: Immorally optimized? - alternate observation points" -->
<!-- id="BAY101-F13B27F39DA9F21C2402B72DC9B0@phx.gbl" -->
<!-- inreplyto="20050909181505.85284.qmail@web61319.mail.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> H C (<a href="mailto:lphege@hotmail.com?Subject=Re:%20Immorally%20optimized?%20-%20alternate%20observation%20points"><em>lphege@hotmail.com</em></a>)<br>
<strong>Date:</strong> Fri Sep 09 2005 - 20:07:05 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12312.html">Eliezer S. Yudkowsky: "Re: Hempel's Paradox"</a>
<li><strong>Previous message:</strong> <a href="12310.html">Richard Loosemore: "Re: Heterogenous Complex Systems"</a>
<li><strong>In reply to:</strong> <a href="12297.html">Phillip Huggan: "Re: Immorally optimized? - alternate observation points"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12295.html">Phil Goetz: "Parallelizing attention and credit-assignment"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12311">[ date ]</a>
<a href="index.html#12311">[ thread ]</a>
<a href="subject.html#12311">[ subject ]</a>
<a href="author.html#12311">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&quot;You've specified an AGI which feels desire, and stated it doesn't mimic 
<br>
human desires&quot;
<br>
<p>It wants to be Friendly, but it doesn't want to have sex with people or eat 
<br>
food.
<br>
<p><p><em>&gt;From: Phillip Huggan &lt;<a href="mailto:cdnprodigy@yahoo.com?Subject=Re:%20Immorally%20optimized?%20-%20alternate%20observation%20points">cdnprodigy@yahoo.com</a>&gt;
</em><br>
<em>&gt;Reply-To: <a href="mailto:sl4@sl4.org?Subject=Re:%20Immorally%20optimized?%20-%20alternate%20observation%20points">sl4@sl4.org</a>
</em><br>
<em>&gt;To: <a href="mailto:sl4@sl4.org?Subject=Re:%20Immorally%20optimized?%20-%20alternate%20observation%20points">sl4@sl4.org</a>
</em><br>
<em>&gt;Subject: Re: Immorally optimized? - alternate observation points
</em><br>
<em>&gt;Date: Fri, 9 Sep 2005 11:15:04 -0700 (PDT)
</em><br>
<em>&gt;
</em><br>
<em>&gt;H C &lt;<a href="mailto:lphege@hotmail.com?Subject=Re:%20Immorally%20optimized?%20-%20alternate%20observation%20points">lphege@hotmail.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt;Imagine (attempted) Friendly AGI named X, who resides in some computer
</em><br>
<em>&gt; &gt;simulation. X observes things, gives meaning, feels desire, hypothesizes,
</em><br>
<em>&gt; &gt;and is capable of creating tests for vis hypotheses. In other words, AGI 
</em><br>
<em>&gt;X
</em><br>
<em>&gt; &gt;is actually a *real* intelligent AGI, intelligent in the human sense (but
</em><br>
<em>&gt; &gt;without athropomorphizing human thought procedures and desires).
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;Now imagine that AGI X has the capability to run &quot;alternate observation
</em><br>
<em>&gt; &gt;points&quot; in which ve creates another &quot;instance&quot; of the [observation 
</em><br>
<em>&gt;program -
</em><br>
<em>&gt; &gt;aka intelligence program] and runs this intelligence program on one
</em><br>
<em>&gt; &gt;particular problem... and this instance exists independently of the X,
</em><br>
<em>&gt; &gt;except it modifies the same memory base. In other words &quot;I need a program 
</em><br>
<em>&gt;to
</em><br>
<em>&gt; &gt;fly a helicopter&quot; *clicks in disk recorded where an alternate observation
</em><br>
<em>&gt;point already learned/experienced flying helicopter* &quot;Ok thanks.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;Now if you optimize this concept, given some problem like &quot;Program this
</em><br>
<em>&gt; &gt;application&quot;, X could create several different AOPs and solve 5 different
</em><br>
<em>&gt; &gt;parts of the problem at the same time, shut them down, and start solving 
</em><br>
<em>&gt;the
</em><br>
<em>&gt;main problem of the application with all of the detailed trial and error
</em><br>
<em>&gt;learning that took place in creating the various parts of the application
</em><br>
<em>&gt;already done.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;The problem is, is it *immoral* to create these &quot;parallel intelligences&quot; 
</em><br>
<em>&gt;and
</em><br>
<em>&gt; &gt;arbitrarily destory them when they've fulfilled their purpose? Also, if 
</em><br>
<em>&gt;you
</em><br>
<em>&gt;decide to respond, try to give explanation for your answers.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;You've specified an AGI which feels desire, and stated it doesn't mimic 
</em><br>
<em>&gt;human desires.  Which is it?  If the AGI itself cannot answer this moral 
</em><br>
<em>&gt;dillemma, it is not friendly and we are all in big trouble.  I suspect the 
</em><br>
<em>&gt;answer depends upon how important the application is you are telling the 
</em><br>
<em>&gt;AGI to solve.  If solving the application requires creating and destroying 
</em><br>
<em>&gt;5 sentient AIs, we are setting a precedent for computronium.
</em><br>
<em>&gt;
</em><br>
<p><p><p>Good point. You could focus on suboptimal performance while waiting for the 
<br>
AGI to Singularitize itself and tell you the answer.
<br>
<p><p><em>&gt;
</em><br>
<em>&gt;__________________________________________________
</em><br>
<em>&gt;Do You Yahoo!?
</em><br>
<em>&gt;Tired of spam?  Yahoo! Mail has the best spam protection around
</em><br>
<em>&gt;<a href="http://mail.yahoo.com">http://mail.yahoo.com</a>
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12312.html">Eliezer S. Yudkowsky: "Re: Hempel's Paradox"</a>
<li><strong>Previous message:</strong> <a href="12310.html">Richard Loosemore: "Re: Heterogenous Complex Systems"</a>
<li><strong>In reply to:</strong> <a href="12297.html">Phillip Huggan: "Re: Immorally optimized? - alternate observation points"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12295.html">Phil Goetz: "Parallelizing attention and credit-assignment"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12311">[ date ]</a>
<a href="index.html#12311">[ thread ]</a>
<a href="subject.html#12311">[ subject ]</a>
<a href="author.html#12311">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
