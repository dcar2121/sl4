<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Non-black non-ravens etc.</title>
<meta name="Author" content="Richard Loosemore (rpwl@lightlink.com)">
<meta name="Subject" content="Re: Non-black non-ravens etc.">
<meta name="Date" content="2005-09-12">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Non-black non-ravens etc.</h1>
<!-- received="Mon Sep 12 18:22:41 2005" -->
<!-- isoreceived="20050913002241" -->
<!-- sent="Mon, 12 Sep 2005 20:22:00 -0400" -->
<!-- isosent="20050913002200" -->
<!-- name="Richard Loosemore" -->
<!-- email="rpwl@lightlink.com" -->
<!-- subject="Re: Non-black non-ravens etc." -->
<!-- id="43261BA8.3090200@lightlink.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="JNEIJCJJHIEAILJBFHILOEGLGCAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Richard Loosemore (<a href="mailto:rpwl@lightlink.com?Subject=Re:%20Non-black%20non-ravens%20etc."><em>rpwl@lightlink.com</em></a>)<br>
<strong>Date:</strong> Mon Sep 12 2005 - 18:22:00 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12340.html">Richard Loosemore: "Re: Complex computer programs"</a>
<li><strong>Previous message:</strong> <a href="12338.html">Phil Goetz: "Re: Complex computer programs"</a>
<li><strong>In reply to:</strong> <a href="12335.html">Ben Goertzel: "RE: Non-black non-ravens etc."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12341.html">Ben Goertzel: "RE: Non-black non-ravens etc."</a>
<li><strong>Reply:</strong> <a href="12341.html">Ben Goertzel: "RE: Non-black non-ravens etc."</a>
<li><strong>Reply:</strong> <a href="12342.html">Chris Capel: "Re: Non-black non-ravens etc."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12339">[ date ]</a>
<a href="index.html#12339">[ thread ]</a>
<a href="subject.html#12339">[ subject ]</a>
<a href="author.html#12339">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Goertzel wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Richard,
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;In my post on the relevance of complex systems, I set out the reasons
</em><br>
<em>&gt;&gt;why it is extremely questionable to assume that anyone can build a valid
</em><br>
<em>&gt;&gt;AGI by starting with the observation of logical reasoning at the
</em><br>
<em>&gt;&gt;extremely high level the we know it, then using this as the basis for
</em><br>
<em>&gt;&gt;the lowest level mechanisms of an AGI.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't think that logical reasoning can serve as the sole basis for an AGI
</em><br>
<em>&gt; design, but I think it can serve as one of the primary bases.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I think that emergence and complex dynamics are necessary aspects of
</em><br>
<em>&gt; intelligence given limited computational resources.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I think that it is quite feasible (and in fact a good idea) to give logic a
</em><br>
<em>&gt; more primary role in an AGI than it has in humans.  But that doesn't mean I
</em><br>
<em>&gt; advocate GOFAI.  It means I advocate AGI systems that intelligently couple
</em><br>
<em>&gt; logical inference with complex, self-organizing dynamics.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; In the human mind, arguably, abstract logical reasoning exists ONLY as a
</em><br>
<em>&gt; high-level emergent phenomenon.  However, I suggest that in an AGI system,
</em><br>
<em>&gt; logical reasoning may exist BOTH as a low-level wired-in subsystem AND as a
</em><br>
<em>&gt; high-level emergent phenomenon, and that these two aspects of logic in the
</em><br>
<em>&gt; AGI system may be coordinated closely together.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Do you have an argument against this sort of approach?  It is not based on
</em><br>
<em>&gt; simulating human intelligence closely, but rather based on trying to combine
</em><br>
<em>&gt; the best of human intelligence with the best of computer
</em><br>
<em>&gt; technology/software -- with the aim of making an AGI that embodies
</em><br>
<em>&gt; creativity and empathy and rationality superior to that of humans.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -- Ben G
</em><br>
<p>You raise an interesting question.  If you were assuming that &quot;logical 
<br>
reasoning&quot; (in a fairly general sense, not committed to Bayes or 
<br>
whatever) was THE basic substrate of the AGI system, then I would be 
<br>
skeptical of it succeeding.  If, as you suggest, you are only hoping to 
<br>
give logic a more primary role than it has in humans (but not exclusive 
<br>
rights to the whole show), then that I am sure is feasible.
<br>
<p>Where the real difficulty arises is how to generate and refine the 
<br>
elementary symbols that the logical reasoning component works on.  If 
<br>
some other system did that, and was then smoothly integrated with the 
<br>
logical part, no problem.  It's the grounding of those symbols that is 
<br>
the sticking point.
<br>
<p>Personally, I feel that the &quot;other&quot; part is going to be massive, and 
<br>
needs a lot more thought than it gets.  To put that another way, I think 
<br>
there are many AI formalisms that look great on paper but which, when 
<br>
implemented, leave all the really important stuff hidden in the mind of 
<br>
the programmer (who invented, preprocessed and then interpreted the 
<br>
symbols that were fed to the formalism).  This is of course the 
<br>
grounding problem itself:  recognized and appreciated by many, but still 
<br>
happening today.
<br>
<p>Lastly, you say:  &quot;However, I suggest that in an AGI system, logical 
<br>
reasoning may exist BOTH as a low-level wired-in subsystem AND as a 
<br>
high-level emergent phenomenon, and that these two aspects of logic in 
<br>
the AGI system may be coordinated closely together.&quot;  If it really did 
<br>
that, it would (as I understand it) be quite a surprise (to put it 
<br>
mildly) ... CAS systems do not as a rule show that kind of weird 
<br>
reflection, as I said in my earlier posts.  I suppose we could call this 
<br>
&quot;self-similar&quot; behavior (emergence of a copy of the low level mechanisms 
<br>
in the highest level emergent behavior), and my understanding is that 
<br>
this has either never been observed or it only happens under peculiar 
<br>
circumstances.
<br>
<p>Richard
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12340.html">Richard Loosemore: "Re: Complex computer programs"</a>
<li><strong>Previous message:</strong> <a href="12338.html">Phil Goetz: "Re: Complex computer programs"</a>
<li><strong>In reply to:</strong> <a href="12335.html">Ben Goertzel: "RE: Non-black non-ravens etc."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12341.html">Ben Goertzel: "RE: Non-black non-ravens etc."</a>
<li><strong>Reply:</strong> <a href="12341.html">Ben Goertzel: "RE: Non-black non-ravens etc."</a>
<li><strong>Reply:</strong> <a href="12342.html">Chris Capel: "Re: Non-black non-ravens etc."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12339">[ date ]</a>
<a href="index.html#12339">[ thread ]</a>
<a href="subject.html#12339">[ subject ]</a>
<a href="author.html#12339">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
