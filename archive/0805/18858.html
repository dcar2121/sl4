<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Slow-fast singularity</title>
<meta name="Author" content="Krekoski Ross (rosskrekoski@gmail.com)">
<meta name="Subject" content="Re: Slow-fast singularity">
<meta name="Date" content="2008-05-08">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Slow-fast singularity</h1>
<!-- received="Thu May  8 21:35:42 2008" -->
<!-- isoreceived="20080509033542" -->
<!-- sent="Thu, 8 May 2008 18:43:20 +0000" -->
<!-- isosent="20080508184320" -->
<!-- name="Krekoski Ross" -->
<!-- email="rosskrekoski@gmail.com" -->
<!-- subject="Re: Slow-fast singularity" -->
<!-- id="87478b5d0805081143o5b952350ua0128a64e4a385f6@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="38f493f10805080159l214c63c6peb0f9361e0b42b32@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Krekoski Ross (<a href="mailto:rosskrekoski@gmail.com?Subject=Re:%20Slow-fast%20singularity"><em>rosskrekoski@gmail.com</em></a>)<br>
<strong>Date:</strong> Thu May 08 2008 - 12:43:20 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="18859.html">Krekoski Ross: "Re: Slow-fast singularity"</a>
<li><strong>Previous message:</strong> <a href="18857.html">Matt Mahoney: "Re: Bound unhappiness below (was Re: What if there's an expiration date?)"</a>
<li><strong>In reply to:</strong> <a href="18848.html">Stuart Armstrong: "Re: Slow-fast singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18859.html">Krekoski Ross: "Re: Slow-fast singularity"</a>
<li><strong>Reply:</strong> <a href="18859.html">Krekoski Ross: "Re: Slow-fast singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18858">[ date ]</a>
<a href="index.html#18858">[ thread ]</a>
<a href="subject.html#18858">[ subject ]</a>
<a href="author.html#18858">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Thu, May 8, 2008 at 8:59 AM, Stuart Armstrong &lt;
<br>
<a href="mailto:dragondreaming@googlemail.com?Subject=Re:%20Slow-fast%20singularity">dragondreaming@googlemail.com</a>&gt; wrote:
<br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; What makes you claim that? We have little understanding of
</em><br>
<em>&gt; intelligence; we don't know how easy or hard increases in intelligence
</em><br>
<em>&gt; will turn out to be; we're not even certain how high the advantages of
</em><br>
<em>&gt; increased intelligence will turn out to be.
</em><br>
<em>&gt;
</em><br>
<em>&gt; It could be a series of increasing returns, and the advantages could
</em><br>
<em>&gt; be huge - but we really don't know that. &quot;Most likely scenario&quot; is
</em><br>
<em>&gt; much to strong a thing to say.
</em><br>
<em>&gt;
</em><br>
<p><p>Yes.
<br>
<p>I personally dont have a strong opinion on the probability of either
<br>
scenario just because there are so many unknowns, and we have an effective
<br>
sample size of 1 (ourselves) with which to base all of our understanding of
<br>
intelligence.  But I think we should realize one thing--- is it only by
<br>
incredible coincidence that our intelligence is at a level such that we can
<br>
understand the formal properties of our brain, but are just below some
<br>
'magical' threshold that would allow us to mentally simulate what
<br>
differences in subjective experience and intelligence a slight change in our
<br>
architecture would entail, but just above the threshold where it would be
<br>
possible to do so for 'lower' entities?
<br>
<p>I've mentioned this before in various forms but in general I think its a
<br>
fairly under-addressed topic: Can an intelligent system of complexity A,
<br>
perfectly emulate (perform a test run of) an intelligent system of
<br>
complexity A? (for fairly obvious reasons it cannot emulate one of higher
<br>
complexity). It seems possible that an intelligent system of complexity A
<br>
can emulate one of complexity A-K where K is the output of some function
<br>
that describes some proportion of A (we dont know specifically how
<br>
complexity in an intelligent system affects intelligence, except that in a
<br>
perfectly designed machine, an increase in complexity will entail an
<br>
increase in intelligence).  I think that because of natural systemic
<br>
overhead, it is impossible for any perfectly designed intelligent system to
<br>
properly model another system of equal complexity. (and indeed no effective
<br>
way to evaluate the model if it could)
<br>
<p>This has implications on the rate at which any AI can self-improve-- if K is
<br>
a reasonably significant proportion of A, even a godlike AI would have
<br>
difficulty improving its own intelligence in an efficient and rapid way.
<br>
<p>This is also why evolution by random mutation is a slow, but actually quite
<br>
efficient way of increasing intelligence--- we dont want a progressively
<br>
larger, but structurally homogenous system (which actually is not an
<br>
efficient increase in complexity, only size). We want structural diversity
<br>
in an intelligent system, and its not clear how a system can 'invent' novel
<br>
structures that is completely foreign to it. Many of our own advances in
<br>
science, by analogy, arise from mimicry of for example non-human biological
<br>
systems.
<br>
<p>Ross
<br>
<p><p><p><em>&gt;
</em><br>
<em>&gt; Stuart
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="18859.html">Krekoski Ross: "Re: Slow-fast singularity"</a>
<li><strong>Previous message:</strong> <a href="18857.html">Matt Mahoney: "Re: Bound unhappiness below (was Re: What if there's an expiration date?)"</a>
<li><strong>In reply to:</strong> <a href="18848.html">Stuart Armstrong: "Re: Slow-fast singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18859.html">Krekoski Ross: "Re: Slow-fast singularity"</a>
<li><strong>Reply:</strong> <a href="18859.html">Krekoski Ross: "Re: Slow-fast singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18858">[ date ]</a>
<a href="index.html#18858">[ thread ]</a>
<a href="subject.html#18858">[ subject ]</a>
<a href="author.html#18858">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:02 MDT
</em></small></p>
</body>
</html>
