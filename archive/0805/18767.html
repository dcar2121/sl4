<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Unbounded happiness</title>
<meta name="Author" content="Lee Corbin (lcorbin@rawbw.com)">
<meta name="Subject" content="Re: Unbounded happiness">
<meta name="Date" content="2008-05-01">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Unbounded happiness</h1>
<!-- received="Thu May  1 01:42:57 2008" -->
<!-- isoreceived="20080501074257" -->
<!-- sent="Thu, 1 May 2008 00:35:42 -0700" -->
<!-- isosent="20080501073542" -->
<!-- name="Lee Corbin" -->
<!-- email="lcorbin@rawbw.com" -->
<!-- subject="Re: Unbounded happiness" -->
<!-- id="002d01c8ab5e$37e96fa0$6401a8c0@homeef7b612677" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="87478b5d0804262200k6ce737cjde0e2be50cebafe7@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Lee Corbin (<a href="mailto:lcorbin@rawbw.com?Subject=Re:%20Unbounded%20happiness"><em>lcorbin@rawbw.com</em></a>)<br>
<strong>Date:</strong> Thu May 01 2008 - 01:35:42 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="18768.html">William Pearson: "Re: Self vs. other (was Re: Balance of power)"</a>
<li><strong>Previous message:</strong> <a href="../0804/18766.html">Matt Mahoney: "Re: Maximizing vs proving friendliness"</a>
<li><strong>In reply to:</strong> <a href="../0804/18715.html">Krekoski Ross: "Re: Unbounded happiness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18796.html">Krekoski Ross: "Re: Unbounded happiness"</a>
<li><strong>Reply:</strong> <a href="18796.html">Krekoski Ross: "Re: Unbounded happiness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18767">[ date ]</a>
<a href="index.html#18767">[ thread ]</a>
<a href="subject.html#18767">[ subject ]</a>
<a href="author.html#18767">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
First, thanks to Stuart for pointing out Anders' paper
<br>
<a href="http://ftp.nada.kth.se/pub/home/asa/Work/Brains/Brains2/">http://ftp.nada.kth.se/pub/home/asa/Work/Brains/Brains2/</a>
<br>
He doesn't have too much directly to say about what
<br>
kinds of identity transformations a human being would
<br>
have to undergo when becoming a Jupiter-sized
<br>
Jupiter brain, but the last four paragraphs of
<br>
<a href="http://ftp.nada.kth.se/pub/home/asa/Work/Brains/Brains2/node14.html">http://ftp.nada.kth.se/pub/home/asa/Work/Brains/Brains2/node14.html</a>
<br>
are pertinent.
<br>
<p>Kresoski writes.
<br>
<p><em>&gt; [Lee wrote]
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; Bottom line: large brains should have no reason to
</em><br>
<em>&gt; &gt; choose to operate slowly, so therefore thought
</em><br>
<em>&gt; &gt; will be conducted at c, and therefore what an
</em><br>
<em>&gt; &gt; &quot;individual sentience&quot; is will be limited in size.
</em><br>
<em>&gt; &gt;   Now yes, I can even now perform &quot;library inquiries&quot;,
</em><br>
<em>&gt; &gt; get an answer to a math problem by letting my
</em><br>
<em>&gt; &gt; computer run long enough, but in neither case is
</em><br>
<em>&gt; &gt; the library or my computer to be considered part of me.
</em><br>
<em>&gt;
</em><br>
<em>&gt; See that's the issue that I have with it-- what do we want
</em><br>
<em>&gt; to consider as part of you right this moment? Firstly we
</em><br>
<em>&gt; have an autonomic nervous system that we are completely
</em><br>
<em>&gt; unaware of-- is that part of you?
</em><br>
<p>No, not at all. I can't go so far as to say that *nothing*
<br>
which I am not aware of can be part of me, for a lot of
<br>
thinking and memory reference is unconscious, but on the
<br>
other hand, heart rate, digestion, breathing, respiration rate,
<br>
salivation, perspiration, diameter of the pupils, etc. (taken
<br>
from Wikipedia's list in their ANS article) simply are not
<br>
an important part of who I am.
<br>
<p><em>&gt; What about your own memories, some of which are not
</em><br>
<em>&gt; consciously accessible right now? What if I were to create
</em><br>
<em>&gt; a neural implant that vastly improved the rate at which I
</em><br>
<em>&gt; could exchange information with the outside world, connect
</em><br>
<em>&gt; to a series of other computers, or individuals with similar implants.
</em><br>
<em>&gt; What consequence does this have for my own individuality?
</em><br>
<p>Excellent questions. Take what I consider to be &quot;my memories&quot;
<br>
right now. I'm very familiar with Euclid's Algorithm, not only
<br>
for finding the Greatest Common Divisor, but for finding integer
<br>
solutions to 107x - 337y = 1. This is a pretty discrete bundle
<br>
of knowledge. It's mine right now: if damage occurs to it (I
<br>
forget part of one of the algorithms) then that's only happened
<br>
to *me*. But what's going on here? Clearly if the tech you
<br>
suggest enabled a lot of people to access those same memories,
<br>
then it wouldn't feel as though it were *mine* anymore.
<br>
<p>Well, I cannot answer these last two questions either. I do
<br>
only know that I'm wary of embracing those technologies,
<br>
and would never do so except for a limited number of my
<br>
us (my duplicates).
<br>
<p><em>&gt; Let's assume that we have a solar system brain that is
</em><br>
<em>&gt; massively parallel in a way analogous to our own brains.
</em><br>
<em>&gt; Is it so inconceivable to have a scenario whereby the
</em><br>
<em>&gt; cognitive experience is 'slowed down'?
</em><br>
<p>Not at all! I was merely saying that you'd have to
<br>
artificially slow it down to maintain what we think
<br>
of today as a human mind. As Anders wrote
<br>
<p>&lt;The subjective effects of S depends on the application. For data retrieval and communication, it just creates a subjective delay 
<br>
which may or may not be acceptable (a delay of a minute in delivering an email is usually acceptable; a one-minute delay in 
<br>
delivering a frame of video is not acceptable). Subjective distances increase for very fast minds; for entities exploiting 
<br>
nanosecond timescales at the speed of light distances of centimeters are significant, for femtosecond entities micrometers and for 
<br>
nuclear entities femtometers. Structures larger than this will be ``large'' compared to the processes that go in them.
<br>
<p>&lt;For infomorphs, delays limit the physical distribution of their component processes: if they are too far apart, the being would 
<br>
have to slow down its rate of subjective time in order to keep synchronized. Even if the processing is infinitely fast lightspeed 
<br>
limits the speed of infomorphs if they wish to interact with the outside environment at a certain rate; since the human mind acts as 
<br>
a whole on a time scale of hundreds of milliseconds, a human-like infomorph running at ``normal'' speed would at most be able to 
<br>
extend 30,000 kilometers before the delays started to limit its speed.&gt;
<br>
<p><p>Not at all! I was merely saying that you'd have to
<br>
artificially slow it down to maintain what we think
<br>
of today as a human mind. As Anders wrote
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;The subjective effects of S depends on the application. For
<br>
&nbsp;&nbsp;&nbsp;&nbsp;data retrieval and communication, it just creates a subjective
<br>
&nbsp;&nbsp;&nbsp;&nbsp;delay which may or may not be acceptable (a delay of a minute
<br>
&nbsp;&nbsp;&nbsp;&nbsp;in delivering an email is usually acceptable; a one-minute
<br>
&nbsp;&nbsp;&nbsp;&nbsp;delay in delivering a frame of video is not acceptable).
<br>
&nbsp;&nbsp;&nbsp;&nbsp;Subjective distances increase for very fast minds; for entities
<br>
&nbsp;&nbsp;&nbsp;&nbsp;exploiting nanosecond timescales at the speed of light
<br>
&nbsp;&nbsp;&nbsp;&nbsp;distances of centimeters are significant, for femtosecond
<br>
&nbsp;&nbsp;&nbsp;&nbsp;entities micrometers and for nuclear entities femtometers.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;Structures larger than this will be ``large'' compared to the
<br>
&nbsp;&nbsp;&nbsp;&nbsp;processes that go in them.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;For infomorphs, delays limit the physical distribution of their
<br>
&nbsp;&nbsp;&nbsp;&nbsp;component processes: if they are too far apart, the being would
<br>
&nbsp;&nbsp;&nbsp;&nbsp;have to slow down its rate of subjective time in order to keep
<br>
&nbsp;&nbsp;&nbsp;&nbsp;synchronized. Even if the processing is infinitely fast
<br>
&nbsp;&nbsp;&nbsp;&nbsp;lightspeed limits the speed of infomorphs if they wish to
<br>
&nbsp;&nbsp;&nbsp;&nbsp;interact with the outside environment at a certain rate; since
<br>
&nbsp;&nbsp;&nbsp;&nbsp;the human mind acts as a whole on a time scale of hundreds of
<br>
&nbsp;&nbsp;&nbsp;&nbsp;milliseconds, a human-like infomorph running at ``normal''
<br>
&nbsp;&nbsp;&nbsp;&nbsp;speed would at most be able to extend 30,000 kilometers before
<br>
&nbsp;&nbsp;&nbsp;&nbsp;the delays started to limit its speed.
<br>
<p><em>&gt; If we compare our brains to the cluster of nerves in insects for
</em><br>
<em>&gt; example-- do we have a less coherent experience since a neural
</em><br>
<em>&gt; signal takes longer to propagate across our cognitive apparatus
</em><br>
<em>&gt; than it does theirs?
</em><br>
<p>Yes, I guess so.
<br>
<p><em>&gt; You say that &quot;individual sentience is limited in size&quot; -- well imagine
</em><br>
<em>&gt; we create a solar system computer. Does it then just spontaneously
</em><br>
<em>&gt; generate a myriad smaller 'sentiences' within it? where does one
</em><br>
<em>&gt; begin and the next one end?
</em><br>
<p>I should amend what I wrote. I meant to say that &quot;individual sentience
<br>
*of our familiar human kind* is limited in size&quot;.
<br>
<p><em>&gt; If you feel uneasy about talking about subjective experience
</em><br>
<em>&gt; (I do, it makes too many assumptions) we can still just talk
</em><br>
<em>&gt; about a solar-system sized computer, and how efficiently it
</em><br>
<em>&gt; processes.
</em><br>
<p>And whether a human brain could be made that large (using
<br>
any technology whatsoever) without becoming very, very
<br>
slow in comparison to other humans.
<br>
<p><em>&gt; I don't see any reason why size would become a significant
</em><br>
<em>&gt; barrier.
</em><br>
<p>Agreed. But if we want to retain human subjective experience,
<br>
it looks like a &quot;human like infomorph running at &quot;normal&quot; speed
<br>
would at most be able to extend 30,000 kilometers before
<br>
the delays started to limit its speed.&quot;
<br>
<p><em>&gt; It would of course have a minimum amount of time that it
</em><br>
<em>&gt; would take to perform a calculation (the same is true of
</em><br>
<em>&gt; our own brains) but the sheer degree of parallel computing
</em><br>
<em>&gt; power would likely override the speed of light constraint
</em><br>
<em>&gt; in terms of efficiency of computation.
</em><br>
<p>Agreed. But our human subjective experience would be
<br>
very much like that of consulting an &quot;exterior&quot; source of
<br>
information. That is, even if my neurons operate at c,
<br>
then information in my brain that is more than a mere
<br>
30,000 km away would start to feel external.
<br>
<p>Lee
<br>
<p>P.S. I didn't quote Anders' last two paragraphs on that
<br>
page which may closely support what you were saying,
<br>
because of time and space considerations in this email. 
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="18768.html">William Pearson: "Re: Self vs. other (was Re: Balance of power)"</a>
<li><strong>Previous message:</strong> <a href="../0804/18766.html">Matt Mahoney: "Re: Maximizing vs proving friendliness"</a>
<li><strong>In reply to:</strong> <a href="../0804/18715.html">Krekoski Ross: "Re: Unbounded happiness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="18796.html">Krekoski Ross: "Re: Unbounded happiness"</a>
<li><strong>Reply:</strong> <a href="18796.html">Krekoski Ross: "Re: Unbounded happiness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18767">[ date ]</a>
<a href="index.html#18767">[ thread ]</a>
<a href="subject.html#18767">[ subject ]</a>
<a href="author.html#18767">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:02 MDT
</em></small></p>
</body>
</html>
