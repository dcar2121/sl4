<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Friendliness at different levels</title>
<meta name="Author" content="Stuart Armstrong (dragondreaming@googlemail.com)">
<meta name="Subject" content="Friendliness at different levels">
<meta name="Date" content="2008-05-05">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Friendliness at different levels</h1>
<!-- received="Mon May  5 09:25:59 2008" -->
<!-- isoreceived="20080505152559" -->
<!-- sent="Mon, 5 May 2008 17:22:58 +0200" -->
<!-- isosent="20080505152258" -->
<!-- name="Stuart Armstrong" -->
<!-- email="dragondreaming@googlemail.com" -->
<!-- subject="Friendliness at different levels" -->
<!-- id="38f493f10805050822t19191ba1w7c33931126baaff1@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Stuart Armstrong (<a href="mailto:dragondreaming@googlemail.com?Subject=Re:%20Friendliness%20at%20different%20levels"><em>dragondreaming@googlemail.com</em></a>)<br>
<strong>Date:</strong> Mon May 05 2008 - 09:22:58 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="18811.html">Stuart Armstrong: "Signaling after a singularity"</a>
<li><strong>Previous message:</strong> <a href="18809.html">Stuart Armstrong: "Bound unhappiness below (was Re: What if there's an expiration date?)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18810">[ date ]</a>
<a href="index.html#18810">[ thread ]</a>
<a href="subject.html#18810">[ subject ]</a>
<a href="author.html#18810">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&quot;With great powers come great responsibilities,&quot; Spider-man
<br>
&quot;But if you could choose Doctor, if you could decide who lives and who
<br>
dies, that would make you a monster,&quot; Doctor Who
<br>
<p>I'd like to add my voice to the occasional monologue of complains
<br>
against the term &quot;friendly AI&quot;. I understand why the term is used -
<br>
essentially we want good outcomes from an AI, but the problem of
<br>
safely specifying outcomes is intractable, so the best solution is to
<br>
have an AI that wants similar outcomes to us. Our friends want the
<br>
best for us, hence friendly AI.
<br>
<p>That's fine, but it makes no sense to call an advanced AI friendly. I
<br>
have many good friends, but very few that I would trust as a
<br>
politician, none I would trust as a head of state, and certainly none
<br>
I would trust with the sort of power an advanced AI would wield. I do
<br>
not care if elected leaders feel my pain, understand me, despise or
<br>
love me. I only care that they make decisions that benefit me or
<br>
refrain from hurting me.
<br>
<p>If two people are about to die, and I must choose one to save, then
<br>
universal friendliness won't help me decide. Unless I pick at random,
<br>
I have to use some sort of balance of cost and benefits to make the
<br>
decision.
<br>
<p>Similarly, an advanced AI must make its decisions based on a much more
<br>
complicated calculus of costs and benefits, not on friendliness. If a
<br>
friendly man tries to save people's lives during a flood, and fails to
<br>
save them all, then he is admirable. If an advanced AI fails to save
<br>
someone, then it is likely that the AI decided to let them die. This
<br>
not the decision of a friend, but that of a calculating leader.
<br>
<p>As part of the AI's decision-making process, friendliness reduces to
<br>
valuing humanity's survival, happiness and development. But the actual
<br>
details of how the AI acts are unrelated to any intuitive feelings of
<br>
&quot;friendliness&quot;. The majority of the AI's runtime and decisions will
<br>
not be governed by friendliness. The best model for an AI is that of a
<br>
&quot;good politician&quot; or &quot;benevolent despot&quot;, not a friend.
<br>
<p>So will I continue using the term FAI (rather than benevolent AI, or
<br>
safe AI)? Of course I will, as it's the agreed upon term. I just
<br>
wanted to point out its misleading quality.
<br>
<p>Stuart
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="18811.html">Stuart Armstrong: "Signaling after a singularity"</a>
<li><strong>Previous message:</strong> <a href="18809.html">Stuart Armstrong: "Bound unhappiness below (was Re: What if there's an expiration date?)"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#18810">[ date ]</a>
<a href="index.html#18810">[ thread ]</a>
<a href="subject.html#18810">[ subject ]</a>
<a href="author.html#18810">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:02 MDT
</em></small></p>
</body>
</html>
