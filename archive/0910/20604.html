<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)</title>
<meta name="Author" content="Tim Freeman (tim@fungible.com)">
<meta name="Subject" content="Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)">
<meta name="Date" content="2009-10-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)</h1>
<!-- received="Sat Oct 24 11:01:18 2009" -->
<!-- isoreceived="20091024170118" -->
<!-- sent="Sat, 24 Oct 2009 09:37:25 -0700" -->
<!-- isosent="20091024163725" -->
<!-- name="Tim Freeman" -->
<!-- email="tim@fungible.com" -->
<!-- subject="Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)" -->
<!-- id="20091024170116.895ECD293C@fungible.com" -->
<!-- inreplyto="373999.10408.qm@web51903.mail.re2.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Tim Freeman (<a href="mailto:tim@fungible.com?Subject=Re:%20Why%20extrapolate?%20(was%20Re:%20[sl4]%20to-do%20list%20for%20strong,%20nice%20AI)"><em>tim@fungible.com</em></a>)<br>
<strong>Date:</strong> Sat Oct 24 2009 - 10:37:25 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20605.html">Robin Lee Powell: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>Previous message:</strong> <a href="20603.html">Tim Freeman: "[sl4] Example, and request for a practical experiment (was Re: How big is an FAI solution?) nice AI)"</a>
<li><strong>In reply to:</strong> <a href="20584.html">Matt Mahoney: "Re: [sl4] to-do list for strong, nice AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20605.html">Robin Lee Powell: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>Reply:</strong> <a href="20605.html">Robin Lee Powell: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>Maybe reply:</strong> <a href="20612.html">Frank Adamek: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20604">[ date ]</a>
<a href="index.html#20604">[ thread ]</a>
<a href="subject.html#20604">[ subject ]</a>
<a href="author.html#20604">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
From: Matt Mahoney &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20Why%20extrapolate?%20(was%20Re:%20[sl4]%20to-do%20list%20for%20strong,%20nice%20AI)">matmahoney@yahoo.com</a>&gt;
<br>
<em>&gt;For another proposed definition of Friendliness, see
</em><br>
<em>&gt;<a href="http://intelligence.org/upload/CEV.html">http://intelligence.org/upload/CEV.html</a>
</em><br>
<p>I get parts of CEV.  &quot;Volition&quot; obviously must be understood by the
<br>
AI, and the &quot;Coherent&quot; part is similar enough to the averaging in my
<br>
algorithm that I don't care about the distinction.
<br>
<p>I also get part of the &quot;Extrapolation&quot; step.  If someone wants X
<br>
because it will let them achieve Y, but they have false beliefs and X
<br>
won't really let them achieve Y, then you don't want to give them X
<br>
just because they want it.  The AI should give people what they would
<br>
want if they had true beliefs, not what they actually want.  That's
<br>
one part of Elizer's &quot;Extrapolated&quot; concept.
<br>
<p>But there's more to &quot;Extrapolated&quot; than that.  Quoting from
<br>
<a href="http://intelligence.org/upload/CEV.html">http://intelligence.org/upload/CEV.html</a> as read on 24 Oct 2009:
<br>
<p>&nbsp;&nbsp;&nbsp;In poetic terms, our coherent extrapolated volition is our wish if we
<br>
&nbsp;&nbsp;&nbsp;knew more, thought faster, were more the people we wished we were, had
<br>
&nbsp;&nbsp;&nbsp;grown up farther together; where the extrapolation converges rather
<br>
&nbsp;&nbsp;&nbsp;than diverges, where our wishes cohere rather than interfere;
<br>
&nbsp;&nbsp;&nbsp;extrapolated as we wish that extrapolated, interpreted as we wish that
<br>
&nbsp;&nbsp;&nbsp;interpreted.
<br>
<p>&quot;Knew more&quot; and &quot;thought faster&quot; are close enough to &quot;if they had true
<br>
beliefs&quot; that I don't care about the difference.
<br>
<p>But the other contrafactual things don't seem desirable:
<br>
<p>&quot;were more the people we wished we were&quot;.  This brings to mind people
<br>
with repressed sexuality who want sex but think sex is bad so they
<br>
don't want to want sex.  This is based on a false belief -- sex isn't
<br>
bad in general.  But this person really wishes they didn't want sex.
<br>
<p>&quot;had grown up farther together&quot;: there are toxic people who, if I had
<br>
grown up farther with them, I'd be completely useless.  This became
<br>
utterly clear to me as a consequence of my first marriage.  This part
<br>
of Extrapolation is just bad.
<br>
<p>In general, I want what I want, and except when the AI knows I'm
<br>
mistaken about facts, I therefore want the AI to give me what I want.
<br>
That's the &quot;Volition&quot; part.  There are other people so there has to be
<br>
some compromise between what everyone wants so the AI can do one
<br>
thing; that's the &quot;Coherent&quot; part.  Other than compensating for
<br>
mistaken beliefs, I don't see any use for the &quot;Extrapolation&quot; part.  I
<br>
don't want the AI catering to hypothetical ideal people, I want to the
<br>
AI to give real people what they want.
<br>
<p>Can anyone make a decent case for these dubious parts of Extrapolation?
<br>
<pre>
-- 
Tim Freeman               <a href="http://www.fungible.com">http://www.fungible.com</a>           <a href="mailto:tim@fungible.com?Subject=Re:%20Why%20extrapolate?%20(was%20Re:%20[sl4]%20to-do%20list%20for%20strong,%20nice%20AI)">tim@fungible.com</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20605.html">Robin Lee Powell: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>Previous message:</strong> <a href="20603.html">Tim Freeman: "[sl4] Example, and request for a practical experiment (was Re: How big is an FAI solution?) nice AI)"</a>
<li><strong>In reply to:</strong> <a href="20584.html">Matt Mahoney: "Re: [sl4] to-do list for strong, nice AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20605.html">Robin Lee Powell: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>Reply:</strong> <a href="20605.html">Robin Lee Powell: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>Maybe reply:</strong> <a href="20612.html">Frank Adamek: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20604">[ date ]</a>
<a href="index.html#20604">[ thread ]</a>
<a href="subject.html#20604">[ subject ]</a>
<a href="author.html#20604">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:05 MDT
</em></small></p>
</body>
</html>
