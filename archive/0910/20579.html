<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] to-do list for strong, nice AI</title>
<meta name="Author" content="Luke (wlgriffiths@gmail.com)">
<meta name="Subject" content="Re: [sl4] to-do list for strong, nice AI">
<meta name="Date" content="2009-10-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] to-do list for strong, nice AI</h1>
<!-- received="Tue Oct 20 12:16:54 2009" -->
<!-- isoreceived="20091020181654" -->
<!-- sent="Tue, 20 Oct 2009 14:16:49 -0400" -->
<!-- isosent="20091020181649" -->
<!-- name="Luke" -->
<!-- email="wlgriffiths@gmail.com" -->
<!-- subject="Re: [sl4] to-do list for strong, nice AI" -->
<!-- id="12902e900910201116m7563b037x63c38c3433c2f82c@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="441494.8831.qm@web51912.mail.re2.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Luke (<a href="mailto:wlgriffiths@gmail.com?Subject=Re:%20[sl4]%20to-do%20list%20for%20strong,%20nice%20AI"><em>wlgriffiths@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Oct 20 2009 - 12:16:49 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20580.html">Luke: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>Previous message:</strong> <a href="20578.html">Matt Mahoney: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>In reply to:</strong> <a href="20578.html">Matt Mahoney: "Re: [sl4] to-do list for strong, nice AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20580.html">Luke: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>Reply:</strong> <a href="20580.html">Luke: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>Reply:</strong> <a href="20581.html">Kevin: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>Reply:</strong> <a href="20584.html">Matt Mahoney: "Re: [sl4] to-do list for strong, nice AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20579">[ date ]</a>
<a href="index.html#20579">[ thread ]</a>
<a href="subject.html#20579">[ subject ]</a>
<a href="author.html#20579">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
@Pavitra:  thanks for reminding me of that.  It's true - there's a lot of
<br>
talking that needs to get done before we can throw out the haiku of FGAI
<br>
design.  I accept this fate, this large-scale discussion, though I can't
<br>
promise I'll read everything before I respond.  Not enough time for that.
<br>
@Matt Mahoney:  Two points, as follows:
<br>
<p>(1) With regard to a definition of friendly AI, and how it needs to
<br>
encompass all those bits, I've got a big problem there.  (a) That's
<br>
impossible.  So we either need to find a way around that intractable problem
<br>
(i.e. a smaller definition, within the 10^5 bits range or something, 10^2
<br>
would be great but that's obviously wishful thinking), or we need to accept
<br>
that we're not going to be able to proceed, and start &quot;saying our prayers&quot;
<br>
or seeking &quot;enlightenment&quot; or stocking up on heroin or whatever else we need
<br>
to do to face death.  This is a completely serious point:  if we decide we
<br>
cannot hope to produce this friendly AI, it's better to accept that as
<br>
quickly as possible and decide what we want to do with this short stay
<br>
between the birth canal and the grave.
<br>
<p>However, as a programmer I'm tempted to point out that often you don't need
<br>
to see the bits that represent an object, but merely the bits that represent
<br>
its interface.  Let someone else worry about implementation.
<br>
<p>(2) You said that a test-giver has to be more intelligent than a test-taker.
<br>
&nbsp;I don't think that's necessarily the case.  For instance, what if the test
<br>
consisted of:  &quot;We're dealing with RSA.  Here's an encrypted message, and
<br>
here's the public key that encrypted it.  What is the private key?&quot;  It
<br>
might take massive computational power to &quot;take&quot; that test, i.e. break the
<br>
code.  But it takes orders of magnitude less to both generate the encrypted
<br>
message, and confirm any answer the test-taker provides.  This is quite
<br>
similar to the problem of theorem-provers mentioned above.  Another example
<br>
of a test could be:  &quot;Here's a lab full of standard stock ingredients.
<br>
&nbsp;Create something that will make me trip.  I will give you your grade one
<br>
hour after you deliver your answer.&quot;
<br>
<p><p>As a final point:  I'm going to go ahead and put the to-do list up online.
<br>
&nbsp;I warn I'm going to lean heavily on real-world applicability, so we might
<br>
see a constant resonance between mathematical definitions and what I
<br>
consider &quot;executable&quot; actions.  I'll be putting up steps like &quot;raise
<br>
$20,000,000 to fund research&quot; and &quot;create a computer with 700 TF to perform
<br>
tests&quot; and the like.  Others can focus on the mathematical rigor necessary
<br>
at various junctures.  Defining waypoints as mathematical objects, and the
<br>
interconnecting strategies as meatspace man-hours, may be our best bet.
<br>
<p>&nbsp;- Luke
<br>
<p><p><p>On Tue, Oct 20, 2009 at 11:22 AM, Matt Mahoney &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20to-do%20list%20for%20strong,%20nice%20AI">matmahoney@yahoo.com</a>&gt; wrote:
<br>
<p><em>&gt; Luke wrote:
</em><br>
<em>&gt; &gt; Alright, it is no wonder you guys can't get anything done.  I start a
</em><br>
<em>&gt; single thread, with a single, simple purpose:  to trade versions of a single
</em><br>
<em>&gt; document: the to-do list.  And you all can't resist the urge to get into the
</em><br>
<em>&gt; most arcane, esoteric mathematical bullshit imaginable.  &quot;Degree of
</em><br>
<em>&gt; compressibility&quot;.  &quot;Test giver must have more information than test-taker&quot;.
</em><br>
<em>&gt;  wank wank wank.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Because your checklist is wrong. Specifically, the first 3 steps are wrong.
</em><br>
<em>&gt; This invalidates the last 2 steps that depend on them. To quote:
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; This document implies dependencies only insofar as each step's dependencies should appear before that step.  Note that other sequential orderings are possible while maintaining this constraint.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; [ ] Compile design requirements for &quot;friendly AI&quot;.  When will we know we have succeeded?
</em><br>
<em>&gt;
</em><br>
<em>&gt; [ ] Develop automated tests which will determine whether a given system is friendly to humans or not
</em><br>
<em>&gt; [ ] Develop automated tests which will determine whether a given system is intelligent or not (IQ, whatever)
</em><br>
<em>&gt; 	(these tests should reflect the requirements laid out in the first step: &quot;compile design requirements&quot;)
</em><br>
<em>&gt;
</em><br>
<em>&gt; [ ] Develop prototype systems and apply these tests to them.  Refactor tests as necessary in the case we find that some requirement is not specified in the tests.
</em><br>
<em>&gt;
</em><br>
<em>&gt; [ ] Continue refactoring prototypes until we have a system which passes both the intelligence tests and friendliness tests.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &lt;&lt;&lt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; 1. The definition of &quot;Friendly AI&quot; has an algorithmic complexity of 10^17
</em><br>
<em>&gt; bits. Roughly, it means to do what people want, with conflicts resolved as
</em><br>
<em>&gt; an ideal secrecy-free market would resolve them. So your definition has to
</em><br>
<em>&gt; describe what 10^10 people want, and how much they want it, which means your
</em><br>
<em>&gt; definition must describe what they know, and each person knows about 10^7
</em><br>
<em>&gt; bits that nobody else knows. My definition is cheating, of course, because I
</em><br>
<em>&gt; am pointing to human brains instead of describing what they contain.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Also, I haven't defined &quot;people&quot;. Does it include embryos, animals, slaves,
</em><br>
<em>&gt; women, and illegal immigrants? (Don't give me an answer that depends on your
</em><br>
<em>&gt; cultural beliefs). Does it include future human-animal-robot-software
</em><br>
<em>&gt; hybrids? Do all people have equal rights or do we weight rights by how much
</em><br>
<em>&gt; money you have like in a real market?
</em><br>
<em>&gt;
</em><br>
<em>&gt; 2. You can't test for friendliness unless you already know that the tester
</em><br>
<em>&gt; is friendly. How do you know it isn't lying?
</em><br>
<em>&gt;
</em><br>
<em>&gt; 3. You can't test for intelligence unless you are smarter than the test
</em><br>
<em>&gt; taker. Otherwise, how do you know that it is giving the right answers?
</em><br>
<em>&gt;
</em><br>
<em>&gt; So the result is we will find another way to build AI. There is a US$1
</em><br>
<em>&gt; quadrillion incentive to get it done. That's the value of global human labor
</em><br>
<em>&gt; divided by market interest rates.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Just in case you haven't noticed, the internet is getting smarter.
</em><br>
<em>&gt;
</em><br>
<em>&gt; -- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20to-do%20list%20for%20strong,%20nice%20AI">matmahoney@yahoo.com</a>
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20580.html">Luke: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>Previous message:</strong> <a href="20578.html">Matt Mahoney: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>In reply to:</strong> <a href="20578.html">Matt Mahoney: "Re: [sl4] to-do list for strong, nice AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20580.html">Luke: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>Reply:</strong> <a href="20580.html">Luke: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>Reply:</strong> <a href="20581.html">Kevin: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>Reply:</strong> <a href="20584.html">Matt Mahoney: "Re: [sl4] to-do list for strong, nice AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20579">[ date ]</a>
<a href="index.html#20579">[ thread ]</a>
<a href="subject.html#20579">[ subject ]</a>
<a href="author.html#20579">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:05 MDT
</em></small></p>
</body>
</html>
