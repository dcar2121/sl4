<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence</title>
<meta name="Author" content="Mike Dougherty (msd001@gmail.com)">
<meta name="Subject" content="Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence">
<meta name="Date" content="2009-10-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence</h1>
<!-- received="Wed Oct  7 21:28:36 2009" -->
<!-- isoreceived="20091008032836" -->
<!-- sent="Wed, 7 Oct 2009 23:28:31 -0400" -->
<!-- isosent="20091008032831" -->
<!-- name="Mike Dougherty" -->
<!-- email="msd001@gmail.com" -->
<!-- subject="Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence" -->
<!-- id="62c14240910072028n615d5ef5t8fddfe36f3831226@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="905948.51329.qm@web51908.mail.re2.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Mike Dougherty (<a href="mailto:msd001@gmail.com?Subject=Re:%20[sl4]%20Starglider's%20Mini-FAQ%20on%20Artificial%20Intelligence"><em>msd001@gmail.com</em></a>)<br>
<strong>Date:</strong> Wed Oct 07 2009 - 21:28:31 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20354.html">William Pearson: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<li><strong>Previous message:</strong> <a href="20352.html">Matt Mahoney: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<li><strong>In reply to:</strong> <a href="20352.html">Matt Mahoney: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20355.html">Matt Mahoney: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<li><strong>Reply:</strong> <a href="20355.html">Matt Mahoney: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20353">[ date ]</a>
<a href="index.html#20353">[ thread ]</a>
<a href="subject.html#20353">[ subject ]</a>
<a href="author.html#20353">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Wed, Oct 7, 2009 at 9:58 PM, Matt Mahoney &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20Starglider's%20Mini-FAQ%20on%20Artificial%20Intelligence">matmahoney@yahoo.com</a>&gt;
<br>
wrote:communicate a few bits per second. An AI could guess 90% to 99%
<br>
of what you know because that knowledge is shared by others. That is
<br>
only possible if the AI is connected to many people. Also, the
<br>
cheapest way to collect the remaining 1% to 10% is to monitor your
<br>
communication and actions. For this, it needs internet access because
<br>
that's where you do most of your communication.
<br>
<p>yeah, and early adopters will be waiting in line for the opportunity
<br>
to install these monitors on themselves.  (google Wave?)
<br>
<p><em>&gt; And when I say &quot;cheap&quot; I mean on the order of US $100 trillion to $1 quadrillion. That's how much it costs to collect 10^17 to 10^18 bits of knowledge from 10^10 human brains at 150 words per minute, 1 bit per character compression, and a global average wage rate of $5 per hour. At least until we develop nanoscale brain scanners.
</em><br>
<p>So what happens then?  You pay me $3 per human upload?  At that rate,
<br>
we'll see how quickly the 'non-essential' humans are liquidated.
<br>
That's why I hope to have some useful skill even after the machines
<br>
have displaced the mundane human workfarce.
<br>
<p><em>&gt; An AI isolated from the internet would be *more* dangerous, for the simple reasons that it would know less about people and people would know less about it. And that's assuming it's possible at all. And don't get started on RSI voodoo. It's humanity, not a human, that creates AI. So that is the threshold you need to cross. Anything less is gray goo. An AI can't understand its own source code (Wolpert's theorem) so any improvement has to come from learning and hardware.
</em><br>
<p>Is DNA the &quot;sourcecode&quot; for biological life?  Would that suggest that
<br>
supposed-intelligence (that which we possess compared to so-called
<br>
artificial intelligence we seek to create) is also bound by
<br>
not-knowing?  fwiw - I'm confident that AI research by less than the
<br>
sum of humanity can produce something 'better' than gray goo; there's
<br>
also the paper-clip universe.   :)
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20354.html">William Pearson: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<li><strong>Previous message:</strong> <a href="20352.html">Matt Mahoney: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<li><strong>In reply to:</strong> <a href="20352.html">Matt Mahoney: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20355.html">Matt Mahoney: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<li><strong>Reply:</strong> <a href="20355.html">Matt Mahoney: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20353">[ date ]</a>
<a href="index.html#20353">[ thread ]</a>
<a href="subject.html#20353">[ subject ]</a>
<a href="author.html#20353">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:04 MDT
</em></small></p>
</body>
</html>
