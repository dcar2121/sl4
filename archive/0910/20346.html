<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] I am a Singularitian who does not believe in the  Singularity.</title>
<meta name="Author" content="Randall Schmidt (rschmidt22@gmail.com)">
<meta name="Subject" content="Re: [sl4] I am a Singularitian who does not believe in the  Singularity.">
<meta name="Date" content="2009-10-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] I am a Singularitian who does not believe in the  Singularity.</h1>
<!-- received="Wed Oct  7 11:15:32 2009" -->
<!-- isoreceived="20091007171532" -->
<!-- sent="Wed, 7 Oct 2009 13:15:25 -0400" -->
<!-- isosent="20091007171525" -->
<!-- name="Randall Schmidt" -->
<!-- email="rschmidt22@gmail.com" -->
<!-- subject="Re: [sl4] I am a Singularitian who does not believe in the  Singularity." -->
<!-- id="d5b7a7c30910071015u534711e5p808140ea5178330e@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20091007161322.GP21392@digitalkingdom.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Randall Schmidt (<a href="mailto:rschmidt22@gmail.com?Subject=Re:%20[sl4]%20I%20am%20a%20Singularitian%20who%20does%20not%20believe%20in%20the%20%20Singularity."><em>rschmidt22@gmail.com</em></a>)<br>
<strong>Date:</strong> Wed Oct 07 2009 - 11:15:25 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20347.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>Previous message:</strong> <a href="20345.html">Robin Lee Powell: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>In reply to:</strong> <a href="20345.html">Robin Lee Powell: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20348.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20346">[ date ]</a>
<a href="index.html#20346">[ thread ]</a>
<a href="subject.html#20346">[ subject ]</a>
<a href="author.html#20346">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
A computer intelligent enough to think for itself and act on its own
<br>
initiative needs to have some sort of emotion system similar to that of
<br>
humans, which would in many cases limit its effectiveness. A self-aware
<br>
entity must have a desire to do what it intends to do, a desire rooted in a
<br>
superlative desire (self-preservation, pursuit of power, etc). Thus it's
<br>
necessary to somehow program a computer to desire nothing more than
<br>
servitude to its masters. Would that be difficult? As is evident in humans,
<br>
certain desires are innate and very difficult for ours biological mind to
<br>
act counter to (though it does happen). I think that it would be possible to
<br>
ingrain desires much more deeply in a computer than in a human, but that's a
<br>
pretty abstract idea at this point.
<br>
<p>But what happens when a computer is ordered to do something (for instance,
<br>
kill) that is against its base desires? Following orders would also
<br>
naturally be one of its base desires, so what would it do? Humans tend to
<br>
break down at this point and sometimes behave irrationally. Would computers
<br>
&quot;break&quot; as well?
<br>
<p>On Wed, Oct 7, 2009 at 12:13 PM, Robin Lee Powell &lt;
<br>
<a href="mailto:rlpowell@digitalkingdom.org?Subject=Re:%20[sl4]%20I%20am%20a%20Singularitian%20who%20does%20not%20believe%20in%20the%20%20Singularity.">rlpowell@digitalkingdom.org</a>&gt; wrote:
<br>
<p><em>&gt; On Wed, Oct 07, 2009 at 01:26:15PM +0000, Randall Randall wrote:
</em><br>
<em>&gt; &gt; On Wed, Oct 07, 2009 at 08:41:01AM +0100, Stuart Armstrong wrote:
</em><br>
<em>&gt; &gt; &gt; &gt;&gt; If you saw a random baby lying on the sidewalk, you would not
</em><br>
<em>&gt; &gt; &gt; &gt;&gt; kill it. ?This is a &quot;limitation&quot; in the human architecture.
</em><br>
<em>&gt; &gt; &gt; &gt;&gt; ?Do you find yourself fighting against this built-in
</em><br>
<em>&gt; &gt; &gt; &gt;&gt; limitation? ?Do you find yourself thinking, &quot;You know, my
</em><br>
<em>&gt; &gt; &gt; &gt;&gt; life would be so much better if I wanted to kill babies.
</em><br>
<em>&gt; &gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; &gt; If you substituted the word &quot;baby&quot; for &quot;slug&quot; you would have a
</em><br>
<em>&gt; &gt; &gt; &gt; much more realistic analogy;
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; Um - no you wouldn't. You'd get an massively less realistic
</em><br>
<em>&gt; &gt; &gt; analogy; slugs are things we hate and value not at all. The
</em><br>
<em>&gt; &gt; &gt; process analogised is going from valuing something very highly
</em><br>
<em>&gt; &gt; &gt; to valuing something much less; loving babies but voluntarily
</em><br>
<em>&gt; &gt; &gt; deciding to treat babies as slugs.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Of course, John is talking about the intelligence difference,
</em><br>
<em>&gt; &gt; which he sees as overriding all that &quot;goals&quot; business.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Yes.  This is so blatantly insane, and he seems to not actually
</em><br>
<em>&gt; absorb anything anyone says on the topic, that I wasn't really
</em><br>
<em>&gt; talking to him.  I just wanted to make sure it didn't go
</em><br>
<em>&gt; unchallenged, since there seem to be newbies around.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; Some people do love and highly value their houseplants, which
</em><br>
<em>&gt; &gt; might be an analogy you can both agree on.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Very, very few people would run into a burning house to save their
</em><br>
<em>&gt; houseplants; that's just not a strong enough emotional attachment to
</em><br>
<em>&gt; be a decent analogy.  I guess that's sort of the boundary for me:
</em><br>
<em>&gt; take something you care enough about that you would run into a
</em><br>
<em>&gt; burning house to save it; do you feel &quot;restrained&quot; by the fact that
</em><br>
<em>&gt; you can't want to kill that thing for fun?  Do you wish to fix that
</em><br>
<em>&gt; &quot;limitation&quot;?
</em><br>
<em>&gt;
</em><br>
<em>&gt; The entire idea is preposterous.  Believing that such a thing would
</em><br>
<em>&gt; occur shows an utter lack of understanding of the entire concept of
</em><br>
<em>&gt; goals and/or utility functions.  I'd say it shows an utter lack of
</em><br>
<em>&gt; understanding of the entire concept of *intelligence*, but no-one
</em><br>
<em>&gt; understands intelligence well enough to make a claim like that, I
</em><br>
<em>&gt; think.
</em><br>
<em>&gt;
</em><br>
<em>&gt; -Robin
</em><br>
<em>&gt;
</em><br>
<em>&gt; --
</em><br>
<em>&gt; They say:  &quot;The first AIs will be built by the military as weapons.&quot;
</em><br>
<em>&gt; And I'm  thinking:  &quot;Does it even occur to you to try for something
</em><br>
<em>&gt; other  than  the default  outcome?&quot;  See <a href="http://shrunklink.com/cdiz">http://shrunklink.com/cdiz</a>
</em><br>
<em>&gt; <a href="http://www.digitalkingdom.org/~rlpowell/<http://www.digitalkingdom.org/%7Erlpowell/">http://www.digitalkingdom.org/~rlpowell/<http://www.digitalkingdom.org/%7Erlpowell/</a>&gt;***
</em><br>
<em>&gt; <a href="http://www.lojban.org/">http://www.lojban.org/</a>
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20347.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>Previous message:</strong> <a href="20345.html">Robin Lee Powell: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>In reply to:</strong> <a href="20345.html">Robin Lee Powell: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20348.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20346">[ date ]</a>
<a href="index.html#20346">[ thread ]</a>
<a href="subject.html#20346">[ subject ]</a>
<a href="author.html#20346">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:04 MDT
</em></small></p>
</body>
</html>
