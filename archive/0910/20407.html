<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: [sl4] I am a Singularitian who does not believe in the Singularity.</title>
<meta name="Author" content="Bradley Thomas (brad36@gmail.com)">
<meta name="Subject" content="RE: [sl4] I am a Singularitian who does not believe in the Singularity.">
<meta name="Date" content="2009-10-12">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: [sl4] I am a Singularitian who does not believe in the Singularity.</h1>
<!-- received="Mon Oct 12 10:45:37 2009" -->
<!-- isoreceived="20091012164537" -->
<!-- sent="Mon, 12 Oct 2009 12:45:31 -0400" -->
<!-- isosent="20091012164531" -->
<!-- name="Bradley Thomas" -->
<!-- email="brad36@gmail.com" -->
<!-- subject="RE: [sl4] I am a Singularitian who does not believe in the Singularity." -->
<!-- id="9DAD389E93344A0796A786DA4856D05E@bradley01c25a6" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="4AD2A1D0.60500@gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Bradley Thomas (<a href="mailto:brad36@gmail.com?Subject=RE:%20[sl4]%20I%20am%20a%20Singularitian%20who%20does%20not%20believe%20in%20the%20Singularity."><em>brad36@gmail.com</em></a>)<br>
<strong>Date:</strong> Mon Oct 12 2009 - 10:45:31 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20408.html">Robin Lee Powell: "Re: [sl4] Complete drivel on this list: was: I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>Previous message:</strong> <a href="20406.html">Robin Lee Powell: "Re: [sl4] Complete drivel on this list: was: I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>In reply to:</strong> <a href="20394.html">Pavitra: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20401.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20407">[ date ]</a>
<a href="index.html#20407">[ thread ]</a>
<a href="subject.html#20407">[ subject ]</a>
<a href="author.html#20407">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Your points are well taken. I wish I could see an easy way that it would be
<br>
possible for us to retain control of an AGI. To keep our hands on the reboot
<br>
button. If we don't, we might soon have a God, post-Singularity, if we don't
<br>
already! I think in that scenario most bets are probably off anyway. I think
<br>
we'll probably still be able to influence the AGI to some degree, maybe even
<br>
distract it, or even knock it off course a little, but that's about the
<br>
extent of it. So that's what I mean by &quot;manipulate&quot; in that case - a weaker
<br>
kind of manipulation more like a puppy biting at its heels.
<br>
<p><p>Brad Thomas
<br>
www.bradleythomas.com
<br>
Twitter @bradleymthomas, @instansa
<br>
&nbsp;
<br>
<p><p>-----Original Message-----
<br>
From: <a href="mailto:owner-sl4@sl4.org?Subject=RE:%20[sl4]%20I%20am%20a%20Singularitian%20who%20does%20not%20believe%20in%20the%20Singularity.">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=RE:%20[sl4]%20I%20am%20a%20Singularitian%20who%20does%20not%20believe%20in%20the%20Singularity.">owner-sl4@sl4.org</a>] On Behalf Of Pavitra
<br>
Sent: Sunday, October 11, 2009 11:26 PM
<br>
To: <a href="mailto:sl4@sl4.org?Subject=RE:%20[sl4]%20I%20am%20a%20Singularitian%20who%20does%20not%20believe%20in%20the%20Singularity.">sl4@sl4.org</a>
<br>
Subject: Re: [sl4] I am a Singularitian who does not believe in the
<br>
Singularity.
<br>
<p><p>Bradley Thomas wrote:
<br>
<em>&gt; If humans are included as part of the goal-setting system (by virtue 
</em><br>
<em>&gt; of our ability to reboot the AGI or otherwise affect its operation) 
</em><br>
<em>&gt; then some of our goal-setting will inevitably leak onto the AGI. We'll 
</em><br>
<em>&gt; tweak/reboot it as this suits our own goals.
</em><br>
<p>This assumes that, if the AGI isn't working the way we want, then (1) the
<br>
failure will be detectable, and (2) we'll still have enough power over it
<br>
that we're able to tweak/reboot it.
<br>
<p><em>&gt; I'd argue that so long as humans can get new information to the AGI, 
</em><br>
<em>&gt; humans are part of its goal setting system. The high level goals of 
</em><br>
<em>&gt; the AGI are not immune to interference from us. No matter how secure 
</em><br>
<em>&gt; the AGI's high level goals supposedly are, we could conceive of ways 
</em><br>
<em>&gt; to manipulate them.
</em><br>
<p>That sounds plausible, but I'm not convinced. Isn't this equivalent to
<br>
saying &quot;given two agents playing a game (in the game-theoretic sense),
<br>
player two can always ensure an outcome e finds acceptable&quot;?
<br>
<p><em>&gt; For example imagine an AGI with the top level goals of alternately 
</em><br>
<em>&gt; curing world poverty one day and assisting big business the next. Come 
</em><br>
<em>&gt; midnight, the AGI switches over no matter how successful its been the 
</em><br>
<em>&gt; previous day. Sounds fair so far... Until one day Acme MegaGyroscopes 
</em><br>
<em>&gt; figures out that it can change the rate of spin of the earth...
</em><br>
<p>Realistically, who's going to figure that out first -- the human engineers
<br>
at AMG, or the superhuman AGI?
<br>
<p><p>I think you underestimate the consequences of a vastly superhuman
<br>
intelligence. The difference between a post-Singularity AGI and a human is
<br>
comparable to the difference between a human and a colony of mold, or
<br>
between organic life and dead rock. If we're smart, diligent, and lucky,
<br>
then human-civilized worlds might become like cells in its body.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20408.html">Robin Lee Powell: "Re: [sl4] Complete drivel on this list: was: I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>Previous message:</strong> <a href="20406.html">Robin Lee Powell: "Re: [sl4] Complete drivel on this list: was: I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>In reply to:</strong> <a href="20394.html">Pavitra: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20401.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20407">[ date ]</a>
<a href="index.html#20407">[ thread ]</a>
<a href="subject.html#20407">[ subject ]</a>
<a href="author.html#20407">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:04 MDT
</em></small></p>
</body>
</html>
