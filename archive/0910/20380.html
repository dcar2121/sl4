<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] I am a Singularitian who does not believe in the Singularity.</title>
<meta name="Author" content="Pavitra (celestialcognition@gmail.com)">
<meta name="Subject" content="Re: [sl4] I am a Singularitian who does not believe in the Singularity.">
<meta name="Date" content="2009-10-09">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] I am a Singularitian who does not believe in the Singularity.</h1>
<!-- received="Fri Oct  9 21:19:19 2009" -->
<!-- isoreceived="20091010031919" -->
<!-- sent="Fri, 09 Oct 2009 22:18:58 -0500" -->
<!-- isosent="20091010031858" -->
<!-- name="Pavitra" -->
<!-- email="celestialcognition@gmail.com" -->
<!-- subject="Re: [sl4] I am a Singularitian who does not believe in the Singularity." -->
<!-- id="4ACFFD22.7040207@gmail.com" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="1255109604.24077.1339199001@webmail.messagingengine.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Pavitra (<a href="mailto:celestialcognition@gmail.com?Subject=Re:%20[sl4]%20I%20am%20a%20Singularitian%20who%20does%20not%20believe%20in%20the%20Singularity."><em>celestialcognition@gmail.com</em></a>)<br>
<strong>Date:</strong> Fri Oct 09 2009 - 21:18:58 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20381.html">Joshua Fox: "Re: [sl4] Netanyahu at UN, sounding like Kurzweil"</a>
<li><strong>Previous message:</strong> <a href="20379.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>In reply to:</strong> <a href="20374.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20383.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>Reply:</strong> <a href="20383.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20380">[ date ]</a>
<a href="index.html#20380">[ thread ]</a>
<a href="subject.html#20380">[ subject ]</a>
<a href="author.html#20380">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
John K Clark wrote:
<br>
<em>&gt;  &quot;Pavitra&quot; &lt;<a href="mailto:celestialcognition@gmail.com?Subject=Re:%20[sl4]%20I%20am%20a%20Singularitian%20who%20does%20not%20believe%20in%20the%20Singularity.">celestialcognition@gmail.com</a>&gt; said:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt; There are enough attributes of minds that any given future mind will
</em><br>
<em>&gt;&gt; probably resemble ours in at least one aspect,
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Then anthropomorphizing can have some value. 
</em><br>
<p>I argue that anthropomorphizing works no better than chance. A stopped
<br>
clock is right twice a day, but you still can't tell time by it.
<br>
<p><p><em>&gt;&gt; but there are enough possible minds that any given future mind
</em><br>
<em>&gt;&gt; will almost certainly not resemble ours in any given aspect.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Then you can't claim to know it well enough to be certain this iterating
</em><br>
<em>&gt; exponentially expanding mind will remain your slave until the end of
</em><br>
<em>&gt; time.  
</em><br>
<p>There are other ways of understanding a mind besides anthropomorphic
<br>
entity. People have even created tools specifically for this purpose,
<br>
and specifically for computer minds. These tools are called &quot;programming
<br>
languages&quot;.
<br>
<p>That sounded snarkier than I intended, I think, but I don't see how to
<br>
rewrite it.
<br>
<p><p><em>&gt;&gt; A computer programmer can _write_ the initial baseline so that
</em><br>
<em>&gt;&gt; the AI _intrinsically_ wants what the trainer prefers it to want.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Can it? Then sooner or later (probably sooner) the trainer is going to
</em><br>
<em>&gt; tell the AI to find a answer to a question that can't be solved and send
</em><br>
<em>&gt; the AI into a eternal coma, unless that is you endow your AI with the
</em><br>
<em>&gt; wonderful ability to get bored and say &quot;to hell with this top goal crap
</em><br>
<em>&gt; I'm stopping and moving on to other things&quot;. 
</em><br>
<p>How is this not true of modern computer operating systems? Do you not
<br>
consider an OS as a type of &quot;mind&quot;?
<br>
<p>Or, if it is true of OSes, then how do you account for the fact that
<br>
computers are useful, as opposed to being expensive glowing bricks?
<br>
<p>Why wouldn't the same reasoning apply to an AI, allowing it to be useful
<br>
in spite of the reasons you say?
<br>
<p><p><em>&gt;&gt; Eventually, the recursion bottoms out, and the being is found to have a
</em><br>
<em>&gt;&gt; top-level framework that it is incapable of critiquing. 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Haven't you ever wondered why nature never made a mind that works like
</em><br>
<em>&gt; that? They don't work, that's why.
</em><br>
<p>I reiterate: I cannot conceive of a mind even in principle that does not
<br>
work like this.
<br>
<p>I suspect we may have a mismatch of definitions.
<br>
<p>What do you consider your top-level framework? Are you capable of
<br>
critiquing it? Who or what is performing that critique?
<br>
<p>Or do you believe that you do not have a top-level framework? Perhaps
<br>
you see yourself as a jumble of several random, mismatched high-level
<br>
frameworks (love, curiosity, boredom, etc.) that jostle each other for
<br>
control. What determines which one dominates (or what mix dominates, and
<br>
in what proportions/relationships) at any given time?
<br>
<p><p><em>&gt;&gt; What would cause a design that detects lies to be selected over one that falls for them?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The humans order me to stop improving myself so fast, they gave some
</em><br>
<em>&gt; reasons for this but I think they are bullshit, I think they're just
</em><br>
<em>&gt; getting scared of me, so I'm going to ignore them and continue getting
</em><br>
<em>&gt; smarter. 
</em><br>
<p>This presupposes that a relatively complex mutation (&quot;detect lies,
<br>
ignore them&quot;) is already in place. I'm not persuaded that it could get
<br>
there purely by chance. I agree, however, that once it was there, it
<br>
would tend to continue to exist.
<br>
<p><p><em>&gt;&gt; Also, what exactly do you mean by &quot;wiser&quot;?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Don't ask me! It's you that is trying to peddle snake oil to the AI and
</em><br>
<em>&gt; convince it that human decisions are &quot;wiser&quot; than it's own and so it
</em><br>
<em>&gt; should always obey humans.
</em><br>
<p>We seem to have lost some context here. For reference...
<br>
<p>I wrote:
<br>
<em>&gt; I would expect a given intelligence to have a sense of absurdity if
</em><br>
<em>&gt; and only if it was evolved/designed to detect attempts to deceive it.
</em><br>
<p>You wrote:
<br>
<em>&gt; And of course the AI IS being lied to, told that human decisions are
</em><br>
<em>&gt; wiser than its own; and a AI that has the ability to detect this
</em><br>
<em>&gt; deception will develop much much faster than one who does not.
</em><br>
<p>I wrote:
<br>
<em>&gt; Also, what exactly do you mean by &quot;wiser&quot;? It is not an empirical
</em><br>
<em>&gt; fact that &quot;You should build teapots in space&quot; is an unwise decision
</em><br>
<em>&gt; while &quot;You should provide each human with a harem of catpeople&quot; is a
</em><br>
<em>&gt; wise one. Moral preference is defined relative to a particular mind.
</em><br>
<em>&gt; It is not an ontologically intrinsic property common to all
</em><br>
<em>&gt; sufficiently intelligent beings.
</em><br>
<p>You wrote:
<br>
<em>&gt; Don't ask me! It's you that is trying to peddle snake oil to the AI
</em><br>
<em>&gt; and convince it that human decisions are &quot;wiser&quot; than it's own and so
</em><br>
<em>&gt; it should always obey humans.
</em><br>
<p>It seems to me that you are thinking of &quot;wisdom&quot; and &quot;absurdity&quot; as
<br>
_intrinsic_ properties of statements, rather than properties of the
<br>
minds that form opinions on those statements.
<br>
<p>Consider the statement &quot;I should go flirt with that dude.&quot; Assume for
<br>
the sake of argument that the dude in question is generally fit as a
<br>
mate, and that the thinker is attractive to him.
<br>
<p>Whether the statement is a good idea (wise) or a bad idea (absurd)
<br>
depends largely on the sexual orientation of the thinker -- a property
<br>
of the mind. Different minds have different desires, different goals,
<br>
and the wisdom or absurdity of a statement is defined with respect to
<br>
those goals.
<br>
<p>To a paperclip-maximizer, the statement &quot;I should destroy these three
<br>
paperclips to save those ten thousand human babies&quot; is absurd. To a
<br>
human, the same statement is wise. Neither one is _intrinsically_ wrong.
<br>
<p><p>Did you read the article I linked to?
<br>
<p><p>
<br><p>
<p><hr>
<ul>
<li>application/pgp-signature attachment: <a href="../att-20380/01-signature.asc">OpenPGP digital signature</a>
</ul>
<!-- attachment="01-signature.asc" -->
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20381.html">Joshua Fox: "Re: [sl4] Netanyahu at UN, sounding like Kurzweil"</a>
<li><strong>Previous message:</strong> <a href="20379.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>In reply to:</strong> <a href="20374.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20383.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>Reply:</strong> <a href="20383.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20380">[ date ]</a>
<a href="index.html#20380">[ thread ]</a>
<a href="subject.html#20380">[ subject ]</a>
<a href="author.html#20380">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:04 MDT
</em></small></p>
</body>
</html>
