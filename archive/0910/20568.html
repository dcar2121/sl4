<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] to-do list for strong, nice AI</title>
<meta name="Author" content="Matt Mahoney (matmahoney@yahoo.com)">
<meta name="Subject" content="Re: [sl4] to-do list for strong, nice AI">
<meta name="Date" content="2009-10-16">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] to-do list for strong, nice AI</h1>
<!-- received="Fri Oct 16 14:38:17 2009" -->
<!-- isoreceived="20091016203817" -->
<!-- sent="Fri, 16 Oct 2009 13:38:11 -0700 (PDT)" -->
<!-- isosent="20091016203811" -->
<!-- name="Matt Mahoney" -->
<!-- email="matmahoney@yahoo.com" -->
<!-- subject="Re: [sl4] to-do list for strong, nice AI" -->
<!-- id="151179.12197.qm@web51911.mail.re2.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="4AD41E30.80809@gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Matt Mahoney (<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20to-do%20list%20for%20strong,%20nice%20AI"><em>matmahoney@yahoo.com</em></a>)<br>
<strong>Date:</strong> Fri Oct 16 2009 - 14:38:11 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20569.html">Matt Mahoney: "Re: [sl4] prediction markets"</a>
<li><strong>Previous message:</strong> <a href="20567.html">William Pearson: "[sl4] [Essay brainstorm] Title- The most important question - what will the  impact of AI on humanity be?"</a>
<li><strong>In reply to:</strong> <a href="20447.html">Pavitra: "Re: [sl4] to-do list for strong, nice AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20570.html">Pavitra: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>Reply:</strong> <a href="20570.html">Pavitra: "Re: [sl4] to-do list for strong, nice AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20568">[ date ]</a>
<a href="index.html#20568">[ thread ]</a>
<a href="subject.html#20568">[ subject ]</a>
<a href="author.html#20568">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Pavitra wrote:
<br>
<em>&gt; A[ ] Develop a mathematically formal definition of Friendliness.
</em><br>
<p>In order for AI to do what you want (as opposed to what you tell it), it has to at least know what you know, and use that knowledge at least as fast as your brain does. To satisfy conflicts between people (e.g. I want your money), AI has to know what everyone knows. Then it could calculate what an ideal secrecy-free market would do and allocate resources accordingly.
<br>
<p>One human knows 10^9 bits (Landauer's estimate of human long term memory). 10^10 humans know 10^17 to 10^18 bits, allowing for some overlapping knowledge.
<br>
<p><em>&gt; A-&gt;B[ ] Develop an automated test for Friendliness with a 0% false
</em><br>
<em>&gt;         positive rate and a reasonably low false negative rate.
</em><br>
<p>Unlikely. Using an iterative approach, each time that a human gives feedback to the AI (good or bad), one bit of information is added to the model. Development will be slow.
<br>
&nbsp;
<br>
<em>&gt; C[ ] Develop a mathematically formal definition of intelligence.
</em><br>
<p>Legg and Hutter propose to define universal intelligence as the expected reward given a universal (Solomonoff) distribution of environments. <a href="http://www.hutter1.net/ai/sior.pdf">http://www.hutter1.net/ai/sior.pdf</a> However it is not computable because the number of environments is infinite. Other definitions are possible of course, e.g. the Turing test.
<br>
<p><em>&gt; C-&gt;D[ ] Develop an automated comparison test that returns the more
</em><br>
<em>&gt;         intelligent of two given systems.
</em><br>
<p>How? The test giver has to know more than the test taker.
<br>
<p>However, you don't need C and D. If you solve B then you already have a model of all human minds, and therefore have already solved intelligence, at least by the Turing test.
<br>
<p><em>&gt; B,D-&gt;E[ ] Develop prototype systems and apply these tests to them
</em><br>
<em>&gt;           iteratively until the Singularity occurs.
</em><br>
<p>Let's keep in mind that a Singularity is *not* the goal. The goal is friendly AI. The Singularity is what happens when we lose control of it.
<br>
<p>-- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20to-do%20list%20for%20strong,%20nice%20AI">matmahoney@yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20569.html">Matt Mahoney: "Re: [sl4] prediction markets"</a>
<li><strong>Previous message:</strong> <a href="20567.html">William Pearson: "[sl4] [Essay brainstorm] Title- The most important question - what will the  impact of AI on humanity be?"</a>
<li><strong>In reply to:</strong> <a href="20447.html">Pavitra: "Re: [sl4] to-do list for strong, nice AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20570.html">Pavitra: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>Reply:</strong> <a href="20570.html">Pavitra: "Re: [sl4] to-do list for strong, nice AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20568">[ date ]</a>
<a href="index.html#20568">[ thread ]</a>
<a href="subject.html#20568">[ subject ]</a>
<a href="author.html#20568">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:05 MDT
</em></small></p>
</body>
</html>
