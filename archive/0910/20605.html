<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)</title>
<meta name="Author" content="Robin Lee Powell (rlpowell@digitalkingdom.org)">
<meta name="Subject" content="Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)">
<meta name="Date" content="2009-10-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)</h1>
<!-- received="Sat Oct 24 11:15:21 2009" -->
<!-- isoreceived="20091024171521" -->
<!-- sent="Sat, 24 Oct 2009 10:15:20 -0700" -->
<!-- isosent="20091024171520" -->
<!-- name="Robin Lee Powell" -->
<!-- email="rlpowell@digitalkingdom.org" -->
<!-- subject="Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)" -->
<!-- id="20091024171520.GC18098@digitalkingdom.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="20091024170116.895ECD293C@fungible.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Robin Lee Powell (<a href="mailto:rlpowell@digitalkingdom.org?Subject=Re:%20Why%20extrapolate?%20(was%20Re:%20[sl4]%20to-do%20list%20for%20strong,%20nice%20AI)"><em>rlpowell@digitalkingdom.org</em></a>)<br>
<strong>Date:</strong> Sat Oct 24 2009 - 11:15:20 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20606.html">Tim Freeman: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>Previous message:</strong> <a href="20604.html">Tim Freeman: "Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>In reply to:</strong> <a href="20604.html">Tim Freeman: "Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20606.html">Tim Freeman: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>Reply:</strong> <a href="20606.html">Tim Freeman: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20605">[ date ]</a>
<a href="index.html#20605">[ thread ]</a>
<a href="subject.html#20605">[ subject ]</a>
<a href="author.html#20605">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Sat, Oct 24, 2009 at 09:37:25AM -0700, Tim Freeman wrote:
<br>
<em>&gt; But there's more to &quot;Extrapolated&quot; than that.  Quoting from
</em><br>
<em>&gt; <a href="http://intelligence.org/upload/CEV.html">http://intelligence.org/upload/CEV.html</a> as read on 24 Oct 2009:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    In poetic terms, our coherent extrapolated volition is our wish
</em><br>
<em>&gt;    if we knew more, thought faster, were more the people we wished
</em><br>
<em>&gt;    we were, had grown up farther together; where the extrapolation
</em><br>
<em>&gt;    converges rather than diverges, where our wishes cohere rather
</em><br>
<em>&gt;    than interfere; extrapolated as we wish that extrapolated,
</em><br>
<em>&gt;    interpreted as we wish that interpreted.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &quot;Knew more&quot; and &quot;thought faster&quot; are close enough to &quot;if they had
</em><br>
<em>&gt; true beliefs&quot; that I don't care about the difference.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; But the other contrafactual things don't seem desirable:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &quot;were more the people we wished we were&quot;.  This brings to mind
</em><br>
<em>&gt; people with repressed sexuality who want sex but think sex is bad
</em><br>
<em>&gt; so they don't want to want sex.  This is based on a false belief
</em><br>
<em>&gt; -- sex isn't bad in general.  But this person really wishes they
</em><br>
<em>&gt; didn't want sex.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &quot;had grown up farther together&quot;: there are toxic people who, if I
</em><br>
<em>&gt; had grown up farther with them, I'd be completely useless.  This
</em><br>
<em>&gt; became utterly clear to me as a consequence of my first marriage.
</em><br>
<em>&gt; This part of Extrapolation is just bad.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Can anyone make a decent case for these dubious parts of
</em><br>
<em>&gt; Extrapolation?
</em><br>
<p>I take it as a more or less ordered list; *first* fix those people
<br>
in the ways the obviously need fixing (&quot;know more&quot;, &quot;thought
<br>
faster&quot;) *then* imagine what they would want to fix about themselves
<br>
(&quot;were more the people we wishedwe were&quot;), then imagine them
<br>
learning and changing in response to the people around them (&quot;had
<br>
grown up farther together&quot;), drop all the things that are different
<br>
between people but don't actually matter very much (like, say,
<br>
particular preferences in food or sex or whatever) (&quot;where the
<br>
extrapolation converges rather than diverges, where our wishes
<br>
cohere rather than interfere&quot;), and ask what the people themselves
<br>
thus extrapolated would think of the results (&quot;extrapolated as we
<br>
wish that extrapolated, interpreted as we wish that interpreted&quot;).
<br>
<p>[reordered]
<br>
<em>&gt; In general, I want what I want, and except when the AI knows I'm
</em><br>
<em>&gt; mistaken about facts, I therefore want the AI to give me what I
</em><br>
<em>&gt; want. That's the &quot;Volition&quot; part.  There are other people so there
</em><br>
<em>&gt; has to be some compromise between what everyone wants so the AI
</em><br>
<em>&gt; can do one thing; that's the &quot;Coherent&quot; part.  Other than
</em><br>
<em>&gt; compensating for mistaken beliefs, I don't see any use for the
</em><br>
<em>&gt; &quot;Extrapolation&quot; part.  I don't want the AI catering to
</em><br>
<em>&gt; hypothetical ideal people, I want to the AI to give real people
</em><br>
<em>&gt; what they want.
</em><br>
<p>The vast majority of people in the world (China, India, South
<br>
America, Africa) are still more-or-less medieval peasant farmers;
<br>
maybe not literally, but the mentality is going to be about the
<br>
same.  The world they would envision without more knowledge and more
<br>
time to think about it and so on is going to look very much like the
<br>
stereotypical Christian heaven: you get to lie around and eat
<br>
grapes, and you never do anything because your every need is take
<br>
care of.  No thank you!!  That's hell to me, and after a week or a
<br>
month it would be hell to them too, but it's what they want right
<br>
now.  That (and similar issues, like the millions upon millions of
<br>
people who really want a house and a dog and 2.5 kids and 2 cars)
<br>
is what the extrapolation step is about.
<br>
<p>*You* might not need the extrapolation step, but the mere fact that
<br>
you're reading sl4 makes you, what, one in *one hundred million* in
<br>
the general population?  Please, have pity on everybody else.  :)
<br>
<p>-Robin
<br>
<p><pre>
-- 
They say:  &quot;The first AIs will be built by the military as weapons.&quot;
And I'm  thinking:  &quot;Does it even occur to you to try for something
other  than  the default  outcome?&quot;  See <a href="http://shrunklink.com/cdiz">http://shrunklink.com/cdiz</a>
<a href="http://www.digitalkingdom.org/~rlpowell/">http://www.digitalkingdom.org/~rlpowell/</a> *** <a href="http://www.lojban.org/">http://www.lojban.org/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20606.html">Tim Freeman: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>Previous message:</strong> <a href="20604.html">Tim Freeman: "Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>In reply to:</strong> <a href="20604.html">Tim Freeman: "Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20606.html">Tim Freeman: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>Reply:</strong> <a href="20606.html">Tim Freeman: "Re: Why extrapolate? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20605">[ date ]</a>
<a href="index.html#20605">[ thread ]</a>
<a href="subject.html#20605">[ subject ]</a>
<a href="author.html#20605">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:05 MDT
</em></small></p>
</body>
</html>
