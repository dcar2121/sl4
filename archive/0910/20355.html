<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence</title>
<meta name="Author" content="Matt Mahoney (matmahoney@yahoo.com)">
<meta name="Subject" content="Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence">
<meta name="Date" content="2009-10-08">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence</h1>
<!-- received="Thu Oct  8 07:59:48 2009" -->
<!-- isoreceived="20091008135948" -->
<!-- sent="Thu, 8 Oct 2009 06:59:42 -0700 (PDT)" -->
<!-- isosent="20091008135942" -->
<!-- name="Matt Mahoney" -->
<!-- email="matmahoney@yahoo.com" -->
<!-- subject="Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence" -->
<!-- id="866336.87174.qm@web51908.mail.re2.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="62c14240910072028n615d5ef5t8fddfe36f3831226@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Matt Mahoney (<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20Starglider's%20Mini-FAQ%20on%20Artificial%20Intelligence"><em>matmahoney@yahoo.com</em></a>)<br>
<strong>Date:</strong> Thu Oct 08 2009 - 07:59:42 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20356.html">Stuart Armstrong: "Re: [sl4] I am a Singularitian who does not believe in the  Singularity."</a>
<li><strong>Previous message:</strong> <a href="20354.html">William Pearson: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<li><strong>In reply to:</strong> <a href="20353.html">Mike Dougherty: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20366.html">Mike Dougherty: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<li><strong>Reply:</strong> <a href="20366.html">Mike Dougherty: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20355">[ date ]</a>
<a href="index.html#20355">[ thread ]</a>
<a href="subject.html#20355">[ subject ]</a>
<a href="author.html#20355">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
From: Mike Dougherty &lt;<a href="mailto:msd001@gmail.com?Subject=Re:%20[sl4]%20Starglider's%20Mini-FAQ%20on%20Artificial%20Intelligence">msd001@gmail.com</a>&gt;
<br>
On Wed, Oct 7, 2009 at 9:58 PM, Matt Mahoney &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20Starglider's%20Mini-FAQ%20on%20Artificial%20Intelligence">matmahoney@yahoo.com</a>&gt; wrote:
<br>
<em>&gt;&gt; communicate a few bits per second. An AI could guess 90% to 99%
</em><br>
<em>&gt;&gt; of what you know because that knowledge is shared by others. That is
</em><br>
<em>&gt;&gt; only possible if the AI is connected to many people. Also, the
</em><br>
<em>&gt;&gt; cheapest way to collect the remaining 1% to 10% is to monitor your
</em><br>
<em>&gt;&gt; communication and actions. For this, it needs internet access because
</em><br>
<em>&gt;&gt; that's where you do most of your communication.
</em><br>
<p><em>&gt; yeah, and early adopters will be waiting in line for the opportunity
</em><br>
<em>&gt; to install these monitors on themselves.  (google Wave?)
</em><br>
<p>Google and Yahoo already have copies of thousands of your emails, even those you deleted. AI will make surveillance easier. Imagine billions of high resolution public webcams with face recognition and speech recognition, all instantly transcribed, indexed, and instantly searchable. It's what we want. If we cared about privacy we would be having this conversation by encrypted email instead of on a public forum.
<br>
<p><em>&gt;&gt; And when I say &quot;cheap&quot; I mean on the order of US $100 trillion to $1 quadrillion. That's how much it costs to collect 10^17 to 10^18 bits of knowledge from 10^10 human brains at 150 words per minute, 1 bit per character compression, and a global average wage rate of $5 per hour. At least until we develop nanoscale brain scanners.
</em><br>
<p><em>&gt; So what happens then?  You pay me $3 per human upload?  At that rate,
</em><br>
<em>&gt; we'll see how quickly the 'non-essential' humans are liquidated.
</em><br>
<p><p>So what? If a program simulates you so well that nobody can tell the difference, is it you? Nobody can answer that question, because the question itself is irrational. It only seems important because evolution programmed you to fear the things that can kill you. You'll upload if someone promises to wave a magic wand that transfers your soul.
<br>
<p><em>&gt; That's why I hope to have some useful skill even after the machines
</em><br>
<em>&gt; have displaced the mundane human workfarce.
</em><br>
<p>Forget it. An AI that models your mind could do anything you could.
<br>
<p><em>&gt;&gt; An AI isolated from the internet would be *more* dangerous, for the simple reasons that it would know less about people and people would know less about it. And that's assuming it's possible at all. And don't get started on RSI voodoo. It's humanity, not a human, that creates AI. So that is the threshold you need to cross. Anything less is gray goo. An AI can't understand its own source code (Wolpert's theorem) so any improvement has to come from learning and hardware.
</em><br>
<p><em>&gt; Is DNA the &quot;sourcecode&quot; for biological life?  Would that suggest that
</em><br>
<em>&gt; supposed-intelligence (that which we possess compared to so-called
</em><br>
<em>&gt; artificial intelligence we seek to create) is also bound by
</em><br>
<em>&gt; not-knowing? 
</em><br>
<p>Yes, because Wolpert's theorem still applies. You aren't smart enough to tell which of your children will be more successful than you, even if you sequence their DNA.
<br>
<p><em>&gt; fwiw - I'm confident that AI research by less than the
</em><br>
<em>&gt; sum of humanity can produce something 'better' than gray goo; there's
</em><br>
<em>&gt; also the paper-clip universe.   :)
</em><br>
<p><p>Depends what you mean by &quot;better&quot;. You were created by evolution. It wasn't your idea to program yourself to fear death and then die. But evolution knows better.
<br>
<p><p>-- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20Starglider's%20Mini-FAQ%20on%20Artificial%20Intelligence">matmahoney@yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20356.html">Stuart Armstrong: "Re: [sl4] I am a Singularitian who does not believe in the  Singularity."</a>
<li><strong>Previous message:</strong> <a href="20354.html">William Pearson: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<li><strong>In reply to:</strong> <a href="20353.html">Mike Dougherty: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20366.html">Mike Dougherty: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<li><strong>Reply:</strong> <a href="20366.html">Mike Dougherty: "Re: [sl4] Starglider's Mini-FAQ on Artificial Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20355">[ date ]</a>
<a href="index.html#20355">[ thread ]</a>
<a href="subject.html#20355">[ subject ]</a>
<a href="author.html#20355">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:04 MDT
</em></small></p>
</body>
</html>
