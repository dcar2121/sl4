<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] to-do list for strong, nice AI</title>
<meta name="Author" content="Luke (wlgriffiths@gmail.com)">
<meta name="Subject" content="Re: [sl4] to-do list for strong, nice AI">
<meta name="Date" content="2009-10-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] to-do list for strong, nice AI</h1>
<!-- received="Tue Oct 20 12:26:07 2009" -->
<!-- isoreceived="20091020182607" -->
<!-- sent="Tue, 20 Oct 2009 14:26:01 -0400" -->
<!-- isosent="20091020182601" -->
<!-- name="Luke" -->
<!-- email="wlgriffiths@gmail.com" -->
<!-- subject="Re: [sl4] to-do list for strong, nice AI" -->
<!-- id="12902e900910201126y126250ffu143dfc5eadcac9f4@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="12902e900910201116m7563b037x63c38c3433c2f82c@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Luke (<a href="mailto:wlgriffiths@gmail.com?Subject=Re:%20[sl4]%20to-do%20list%20for%20strong,%20nice%20AI"><em>wlgriffiths@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Oct 20 2009 - 12:26:01 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20581.html">Kevin: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>Previous message:</strong> <a href="20579.html">Luke: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>In reply to:</strong> <a href="20579.html">Luke: "Re: [sl4] to-do list for strong, nice AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20589.html">Tim Freeman: "How big is an FAI solution? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>Reply:</strong> <a href="20589.html">Tim Freeman: "How big is an FAI solution? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20580">[ date ]</a>
<a href="index.html#20580">[ thread ]</a>
<a href="subject.html#20580">[ subject ]</a>
<a href="author.html#20580">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Link to the Google doc:
<br>
<a href="http://docs.google.com/Doc?docid=0AeO1BSsSjfiPZGdjZDN2bWhfMTYwZnM4cWN6ZDk&amp;hl=en">http://docs.google.com/Doc?docid=0AeO1BSsSjfiPZGdjZDN2bWhfMTYwZnM4cWN6ZDk&amp;hl=en</a><br>
Please let me know if you have trouble editing the document. I believe there
<br>
is a discussion feature built into the document; though I'm not sure. If
<br>
there is, please add a quick comment whenever you save changes, explaining
<br>
your rationale. The more concise your comment, the easier it will be for
<br>
future collaborators to read the developmental history of the document.
<br>
<p>- Luke
<br>
<p>On Tue, Oct 20, 2009 at 2:16 PM, Luke &lt;<a href="mailto:wlgriffiths@gmail.com?Subject=Re:%20[sl4]%20to-do%20list%20for%20strong,%20nice%20AI">wlgriffiths@gmail.com</a>&gt; wrote:
<br>
<p><em>&gt; @Pavitra:  thanks for reminding me of that.  It's true - there's a lot of
</em><br>
<em>&gt; talking that needs to get done before we can throw out the haiku of FGAI
</em><br>
<em>&gt; design.  I accept this fate, this large-scale discussion, though I can't
</em><br>
<em>&gt; promise I'll read everything before I respond.  Not enough time for that.
</em><br>
<em>&gt; @Matt Mahoney:  Two points, as follows:
</em><br>
<em>&gt;
</em><br>
<em>&gt; (1) With regard to a definition of friendly AI, and how it needs to
</em><br>
<em>&gt; encompass all those bits, I've got a big problem there.  (a) That's
</em><br>
<em>&gt; impossible.  So we either need to find a way around that intractable problem
</em><br>
<em>&gt; (i.e. a smaller definition, within the 10^5 bits range or something, 10^2
</em><br>
<em>&gt; would be great but that's obviously wishful thinking), or we need to accept
</em><br>
<em>&gt; that we're not going to be able to proceed, and start &quot;saying our prayers&quot;
</em><br>
<em>&gt; or seeking &quot;enlightenment&quot; or stocking up on heroin or whatever else we need
</em><br>
<em>&gt; to do to face death.  This is a completely serious point:  if we decide we
</em><br>
<em>&gt; cannot hope to produce this friendly AI, it's better to accept that as
</em><br>
<em>&gt; quickly as possible and decide what we want to do with this short stay
</em><br>
<em>&gt; between the birth canal and the grave.
</em><br>
<em>&gt;
</em><br>
<em>&gt; However, as a programmer I'm tempted to point out that often you don't need
</em><br>
<em>&gt; to see the bits that represent an object, but merely the bits that represent
</em><br>
<em>&gt; its interface.  Let someone else worry about implementation.
</em><br>
<em>&gt;
</em><br>
<em>&gt; (2) You said that a test-giver has to be more intelligent than a
</em><br>
<em>&gt; test-taker.  I don't think that's necessarily the case.  For instance, what
</em><br>
<em>&gt; if the test consisted of:  &quot;We're dealing with RSA.  Here's an encrypted
</em><br>
<em>&gt; message, and here's the public key that encrypted it.  What is the private
</em><br>
<em>&gt; key?&quot;  It might take massive computational power to &quot;take&quot; that test, i.e.
</em><br>
<em>&gt; break the code.  But it takes orders of magnitude less to both generate the
</em><br>
<em>&gt; encrypted message, and confirm any answer the test-taker provides.  This is
</em><br>
<em>&gt; quite similar to the problem of theorem-provers mentioned above.  Another
</em><br>
<em>&gt; example of a test could be:  &quot;Here's a lab full of standard stock
</em><br>
<em>&gt; ingredients.  Create something that will make me trip.  I will give you your
</em><br>
<em>&gt; grade one hour after you deliver your answer.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; As a final point:  I'm going to go ahead and put the to-do list up online.
</em><br>
<em>&gt;  I warn I'm going to lean heavily on real-world applicability, so we might
</em><br>
<em>&gt; see a constant resonance between mathematical definitions and what I
</em><br>
<em>&gt; consider &quot;executable&quot; actions.  I'll be putting up steps like &quot;raise
</em><br>
<em>&gt; $20,000,000 to fund research&quot; and &quot;create a computer with 700 TF to perform
</em><br>
<em>&gt; tests&quot; and the like.  Others can focus on the mathematical rigor necessary
</em><br>
<em>&gt; at various junctures.  Defining waypoints as mathematical objects, and the
</em><br>
<em>&gt; interconnecting strategies as meatspace man-hours, may be our best bet.
</em><br>
<em>&gt;
</em><br>
<em>&gt;  - Luke
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; On Tue, Oct 20, 2009 at 11:22 AM, Matt Mahoney &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20to-do%20list%20for%20strong,%20nice%20AI">matmahoney@yahoo.com</a>&gt;wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt; Luke wrote:
</em><br>
<em>&gt;&gt; &gt; Alright, it is no wonder you guys can't get anything done.  I start a
</em><br>
<em>&gt;&gt; single thread, with a single, simple purpose:  to trade versions of a single
</em><br>
<em>&gt;&gt; document: the to-do list.  And you all can't resist the urge to get into the
</em><br>
<em>&gt;&gt; most arcane, esoteric mathematical bullshit imaginable.  &quot;Degree of
</em><br>
<em>&gt;&gt; compressibility&quot;.  &quot;Test giver must have more information than test-taker&quot;.
</em><br>
<em>&gt;&gt;  wank wank wank.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Because your checklist is wrong. Specifically, the first 3 steps are
</em><br>
<em>&gt;&gt; wrong. This invalidates the last 2 steps that depend on them. To quote:
</em><br>
<em>&gt;&gt; &gt;&gt;&gt;
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; This document implies dependencies only insofar as each step's dependencies should appear before that step.  Note that other sequential orderings are possible while maintaining this constraint.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; [ ] Compile design requirements for &quot;friendly AI&quot;.  When will we know we have succeeded?
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; [ ] Develop automated tests which will determine whether a given system is friendly to humans or not
</em><br>
<em>&gt;&gt; [ ] Develop automated tests which will determine whether a given system is intelligent or not (IQ, whatever)
</em><br>
<em>&gt;&gt; 	(these tests should reflect the requirements laid out in the first step: &quot;compile design requirements&quot;)
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; [ ] Develop prototype systems and apply these tests to them.  Refactor tests as necessary in the case we find that some requirement is not specified in the tests.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; [ ] Continue refactoring prototypes until we have a system which passes both the intelligence tests and friendliness tests.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; &lt;&lt;&lt;
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; 1. The definition of &quot;Friendly AI&quot; has an algorithmic complexity of 10^17
</em><br>
<em>&gt;&gt; bits. Roughly, it means to do what people want, with conflicts resolved as
</em><br>
<em>&gt;&gt; an ideal secrecy-free market would resolve them. So your definition has to
</em><br>
<em>&gt;&gt; describe what 10^10 people want, and how much they want it, which means your
</em><br>
<em>&gt;&gt; definition must describe what they know, and each person knows about 10^7
</em><br>
<em>&gt;&gt; bits that nobody else knows. My definition is cheating, of course, because I
</em><br>
<em>&gt;&gt; am pointing to human brains instead of describing what they contain.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Also, I haven't defined &quot;people&quot;. Does it include embryos, animals,
</em><br>
<em>&gt;&gt; slaves, women, and illegal immigrants? (Don't give me an answer that depends
</em><br>
<em>&gt;&gt; on your cultural beliefs). Does it include future
</em><br>
<em>&gt;&gt; human-animal-robot-software hybrids? Do all people have equal rights or do
</em><br>
<em>&gt;&gt; we weight rights by how much money you have like in a real market?
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; 2. You can't test for friendliness unless you already know that the tester
</em><br>
<em>&gt;&gt; is friendly. How do you know it isn't lying?
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; 3. You can't test for intelligence unless you are smarter than the test
</em><br>
<em>&gt;&gt; taker. Otherwise, how do you know that it is giving the right answers?
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; So the result is we will find another way to build AI. There is a US$1
</em><br>
<em>&gt;&gt; quadrillion incentive to get it done. That's the value of global human labor
</em><br>
<em>&gt;&gt; divided by market interest rates.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Just in case you haven't noticed, the internet is getting smarter.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; -- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20[sl4]%20to-do%20list%20for%20strong,%20nice%20AI">matmahoney@yahoo.com</a>
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20581.html">Kevin: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>Previous message:</strong> <a href="20579.html">Luke: "Re: [sl4] to-do list for strong, nice AI"</a>
<li><strong>In reply to:</strong> <a href="20579.html">Luke: "Re: [sl4] to-do list for strong, nice AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20589.html">Tim Freeman: "How big is an FAI solution? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<li><strong>Reply:</strong> <a href="20589.html">Tim Freeman: "How big is an FAI solution? (was Re: [sl4] to-do list for strong, nice AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20580">[ date ]</a>
<a href="index.html#20580">[ thread ]</a>
<a href="subject.html#20580">[ subject ]</a>
<a href="author.html#20580">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:05 MDT
</em></small></p>
</body>
</html>
