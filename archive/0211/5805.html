<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Defining Right and Wrong</title>
<meta name="Author" content="Billy Brown (BBrown@RealBusinessSolutions.com)">
<meta name="Subject" content="RE: Defining Right and Wrong">
<meta name="Date" content="2002-11-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Defining Right and Wrong</h1>
<!-- received="Sat Nov 30 10:43:05 2002" -->
<!-- isoreceived="20021130174305" -->
<!-- sent="Sat, 30 Nov 2002 11:40:53 -0600" -->
<!-- isosent="20021130174053" -->
<!-- name="Billy Brown" -->
<!-- email="BBrown@RealBusinessSolutions.com" -->
<!-- subject="RE: Defining Right and Wrong" -->
<!-- id="BOEOLPLEIANPGFGICJLMEEJFCIAA.BBrown@RealBusinessSolutions.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="3DE8615C.6050503@objectent.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Billy Brown (<a href="mailto:BBrown@RealBusinessSolutions.com?Subject=RE:%20Defining%20Right%20and%20Wrong"><em>BBrown@RealBusinessSolutions.com</em></a>)<br>
<strong>Date:</strong> Sat Nov 30 2002 - 10:40:53 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5806.html">Jef Allbright: "Re: Complexity, Ethics, Esthetics (was re: Defining Right and Wrong)"</a>
<li><strong>Previous message:</strong> <a href="5804.html">Cliff Stabbert: "The ethics of prediction"</a>
<li><strong>In reply to:</strong> <a href="5798.html">Samantha Atkins: "Re: Defining Right and Wrong"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5810.html">Michael Roy Ames: "Re: Defining Right and Wrong"</a>
<li><strong>Reply:</strong> <a href="5810.html">Michael Roy Ames: "Re: Defining Right and Wrong"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5805">[ date ]</a>
<a href="index.html#5805">[ thread ]</a>
<a href="subject.html#5805">[ subject ]</a>
<a href="author.html#5805">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Samantha Atkins wrote:
<br>
<em>&gt; Even if you create a model that is logically inconsistent?  You
</em><br>
<em>&gt; cannot isolate the eseential problem by throwing out essential
</em><br>
<em>&gt; parts of the problem.  Only the relatively unimportant mass of
</em><br>
<em>&gt; detail should be removed or a logical consistent analogue to the
</em><br>
<em>&gt; real problem created.
</em><br>
<p>Of course. But I think you mistake my point.
<br>
<p>I think that the central underlying problem of ethics is one that can
<br>
roughly be summarized as &quot;How do we act so as to do as much good (or at
<br>
least as little harm) as we can?&quot; We would like to be able to do so
<br>
reliably, in any situation, and we would ideally like to choose the very
<br>
best course of action instead of just a middling-good one.
<br>
<p>My impossible ethics engine illustrated what it woould take to actually
<br>
acheive this goal in the absence of any prior knowledge about ethics. It
<br>
differs from more conventional treatments of the subject in only two
<br>
significant ways that I can see:
<br>
<p>1) It makes the immense, overwhelming complexity of the problem explicit
<br>
instead of sweeping it under the rug.
<br>
2) Instead of imposing a universal standard for what constitutes a &quot;good&quot; or
<br>
&quot;bad&quot; outcome, it evaluates each actor's experiences by its own standards.
<br>
<p>So, do you see the goal of ethics as somethic different? Or is is just that
<br>
you don't see any point in thinking about the problem in this way?
<br>
<p><em>&gt; &quot;Perfect&quot; knowledge is a logical absurdity.  Do you deny this?
</em><br>
<em>&gt; If so please show how it is possible.  Information will always
</em><br>
<em>&gt; be limited, finite rather than infinite.  Planning time will
</em><br>
<em>&gt; always be finite.  Even a full blown AGI Power does not work by
</em><br>
<em>&gt; magic pixie dust that can do even the logically impossible.
</em><br>
<p>Complete knowledge of the consequences of an action is only a practical
<br>
impossibility, not a logical one. In the real world it can never be
<br>
acheived, thanks to problems ranging from quantum uncertainty to the chaotic
<br>
nature of hman minds and social systems. But one can easily imagine a
<br>
simulated &quot;toy world&quot; in which this is not true - make a version of Life
<br>
that runs for a finite number of turns, and you can easily predict all the
<br>
consequences of any given action.
<br>
<p>Besides, I'm not saying that perfect knowledge is a requirement of good
<br>
ethics, as I mention below.
<br>
<p><em>&gt; Your approach is utterly unworkable so it cannot be said to be
</em><br>
<em>&gt; &quot;more productive&quot;.
</em><br>
<p>Really? Let's take a look at this.
<br>
<p>Obviously, no one will ever be able to built my hypothetical ethics engine
<br>
(at least not in any universe that resemples this one). But that is not a
<br>
new problem in science. You don't have to have a perfect model before you
<br>
can start thinking about ethics.
<br>
<p>The logical approach would be to treat this like any other difficult
<br>
research problem. Start by trying to build a model that works for some
<br>
easy-looking special case, (say, simplified economic transactions between
<br>
really stupid agents, or collaboration/defection in games a little more
<br>
complex that Prisoner's Dillema). Once you find a way to model one toy
<br>
domain, you can use the experience you gained to tackle a harder one.
<br>
<p>Eventually, this kind of research will reach the point where it can handle
<br>
agents and societies complex enough to serve as a model for actual humans.
<br>
At that point you can create a science of experimental ethics, in which you
<br>
run experiments comparing different sets of behavioral rules to see how well
<br>
they work. Unlike abstract philosophical reasoning, this kind of
<br>
experimentation would produce actual data about how systems perform under
<br>
different circumstances, what situations they handle well, where their weak
<br>
areas lie, and so on.
<br>
<p>At this point you've turned the majority of ethics into a combination of
<br>
software engineering and experimental science, which to my mind is a
<br>
necessary step for any serious Friendly AI project. You (or the AI) can then
<br>
go on to build ever-better models, with more predictive power over wider
<br>
ranges of circumstances. You can build up deep knowledge about the results
<br>
of different notions of &quot;good&quot; and &quot;bad&quot;, about the behavior of different
<br>
ethics algorithms, and about the effects of environmental changes like new
<br>
kinds of minds. And you can ground your conclusions in experimental results,
<br>
rather than unfalsifiable argumentation.
<br>
<p>That sounds pretty productive to me.
<br>
<p>Billy
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5806.html">Jef Allbright: "Re: Complexity, Ethics, Esthetics (was re: Defining Right and Wrong)"</a>
<li><strong>Previous message:</strong> <a href="5804.html">Cliff Stabbert: "The ethics of prediction"</a>
<li><strong>In reply to:</strong> <a href="5798.html">Samantha Atkins: "Re: Defining Right and Wrong"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5810.html">Michael Roy Ames: "Re: Defining Right and Wrong"</a>
<li><strong>Reply:</strong> <a href="5810.html">Michael Roy Ames: "Re: Defining Right and Wrong"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5805">[ date ]</a>
<a href="index.html#5805">[ thread ]</a>
<a href="subject.html#5805">[ subject ]</a>
<a href="author.html#5805">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:41 MDT
</em></small></p>
</body>
</html>
