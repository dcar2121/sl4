<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] I am a Singularitian who does not believe in the Singularity</title>
<meta name="Author" content="Robin Lee Powell (rlpowell@digitalkingdom.org)">
<meta name="Subject" content="Re: [sl4] I am a Singularitian who does not believe in the Singularity">
<meta name="Date" content="2009-09-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] I am a Singularitian who does not believe in the Singularity</h1>
<!-- received="Wed Sep 30 14:31:38 2009" -->
<!-- isoreceived="20090930203138" -->
<!-- sent="Wed, 30 Sep 2009 13:31:35 -0700" -->
<!-- isosent="20090930203135" -->
<!-- name="Robin Lee Powell" -->
<!-- email="rlpowell@digitalkingdom.org" -->
<!-- subject="Re: [sl4] I am a Singularitian who does not believe in the Singularity" -->
<!-- id="20090930203135.GJ14589@digitalkingdom.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="1fa8c3b90909300303m3fa1c4e7u98a98c2df1464106@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Robin Lee Powell (<a href="mailto:rlpowell@digitalkingdom.org?Subject=Re:%20[sl4]%20I%20am%20a%20Singularitian%20who%20does%20not%20believe%20in%20the%20Singularity"><em>rlpowell@digitalkingdom.org</em></a>)<br>
<strong>Date:</strong> Wed Sep 30 2009 - 14:31:35 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20336.html">Frank Adamek: "Re: [sl4] I am a Singularitian who does not believe in the Singularity"</a>
<li><strong>Previous message:</strong> <a href="20334.html">Matt Mahoney: "Re: [sl4] I am a Singularitian who does not believe in the Singularity"</a>
<li><strong>In reply to:</strong> <a href="20331.html">Giulio Prisco (2nd email): "[sl4] I am a Singularitian who does not believe in the Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0910/20342.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>Reply:</strong> <a href="../0910/20342.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20335">[ date ]</a>
<a href="index.html#20335">[ thread ]</a>
<a href="subject.html#20335">[ subject ]</a>
<a href="author.html#20335">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Wed, Sep 30, 2009 at 12:03:40PM +0200, Giulio Prisco (2nd email) wrote:
<br>
<em>&gt; Some consider the coming intelligence explosion as an existential
</em><br>
<em>&gt; risk. Superhuman intelligences may have goals inconsistent with
</em><br>
<em>&gt; human survival and prosperity. AI researcher Hugo de Garis
</em><br>
<em>&gt; suggests AIs may simply eliminate the human race, and humans would
</em><br>
<em>&gt; be powerless to stop them. Eliezer Yudkowsky and the Singularity
</em><br>
<em>&gt; Institute for Artificial Intelligence propose that research be
</em><br>
<em>&gt; undertaken to produce friendly artificial intelligence (FAI) in
</em><br>
<em>&gt; order to address the dangers. I must admit to a certain skepticism
</em><br>
<em>&gt; toward FAI: if super intelligences are really super intelligent
</em><br>
<em>&gt; (that is, much more intelligent than us), they will be easily able
</em><br>
<em>&gt; to circumvent any limitations we may try to impose on them. 
</em><br>
<p>That's why imposing limitations is a fail, as has been written about
<br>
extensively.  The point is to make AIs that want to be nice to
<br>
humans in exactly the same way that humans tend to want to be nice
<br>
to babies.
<br>
<p>If you saw a random baby lying on the sidewalk, you would not kill
<br>
it.  This is a &quot;limitation&quot; in the human architecture.  Do you find
<br>
yourself fighting against this built-in limitation?  Do you find
<br>
yourself thinking, &quot;You know, my life would be so much better if I
<br>
wanted to kill babies.  I really want to want to kill babies&quot;?  No,
<br>
of course you don't.  You don't see it as a limitation; it's just a
<br>
part of who you are.  The goal of SIAI is to build AIs that feel the
<br>
same way about humans.
<br>
<p>-Robin
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20336.html">Frank Adamek: "Re: [sl4] I am a Singularitian who does not believe in the Singularity"</a>
<li><strong>Previous message:</strong> <a href="20334.html">Matt Mahoney: "Re: [sl4] I am a Singularitian who does not believe in the Singularity"</a>
<li><strong>In reply to:</strong> <a href="20331.html">Giulio Prisco (2nd email): "[sl4] I am a Singularitian who does not believe in the Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0910/20342.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<li><strong>Reply:</strong> <a href="../0910/20342.html">John K Clark: "Re: [sl4] I am a Singularitian who does not believe in the Singularity."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20335">[ date ]</a>
<a href="index.html#20335">[ thread ]</a>
<a href="subject.html#20335">[ subject ]</a>
<a href="author.html#20335">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:04 MDT
</em></small></p>
</body>
</html>
