<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Uploading with current technology</title>
<meta name="Author" content="Gary Miller (garymiller@starband.net)">
<meta name="Subject" content="RE: Uploading with current technology">
<meta name="Date" content="2002-12-09">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Uploading with current technology</h1>
<!-- received="Mon Dec  9 09:10:53 2002" -->
<!-- isoreceived="20021209161053" -->
<!-- sent="Mon, 9 Dec 2002 11:10:35 -0500" -->
<!-- isosent="20021209161035" -->
<!-- name="Gary Miller" -->
<!-- email="garymiller@starband.net" -->
<!-- subject="RE: Uploading with current technology" -->
<!-- id="000001c29f9d$88b99220$3e553f94@GaryMiller01" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="Pine.SOL.4.33.0212090856050.27372-100000@doll.ssec.wisc.edu" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Gary Miller (<a href="mailto:garymiller@starband.net?Subject=RE:%20Uploading%20with%20current%20technology"><em>garymiller@starband.net</em></a>)<br>
<strong>Date:</strong> Mon Dec 09 2002 - 09:10:35 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5850.html">polysync@pobox.com: "Re: Uploading with current technology"</a>
<li><strong>Previous message:</strong> <a href="5848.html">Bill Hibbard: "Re: Uploading with current technology"</a>
<li><strong>In reply to:</strong> <a href="5848.html">Bill Hibbard: "Re: Uploading with current technology"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5851.html">Bill Hibbard: "RE: Uploading with current technology"</a>
<li><strong>Reply:</strong> <a href="5851.html">Bill Hibbard: "RE: Uploading with current technology"</a>
<li><strong>Reply:</strong> <a href="5854.html">James Rogers: "RE: Uploading with current technology"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5849">[ date ]</a>
<a href="index.html#5849">[ thread ]</a>
<a href="subject.html#5849">[ subject ]</a>
<a href="author.html#5849">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi Bill,
<br>
<p>On Sun, 9 Dec 2002, Bill Hibbard wrote:
<br>
<p><em>&gt;&gt; Furthermore, behaviors learned via their old greedy or xenophobic
</em><br>
values would be negatively 
<br>
<em>&gt;&gt; reinforced and disappear.
</em><br>
&nbsp;
<br>
How do you give negative reinforcement to someone who has succeeded so
<br>
far beyond the average man that they are both spiritually, emotionally
<br>
and physically untouchable?
<br>
<p>Obsessive fear of losing what one has already worked so hard to achieve
<br>
is one of the drivers for achieving ever increasing power and wealth.
<br>
Perhaps it is the recognition and fear of one's eventual mortality today
<br>
that encourages the very rich to share the wealth through philanthropy
<br>
and to invest in their afterlife so to speak.  Once a person has reached
<br>
this level of success and power, I would defy anyone to reeducate them
<br>
to the fact that giving a large portion of their money away is the
<br>
optimal way to further their own self-interests especially if their
<br>
life-spans were hugely extended.
<br>
<p>We live in a day again where the middle class is being eroded from the
<br>
top and bottom. The rich do get richer and the poor are becoming more
<br>
numerous.  I have a tremendous respect for people like Bill Gates who
<br>
are spending large amounts of their money in this life to improve living
<br>
conditions in so many parts of the world.  I would pray to see this
<br>
become the norm instead of the exception.  But unfortunately too many
<br>
billionaires still operate under the philosophy that &quot;whoever dies with
<br>
the most toys (or billions) wins the game&quot;.
<br>
<p><p>-----Original Message-----
<br>
From: <a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Uploading%20with%20current%20technology">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Uploading%20with%20current%20technology">owner-sl4@sl4.org</a>] On Behalf Of Bill
<br>
Hibbard
<br>
Sent: Monday, December 09, 2002 10:00 AM
<br>
To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Uploading%20with%20current%20technology">sl4@sl4.org</a>
<br>
Subject: Re: Uploading with current technology
<br>
<p><p><p>Hi Gordon,
<br>
<p>On Sun, 8 Dec 2002, Gordon Worley wrote:
<br>
<p><em>&gt; On Sunday, December 8, 2002, at 01:08  PM, Ben Goertzel wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; <a href="http://users.rcn.com/standley/AI/immortality.htm">http://users.rcn.com/standley/AI/immortality.htm</a>
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Thoughts?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Can anyone with more neuro expertise tell me: Is this guy correct as
</em><br>
<p><em>&gt; &gt; regards what is currently technologically plausible?
</em><br>
<em>&gt;
</em><br>
<em>&gt; The Singularity and, specifically, FAI is a faster, safer way of 
</em><br>
<em>&gt; transcending.  Super *human* intelligence is highly dangerous.  Think 
</em><br>
<em>&gt; male chimp with nuclear feces.  Unless you've got someone way protect 
</em><br>
<em>&gt; the universe from the super *humans*, we're probably better off with 
</em><br>
<em>&gt; our current brains.
</em><br>
<p>I largely agree. But as I point out in my book:
<br>
<p>&nbsp;&nbsp;<a href="http://www.ssec.wisc.edu/~billh/super.html">http://www.ssec.wisc.edu/~billh/super.html</a>
<br>
<p>after humans meet super-intelligent machines they will want
<br>
to become super-intelligent themselves, and will want the indfinite life
<br>
span of a repairable machine brain supporting their mind.
<br>
<p>With super-intelligent machines, the key to human safety is
<br>
in controlling the values that reinforce learning of intelligent
<br>
behaviors. In machines, we can design them so their behaviors are
<br>
positively reinforced by human happiness and negatively reinforced by
<br>
human unhappiness.
<br>
<p>Behaviors are reinforced by much different values in human brains. Human
<br>
values are mostly self-interest. As social animals humans have some more
<br>
altruistic values, but these mostly depend on social pressure. Very
<br>
powerful humans can transcend social pressure and revert to their
<br>
selfish values, hence the maxim that power corrupts and absolute power
<br>
corrupts absolutely. Nothing will give a human more power than
<br>
super-intelligence.
<br>
<p>Society has a gradual (lots of short-term setbacks, to be
<br>
sure) long-term trend toward equality because human brains
<br>
are distributed quite democratically: the largest IQ (not
<br>
a perfect measure, but widely applied) in history is only
<br>
twice the average. However, the largest computers, buildings, trucks,
<br>
etc are thousands of times their averages. The migration of human minds
<br>
into machine brains theatens to end the even distribution of human
<br>
intelligence, and hence end the gradual long-term trend toward social
<br>
equality.
<br>
<p>Given that the combination of super-intelligence and human values is
<br>
dangerous, the solution is to make alteration of reinforcement learning
<br>
values a necessary condition for granting a human super-intelligence.
<br>
That is, when we have the technology to manipulate human intelligence
<br>
then we also need to develop the technology to manipulate human
<br>
reinforcement learning values. Because this change in values would
<br>
affect learning, it would not immediately change the human's old
<br>
behaviors. Hence they would still &quot;be themselves&quot;. But as they learned
<br>
super-intelligent behaviors, their new values would cause those newly
<br>
learned behaviors to serve the happiness of all humans. Furthermore,
<br>
behaviors learned via their old greedy or xenophobic values would be
<br>
negatively reinforced and disappear.
<br>
<p>One danger is the temptation to use genetic manipulation as a shortcut
<br>
to super-intelligent humans. This may provide a way to increase human
<br>
intelligence before we understand how it works and before we know how to
<br>
change human reinforcement learning values. This danger is neatly
<br>
parallel with Mary Shelley's Frankestein, in which a human monster is
<br>
created by a scientist tinkering with technology thet he did not really
<br>
understand. We need to understand how human brains work and solve the
<br>
AGI problem before we start manipulating human brains.
<br>
<p>Cheers,
<br>
Bill
<br>
----------------------------------------------------------
<br>
Bill Hibbard, SSEC, 1225 W. Dayton St., Madison, WI  53706
<br>
<a href="mailto:test@doll.ssec.wisc.edu?Subject=RE:%20Uploading%20with%20current%20technology">test@doll.ssec.wisc.edu</a>  608-263-4427  fax: 608-263-6738
<br>
<a href="http://www.ssec.wisc.edu/~billh/vis.html">http://www.ssec.wisc.edu/~billh/vis.html</a>
<br>
<p><p>
<br><p>
<p><p><p><hr>
<ul>
<li>text/x-vcard attachment: <a href="../att-5849/01-Gary_A._Miller__garymiller_starband.net___garymiller_starband.net_.vcf">Gary_A._Miller__garymiller_starband.net___garymiller_starband.net_.vcf</a>
</ul>
<!-- attachment="01-Gary_A._Miller__garymiller_starband.net___garymiller_starband.net_.vcf" -->
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5850.html">polysync@pobox.com: "Re: Uploading with current technology"</a>
<li><strong>Previous message:</strong> <a href="5848.html">Bill Hibbard: "Re: Uploading with current technology"</a>
<li><strong>In reply to:</strong> <a href="5848.html">Bill Hibbard: "Re: Uploading with current technology"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5851.html">Bill Hibbard: "RE: Uploading with current technology"</a>
<li><strong>Reply:</strong> <a href="5851.html">Bill Hibbard: "RE: Uploading with current technology"</a>
<li><strong>Reply:</strong> <a href="5854.html">James Rogers: "RE: Uploading with current technology"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5849">[ date ]</a>
<a href="index.html#5849">[ thread ]</a>
<a href="subject.html#5849">[ subject ]</a>
<a href="author.html#5849">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:41 MDT
</em></small></p>
</body>
</html>
