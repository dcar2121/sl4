<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Uploading with current technology (Sorry Off topic)</title>
<meta name="Author" content="Gary Miller (garymiller@starband.net)">
<meta name="Subject" content="RE: Uploading with current technology (Sorry Off topic)">
<meta name="Date" content="2002-12-09">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Uploading with current technology (Sorry Off topic)</h1>
<!-- received="Mon Dec  9 12:16:11 2002" -->
<!-- isoreceived="20021209191611" -->
<!-- sent="Mon, 9 Dec 2002 14:15:48 -0500" -->
<!-- isosent="20021209191548" -->
<!-- name="Gary Miller" -->
<!-- email="garymiller@starband.net" -->
<!-- subject="RE: Uploading with current technology (Sorry Off topic)" -->
<!-- id="000001c29fb7$6ae158e0$3e553f94@GaryMiller01" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="Pine.SOL.4.33.0212091140180.28910-100000@doll.ssec.wisc.edu" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Gary Miller (<a href="mailto:garymiller@starband.net?Subject=RE:%20Uploading%20with%20current%20technology%20(Sorry%20Off%20topic)"><em>garymiller@starband.net</em></a>)<br>
<strong>Date:</strong> Mon Dec 09 2002 - 12:15:48 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5854.html">James Rogers: "RE: Uploading with current technology"</a>
<li><strong>Previous message:</strong> <a href="5852.html">Bill Hibbard: "Re: Uploading with current technology"</a>
<li><strong>In reply to:</strong> <a href="5851.html">Bill Hibbard: "RE: Uploading with current technology"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5858.html">Eliezer S. Yudkowsky: "Re: Uploading with current technology (Sorry Off topic)"</a>
<li><strong>Reply:</strong> <a href="5858.html">Eliezer S. Yudkowsky: "Re: Uploading with current technology (Sorry Off topic)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5853">[ date ]</a>
<a href="index.html#5853">[ thread ]</a>
<a href="subject.html#5853">[ subject ]</a>
<a href="author.html#5853">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Bill and my apologies to the mailing list for being off-topic... 
<br>
<p>On December 9th you said:
<br>
<p>&quot;Bill Gates may not be all that altruistic. Perhaps he is trying to
<br>
counteract the bad publicity of the M$ antitrust case. His anti-AIDS
<br>
campaign is wonderful, but it is interesting that it is targeted at
<br>
India where there are many talented programmers, rather than Africa
<br>
where there are not so many programmers.&quot;
<br>
<p>I can appreciate your cynicism in this day and age.  But since it's
<br>
inception in 1994 the Bill and Melissa Gates foundation is responsible
<br>
for over 2.5 billion in global health program grants!  Even based on
<br>
stock values before the economic downturn this is a sizable percentage
<br>
of his total net worth!  Show me what the next 5 richest people in the
<br>
world have given back to the world in this same time period!
<br>
<p>Infectious Disease and Vaccines  $1,342,508,667
<br>
Reproductive and Health Care       $589,170,701
<br>
HIV/AIDS and TB                    $538,543,383
<br>
Other                               $40,307,826
<br>
Emergency Relief                    $10,350,000
<br>
Total                            $2,520,880,577
<br>
<p>The choice of of India over Africa or any other country was I'm sure
<br>
complex.  When you give money away you have to make sure that the
<br>
country or program accepting is going to make maximal usage of the money
<br>
with a minimum diverted to arms, corrupt government, etc...  You also
<br>
have to look at the other disease and starvation rates to insure you are
<br>
not just prolonging the misery to a population who is being ravaged by
<br>
other problems which are beyond the scope of what you are capable of
<br>
doing.
<br>
<p>I know we in America like to root for the underdog and pick apart the
<br>
biggest and the richest.  Perhaps from jealousy or perhaps it's just our
<br>
nature.  Our children at the same time idolize sports heroes, rap and
<br>
rock stars, and movie stars who sometimes go out of their way to
<br>
glamorize hard drugs, violence, and self-loathing.  Wouldn't it be
<br>
better if they emulated someone who was successful beyond belief and
<br>
gave something back to the world.  
<br>
<p>Yes OpenSource softwarre is free to the world but it will never
<br>
vaccinate one child, or save one family from watching their children
<br>
die.  It may not be that farfetched that the next time you tell someone
<br>
that Microsoft is stealing their money and to use LINUX instead some
<br>
child may go unvaccinated somewhere in the world.  I may be in denial
<br>
but everytime I send money to Microsoft I try to believe that a part of
<br>
that money goes to help someone somewhere in the world.
<br>
<p>&nbsp;
<br>
<p><p>-----Original Message-----
<br>
From: <a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Uploading%20with%20current%20technology%20(Sorry%20Off%20topic)">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Uploading%20with%20current%20technology%20(Sorry%20Off%20topic)">owner-sl4@sl4.org</a>] On Behalf Of Bill
<br>
Hibbard
<br>
Sent: Monday, December 09, 2002 12:55 PM
<br>
To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Uploading%20with%20current%20technology%20(Sorry%20Off%20topic)">sl4@sl4.org</a>
<br>
Subject: RE: Uploading with current technology
<br>
<p><p><p>Hi Gary,
<br>
<p>On Mon, 9 Dec 2002, Gary Miller wrote:
<br>
<p><em>&gt; Hi Bill,
</em><br>
<em>&gt;
</em><br>
<em>&gt; On Sun, 9 Dec 2002, Bill Hibbard wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;&gt; Furthermore, behaviors learned via their old greedy or xenophobic
</em><br>
<em>&gt; values would be negatively
</em><br>
<em>&gt; &gt;&gt; reinforced and disappear.
</em><br>
<em>&gt;
</em><br>
<em>&gt; How do you give negative reinforcement to someone who has succeeded so
</em><br>
<p><em>&gt; far beyond the average man that they are both spiritually, emotionally
</em><br>
<p><em>&gt; and physically untouchable?
</em><br>
<p>Reinforcement values can be built into the basic learning architecture
<br>
of a brain. The communist experiments of the twentieth century
<br>
demonstrated the difficulty of changing basic human values.
<br>
<p><em>&gt; Obsessive fear of losing what one has already worked so hard to 
</em><br>
<em>&gt; achieve is one of the drivers for achieving ever increasing power and 
</em><br>
<em>&gt; wealth. Perhaps it is the recognition and fear of one's eventual 
</em><br>
<em>&gt; mortality today that encourages the very rich to share the wealth 
</em><br>
<em>&gt; through philanthropy and to invest in their afterlife so to speak.  
</em><br>
<em>&gt; Once a person has reached this level of success and power, I would 
</em><br>
<em>&gt; defy anyone to reeducate them to the fact that giving a large portion 
</em><br>
<em>&gt; of their money away is the optimal way to further their own 
</em><br>
<em>&gt; self-interests especially if their life-spans were hugely extended.
</em><br>
<p>This just seconds what I said in my message: socially
<br>
imposed values can be easily over-powered by the innate
<br>
values of human brains, in humans with the power to ignore social
<br>
pressure.
<br>
<p>Thus to insure human safety in a world populated by super- intelligent
<br>
machines or humans, the basic (hard-wired) reinforcement learning values
<br>
of super-intelligent brains must be the happiness of all humans.
<br>
<p><em>&gt; We live in a day again where the middle class is being eroded from the
</em><br>
<p><em>&gt; top and bottom. The rich do get richer and the poor are becoming more 
</em><br>
<em>&gt; numerous.  I have a tremendous respect for people like Bill Gates who 
</em><br>
<em>&gt; are spending large amounts of their money in this life to improve 
</em><br>
<em>&gt; living conditions in so many parts of the world.  I would pray to see 
</em><br>
<em>&gt; this become the norm instead of the exception.  But unfortunately too 
</em><br>
<em>&gt; many billionaires still operate under the philosophy that &quot;whoever 
</em><br>
<em>&gt; dies with the most toys (or billions) wins the game&quot;.
</em><br>
<p>Bill Gates may not be all that altruistic. Perhaps he is trying to
<br>
counteract the bad publicity of the M$ antitrust case. His anti-AIDS
<br>
campaign is wonderful, but it is interesting that it is targeted at
<br>
India where there are many talented programmers, rather than Africa
<br>
where there are not so many programmers.
<br>
<p>Cheers,
<br>
Bill
<br>
<p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Uploading%20with%20current%20technology%20(Sorry%20Off%20topic)">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Uploading%20with%20current%20technology%20(Sorry%20Off%20topic)">owner-sl4@sl4.org</a>] On Behalf Of Bill 
</em><br>
<em>&gt; Hibbard
</em><br>
<em>&gt; Sent: Monday, December 09, 2002 10:00 AM
</em><br>
<em>&gt; To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Uploading%20with%20current%20technology%20(Sorry%20Off%20topic)">sl4@sl4.org</a>
</em><br>
<em>&gt; Subject: Re: Uploading with current technology
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Hi Gordon,
</em><br>
<em>&gt;
</em><br>
<em>&gt; On Sun, 8 Dec 2002, Gordon Worley wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; On Sunday, December 8, 2002, at 01:08  PM, Ben Goertzel wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; &gt; <a href="http://users.rcn.com/standley/AI/immortality.htm">http://users.rcn.com/standley/AI/immortality.htm</a>
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; Thoughts?
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; Can anyone with more neuro expertise tell me: Is this guy correct 
</em><br>
<em>&gt; &gt; &gt; as
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; &gt; regards what is currently technologically plausible?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; The Singularity and, specifically, FAI is a faster, safer way of 
</em><br>
<em>&gt; &gt; transcending.  Super *human* intelligence is highly dangerous.  
</em><br>
<em>&gt; &gt; Think male chimp with nuclear feces.  Unless you've got someone way 
</em><br>
<em>&gt; &gt; protect the universe from the super *humans*, we're probably better 
</em><br>
<em>&gt; &gt; off with our current brains.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I largely agree. But as I point out in my book:
</em><br>
<em>&gt;
</em><br>
<em>&gt;   <a href="http://www.ssec.wisc.edu/~billh/super.html">http://www.ssec.wisc.edu/~billh/super.html</a>
</em><br>
<em>&gt;
</em><br>
<em>&gt; after humans meet super-intelligent machines they will want to become 
</em><br>
<em>&gt; super-intelligent themselves, and will want the indfinite life span of
</em><br>
<p><em>&gt; a repairable machine brain supporting their mind.
</em><br>
<em>&gt;
</em><br>
<em>&gt; With super-intelligent machines, the key to human safety is in 
</em><br>
<em>&gt; controlling the values that reinforce learning of intelligent 
</em><br>
<em>&gt; behaviors. In machines, we can design them so their behaviors are 
</em><br>
<em>&gt; positively reinforced by human happiness and negatively reinforced by 
</em><br>
<em>&gt; human unhappiness.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Behaviors are reinforced by much different values in human brains. 
</em><br>
<em>&gt; Human values are mostly self-interest. As social animals humans have 
</em><br>
<em>&gt; some more altruistic values, but these mostly depend on social 
</em><br>
<em>&gt; pressure. Very powerful humans can transcend social pressure and 
</em><br>
<em>&gt; revert to their selfish values, hence the maxim that power corrupts 
</em><br>
<em>&gt; and absolute power corrupts absolutely. Nothing will give a human more
</em><br>
<p><em>&gt; power than super-intelligence.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Society has a gradual (lots of short-term setbacks, to be
</em><br>
<em>&gt; sure) long-term trend toward equality because human brains are 
</em><br>
<em>&gt; distributed quite democratically: the largest IQ (not a perfect 
</em><br>
<em>&gt; measure, but widely applied) in history is only twice the average. 
</em><br>
<em>&gt; However, the largest computers, buildings, trucks, etc are thousands 
</em><br>
<em>&gt; of times their averages. The migration of human minds into machine 
</em><br>
<em>&gt; brains theatens to end the even distribution of human intelligence, 
</em><br>
<em>&gt; and hence end the gradual long-term trend toward social equality.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Given that the combination of super-intelligence and human values is 
</em><br>
<em>&gt; dangerous, the solution is to make alteration of reinforcement 
</em><br>
<em>&gt; learning values a necessary condition for granting a human 
</em><br>
<em>&gt; super-intelligence. That is, when we have the technology to manipulate
</em><br>
<p><em>&gt; human intelligence then we also need to develop the technology to 
</em><br>
<em>&gt; manipulate human reinforcement learning values. Because this change in
</em><br>
<p><em>&gt; values would affect learning, it would not immediately change the 
</em><br>
<em>&gt; human's old behaviors. Hence they would still &quot;be themselves&quot;. But as 
</em><br>
<em>&gt; they learned super-intelligent behaviors, their new values would cause
</em><br>
<p><em>&gt; those newly learned behaviors to serve the happiness of all humans. 
</em><br>
<em>&gt; Furthermore, behaviors learned via their old greedy or xenophobic 
</em><br>
<em>&gt; values would be negatively reinforced and disappear.
</em><br>
<em>&gt;
</em><br>
<em>&gt; One danger is the temptation to use genetic manipulation as a shortcut
</em><br>
<p><em>&gt; to super-intelligent humans. This may provide a way to increase human 
</em><br>
<em>&gt; intelligence before we understand how it works and before we know how 
</em><br>
<em>&gt; to change human reinforcement learning values. This danger is neatly 
</em><br>
<em>&gt; parallel with Mary Shelley's Frankestein, in which a human monster is 
</em><br>
<em>&gt; created by a scientist tinkering with technology thet he did not 
</em><br>
<em>&gt; really understand. We need to understand how human brains work and 
</em><br>
<em>&gt; solve the AGI problem before we start manipulating human brains.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Cheers,
</em><br>
<em>&gt; Bill
</em><br>
<em>&gt; ----------------------------------------------------------
</em><br>
<em>&gt; Bill Hibbard, SSEC, 1225 W. Dayton St., Madison, WI  53706 
</em><br>
<em>&gt; <a href="mailto:test@doll.ssec.wisc.edu?Subject=RE:%20Uploading%20with%20current%20technology%20(Sorry%20Off%20topic)">test@doll.ssec.wisc.edu</a>  608-263-4427  fax: 608-263-6738 
</em><br>
<em>&gt; <a href="http://www.ssec.wisc.edu/~billh/vis.html">http://www.ssec.wisc.edu/~billh/vis.html</a>
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<p><p>
<br><p>
<p><p><p><hr>
<ul>
<li>text/x-vcard attachment: <a href="../att-5853/01-Gary_A._Miller__garymiller_starband.net___garymiller_starband.net_.vcf">Gary_A._Miller__garymiller_starband.net___garymiller_starband.net_.vcf</a>
</ul>
<!-- attachment="01-Gary_A._Miller__garymiller_starband.net___garymiller_starband.net_.vcf" -->
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5854.html">James Rogers: "RE: Uploading with current technology"</a>
<li><strong>Previous message:</strong> <a href="5852.html">Bill Hibbard: "Re: Uploading with current technology"</a>
<li><strong>In reply to:</strong> <a href="5851.html">Bill Hibbard: "RE: Uploading with current technology"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5858.html">Eliezer S. Yudkowsky: "Re: Uploading with current technology (Sorry Off topic)"</a>
<li><strong>Reply:</strong> <a href="5858.html">Eliezer S. Yudkowsky: "Re: Uploading with current technology (Sorry Off topic)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5853">[ date ]</a>
<a href="index.html#5853">[ thread ]</a>
<a href="subject.html#5853">[ subject ]</a>
<a href="author.html#5853">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:41 MDT
</em></small></p>
</body>
</html>
