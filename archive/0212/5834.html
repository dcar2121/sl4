<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Complexity, Ethics, Esthetics (was re: Defining Right and Wrong)</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: Complexity, Ethics, Esthetics (was re: Defining Right and Wrong)">
<meta name="Date" content="2002-12-05">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Complexity, Ethics, Esthetics (was re: Defining Right and Wrong)</h1>
<!-- received="Thu Dec  5 12:10:08 2002" -->
<!-- isoreceived="20021205191008" -->
<!-- sent="Thu, 05 Dec 2002 11:13:33 -0800" -->
<!-- isosent="20021205191333" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Complexity, Ethics, Esthetics (was re: Defining Right and Wrong)" -->
<!-- id="3DEFA55D.6000505@objectent.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="1112529186.20021204131952@earthlink.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20Complexity,%20Ethics,%20Esthetics%20(was%20re:%20Defining%20Right%20and%20Wrong)"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Thu Dec 05 2002 - 12:13:33 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5835.html">Samantha Atkins: "Re: The SSSM revisited"</a>
<li><strong>Previous message:</strong> <a href="5833.html">Damien Broderick: "RE: The SSSM revisited"</a>
<li><strong>In reply to:</strong> <a href="5824.html">Cliff Stabbert: "Re[2]: Complexity, Ethics, Esthetics (was re: Defining Right and Wrong)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0211/5773.html">Peter Voss: "RE: Defining Right and Wrong"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5834">[ date ]</a>
<a href="index.html#5834">[ thread ]</a>
<a href="subject.html#5834">[ subject ]</a>
<a href="author.html#5834">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Cliff Stabbert wrote:
<br>
<em>&gt; Wednesday, December 4, 2002, 5:23:46 AM, Samantha Atkins wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; SA&gt; Cliff Stabbert wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;&gt;Tuesday, December 3, 2002, 1:46:23 PM, Samantha Atkins wrote:
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;&gt;SA&gt; All the above said though, I have no right to choose for anyone 
</em><br>
<em>&gt;&gt;&gt;SA&gt; else.  If they want the equivalent to being a wirehead then they 
</em><br>
<em>&gt;&gt;&gt;SA&gt; must have room to choose that although not to bind others to 
</em><br>
<em>&gt;&gt;&gt;SA&gt; supporting their decision directly.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;But here, we get into the subtle details (where mr. S. is known to
</em><br>
<em>&gt;&gt;&gt;hang out) of how one determines what an entity wants.  If you're a
</em><br>
<em>&gt;&gt;&gt;parent, you know that ultimately your child's happiness is better
</em><br>
<em>&gt;&gt;&gt;served by a healthy diet than always giving in to the child's
</em><br>
<em>&gt;&gt;&gt;*proclaimed* desire -- for McDonald's and candy, say (I am
</em><br>
<em>&gt;&gt;&gt;conveniently sidestepping media saturation influence here, which does
</em><br>
<em>&gt;&gt;&gt;play a big role).
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt; SA&gt; I was not speaking of children and I don't think a metaphor of 
</em><br>
<em>&gt; SA&gt; human adults as children relative to a FAI is at all 
</em><br>
<em>&gt; SA&gt; appropriate.  A FAI worth its salt will know that Friendliness 
</em><br>
<em>&gt; SA&gt; relative to humans requires persuasion in non-coercive human 
</em><br>
<em>&gt; SA&gt; activities.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Alright, I think we're talking past each other here.  Of course I
</em><br>
<em>&gt; don't have the right to deny others the choice to be a wirehead.
</em><br>
<em>&gt; I was raising the issue of whether an _FAI_ would offer that option, and
</em><br>
<em>&gt; if it did, to what extent it should try to persuade people choosing it
</em><br>
<em>&gt; that there are better things.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I was not trying to reduce the FAI-human relationship to a simple
</em><br>
<em>&gt; parent-child one, but there are analogous elements if:
</em><br>
<em>&gt;   - self-actualization of human potential is &quot;best&quot; for humans
</em><br>
<em>&gt;   - many humans will choose quick and shallow satisfaction over
</em><br>
<em>&gt;     that deeper one
</em><br>
<em>&gt;   - the FAI &quot;knows better&quot;
</em><br>
<em>&gt;
</em><br>
<p>Full actualization is the goal.  Self-actualization is one 
<br>
interpretation of the principle of non-coercion.  There is 
<br>
nothing wrong with &quot;leading the horse to water&quot;.  Forcing the 
<br>
horse to drink is coercive. Seeking to persuade the horse is not.
<br>
<p><em>&gt; Here in the US, it's certainly not just children who eat too much
</em><br>
<em>&gt; McDonald's and candy...
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't think an FAI should force anybody to do anything.  But the
</em><br>
<em>&gt; question of where &quot;persuasion&quot; crosses that line is a bit tricky with
</em><br>
<em>&gt; a superintelligence.
</em><br>
<em>&gt; 
</em><br>
<p>Agreed in the sense that there is an open question, in my mind 
<br>
at least, about when it is or is not permissible to augment/cure 
<br>
problems in individuals that they are incapable of perhaps even 
<br>
noticing, even when they are carefully pointed out, much less 
<br>
requesting a cure for.   This problem exists today in, for 
<br>
instance, our treatment of the allegedly mentally ill.
<br>
<p><em>&gt; 
</em><br>
<em>&gt;&gt;&gt;======
</em><br>
<em>&gt;&gt;&gt;A tangentially related issue:
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;SA&gt; Not to mention that the above is massively boring.  You would
</em><br>
<em>&gt;&gt;&gt;SA&gt; have to remove part of human intelligence to have many people 
</em><br>
<em>&gt;&gt;&gt;SA&gt; &quot;happy&quot; with simply continuous pleasure.  Pleasure is also quite 
</em><br>
<em>&gt;&gt;&gt;SA&gt; relative for us.  Too much of a &quot;good thing&quot; results in the 
</em><br>
<em>&gt;&gt;&gt;SA&gt; devaluation of that pleasure and even eventual repugnance.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;What if you could devise an &quot;optimal path&quot; -- the best rythm of
</em><br>
<em>&gt;&gt;&gt;alternating ups and downs, challenges and rewards -- is that something
</em><br>
<em>&gt;&gt;&gt;a superintelligence should guide us along, or would that be _less than
</em><br>
<em>&gt;&gt;&gt;optimally rewarding_ because we hadn't chosen that path completely
</em><br>
<em>&gt;&gt;&gt;independently?  
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt; 
</em><br>
<p>I don't posit any requirement that we find the optimal path 
<br>
completely independently.  As a matter of fact, I do not believe 
<br>
that human beings are powerful or clean enough information 
<br>
processors to have an great likelihood of finding such a path 
<br>
unaided.
<br>
<p>One of my strongest desires for GAI and IA is to increase such 
<br>
processing ability (and yes, wisdom to boot) to find much more 
<br>
optiomal paths than those proposed and followed today.
<br>
<p><p><em>&gt; SA&gt; What if we stop thinking up rather low grade &quot;solutions&quot; and 
</em><br>
<em>&gt; SA&gt; think about higher level ones and how those may be made most 
</em><br>
<em>&gt; SA&gt; likely?  Human actualization is not about getting the most 
</em><br>
<em>&gt; SA&gt; pleasure jollies.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Yes, that's my point.  That there may be an optimal path towards
</em><br>
<em>&gt; actualization, consisting of the right sequence of challenges and
</em><br>
<em>&gt; rewards, in any given instance.  My question is whether we would feel
</em><br>
<em>&gt; cheated out of &quot;real&quot; challenge if offered such a path (should it
</em><br>
<em>&gt; exist).
</em><br>
<em>&gt; 
</em><br>
<p>Carrot and stick is not a good model but I take your general 
<br>
point.  Some people will feel cheated perhaps.  But I will not 
<br>
be among them.
<br>
<p><em>&gt; Should an FAI offer such paths?  Or should it just restrict itself to
</em><br>
<em>&gt; giving people freedom, i.e. disallowing the initiation of force?
</em><br>
<em>&gt;
</em><br>
<p>It most certainly should offer such paths.  A FAI inforcing 
<br>
non-coercion whether the people freely choose it or not is a 
<br>
preemptive example.
<br>
<p><p><em>&gt; If it does more, then what is that more and where are the lines it
</em><br>
<em>&gt; shouldn't cross?
</em><br>
<em>&gt;
</em><br>
<p>There are lines but I doubt that either of us have sufficient 
<br>
intelligence and wisdom to fully draw them.  :-)
<br>
<p><p><em>&gt; 
</em><br>
<em>&gt;&gt;&gt;Except maybe to point out that the notion of &quot;objective ethics&quot; is at
</em><br>
<em>&gt;&gt;&gt;least as difficult as the notion of &quot;objective aesthetics&quot;.  
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; SA&gt; That is not a meaningful observation in this context.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Perhaps it is for those who claim objective ethics are possible while
</em><br>
<em>&gt; they might agree if asked that beauty is in the eye of the beholder,
</em><br>
<em>&gt; or determined by (cultural, historical, personal) context.  If
</em><br>
<em>&gt; aesthetics is context-dependent surely ethics is.
</em><br>
<em>&gt;
</em><br>
<p>That does not cleanly follow and this line does not seem 
<br>
fruitful to the  main conversations.
<br>
<p><em>&gt; 
</em><br>
<em>&gt;&gt;&gt;Somehow we
</em><br>
<em>&gt;&gt;&gt;have to reconcile the notion that &quot;it's all subjective&quot; with the
</em><br>
<em>&gt;&gt;&gt;notion that it's not _all_ _just_ subjective, that some things _are_,
</em><br>
<em>&gt;&gt;&gt;dammit, better/more artful than others.  
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; SA&gt; It is impossible to reconcile opposites.  It is not all just 
</em><br>
<em>&gt; SA&gt; subjective so why should I reconcile what is to that spurious idea?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Because humans hold contradictary ideas, which is why I used &quot;the
</em><br>
<em>&gt; notion that&quot; rather than &quot;the fact that&quot;.  If we're going to build
</em><br>
<em>&gt; superintelligences we need to get beyond that and other paradoxes.
</em><br>
<em>&gt; 
</em><br>
<p>We need to follow what is true to the best of our ability (and 
<br>
the AIs eventually) to find it.  We do not need to reconcile 
<br>
what truth we have found to falsehoods.
<br>
<p><em>&gt; 
</em><br>
<em>&gt;&gt;&gt;To tie this in with your
</em><br>
<em>&gt;&gt;&gt;earlier statement, perhaps the ethical as well as the aesthetical is
</em><br>
<em>&gt;&gt;&gt;that which increases your intelligence and / or the opportunities for
</em><br>
<em>&gt;&gt;&gt;actualizing its potential...words such as &quot;uplifting&quot; are often
</em><br>
<em>&gt;&gt;&gt;applied in such contexts.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; SA&gt; Perhaps a shorter statement would be that the Good is that which 
</em><br>
<em>&gt; SA&gt; actualizes the life/existence of the sentient beings involved. 
</em><br>
<em>&gt; SA&gt; The &quot;Good&quot; applies both to judging/providing a partial basis for 
</em><br>
<em>&gt; SA&gt; Ethics and Aesthetics.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I can agree with that statement, and I'm curious what role you feel an
</em><br>
<em>&gt; FAI should play in regards to it.
</em><br>
<em>&gt;
</em><br>
<p>I think the FAI will be much better at understanding what most 
<br>
fully actualizes the life/existence of itself and other 
<br>
sentients than we are.
<br>
<p>- samantha
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5835.html">Samantha Atkins: "Re: The SSSM revisited"</a>
<li><strong>Previous message:</strong> <a href="5833.html">Damien Broderick: "RE: The SSSM revisited"</a>
<li><strong>In reply to:</strong> <a href="5824.html">Cliff Stabbert: "Re[2]: Complexity, Ethics, Esthetics (was re: Defining Right and Wrong)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0211/5773.html">Peter Voss: "RE: Defining Right and Wrong"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5834">[ date ]</a>
<a href="index.html#5834">[ thread ]</a>
<a href="subject.html#5834">[ subject ]</a>
<a href="author.html#5834">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:41 MDT
</em></small></p>
</body>
</html>
