<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Existential Risk and Fermi's Paradox</title>
<meta name="Author" content="Larry (entropy@farviolet.com)">
<meta name="Subject" content="Re: Existential Risk and Fermi's Paradox">
<meta name="Date" content="2007-04-18">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Existential Risk and Fermi's Paradox</h1>
<!-- received="Wed Apr 18 09:59:57 2007" -->
<!-- isoreceived="20070418155957" -->
<!-- sent="Wed, 18 Apr 2007 08:56:29 -0700 (PDT)" -->
<!-- isosent="20070418155629" -->
<!-- name="Larry" -->
<!-- email="entropy@farviolet.com" -->
<!-- subject="Re: Existential Risk and Fermi's Paradox" -->
<!-- id="Pine.LNX.4.60.0704180814490.4944@farviolet.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="f21c22e30704180351le6965achb46757b7fd5eb48e@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Larry (<a href="mailto:entropy@farviolet.com?Subject=Re:%20Existential%20Risk%20and%20Fermi's%20Paradox"><em>entropy@farviolet.com</em></a>)<br>
<strong>Date:</strong> Wed Apr 18 2007 - 09:56:29 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="16329.html">Eliezer S. Yudkowsky: "Re: Existential Risk and Fermi's Paradox"</a>
<li><strong>Previous message:</strong> <a href="16327.html">Stathis Papaioannou: "Re: Existential Risk and Fermi's Paradox"</a>
<li><strong>In reply to:</strong> <a href="16327.html">Stathis Papaioannou: "Re: Existential Risk and Fermi's Paradox"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16329.html">Eliezer S. Yudkowsky: "Re: Existential Risk and Fermi's Paradox"</a>
<li><strong>Reply:</strong> <a href="16329.html">Eliezer S. Yudkowsky: "Re: Existential Risk and Fermi's Paradox"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16328">[ date ]</a>
<a href="index.html#16328">[ thread ]</a>
<a href="subject.html#16328">[ subject ]</a>
<a href="author.html#16328">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Wed, 18 Apr 2007, Stathis Papaioannou wrote:
<br>
<p><em>&gt; On 4/18/07, Larry &lt;<a href="mailto:entropy@farviolet.com?Subject=Re:%20Existential%20Risk%20and%20Fermi's%20Paradox">entropy@farviolet.com</a>&gt; wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt; Not to mention the universe is intrinsically intelligent. The real change
</em><br>
<em>&gt;&gt; has been in the efficiency of intelligence.
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; 0) The universe got here somehow
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; 1) The slow intelligence of random chemical reactions
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; 2) gives us simple self replicators
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; 3) gives us simple animals/plants and sexual reproduction
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; 4) gives us simple nervous systems
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; 5) gives us complex nervous systems and complex tool use
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; 6) gives us beings able to rapidly custom design beings
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Our brains are nothing but speed up evolution. The birth and
</em><br>
<em>&gt;&gt; death of firing patterns replacing the birth and death of life
</em><br>
<em>&gt;&gt; forms.
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Its built into the circuitry that way all through us. At each
</em><br>
<em>&gt;&gt; level nerve pulses compete to make it to the next, the
</em><br>
<em>&gt;&gt; &quot;dominant&quot; pulses generating negative feedback that supresses
</em><br>
<em>&gt;&gt; the lesser. That way your hand on the stove pulls you away from
</em><br>
<em>&gt;&gt; worrying about your overdue bills for a moment.
</em><br>
<em>&gt;
</em><br>
<em>&gt; That's an impressively elegant synthesis. The only problem I have with it is
</em><br>
<em>&gt; that it implies a hierarchy in evolution, progressing towards ever greater
</em><br>
<em>&gt; (faster, more complex, more concentrated) intelligence. This may be just
</em><br>
<em>&gt; prejudice on my part, but I have long assumed that those books on evolution
</em><br>
<em>&gt; I read as a kid which put Man at the top of the heap were a throwback to
</em><br>
<em>&gt; pre-Copernican times. It would be neater if the collective intelligence of
</em><br>
<em>&gt; bacteria in principle could defeat any more complex organism.
</em><br>
<p>What your experiencing right now is the collective intelligence of
<br>
bacteria. We are just big bacterial colonies with a subset
<br>
(brain) specialized for intelligence :)
<br>
<p>But even the non neurological intelligence of bacteria is quite impressive,
<br>
it built us, and our brains, a feat we can't yet replicate. A large bowl
<br>
of organic chemical soup given 4 billion years under a big light is far
<br>
far smarter than a human being or all human beings put together is. The
<br>
soup has been churning out creative works left and right.
<br>
<p>It now seems to be standard dogma to say &quot;evolution doesn't advance&quot;, a
<br>
reflexive response to the old dogma showing mankind as the end goal of
<br>
evolution. Neither is accurate. Evolution is like a random walk, and 
<br>
random walks do expand over time. There is nothing wrong with saying that
<br>
evolution (on earth) is now covering virgin territory in the form of human
<br>
beings. Of course we arn't the only virgin territory, I'm sure a bacteria
<br>
somewhere has some new exciting capability as well.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="16329.html">Eliezer S. Yudkowsky: "Re: Existential Risk and Fermi's Paradox"</a>
<li><strong>Previous message:</strong> <a href="16327.html">Stathis Papaioannou: "Re: Existential Risk and Fermi's Paradox"</a>
<li><strong>In reply to:</strong> <a href="16327.html">Stathis Papaioannou: "Re: Existential Risk and Fermi's Paradox"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="16329.html">Eliezer S. Yudkowsky: "Re: Existential Risk and Fermi's Paradox"</a>
<li><strong>Reply:</strong> <a href="16329.html">Eliezer S. Yudkowsky: "Re: Existential Risk and Fermi's Paradox"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#16328">[ date ]</a>
<a href="index.html#16328">[ thread ]</a>
<a href="subject.html#16328">[ subject ]</a>
<a href="author.html#16328">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:57 MDT
</em></small></p>
</body>
</html>
