<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Normative Reasoning: A Siren Song?</title>
<meta name="Author" content="Michael Wilson (mwdestinystar@yahoo.co.uk)">
<meta name="Subject" content="Normative Reasoning: A Siren Song?">
<meta name="Date" content="2004-09-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Normative Reasoning: A Siren Song?</h1>
<!-- received="Sun Sep 19 08:02:48 2004" -->
<!-- isoreceived="20040919140248" -->
<!-- sent="Sun, 19 Sep 2004 15:02:45 +0100 (BST)" -->
<!-- isosent="20040919140245" -->
<!-- name="Michael Wilson" -->
<!-- email="mwdestinystar@yahoo.co.uk" -->
<!-- subject="Normative Reasoning: A Siren Song?" -->
<!-- id="20040919140245.20562.qmail@web25306.mail.ukl.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Wilson (<a href="mailto:mwdestinystar@yahoo.co.uk?Subject=Re:%20Normative%20Reasoning:%20A%20Siren%20Song?"><em>mwdestinystar@yahoo.co.uk</em></a>)<br>
<strong>Date:</strong> Sun Sep 19 2004 - 08:02:45 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9842.html">Jef Allbright: "Re: Normative Reasoning: A Siren Song?"</a>
<li><strong>Previous message:</strong> <a href="9840.html">Eliezer Yudkowsky: "Re: Litter on the Bayesian Way?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9842.html">Jef Allbright: "Re: Normative Reasoning: A Siren Song?"</a>
<li><strong>Reply:</strong> <a href="9842.html">Jef Allbright: "Re: Normative Reasoning: A Siren Song?"</a>
<li><strong>Reply:</strong> <a href="9843.html">Nick Bostrom: "Re: Normative Reasoning: A Siren Song?"</a>
<li><strong>Reply:</strong> <a href="9844.html">Thomas Buckner: "Re: Normative Reasoning: A Siren Song?"</a>
<li><strong>Maybe reply:</strong> <a href="9853.html">Sebastian Hagen: "Re: Normative Reasoning: A Siren Song?"</a>
<li><strong>Reply:</strong> <a href="9873.html">Peter C. McCluskey: "Re: Normative Reasoning: A Siren Song?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9841">[ date ]</a>
<a href="index.html#9841">[ thread ]</a>
<a href="subject.html#9841">[ subject ]</a>
<a href="author.html#9841">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Though speculation about post-Singularity development trajectories is
<br>
usually futile, my recent research has thrown up a serious moral issue
<br>
which I believe has important implications for CV. The basic points are
<br>
that a normative method of reasoning exists, it and close approximations
<br>
thereof are tremendously powerful and any self-improving rational
<br>
intelligence (artificial or upload) will eventually converge to this
<br>
architecture unless their utility function explicitly prevents this
<br>
action.
<br>
<p>The problem here is that just about all the human qualities we care about
<br>
are actually the result of serious flaws in our cognitive architecture,
<br>
and many of these seem to have lossless translations into goal specifications
<br>
for a perfectly rational substrate (the basis for Yudkowsky's really
<br>
powerful optimisation processes). As humanity self-improves, normative
<br>
reasoning (of which appropriately implemented Solomonoff induction is at
<br>
the very least a good approximation) is a major attractor; adopting it makes
<br>
you as effective as possible at utilising any finite amount of information
<br>
and computing power. If there's any sort of competition going on, turning
<br>
yourself into a RPOP is the way to win. Unfortunately it also appears to be
<br>
the end of most of the stuff we place moral value on. A universe full of
<br>
perfect rationalists is a universe where all diversity resides solely in
<br>
people's goal systems (which may or may not converge); the qualities of
<br>
'insight', 'creativeness', 'willpower' etc will all dissappear as they are
<br>
defined against flaws, and goal-system properties such as 'compassion' will
<br>
revert to 'did this person have an initial utility function that was
<br>
compassionate under renomralisation'? This is on top of the already known
<br>
issues with qualia and the illusion of free will; both are results of
<br>
specific (adaptive) flaws in human introspective capability which would be
<br>
relatively trivial for transhumans to engineer out, but at the cost of
<br>
breaking the grounding for the actual (rather than theoretical)
<br>
implementation of our moral and legal systems and creating something we can
<br>
no longer emphasise with.
<br>
<p>The basic question here is 'can we create a Power we can care about?'. A
<br>
Yudkowsky RPOP is at least potentially a Power, but it is explicitly
<br>
designed to be one we don't care about, as it isn't sentient in a way we'd
<br>
assign moral worth to (a decision currently made using our ad-hoc evolved
<br>
neural lash-together). What do we need to add to make it volitional, and
<br>
what further characteristics would we want to be present in the beings 
<br>
humanity will become? Are some inherent limitations and flaws actually
<br>
necessary in an intelligence order to qualify as something worthwhile?
<br>
Less relevantly, is a Nice Place To Live likely to insist that its volitional
<br>
sentients have some selection of reasoning flaws in order to create a
<br>
diverse and interesting society? This is something of a blow for
<br>
rationalists, in that perfect rationality may indeed be hopelessly inhuman,
<br>
but isn't there a way to hybridise normative and non-normative reasoning
<br>
into a cognitive architecture that is both powerful and morally relevant
<br>
(ok, perhaps this is my desire for Cosmic Power coming through :)?
<br>
<p>The CV question could be glibly summarised as 'is there a likely incremental
<br>
self-improvement path from me to a paperclip optimiser?'. While few people
<br>
like paperclips /that/ much, it seems likely that many people would choose
<br>
to become perfect rationalists without appreciating what they're losing. If
<br>
there is a path to normative reasoning that looks locally good all the way
<br>
and reports back that everything is fine when extrapolating, an
<br>
implementation of CV that doesn't allow for this may lead us into something
<br>
we should consider a disaster.
<br>
<p>This issue is ultimately a comprehension gap; a universe of perfect
<br>
rationalists might well be rated as valuable inhabitants, but we have no
<br>
way of mapping our conception of worthwhile and desirable onto this
<br>
basically alien assessment. Along the wild ride that has constituted my
<br>
seed AI research to date, my original engineering attitude (focus on
<br>
practical stuff that works, everything can be fixed with enough technology)
<br>
has had to expand to acknowledge the value of both the abstract (normative
<br>
reasoning theory and relevant cosmology) and the humanist (despite all the
<br>
hard maths and stuff you have to cover just to avoid disaster, Friendliness
<br>
ultimately comes down to a question of what sort of universe we want to
<br>
live in).
<br>
<p>&nbsp;* Michael Wilson
<br>
<p><a href="http://www.sl4.org/bin/wiki.pl?Starglider">http://www.sl4.org/bin/wiki.pl?Starglider</a>
<br>
<p><p><p><p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
___________________________________________________________ALL-NEW Yahoo! Messenger - all new features - even more fun!  <a href="http://uk.messenger.yahoo.com">http://uk.messenger.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9842.html">Jef Allbright: "Re: Normative Reasoning: A Siren Song?"</a>
<li><strong>Previous message:</strong> <a href="9840.html">Eliezer Yudkowsky: "Re: Litter on the Bayesian Way?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9842.html">Jef Allbright: "Re: Normative Reasoning: A Siren Song?"</a>
<li><strong>Reply:</strong> <a href="9842.html">Jef Allbright: "Re: Normative Reasoning: A Siren Song?"</a>
<li><strong>Reply:</strong> <a href="9843.html">Nick Bostrom: "Re: Normative Reasoning: A Siren Song?"</a>
<li><strong>Reply:</strong> <a href="9844.html">Thomas Buckner: "Re: Normative Reasoning: A Siren Song?"</a>
<li><strong>Maybe reply:</strong> <a href="9853.html">Sebastian Hagen: "Re: Normative Reasoning: A Siren Song?"</a>
<li><strong>Reply:</strong> <a href="9873.html">Peter C. McCluskey: "Re: Normative Reasoning: A Siren Song?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9841">[ date ]</a>
<a href="index.html#9841">[ thread ]</a>
<a href="subject.html#9841">[ subject ]</a>
<a href="author.html#9841">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:48 MDT
</em></small></p>
</body>
</html>
