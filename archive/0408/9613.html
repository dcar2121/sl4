<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: 'The Libertarian-Transhumanist Philosophical Platform'</title>
<meta name="Author" content="Eugen Leitl (eugen@leitl.org)">
<meta name="Subject" content="Re: 'The Libertarian-Transhumanist Philosophical Platform'">
<meta name="Date" content="2004-08-10">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: 'The Libertarian-Transhumanist Philosophical Platform'</h1>
<!-- received="Tue Aug 10 03:54:01 2004" -->
<!-- isoreceived="20040810095401" -->
<!-- sent="Tue, 10 Aug 2004 11:53:57 +0200" -->
<!-- isosent="20040810095357" -->
<!-- name="Eugen Leitl" -->
<!-- email="eugen@leitl.org" -->
<!-- subject="Re: 'The Libertarian-Transhumanist Philosophical Platform'" -->
<!-- id="20040810095357.GE1477@leitl.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="41188907.7010806@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eugen Leitl (<a href="mailto:eugen@leitl.org?Subject=Re:%20'The%20Libertarian-Transhumanist%20Philosophical%20Platform'"><em>eugen@leitl.org</em></a>)<br>
<strong>Date:</strong> Tue Aug 10 2004 - 03:53:57 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="9614.html">David: "Universe is manifestation of Mathematics?"</a>
<li><strong>Previous message:</strong> <a href="9612.html">Eliezer Yudkowsky: "Re: 'The Libertarian-Transhumanist Philosophical Platform'"</a>
<li><strong>In reply to:</strong> <a href="9612.html">Eliezer Yudkowsky: "Re: 'The Libertarian-Transhumanist Philosophical Platform'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9617.html">Eliezer Yudkowsky: "Re: 'The Libertarian-Transhumanist Philosophical Platform'"</a>
<li><strong>Reply:</strong> <a href="9617.html">Eliezer Yudkowsky: "Re: 'The Libertarian-Transhumanist Philosophical Platform'"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9613">[ date ]</a>
<a href="index.html#9613">[ thread ]</a>
<a href="subject.html#9613">[ subject ]</a>
<a href="author.html#9613">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Tue, Aug 10, 2004 at 04:36:23AM -0400, Eliezer Yudkowsky wrote:
<br>
<p><em>&gt; Also, Geddes, kindly do not call it &quot;Yudkowsky's arrow of morality&quot; for I 
</em><br>
<em>&gt; never said such a thing.
</em><br>
<p>Speaking of which, kindly stop putting words in my mouth as well:
<br>
to wit: <a href="http://www.intelligence.org/yudkowsky/friendly.html">http://www.intelligence.org/yudkowsky/friendly.html</a>
<br>
<p>&quot;Eugen Leitl believes that altruism is impossible, period, for a
<br>
superintelligence (SI), whether that superintelligence is derived from humans
<br>
or AIs. The last time we argued this, which was quite sometime ago, and thus
<br>
his views may be different now, he was arguing for the impossibility of
<br>
altruistic SI based on the belief that, one, &quot;All minds necessarily seek to
<br>
survive as a subgoal, therefore this subgoal can stomp on a supergoal&quot;; and
<br>
two, &quot;In a Darwinian scenario, any mind that doesn't seek to survive will
<br>
die, therefore all minds will evolve an independent drive for survival.&quot; His
<br>
first argument is flawed on grounds that it's easy to construct mind models
<br>
in which subgoals do not stomp supergoals; in fact, it's easy to construct
<br>
mind models in which &quot;subgoals&quot; are only temporary empirical regularities, or
<br>
even, given sufficient computing power, mind models in which no elements
<br>
called &quot;subgoals&quot; exist. His second argument is flawed on two grounds. First,
<br>
Darwinian survival properties do not necessarily have a one-to-one
<br>
correspondence with cognitive motives, and if they did, the universal drive
<br>
would be reproduction, not survival; and second, post-Singularity scenarios
<br>
don't contain any room for Darwinian scenarios, let alone Darwinian scenarios
<br>
that are capable of wiping out every trace of intelligent morality.
<br>
<p>Eugen essentially views evolutionary design as the strongest form of design,
<br>
much like John Smart, though possibly for different reasons, and thus he
<br>
discounts intelligence as a possible navigator in the distribution of future
<br>
minds. (I do wish to note that I may be misrepresenting Eugen here.) Eugen
<br>
and I have also discussed his ideas for a Singularity without AI. As I
<br>
recall, his ideas require the uploading of a substantial portion of the human
<br>
race, possibly even without their consent, and distributing these uploads
<br>
throughout the Solar System, before any of them are allowed to begin a hard
<br>
takeoff, except for a small steering committee, which is supposed to abstain
<br>
from any intelligence enhancement, because he doesn't trust uploads either. I
<br>
believe the practical feasibility, and likely the desirability, of this
<br>
scenario is zero.&quot;
<br>
<p>I've never said the quotes you attribute to me in &quot;&quot;, and you *do* 
<br>
misprepresent several things we've talked about.
<br>
<p>So kindly pull it from your site. Thanks. (Why did I need to find this
<br>
through Google of all things? Before you write stuff about people, and 
<br>
publish it, you ought to notify said people to prevent reactions like this). 
<br>
<p><pre>
-- 
Eugen* Leitl <a href="http://leitl.org">leitl</a>
______________________________________________________________
ICBM: 48.07078, 11.61144            <a href="http://www.leitl.org">http://www.leitl.org</a>
8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE
<a href="http://moleculardevices.org">http://moleculardevices.org</a>         <a href="http://nanomachines.net">http://nanomachines.net</a>

</pre>
<p>
<p><hr>
<ul>
<li>application/pgp-signature attachment: <a href="../att-9613/01-part">stored</a>
</ul>
<!-- attachment="01-part" -->
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="9614.html">David: "Universe is manifestation of Mathematics?"</a>
<li><strong>Previous message:</strong> <a href="9612.html">Eliezer Yudkowsky: "Re: 'The Libertarian-Transhumanist Philosophical Platform'"</a>
<li><strong>In reply to:</strong> <a href="9612.html">Eliezer Yudkowsky: "Re: 'The Libertarian-Transhumanist Philosophical Platform'"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="9617.html">Eliezer Yudkowsky: "Re: 'The Libertarian-Transhumanist Philosophical Platform'"</a>
<li><strong>Reply:</strong> <a href="9617.html">Eliezer Yudkowsky: "Re: 'The Libertarian-Transhumanist Philosophical Platform'"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#9613">[ date ]</a>
<a href="index.html#9613">[ thread ]</a>
<a href="subject.html#9613">[ subject ]</a>
<a href="author.html#9613">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:48 MDT
</em></small></p>
</body>
</html>
