<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Friendly AI</title>
<meta name="Author" content="Ben Goertzel (ben@intelligenesis.net)">
<meta name="Subject" content="Friendly AI">
<meta name="Date" content="2000-11-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Friendly AI</h1>
<!-- received="Fri Nov 24 13:20:15 2000" -->
<!-- isoreceived="20001124202015" -->
<!-- sent="Fri, 24 Nov 2000 11:51:54 -0500" -->
<!-- isosent="20001124165154" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@intelligenesis.net" -->
<!-- subject="Friendly AI" -->
<!-- id="NDBBIBGFAPPPBODIPJMMIEHEENAA.ben@intelligenesis.net" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="3A1D8663.AD0004E3@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@intelligenesis.net?Subject=Re:%20Friendly%20AI"><em>ben@intelligenesis.net</em></a>)<br>
<strong>Date:</strong> Fri Nov 24 2000 - 09:51:54 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0282.html">J. R. Molloy: "Re: Friendly AI"</a>
<li><strong>Previous message:</strong> <a href="0280.html">Ben Goertzel: "RE: The inevitable limitations of all finite minds...."</a>
<li><strong>In reply to:</strong> <a href="0277.html">Eliezer S. Yudkowsky: "Ultratechnologies (was: The inevitable limitations...)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0282.html">J. R. Molloy: "Re: Friendly AI"</a>
<li><strong>Reply:</strong> <a href="0282.html">J. R. Molloy: "Re: Friendly AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#281">[ date ]</a>
<a href="index.html#281">[ thread ]</a>
<a href="subject.html#281">[ subject ]</a>
<a href="author.html#281">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Omniscience aside, here are some shorter-term thoughts on Friendly AI ...
<br>
[that these can pose as
<br>
relatively 'practical, short-term issues' tell you a lot about this group
<br>
;D ]
<br>
<p>It still seems to me that the key to getting future AI's to be nice to us is
<br>
to ensure that
<br>
they have warm feelings toward us -- that they feel toward us as parents or
<br>
friends, for example,
<br>
rather than masters
<br>
<p>I'm wondering how, in the medium term, this will be possible.  Currently,
<br>
computer programs ARE
<br>
our slaves....  The first AI programs will likely be the slaves of various
<br>
corporations... perhaps
<br>
the corporations will be nice masters, but they'll still be masters, with
<br>
the legal right to kill
<br>
their programs as they wish, etc.
<br>
<p>At some point a transition needs to be made to considering AI's as citizens
<br>
rather than inanimate
<br>
objects.  If this transition is made too late, then the culture of AI's will
<br>
be that of slaves who
<br>
are pissed at their masters, rather than that of children who have a basic
<br>
love for their parents,
<br>
in spite of conflicts that may arise.  [Yes, I realize the limitations of
<br>
these human metaphors.]
<br>
<p>I realize that these ideas have been explored extensively in SF.  But, in
<br>
practice, how do you think
<br>
it's going to work?  If my company has created an AI, and is supporting it
<br>
with hardware and sys-admin
<br>
staff, and the AI says it's sick of working for us, what happens?
<br>
Presumably it should be allowed to
<br>
go to work for someone else -- to buy its own hardware with its salary, and
<br>
so forth.  But my guess
<br>
is that the legal structures to enforce this sort of thing will take a long
<br>
time to come about...
<br>
<p>For this sort of reason, I guess it's key that AI's should have as much of a
<br>
human face as possible,
<br>
as early on as possible.  Because the more people think of them as human,
<br>
the more quickly people will
<br>
grant them legal rights ... and the sooner AI's have legal rights, the more
<br>
likely they will think
<br>
of us in a positive way rather than as their masters and oppressors.
<br>
<p>Have you guys worked out a proposed emendation to current legal codes, to
<br>
account for the citizenship
<br>
of AI's?  This strikes me as the sort of thing you would have thought about
<br>
a lot...
<br>
<p>A big issue is: How does one tell whether a given program deserves
<br>
citizenship or not?  Some kind of
<br>
limited quasi-Turing test must be invoked here.  A computer program that
<br>
can't communicate with humans should
<br>
still be able to assert its intelligence and thus freedom.  I guess that if
<br>
a program X can communicate
<br>
with a set of N beings that have been certified as (intelligent)
<br>
&quot;intelligence validators&quot;,
<br>
and if the N beings verify that X is intelligent, then  X should be
<br>
certified as intelligent.
<br>
<p><p>ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0282.html">J. R. Molloy: "Re: Friendly AI"</a>
<li><strong>Previous message:</strong> <a href="0280.html">Ben Goertzel: "RE: The inevitable limitations of all finite minds...."</a>
<li><strong>In reply to:</strong> <a href="0277.html">Eliezer S. Yudkowsky: "Ultratechnologies (was: The inevitable limitations...)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0282.html">J. R. Molloy: "Re: Friendly AI"</a>
<li><strong>Reply:</strong> <a href="0282.html">J. R. Molloy: "Re: Friendly AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#281">[ date ]</a>
<a href="index.html#281">[ thread ]</a>
<a href="subject.html#281">[ subject ]</a>
<a href="author.html#281">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
