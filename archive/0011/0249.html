<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Pain vs. negative feedback (was: Evolving minds)</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Pain vs. negative feedback (was: Evolving minds)">
<meta name="Date" content="2000-11-18">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Pain vs. negative feedback (was: Evolving minds)</h1>
<!-- received="Sat Nov 18 19:35:35 2000" -->
<!-- isoreceived="20001119023535" -->
<!-- sent="Sat, 18 Nov 2000 19:33:44 -0500" -->
<!-- isosent="20001119003344" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Pain vs. negative feedback (was: Evolving minds)" -->
<!-- id="3A171FE8.98358010@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="JBEPKOGDDIKKAHFPOEFICEFMCCAA.ben@webmind.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Pain%20vs.%20negative%20feedback%20(was:%20Evolving%20minds)"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Sat Nov 18 2000 - 17:33:44 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0250.html">J. R. Molloy: "Re: Evolving minds"</a>
<li><strong>Previous message:</strong> <a href="0248.html">Dale Johnstone: "RE: META: Evolving minds"</a>
<li><strong>In reply to:</strong> <a href="0243.html">Ben Goertzel: "RE: Evolving minds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0251.html">Ben Goertzel: "RE: Pain vs. negative feedback (was: Evolving minds)"</a>
<li><strong>Reply:</strong> <a href="0251.html">Ben Goertzel: "RE: Pain vs. negative feedback (was: Evolving minds)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#249">[ date ]</a>
<a href="index.html#249">[ thread ]</a>
<a href="subject.html#249">[ subject ]</a>
<a href="author.html#249">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Goertzel wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; In Feb. we'll start a new phase, when we'll make operational
</em><br>
<em>&gt; the &quot;psyche&quot; component of the system (goals, feelings,
</em><br>
<em>&gt; motivations) ... we then will be quite precisely dealing with
</em><br>
<em>&gt; issues of friendliness and unfriendliness.  Questions like:
</em><br>
<em>&gt; What attitude does the system have when we insert new knowledge
</em><br>
<em>&gt; into its mind, which causes it annoyance and pain because it
</em><br>
<em>&gt; forces it to revise its hard-won beliefs....
</em><br>
<p>I really think you're making unnecessary problems for yourselves!  The
<br>
human brain uses instincts because it was built that way.  Why use
<br>
instincts when you can use declarative, rational, context-sensitive
<br>
thoughts to accomplish the same function with more finesse?  Because
<br>
thoughts are slower?  True.  Still, why use blind instincts when you can
<br>
use context-sensitive instincts?  Why should the system experience pain
<br>
when propagating updates to old knowledge, any more than it experiences
<br>
pain on updating its visual field?  Why is that kind of pain necessary? 
<br>
How does it make Webmind more intelligent?
<br>
<p><em>&gt; How does the system
</em><br>
<em>&gt; feel about us changing the way it evaluates its own health... or
</em><br>
<em>&gt; the degree to which it &quot;feels it&quot; when humans are unhappy with it...
</em><br>
<p>It looks to me like it would take an extremely sophisticated design for
<br>
Webmind to feel anything at all.  I mean, you and I might not like it if
<br>
someone started tweaking our own feedback systems to increase the amount
<br>
of pain - because we map ourselves onto our future selves and sympathize
<br>
with our future selves.  That is not a trivial ability.
<br>
<p>Webmind would need to realize that it had more pain than it would have had
<br>
otherwise, trace back the causality for that to the action of the human,
<br>
categorize the presence of &quot;more pain than in a subjunctive alternate
<br>
reality&quot; as &quot;undesirable&quot; (regardless of the purpose that pain is supposed
<br>
to accomplish), and combine the fact of &quot;human responsibility&quot; with the
<br>
&quot;undesirable outcome&quot; to resent the humans.
<br>
<p>I don't think Webmind should use an anthropomorphic pain architecture, and
<br>
I think Webmind programmers should avoid thinking of the negative feedback
<br>
mechanisms as being analogous to pain.  Negative feedback should be
<br>
thought of in terms of the design goals of negative feedback.  When
<br>
behavior leads to undesirable outcomes, there are feedback mechanisms that
<br>
make those behaviors less likely on the next iteration.  In the beginning,
<br>
these mechanisms may be instinctive.  Webmind 3.0, or whenever Webmind
<br>
starts getting into sophisticated self-imagery, can analyze its own mind,
<br>
trace back undesirable behaviors to their causal origin, and perform
<br>
design adjustments that would have prevented that undesirable outcome and
<br>
as many related undesirable outcomes as possible.  (That design alteration
<br>
is desirable because it increases the probability of desirable outcomes in
<br>
the future, *not* necessarily because of identification with the past
<br>
self.)
<br>
<p>In this latter case, Webmind should have no objection to your tweaking
<br>
with the &quot;negative feedback&quot; (not &quot;pain&quot;) mechanisms, if by doing so, you
<br>
increase the probability of desirable outcomes in the future.
<br>
<p>A properly structured mind should attempt to avoid the undesirable
<br>
(unFriendly) outcomes themselves, not intermediate and internal causes
<br>
such as any negative feedback resulting from the undesirable outcomes. 
<br>
Otherwise the mind spirals into wireheaded solipsism, trying to alter its
<br>
model of the world, instead of trying to alter the world itself.
<br>
<p>This is why I'm so heavy on the necessity of pain being a design subgoal
<br>
of Friendliness, rather than Friendliness being a way of achieving
<br>
pleasure or avoiding pain.  By adopting that design stance, you are making
<br>
huge problems for yourselves which are entirely unnecessary.
<br>
<p><em>&gt; Because we're so close to this phase (just a couple more months
</em><br>
<em>&gt; of testing &amp; debugging simpler components), this conversation
</em><br>
<em>&gt; is particularly interesting to me
</em><br>
<p>I'm very much interested as well, especially insofar as the choices you
<br>
make now may constrain the options you have available later.
<br>
<p><em>&gt; Don't get me wrong, the Baby Webmind whose feelings I'm talking about here
</em><br>
<em>&gt; is a pretty naive
</em><br>
<em>&gt; little baby at the moment... it's a long way from transcending human
</em><br>
<em>&gt; intelligence (except in very
</em><br>
<em>&gt; narrow areas like market prediction) ... but the issue you're mentioning
</em><br>
<em>&gt; arise nonetheless
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; A year ago, I believed there was nothing you or I or anyone could
</em><br>
<em>&gt; &gt; or should know about Friendly AI in advance.  I now recognize that
</em><br>
<em>&gt; &gt; this belief was quite convenient.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; There certainly is something to be known in advance... but the percentage
</em><br>
<em>&gt; of relevant knowledge that can be known in advance is NOT one of the things
</em><br>
<em>&gt; that can be known in advance ;&gt;
</em><br>
<p>Ah, yes, but once you know something in advance, you can take a pretty
<br>
good guess as to whether that particular thing is something you need to
<br>
know in advance.
<br>
<p>Obviously, one of the fundamental goals in Friendly AI should be to use
<br>
methods that minimize the number of things you need to know in advance. 
<br>
It also follows that those methods are one of the things you most need to
<br>
know in advance.  (See?  Now we know that in advance!)
<br>
<p>Try saying all that with a straight face... but it's all true.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0250.html">J. R. Molloy: "Re: Evolving minds"</a>
<li><strong>Previous message:</strong> <a href="0248.html">Dale Johnstone: "RE: META: Evolving minds"</a>
<li><strong>In reply to:</strong> <a href="0243.html">Ben Goertzel: "RE: Evolving minds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0251.html">Ben Goertzel: "RE: Pain vs. negative feedback (was: Evolving minds)"</a>
<li><strong>Reply:</strong> <a href="0251.html">Ben Goertzel: "RE: Pain vs. negative feedback (was: Evolving minds)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#249">[ date ]</a>
<a href="index.html#249">[ thread ]</a>
<a href="subject.html#249">[ subject ]</a>
<a href="author.html#249">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
