<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Evolving minds</title>
<meta name="Author" content="Ben Goertzel (ben@webmind.com)">
<meta name="Subject" content="RE: Evolving minds">
<meta name="Date" content="2000-11-18">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Evolving minds</h1>
<!-- received="Sat Nov 18 17:35:24 2000" -->
<!-- isoreceived="20001119003524" -->
<!-- sent="Sat, 18 Nov 2000 16:46:37 -0500" -->
<!-- isosent="20001118214637" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@webmind.com" -->
<!-- subject="RE: Evolving minds" -->
<!-- id="JBEPKOGDDIKKAHFPOEFICEFMCCAA.ben@webmind.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3A16D9DB.392ADD8B@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@webmind.com?Subject=RE:%20Evolving%20minds"><em>ben@webmind.com</em></a>)<br>
<strong>Date:</strong> Sat Nov 18 2000 - 14:46:37 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0244.html">Alexandre Owen Muniz: "Individualism in Transhuman Society."</a>
<li><strong>Previous message:</strong> <a href="0242.html">Ben Goertzel: "META: RE: META: Evolving minds"</a>
<li><strong>In reply to:</strong> <a href="0240.html">Eliezer S. Yudkowsky: "Re: Evolving minds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0247.html">Eliezer S. Yudkowsky: "Should we vesper speems? (was: Evolving minds)"</a>
<li><strong>Reply:</strong> <a href="0247.html">Eliezer S. Yudkowsky: "Should we vesper speems? (was: Evolving minds)"</a>
<li><strong>Reply:</strong> <a href="0249.html">Eliezer S. Yudkowsky: "Pain vs. negative feedback (was: Evolving minds)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#243">[ date ]</a>
<a href="index.html#243">[ thread ]</a>
<a href="subject.html#243">[ subject ]</a>
<a href="author.html#243">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; I am not sure I agree with your exact phrasing.  I would rephrase
</em><br>
<em>&gt; as follows:
</em><br>
<em>&gt;
</em><br>
<em>&gt; 1)  Once an AI system is smart enough to restructure all the matter of the
</em><br>
<em>&gt; Solar System into vis own mind-stuff, we will not be able to guide vis
</em><br>
<em>&gt; development *if ve doesn't want us to*.
</em><br>
<p>Even if it wants us to, we may not have the intelligence to understand how
<br>
its mind works
<br>
well enough to guide it...
<br>
<p>How much can a dog guide YOUR development?
<br>
<p><p><em>&gt; In practice, what is necessary is that the early Friendly AI make
</em><br>
<em>&gt; reference to
</em><br>
<em>&gt; the intentions of the programmer.  Not the specific intentions that have
</em><br>
<em>&gt; already been embodied, but &quot;the intentions of the programmer&quot;, in general,
</em><br>
<em>&gt; including the intentions that the early AI doesn't know about yet.
</em><br>
<em>&gt;
</em><br>
<em>&gt; When the programmer says:  &quot;I have this new element to include in
</em><br>
<em>&gt; the design
</em><br>
<em>&gt; of your goal system&quot;, the AI needs to think:  &quot;Aha!  Here's an element of
</em><br>
<em>&gt; what-should-be-my-design that I didn't know about before!&quot;, not
</em><br>
<em>&gt; &quot;He wants to
</em><br>
<em>&gt; give me a new goal system, which leads to suboptimal results from the
</em><br>
<em>&gt; perspective of my current goal system... I'd better resist.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; In &quot;Friendly AI&quot;, I'm working on describing the specific cognitive imagery
</em><br>
<em>&gt; necessary for all that to take place.
</em><br>
<p>Isn't this just a fancy way of saying that a Friendly AI should
<br>
love its mommy and its daddy?  ;&gt;
<br>
<p><em>&gt; Well, without more detailed knowledge of Webmind, I can't be
</em><br>
<em>&gt; sure; however, I
</em><br>
<em>&gt; don't *think* you're encountering challenges of the same
</em><br>
<em>&gt; underlying class as
</em><br>
<em>&gt; the challenges that would be involved in Friendly AI.  But I
</em><br>
<em>&gt; don't know.  I'm
</em><br>
<em>&gt; not a Webminder.
</em><br>
<p>Right now, we're just dealing with parameter tuning for improved
<br>
intelligence.
<br>
<p>In Feb. we'll start a new phase, when we'll make operational the &quot;psyche&quot;
<br>
component
<br>
of the system (goals, feelings, motivations) ... we then will be quite
<br>
precisely
<br>
dealing with issues of friendliness and unfriendliness.  Questions like:
<br>
What attitude
<br>
does the system have when we insert new knowledge into its mind, which
<br>
causes it annoyance
<br>
and pain because it forces it to revise its hard-won beliefs....  How does
<br>
the system feel
<br>
about us changing the way it evaluates its own health... or the degree to
<br>
which it &quot;feels it&quot;
<br>
when humans are unhappy with it...
<br>
<p>Because we're so close to this phase (just a couple more months of testing &amp;
<br>
debugging simpler
<br>
components), this conversation is particularly interesting to me
<br>
<p>Don't get me wrong, the Baby Webmind whose feelings I'm talking about here
<br>
is a pretty naive
<br>
little baby at the moment... it's a long way from transcending human
<br>
intelligence (except in very
<br>
narrow areas like market prediction) ... but the issue you're mentioning
<br>
arise nonetheless
<br>
<p><em>&gt; A year ago, I believed there was nothing you or I or anyone could
</em><br>
<em>&gt; or should
</em><br>
<em>&gt; know about Friendly AI in advance.  I now recognize that this
</em><br>
<em>&gt; belief was quite
</em><br>
<em>&gt; convenient.
</em><br>
<p>There certainly is something to be known in advance... but the percentage
<br>
of relevant knowledge that can be known in advance is NOT one of the things
<br>
that can be known in advance ;&gt;
<br>
<p><em>&gt; There is still a discipline of seed AI in Artificial Intelligence, and a
</em><br>
<em>&gt; discipline of &quot;seed morality&quot; in Friendly AI.
</em><br>
<em>&gt;
</em><br>
<p>Yes indeed...
<br>
<p>ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0244.html">Alexandre Owen Muniz: "Individualism in Transhuman Society."</a>
<li><strong>Previous message:</strong> <a href="0242.html">Ben Goertzel: "META: RE: META: Evolving minds"</a>
<li><strong>In reply to:</strong> <a href="0240.html">Eliezer S. Yudkowsky: "Re: Evolving minds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0247.html">Eliezer S. Yudkowsky: "Should we vesper speems? (was: Evolving minds)"</a>
<li><strong>Reply:</strong> <a href="0247.html">Eliezer S. Yudkowsky: "Should we vesper speems? (was: Evolving minds)"</a>
<li><strong>Reply:</strong> <a href="0249.html">Eliezer S. Yudkowsky: "Pain vs. negative feedback (was: Evolving minds)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#243">[ date ]</a>
<a href="index.html#243">[ thread ]</a>
<a href="subject.html#243">[ subject ]</a>
<a href="author.html#243">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
