<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: META: Molloy (was: Friendly AI)</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="META: Molloy (was: Friendly AI)">
<meta name="Date" content="2000-11-25">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>META: Molloy (was: Friendly AI)</h1>
<!-- received="Sat Nov 25 03:54:27 2000" -->
<!-- isoreceived="20001125105427" -->
<!-- sent="Sat, 25 Nov 2000 03:53:59 -0500" -->
<!-- isosent="20001125085359" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="META: Molloy (was: Friendly AI)" -->
<!-- id="3A1F7E27.1E8D4EB@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="02d101c056a6$fe51afa0$49bc473f@jrmolloy" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20META:%20Molloy%20(was:%20Friendly%20AI)"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Sat Nov 25 2000 - 01:53:59 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0286.html">Ben Goertzel: "RE: Friendly AI"</a>
<li><strong>Previous message:</strong> <a href="0284.html">Brian Atkins: "dawn of neurohacks"</a>
<li><strong>In reply to:</strong> <a href="0282.html">J. R. Molloy: "Re: Friendly AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0288.html">Ben Goertzel: "RE: META: Molloy (was: Friendly AI)"</a>
<li><strong>Reply:</strong> <a href="0288.html">Ben Goertzel: "RE: META: Molloy (was: Friendly AI)"</a>
<li><strong>Maybe reply:</strong> <a href="0290.html">Spudboy100@aol.com: "Re: META: Molloy (was: Friendly AI)"</a>
<li><strong>Reply:</strong> <a href="0293.html">Dale Johnstone: "META: List filtering."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#285">[ date ]</a>
<a href="index.html#285">[ thread ]</a>
<a href="subject.html#285">[ subject ]</a>
<a href="author.html#285">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&quot;J. R. Molloy&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; BTW, thanks to Eliezer for setting up this list. I hope he doesn't get
</em><br>
<em>&gt; bummed out by the likes of me spouting my opinions here.
</em><br>
<p>Well, to be honest - and I did ask for honesty on this list - I am a bit
<br>
bummed out by the fact that you started posting, since I think that you
<br>
make the most intellectually sterile posts of anyone I've ever known. 
<br>
I've been internally debating with myself what to do about that for the
<br>
last couple of days.  It's made harder by the fact that your posts, taken
<br>
individually, always manage to sound like the sort of thing that *should*
<br>
be interesting.  You know, the kind of posts where people who pride
<br>
themselves on their open-mindedness say to themselves:  &quot;This is something
<br>
that should be interesting&quot; or &quot;Other people might be interested in this&quot;
<br>
or &quot;This is something that deserves to be debated&quot;, but nobody's actually
<br>
*personally* interested and the top posters are bored sick by the thought
<br>
of writing a response.  That sort of thing is poison to list quality and
<br>
it's exactly the sort of thing I want to avoid for SL4.
<br>
<p>I'm not sure SL4's readers would understand if I pre-emptively banned you,
<br>
and writing to you offline and asking you to stop posting would interfere
<br>
with the openness of the moderation process.  Since you raise the subject,
<br>
though, I think that simply stating my personal opinion on the topic may
<br>
turn out to everything needed, in terms of maintaining list quality.  If,
<br>
however, your posts continue to generate responses and the responses
<br>
themselves do not cover wholly new-to-the-planet-Earth intellectual
<br>
territory, then I may ask you to stop posting.
<br>
<p>For the record, my current solution is as follows:
<br>
<p>&quot;Nobody should feel obligated to respond to J.R. Molloy's posts.&quot;
<br>
<p>==
<br>
<p>Incidentally, Spudboy, you are guilty of the same offense as Molloy -
<br>
although to a lesser degree.  Our futuristic reasoning is causal, not
<br>
teleological.  It's hard to explain, in words, the difference between the
<br>
clarity of extrapolation and just making up things that sound nice as you
<br>
go along, but I get the strong impression that you are doing the latter. 
<br>
And you CONSISTENTLY quote the entire bodies of messages in your response,
<br>
which is technically a violation of list etiquette that only the most
<br>
valued posters are allowed to get away with.
<br>
<p>==
<br>
<p>Molloy and Spudboy are totally free to flame me for saying this, of
<br>
course.  Anyone who disagrees with my methods of moderation is free to say
<br>
so, especially Samantha Atkins (who does maintain high post quality, but
<br>
who disagrees with me about the ethics of moderation).  It seems obvious
<br>
to me that META posts, especially those critical of me, should be
<br>
moderated much less rigorously than discussion of futurism proper - unless
<br>
the META posts start to take over the list.  I will continue to do my best
<br>
to ensure quality of posts on futurism proper.
<br>
<p>==
<br>
<p>&quot;J. R. Molloy&quot; wrote:
<br>
<em>&gt; 
</em><br>
<p><em>&gt; Multi-AI seems to me the most promising approach to creating AI and Alife.
</em><br>
<em>&gt; Some will argue that it's too dangerous because a multi-AI experiment can
</em><br>
<em>&gt; more readily get out of control than a single AI, but I'd counter that a
</em><br>
<em>&gt; hundred AIs can respond to evolutionary tactics better than a single AI
</em><br>
<em>&gt; can, and that evolution (more than top-down coding) will most likely
</em><br>
<em>&gt; result in genuine AI systems bred to interact with humans.
</em><br>
<p>&quot;J. R. Molloy&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Evolution does not stop being evolution when guided by un-natural
</em><br>
<em>&gt; selection.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Check out:
</em><br>
<em>&gt; <a href="http://www.canoe.ca/CNEWSScience0008/30_robot.html">http://www.canoe.ca/CNEWSScience0008/30_robot.html</a>
</em><br>
<em>&gt; A computer programmed to follow the rules of evolution has for the first
</em><br>
<em>&gt; time designed and manufactured simple robots with minimal help from
</em><br>
<em>&gt; people.
</em><br>
<p>&quot;J. R. Molloy&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; The perfectly infinite multiverse presents unlimited existential awareness
</em><br>
<em>&gt; to any intelligence (human or SI) that can grok it. &quot;Does SI have Buddha
</em><br>
<em>&gt; nature?&quot; asked the sanyasi.
</em><br>
<em>&gt; &quot;Mu&quot; replied the master.
</em><br>
<p>&quot;J. R. Molloy&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Is technological singularity a &quot;powerful notion&quot; or is it an event that
</em><br>
<em>&gt; requires the attention of all sane human beings (ethical, intelligent,
</em><br>
<em>&gt; individual, worldly, and mindful folks everywhere).
</em><br>
<p>&quot;J. R. Molloy&quot; wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; It seems to me we should first of all consider how AIs behave toward us.
</em><br>
<em>&gt; Let them feel whatever they want -- it doesn't matter as much as how they
</em><br>
<em>&gt; actually function and conduct themselves. They might try to kill us
</em><br>
<em>&gt; because they love us, or they might try to help us solve our problems
</em><br>
<em>&gt; because they pity us. Who cares.
</em><br>
<em>&gt; Asimov's unwritten Alife law: AIs that misbehave get terminated
</em><br>
<em>&gt; immediately. The ones that invent new ways to solve human problems get to
</em><br>
<em>&gt; breed (multiply, reproduce, evolve new versions of themselves, etc.).
</em><br>
<p>==
<br>
<p><a href="mailto:Spudboy100@aol.com?Subject=Re:%20META:%20Molloy%20(was:%20Friendly%20AI)">Spudboy100@aol.com</a> wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; This is a question more for the future. But if somebody gets uploaded, and
</em><br>
<em>&gt; stays inside their fantasy world, will not insanity result? Is this why there
</em><br>
<em>&gt; have been no repeated &quot;signals&quot; seti-wise. That civilizations join the Land
</em><br>
<em>&gt; of the Lotus Eaters and forget their primate orgins. If one spends their time
</em><br>
<em>&gt; as a artilectual rhomboid inside cybernetic, dimension -7, and forgets what
</em><br>
<em>&gt; its like to go to a bookstore and have coffee with a friend; won't this just
</em><br>
<em>&gt; serve to set us up for a bad end?
</em><br>
<p><a href="mailto:Spudboy100@aol.com?Subject=Re:%20META:%20Molloy%20(was:%20Friendly%20AI)">Spudboy100@aol.com</a> wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; I am not sure that Ben's shocklevel is Not more profound at SL2, then it is
</em><br>
<em>&gt; at SL3. If a culture has already experienced SL-2, then SL-3 is merely an
</em><br>
<em>&gt; extension. If the Galaxy is discovered to be, mostly non-biotic and
</em><br>
<em>&gt; non-intelligent; then what inpact is star-travel? Intelligent aliens created
</em><br>
<em>&gt; out of petri dishes seem much more dramatic to me, because they become the
</em><br>
<em>&gt; human species' Mind Children; to quote Moravec and Minsky. Opinions?
</em><br>
<p><a href="mailto:Spudboy100@aol.com?Subject=Re:%20META:%20Molloy%20(was:%20Friendly%20AI)">Spudboy100@aol.com</a> wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Can there be an Ultimate SuperMind? How would we define such a mind, woulld
</em><br>
<em>&gt; it encompass the universe, or could it transcend the visible cosmos and  pass
</em><br>
<em>&gt; to other cosm's? I am not trying to get to religion in a dishonest way, on
</em><br>
<em>&gt; this list; but I like the dealing with the endpoint of things, and seeing
</em><br>
<em>&gt; what real creativity and power might achieve.
</em><br>
<p><a href="mailto:Spudboy100@aol.com?Subject=Re:%20META:%20Molloy%20(was:%20Friendly%20AI)">Spudboy100@aol.com</a> wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Have you considered scenario's when the first of these ultratechnologies will
</em><br>
<em>&gt; occur or come to full flower? What do you think has to come together,
</em><br>
<em>&gt; scientifically, culturally, and economically to have this takeoff? Any
</em><br>
<em>&gt; putative, timelines, people need to be aware of?
</em><br>
<p>(Answer:  NO.  Everything on the ultratech list, except possibly
<br>
nanotechnology, is post-Singularity tech unless something totally
<br>
unexpected happens (see &quot;Moving Mars&quot; by Greg Bear), probably with
<br>
disastrous results.)
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0286.html">Ben Goertzel: "RE: Friendly AI"</a>
<li><strong>Previous message:</strong> <a href="0284.html">Brian Atkins: "dawn of neurohacks"</a>
<li><strong>In reply to:</strong> <a href="0282.html">J. R. Molloy: "Re: Friendly AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0288.html">Ben Goertzel: "RE: META: Molloy (was: Friendly AI)"</a>
<li><strong>Reply:</strong> <a href="0288.html">Ben Goertzel: "RE: META: Molloy (was: Friendly AI)"</a>
<li><strong>Maybe reply:</strong> <a href="0290.html">Spudboy100@aol.com: "Re: META: Molloy (was: Friendly AI)"</a>
<li><strong>Reply:</strong> <a href="0293.html">Dale Johnstone: "META: List filtering."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#285">[ date ]</a>
<a href="index.html#285">[ thread ]</a>
<a href="subject.html#285">[ subject ]</a>
<a href="author.html#285">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
