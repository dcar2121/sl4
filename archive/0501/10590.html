<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Bad Bayesian - no biscuit!</title>
<meta name="Author" content="Eliezer Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Bad Bayesian - no biscuit!">
<meta name="Date" content="2005-01-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Bad Bayesian - no biscuit!</h1>
<!-- received="Sat Jan 22 09:40:55 2005" -->
<!-- isoreceived="20050122164055" -->
<!-- sent="Sat, 22 Jan 2005 11:40:21 -0500" -->
<!-- isosent="20050122164021" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Bad Bayesian - no biscuit!" -->
<!-- id="41F281F5.6090807@pobox.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="001e01c50060$acd24910$b8232dcb@homepc" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Bad%20Bayesian%20-%20no%20biscuit!"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Sat Jan 22 2005 - 09:40:21 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10591.html">Ben Goertzel: "RE: [agi] What are qualia..."</a>
<li><strong>Previous message:</strong> <a href="10589.html">Patrick Crenshaw: "Re: maybe we are in pi"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10594.html">maru: "Re: Bad Bayesian - no biscuit!"</a>
<li><strong>Reply:</strong> <a href="10594.html">maru: "Re: Bad Bayesian - no biscuit!"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10590">[ date ]</a>
<a href="index.html#10590">[ thread ]</a>
<a href="subject.html#10590">[ subject ]</a>
<a href="author.html#10590">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Brett Paatsch wrote:
<br>
<em>&gt; Or as Feynman ([para 39] in accompanying post) said:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &quot;This method [science] is based on the principle that observation is the
</em><br>
<em>&gt;  judge of whether something is so or not.  All other aspects and 
</em><br>
<em>&gt; characteristics of science can be understood directly when we understand
</em><br>
<em>&gt;  that observation is the ultimate and final judge of the truth of an
</em><br>
<em>&gt; idea. But &quot;prove&quot; used in this way really means &quot;test&quot;, in the same way
</em><br>
<em>&gt; that hundred-proof alcohol is a test of the alcohol, and for people
</em><br>
<em>&gt; today the idea really should be translated as, &quot;The exception tests the
</em><br>
<em>&gt; rule.&quot; Or, put another way, &quot;The exception proves that the rule is
</em><br>
<em>&gt; wrong&quot;. That is the principle of science. If there is an exception to
</em><br>
<em>&gt; any rule, and if it can be proved by observation, that rule is wrong.&quot;
</em><br>
<p>And as Feynman said in the _Lectures on Physics_:
<br>
<p>&quot;Philosophers, incidentally, say a great deal about what is absolutely 
<br>
necessary for science, and it is always, so far as one can see, rather 
<br>
naive, and probably wrong.  For example, some philosopher or other said it 
<br>
is fundamental to the scientific effort that if an experiment is performed 
<br>
in, say, Stockholm, and then the same experiment is done in, say, Quito, 
<br>
the same results must occur.  That is quite false.  It is not necessary 
<br>
that science do that; it may be a fact of experience, but it is not 
<br>
necessary.  For example, if one of the experiments is to look out at the 
<br>
sky and see the aurora borealis in Stockholm, you do not see it in Quito; 
<br>
that is a different phenomenon.  &quot;But,&quot; you say, &quot;that is something that 
<br>
has to do with the outside; can you close yourself up in a box in Stockholm 
<br>
and pull down the shade and get any difference?&quot;  Surely.  If we take a 
<br>
pendulum on a universal joint, and pull it out and let go, then the 
<br>
pendulum will swing almonst in a plane, but not quite.  Slowly the plane 
<br>
keeps changing in Stockholm, but not in Quito.  The blinds are down, too. 
<br>
The fact that this has happened does not bring on the destruction of 
<br>
science.  What is the fundamental hypothesis of science, the fundamental 
<br>
philosophy?  We stated it in the first chapter: the sole test of the 
<br>
validity of any idea is experiment.  If it turns out that most experiments 
<br>
work out the same in Quito as the do in Stockholm, then those &quot;most 
<br>
experiments&quot; will be used to formulate some general law, and the those 
<br>
experiments which do not come out the same we will say were a result of the 
<br>
environment near Stockholm.  We wil invent some way to summarize the 
<br>
results of the experiment, and we do not have to be told ahead of time what 
<br>
this way will look like.  If we are told that the same experiment will 
<br>
always produce the same result, that is all very well, but if when we try 
<br>
it, it does not, then it does not.  We just have to take what we see, and 
<br>
then formulate all the rest of our ideas in terms of our actual experience.&quot;
<br>
<p>I reply:  Nonetheless we *observe* that the same experiment *does* return 
<br>
the same answer in Quito as in Stockholm, once we understand how to perform 
<br>
the &quot;same&quot; experiment.  The more fundamental the level on which we compute 
<br>
our model, the more the underlying laws are exactly the same in every 
<br>
observation.  This is not a thing that philosophers dreamed up a priori; it 
<br>
is a thing humanity has discovered through experience - but nonetheless it 
<br>
is so.
<br>
<p>It may be that someday we will understand that reality is *necessarily* 
<br>
regular, that this is the way things *must* be, and that it could not have 
<br>
been any other way.  Historically, humanity will still have discovered this 
<br>
point from observation, but our future selves may be so strongly attuned to 
<br>
reality that, like the universe itself, they cannot conceive of things 
<br>
being other than the way they are.  Or not.  I don't know if that's what I 
<br>
would want, even given the premise.  But if some future intelligence *does* 
<br>
somehow manage to become absolutely certain of something, and ve indeed 
<br>
wins on every single prediction, vis Bayesian score would be higher than 
<br>
mine - even if contemplating vis absolute certainty would give a modern-day 
<br>
rationalist the squiggles.  I don't find it implausible that in reality 
<br>
itself there are things that absolutely cannot be other than the way they 
<br>
are, even if a rationalist cannot avoid uncertainty about them.
<br>
<p>Feynman's advice, in the classical tradition of rationality, is about the 
<br>
way in which human beings discover things, and about the fallibility of 
<br>
human discoveries even after they are made.  But despite all cautions about 
<br>
human fallibility, not one of all the strange and unexpected events that 
<br>
happened in the 20th century violated conservation of momentum.  Reality - 
<br>
we *observe* this, we do not say it a priori - is very constricted in the 
<br>
kind of surprises it has presented us with.  Sometimes we even discover new 
<br>
and unexpected laws of physics, but the new laws still have the same 
<br>
character as old physics; they are universal mathematical laws.
<br>
<p>I think it is now okay to say that there is something important about a 
<br>
*fundamental* law of physics needing to work the same way in Quito as in 
<br>
Stockholm.  There is something important about physics being simple math. 
<br>
We do not necessarily understand *why* it is so, at this point in human 
<br>
history.  But it is not a dictum of philosophy, it is a lesson of experience.
<br>
<p>It is a lesser lesson of experience that people don't wake up with blue 
<br>
tentacles.  This rule of thumb is not just a philosophical dictum, and if 
<br>
you violate it, you may end up in trouble.
<br>
<p>All correct theories about reality are necessarily consistent with each 
<br>
other; imperfect maps may conflict, but there is only one territory.  If 
<br>
you make up a story that &quot;explains&quot; waking up with a blue tentacle, *when 
<br>
it never actually happened*, there is a discordant note - that story is not 
<br>
necessarily consistent with everything else you know, let alone consistent 
<br>
with the territory.  Consider how different is the skill of explaining 
<br>
truth from the skill of explaining falsity!  The former skill requires that 
<br>
the explanation be consistent with every other true theory in our 
<br>
possession about the universe, so that we may rule out some explanations, 
<br>
or question some previous theories.  The latter skill... well, I'm not sure 
<br>
what to say; the rules would seem to be arbitrary.  We want to train 
<br>
ourselves to excel at explaining true things, not explaining false things, 
<br>
for only the former is the strength of a rationalist.
<br>
<p>Just because you don't know what the future brings, doesn't mean that 
<br>
reality itself will throw just anything at you.  Just because *you* don't 
<br>
know *absolutely* that something *won't* happen, doesn't mean that if you 
<br>
devise a random fiction, it would be theoretically possible for one with 
<br>
total knowledge of Nature to explain it.  A random fiction is most likely 
<br>
an event that could never be woven into the thread of this our real world. 
<br>
&nbsp;&nbsp;If observations alone are cause for explanations, you are less likely to 
<br>
try and explain the unexplainable.
<br>
<p><em>&gt; Ah but don't you see. No one in all of human history has ever woken up
</em><br>
<em>&gt; with a functioning tentacle in place of their arm - to the best of *my*
</em><br>
<em>&gt; current knowledge only. I didn't forget that that was to the best of
</em><br>
<em>&gt; *my* current knowledge only when I entered into the spirit of your 
</em><br>
<em>&gt; hypothetical. I didn't forget that my current knowledge is knowledge 
</em><br>
<em>&gt; acquired in a particular way and that ultimately it is provisional 
</em><br>
<em>&gt; knowledge only. I didn't have to have considered or devoted mindspace to
</em><br>
<em>&gt; the hypothetical you put before you put it. I thought of it only when
</em><br>
<em>&gt; you invited me to imagine it.
</em><br>
<p>My inviting you to imagine a blue tentacle might or might not be a good 
<br>
reason to *imagine* a blue tentacle, but it surely was not a good enough 
<br>
reason to come up with an *explanation* for a blue tentacle.  Only a real 
<br>
observation would be cause for that, and reality is rather unlikely to 
<br>
present you with that observation.
<br>
<p>The measure of your strength as a rationalist is your ability to be more 
<br>
confused by fiction than by reality.  If you are equally good at explaining 
<br>
any outcome, you have zero knowledge.  I presented you with a fiction, an 
<br>
event that was never part of this our real world.  You should not have been 
<br>
able to explain it.  It is a virtue to be able to explain history books, 
<br>
but only if you are *not* able to explain online webcomics.
<br>
<p>A true anecdote:
<br>
<p>Once upon a time, I was on an IRC channel when R comes in, saying that his 
<br>
friend H is having trouble breathing; R needs advice.  R says that the 
<br>
ambulance people came in, checked H out, and left, even though H was still 
<br>
having trouble breathing.  And I look at this and in a fleeting moment of 
<br>
confusion I think:  &quot;What the hell?  That doesn't accord with anything I 
<br>
know about medical procedure.  I've read newspaper stories about homeless 
<br>
people who claim to be sick to get a brief bit of shelter, and the 
<br>
ambulance crews know they're faking but have to take them in anyway.&quot;  But 
<br>
I suppress that fleeting moment of confusion, and say... I forget what I 
<br>
said, but I think it was something like, &quot;Well, they're the experienced 
<br>
medics - if they say H doesn't need to visit the emergency room, H must 
<br>
really not need to visit the emergency room.  Trust the doctors.&quot;
<br>
<p>A bit later R returns to the IRC room, angry.  It turns out that H was 
<br>
making up the whole thing, trying for sympathy, to scam a bit of money, 
<br>
whatever, and there never was an ambulance.
<br>
<p>And I said to myself:  &quot;Why the hell did I accept this confusing story? 
<br>
I'm no better than those apocryphal high school students speculating about 
<br>
thermodynamics.  Next time, I vow to notice when I am confused, and not let 
<br>
the critical hint of my bewilderment flit by so quickly.&quot;
<br>
<p>It's really annoying that my mind actually got all the way to the point of 
<br>
being confused, and I just squashed it and accepted the story.  Think of 
<br>
the glory that would have accrued to me as a rationalist, if I alone on the 
<br>
IRC channel had said:  &quot;This story is so confusing that I may want to deny 
<br>
the data.  How sure are you that your friend's story is true?  Were you there?&quot;
<br>
<p>Therefore did I devise this saying, to chide myself for having failed to 
<br>
distinguish truth from falsehood:  &quot;Your strength as a rationalist is your 
<br>
ability to be more confused by fiction than by reality.&quot;
<br>
<p><em>&gt; In the recent discussion John C Wright finds
</em><br>
<em>&gt; god, Damien didn't forget all the novels he had read, the movies he had
</em><br>
<em>&gt; seen etc in couching his arguments to John C Wright, quite to the
</em><br>
<em>&gt; contrary, he integrated his understanding of such cultural biases, and
</em><br>
<em>&gt; pointed out that John C Wright had had the sort of experience that 'fit'
</em><br>
<em>&gt; with his culture rather than one that would have 'fit' with a different
</em><br>
<em>&gt; culture.
</em><br>
<p>The logical form of Damien's argument was that since Wright's purported 
<br>
story, which might be real and might not be, was drastically inconsistent 
<br>
with experiment, and drastically consistent with known fictions, it was 
<br>
probably also a fiction.
<br>
<p>This doesn't mean we are reasoning from fictions as if they were real 
<br>
events.  It means we are being aware of the probable causes of human 
<br>
delusion.  But it is necessary to first investigate the question of 
<br>
consistency with science; even true statements will often have some *vague* 
<br>
resemblance to fiction, because there are so many fictions out there.
<br>
<p><em>&gt; My explanation was only provisional so if it happens I'll be open to 
</em><br>
<em>&gt; alternative explanations. And if it happens I won't have to throw away
</em><br>
<em>&gt; all my experiences or forget stuff to explain it. I will only have to
</em><br>
<em>&gt; change my model and I'll only have to change it in certain ways.
</em><br>
<p>If anyone ever wakes up with a blue tentacle, then you were virtuous to 
<br>
claim in advance that the event was explicable.  If the real chain of 
<br>
events leading up to the blue tentacle matches your given reason, then you 
<br>
were virtuous to claim that reason as your specific explanation.
<br>
<p>If no one ever wakes up with a blue tentacle, then clearly a blue tentacle 
<br>
wasn't the sort of thing which would ever be woven into reality by a 
<br>
sequence of events that would constitute an &quot;explanation&quot; of it, and it was 
<br>
a mistake to claim that a blue tentacle was an explicable event.
<br>
<p>What would be your explanation if one day, everyone in the world began 
<br>
observing that two of something plus two of something made five of something?
<br>
<p><em>&gt;&gt; When you have only a poor explanation, one that doesn't make things 
</em><br>
<em>&gt;&gt; ordinary in retrospect, just admit you don't have an explanation, and
</em><br>
<em>&gt;&gt; keep going.  Poor explanations very, very rarely turn out to be
</em><br>
<em>&gt;&gt; actually correct.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't think that this is right, or that it is a logical conclusion to
</em><br>
<em>&gt; draw from the better parts of your argument in your essay. We have maps
</em><br>
<em>&gt; of the terrain of reality because we need them. Maps have utility. If 
</em><br>
<em>&gt; you give me a poor map and I know nothing of you and find that the map
</em><br>
<em>&gt; is wrong then, in that case yes, perhaps I might be better off without
</em><br>
<em>&gt; that map altogether, but if the map I have is one that I have 
</em><br>
<em>&gt; constructed myself, then when I find it differs from the terrain I can 
</em><br>
<em>&gt; just correct or improve the map.
</em><br>
<p>That is an argument for:  &quot;I will sit down and write a story, knowing it to 
<br>
be fiction, about how a secret organization came into my apartment and 
<br>
replaced my arm with a blue tentacle.  I do not *believe* this has 
<br>
happened.  No, seriously, I don't believe it and I'm not going to act as if 
<br>
I believed it, because it's a stupid explanation.  But maybe the mental 
<br>
exercise will shake something loose in my mind, and I'll think of a better 
<br>
explanation.&quot;
<br>
<p>To say that it can have utility to mentally extrapolate the consequences of 
<br>
a premise is not the same as believing that premise.  One must be careful 
<br>
here; if you act like you believe something, or if you end up emotionally 
<br>
attached to the belief, I don't credit you as a rationalist just because 
<br>
you claim you didn't believe you would win the lottery, you bought the 
<br>
tickets &quot;for the drama&quot; of it, etc.  People with a fragmentary 
<br>
understanding of the Way sometimes anticipate that they can pass as 
<br>
rationalists by claiming not to believe the things they anticipate.
<br>
<p><em>&gt;&gt; A gang of people sneaking into your room with unknown technology is a
</em><br>
<em>&gt;&gt; poor explanation.  Whatever the real explanation was, it  wouldn't be
</em><br>
<em>&gt;&gt; that.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I think you can only establish that it's poor (for others than you) in 
</em><br>
<em>&gt; relation to the provision of a better one.  &quot;I don't know&quot;, whilst a
</em><br>
<em>&gt; fair and honest answer, is not any sort of explanation. My answer shows 
</em><br>
<em>&gt; you I don't know but doesn't leave you (or importantly) me merely and
</em><br>
<em>&gt; completely bewildered. It gives me things to check.
</em><br>
<p>That is not an *answer*.  It is not something to which Bayesian reasoning 
<br>
gives a high probability.  That is a science fiction story, a tool for 
<br>
brainstorming an answer.  I have sometimes derived interesting ideas from 
<br>
my attempts to write SF, but I know those stories for fiction, not reality.
<br>
<p>If you see something that looks like a poor explanation but is the only 
<br>
explanation you have, it may take a bit of effort to achieve a state of 
<br>
mind where you *really* don't anticipate it - rather than claiming to 
<br>
yourself that you are dutifully skeptical.
<br>
<p><em>&gt; And it is very hard for us as individuals to take other's
</em><br>
<em>&gt; &quot;rationalities&quot; as givens when we don't get to see the others
</em><br>
<em>&gt; observations as our own observations. Second (or more) hand
</em><br>
<em>&gt; &quot;observations&quot; have to be discounted to some extend on first hand ones.
</em><br>
<p>See Robin Hanson and Tyler Cowen's paper on meta-rationality, &quot;Are 
<br>
Disagreements Honest?&quot;  <a href="http://hanson.gmu.edu/deceive.pdf">http://hanson.gmu.edu/deceive.pdf</a>
<br>
<p><em>&gt; Progress depends on people (as change agents) being willing to stick
</em><br>
<em>&gt; their necks out to try to explain.
</em><br>
<p>That doesn't require that you bet on, anticipate, or believe a hypothesis, 
<br>
before it is confirmed.  It means that you write science fiction about a 
<br>
poor hypothesis, to get your mind working on the problem.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10591.html">Ben Goertzel: "RE: [agi] What are qualia..."</a>
<li><strong>Previous message:</strong> <a href="10589.html">Patrick Crenshaw: "Re: maybe we are in pi"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10594.html">maru: "Re: Bad Bayesian - no biscuit!"</a>
<li><strong>Reply:</strong> <a href="10594.html">maru: "Re: Bad Bayesian - no biscuit!"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10590">[ date ]</a>
<a href="index.html#10590">[ thread ]</a>
<a href="subject.html#10590">[ subject ]</a>
<a href="author.html#10590">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
