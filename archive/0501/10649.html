<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: What are qualia...</title>
<meta name="Author" content="Michael Wilson (mwdestinystar@yahoo.co.uk)">
<meta name="Subject" content="Re: What are qualia...">
<meta name="Date" content="2005-01-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: What are qualia...</h1>
<!-- received="Mon Jan 24 16:25:39 2005" -->
<!-- isoreceived="20050124232539" -->
<!-- sent="Mon, 24 Jan 2005 23:25:15 +0000 (GMT)" -->
<!-- isosent="20050124232515" -->
<!-- name="Michael Wilson" -->
<!-- email="mwdestinystar@yahoo.co.uk" -->
<!-- subject="Re: What are qualia..." -->
<!-- id="20050124232515.46696.qmail@web25308.mail.ukl.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="What are qualia..." -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Wilson (<a href="mailto:mwdestinystar@yahoo.co.uk?Subject=Re:%20What%20are%20qualia..."><em>mwdestinystar@yahoo.co.uk</em></a>)<br>
<strong>Date:</strong> Mon Jan 24 2005 - 16:25:15 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10650.html">maru: "Re: When does it pay to play (lottery)?"</a>
<li><strong>Previous message:</strong> <a href="10648.html">David Clark: "Re: When does it pay to play (lottery)?"</a>
<li><strong>Maybe in reply to:</strong> <a href="10578.html">Philip Sutton: "What are qualia..."</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10649">[ date ]</a>
<a href="index.html#10649">[ thread ]</a>
<a href="subject.html#10649">[ subject ]</a>
<a href="author.html#10649">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
This message seems to have been lost when lucifer.org went down. My
<br>
aplogies if this is a duplicate.
<br>
<p>Date   : Sun, 23 Jan 2005 22:49:01 +0000 (GMT)
<br>
<em>&gt;From   : &quot;Michael Wilson&quot; &lt;<a href="mailto:mwdestinystar@yahoo.co.uk?Subject=Re:%20What%20are%20qualia...">mwdestinystar@yahoo.co.uk</a>&gt;
</em><br>
Subject: Re: What are qualia...
<br>
To     : <a href="mailto:sl4@sl4.org?Subject=Re:%20What%20are%20qualia...">sl4@sl4.org</a>
<br>
<p>Mitchell Porter wrote: 
<br>
<em>&gt; And what is the &quot;mystery&quot; that is being &quot;reified&quot;? Oh, just
</em><br>
<em>&gt; that half of what we experience in sensation (the &quot;secondary
</em><br>
<em>&gt; qualities&quot;) DOES NOT EXIST in the world-according-to-physics!
</em><br>
<p>The mysterious question is 'what are qualia?'. The non-mysterious
<br>
question that we should be asking is 'why do people think they have
<br>
qualia'? The non-mysterious answer to the second question, which we
<br>
don't have yet, would be a description of your cognitive processes
<br>
causally complete enough to explain (in terms of neuron firings) why
<br>
you asked the first question. This would combine a description of how
<br>
the cognitive processes we reflectively categorise as various sorts of
<br>
qualia (the 'neural correlates of qualia') contribute to human cognition
<br>
/and/ an explanation of how the process of examining this reflective
<br>
perception in detail derails into dualistic, subjectivist fantasies.
<br>
Like many materialists I have my own guesses on possible inconsistencies
<br>
in the brain's representational schemes (themselves embedded in neural 
<br>
machinery generated by pressure not to represent reality consistently,
<br>
but to survive the paleolithic  environment) that would account for
<br>
this. However we won't be able to answer this with any certainty until
<br>
we get much better data. 
<br>
<p><em>&gt; What we see as &quot;red&quot;, for instance, is really just a colorless
</em><br>
<em>&gt; arrangement of corpuscles, which, by their particular size,
</em><br>
<em>&gt; shape, and motion, have the power to produce in us the
</em><br>
<em>&gt; sensation of redness.
</em><br>
<p>For example in this particular confusion, people have taken the
<br>
brain's heavy bias towards (and optimisation for) object/property
<br>
representational schemes and stretched it way past breaking point.
<br>
As Eliezer would say, there is no redness out there in reality
<br>
because the sensation of redness is a feature of the (neural) map,
<br>
not the territory. The reason we can't see this is directly is
<br>
because our cognitive architecture doesn't have a clean separation
<br>
between reality map, reflective map and processing mechanisms.
<br>
Have a look at LOGI's stuff on concept kernels to get an idea of
<br>
what the 'qualia' actually do (bearing in mind that the brain is
<br>
much messier than LOGI), and why they seem so much richer than a
<br>
simple 'photons between wavelength X and Y' constraint.
<br>
<p><em>&gt; rejecting Searle's point that &quot;reference&quot;, self- or otherwise,
</em><br>
<em>&gt; does not exist in a purely physical system, any more than a
</em><br>
<em>&gt; pattern of black and white markings inherently means anything.
</em><br>
<p>Physics doesn't have reference, it has correlation. What we call
<br>
reference is a pattern of correlations that we find useful in
<br>
some specific way (i.e. we can reliably cause other people to
<br>
manipulate a bit of their map that tracks roughly the same bit of
<br>
reality as a piece of our map).
<br>
<p><em>&gt; So what is the alternative? One can begin by trying to
</em><br>
<em>&gt; perceive the extent to which one's own perception of
</em><br>
<em>&gt; the world is actually the result of imagination.
</em><br>
<p>Welcome to 'active perception'. Join the queue on the right to
<br>
receive your free innoculation against semantic net infatuation.
<br>
<p><em>&gt; But can you also &quot;see&quot; that &quot;seeing color A&quot; and
</em><br>
<em>&gt; &quot;neurons firing&quot; are also very different things.
</em><br>
<p>They're both maps of the same bit of reality, just with
<br>
differing detail and level of indirection.
<br>
<p><em>&gt; and any theory which ends up denying the very existence
</em><br>
<em>&gt; of that starting point is on the wrong track.
</em><br>
<p>If we could reliably predict the subjective experience that
<br>
will result from any arbitrary combination of direct neural
<br>
stimuli, would that be good enough for you?
<br>
<p><em>&gt; The immediate challenge is just to develop an adequate
</em><br>
<em>&gt; description of consciousness - a phenomenology.
</em><br>
<p>We tried doing that with just reflective data for a few thousand
<br>
years and it didn't work. The experimentalists say that they'll
<br>
have the answer after a bit more progress on instrumentation and
<br>
a lot of computer time. It seems reasonable to wait a few paltry
<br>
decades (CRNS) and give them a chance to deliver on that. Of course
<br>
IMHO we can't afford to wait.
<br>
<p><em>&gt; I want to raise just one more issue, and that is the peril of
</em><br>
<em>&gt; creating AI - especially &quot;self-enhancing&quot; and &quot;Friendly&quot; AI -
</em><br>
<em>&gt; when the nature of consciousness and physical reality is not
</em><br>
<em>&gt; yet understood.
</em><br>
<p>Robust FAI designs have to be able to cope with the possibility
<br>
that our ideas about most things are wrong. This is implied by
<br>
the fact that nothing has a starting prior of 1.0 or 0.0. CV is
<br>
unusually demanding as an FAI theory in that it requires a
<br>
complete theory of human cognition to execute, but that theory
<br>
does not necessarily have to be developed by humans.
<br>
<p><em>&gt; It would appear that with AI, we are not re-creating
</em><br>
<em>&gt; consciousness; we are instead creating the best illusion
</em><br>
<em>&gt; of it that we can, while operating within the physicalist
</em><br>
<em>&gt; framework - and then buying into the illusion.
</em><br>
<p>It's true that no-one knows how to exactly replicate the causal
<br>
system that produces human conscious experience at the moment.
<br>
There are various guesses about how to do it and some people are
<br>
going ahead and trying anyway. Presumably if you believe
<br>
consciousness is extra-physical in some way you don't accept
<br>
that an upload of a person would be conscious (if so, at what
<br>
point does consciousness cease if we replace natural neurons with
<br>
artificial ones one by one?).
<br>
<p><em>&gt; Even without a Singularity, it looks like we will be sharing
</em><br>
<em>&gt; the world with entities which are genuinely not conscious but
</em><br>
<em>&gt; which *can* pass the Turing Test.
</em><br>
<p>This I agree with, in that (a) it should be possible to simulate
<br>
the output of a human-style introspective system without actually
<br>
instantiating the process in such a way as to generate conscious
<br>
experience (this is required if we want to implement CV without
<br>
creating hordes of imprisoned sentients) and (b) under most
<br>
circumstances it is both simpler and safer to build AGI this way.
<br>
<p><em>&gt; What I *do* think is unlikely, is that we will build super-AIs
</em><br>
<em>&gt; on the basis of a wrong theory of the mind's place in nature,
</em><br>
<em>&gt; which will then magically acquire the capability to discover
</em><br>
<em>&gt; our mistake.
</em><br>
<p>It's certainly possible; AIs should be much better researchers than
<br>
humans and if necessary one could trace human brain pathways and
<br>
work out why we perceive qualia without being hindered by our
<br>
countless inbuilt delusions about how we work. Even if there is
<br>
causally significent incomputability lurking in there somewhere, an
<br>
FAI should have no problem finding it (though of course building an
<br>
FAI in the first place is very, very hard).
<br>
<p><em>&gt; If we do this, we will more likely just end up *replacing* real
</em><br>
<em>&gt; mind with pseudo-mind, throughout nature.
</em><br>
<p>This is a real issue, but it's one of preserving a preffered type of
<br>
cognitive architecture despite the fact that it's inconsistent and
<br>
inefficient, not anything mystical or extraphysical.
<br>
<p>&nbsp;* Michael Wilson
<br>
<p><p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
___________________________________________________________ 
<br>
ALL-NEW Yahoo! Messenger - all new features - even more fun! <a href="http://uk.messenger.yahoo.com">http://uk.messenger.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10650.html">maru: "Re: When does it pay to play (lottery)?"</a>
<li><strong>Previous message:</strong> <a href="10648.html">David Clark: "Re: When does it pay to play (lottery)?"</a>
<li><strong>Maybe in reply to:</strong> <a href="10578.html">Philip Sutton: "What are qualia..."</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10649">[ date ]</a>
<a href="index.html#10649">[ thread ]</a>
<a href="subject.html#10649">[ subject ]</a>
<a href="author.html#10649">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
