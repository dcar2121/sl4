<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Definition of strong recursive self-improvement</title>
<meta name="Author" content="Russell Wallace (russell.wallace@gmail.com)">
<meta name="Subject" content="Re: Definition of strong recursive self-improvement">
<meta name="Date" content="2005-01-01">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Definition of strong recursive self-improvement</h1>
<!-- received="Sat Jan  1 17:25:23 2005" -->
<!-- isoreceived="20050102002523" -->
<!-- sent="Sun, 2 Jan 2005 00:25:20 +0000" -->
<!-- isosent="20050102002520" -->
<!-- name="Russell Wallace" -->
<!-- email="russell.wallace@gmail.com" -->
<!-- subject="Re: Definition of strong recursive self-improvement" -->
<!-- id="8d71341e05010116252c29497c@mail.gmail.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="948b11e050101130948aa2565@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Russell Wallace (<a href="mailto:russell.wallace@gmail.com?Subject=Re:%20Definition%20of%20strong%20recursive%20self-improvement"><em>russell.wallace@gmail.com</em></a>)<br>
<strong>Date:</strong> Sat Jan 01 2005 - 17:25:20 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10507.html">Eliezer S. Yudkowsky: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>Previous message:</strong> <a href="10505.html">Keith Henson: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>In reply to:</strong> <a href="10503.html">Samantha Atkins: "Re: Definition of strong recursive self-improvement"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10499.html">Randall Randall: "Re: Definition of strong recursive self-improvement"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10506">[ date ]</a>
<a href="index.html#10506">[ thread ]</a>
<a href="subject.html#10506">[ subject ]</a>
<a href="author.html#10506">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Sat, 1 Jan 2005 13:09:53 -0800, Samantha Atkins &lt;<a href="mailto:sjatkins@gmail.com?Subject=Re:%20Definition%20of%20strong%20recursive%20self-improvement">sjatkins@gmail.com</a>&gt; wrote:
<br>
<em>&gt; I am not sure I see the difficulty.  If one has ways of measuring
</em><br>
<em>&gt; correctness/degree of fit to a goal of results given problem context
</em><br>
<em>&gt; and the efficiency with which a nominally correct solution was arrived
</em><br>
<em>&gt; at and means for tweaking the mechanisms employed to reach the
</em><br>
<em>&gt; solution then even something like a GA is in principle capable of
</em><br>
<em>&gt; generating progressive improvments to the system.
</em><br>
<p>In principle at least, yes; a GA produced one full general
<br>
intelligence system already, after all, and perhaps it could do so
<br>
again.
<br>
<p>However, then you're back to having a population of entities capable
<br>
of self-replication, whose fitness is tested by measuring their
<br>
performance in the real world; this is quite different from the &quot;AI in
<br>
a basement&quot; scenario that I understand Eliezer to be counting on.
<br>
<p><em>&gt; I don't see that recursive self-improvment requires that the
</em><br>
<em>&gt; [super]goal itself is changing.    So what is the problem?
</em><br>
<p>Well, it complicates things considerably from the perspective of
<br>
having to keep an eye on the population of candidate improved AIs to
<br>
make sure what they're doing in the real world is actually
<br>
contributing to your supergoal (rather than, say, the de facto
<br>
supergoal of just making more copies of themselves). It's not a
<br>
&quot;forget it, Friendly AI is impossible&quot; scenario, but it's very much
<br>
more complicated than the &quot;hard takeoff in a basement&quot; one - which is
<br>
why &quot;strongly recursive self-improvement&quot; as I understand Eliezer to
<br>
mean it, would be a nicer/safer way to go if it were possible.
<br>
<p>- Russell
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10507.html">Eliezer S. Yudkowsky: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>Previous message:</strong> <a href="10505.html">Keith Henson: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>In reply to:</strong> <a href="10503.html">Samantha Atkins: "Re: Definition of strong recursive self-improvement"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10499.html">Randall Randall: "Re: Definition of strong recursive self-improvement"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10506">[ date ]</a>
<a href="index.html#10506">[ thread ]</a>
<a href="subject.html#10506">[ subject ]</a>
<a href="author.html#10506">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
