<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Bad Bayesian - no biscuit! (was A New Year's gift for Bayesians)</title>
<meta name="Author" content="Eliezer Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Bad Bayesian - no biscuit! (was A New Year's gift for Bayesians)">
<meta name="Date" content="2005-01-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Bad Bayesian - no biscuit! (was A New Year's gift for Bayesians)</h1>
<!-- received="Thu Jan 20 01:15:54 2005" -->
<!-- isoreceived="20050120081554" -->
<!-- sent="Thu, 20 Jan 2005 03:15:13 -0500" -->
<!-- isosent="20050120081513" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Bad Bayesian - no biscuit! (was A New Year's gift for Bayesians)" -->
<!-- id="41EF6891.5000803@pobox.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="JNEIJCJJHIEAILJBFHILGEHGDCAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Bad%20Bayesian%20-%20no%20biscuit!%20(was%20A%20New%20Year's%20gift%20for%20Bayesians)"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Thu Jan 20 2005 - 01:15:13 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10560.html">Thomas Buckner: "RE: Bad Bayesian - no biscuit! (was A New Year's gift for Bayesians)"</a>
<li><strong>Previous message:</strong> <a href="10558.html">Marc Geddes: "A plain English description of my technical definition of 'Friendliness'"</a>
<li><strong>In reply to:</strong> <a href="10556.html">Ben Goertzel: "RE: Bad Bayesian - no biscuit! (was A New Year's gift for Bayesians)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10562.html">Ben Goertzel: "RE: Bad Bayesian - no biscuit! (was A New Year's gift for Bayesians)"</a>
<li><strong>Reply:</strong> <a href="10562.html">Ben Goertzel: "RE: Bad Bayesian - no biscuit! (was A New Year's gift for Bayesians)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10559">[ date ]</a>
<a href="index.html#10559">[ thread ]</a>
<a href="subject.html#10559">[ subject ]</a>
<a href="author.html#10559">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Goertzel wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Well, when I was a math prof at UNLV, a number of my fellow math
</em><br>
<em>&gt; professors liked to gamble on a regular basis.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; These folks had high IQ's, decently long lists of pure-math
</em><br>
<em>&gt; publications, and generally a lot of common sense and rationality in
</em><br>
<em>&gt; everyday life situations.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I was a bit perplexed at the time that these highly clever and
</em><br>
<em>&gt; reasonable mathematicians were at all interested in gambling, but that
</em><br>
<em>&gt; was before I grasped the deep perversity of human nature as fully as I
</em><br>
<em>&gt; do now ;-)
</em><br>
<p>You're admiring the wrong people!  Let them stop buying lottery tickets, 
<br>
then admire them.  It only defeats your own potential if you think that 
<br>
intelligence has no better use than that.
<br>
<p><em>&gt;&gt; I understand the thriving lottery industry as the present state of
</em><br>
<em>&gt;&gt; affairs, and I ask &quot;How can we train people not to buy lottery
</em><br>
<em>&gt;&gt; tickets?&quot;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; But if people buy lottery tickets because they find the emotional drama
</em><br>
<em>&gt; of it FUN, then teaching them not to buy lottery tickets means either
</em><br>
<em>&gt; 
</em><br>
<em>&gt; a) teaching them not to want to have fun
</em><br>
<em>&gt; 
</em><br>
<em>&gt; b) teaching them to find different things fun than they currently do
</em><br>
<p>People pray because they want their child to not die of cancer.  Teaching 
<br>
them not to pray means (a) teaching them not to want their child to survive 
<br>
(b) associating different outcomes with the effort of prayer.  So too with 
<br>
the lottery.  Even if they claim to pursue the allure of the allure of 
<br>
unimaginable wealth rather than the allure of unimaginable wealth per se, 
<br>
both allures depend on a false belief - a subtle false belief, because 
<br>
while their verbally reported probabilities may be correct, their feeling 
<br>
of probability doesn't correspond to the verbal report.  If people knew 
<br>
more and thought faster, they wouldn't play the lottery.
<br>
<p>If yon mathematicians really understood that winning the lottery was 
<br>
impossible and that they were absolutely certain not to win - an absolute 
<br>
certainty I don't bother to qualify with disclaimers, because it is so 
<br>
enormously stronger than the propositions that people usually believe to be 
<br>
absolutely certain - then they would feel no drama.  I strongly suspect 
<br>
that &quot;I understand the probabilities, but I pursue the drama&quot; is a post 
<br>
facto excuse so that they can retain their self-respect as rationalists 
<br>
without modifying a behavior they know to be irrational.  If they 
<br>
understood the probabilities, there would not be drama.  Mathematicians 
<br>
anticipate that to appear rational they must admit to their fellow 
<br>
mathematicians that they have no significant probability of winning the 
<br>
lottery.  In the corners of their minds they anticipate they can get away 
<br>
with claiming that they pursue the drama, so their self-deceiving mind 
<br>
inserts that justification into their account of themselves.  In today's 
<br>
society their anticipation is correct, for few are strong enough in the 
<br>
Way, or have enough explicit knowledge of the Way, to explicitly describe 
<br>
the mistake.
<br>
<p><em>&gt; I.e. it involves changing their motivational structure rather than their
</em><br>
<em>&gt; reasoning methods, it seems to me.
</em><br>
<p>Change the reasoning method, and the motivational structure will follow.
<br>
<p><em>&gt; Personally I have pretty much given up on teaching people not to have
</em><br>
<em>&gt; silly chimp-like motivational structures.  It's a damn hard problem,
</em><br>
<em>&gt; harder than creating an AGI, in my opinion.
</em><br>
<p>But explaining rationality is a hell of a lot easier than explaining AGI. 
<br>
One of the reasons I now concentrate on the art of human rationality in my 
<br>
writing, is that human rationality is a comprehensible reuse of AGI 
<br>
knowledge, impressive in its own right.  Where AGI itself is nearly 
<br>
impossible to explain, one can see - in retrospect, at least - that one who 
<br>
seeks to apprehend the hidden succession technique of the Way should be a 
<br>
master of its ordinary application, or at least have explicit knowledge 
<br>
thereof.  If I am an AGI wannabe and I have made any sort of significant 
<br>
progress, I ought to be able to solve problems in human rationality with my 
<br>
eyes closed standing on my head in a cold shower with my left cerebral 
<br>
hemisphere removed.
<br>
<p><em>&gt; I try to guide my kids to have motivational structures that I respect,
</em><br>
<em>&gt; but that's an easier problem than the more general case, since they have
</em><br>
<em>&gt; genetic material that's relatively amenable to my taste, and they get a
</em><br>
<em>&gt; lot of personal attention from me....  And it's still not such an easy
</em><br>
<em>&gt; problem, as they've all inherited my individuality and pigheaded
</em><br>
<em>&gt; stubbornness along with many of my other fine and not-so-fine traits ;-)
</em><br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10560.html">Thomas Buckner: "RE: Bad Bayesian - no biscuit! (was A New Year's gift for Bayesians)"</a>
<li><strong>Previous message:</strong> <a href="10558.html">Marc Geddes: "A plain English description of my technical definition of 'Friendliness'"</a>
<li><strong>In reply to:</strong> <a href="10556.html">Ben Goertzel: "RE: Bad Bayesian - no biscuit! (was A New Year's gift for Bayesians)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10562.html">Ben Goertzel: "RE: Bad Bayesian - no biscuit! (was A New Year's gift for Bayesians)"</a>
<li><strong>Reply:</strong> <a href="10562.html">Ben Goertzel: "RE: Bad Bayesian - no biscuit! (was A New Year's gift for Bayesians)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10559">[ date ]</a>
<a href="index.html#10559">[ thread ]</a>
<a href="subject.html#10559">[ subject ]</a>
<a href="author.html#10559">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
