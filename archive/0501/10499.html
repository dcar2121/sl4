<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Definition of strong recursive self-improvement</title>
<meta name="Author" content="Randall Randall (randall@randallsquared.com)">
<meta name="Subject" content="Re: Definition of strong recursive self-improvement">
<meta name="Date" content="2005-01-01">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Definition of strong recursive self-improvement</h1>
<!-- received="Sat Jan  1 00:41:59 2005" -->
<!-- isoreceived="20050101074159" -->
<!-- sent="Sat, 1 Jan 2005 02:41:55 -0500" -->
<!-- isosent="20050101074155" -->
<!-- name="Randall Randall" -->
<!-- email="randall@randallsquared.com" -->
<!-- subject="Re: Definition of strong recursive self-improvement" -->
<!-- id="9C290B1A-5BC8-11D9-B852-000A95A0F1E8@randallsquared.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="41D62393.5070205@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Randall Randall (<a href="mailto:randall@randallsquared.com?Subject=Re:%20Definition%20of%20strong%20recursive%20self-improvement"><em>randall@randallsquared.com</em></a>)<br>
<strong>Date:</strong> Sat Jan 01 2005 - 00:41:55 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10500.html">Giu1i0 Pri5c0: "Re: A New Year's gift for Bayesians"</a>
<li><strong>Previous message:</strong> <a href="../0412/10498.html">Russell Wallace: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>In reply to:</strong> <a href="../0412/10496.html">Eliezer Yudkowsky: "Re: Definition of strong recursive self-improvement"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10502.html">Russell Wallace: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>Reply:</strong> <a href="10502.html">Russell Wallace: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>Reply:</strong> <a href="10504.html">Randall Randall: "Re: Definition of strong recursive self-improvement"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10499">[ date ]</a>
<a href="index.html#10499">[ thread ]</a>
<a href="subject.html#10499">[ subject ]</a>
<a href="author.html#10499">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Dec 31, 2004, at 11:14 PM, Eliezer Yudkowsky wrote:
<br>
<em>&gt; Russell Wallace wrote:
</em><br>
<em>&gt;&gt; Yes; and both of these would in the long run encounter the same
</em><br>
<em>&gt;&gt; fundamental problem that a Strong RSI AI must encounter, as far as I
</em><br>
<em>&gt;&gt; can see. Again, the problem is, how do you know whether a putative
</em><br>
<em>&gt;&gt; improvement is in fact an improvement? There is no way of finding out
</em><br>
<em>&gt;&gt; other than by letting it run loose for an open-ended period of time,
</em><br>
<em>&gt;&gt; in which case you're back into evolution by natural selection. Do you
</em><br>
<em>&gt;&gt; think you have found a way to solve this problem? If so, how?
</em><br>
<em>&gt;
</em><br>
<em>&gt; You mean that when you write code, you have no way of knowing what any 
</em><br>
<em>&gt; individual module does, except letting it run for an open-ended period 
</em><br>
<em>&gt; of time?  That must make it awfully difficult to write code.
</em><br>
<p>I think I understand the question being asked here,
<br>
and I think it's an important one, so let me try to
<br>
ask it or a related one in a different way:
<br>
<p>When you write code, you simulate, on some level,
<br>
what the code is doing in order to determine whether
<br>
the algorithm you're writing will do what you intend.
<br>
However, no amount of simulation will allow you to
<br>
design an algorithm that is more intelligent than
<br>
you are, since it must be executable within your
<br>
current algorithm.  At the most, you can design an
<br>
algorithm that would more quickly reach conclusions
<br>
you can already reach (by simulation, if necessary).
<br>
After several iterations, you may be able to design
<br>
algorithms which would have required more time than
<br>
is available to simulate, so this does seem to fit
<br>
the definition of strong RSI, but this method will
<br>
never give you an algorithm that is strongly more
<br>
intelligent than you are, since you have to be able
<br>
to run the algorithm in simulation in advance of
<br>
implementing it on the same level as your current
<br>
algorithm.  Further, this requires that there is
<br>
always some improvement that can be simulated on
<br>
your current virtual machine, but which will allow
<br>
simulations of things that cannot be (feasibly)
<br>
simulated on your current VM.
<br>
<p>Is there some reason to think that such &quot;easy&quot;
<br>
improvements will always be available?  I understand
<br>
that's a very open-ended question.
<br>
<p>Here's a worse issue:  Since there is more memory and
<br>
speed available on the hardware one is running on
<br>
than in the VM (by definition), if one assumes that
<br>
there are always easy improvements simulable on your
<br>
VM, then there are likely to be further improvements
<br>
available with an evolutionary system that doesn't
<br>
care about keeping control.  That is, the curve of
<br>
improvement available to a lower level of simulation,
<br>
or running an evolution on the hardware, lies above
<br>
the curve available for VM-only simulation, so
<br>
non-Friendly AI will have the opportunity to outrace
<br>
Friendly AI.
<br>
<p><em>&gt;  How many randomly generated strings do you need to test before you 
</em><br>
<em>&gt; find one that compiles?
</em><br>
<p>Well, you'd clearly want to use a language in which you
<br>
could do symbolic computation, so that *all* attempts
<br>
compile.  That's been a solved problem for decades.
<br>
<p><pre>
--
Randall Randall &lt;<a href="mailto:randall@randallsquared.com?Subject=Re:%20Definition%20of%20strong%20recursive%20self-improvement">randall@randallsquared.com</a>&gt;
&quot;If you do not work on an important problem,
it's unlikely you'll do important work.&quot; -- Richard Hamming
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10500.html">Giu1i0 Pri5c0: "Re: A New Year's gift for Bayesians"</a>
<li><strong>Previous message:</strong> <a href="../0412/10498.html">Russell Wallace: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>In reply to:</strong> <a href="../0412/10496.html">Eliezer Yudkowsky: "Re: Definition of strong recursive self-improvement"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10502.html">Russell Wallace: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>Reply:</strong> <a href="10502.html">Russell Wallace: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>Reply:</strong> <a href="10504.html">Randall Randall: "Re: Definition of strong recursive self-improvement"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10499">[ date ]</a>
<a href="index.html#10499">[ thread ]</a>
<a href="subject.html#10499">[ subject ]</a>
<a href="author.html#10499">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
