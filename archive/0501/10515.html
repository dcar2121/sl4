<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Definition of strong recursive self-improvement</title>
<meta name="Author" content="Russell Wallace (russell.wallace@gmail.com)">
<meta name="Subject" content="Re: Definition of strong recursive self-improvement">
<meta name="Date" content="2005-01-02">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Definition of strong recursive self-improvement</h1>
<!-- received="Sun Jan  2 12:41:20 2005" -->
<!-- isoreceived="20050102194120" -->
<!-- sent="Sun, 2 Jan 2005 19:41:18 +0000" -->
<!-- isosent="20050102194118" -->
<!-- name="Russell Wallace" -->
<!-- email="russell.wallace@gmail.com" -->
<!-- subject="Re: Definition of strong recursive self-improvement" -->
<!-- id="8d71341e050102114157985a2a@mail.gmail.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="41D831AE.3070507@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Russell Wallace (<a href="mailto:russell.wallace@gmail.com?Subject=Re:%20Definition%20of%20strong%20recursive%20self-improvement"><em>russell.wallace@gmail.com</em></a>)<br>
<strong>Date:</strong> Sun Jan 02 2005 - 12:41:18 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10516.html">Mike Williams: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>Previous message:</strong> <a href="10514.html">Russell Wallace: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>In reply to:</strong> <a href="10513.html">Eliezer S. Yudkowsky: "Re: Definition of strong recursive self-improvement"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10517.html">Eliezer S. Yudkowsky: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>Reply:</strong> <a href="10517.html">Eliezer S. Yudkowsky: "Re: Definition of strong recursive self-improvement"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10515">[ date ]</a>
<a href="index.html#10515">[ thread ]</a>
<a href="subject.html#10515">[ subject ]</a>
<a href="author.html#10515">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Sun, 02 Jan 2005 11:38:54 -0600, Eliezer S. Yudkowsky
<br>
&lt;<a href="mailto:sentience@pobox.com?Subject=Re:%20Definition%20of%20strong%20recursive%20self-improvement">sentience@pobox.com</a>&gt; wrote:
<br>
<em>&gt; Thank you for your helpful explanation; go forth and implement it in an
</em><br>
<em>&gt; AI code-writing system and put all the programmers out of business.
</em><br>
<p>On my to-do list ^.^
<br>
<p><em>&gt; I do not intend to achieve (it is theoretically impossible to achieve, I
</em><br>
<em>&gt; think) a 1.00000... expected probability of success.  However, such
</em><br>
<em>&gt; outside causes as you name are not *independent* causes of failure among
</em><br>
<em>&gt; all the elements of a complex system.
</em><br>
<p>Nor am I claiming otherwise.
<br>
<p><em>&gt; But if I knew how to build an FAI that worked so long as no one tossed
</em><br>
<em>&gt; its CPU into a bowl of ice cream, I would count myself as having made
</em><br>
<em>&gt; major progress.
</em><br>
<p>Yes, I think it's safe to say that would qualify as progress alright.
<br>
<p>Do you still believe in the &quot;hard takeoff in a basement&quot; scenario, though?
<br>
<p><em>&gt; Meanwhile, saying that humans use &quot;semi-formal reasoning&quot; to write code
</em><br>
<em>&gt; is not, I'm afraid, a Technical Explanation.
</em><br>
<p>No, really? I'm shocked :) (Good article that, btw.)
<br>
<p>If either of us were at the point of being able to provide a Technical
<br>
Explanation for this stuff, this conversation would be taking a very
<br>
different form. (For one thing, the side that had it could probably
<br>
let their AI do a lot of the debating for them!) But my semi-technical
<br>
explanation does answer the question you asked, which is how _in
<br>
principle_ it can be possible for human programmers to ever write
<br>
working code; and it therefore suffices to answer your objection that
<br>
if I was right about the problems, there could be no such thing even
<br>
in principle.
<br>
<p><em>&gt; Imagine someone who knew
</em><br>
<em>&gt; naught of Bayes, pointing to probabilistic reasoning and saying it was
</em><br>
<em>&gt; all &quot;guessing&quot; and therefore would inevitably fail at one point or
</em><br>
<em>&gt; another.  In that vague and verbal model you could not express the
</em><br>
<em>&gt; notion of a more reliable, better-discriminating probabilistic guesser,
</em><br>
<em>&gt; powered by Bayesian principles and a better implementation, that could
</em><br>
<em>&gt; achieve a calibrated probability of 0.0001% for the failure of an entire
</em><br>
<em>&gt; system over, say, ten millennia.
</em><br>
<p>This is all very well, but how do you go about applying Bayes to a
<br>
situation where the number of possible hypotheses greatly exceeds the
<br>
number of atoms in the visible universe?
<br>
<p>How do you get a calibrated probability of failure, or even calculate
<br>
P(E|H) for a few H's, in a situation where calculating P(E|H) for one
<br>
H would take computer time measured in teraexaflop-eons, and plenty of
<br>
them?
<br>
<p>(These are not rhetorical questions. I'm asking them because answers
<br>
would be of great practical value.)
<br>
<p><em>&gt; (For I do now regard FAI as an interim
</em><br>
<em>&gt; measure, to be replaced by some other System when humans have grown up a
</em><br>
<em>&gt; little.)
</em><br>
<p>So you want to take humans out of the loop for awhile, then put them
<br>
back in after a few millennia? (Whereas I'm inclined to think humans
<br>
will need to stay in the loop all the way along.)
<br>
<p>- Russell
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10516.html">Mike Williams: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>Previous message:</strong> <a href="10514.html">Russell Wallace: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>In reply to:</strong> <a href="10513.html">Eliezer S. Yudkowsky: "Re: Definition of strong recursive self-improvement"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10517.html">Eliezer S. Yudkowsky: "Re: Definition of strong recursive self-improvement"</a>
<li><strong>Reply:</strong> <a href="10517.html">Eliezer S. Yudkowsky: "Re: Definition of strong recursive self-improvement"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10515">[ date ]</a>
<a href="index.html#10515">[ thread ]</a>
<a href="subject.html#10515">[ subject ]</a>
<a href="author.html#10515">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
