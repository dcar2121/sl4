<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Probabilistic Philosophy of Mind</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="Probabilistic Philosophy of Mind">
<meta name="Date" content="2005-01-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Probabilistic Philosophy of Mind</h1>
<!-- received="Sat Jan 15 08:33:37 2005" -->
<!-- isoreceived="20050115153337" -->
<!-- sent="Sat, 15 Jan 2005 10:33:14 -0500" -->
<!-- isosent="20050115153314" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="Probabilistic Philosophy of Mind" -->
<!-- id="JNEIJCJJHIEAILJBFHILCEMLDBAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="s1e8fca3.098@IA-GEN-A2.dundee.ac.uk" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=Re:%20Probabilistic%20Philosophy%20of%20Mind"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sat Jan 15 2005 - 08:33:14 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10535.html">David Clark: "Re: Fuzzy vs Probability"</a>
<li><strong>Previous message:</strong> <a href="10533.html">Ben Goertzel: "RE: Fuzzy vs Probability"</a>
<li><strong>In reply to:</strong> <a href="10531.html">Stephen Tattum: "Fuzzy vs Probability"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10535.html">David Clark: "Re: Fuzzy vs Probability"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10534">[ date ]</a>
<a href="index.html#10534">[ thread ]</a>
<a href="subject.html#10534">[ subject ]</a>
<a href="author.html#10534">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Stephen,
<br>
<p>This long email is a (lightly edited) excerpt from one of the
<br>
long-in-progress books on my Novamente AI system and the ideas underlying
<br>
it.
<br>
<p>It outlines a philosophy of mind that has probability theory at the
<br>
foundation, and explains how this philosophy of mind relates to our
<br>
probability-theory-based AI design.
<br>
<p>First of all: There are many different ways to formulate the &quot;psynet model
<br>
of mind&quot;, the philosophy of mind that lies at the foundation of the
<br>
Novamente design.   One formulation that has particular resonance with the
<br>
AI design details is what we call the &quot;probabilistic psynet model.&quot;  This is
<br>
a way of expressing and verbalizing the psynet model that introduces
<br>
probabilistic notions from the very start - convenient because Novamente's
<br>
core AI techniques are probabilistically based.
<br>
<p>The key principles of the psynet model of mind, expressed in
<br>
probability-theory-friendly form, are as follows (of course, a few
<br>
principles could be added or omitted without changing the essence of the
<br>
formulation - the psynet model is a theory with fuzzy boundaries):
<br>
<p>1)	An intelligent system is a system that can achieve complex goals in
<br>
complex environments
<br>
<p>2)	A mind is the set of patterns in, or associated with, an intelligent
<br>
system
<br>
<p>3)	Intelligence is a matter of (implicitly or explicitly) finding procedures
<br>
that, if executed, have a high probability of leading to goal achievement in
<br>
the observed context
<br>
<p>4)	A pattern is defined probabilistically (f is a pattern in X if f produces
<br>
X and the reference simple-entity-generator is more likely to produce f than
<br>
to produce X)
<br>
<p>5)	In order to achieve intelligence, an intelligent system must execute a
<br>
variety of procedures in a variety of contexts, and then create abstractions
<br>
allowing it to generate new procedures that will hopefuly be effective in
<br>
new contexts.  These &quot;abstractions&quot; are patterns relating procedures and
<br>
goal-achievement
<br>
<p>6)	An intelligent system must have a way to take patterns and generate new
<br>
ones from them.  As patterns are defined probabilistically, this takes the
<br>
form (implicitly or explicitly) of probabilistic inference)
<br>
<p>7)	Patterns directly relating procedures and goal-achievement spawn other
<br>
patterns (patterns between patterns).  These patterns tend to be organized
<br>
in a &quot;dual network&quot; structure, with a hierarchical and heterarchical
<br>
(associational) structure overlapping.
<br>
<p>8)	An intelligent system will tend to construct a probabilistic model of
<br>
itself, which is represented by a subnetwork of the dual network that may be
<br>
called the &quot;self&quot; of the system
<br>
<p>9)	Given finite resources devoted to pattern learning, an intelligent system
<br>
must choose which aspects of its world and itself to pay more attention to.
<br>
This is an example of goal-directed learning, in that the system must learn
<br>
which attention-allocation procedures, overall, tend to lead to better goal
<br>
achievement.  This learning is a process of pattern recognition, similar in
<br>
nature to the other probabilistic pattern recognition processes that the
<br>
mind carries out.
<br>
<p>10)	Emergence occurs spontaneously in pattern-networks: i.e. often when two
<br>
patterns that were difficult to find are placed together in the same memory,
<br>
the result is that there are patterns that are relatively easy to find,
<br>
spanning the two difficult-to-find patterns &quot;emergently.&quot;
<br>
<p>11)	Linguistic communication involves minds transmitting abstract patterns
<br>
to one another via the use of symbols (which are themselves a particular
<br>
type of pattern).  This allows minds to acquire very complex
<br>
pattern-networks without learning all the patterns themselves, and it
<br>
encourages the creation of patterns spanning multiple individual minds, in
<br>
effect binding multiple minds into an overall &quot;mindplex.&quot;
<br>
<p>Does such a probabilistically-expressed theory of mind imply that every mind
<br>
must explicitly make use of probability theory formulas?   Of course not.
<br>
Clearly, it's possible to create AI architectures that are explicitly
<br>
probabilistic, and others that are not founded on probabilistic notions at
<br>
all, yet (similarly to the human brain) behave overall in accordance with
<br>
approximate probabilistic calculations.  The human brain is clearly
<br>
implicitly but not explicitly probabilistic; Novamente is explicitly
<br>
probabilistic, but is far from the only explicitly probabilistic AI design.
<br>
<p>Now, how does Novamente embody these general probabilistic/philosophical
<br>
principles?  A very quick summary (probably only partially comprehensible at
<br>
this stage - the list should be reread after the rest of the book has been
<br>
digested!) is given here.
<br>
<p>In essence, Novamente consists of a large pool of patterns observed in the
<br>
world and itself, represented in terms of a special hypergraph-based
<br>
formalism that involves various types of nodes and links.  Some nodes and
<br>
links represent probabilistic patterns directly, others represent the
<br>
interaction of other nodes and links, thus allowing complex patterns to be
<br>
built up from multiple nodes and links.  New nodes and links are learned by
<br>
a variety of processes, all of which make use of two basic tools:
<br>
probabilistic term logic and the Bayesian Optimization Algorithm.
<br>
<p>More explicitly what this boils down to is:
<br>
<p>1)	Procedures are represented using objects called &quot;combinator trees&quot; using
<br>
a special vocabulary defined by the Combo programming language.  Combinator
<br>
trees contain special nodes and links representing patterns and procedures.
<br>
<p>2)	The environment of the system is represented via perceptual nodes and
<br>
links, which are interpreted as probabilistic patterns in the environment
<br>
<p>3)	The internal state of the system is represented via feeling-nodes and
<br>
associated links, which are interpreted as probabilistic patterns in the
<br>
system itself
<br>
<p>4)	Goals are represented as procedures (i.e. as predicates which output True
<br>
to the extent that the goal-state they embody is satisfied)
<br>
<p>5)	Patterns may be represented explicitly as procedures (i.e. combinator
<br>
trees wrapped in PredicateNodes)
<br>
<p>6)	In simple cases, patterns may also be represented as Node or Link objects
<br>
representing conditional probabilities or Boolean combinations thereof
<br>
<p>7)	Learning of patterns is carried out via two methods:
<br>
a.	PTL, which performs probabilistic inference on Node and Link objects
<br>
b.	BOA, which is specialized to efficiently recognize simple patterns among
<br>
general procedures
<br>
<p>8)	Attention allocation is carried out using BOA and PTL applied to the
<br>
problem of learning what it's valuable to pay attention to in what contexts
<br>
Note that points 1-5 are highly general statements about representation.
<br>
They simply state that we're using a certain general mathematical formalism
<br>
to represent procedures, patterns and goals, and that patterns may involve
<br>
tokens that represent percepts or feelings.  Of course, there are already
<br>
major choices being made at this level: to use combinator trees instead of
<br>
e.g. neural networks; to use the same representational approach for patterns
<br>
and procedures.
<br>
<p>Point 6 represents another major choice: basically, to bias the system
<br>
toward the recognition of patterns compactly representable in terms of
<br>
probabilistic term logic.
<br>
<p>Point 7a identifies a generic learning method (BOA) that can be used on any
<br>
procedures, but is fairly resource-intensive.  7b identifies a more
<br>
specialized learning method that works on special, simple patterns and is
<br>
much less resource-intensive.  Finally, 8 states that attention allocation
<br>
will be handled using these same methods (rather than some other heuristic
<br>
technique).
<br>
<p>As noted above, there are many other choices that could have been made -
<br>
Novamente is certainly not the only approach to AGI consistent with the
<br>
probabilistic variant of the psynet model, let alone the only valid approach
<br>
to AGI.  All we claim is that it seems to be a valid approach to AGI, and
<br>
one that we have managed to spell out in great detail, and are partway
<br>
through implementing and tuning.
<br>
<p>Unfortunately, due to a lack of hardly any funding oriented toward AGI, the
<br>
work is going very slowly, and we are spending most of our time working on
<br>
various short-term narrow-AI applications of the partially-complete
<br>
Novamente codebase.  But we'll get there....
<br>
<p>-- Ben Goertzel
<br>
<p><p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sl4.org?Subject=Re:%20Probabilistic%20Philosophy%20of%20Mind">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=Re:%20Probabilistic%20Philosophy%20of%20Mind">owner-sl4@sl4.org</a>]On Behalf Of Stephen
</em><br>
<em>&gt; Tattum
</em><br>
<em>&gt; Sent: Saturday, January 15, 2005 6:21 AM
</em><br>
<em>&gt; To: <a href="mailto:sl4@sl4.org?Subject=Re:%20Probabilistic%20Philosophy%20of%20Mind">sl4@sl4.org</a>
</em><br>
<em>&gt; Subject: Fuzzy vs Probability
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; I was looking over the Singularity Institute page on becoming a seed AI
</em><br>
<em>&gt; Programmer the other day and I couldn't help but feel that there is an
</em><br>
<em>&gt; overwhelming bias towards bayesian reasoning and I have noticed that a
</em><br>
<em>&gt; lot of contributors to sl4 hail this as all-powerful - should they?
</em><br>
<em>&gt; Check out this paper by Bart Kosko (clearly a 'brilliant' individual)
</em><br>
<em>&gt; and his other work -
</em><br>
<em>&gt;
</em><br>
<em>&gt; <a href="http://sipi.usc.edu/~kosko/ProbabilityMonopoly.pdf">http://sipi.usc.edu/~kosko/ProbabilityMonopoly.pdf</a>
</em><br>
<em>&gt; <a href="http://sipi.usc.edu/~kosko/">http://sipi.usc.edu/~kosko/</a>
</em><br>
<em>&gt;
</em><br>
<em>&gt; I couldn't help noticing also that generally there are gaps in the
</em><br>
<em>&gt; plan. As a philosopher I saw the ommission of any philosophy of mind -
</em><br>
<em>&gt; crucial to any AI discussions and for any 'deep understanding' of the
</em><br>
<em>&gt; issues actually outlined - strange... I have witnessed in the past
</em><br>
<em>&gt; prejudice against philosophy and philosophers here too (apology already
</em><br>
<em>&gt; accepted of course) and I wondered if the project of creating AI is
</em><br>
<em>&gt; being pushed forward before it is ready. Now I believe that the
</em><br>
<em>&gt; singularity is inevitable and I am not suggesting that the institute is
</em><br>
<em>&gt; wrong, just that creating an Artificial General Intelligence, needs more
</em><br>
<em>&gt; emphasis on the general. Any thoughts?
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10535.html">David Clark: "Re: Fuzzy vs Probability"</a>
<li><strong>Previous message:</strong> <a href="10533.html">Ben Goertzel: "RE: Fuzzy vs Probability"</a>
<li><strong>In reply to:</strong> <a href="10531.html">Stephen Tattum: "Fuzzy vs Probability"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10535.html">David Clark: "Re: Fuzzy vs Probability"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10534">[ date ]</a>
<a href="index.html#10534">[ thread ]</a>
<a href="subject.html#10534">[ subject ]</a>
<a href="author.html#10534">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
