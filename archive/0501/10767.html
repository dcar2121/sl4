<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Ethics (was FAI (aka 'Reality Hacking'))</title>
<meta name="Author" content="Jef Allbright (jef@jefallbright.net)">
<meta name="Subject" content="Re: Ethics (was FAI (aka 'Reality Hacking'))">
<meta name="Date" content="2005-01-31">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Ethics (was FAI (aka 'Reality Hacking'))</h1>
<!-- received="Mon Jan 31 15:06:41 2005" -->
<!-- isoreceived="20050131220641" -->
<!-- sent="Mon, 31 Jan 2005 14:06:25 -0800" -->
<!-- isosent="20050131220625" -->
<!-- name="Jef Allbright" -->
<!-- email="jef@jefallbright.net" -->
<!-- subject="Re: Ethics (was FAI (aka 'Reality Hacking'))" -->
<!-- id="41FEABE1.50404@jefallbright.net" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="Ethics (was FAI (aka 'Reality Hacking'))" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Jef Allbright (<a href="mailto:jef@jefallbright.net?Subject=Re:%20Ethics%20(was%20FAI%20(aka%20'Reality%20Hacking'))"><em>jef@jefallbright.net</em></a>)<br>
<strong>Date:</strong> Mon Jan 31 2005 - 15:06:25 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10768.html">Jef Allbright: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<li><strong>Previous message:</strong> <a href="10766.html">Jef Allbright: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<li><strong>Maybe in reply to:</strong> <a href="10733.html">Phil Goetz: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10778.html">Phil Goetz: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<li><strong>Reply:</strong> <a href="10778.html">Phil Goetz: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10767">[ date ]</a>
<a href="index.html#10767">[ thread ]</a>
<a href="subject.html#10767">[ subject ]</a>
<a href="author.html#10767">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; --- Jef Allbright &lt;<a href="mailto:jef@jefallbright.net?Subject=Re:%20Ethics%20(was%20FAI%20(aka%20'Reality%20Hacking'))">jef@jefallbright.net</a>&gt; wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt; What morality is: Choices about &quot;right&quot; and &quot;wrong&quot; behavior based on
</em><br>
<em>&gt;&gt; an assumed foundation that extends beyond the individual to the 
</em><br>
<em>&gt;&gt; group, and beyond the immediate to the practically eternal, and
</em><br>
<em>&gt;&gt; beyond the situation at hand to classes of situations in general.
</em><br>
<em>&gt;&gt; Morality as so defined and practiced is an illusion leading to
</em><br>
<em>&gt;&gt; apparent paradox, but one that is very commonly accepted and
</em><br>
<em>&gt;&gt; practiced.  Most of our current moral foundation is a result of
</em><br>
<em>&gt;&gt; evolutionary processes, promoting survival of the species and the
</em><br>
<em>&gt;&gt; group, without the expense of reasoning through the issues.  It
</em><br>
<em>&gt;&gt; worked well for a very long time.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I understand and basically agree with this.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt; What morality is becoming: Choices based on local values and
</em><br>
<em>&gt;&gt; circumstances, approximations to what works in the greater reality,
</em><br>
<em>&gt;&gt; providing local efficacy and a valuable source of diversity to the
</em><br>
<em>&gt;&gt; larger group.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I don't understand what you're getting at here.
</em><br>
<em>&gt; What's the difference between this, and the former?
</em><br>
<p>I didn't make it very clear that the former is moral decision-making on 
<br>
a foundation of relatively obsolete evolved mechanisms with the 
<br>
assumption that they are to be applied universally to all agents, times, 
<br>
and instances.
<br>
<p>The latter is about decision making with awareness and consideration 
<br>
that effective choices will be crafted to meet local and specific needs 
<br>
while being only a approximation of universal truths, and that there is 
<br>
always a greater context to be considered.
<br>
<p><em>&gt; 
</em><br>
<em>&gt;&gt; Overview: Just as with the thermodynamic &quot;arrow of time&quot;, there is an
</em><br>
<em>&gt;&gt; analogous &quot;arrow of morality&quot; by which that which works (and is
</em><br>
<em>&gt;&gt; therefore seen as good) within local contexts will tend in the 
</em><br>
<em>&gt;&gt; direction of that which works within a larger context as the local
</em><br>
<em>&gt;&gt; contexts combine to form larger contexts of interaction.  This is a
</em><br>
<em>&gt;&gt; true relationship between physics and morality.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I think there are two wrong assumptions in your
</em><br>
<em>&gt; idea that this occurs and that it makes morality
</em><br>
<em>&gt; more objective.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 1. You assume that morality that works in a larger
</em><br>
<em>&gt; system is more objective than morality that works in
</em><br>
<em>&gt; a smaller system. I don't think so. Most of what
</em><br>
<em>&gt; we regard as moral behavior, in fact (generally,
</em><br>
<em>&gt; everything involving reciprocity), is more adaptive
</em><br>
<em>&gt; in small communities. Moving to a larger system
</em><br>
<em>&gt; may simply destroy the evolutionary stability of
</em><br>
<em>&gt; a complex moral system and replace it with a
</em><br>
<em>&gt; simpler one. In any case, there's no reason to
</em><br>
<em>&gt; believe that the new system is more objective.
</em><br>
<p>I agree that our current notions of morality based on evolved mechanisms 
<br>
tend to remain most effective in smaller communities.
<br>
<p>My point is that smaller communities face increasing pressure to merge 
<br>
with others, with increasing occurrence of conventionally held moral 
<br>
beliefs being tested against each other, and the tendency is for those 
<br>
which reflect a more accurate model of reality to be selected for their 
<br>
greater utility.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; 2. You assume that social systems naturally become
</em><br>
<em>&gt; more complex as time goes on. I have two objections
</em><br>
<em>&gt; to this:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; A) Societies seem to follow a growth-boom-crash
</em><br>
<em>&gt; pattern; there may very well be tendencies for
</em><br>
<em>&gt; societies to become less stable as they become more
</em><br>
<em>&gt; complex, making crash inevitable. This has been
</em><br>
<em>&gt; a popular idea at least since Rousseau. It is
</em><br>
<em>&gt; usually stated in terms of &quot;moral decay&quot;. So all
</em><br>
<em>&gt; those people would disagree with any notion that
</em><br>
<em>&gt; increasing complexity leads to a betterment of
</em><br>
<em>&gt; morals. (I suppose betterment = becoming more
</em><br>
<em>&gt; objective.)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; B) See Stephen Gould's book /Full House/. The
</em><br>
<em>&gt; entire book is a debunking of the idea that
</em><br>
<em>&gt; evolution causes systems to become more complex
</em><br>
<em>&gt; over time. Gould claims, with much data to back
</em><br>
<em>&gt; him up, that evolution is a random walk, and that
</em><br>
<em>&gt; there is no tendency for species to increase in
</em><br>
<em>&gt; complexity over time. The distribution of species
</em><br>
<em>&gt; complexity may grow wider over time, but that is
</em><br>
<em>&gt; only because there is a limiting &quot;left-wall&quot;
</em><br>
<em>&gt; minimal level of complexity below which a species
</em><br>
<em>&gt; cannot go. This makes species complexity a
</em><br>
<em>&gt; one-dimensional random walk with a left boundary.
</em><br>
<em>&gt; 
</em><br>
<p><p>I see that Eliezer already responded to this, in agreement with my own 
<br>
assessment of Gould as well as the reference to accretion of additional 
<br>
adaptive functions by organisms until they reach a particular metastable 
<br>
point.  I would add only that I see the evolutionary pressure on human 
<br>
societies rapidly increasing, rather than reaching stability any time soon.
<br>
<p>- Jef
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10768.html">Jef Allbright: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<li><strong>Previous message:</strong> <a href="10766.html">Jef Allbright: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<li><strong>Maybe in reply to:</strong> <a href="10733.html">Phil Goetz: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10778.html">Phil Goetz: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<li><strong>Reply:</strong> <a href="10778.html">Phil Goetz: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10767">[ date ]</a>
<a href="index.html#10767">[ thread ]</a>
<a href="subject.html#10767">[ subject ]</a>
<a href="author.html#10767">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
