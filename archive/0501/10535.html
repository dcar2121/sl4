<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Fuzzy vs Probability</title>
<meta name="Author" content="David Clark (clarkd@rccconsulting.com)">
<meta name="Subject" content="Re: Fuzzy vs Probability">
<meta name="Date" content="2005-01-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Fuzzy vs Probability</h1>
<!-- received="Sat Jan 15 08:51:02 2005" -->
<!-- isoreceived="20050115155102" -->
<!-- sent="Sat, 15 Jan 2005 08:48:03 -0700" -->
<!-- isosent="20050115154803" -->
<!-- name="David Clark" -->
<!-- email="clarkd@rccconsulting.com" -->
<!-- subject="Re: Fuzzy vs Probability" -->
<!-- id="000601c4fb19$99eae9c0$0502a8c0@rcc5" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="s1e8fca3.098@IA-GEN-A2.dundee.ac.uk" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> David Clark (<a href="mailto:clarkd@rccconsulting.com?Subject=Re:%20Fuzzy%20vs%20Probability"><em>clarkd@rccconsulting.com</em></a>)<br>
<strong>Date:</strong> Sat Jan 15 2005 - 08:48:03 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10536.html">Eliezer Yudkowsky: "Re: Fuzzy vs Probability"</a>
<li><strong>Previous message:</strong> <a href="10534.html">Ben Goertzel: "Probabilistic Philosophy of Mind"</a>
<li><strong>In reply to:</strong> <a href="10531.html">Stephen Tattum: "Fuzzy vs Probability"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10537.html">maru dubshinki: "Re: Fuzzy vs Probability"</a>
<li><strong>Reply:</strong> <a href="10537.html">maru dubshinki: "Re: Fuzzy vs Probability"</a>
<li><strong>Reply:</strong> <a href="10539.html">Mark Waser \(home\): "Re: Fuzzy vs Probability"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10535">[ date ]</a>
<a href="index.html#10535">[ thread ]</a>
<a href="subject.html#10535">[ subject ]</a>
<a href="author.html#10535">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
----- Original Message ----- 
<br>
From: &quot;Stephen Tattum&quot; &lt;<a href="mailto:S.Tattum@dundee.ac.uk?Subject=Re:%20Fuzzy%20vs%20Probability">S.Tattum@dundee.ac.uk</a>&gt;
<br>
To: &lt;<a href="mailto:sl4@sl4.org?Subject=Re:%20Fuzzy%20vs%20Probability">sl4@sl4.org</a>&gt;
<br>
Sent: Saturday, January 15, 2005 4:20 AM
<br>
Subject: Fuzzy vs Probability
<br>
<p><p><em>&gt; I couldn't help noticing also that generally there are gaps in the
</em><br>
<em>&gt; plan. As a philosopher I saw the ommission of any philosophy of mind -
</em><br>
<em>&gt; crucial to any AI discussions and for any 'deep understanding' of the
</em><br>
<em>&gt; issues actually outlined - strange... I have witnessed in the past
</em><br>
<em>&gt; prejudice against philosophy and philosophers here too (apology already
</em><br>
<em>&gt; accepted of course) and I wondered if the project of creating AI is
</em><br>
<em>&gt; being pushed forward before it is ready. Now I believe that the
</em><br>
<em>&gt; singularity is inevitable and I am not suggesting that the institute is
</em><br>
<em>&gt; wrong, just that creating an Artificial General Intelligence, needs more
</em><br>
<em>&gt; emphasis on the general. Any thoughts?
</em><br>
<p>Why does AI or any other intelligence have to mimic humans?  If an AI were
<br>
being made out of cells and biology like the human brain then it might be
<br>
reasonable to design the AI structures in the same way, but that is not the
<br>
case.  Take as one example the number of variables we can hold in our minds
<br>
at one time.  Maybe 6, 10 or even 20.  A silicon based computer can hold any
<br>
number of variables (1,000 100,000) in *focus* at one time.  Human memory is
<br>
very inexact.  Computer memory is perfect.  Human brains are hugely parallel
<br>
and computers are hugely serial.  Even if most humans don't use Bayesian
<br>
reasoning, would they do so if they were smart enough?  Bayesian reasoning
<br>
should stand or fall based on what it can give an AI, not on whether humans
<br>
use it much or not.  I see many faults in the way human's think, should I
<br>
design an AI that has the same obvious faults?
<br>
<p>If Eliezer's discussions are not considered 'deep understanding' or at the
<br>
very least detailed explanations then you haven't been reading SL4 or his
<br>
documents very carefully.
<br>
<p>-- David Clark
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10536.html">Eliezer Yudkowsky: "Re: Fuzzy vs Probability"</a>
<li><strong>Previous message:</strong> <a href="10534.html">Ben Goertzel: "Probabilistic Philosophy of Mind"</a>
<li><strong>In reply to:</strong> <a href="10531.html">Stephen Tattum: "Fuzzy vs Probability"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10537.html">maru dubshinki: "Re: Fuzzy vs Probability"</a>
<li><strong>Reply:</strong> <a href="10537.html">maru dubshinki: "Re: Fuzzy vs Probability"</a>
<li><strong>Reply:</strong> <a href="10539.html">Mark Waser \(home\): "Re: Fuzzy vs Probability"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10535">[ date ]</a>
<a href="index.html#10535">[ thread ]</a>
<a href="subject.html#10535">[ subject ]</a>
<a href="author.html#10535">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
