<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Ethics (was FAI (aka 'Reality Hacking'))</title>
<meta name="Author" content="Phil Goetz (philgoetz@yahoo.com)">
<meta name="Subject" content="Re: Ethics (was FAI (aka 'Reality Hacking'))">
<meta name="Date" content="2005-01-31">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Ethics (was FAI (aka 'Reality Hacking'))</h1>
<!-- received="Mon Jan 31 11:40:45 2005" -->
<!-- isoreceived="20050131184045" -->
<!-- sent="Mon, 31 Jan 2005 10:40:21 -0800 (PST)" -->
<!-- isosent="20050131184021" -->
<!-- name="Phil Goetz" -->
<!-- email="philgoetz@yahoo.com" -->
<!-- subject="Re: Ethics (was FAI (aka 'Reality Hacking'))" -->
<!-- id="20050131184021.8468.qmail@web54505.mail.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="41FD0589.1050002@jefallbright.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Phil Goetz (<a href="mailto:philgoetz@yahoo.com?Subject=Re:%20Ethics%20(was%20FAI%20(aka%20'Reality%20Hacking'))"><em>philgoetz@yahoo.com</em></a>)<br>
<strong>Date:</strong> Mon Jan 31 2005 - 11:40:21 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10763.html">Phil Goetz: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<li><strong>Previous message:</strong> <a href="10761.html">Phil Goetz: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<li><strong>In reply to:</strong> <a href="10739.html">Jef Allbright: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10764.html">Eliezer S. Yudkowsky: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<li><strong>Reply:</strong> <a href="10764.html">Eliezer S. Yudkowsky: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10762">[ date ]</a>
<a href="index.html#10762">[ thread ]</a>
<a href="subject.html#10762">[ subject ]</a>
<a href="author.html#10762">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- Jef Allbright &lt;<a href="mailto:jef@jefallbright.net?Subject=Re:%20Ethics%20(was%20FAI%20(aka%20'Reality%20Hacking'))">jef@jefallbright.net</a>&gt; wrote:
<br>
<p><em>&gt; What morality is:
</em><br>
<em>&gt; Choices about &quot;right&quot; and &quot;wrong&quot; behavior based on
</em><br>
<em>&gt; an assumed 
</em><br>
<em>&gt; foundation that extends beyond the individual to the
</em><br>
<em>&gt; group, and beyond 
</em><br>
<em>&gt; the immediate to the practically eternal, and beyond
</em><br>
<em>&gt; the situation at 
</em><br>
<em>&gt; hand to classes of situations in general.  Morality
</em><br>
<em>&gt; as so defined and 
</em><br>
<em>&gt; practiced is an illusion leading to apparent
</em><br>
<em>&gt; paradox, but one that is 
</em><br>
<em>&gt; very commonly accepted and practiced.  Most of our
</em><br>
<em>&gt; current moral 
</em><br>
<em>&gt; foundation is a result of evolutionary processes,
</em><br>
<em>&gt; promoting survival of 
</em><br>
<em>&gt; the species and the group, without the expense of
</em><br>
<em>&gt; reasoning through the 
</em><br>
<em>&gt; issues.  It worked well for a very long time.
</em><br>
<p>I understand and basically agree with this.
<br>
<p><em>&gt; What morality is becoming:
</em><br>
<em>&gt; Choices based on local values and circumstances,
</em><br>
<em>&gt; approximations to what 
</em><br>
<em>&gt; works in the greater reality, providing local
</em><br>
<em>&gt; efficacy and a valuable 
</em><br>
<em>&gt; source of diversity to the larger group.
</em><br>
<p>I don't understand what you're getting at here.
<br>
What's the difference between this, and the former?
<br>
<p><em>&gt; Overview:
</em><br>
<em>&gt; Just as with the thermodynamic &quot;arrow of time&quot;,
</em><br>
<em>&gt; there is an analogous 
</em><br>
<em>&gt; &quot;arrow of morality&quot; by which that which works (and
</em><br>
<em>&gt; is therefore seen as 
</em><br>
<em>&gt; good) within local contexts will tend in the
</em><br>
<em>&gt; direction of that which 
</em><br>
<em>&gt; works within a larger context as the local contexts
</em><br>
<em>&gt; combine to form 
</em><br>
<em>&gt; larger contexts of interaction.  This is a true
</em><br>
<em>&gt; relationship between 
</em><br>
<em>&gt; physics and morality.
</em><br>
<p>I think there are two wrong assumptions in your
<br>
idea that this occurs and that it makes morality
<br>
more objective.
<br>
<p>1.  You assume that morality that works in a larger
<br>
system is more objective than morality that works in
<br>
a smaller system.  I don't think so.  Most of what
<br>
we regard as moral behavior, in fact (generally,
<br>
everything involving reciprocity), is more adaptive
<br>
in small communities.  Moving to a larger system
<br>
may simply destroy the evolutionary stability of
<br>
a complex moral system and replace it with a
<br>
simpler one.  In any case, there's no reason to
<br>
believe that the new system is more objective.
<br>
<p>2.  You assume that social systems naturally become
<br>
more complex as time goes on.  I have two objections
<br>
to this:
<br>
<p>A)  Societies seem to follow a growth-boom-crash
<br>
pattern; there may very well be tendencies for
<br>
societies to become less stable as they become more
<br>
complex, making crash inevitable.  This has been
<br>
a popular idea at least since Rousseau.  It is
<br>
usually stated in terms of &quot;moral decay&quot;.  So all
<br>
those people would disagree with any notion that
<br>
increasing complexity leads to a betterment of
<br>
morals.  (I suppose betterment = becoming more
<br>
objective.)
<br>
<p>B)  See Stephen Gould's book /Full House/.  The
<br>
entire book is a debunking of the idea that
<br>
evolution causes systems to become more complex
<br>
over time.  Gould claims, with much data to back
<br>
him up, that evolution is a random walk, and that
<br>
there is no tendency for species to increase in
<br>
complexity over time.  The distribution of species
<br>
complexity may grow wider over time, but that is
<br>
only because there is a limiting &quot;left-wall&quot;
<br>
minimal level of complexity below which a species
<br>
cannot go.  This makes species complexity a
<br>
one-dimensional random walk with a left boundary.
<br>
<p>- Phil G.
<br>
<p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
__________________________________ 
<br>
Do you Yahoo!? 
<br>
The all-new My Yahoo! - What will yours do?
<br>
<a href="http://my.yahoo.com">http://my.yahoo.com</a> 
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10763.html">Phil Goetz: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<li><strong>Previous message:</strong> <a href="10761.html">Phil Goetz: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<li><strong>In reply to:</strong> <a href="10739.html">Jef Allbright: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10764.html">Eliezer S. Yudkowsky: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<li><strong>Reply:</strong> <a href="10764.html">Eliezer S. Yudkowsky: "Re: Ethics (was FAI (aka 'Reality Hacking'))"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10762">[ date ]</a>
<a href="index.html#10762">[ thread ]</a>
<a href="subject.html#10762">[ subject ]</a>
<a href="author.html#10762">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
