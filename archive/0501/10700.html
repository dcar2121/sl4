<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: FAI (aka 'Reality Hacking') - A list of all my proposed guesses (aka 'hacks')</title>
<meta name="Author" content="Thomas Buckner (tcbevolver@yahoo.com)">
<meta name="Subject" content="RE: FAI (aka 'Reality Hacking') - A list of all my proposed guesses (aka 'hacks')">
<meta name="Date" content="2005-01-28">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: FAI (aka 'Reality Hacking') - A list of all my proposed guesses (aka 'hacks')</h1>
<!-- received="Fri Jan 28 18:46:20 2005" -->
<!-- isoreceived="20050129014620" -->
<!-- sent="Fri, 28 Jan 2005 17:45:57 -0800 (PST)" -->
<!-- isosent="20050129014557" -->
<!-- name="Thomas Buckner" -->
<!-- email="tcbevolver@yahoo.com" -->
<!-- subject="RE: FAI (aka 'Reality Hacking') - A list of all my proposed guesses (aka 'hacks')" -->
<!-- id="20050129014557.62527.qmail@web60007.mail.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="JNEIJCJJHIEAILJBFHILIEAHDEAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas Buckner (<a href="mailto:tcbevolver@yahoo.com?Subject=RE:%20FAI%20(aka%20'Reality%20Hacking')%20-%20A%20list%20of%20all%20my%20proposed%20guesses%20(aka%20'hacks')"><em>tcbevolver@yahoo.com</em></a>)<br>
<strong>Date:</strong> Fri Jan 28 2005 - 18:45:57 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10701.html">Aaron McBride: "Re: Pocket Guide to the Singularity"</a>
<li><strong>Previous message:</strong> <a href="10699.html">maru: "Re: FAI (aka 'Reality Hacking') - A list of all my proposed guesses (aka 'hacks')"</a>
<li><strong>In reply to:</strong> <a href="10685.html">Ben Goertzel: "RE: FAI (aka 'Reality Hacking') - A list of all my proposed guesses (aka 'hacks')"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10734.html">Phil Goetz: "Computational power (was RE: FAI (aka 'Reality Hacking'))"</a>
<li><strong>Reply:</strong> <a href="10734.html">Phil Goetz: "Computational power (was RE: FAI (aka 'Reality Hacking'))"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10700">[ date ]</a>
<a href="index.html#10700">[ thread ]</a>
<a href="subject.html#10700">[ subject ]</a>
<a href="author.html#10700">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- Ben Goertzel &lt;<a href="mailto:ben@goertzel.org?Subject=RE:%20FAI%20(aka%20'Reality%20Hacking')%20-%20A%20list%20of%20all%20my%20proposed%20guesses%20(aka%20'hacks')">ben@goertzel.org</a>&gt; wrote:
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; This is a substantive hypothesis. Here's why
</em><br>
<em>&gt; I disagree with it.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Let I(P) = the best way to solve problem P
</em><br>
<em>&gt; given infinite computing power.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Let L(P) = the best way to solve problem P
</em><br>
<em>&gt; given limited computing
</em><br>
<em>&gt; &gt; power; for the sake of definiteness, say a
</em><br>
<em>&gt; nanotech supercomputer,
</em><br>
<em>&gt; &gt; which is the most we can plausibly hope to
</em><br>
<em>&gt; get our hands on in the
</em><br>
<em>&gt; &gt; foreseeable future.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Sure, but let's introduce a different notation
</em><br>
<em>&gt; 
</em><br>
<em>&gt; L(P,x) = the best way to solve P given
</em><br>
<em>&gt; computing power x
</em><br>
<em>&gt; 
</em><br>
<em>&gt; We know that
</em><br>
<em>&gt; 
</em><br>
<em>&gt; L(P,infinity) = AIXI or some variant
</em><br>
<em>&gt; 
</em><br>
<em>&gt; L(P, human brain power) = something with no
</em><br>
<em>&gt; resemblance to AIXI
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It's really an open question what
</em><br>
<em>&gt; 
</em><br>
<em>&gt; L(P, nanotech supercomputer) = ???
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Probably it will have aspects of AIXI and
</em><br>
<em>&gt; aspects of brain-ish architecture,
</em><br>
<em>&gt; and some entirely different aspects as well.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; We have candidates for (or at least plausible
</em><br>
<em>&gt; steps in the direction
</em><br>
<em>&gt; &gt; of) I(real life); AIXI et al. And we note
</em><br>
<em>&gt; that some formulations of
</em><br>
<em>&gt; &gt; these do, as Marc conjectures, relate to
</em><br>
<em>&gt; Chaitin's omega. But as I
</em><br>
<em>&gt; &gt; remarked in a previous discussion a little
</em><br>
<em>&gt; while ago, there are good
</em><br>
<em>&gt; &gt; reasons AIXI is PDFware rather than running
</em><br>
<em>&gt; code.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The mixture of references to Chaitin's omega
</em><br>
<em>&gt; number and Tipler's Omega Point
</em><br>
<em>&gt; is a bit confusing, no?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -- Ben
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
I've read recently (and I'm sorry to say I can't
<br>
remember where) that researchers think the amount
<br>
of information processing that has gone on in the
<br>
universe is close to the theoretical maximum that
<br>
it could have done. If this pie cannot be
<br>
enlarged, it follows that all an AI can do is
<br>
'make the universe more efficient' by
<br>
reallocating much of the available energy/matter
<br>
to whatever information processing best serves
<br>
its supergoals. Assuming no net increase in the
<br>
info-processing overhead in this universe, it's
<br>
ultimately a zero-sum game.
<br>
<p>Four or five years ago, I was *very* interested
<br>
in the Tipler version of the Omega Point (recall
<br>
that it was Teilhard de Chardin who coined the
<br>
phrase).
<br>
<p>However, as I have previously noted, our Hubble
<br>
volume is flat and expanding. The
<br>
controlled-collapse free lunch is *out*. I take
<br>
no pleasure in saying this. Some other free lunch
<br>
may yet be discovered, and that wouldn't surprise
<br>
me either, but right now there's no truly
<br>
infinite source of time, matter, energy,
<br>
processing power, or even candy corn. That we
<br>
know of.
<br>
<p>What does this tell me in terms of 'moving toward
<br>
the Omega Point'? That this goal is worthy, but
<br>
it can comfortably stay on the back-burner, for a
<br>
billion years. The universe will still be
<br>
youngish. More pressing by far is preserving the
<br>
human race in good condition until further
<br>
notice. It may be that the Omega Point as Tipler
<br>
speaks of it (infinite processing for
<br>
subjectively infinite time without eternal-return
<br>
loops, without a heat death, for ever and ever)
<br>
is simply not possible.
<br>
<p>Since the Tipler Omega Point is a pig-in-a-poke,
<br>
a promissory note with no collateral, it must not
<br>
be an excuse for shorter-term UnFriendliness.
<br>
<p>And perhaps it will be found to be possible. But
<br>
if it is, it's not a problem for today.
<br>
<p>If Marc Geddes means some weaker version of Omega
<br>
Point, let's say 'vast info-processing and a
<br>
digital Heaven for all possible humans living and
<br>
dead, until the energy runs out and we all die
<br>
again' then this is not a bad plan, but
<br>
Collective Volition might have other ideas
<br>
(especially if all possible humans is too much
<br>
for the vast but not truly infinite processing
<br>
available).
<br>
<p>Tom Buckner
<br>
<p><p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
__________________________________ 
<br>
Do you Yahoo!? 
<br>
Yahoo! Mail - You care about security. So do we. 
<br>
<a href="http://promotions.yahoo.com/new_mail">http://promotions.yahoo.com/new_mail</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10701.html">Aaron McBride: "Re: Pocket Guide to the Singularity"</a>
<li><strong>Previous message:</strong> <a href="10699.html">maru: "Re: FAI (aka 'Reality Hacking') - A list of all my proposed guesses (aka 'hacks')"</a>
<li><strong>In reply to:</strong> <a href="10685.html">Ben Goertzel: "RE: FAI (aka 'Reality Hacking') - A list of all my proposed guesses (aka 'hacks')"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10734.html">Phil Goetz: "Computational power (was RE: FAI (aka 'Reality Hacking'))"</a>
<li><strong>Reply:</strong> <a href="10734.html">Phil Goetz: "Computational power (was RE: FAI (aka 'Reality Hacking'))"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10700">[ date ]</a>
<a href="index.html#10700">[ thread ]</a>
<a href="subject.html#10700">[ subject ]</a>
<a href="author.html#10700">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
