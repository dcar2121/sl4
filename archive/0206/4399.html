<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: How hard a Singularity?</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: How hard a Singularity?">
<meta name="Date" content="2002-06-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: How hard a Singularity?</h1>
<!-- received="Wed Jun 26 18:10:17 2002" -->
<!-- isoreceived="20020627001017" -->
<!-- sent="Wed, 26 Jun 2002 14:56:22 -0700" -->
<!-- isosent="20020626215622" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: How hard a Singularity?" -->
<!-- id="3D1A3886.8040201@objectent.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="4.3.2.7.2.20020626132515.01c16430@mail.earthlink.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20How%20hard%20a%20Singularity?"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Wed Jun 26 2002 - 15:56:22 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4400.html">James Higgins: "Friendly AI meme and SL4 subscribers"</a>
<li><strong>Previous message:</strong> <a href="4398.html">James Higgins: "Re: FAI and SIAI as dangerous"</a>
<li><strong>In reply to:</strong> <a href="4394.html">James Higgins: "Re: How hard a Singularity?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4402.html">Eliezer S. Yudkowsky: "Re: How hard a Singularity?"</a>
<li><strong>Reply:</strong> <a href="4402.html">Eliezer S. Yudkowsky: "Re: How hard a Singularity?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4399">[ date ]</a>
<a href="index.html#4399">[ thread ]</a>
<a href="subject.html#4399">[ subject ]</a>
<a href="author.html#4399">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
James Higgins wrote:
<br>
<em>&gt; At 03:59 PM 6/26/2002 -0400, Eliezer S. Yudkowsky wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt; James Higgins wrote:
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; Actually, I was thinking about this earlier, glad you asked.
</em><br>
<em>&gt;&gt;&gt; I think the best solution would be to assemble a board of maybe 10 
</em><br>
<em>&gt;&gt;&gt; people.  These people should be intelligent, but not necessarily 
</em><br>
<em>&gt;&gt;&gt; geniuses.  Some should be experts on AI, but not all.  I would say 
</em><br>
<em>&gt;&gt;&gt; the criteria ALL members must posses would be:
</em><br>
<em>&gt;&gt;&gt;         1.  A strong desire to see the Singularity occur
</em><br>
<em>&gt;&gt;&gt;         2.  Strongly value human life and the survival of the human race
</em><br>
<em>&gt;&gt;&gt;         3.  Must be willing and able to accept that a solution, other 
</em><br>
<em>&gt;&gt;&gt; than their own, is a better solution
</em><br>
<em>&gt;&gt;&gt; The deciding body SHOULD NOT have exactly coinciding interest.  They 
</em><br>
<em>&gt;&gt;&gt; should not, under any circumstances, all be working on the same 
</em><br>
<em>&gt;&gt;&gt; project (such as the Singularity Institute).
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; James,
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Do you believe that a committee of experts could be assembled to 
</em><br>
<em>&gt;&gt; successfully build an AI?  Or even to successfully judge which new AI 
</em><br>
<em>&gt;&gt; theories are most likely to succeed?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Do I believe a committee could successfully build an AI?  Maybe.  But I 
</em><br>
<em>&gt; don't think it would be a good idea to do it that way.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt; If not, why would they be able to do it for Friendly AI?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I never said they could, or should, DESIGN anything.  Simply approve 
</em><br>
<em>&gt; designs.  Zoning committees don't build anything, but they are important
</em><br>
<em>&gt; to maintain order in a metropolitan area.  I believe a Singularity 
</em><br>
<em>&gt; Committee (or whatever it should be called - I'd like to avoid the term 
</em><br>
<em>&gt; &quot;committee&quot;) would be a very useful asset to the human race.  
</em><br>
<p>Sorry, but this cannot be made to work.  Committees approving 
<br>
software designs generally simply bog down the process and 
<br>
remove anything truly innovative.  I have experienced this in my 
<br>
over two decades of software architecture/design/implementation 
<br>
experience on software much more mundane and committee 
<br>
understandable than an AI seed could be.  Humans, especially in 
<br>
their aggregated &quot;committee&quot; form, simply don't have remotely 
<br>
the intelligence, creativity or ability to grasp the gestalt 
<br>
that would be required.
<br>
<p><p><p><em>&gt; Although I 
</em><br>
<em>&gt; can see where it could easily be seen as a detriment to will-full, 
</em><br>
<em>&gt; single-minded, solo players or even like minded teams.  Individual 
</em><br>
<em>&gt; accomplishment is irrelevant in light of the Singularity, successful 
</em><br>
<em>&gt; completion of the project in the safest manor possible is the only 
</em><br>
<em>&gt; rational goal.
</em><br>
<em>&gt;
</em><br>
<p>Sorry again, only individuals are relevant when you are 
<br>
considering vastly sophisticated and largely blue sky new 
<br>
software designs.  Those don't come out of anything but 
<br>
individuals.
<br>
<p>- samantha
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4400.html">James Higgins: "Friendly AI meme and SL4 subscribers"</a>
<li><strong>Previous message:</strong> <a href="4398.html">James Higgins: "Re: FAI and SIAI as dangerous"</a>
<li><strong>In reply to:</strong> <a href="4394.html">James Higgins: "Re: How hard a Singularity?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4402.html">Eliezer S. Yudkowsky: "Re: How hard a Singularity?"</a>
<li><strong>Reply:</strong> <a href="4402.html">Eliezer S. Yudkowsky: "Re: How hard a Singularity?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4399">[ date ]</a>
<a href="index.html#4399">[ thread ]</a>
<a href="subject.html#4399">[ subject ]</a>
<a href="author.html#4399">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:39 MDT
</em></small></p>
</body>
</html>
