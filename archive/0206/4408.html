<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: How hard a Singularity?</title>
<meta name="Author" content="James Higgins (jameshiggins@earthlink.net)">
<meta name="Subject" content="RE: How hard a Singularity?">
<meta name="Date" content="2002-06-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: How hard a Singularity?</h1>
<!-- received="Wed Jun 26 19:02:21 2002" -->
<!-- isoreceived="20020627010221" -->
<!-- sent="Wed, 26 Jun 2002 15:51:32 -0700" -->
<!-- isosent="20020626225132" -->
<!-- name="James Higgins" -->
<!-- email="jameshiggins@earthlink.net" -->
<!-- subject="RE: How hard a Singularity?" -->
<!-- id="4.3.2.7.2.20020626153202.01c3d388@mail.earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="LAEGJLOGJIOELPNIOOAJGEMOCLAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Higgins (<a href="mailto:jameshiggins@earthlink.net?Subject=RE:%20How%20hard%20a%20Singularity?"><em>jameshiggins@earthlink.net</em></a>)<br>
<strong>Date:</strong> Wed Jun 26 2002 - 16:51:32 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4409.html">Ben Goertzel: "RE: How hard a Singularity?"</a>
<li><strong>Previous message:</strong> <a href="4407.html">Eliezer S. Yudkowsky: "Re: How hard a Singularity?"</a>
<li><strong>In reply to:</strong> <a href="4404.html">Ben Goertzel: "RE: How hard a Singularity?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4410.html">Ben Goertzel: "RE: How hard a Singularity?"</a>
<li><strong>Reply:</strong> <a href="4410.html">Ben Goertzel: "RE: How hard a Singularity?"</a>
<li><strong>Reply:</strong> <a href="4520.html">Ben Goertzel: "RE: How hard a Singularity?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4408">[ date ]</a>
<a href="index.html#4408">[ thread ]</a>
<a href="subject.html#4408">[ subject ]</a>
<a href="author.html#4408">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
At 04:29 PM 6/26/2002 -0600, Ben Goertzel wrote:
<br>
<em>&gt;Now this conversation gets interesting...
</em><br>
<p>And its making progress...
<br>
<p><em>&gt;James Higgins wrote:
</em><br>
<em>&gt; &gt; The committee is there for RISK MANAGEMENT.  A task which should
</em><br>
<em>&gt; &gt; very much
</em><br>
<em>&gt; &gt; be done thoroughly on such a task as creating a Singularity.  They do not
</em><br>
<em>&gt; &gt; have to, collectively, understand all the inner working of the
</em><br>
<em>&gt; &gt; design.  They simply have to be convinced to a reasonable degree that the
</em><br>
<em>&gt; &gt; design, as a whole, is safe.  There are many such examples of this in
</em><br>
<em>&gt; &gt; present day life, where an entity is responsible for ensuring safety.  If
</em><br>
<em>&gt; &gt; it is impossible for a group of 10 intelligent people to agree that it is
</em><br>
<em>&gt; &gt; safe to launch a Singularity then, frankly, it shouldn't be launched.
</em><br>
<em>&gt;
</em><br>
<em>&gt;James, I can see your heart's in the right place... but, I'm afraid you may
</em><br>
<em>&gt;be overestimating the rationality of humans and human groups...
</em><br>
<p>Maybe so.  [Added after completing the remainder of the email: Don't think 
<br>
so, I think we are at least in the same ballpark]
<br>
<p><em>&gt;What if Bill Joy is on the committee?  He's intelligent....
</em><br>
<p>Obviously the members of the committee would be chosen very carefully.  I 
<br>
don't suggest that it be a public event or that just any person may 
<br>
apply.  Eliezer and yourself would be obvious choices.  Actually, I think 
<br>
if the two of you choose the remaining members I'd be ok with that.  As 
<br>
long as neither of you tried to load the deck and the committee didn't end 
<br>
up filled mostly with people from your two projects, that is.
<br>
<p><em>&gt;The Singularity is a highly emotionally charged issue.  There may be humans
</em><br>
<em>&gt;who are simply emotionally opposed to the Singularity, and unable to
</em><br>
<em>&gt;rationally balance the risk of not going forward vs. the risk of going
</em><br>
<em>&gt;forward.
</em><br>
<p>Ah, which is why I said that members of the committee would: 1) have to 
<br>
WANT (very much) to see the Singularity occur.
<br>
<p><em>&gt; &gt; &gt; The committee
</em><br>
<em>&gt; &gt; &gt;will pick out a set of Asimov Laws designed by Marvin Minsky in
</em><br>
<em>&gt; &gt; accordance
</em><br>
<em>&gt; &gt; &gt;with currently faddish AI principles.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Minsky is a tremendously smart guy -- he's a bit egomaniacal and cussed, but
</em><br>
<em>&gt;he's also basically a techno-optimist without a strong anti-Singularity
</em><br>
<em>&gt;bias.  I have a great respect for him in pretty much all ways.  I think he'd
</em><br>
<em>&gt;be a great choice for such a committee.
</em><br>
<p>I've heard a bit a bout Minsky from another individual I know.  So start 
<br>
the committee off with the three of you.  New members would be added by a 
<br>
2/3 vote of you three.  With a minimum desired membership of at least 5 I'd 
<br>
say.  Maximum to be decided by you three, but I'd say 25 would be way too high.
<br>
<p><em>&gt;My overall reaction to the &quot;committee&quot; idea is as follows.
</em><br>
<em>&gt;
</em><br>
<em>&gt;1) I don't think a governmentally-appointed committee is likely to work, for
</em><br>
<em>&gt;reasons similar to (but milder than) the ones Eliezer states.  Such a
</em><br>
<em>&gt;committee's membership would be formed by &quot;politics as usual,&quot; it would end
</em><br>
<em>&gt;up with a few Joy types on it as well as a few knee-jerk pro-Singularity
</em><br>
<em>&gt;types and some moderates -- and as such it would never reach a consensus on
</em><br>
<em>&gt;anything, ever, though it might lead to some interesting discussions.
</em><br>
<p>For the record, I NEVER thought a government, or even industry, formed 
<br>
committee would or could be effective.  The committee would have to be 
<br>
assembled carefully by people who believe strongly in the Singularity, are 
<br>
intelligent and we know.
<br>
<p><em>&gt;2) I do think that the decision of whether to launch the Singularity is too
</em><br>
<em>&gt;big for any one person, or any one dedicated research team.  For one thing,
</em><br>
<em>&gt;it's just a HUGE decision; for another thing, there will be a tendency for
</em><br>
<em>&gt;any team to want to see their own AI &quot;go all the way&quot; -- an emotional factor
</em><br>
<em>&gt;that will be hard to overcome for anyone, no matter how mature they are.
</em><br>
<p>Which is why, for such a significant event in human history, they should 
<br>
not be the ones to decide.
<br>
<p><em>&gt;Because of factors 1) and 2), I think that whatever individual or group
</em><br>
<em>&gt;reaches near-human-level-AI is going to have to take it upon themselves to
</em><br>
<em>&gt;assemble an advisory board composed of individuals combining reasonable
</em><br>
<em>&gt;technical expertise and reasonable general wisdom.  If I were in this
</em><br>
<em>&gt;position, I would certainly choose Minsky and Kurzweil, for example, but
</em><br>
<em>&gt;probably not Joy (although I can't say for sure, because I don't know him,
</em><br>
<em>&gt;and for all I know his real views might be milder than the ones he expressed
</em><br>
<em>&gt;in his polemical article and associated interviews).  I do know Jaron
</em><br>
<em>&gt;Lanier, who holds Joy-ish views, and who I would *not* choose for my
</em><br>
<em>&gt;committee, because in spite of his intelligence I feel he holds irrationally
</em><br>
<em>&gt;&quot;knee-jerk&quot; anti-Singularity views.  (And, yeah, Ok, I would choose Eliezer
</em><br>
<em>&gt;as well!)
</em><br>
<p>It would be better on the whole to have a single committee if at all 
<br>
possible.  And, yes, I do understand the complications and reasons why this 
<br>
is unlikely to happen.  But that doesn't mean we should not try.  If such a 
<br>
committee were formed I would not have any issues with it being attached to 
<br>
an entity such as the Singularity Institue, as long as most of its members 
<br>
weren't answerable to or involved in their development work.
<br>
<p>Such a committee should be formed and at least made available for other 
<br>
projects to utilize.
<br>
<p><em>&gt;I think that a broader discussion group should *also* be assembled,
</em><br>
<em>&gt;involving the more articulate and rational of the rabid
</em><br>
<em>&gt;anti-Singularitarians (Joy, Lanier, etc.) as well as pro-technology people.
</em><br>
<em>&gt;This committee should be assembled in order to gather its opinions only,
</em><br>
<em>&gt;without a view toward decision-making.
</em><br>
<p>An excellent idea.
<br>
<p><em>&gt;Government is not going to solve this problem.  And I say this as someone
</em><br>
<em>&gt;with fairly democratic-socialist tendencies, not as a typical extropian
</em><br>
<em>&gt;libertarian.  If government tries to manage the Singularity, it's just going
</em><br>
<em>&gt;to drive real Singularity development work underground or overseas.  The
</em><br>
<em>&gt;problem has to be solved by maturity and responsibility on the part of the
</em><br>
<em>&gt;people doing the development, I feel.  This is scary, but to me, it's less
</em><br>
<em>&gt;scary than thinking about the government handling something of such
</em><br>
<em>&gt;importance....  While it's true that gov't is generally good at halting
</em><br>
<em>&gt;action from occurring, by bogging it down in endless bureaucracy, gov't's
</em><br>
<em>&gt;have also been responsible for a hell of a lot of fanatically unwise
</em><br>
<em>&gt;actions -- governmental involvement is far from a prescription for wisdom!!
</em><br>
<p>I don't believe there is ANY POSSIBILITY that government could positively 
<br>
contribute to this problem, much less solve it.  I don't even want them to 
<br>
try, even by providing grants (since money always has strings attached).
<br>
<p>James Higgins
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4409.html">Ben Goertzel: "RE: How hard a Singularity?"</a>
<li><strong>Previous message:</strong> <a href="4407.html">Eliezer S. Yudkowsky: "Re: How hard a Singularity?"</a>
<li><strong>In reply to:</strong> <a href="4404.html">Ben Goertzel: "RE: How hard a Singularity?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4410.html">Ben Goertzel: "RE: How hard a Singularity?"</a>
<li><strong>Reply:</strong> <a href="4410.html">Ben Goertzel: "RE: How hard a Singularity?"</a>
<li><strong>Reply:</strong> <a href="4520.html">Ben Goertzel: "RE: How hard a Singularity?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4408">[ date ]</a>
<a href="index.html#4408">[ thread ]</a>
<a href="subject.html#4408">[ subject ]</a>
<a href="author.html#4408">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:39 MDT
</em></small></p>
</body>
</html>
