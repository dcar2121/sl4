<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Books on rationality</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Books on rationality">
<meta name="Date" content="2002-06-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Books on rationality</h1>
<!-- received="Fri Jun 07 13:08:18 2002" -->
<!-- isoreceived="20020607190818" -->
<!-- sent="Fri, 7 Jun 2002 11:09:18 -0600" -->
<!-- isosent="20020607170918" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Books on rationality" -->
<!-- id="LAEGJLOGJIOELPNIOOAJGEDJCKAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="JEEOJKGAIKFKEHJONHMPOEJFDFAA.lcorbin@tsoft.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Books%20on%20rationality"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Fri Jun 07 2002 - 11:09:18 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3913.html">Mike & Donna Deering: "Re: Books on rationality"</a>
<li><strong>Previous message:</strong> <a href="3911.html">Lee Corbin: "RE: Books on rationality"</a>
<li><strong>In reply to:</strong> <a href="3911.html">Lee Corbin: "RE: Books on rationality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3918.html">Eliezer S. Yudkowsky: "Re: Books on rationality"</a>
<li><strong>Reply:</strong> <a href="3918.html">Eliezer S. Yudkowsky: "Re: Books on rationality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3912">[ date ]</a>
<a href="index.html#3912">[ thread ]</a>
<a href="subject.html#3912">[ subject ]</a>
<a href="author.html#3912">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; &quot;Words are like ball-bearings on a skating rink:
</em><br>
<em>&gt; to get anywhere, tread lightly and avoid putting
</em><br>
<em>&gt; too much weight on any one of them.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; The easy part:  adopting the truth of that prescription
</em><br>
<em>&gt; and seeing how in the recent discussion several people
</em><br>
<em>&gt; we'd always describe as &quot;quite rational&quot; scarcely knew
</em><br>
<em>&gt; what they meant by the term.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The hard part:  getting somewhere, especially in software,
</em><br>
<em>&gt; I suppose, without heavy reliance on hard and well-defined
</em><br>
<em>&gt; concepts.  (I'm confident from what I've read, however,
</em><br>
<em>&gt; that no one is likely to be doing a better job than some
</em><br>
<em>&gt; of the savants on this list.)
</em><br>
<p>It's true.  I re-read Wittgenstein recently and was newly impressed by his
<br>
discussion of &quot;language-games&quot;, i.e. of the fact that &quot;word meanings&quot; are
<br>
just conventions of social discourse and rarely capture any truly &quot;natural&quot;
<br>
or &quot;absolutely meaningful&quot; concept.
<br>
<p>In this view, debates over the real meaning of truth, beauty, rationality,
<br>
etc. are not terribly useful.  There are going to be many overlapping
<br>
conceptions of such things, and the human language term is going to be a
<br>
fuzzy mixed-up combination of them (furthermore a combination that shifts
<br>
over time).
<br>
<p>My approach in my own work has been to create relatively precise definitions
<br>
of concepts like &quot;intelligence&quot;, &quot;mind&quot; and &quot;reason&quot; -- without claiming
<br>
that these capture some kind of ultimate essential concept and are thus
<br>
better than alternative definitions.  More in the mathematician's mindset,
<br>
where first you make your definitions and then you do some work relying on
<br>
them.  e.g., is intelligence &quot;really&quot; captured in my def'n &quot;Achieving
<br>
complex goals in complex environments&quot;?  I don't know what this means,
<br>
because I don't have access to the space of Platonically Ideal Correct
<br>
Definitions of concepts like intelligence.  All I know is that when I make a
<br>
definition, at least I know what I'm talking about reasonably well ;&gt;
<br>
<p>So, yeah, debating what rationality really is, is useless.  What's valuable
<br>
is to make a reasonably crisp definition of rationality, explain it, give
<br>
examples, and then give guidance as to how to achieve it for those who are
<br>
interested.  I guess that is what Gordon plans.
<br>
<p>One thing the recent discussion uncovered, is that Gordon's notion of
<br>
rationality made more assumptions about the mind's underlying goals than my
<br>
own notion of rationality.  My notion of rationality is, basically:
<br>
<p>***
<br>
A system X is rational *relative to a system Y* if
<br>
<p>-- the conclusions it draws are (in Y's judgment) about as accurate as
<br>
possible given the constraints on X's cognitive abilities
<br>
<p>A corollary of rationality is that, if a system has explicitly stated goals,
<br>
it should draw accurate conclusions (within the limits of its abilities)
<br>
about how likely its actions are to help it achieve its goals, and about how
<br>
its short-term goals relate to its long term goals
<br>
***
<br>
<p>Often, in judging whether a human X is rational or not, we assume that the
<br>
judging entity Y is a kind of composite consensus-reality cultural belief
<br>
system.
<br>
<p>To make an objective definition of rationality, one has to assume one knows
<br>
the answers, e.g. one can postulate a judging system Y that makes perfect
<br>
probabilistic judgments based on the available evidence (though one can
<br>
never actually build such a system).
<br>
<p>It is worth remembering, however, that we are not this perfect reasoning
<br>
system Y, ergo when we judge X to be irrational, we are doing so only
<br>
relative to our own judgmental ability, which may be flawed.
<br>
<p>I do not think that my definition of &quot;rational&quot; (loosely given above)
<br>
captures the full natural language concept of rationality.  Natural language
<br>
concepts can almost never be captured in crisp definitions.  My definition
<br>
is useful for me, perhaps useful to others, and that's enough :&gt;
<br>
<p>Note that my definition does NOT specify that a system must have any
<br>
particular goals to be rational.  In my definition, an evil serial killer
<br>
could be rational if, given his emotionally determined goals, he drew
<br>
accurate conclusions about how to achieve them.  This seems in line with
<br>
common usage of the term, where we have the notion of the &quot;cold-blooded
<br>
calculating killer&quot; ....
<br>
<p><p><p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3913.html">Mike & Donna Deering: "Re: Books on rationality"</a>
<li><strong>Previous message:</strong> <a href="3911.html">Lee Corbin: "RE: Books on rationality"</a>
<li><strong>In reply to:</strong> <a href="3911.html">Lee Corbin: "RE: Books on rationality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3918.html">Eliezer S. Yudkowsky: "Re: Books on rationality"</a>
<li><strong>Reply:</strong> <a href="3918.html">Eliezer S. Yudkowsky: "Re: Books on rationality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3912">[ date ]</a>
<a href="index.html#3912">[ thread ]</a>
<a href="subject.html#3912">[ subject ]</a>
<a href="author.html#3912">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:39 MDT
</em></small></p>
</body>
</html>
