<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: How hard a Singularity?</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: How hard a Singularity?">
<meta name="Date" content="2002-06-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: How hard a Singularity?</h1>
<!-- received="Sat Jun 22 13:12:26 2002" -->
<!-- isoreceived="20020622191226" -->
<!-- sent="Sat, 22 Jun 2002 11:17:01 -0600" -->
<!-- isosent="20020622171701" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: How hard a Singularity?" -->
<!-- id="LAEGJLOGJIOELPNIOOAJGEEECLAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3D1450D3.7070505@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20How%20hard%20a%20Singularity?"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sat Jun 22 2002 - 11:17:01 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4135.html">Brian Atkins: "Re: How hard a Singularity?"</a>
<li><strong>Previous message:</strong> <a href="4133.html">Michael Roy Ames: "Re: How hard a Singularity?"</a>
<li><strong>In reply to:</strong> <a href="4129.html">Eliezer S. Yudkowsky: "Re: How hard a Singularity?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4136.html">Eliezer S. Yudkowsky: "Re: How hard a Singularity?"</a>
<li><strong>Reply:</strong> <a href="4136.html">Eliezer S. Yudkowsky: "Re: How hard a Singularity?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4134">[ date ]</a>
<a href="index.html#4134">[ thread ]</a>
<a href="subject.html#4134">[ subject ]</a>
<a href="author.html#4134">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;  &gt; While I also believe that the fast Singularity is a distinct
</em><br>
<em>&gt; possibility,
</em><br>
<em>&gt;  &gt;  I don't have an intuition which would help me decide which variant is
</em><br>
<em>&gt;  &gt; more likely and by what odds.
</em><br>
<em>&gt;  &gt;
</em><br>
<em>&gt;  &gt; What is your intuition? Is it a toss-up, a good hunch, or (almost)dead
</em><br>
<em>&gt;  &gt; certainty?
</em><br>
<em>&gt;
</em><br>
<em>&gt; I would call it dead certain in favor of a hard takeoff, unless all the
</em><br>
<em>&gt; intelligences at the core of that hard takeoff unanimously decide
</em><br>
<em>&gt; otherwise.
</em><br>
<em>&gt;   All economic, computational, and, as far as I can tell, moral indicators
</em><br>
<em>&gt; point straight toward a hard takeoff.  The Singularity involves
</em><br>
<em>&gt; an inherent
</em><br>
<em>&gt; positive feedback loop; smart minds produce smarter minds which produce
</em><br>
<em>&gt; still smarter minds and so on.
</em><br>
<p>Eliezer, while we're all free to our own differing intuitions, it seems
<br>
wrong to me to can feel &quot;dead certain&quot; about something we've never seen
<br>
before, that depends on technologies we don't yet substantialy understand.
<br>
<p>I think the period of transition from human-level AI to superhuman-level AI
<br>
will be a matter of months to years, not decades.
<br>
<p>What particular transformative effects the presence of superhuman-level AI
<br>
will have, and in what order, is pretty hard to say, huh?
<br>
<p>Perhaps for a while, a superhuman AI among humans will be like a human among
<br>
dogs.  A human among dogs *does* have a different and deeper understanding,
<br>
and can do things no dog can do, including many things revolutionizing dogly
<br>
existence ... but still, a human among dogs is not a god.  How long might a
<br>
phase like this last?  Hard to say.
<br>
<p>Moravec-and-Kurzweil-style curve-plotting is interesting and important, but
<br>
nevertheless, the problem of induction remains... .  All sorts of things
<br>
could happen.  For instance, the superhuman AI's we build may continue to
<br>
progress exponentially, but in directions other than those we foresee now.
<br>
<p>In short, as I keep repeating, one of the unknown things about our coming
<br>
plunge into the Great Unknown, is how rapidly the plunge will occur, and the
<br>
trajectory that the plunge will follow.   Dead certainty on these points
<br>
seems inappropriate to me.
<br>
<p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4135.html">Brian Atkins: "Re: How hard a Singularity?"</a>
<li><strong>Previous message:</strong> <a href="4133.html">Michael Roy Ames: "Re: How hard a Singularity?"</a>
<li><strong>In reply to:</strong> <a href="4129.html">Eliezer S. Yudkowsky: "Re: How hard a Singularity?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4136.html">Eliezer S. Yudkowsky: "Re: How hard a Singularity?"</a>
<li><strong>Reply:</strong> <a href="4136.html">Eliezer S. Yudkowsky: "Re: How hard a Singularity?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4134">[ date ]</a>
<a href="index.html#4134">[ thread ]</a>
<a href="subject.html#4134">[ subject ]</a>
<a href="author.html#4134">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:39 MDT
</em></small></p>
</body>
</html>
