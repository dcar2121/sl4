<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: FAI means no programmer-sensitive AI morality</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: FAI means no programmer-sensitive AI morality">
<meta name="Date" content="2002-06-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: FAI means no programmer-sensitive AI morality</h1>
<!-- received="Sun Jun 30 00:48:20 2002" -->
<!-- isoreceived="20020630064820" -->
<!-- sent="Sat, 29 Jun 2002 21:50:42 -0700" -->
<!-- isosent="20020630045042" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: FAI means no programmer-sensitive AI morality" -->
<!-- id="3D1E8E22.7020901@objectent.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3D1DD20E.6070009@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20FAI%20means%20no%20programmer-sensitive%20AI%20morality"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Sat Jun 29 2002 - 22:50:42 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4583.html">Eliezer S. Yudkowsky: "Re: FAI means no programmer-sensitive AI morality"</a>
<li><strong>Previous message:</strong> <a href="4581.html">Ben Goertzel: "RE: FAI means no programmer-sensitive AI morality"</a>
<li><strong>In reply to:</strong> <a href="4552.html">Eliezer S. Yudkowsky: "Re: FAI means no programmer-sensitive AI morality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4586.html">Ben Goertzel: "RE: FAI means no programmer-sensitive AI morality"</a>
<li><strong>Reply:</strong> <a href="4586.html">Ben Goertzel: "RE: FAI means no programmer-sensitive AI morality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4582">[ date ]</a>
<a href="index.html#4582">[ thread ]</a>
<a href="subject.html#4582">[ subject ]</a>
<a href="author.html#4582">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eliezer S. Yudkowsky wrote:
<br>
<em> &gt; Ben Goertzel wrote:
</em><br>
<em> &gt;
</em><br>
<em> &gt; Rationality, and/or the correspondence theory of truth, is a 
</em><br>
modern-day
<br>
<em> &gt; scientific philosophy.  It is also, in somewhat different and 
</em><br>
admittedly
<br>
<em> &gt; lesser form, an innate human intuition.  The vast majority of 
</em><br>
religious
<br>
<em> &gt; people, especially what we would call &quot;fundamentalists&quot; and 
</em><br>
those
<br>
<em> &gt; outside the First World, adhere to a correspondence theory of 
</em><br>
the truth
<br>
<em> &gt; of their religion; when they say something is true, they mean 
</em><br>
that it is
<br>
<em> &gt; so; that outside reality corresponds to their belief.
</em><br>
<em> &gt;
</em><br>
<p>Correspondence theory leaves wide open how you know what is
<br>
real, whether only external sensory derived things are included
<br>
in the real and so on.  Even with those things nailed down it is
<br>
by no means clear that correspondence between internal models
<br>
and perceived external reality is a full and adequate
<br>
justification for saying that those models are &quot;true&quot;. The
<br>
phrase &quot;scientific philosophy&quot; does not parse well and is not
<br>
full recommended or justified by simply mentioning the
<br>
correspondence theory of truth. Thorwing in &quot;innate human
<br>
intuition&quot; does not exactly strengthen the case you seem to be
<br>
presenting.  I doubt very much that you can then stretch the
<br>
sketchily laid out &quot;correspondence theory of truth&quot; to how some
<br>
religious people hold their religion.  In point of fact, many
<br>
religious people hold that the most salient facts of reality are
<br>
actually inherently unknowable by human minds, at least in any 
<br>
normal state of consciousness.  That is way  different from 
<br>
holding to a correspondence theory of truth
<br>
regarding what they believe.
<br>
<p><p><em> &gt; There are some First World theologians who have, after 
</em><br>
repeated defeats
<br>
<em> &gt; by science and rationality, generalized and begun 
</em><br>
constructing elaborate
<br>
<em> &gt; philosophies in an effort to evade disproof and deprecate the 
</em><br>
value of
<br>
<em> &gt; evidence.  They don't have the ability to actually do it. 
</em><br>
Every human
<br>
<p>Much more elaboarate religious philosophies existed in the Far
<br>
East thousands of years before these purported constructions
<br>
that you claim as defense against science and rationality.
<br>
Western theology generally lags behind.
<br>
<p><p><em> &gt; uses the correspondence theory of truth innately, 
</em><br>
ubiquitously, and
<br>
<em> &gt; without conscious awareness, regardless of what other 
</em><br>
arational forms of
<br>
<em> &gt; support are also invoked and regardless of what verbal 
</em><br>
philosophies are
<br>
<em> &gt; constructed on top.
</em><br>
<p>This is an assertion. I don't quite see its relevance.
<br>
<p><em> &gt; If you think of theories as being made up of
</em><br>
<em> &gt; different kinds of perceived support, including rationality 
</em><br>
atoms, drama
<br>
<em> &gt; atoms, and so on, then humans instinctively construct 
</em><br>
theories using all
<br>
<em> &gt; available forms of support.  A verbal commitment to 
</em><br>
rationality does not
<br>
<em> &gt; automatically rid your theories of drama atoms and 
</em><br>
rationalization atoms
<br>
<em> &gt; and social-approval atoms and so on.  A verbal commitment 
</em><br>
*against*
<br>
<em> &gt; rationality does not automatically rid your theories of 
</em><br>
rationality
<br>
<em> &gt; atoms.  Humans are storytellers and instinctively tell 
</em><br>
stories using all
<br>
<em> &gt; available support, including rational support, dramatic 
</em><br>
support, and so
<br>
<em> &gt; on.  If some First World theologians like to believe their 
</em><br>
theories are
<br>
<em> &gt; &quot;outside rationality&quot; they may be able to fool themselves, 
</em><br>
but they can
<br>
<em> &gt; no more tell stories without invoking the correspondence 
</em><br>
theory of truth
<br>
<em> &gt; than they can spread wings and fly.
</em><br>
<em> &gt;
</em><br>
<p>Since you haven't really well defined what rationality is it is
<br>
difficult to respond to this statement.  But if you think all
<br>
there is is what can be grasped by science and that rationality
<br>
consists only of one's mental constructs corresponding to what
<br>
can be known of this set through science, then many would differ
<br>
with you.  There is no need to simply tell stories in religion 
<br>
except as &quot;fingers pointing toward the moon&quot; when it comes to
<br>
spirituality.  The stories are no more the reality than the
<br>
fingers are the moon.  And that my friend is far different from
<br>
the limited little coral you seem to be herding religion or at 
<br>
least certain types of religious people into.  Now I certainly 
<br>
agree that many theologians and ministers are foolish enough as 
<br>
to claim the finger is the moon.
<br>
<p>- samantha
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4583.html">Eliezer S. Yudkowsky: "Re: FAI means no programmer-sensitive AI morality"</a>
<li><strong>Previous message:</strong> <a href="4581.html">Ben Goertzel: "RE: FAI means no programmer-sensitive AI morality"</a>
<li><strong>In reply to:</strong> <a href="4552.html">Eliezer S. Yudkowsky: "Re: FAI means no programmer-sensitive AI morality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4586.html">Ben Goertzel: "RE: FAI means no programmer-sensitive AI morality"</a>
<li><strong>Reply:</strong> <a href="4586.html">Ben Goertzel: "RE: FAI means no programmer-sensitive AI morality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4582">[ date ]</a>
<a href="index.html#4582">[ thread ]</a>
<a href="subject.html#4582">[ subject ]</a>
<a href="author.html#4582">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:40 MDT
</em></small></p>
</body>
</html>
