<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Friendly AI koans</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Friendly AI koans">
<meta name="Date" content="2002-06-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Friendly AI koans</h1>
<!-- received="Wed Jun 26 13:11:45 2002" -->
<!-- isoreceived="20020626191145" -->
<!-- sent="Wed, 26 Jun 2002 13:11:11 -0400" -->
<!-- isosent="20020626171111" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Friendly AI koans" -->
<!-- id="3D19F5AF.2020909@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Friendly%20AI%20koans"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Wed Jun 26 2002 - 11:11:11 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4377.html">Michael Roy Ames: "Re: Self-modifying FAI (was: How hard a Singularity?)"</a>
<li><strong>Previous message:</strong> <a href="4375.html">Eliezer S. Yudkowsky: "Re: Self-modifying FAI (was: How hard a Singularity?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4390.html">James Higgins: "Re: Friendly AI koans"</a>
<li><strong>Reply:</strong> <a href="4390.html">James Higgins: "Re: Friendly AI koans"</a>
<li><strong>Maybe reply:</strong> <a href="../0207/4811.html">Justin Corwin: "Re: Friendly AI koans"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4376">[ date ]</a>
<a href="index.html#4376">[ thread ]</a>
<a href="subject.html#4376">[ subject ]</a>
<a href="author.html#4376">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
1.  You're designing a Friendship system.  You think you know how to 
<br>
transfer over the contents of your own moral philosophy over, but you can't 
<br>
for the life of you think of any way to even begin to construct a moral 
<br>
philosophy that could legitimately be said to belong to &quot;humanity&quot; and not 
<br>
just you.  Others have repeatedly demanded this of you and you think they 
<br>
are completely justified in doing so.  What do you do?
<br>
<p>2.  You didn't think of the idea of probabilistic supergoals when you were 
<br>
designing the Friendship system.  Instead your AI has a set of &quot;real&quot; 
<br>
supergoals of priority 10, and one meta-supergoal of priority 1000 that says 
<br>
to change the &quot;real&quot; supergoals to whatever the programmer says they should 
<br>
be.  At some point you want to tweak the meta-supergoal, but you find that 
<br>
the AI has deleted the controls which would allow this, because the physical 
<br>
event of any change whatever to the meta-supergoal is predicted to lead to 
<br>
suboptimal fulfillment of the AI's current maximum-priority goal.  If you 
<br>
want a case like this to be recoverable by argument with the AI rather than 
<br>
direct tampering with the goal system, what does the AI need to know - what 
<br>
arguments does the AI need to perceive as valid - in order to be argued out 
<br>
of its blind spot?
<br>
<p>3.  Someone offers a goal system in which sensory feedback at various levels 
<br>
of control - from &quot;pain&quot; at the physical level to &quot;shame&quot; at the top 
<br>
&quot;conscience&quot; level - acts as negative and positive feedback on a 
<br>
hierarchical set of control schema, sculpting them into the form that 
<br>
minimizes negative and maximizes positive feedback.  Given that both systems 
<br>
involve the stabilization of cognitive content by external feedback, what is 
<br>
the critical difference between this architecture and the &quot;external 
<br>
reference semantics&quot; in Friendly AI?  How and why will the architecture fail?
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4377.html">Michael Roy Ames: "Re: Self-modifying FAI (was: How hard a Singularity?)"</a>
<li><strong>Previous message:</strong> <a href="4375.html">Eliezer S. Yudkowsky: "Re: Self-modifying FAI (was: How hard a Singularity?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4390.html">James Higgins: "Re: Friendly AI koans"</a>
<li><strong>Reply:</strong> <a href="4390.html">James Higgins: "Re: Friendly AI koans"</a>
<li><strong>Maybe reply:</strong> <a href="../0207/4811.html">Justin Corwin: "Re: Friendly AI koans"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4376">[ date ]</a>
<a href="index.html#4376">[ thread ]</a>
<a href="subject.html#4376">[ subject ]</a>
<a href="author.html#4376">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:39 MDT
</em></small></p>
</body>
</html>
