<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Military Friendly AI</title>
<meta name="Author" content="Smigrodzki, Rafal (SmigrodzkiR@msx.upmc.edu)">
<meta name="Subject" content="RE: Military Friendly AI">
<meta name="Date" content="2002-06-27">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Military Friendly AI</h1>
<!-- received="Thu Jun 27 19:01:53 2002" -->
<!-- isoreceived="20020628010153" -->
<!-- sent="Thu, 27 Jun 2002 18:45:38 -0400" -->
<!-- isosent="20020627224538" -->
<!-- name="Smigrodzki, Rafal" -->
<!-- email="SmigrodzkiR@msx.upmc.edu" -->
<!-- subject="RE: Military Friendly AI" -->
<!-- id="EB5DDEEFC7B4D411AD3B00508BDFF3E206A852B1@1upmc-msx7.isdip.upmc.edu" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="Military Friendly AI" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Smigrodzki, Rafal (<a href="mailto:SmigrodzkiR@msx.upmc.edu?Subject=RE:%20Military%20Friendly%20AI"><em>SmigrodzkiR@msx.upmc.edu</em></a>)<br>
<strong>Date:</strong> Thu Jun 27 2002 - 16:45:38 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4479.html">Smigrodzki, Rafal: "RE: Who will launch the Singularity?"</a>
<li><strong>Previous message:</strong> <a href="4477.html">Eliezer S. Yudkowsky: "Re: Military Friendly AI"</a>
<li><strong>Maybe in reply to:</strong> <a href="4447.html">Eliezer S. Yudkowsky: "Military Friendly AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4509.html">James Higgins: "Re: Military Friendly AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4478">[ date ]</a>
<a href="index.html#4478">[ thread ]</a>
<a href="subject.html#4478">[ subject ]</a>
<a href="author.html#4478">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&nbsp;Eliezer S. Yudkowsky [mailto:<a href="mailto:sentience@pobox.com?Subject=RE:%20Military%20Friendly%20AI">sentience@pobox.com</a>] wrote:
<br>
<p>Sure, when the AI is young.  When the AI grows up I would expect it to rerun
<br>
<p>the programmers perceived considerations involved in their moral decisions, 
<br>
come to the conclusion that violent solutions were not as desirable as it 
<br>
was told (assuming the &quot;honorable soldiers&quot; are not actually correct!), 
<br>
models its own growth for biases that could have been introduced, and washes
<br>
<p>out the biases.  Of course a Friendly AI has to be able to do this once it 
<br>
grows up!  It's not just a military question!
<br>
<p>### Do you expect that the search for the external referent *must* yield a
<br>
single structure? As Ben mentioned, associations and rules-of-thumb will
<br>
play a role in the decision making, since an &quot;ab initio&quot; modeling of the
<br>
programers, and the basis of their ethical convictions is likely to be
<br>
impossible to directly ascertain. So the individual AI's experience will
<br>
have lasting effects on its behavior, not correctable by analysis of the
<br>
past, requiring experimental verifications (actually doing something and
<br>
observing the long-term effects). Maybe if the experiment goes on for a long
<br>
time, the AI will finally reach the objectively defined Friendliness but
<br>
this is not likely to happen in an environment complicated by competing
<br>
AI's. Instead ve could end up in a limbo not subjectively (AI-level)
<br>
distinguishable from true Friendliness.
<br>
<p>Say, the FAI is informed by the other AI's (during mortal combat) that vis
<br>
empirical data ve used to derive vis current practical implementation of
<br>
Friendly behavior, is untrustworthy. The other AI's provide plausible but
<br>
not fully verifiable explanations. Will the FAI change its Friendliness?
<br>
Will ve trust the others or vis own commanding ethics officer? How will ve
<br>
deal with uncertainty at a level much higher than the analysis of human
<br>
motivations - at the level of other SAI's?
<br>
<p>-------
<br>
<em>&gt; As you later say, the growing up of the infant AI might be unfavorably 
</em><br>
<em>&gt; affected, in the distant analogy to the detrimental effects of early 
</em><br>
<em>&gt; childhood emotional trauma in humans.
</em><br>
<p>This is an appealing analogy which happens to be, as best I can tell, 
<br>
completely wrong.
<br>
<p>### Yes, it's just a little eristics trick of mine, an appealing analogy of
<br>
no intrinsic truth value.
<br>
<p>Rafal
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4479.html">Smigrodzki, Rafal: "RE: Who will launch the Singularity?"</a>
<li><strong>Previous message:</strong> <a href="4477.html">Eliezer S. Yudkowsky: "Re: Military Friendly AI"</a>
<li><strong>Maybe in reply to:</strong> <a href="4447.html">Eliezer S. Yudkowsky: "Military Friendly AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4509.html">James Higgins: "Re: Military Friendly AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4478">[ date ]</a>
<a href="index.html#4478">[ thread ]</a>
<a href="subject.html#4478">[ subject ]</a>
<a href="author.html#4478">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:39 MDT
</em></small></p>
</body>
</html>
