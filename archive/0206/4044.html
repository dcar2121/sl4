<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: QUES: CFAI</title>
<meta name="Author" content="Anand AI (trans_humanism@msn.com)">
<meta name="Subject" content="Re: QUES: CFAI">
<meta name="Date" content="2002-06-16">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: QUES: CFAI</h1>
<!-- received="Sun Jun 16 21:20:11 2002" -->
<!-- isoreceived="20020617032011" -->
<!-- sent="Sun, 16 Jun 2002 17:32:05 -0500" -->
<!-- isosent="20020616223205" -->
<!-- name="Anand AI" -->
<!-- email="trans_humanism@msn.com" -->
<!-- subject="Re: QUES: CFAI" -->
<!-- id="F39ixMwInhdAHxNzFiP00008fb5@hotmail.com" -->
<!-- inreplyto="QUES: CFAI" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Anand AI (<a href="mailto:trans_humanism@msn.com?Subject=Re:%20QUES:%20CFAI"><em>trans_humanism@msn.com</em></a>)<br>
<strong>Date:</strong> Sun Jun 16 2002 - 16:32:05 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4045.html">Michael Roy Ames: "Re: QUES: CFAI"</a>
<li><strong>Previous message:</strong> <a href="4043.html">Gordon Worley: "Re: Threats to the Singularity."</a>
<li><strong>Maybe in reply to:</strong> <a href="4031.html">Anand AI: "QUES: CFAI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4045.html">Michael Roy Ames: "Re: QUES: CFAI"</a>
<li><strong>Reply:</strong> <a href="4045.html">Michael Roy Ames: "Re: QUES: CFAI"</a>
<li><strong>Reply:</strong> <a href="4047.html">Michael Roy Ames: "Re: QUES: CFAI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4044">[ date ]</a>
<a href="index.html#4044">[ thread ]</a>
<a href="subject.html#4044">[ subject ]</a>
<a href="author.html#4044">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Anand wrote:
<br>
<em>&gt;01. Does CFAI argue for a set of panhuman characteristics that comrpise
</em><br>
<em>&gt;human moral cognition?  If so, what characteristics do we have evidence
</em><br>
<em>&gt;for, and what characteristics of human moral cognition will be
</em><br>
<em>&gt;reproduced?
</em><br>
<p>The following is correlated to question #1. The below quoted text has the
<br>
premise that a philosophy can be grounded and approximately derived from
<br>
panhuman characteristics, and used as content for Friendly AI. I am
<br>
requesting clear explication of and evidence for this premise. Also, what
<br>
evidence is there for the below claim that &quot;panhuman attributes such as
<br>
'altruism'... build up _very_ strongly when all the humans on Earth are
<br>
superposed&quot;?
<br>
<p>CFAI: 3.4.2.4.3: SAS: Grounding for external reference semantics:
<br>
<em>&gt;In a later section, I give the actual, highly secret, no-peeking target
</em><br>
<em>&gt;definition of Friendliness that is sufficiently convergent, totally
</em><br>
<em>&gt;programmer-independent, and so on.  Hopefully, you've seen enough already
</em><br>
<em>&gt;to accept, as a working hypothesis, the idea that a philosophy can be
</em><br>
<em>&gt;grounded in panhuman affectors.  The programmers try to produce a
</em><br>
<em>&gt;philosophy that's an approximation to that one.  Then, they pass it on to
</em><br>
<em>&gt;the Friendly AI.  The Friendly AI's external referent is supposed to refer
</em><br>
<em>&gt;to that programmer-independent philosophy, about which the programmers
</em><br>
<em>&gt;are good sources of information, as long as the programmers give it their
</em><br>
<em>&gt;honest best shot.  This is not a complete grounding - that takes causal
</em><br>
<em>&gt;validity semantics - but it does work to describe all the ways that
</em><br>
<em>&gt;external reference semantics should behave.  For example, morality does
</em><br>
<em>&gt;not change when words leave the programmers' lips, it is possible for a
</em><br>
<em>&gt;programmer to say the wrong thing, the cognitive cause of a statement
</em><br>
<em>&gt;almost always has priority over the statement itself, manipulating the
</em><br>
<em>&gt;programmer's brain doesn't change morality, and so on.
</em><br>
<p>CFAI: 3.4.4: The actual definition of Friendliness:
<br>
<em>&gt;The renormalizing shaper network should ultimately ground itself in the
</em><br>
<em>&gt;panhuman and gaussian layers, without use of material from the personality
</em><br>
<em>&gt;layer of the original programmer.  This is how &quot;programmer independence&quot;
</em><br>
<em>&gt;is ultimately defined.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Humanity is diverse, and there's still some variance even in the panhuman
</em><br>
<em>&gt;layer, but it's still possible to conceive of description for humanity and
</em><br>
<em>&gt;not just any one individual human, by superposing the sum of all the
</em><br>
<em>&gt;variances in the panhuman layer into one description of humanity.
</em><br>
<em>&gt;Suppose, for example, that any given human has a preference for X; this
</em><br>
<em>&gt;preference can be thought of as a cloud in configuration space.  Certain
</em><br>
<em>&gt;events very strongly satisfy the metric for X; others satisfy it more
</em><br>
<em>&gt;weakly; other events satisfy it not at all.  Thus, there's a cloud in
</em><br>
<em>&gt;configuration space, with a clearly defined center.  If you take something
</em><br>
<em>&gt;in the panhuman layer (not the personal layer) and superimpose the
</em><br>
<em>&gt;clouds of all humanity, you should end up with a slightly larger cloud
</em><br>
<em>&gt;that still has a clearly defined center.  Any point that is squarely in
</em><br>
<em>&gt;the center of the cloud is &quot;grounded in the panhuman layer of
</em><br>
<em>&gt;humanity&quot;.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Panhuman attributes that we would think of as &quot;selfish&quot; or
</em><br>
<em>&gt;&quot;observer-biased&quot; tend to cancel out in the superposition; since each
</em><br>
<em>&gt;individual human has a drastically different definition, the cloud is very
</em><br>
<em>&gt;thin, and insofar as it can be described at all, would center about
</em><br>
<em>&gt;equally on each individual human.  Panhuman attributes such as
</em><br>
<em>&gt;&quot;altruism&quot;, especially morally symmetric altruism or altruism that has
</em><br>
<em>&gt;been phrased using the semantics of objectivity, or by other means
</em><br>
<em>&gt;made a little more convergent for use in &quot;morality&quot; and not just the
</em><br>
<em>&gt;originating mind, builds up very strongly when all the humans on Earth
</em><br>
<em>&gt;are superposed.  The difference is analogous to that between a beam of
</em><br>
<em>&gt;incoherent light and a laser.
</em><br>
<p>Anand wrote:
<br>
<em>&gt;02. Why is volition-based Friendliness the assumed model of Friendliness
</em><br>
<em>&gt;content?  What will it and what will it not constitute and allow?  If the
</em><br>
<em>&gt;model is entirely incorrect, how is this predicted to affect the AI's
</em><br>
<em>&gt;architecture[, specifically, causal validity semantics]?
</em><br>
<p>CFAI contains only two paragraphs, I believe, that explicitly relate to the
<br>
above question.  Please interpret my second question as a request for
<br>
elaboration beyond the below quoted text.
<br>
<p>CFAI: 1.3: Seed AI and the Singularity:
<br>
<em>&gt;Punting the issue of &quot;What is 'good'?&quot; back to individual sentients
</em><br>
<em>&gt;enormously simplifies a lot of moral issues; whether life is better than
</em><br>
<em>&gt;death, for example.  Nobody should be able to interfere if a sentient
</em><br>
<em>&gt;chooses life.  And - in all probability - nobody should be able to
</em><br>
<em>&gt;interfere if a sentient chooses death.  So what's left to argue about?
</em><br>
<em>&gt;Well, quite a bit, and a fully Friendly AI needs to be able to argue it;
</em><br>
<em>&gt;the resolution, however, is likely to come down to individual volition.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Thus, Creating Friendly AI uses &quot;volition-based Friendliness&quot; as the
</em><br>
<em>&gt;assumed model for Friendliness content.  Volition-based Friendliness
</em><br>
<em>&gt;has both a negative aspect - don't cause involuntary pain, death,
</em><br>
<em>&gt;alteration, et cetera; try to do something about those things if you see
</em><br>
<em>&gt;them happening - and a positive aspect: to try and fulfill the requests
</em><br>
<em>&gt;of sentient entities.
</em><br>
<p>Anand wrote:
<br>
<em>&gt;03. What alternatives to volition-based Friendliness have been considered,
</em><br>
<em>&gt;and why were they not chosen?
</em><br>
<p>According to my memory, CFAI does not contain an answer to the above
<br>
question. If this is wrong, please reference specific sections.
<br>
<p>Anand wrote:
<br>
<em>&gt;04. How will the AI know and decide what constitutes &quot;normativeness&quot;?
</em><br>
<p>Specifically, I do not understand what constitutes &quot;normativeness&quot; in the
<br>
real-world. What constitutes a normative human or normative altruism, and
<br>
how can they be achieved?
<br>
<p>Thanks,
<br>
<p>Anand
<br>
<p><p><p>_________________________________________________________________
<br>
Get your FREE download of MSN Explorer at <a href="http://explorer.msn.com/intl.asp">http://explorer.msn.com/intl.asp</a>.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4045.html">Michael Roy Ames: "Re: QUES: CFAI"</a>
<li><strong>Previous message:</strong> <a href="4043.html">Gordon Worley: "Re: Threats to the Singularity."</a>
<li><strong>Maybe in reply to:</strong> <a href="4031.html">Anand AI: "QUES: CFAI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4045.html">Michael Roy Ames: "Re: QUES: CFAI"</a>
<li><strong>Reply:</strong> <a href="4045.html">Michael Roy Ames: "Re: QUES: CFAI"</a>
<li><strong>Reply:</strong> <a href="4047.html">Michael Roy Ames: "Re: QUES: CFAI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4044">[ date ]</a>
<a href="index.html#4044">[ thread ]</a>
<a href="subject.html#4044">[ subject ]</a>
<a href="author.html#4044">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:39 MDT
</em></small></p>
</body>
</html>
