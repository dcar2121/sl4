<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: How Kurzweil lost the Singularity</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: How Kurzweil lost the Singularity">
<meta name="Date" content="2002-06-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: How Kurzweil lost the Singularity</h1>
<!-- received="Sat Jun 15 14:21:15 2002" -->
<!-- isoreceived="20020615202115" -->
<!-- sent="Sat, 15 Jun 2002 11:31:11 -0600" -->
<!-- isosent="20020615173111" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: How Kurzweil lost the Singularity" -->
<!-- id="LAEGJLOGJIOELPNIOOAJGEODCKAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3D0B6DD5.4020202@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20How%20Kurzweil%20lost%20the%20Singularity"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sat Jun 15 2002 - 11:31:11 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4017.html">Ben Houston: "RE: A CodeDOM-Aware Generative IDE"</a>
<li><strong>Previous message:</strong> <a href="4015.html">Eliezer S. Yudkowsky: "How Kurzweil lost the Singularity"</a>
<li><strong>In reply to:</strong> <a href="4015.html">Eliezer S. Yudkowsky: "How Kurzweil lost the Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4022.html">Ben Goertzel: "RE: How Kurzweil lost the Singularity"</a>
<li><strong>Reply:</strong> <a href="4022.html">Ben Goertzel: "RE: How Kurzweil lost the Singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4016">[ date ]</a>
<a href="index.html#4016">[ thread ]</a>
<a href="subject.html#4016">[ subject ]</a>
<a href="author.html#4016">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
hey Eliezer,
<br>
<p>FIRSTLY, I'm about to leave for a week-long camping trip, so I'll be offline
<br>
for the next week, starting in a few hours....  Thus I may not read your
<br>
reply to my e-mail for a week ;&gt;
<br>
<p>Now...  I think you oversimplify things a little bit.
<br>
<p>But ultimately, which one of us has better inferred Kurzweil's inner psyche,
<br>
is not very important, huh??  ;&gt;
<br>
<p><p><em>&gt;  On every occasion in which I have spoken to
</em><br>
<em>&gt; Kurzweil, the concept of influencing the Singularity in any way
</em><br>
<em>&gt; is met with
</em><br>
<em>&gt; blank incomprehension.
</em><br>
<p>I don't think so.  My impression from talking to him is that he considers it
<br>
possible for individuals to affect the course of the Singularity.  I think
<br>
he just takes a kind of &quot;grand historical&quot; perspective, rather than an
<br>
individually-focused perspective.
<br>
<p>To take an example from another domain, in the grand historical perspective,
<br>
one might say &quot;the emergence of quantum physics was inevitable.&quot;  And in a
<br>
way it *was* inevitable, regardless of whether the particular individuals
<br>
Heisenberg, Schrodinger, Planck, etc. took up physics or gardening.  On the
<br>
other hand, it was important that SOME individuals did the actual physics!
<br>
And it took some pretty smart individuals...
<br>
<p>Similarly, from the grand historical perspective, it doesn't matter what you
<br>
or I personally do for the Singularity, it's gonna happen.  Yet, it's
<br>
important that SOMEBODY does the things we're doing...
<br>
<p>The problem is that this grand historical perspective is a little more
<br>
applicable to the emergence of a scientific theory, than to the Singularity.
<br>
Because the Singularity  may have a much more &quot;sensitive dependence on
<br>
initial conditions&quot;....
<br>
<p>Sure, if Wallace instead of Darwin had been seen as the main champion of
<br>
evolutionary theory, Neo-Darwinism might be a better theory today (more
<br>
focus on cybernetics).  And if Einstein had not existed, general relativity
<br>
might have emerged only much later, so that the GUT's of today would be even
<br>
more strongly field-theory-focused rather than gravity-focused.  So there is
<br>
*some* dependence on initial conditions in the development of a scientific
<br>
theory.
<br>
<p>But with the Singularity, a different &quot;twist&quot; in the launch conditions could
<br>
lead to unrecoverable disaster....  This is less likely to happen in the
<br>
evolution of science.  Hence the &quot;grand historical perspective&quot; that
<br>
Kurzweil favors, is more problematic in regard to the Singularity than in
<br>
regard to most other historical phenomena...
<br>
<p><p><em>&gt; As far as Kurzweil is concerned, he wins the
</em><br>
<em>&gt; argument when he convinces the audience that the Singularity will happen.
</em><br>
<p>Sure, but his choice of what argument to have with the public right now,
<br>
does not tell you what his whole world-view is...
<br>
<p>He's doing PR, and he knows how to do it better than either of us does.
<br>
<p><em>&gt; Kurzweil wants to believe in the benevolence and inevitability of the
</em><br>
<em>&gt; Singularity and any argument of the form &quot;You can do X and it will improve
</em><br>
<em>&gt; your chances of (a Singularity) / (a positive Singularity)&quot; appears to him
</em><br>
<em>&gt; to be a vulnerability in his argument:  &quot;The Singularity *could*
</em><br>
<em>&gt; (go wrong)
</em><br>
<em>&gt; / (not happen) if not-X.&quot;  Kurzweil will therefore argue against it.
</em><br>
<em>&gt; Kurzweil's entire worldview prohibits the possibility of
</em><br>
<em>&gt; Singularity activism.
</em><br>
<p>I think this is rather an overstatement....  I don't think you're fully
<br>
appreciating the nature of the &quot;grand historical perspective.&quot;
<br>
<p>Saying that &quot;the emergence of X is inevitable as a consequence of countless
<br>
human actions&quot; is not implying that &quot;these countless human actions are
<br>
unimportant.&quot;
<br>
<p>I think that *part* of what gets your goose about Kurzweil is that he
<br>
doesn't value YOUR actions any more highly than those of 100000 other
<br>
scientists and engineers working on generally Singularity-focused advanced
<br>
technology ;&gt;
<br>
<p><em>&gt; In fact, having watched Kurzweil debate Vinge, I've come to the conclusion
</em><br>
<em>&gt; that Kurzweil's worldview prohibits Kurzweil from arriving at any real
</em><br>
<em>&gt; understanding of the basic nature of the Singularity.  Over the
</em><br>
<em>&gt; course of my
</em><br>
<em>&gt; personal interaction with Kurzweil, I've seen him say two really bizarre
</em><br>
<em>&gt; things.  One was during the recent chat with Vinge, when Kurzweil
</em><br>
<em>&gt; predicted
</em><br>
<em>&gt; superhuman AI intelligence in 2029, followed shortly thereafter by the
</em><br>
<em>&gt; statement that the Singularity &quot;would not begin to tear the
</em><br>
<em>&gt; fabric of human
</em><br>
<em>&gt; understanding until 2040&quot;.
</em><br>
<p>He has a different estimate of the growth curve of intelligence in the
<br>
near-superhuman realm than you do.
<br>
<p>He understands the idea of exponential intelligence increase thru AI
<br>
self-modification, he just thinks the exponent will be smaller than you
<br>
think it will be.
<br>
<p>I think he's overpessimistic and you're overoptimistic in this particular
<br>
regard, but we're all just grabbing exponents out of our asses here,
<br>
basically...
<br>
<p><em>&gt; The second really bizarre thing I've heard
</em><br>
<em>&gt; Kurzweil say was at his SIG at the recent Foresight Gathering,
</em><br>
<em>&gt; when I asked
</em><br>
<em>&gt; why AIs thinking at million-to-one speeds wouldn't speed up the
</em><br>
<em>&gt; development
</em><br>
<em>&gt; of technology, and he said &quot;Well, that's another reason to expect Moore's
</em><br>
<em>&gt; Law to remain on course.&quot;
</em><br>
<p>I don't get this one... sounds like a miscommunication...
<br>
<p><p><em>&gt;  What
</em><br>
<em>&gt; Kurzweil calls the &quot;Singularity&quot; is the inevitable, inexorable,
</em><br>
<em>&gt; and entirely
</em><br>
<em>&gt; ordinary progress of technology, which, in Kurzweil's world, *causes*
</em><br>
<em>&gt; developments such as transhumanity, but is not *changed* by transhumanity
</em><br>
<em>&gt; except in the same ways that industry has been changed by previous
</em><br>
<em>&gt; technological developments.
</em><br>
<p>I do not think his understanding is this shallow, though I admit he may not
<br>
have thought through the dramatic implications of the Singularity as
<br>
thoroughly as some of us
<br>
<p><em>&gt; What Kurzweil is selling, under the brand name of the
</em><br>
<em>&gt; &quot;Singularity&quot;, is the
</em><br>
<em>&gt; idea that technological progress will continue to go on exactly as it has
</em><br>
<em>&gt; done over the last century, and that the inexorable grinding of
</em><br>
<em>&gt; the gears of
</em><br>
<em>&gt; industry will eventually churn out luxuries such as superintelligent AIs,
</em><br>
<em>&gt; brain-computer interfaces, inloading, uploading, transhuman
</em><br>
<em>&gt; servants, and so
</em><br>
<em>&gt; on.
</em><br>
<p>I think he's saying a bit more than that!  I too am a bit disappointed by
<br>
his choice of emphasis in his Singularity writings -- but still, I don't
<br>
think his writings are as bad as you imply.
<br>
<p>It is true, he does not adequately focus on the fact that, post-Singularity,
<br>
we're going to be in a TOTALLY UNKNOWN region, in which reality and
<br>
experience as we now know it MAY become totally irrelevant.  I think he does
<br>
understand this, to some extent, but chooses not to focus on it.
<br>
<p>On the other hand, I think you tend to downplay the possibility that *limits
<br>
to intelligence and progress* might be discovered, which we do not now
<br>
understand or suspect....  I hope such limits are not found (or if they're
<br>
found, they're not severe), but the possibility of such limits is part and
<br>
parcel of accepting that we are moving into a totally unknown region!
<br>
<p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4017.html">Ben Houston: "RE: A CodeDOM-Aware Generative IDE"</a>
<li><strong>Previous message:</strong> <a href="4015.html">Eliezer S. Yudkowsky: "How Kurzweil lost the Singularity"</a>
<li><strong>In reply to:</strong> <a href="4015.html">Eliezer S. Yudkowsky: "How Kurzweil lost the Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4022.html">Ben Goertzel: "RE: How Kurzweil lost the Singularity"</a>
<li><strong>Reply:</strong> <a href="4022.html">Ben Goertzel: "RE: How Kurzweil lost the Singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4016">[ date ]</a>
<a href="index.html#4016">[ thread ]</a>
<a href="subject.html#4016">[ subject ]</a>
<a href="author.html#4016">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:39 MDT
</em></small></p>
</body>
</html>
