<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Friendly Existential Wager</title>
<meta name="Author" content="Mark Walker (mdwalker@quickclic.net)">
<meta name="Subject" content="Re: Friendly Existential Wager">
<meta name="Date" content="2002-06-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Friendly Existential Wager</h1>
<!-- received="Sat Jun 29 08:31:16 2002" -->
<!-- isoreceived="20020629143116" -->
<!-- sent="Sat, 29 Jun 2002 08:29:22 -0400" -->
<!-- isosent="20020629122922" -->
<!-- name="Mark Walker" -->
<!-- email="mdwalker@quickclic.net" -->
<!-- subject="Re: Friendly Existential Wager" -->
<!-- id="001f01c21f68$991e6100$e4cef418@markcomputer" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="3D1D3D41.1060801@objectent.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Mark Walker (<a href="mailto:mdwalker@quickclic.net?Subject=Re:%20Friendly%20Existential%20Wager"><em>mdwalker@quickclic.net</em></a>)<br>
<strong>Date:</strong> Sat Jun 29 2002 - 06:29:22 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4544.html">Eliezer S. Yudkowsky: "Controlled ascent (was: Military Friendly AI)"</a>
<li><strong>Previous message:</strong> <a href="4542.html">Eugen Leitl: "RE: How hard a Singularity?"</a>
<li><strong>In reply to:</strong> <a href="4538.html">Samantha Atkins: "Re: Friendly Existential Wager"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4508.html">Eliezer S. Yudkowsky: "Re: Friendly Existential Wager"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4543">[ date ]</a>
<a href="index.html#4543">[ thread ]</a>
<a href="subject.html#4543">[ subject ]</a>
<a href="author.html#4543">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
----- Original Message -----
<br>
From: &quot;Samantha Atkins&quot; &lt;<a href="mailto:samantha@objectent.com?Subject=Re:%20Friendly%20Existential%20Wager">samantha@objectent.com</a>&gt;
<br>
To: &lt;<a href="mailto:sl4@sysopmind.com?Subject=Re:%20Friendly%20Existential%20Wager">sl4@sysopmind.com</a>&gt;
<br>
<em>&gt;
</em><br>
<em>&gt; Well, perhaps not a listed fallacy but let's run through it:
</em><br>
<em>&gt; 1) If I believe and act on X and X is true then I obviously gain;
</em><br>
<em>&gt; 2) If I believe X and X is false then I lose very little;
</em><br>
<em>&gt; 3) If I don't believe X and X is true then I lose;
</em><br>
<em>&gt; 4) If I don't believe X and X is not true then I gain little.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The logic itself is empty because the relatively validity of any
</em><br>
<em>&gt; of the statements depends utterly on the qualities of X and the
</em><br>
<em>&gt; consequences of belief and non-belief of that particular X
</em><br>
<em>&gt; immediate and future.  It doesn't depend on the steps at all.
</em><br>
<p>Agreed. (This is true of most arguments: changing the content of the
<br>
variables can affect its validity). I guess I should have made it clear that
<br>
I cited Pascal not because I think his argument is correct (which I don't)
<br>
but because he was the first to think (or at least popularize) this sort of
<br>
thinking.
<br>
<p><em>&gt;
</em><br>
<em>&gt; &gt; For example, in Pascal's Wager I only
</em><br>
<em>&gt; &gt; risk my soul, here everyone else is at risk. Another disanalogy is this:
</em><br>
in
<br>
<em>&gt;
</em><br>
<em>&gt; When applied to Friendly AI it is not clear that concentrating
</em><br>
<em>&gt; first on the Friendliness is the actual way to acheive AI, much
</em><br>
<em>&gt; less Friendly AI.  If we fail to accomplish AI at all, there is
</em><br>
<em>&gt; a downside risk that as our society and problems become
</em><br>
<em>&gt; increasingly complex they grow beyond our non-AI ability to deal
</em><br>
<em>&gt; with.  So (2) has a potential large downside.
</em><br>
<em>&gt;
</em><br>
<p>Yes, this is true and a good point. There are a lot more considerations than
<br>
went into my little post. One thing we would want to know is exactly how
<br>
inefficient (assuming that it is) concentrating on the Friendly component
<br>
would be. B.G. says it has some value but also says that it is like
<br>
&quot;building castles in the air&quot; (if memory serves).  Other considerations are
<br>
things like worrying about nefarious groups stealing your research. Less of
<br>
a worry obviousy if you have only done your Friendly research, more of a
<br>
worry if you have a neonate AI without the Friendliness &quot;bolt on&quot;.
<br>
<p><em>&gt; &gt; the case of God, the prevailing scientific opinion is that God does not
</em><br>
<em>&gt; &gt; exist, in contrast, there is very little agreement among scientists
</em><br>
about
<br>
<em>&gt; &gt; how or when to implement Friendliness. Ironically, your post comes
</em><br>
pretty
<br>
<em>&gt; &gt; close to the fallacy of guilt by association.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; I was unaware that God was purported to dwell or exist within
</em><br>
<em>&gt; any realm that science has competency in.  It is not up to
</em><br>
<em>&gt; science to pronounce an authoriative opinion on the subject.
</em><br>
<em>&gt;
</em><br>
<p>You may be right. My point relies simply on scientists in general thinking
<br>
they are right on this point.
<br>
<p>Let me add that to be tempted by the sort of argument I outlined I think it
<br>
is necessary (but not sufficient) that one appreciate the enormous risks and
<br>
benefits associated with this task (which I believe E.Y. and B. G. do) and
<br>
also believe that we really don't know what we are doing when it comes to
<br>
building an AI. These sorts of wager arguments presume a certain amount of
<br>
ignorance, e.g., in the Pascalian case one has to believe that there is not
<br>
sufficient evidence for or against the existence of God. This already
<br>
precludes most atheists and theists who believe that they have compelling
<br>
evidence one way or another.  As far as I can tell, both E.Y. and B.G.
<br>
reject this point about ignorance, i.e., they think they know enough about
<br>
how to build an AI, or at least they know enough that they know when it is
<br>
appropriate to focus on the Friendly component, so of course they won't be
<br>
tempted by this argument.  Let's hope they are right.
<br>
<p><p>Mark
<br>
<p><p><p>Dr. Mark Walker
<br>
Research Associate (Philosophy), Trinity College, University of Toronto
<br>
Editor-in-Chief, Journal of Evolution and Technology,
<br>
(www.transhumanist.com)
<br>
Editor-in-Chief, Transhumanity, (www.transhumanism.com)
<br>
Home page: <a href="http://www.markalanwalker.com">http://www.markalanwalker.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4544.html">Eliezer S. Yudkowsky: "Controlled ascent (was: Military Friendly AI)"</a>
<li><strong>Previous message:</strong> <a href="4542.html">Eugen Leitl: "RE: How hard a Singularity?"</a>
<li><strong>In reply to:</strong> <a href="4538.html">Samantha Atkins: "Re: Friendly Existential Wager"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4508.html">Eliezer S. Yudkowsky: "Re: Friendly Existential Wager"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4543">[ date ]</a>
<a href="index.html#4543">[ thread ]</a>
<a href="subject.html#4543">[ subject ]</a>
<a href="author.html#4543">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:39 MDT
</em></small></p>
</body>
</html>
