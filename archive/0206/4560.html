<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Military Friendly AI</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Re: Military Friendly AI">
<meta name="Date" content="2002-06-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Military Friendly AI</h1>
<!-- received="Sat Jun 29 18:50:26 2002" -->
<!-- isoreceived="20020630005026" -->
<!-- sent="Sat, 29 Jun 2002 18:47:27 -0400" -->
<!-- isosent="20020629224727" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Re: Military Friendly AI" -->
<!-- id="3D1E38FF.CFE7B410@posthuman.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="LAEGJLOGJIOELPNIOOAJEEAKCMAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Military%20Friendly%20AI"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Sat Jun 29 2002 - 16:47:27 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4561.html">Brian Atkins: "Re: Military Friendly AI"</a>
<li><strong>Previous message:</strong> <a href="4559.html">Eliezer S. Yudkowsky: "Re: FAI means no programmer-sensitive AI morality"</a>
<li><strong>In reply to:</strong> <a href="4493.html">Ben Goertzel: "RE: Military Friendly AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4567.html">Ben Goertzel: "RE: Military Friendly AI"</a>
<li><strong>Reply:</strong> <a href="4567.html">Ben Goertzel: "RE: Military Friendly AI"</a>
<li><strong>Reply:</strong> <a href="4584.html">Stephen Reed: "Albus / NIST / RMA"</a>
<li><strong>Reply:</strong> <a href="../0207/4649.html">James Higgins: "Re: Military Friendly AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4560">[ date ]</a>
<a href="index.html#4560">[ thread ]</a>
<a href="subject.html#4560">[ subject ]</a>
<a href="author.html#4560">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
(I'm obviously late to the party with my comments, but what the heck)
<br>
<p>Ben Goertzel wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; However, it may be even MORE dangerous to fool oneself into believing one
</em><br>
<em>&gt; has adequately grappled with the Friendliness issue prior to creating an
</em><br>
<em>&gt; infrahuman AGI.
</em><br>
<p><p><em>&gt; Here's the thing... as clarified in the previous paragraphs I just typed, we
</em><br>
<em>&gt; *do* have a Friendliness goal built in, we're just sure yet what the best
</em><br>
<em>&gt; way is to do this.  And we're not willing to fool ourselves that we *are*
</em><br>
<em>&gt; sure what the best way is....
</em><br>
<p>I want to point out the seeming implication of these quotes is the
<br>
exact opposite of what I feel SIAI currently believes. We fully expect to
<br>
find problems with our ideas as actual testing goes on. Our experiment
<br>
protocol will not for instance allow our prototypes access to the Internet
<br>
because, hey, we might be wrong.
<br>
<p>Do you plan any &quot;containment&quot; features as part of your protocol?
<br>
<p>Again, I ask: do you plan to publish publicly any kind of basic description
<br>
of your experimental protocol, and how it works at every step of your
<br>
AI design and testing to lower risks? It doesn't have to be now, but I
<br>
think it should be available at a bare minimum 6 months before you
<br>
expect to have your full code up and running.
<br>
<p><em>&gt; &gt;
</em><br>
<em>&gt; &gt; I assume that if you get your working infrahuman AI, and are unable to
</em><br>
<em>&gt; &gt; come up with a bulletproof way of keeping it &quot;Friendly&quot;, you will turn it
</em><br>
<em>&gt; &gt; off?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Not necessarily, this will be a hard decision if it comes to that.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It may be that what we learn is that there is NO bulletproof way to make an
</em><br>
<em>&gt; AGI Friendly... just like there is no bulletproof way to make a human
</em><br>
<em>&gt; Friendly....  It is possible that the wisest course is to go ahead and let
</em><br>
<em>&gt; an AGI evolve even though one knows one is not 100% guaranteed of
</em><br>
<em>&gt; Friendliness.  This would be a tough decision to come to, but not an
</em><br>
<em>&gt; impossible one, in my view.
</em><br>
<p>So, since nowadays you are talking about having some kind of committee make
<br>
the final decision, if they come back to you and say &quot;The .01% chance we have
<br>
calculated that your AI will go rogue at some point in the far future is too
<br>
much in our opinion. Pull the plug.&quot; you will pull the plug?
<br>
<p>Higgins seems to want &quot;hundreds or thousands of relevant experts&quot; to agree
<br>
that it is ok for you to &quot;push the big red button&quot;. Are you ok with that?
<br>
<pre>
-- 
Brian Atkins
Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4561.html">Brian Atkins: "Re: Military Friendly AI"</a>
<li><strong>Previous message:</strong> <a href="4559.html">Eliezer S. Yudkowsky: "Re: FAI means no programmer-sensitive AI morality"</a>
<li><strong>In reply to:</strong> <a href="4493.html">Ben Goertzel: "RE: Military Friendly AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4567.html">Ben Goertzel: "RE: Military Friendly AI"</a>
<li><strong>Reply:</strong> <a href="4567.html">Ben Goertzel: "RE: Military Friendly AI"</a>
<li><strong>Reply:</strong> <a href="4584.html">Stephen Reed: "Albus / NIST / RMA"</a>
<li><strong>Reply:</strong> <a href="../0207/4649.html">James Higgins: "Re: Military Friendly AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4560">[ date ]</a>
<a href="index.html#4560">[ thread ]</a>
<a href="subject.html#4560">[ subject ]</a>
<a href="author.html#4560">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:39 MDT
</em></small></p>
</body>
</html>
