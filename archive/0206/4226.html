<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Seed AI (was: How hard a Singularity?)</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Seed AI (was: How hard a Singularity?)">
<meta name="Date" content="2002-06-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Seed AI (was: How hard a Singularity?)</h1>
<!-- received="Sun Jun 23 14:33:09 2002" -->
<!-- isoreceived="20020623203309" -->
<!-- sent="Sun, 23 Jun 2002 12:33:05 -0600" -->
<!-- isosent="20020623183305" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Seed AI (was: How hard a Singularity?)" -->
<!-- id="LAEGJLOGJIOELPNIOOAJIEGJCLAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3D160BDA.6020202@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Seed%20AI%20(was:%20How%20hard%20a%20Singularity?)"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sun Jun 23 2002 - 12:33:05 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4227.html">Ben Goertzel: "RE: Threats to the Singularity."</a>
<li><strong>Previous message:</strong> <a href="4225.html">Brian Atkins: "Re: How hard a Singularity?"</a>
<li><strong>In reply to:</strong> <a href="4219.html">Eliezer S. Yudkowsky: "Re: Seed AI (was: How hard a Singularity?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4240.html">James Higgins: "Re: Seed AI (was: How hard a Singularity?)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4226">[ date ]</a>
<a href="index.html#4226">[ thread ]</a>
<a href="subject.html#4226">[ subject ]</a>
<a href="author.html#4226">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
hi,
<br>
<p><em>&gt; What kind of knowledge is this implicit knowledge?  How will the
</em><br>
<em>&gt; AI absorb
</em><br>
<em>&gt; it through interaction?  Let's take the mnemonic experiential record of a
</em><br>
<em>&gt; human interaction; what kind of algorithms will absorb &quot;abstract
</em><br>
<em>&gt; thought-patterns&quot; from the record of human statements?
</em><br>
<p>This is a kind of &quot;procedure learning&quot; but involving abstract cognitive
<br>
procedures rather than physical-world action procedures....  In Novamente it
<br>
would be handled by the generic &quot;schema learning&quot; mechanisms with
<br>
appropriate parameter settings.
<br>
<p><em>&gt; &gt; I think that a lot of transfer of thought-patterns will happen
</em><br>
<em>&gt; *implicitly*
</em><br>
<em>&gt; &gt; through interaction in shared environments.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; For this to happen, explicit declarative knowledge of thought
</em><br>
<em>&gt; patterns is
</em><br>
<em>&gt; &gt; not required, on the part of the human teachers.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Okay.  If you don't know in advance how this will work, I predict that
</em><br>
<em>&gt; nothing will happen.
</em><br>
<p>I have a fairly detailed understanding of how this could work...
<br>
<p>A good example is learning the knowledge of how to do mathematical proofs.
<br>
<em>&gt;From seeing how humans have done proofs, the system can learn patterns of
</em><br>
proof -- what kinds of proof strategies and tactics often work in what kinds
<br>
of situations.
<br>
<p>This knowledge about proof strategies and tactics is not explicitly stated
<br>
in math books (except minimally and occasionally) but everyone who learns
<br>
advanced math, learns it by induction from reading proofs and asking
<br>
questions about them...
<br>
<p>A related example is learning how to program.  The implicit ways and means
<br>
of software engineering are learned by humans largely by example.  A lot of
<br>
this is learning abstract cognitive schema for analyzing various sorts of
<br>
problems, translating them into other problems, etc.  WE try to translate
<br>
this kind of knowledge into declarative form, but only with limited success.
<br>
In practice, it's learned by reading others' code, by coding expereince, and
<br>
by collaboration with experienced coders.  Subtract out the &quot;reading others'
<br>
code&quot; and &quot;collaboration&quot; parts and learning how to code would be a LOT
<br>
slower because one would have to brew all one's own coding-related cognitive
<br>
schema.
<br>
<p><em>&gt; &gt; I doubt this is how things will go.  I think human knowledge will be
</em><br>
<em>&gt; &gt; comprehensible by an AI *well before* the AI is capable of drastically
</em><br>
<em>&gt; &gt; modifying its own sourcecode in the interest of vastly increased
</em><br>
<em>&gt; &gt; intelligence.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I would expect the AI's understanding of source code to run well ahead of
</em><br>
<em>&gt; its understanding of human language at any given point.  The AI
</em><br>
<em>&gt; lives right
</em><br>
<em>&gt; next to source code; human language is located in another galaxy
</em><br>
<em>&gt; by comparison.
</em><br>
<p>It's true, but source code is much much more complicated than human
<br>
language...
<br>
<p><em>&gt; &gt; I think that humans will teach the AGI more than just &quot;domain
</em><br>
<em>&gt; problems at
</em><br>
<em>&gt; &gt; the right level,&quot; I think that by cooperatively solving
</em><br>
<em>&gt; problems together
</em><br>
<em>&gt; &gt; with the AGI, humans will teach it a network of interrelated
</em><br>
<em>&gt; &gt; thought-patterns.  Just as we learn from other humans via
</em><br>
<em>&gt; interacting with
</em><br>
<em>&gt; &gt; them.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I'm not sure we learn thought-patterns, whatever those are, from other
</em><br>
<em>&gt; humans;
</em><br>
<p>If you were given a complex theorem to prove, how would you approach it?
<br>
Would you use patterns and strategies inspired by proofs others had done in
<br>
the past, that you'd read?
<br>
<p>If not, you'd have a very low chance of success, at least in many branches
<br>
of math, such as advanced analysis or number theory...
<br>
<p><p><em>&gt; &gt; This is because I see &quot;intelligent goal-directed code
</em><br>
<em>&gt; self-modification&quot; as
</em><br>
<em>&gt; &gt; being a very hard problem, harder than mastering human language, for
</em><br>
<em>&gt; &gt; example.
</em><br>
<em>&gt;
</em><br>
<em>&gt; This honestly strikes me as extremely odd.  Code is vastly easier to
</em><br>
<em>&gt; experiment with than human language; the AI can accumulate more
</em><br>
<em>&gt; experience
</em><br>
<em>&gt; faster; there are no outside references to the black-box external
</em><br>
<em>&gt; world; the
</em><br>
<em>&gt; AI can find its own solutions rather than needing the human one;
</em><br>
<em>&gt; and the AI
</em><br>
<em>&gt; can use its own concepts to think rather than needing to manipulate
</em><br>
<em>&gt; human-sized concepts specialized for human modalities that the AI may not
</em><br>
<em>&gt; even have.  Code is not easy but I'd expect to be a heck of a lot easier
</em><br>
<em>&gt; than language.
</em><br>
<p>But code is hard, it involves very complex inferences, which is why most
<br>
people can't code.
<br>
<p>Natural language does involve a lot of breadth of knowledge and experience
<br>
but the thinking involved is mostly relatively simple.
<br>
<p>A sentence like &quot;Every man has a dog whom every girl likes to call by a
<br>
special pet name&quot; is rare in English, but similar constructs are commonplace
<br>
in programming...
<br>
<p>Of course, AGI's can have an easier time than humans in dealing with complex
<br>
logical constructions, but still, I think coding requires much more advanced
<br>
cognitive schema/heuristics than human language processing.
<br>
<p>Note that I'm not talking about &quot;exactly human-simulative language
<br>
processing&quot;, just about &quot;acceptably communicative languauge processing&quot; and
<br>
&quot;decent language understanding, involving question-asking about unfamilar
<br>
domains.&quot;  of course an AGI's communications will seem alien and non-human,
<br>
even using human language, until way past the human-equivalent level
<br>
(simulating another intelligence being a harder problem than being one's own
<br>
intelligence)
<br>
<p><em>&gt;  &gt; And indeed, this suggests that if seed AI were
</em><br>
<em>&gt; &gt; achieved first by your approach rather than mine, the gap between human
</em><br>
<em>&gt; &gt; level and vastly superhuman level intelligence would be less.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Quite.
</em><br>
<p>But of course, I consider it very unlikely that your approach will lead to
<br>
seed AI in the foreseeable future ;&gt;
<br>
<p>However, I'd be very happy to be proved wrong!!
<br>
<p>-- ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4227.html">Ben Goertzel: "RE: Threats to the Singularity."</a>
<li><strong>Previous message:</strong> <a href="4225.html">Brian Atkins: "Re: How hard a Singularity?"</a>
<li><strong>In reply to:</strong> <a href="4219.html">Eliezer S. Yudkowsky: "Re: Seed AI (was: How hard a Singularity?)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="4240.html">James Higgins: "Re: Seed AI (was: How hard a Singularity?)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4226">[ date ]</a>
<a href="index.html#4226">[ thread ]</a>
<a href="subject.html#4226">[ subject ]</a>
<a href="author.html#4226">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:39 MDT
</em></small></p>
</body>
</html>
