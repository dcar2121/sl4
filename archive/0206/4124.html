<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: How Kurzweil Lost the Singularity</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="How Kurzweil Lost the Singularity">
<meta name="Date" content="2002-06-21">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>How Kurzweil Lost the Singularity</h1>
<!-- received="Fri Jun 21 17:03:04 2002" -->
<!-- isoreceived="20020621230304" -->
<!-- sent="Fri, 21 Jun 2002 14:04:34 -0600" -->
<!-- isosent="20020621200434" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="How Kurzweil Lost the Singularity" -->
<!-- id="LAEGJLOGJIOELPNIOOAJCEDDCLAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=Re:%20How%20Kurzweil%20Lost%20the%20Singularity"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Fri Jun 21 2002 - 14:04:34 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="4125.html">Smigrodzki, Rafal: "How hard a Singularity?"</a>
<li><strong>Previous message:</strong> <a href="4123.html">Ben Goertzel: "RE: AI and hardware"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4124">[ date ]</a>
<a href="index.html#4124">[ thread ]</a>
<a href="subject.html#4124">[ subject ]</a>
<a href="author.html#4124">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Here is a message I just posted to kurzweilai.net
<br>
<p><p>***
<br>
<p>Eliezer &amp; Ray...
<br>
<p>[First a note to readers: bits and pieces of this thread between Eliezer,
<br>
myself and others actually occurred on the SL4 e-mail list, and were later
<br>
(with our permission) posted to this kurzweilai.net forum. This may lead to
<br>
a little pragmatic oddness....]
<br>
<p>Now, I have a few scattered followup points to make..
<br>
<p>1)
<br>
Eliezer: I think that Ray's response to your e-mail shows that my reading of
<br>
his attitude was largely correct, and yours was largely not correct. The key
<br>
point is: Ray does want to do what's possible to ensure the Singularity
<br>
comes out well, he just has a different opinion than you regarding the
<br>
priorities of various actions aimed at ensuring the Singularity comes out
<br>
well. (My own opinion on this is closer to yours than Ray's but not
<br>
identical to yours either.)
<br>
<p>2)
<br>
Ray: I actually didn't realize that the bulk of your work was focused on
<br>
technology dev. these days. Interesting! You've been doing so much popular
<br>
writing and speaking, I sorta assumed that must be taking up the bulk of
<br>
your time, but I shouldn't have underestimated your ability to multitask!
<br>
<p>3)
<br>
I don't think it's right to underplay differences between the perspectives
<br>
between those of us in the &quot;Singularitarian&quot; movement (using this term very
<br>
broadly): of course, differences should be openly and vigorously debated, in
<br>
the interest of advancing understanding.
<br>
<p>But nor should we overemphasize our differences. We don't need a
<br>
Singularitarian sectarianism.... We need to accept that we're all ignorant
<br>
of the nature of what's to come, and that it's absolutely *to be expected*
<br>
that different people who &quot;get&quot; the Singularity vision are going to have
<br>
different intuitions about the details...
<br>
<p>4)
<br>
Ray: As you know, I think you're wrong about AI in some ways, but I think
<br>
our difference of opinion here is not a deep qualitative difference, but
<br>
rather a quantitative difference in probabilities we assign to various
<br>
possibilities.
<br>
<p>I think it's *very likely* that human-level and then transhuman AI can be
<br>
created prior to detailed mapping of the human brain, via a synthesis of
<br>
ideas from CS, cog psych, neuroscience, philosophy of mind, and other
<br>
disciplines. As you know, this is the focus of my life's work.
<br>
<p>As I understand your attitude, on the other hand, you think it's *possible
<br>
but unlikely* that human-level or transhuman AI can be created prior to
<br>
detailed mapping of the human brain's structure and dynamics.
<br>
<p>So, as I understand it, your attitude does go a little beyond the use of &quot;in
<br>
silico brain emulation&quot; as an *existence proof* for the possibility of real
<br>
AI. It seems to me that you also believe this (or some fairly close
<br>
approximation thereof) to be the *most likely route* to the creation of real
<br>
AI.
<br>
<p>And I think you're wrong on this -- but I accept that this is a valid
<br>
difference of intuition. I certainly have no proof as yet that my own design
<br>
for a real AI will work, nor does Eli or anyone else have proof about their
<br>
would-be real AI designs. Differences of intuition on such matters are
<br>
obviously to be expected!
<br>
<p>5)
<br>
Eliezer: About the &quot;Ray has lots of money, so why doesn't he use it to fund
<br>
this or that important line of research&quot; theme, I think that a little more
<br>
understanding of the financial situation of wealthy individuals is in order.
<br>
Ray Kurzweil is not as rich as Bill Gates, and he has a lot of his own R&amp;D
<br>
to fund! It seems to me that Ray is allocating his money in a way that is
<br>
consistent with the greatest future good of humanity and sentience
<br>
*according to his own intuitions and beliefs.* That's more than most wealthy
<br>
individuals do, isn't it?
<br>
<p>Personally, of course I would like to see my own AI work amply funded by Ray
<br>
Kurzweil or anyone else with the bucks. [see www.realai.net for contact info
<br>
to make donations!!]
<br>
<p>But, putting myself in Ray's shoes, I'm quite sure that, if I were wealthy,
<br>
I would rapidly come into contact with thousands of people with great ideas
<br>
for what to do with my money. And I'd have to pick and choose very, very
<br>
carefully and selectively according to my own intuition (which is different
<br>
from Ray's, and surely also imperfect!)
<br>
<p>6)
<br>
Eliezer: I agree with you that the best way to ensure a good Singularity is
<br>
to create a good &quot;real AI&quot; ASAP. I also agree with you that after &quot;real AI&quot;
<br>
is achieved, things are gonna pretty rapidly escalate into some kind of
<br>
&quot;leap into the total unknown,&quot; as opposed to the &quot;at each stage it will just
<br>
seem like ordinary life&quot; scenario that Ray posits.
<br>
<p>However, if we can't convince Ray of these things -- Ray, with his
<br>
sympathetic patternist philosophy and Singularitarian futurism -- how the
<br>
hell can we expect to convince the average scientist, let alone the bulk of
<br>
philanthropists or granting organizations?
<br>
<p>We have to accept that our ideas about the Singularity are not carefully
<br>
grounded in scientific fact, they are to some extent speculative intuitions;
<br>
we cannot reasonably consider others unreasonable for disagreeing with us
<br>
;.&gt;
<br>
<p>An important question is: How to make a more solid, generally
<br>
convincing-to-others case that our perspective on the Singularity is a
<br>
highly plausible one?
<br>
<p>I don't know the answer to this question. Hence my own approach continues to
<br>
be
<br>
<p>a) to work toward building real AI, according to my design that I believe
<br>
will work (and that you are on record stating will not work!), with whatever
<br>
funding and donated effort can be cobbled together.
<br>
<p>b) to seek funding for my real AI work, not for my particular vision of the
<br>
Singularity (although the two are closely connected in my own mind)
<br>
<p><p>-- Ben Goertzel
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="4125.html">Smigrodzki, Rafal: "How hard a Singularity?"</a>
<li><strong>Previous message:</strong> <a href="4123.html">Ben Goertzel: "RE: AI and hardware"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#4124">[ date ]</a>
<a href="index.html#4124">[ thread ]</a>
<a href="subject.html#4124">[ subject ]</a>
<a href="author.html#4124">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:39 MDT
</em></small></p>
</body>
</html>
