<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Shapers, protocols and timescales.</title>
<meta name="Author" content="Michael Wilson (mwdestinystar@yahoo.co.uk)">
<meta name="Subject" content="Shapers, protocols and timescales.">
<meta name="Date" content="2004-04-09">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Shapers, protocols and timescales.</h1>
<!-- received="Fri Apr  9 06:33:37 2004" -->
<!-- isoreceived="20040409123337" -->
<!-- sent="Fri, 9 Apr 2004 13:33:26 +0100 (BST)" -->
<!-- isosent="20040409123326" -->
<!-- name="Michael Wilson" -->
<!-- email="mwdestinystar@yahoo.co.uk" -->
<!-- subject="Shapers, protocols and timescales." -->
<!-- id="20040409123326.58601.qmail@web25110.mail.ukl.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Wilson (<a href="mailto:mwdestinystar@yahoo.co.uk?Subject=Re:%20Shapers,%20protocols%20and%20timescales."><em>mwdestinystar@yahoo.co.uk</em></a>)<br>
<strong>Date:</strong> Fri Apr 09 2004 - 06:33:26 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8462.html">Ben Goertzel: "RE: Shapers, protocols and timescales."</a>
<li><strong>Previous message:</strong> <a href="8460.html">Ben Goertzel: "RE: AI timeframes"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8462.html">Ben Goertzel: "RE: Shapers, protocols and timescales."</a>
<li><strong>Reply:</strong> <a href="8462.html">Ben Goertzel: "RE: Shapers, protocols and timescales."</a>
<li><strong>Reply:</strong> <a href="8463.html">Ben Goertzel: "RE: Shapers, protocols and timescales."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8461">[ date ]</a>
<a href="index.html#8461">[ thread ]</a>
<a href="subject.html#8461">[ subject ]</a>
<a href="author.html#8461">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Goertzel wrote;
<br>
<em>&gt; However, I do *not* believe Eliezer is hiding a correct design for
</em><br>
<em>&gt; an AGI due to security concerns.
</em><br>
<p><em>&gt;From <a href="http://www.sl4.org/bin/wiki.pl?SoYouWantToBeASeedAIProgrammer">http://www.sl4.org/bin/wiki.pl?SoYouWantToBeASeedAIProgrammer</a>;
</em><br>
<p>'You should have read through [Levels of Organization in General
<br>
&nbsp;Intelligence] and understood it fully. The AI theory we will actually
<br>
&nbsp;be using is deeper and less humanlike than the theory found in LOGI,
<br>
&nbsp;but LOGI will still help you prepare for encountering it.'
<br>
<p>That does seem to be the only information on the current SIAI project
<br>
architecture plans currently available to the public (plus whatever
<br>
you extract from reading between the lines of the relevant SL4 posts).
<br>
<p><em>&gt; If he has no time for concrete AI design it's because he has
</em><br>
<em>&gt; prioritized other types of Singularity-oriented work.
</em><br>
<p>True. LOGI-level stuff is actually a key part of Friendliness anyway,
<br>
as you can't be sure about goal system dynamics without a functional
<br>
account of the rest of the AI, but if you're equating 'concrete' to
<br>
'constructive' I agree.
<br>
<p><em>&gt;&gt; and has relatively little actual coding or architecture experience. 
</em><br>
<em>&gt;
</em><br>
<em>&gt; This one is a good point.
</em><br>
<p>Listen to the systems architect.
<br>
&nbsp;The systems architect is your friend. :)
<br>
<p>In reverse order;
<br>
<em>&gt; So far as I can tell there is nothing in Eli's AI framework that
</em><br>
<em>&gt; suggests a knowledge representation capable of being coupled with
</em><br>
<em>&gt; sufficiently powerful learning and reasoning algorithms to be used in
</em><br>
<em>&gt; this way.
</em><br>
<p>LOGI KR elements all represent regularities of some sort. Ignoring for
<br>
now the intricate meta-regularities and meta-patterns that assemble
<br>
them into an actual knowledge source (and allow generalised heuristics
<br>
instead of just completely specific Bayesian inference rules), the
<br>
learning and reasoning mechanisms are various sorts of directed
<br>
correlation search and perception of implied structures (from
<br>
deliberative inference down to the modality level; e.g. noticing that
<br>
two shapes are reflections of each other).
<br>
<p><em>&gt; Essentially, a shaper network requires a workable, learnable,
</em><br>
<em>&gt; reason-able representation of abstract content, which allows abstract
</em><br>
<em>&gt; bits of uncertain knowledge to interact with each other, to modify
</em><br>
<em>&gt; each other, to spawn actions, etc. 
</em><br>
<p>Unsurprisingly that sounds like an agent-based active memory
<br>
implementation, which is too general and powerful a system to be able
<br>
to say much from that one sentence description. I started with a
<br>
classic probabilistic inference network in which inconsistencies were
<br>
removed by heuristic repair (I tried various approaches); the repair
<br>
heuristics are the principles for reasoning about the morals (this
<br>
layering can be repeated indefinitely). I then started modelling
<br>
cognitive pressures to allow context-sensitive biasing of the general
<br>
happiness function (FARGish I know), and when that wasn't flexible
<br>
enough tried adding inference heuristics to do limited amounts of
<br>
production-system-esque network extension as an alternative method of
<br>
improving happiness. If I was feeling kind I might describe this sort
<br>
of messing about as 'open-ended experimentalism'; if not 'poorly
<br>
thought out hack and patch session' might be more appropriate.
<br>
<p>Doing that sort of thing on a live AGI with full-blown DE running would
<br>
be a seriously bad idea. I hope your experimental protocols will be
<br>
rather better considered. :)
<br>
<p><em>&gt; Novamente takes a different approach, using a &quot;probabilistic
</em><br>
<em>&gt; combinatory term logic&quot; approach to knowledge representation, and
</em><br>
<em>&gt; then using a special kind of probabilistic inference (with some
</em><br>
<em>&gt; relation to Hebbian learning) synthesized with evolutionary learning
</em><br>
<em>&gt; for learning/reasoning.
</em><br>
<p>There are several interesting ways to combine Bayesian inference and
<br>
directed evolution, but most of them have utility tree (goal system)
<br>
risks in a utilitarian LOGI/CFAI-derived AGI. I hate to think what
<br>
they'd do in a system that doesn't have a conceptually unified utility
<br>
function; I've heard rumours on the grapevine that you've been revising
<br>
Novamente to have a more conventional goal system and I sincerely
<br>
hope they're correct.
<br>
<p><em>&gt; But my point is that Eli's architecture gives a grand overall
</em><br>
<em>&gt; picture, but doesn't actually give a workable and *learnable and
</em><br>
<em>&gt; modifiable* way to represent complex knowledge.
</em><br>
<p>The constructive details are what the Flare project was working on.
<br>
Considerable additional progress has been made on LOGIesque KR
<br>
substrates since then (by various people).
<br>
<p><em>&gt; Of course it's easy to represent complex knowledge -- predicate logic
</em><br>
<em>&gt; does that, but it does so in a very brittle, non-learnable way.
</em><br>
<p>There are a lot of things I'd like to say on this, but I really
<br>
shouldn't right now. Thus some of my derived statements will be
<br>
irritatingly unsupported; sorry.
<br>
<p><em>&gt; That could be; but a lot of genius researchers are working on related
</em><br>
<em>&gt; but apparently EASIER questions in complex systems dynamics, without
</em><br>
<em>&gt; making very rapid progress...
</em><br>
<p>Self-modifying goal systems are a considerably specialised and
<br>
constrained form of complex dynamic system, ones based on 'pure'
<br>
Bayesian utility theory particularly so.
<br>
<p><em>&gt; Anyway, frankly, you do not know nearly enough about the architecture
</em><br>
<em>&gt; to know if it needs revision or not.
</em><br>
<p>It's true, despite recruiting the best industrial spies money can
<br>
buy, my information remains incomplete and years out of date ;&gt;
<br>
<p>I'll just have to wait for the book :)
<br>
<p><em>&gt; I'll email you off-list some stuff about network security that I
</em><br>
<em>&gt; wrote about a year ago, when I was thinking about getting into that
</em><br>
<em>&gt; area.
</em><br>
<p>Thanks.
<br>
<p><em>&gt; Hm.... I had a long argument about this with my girlfriend (who is
</em><br>
<em>&gt; also a Novamente programmer/scientist), a couple weeks ago.
</em><br>
<em>&gt;
</em><br>
<em>&gt; She at first argued for a 30-40 year timeframe, whereas I argued for
</em><br>
<em>&gt; 5-10
</em><br>
<p>Timescales are the most unreliable part of a unreliable branch of the
<br>
generally unreliable business of predicting technological progress.
<br>
That said, SIAI project completion within 5 years of the starting gun
<br>
seems entirely reasonable to me. When that gun will be fired, I am not
<br>
in a position to predict.
<br>
<p><em>&gt; In the end she agreed that 8-10 years was plausible and 15 years was
</em><br>
<em>&gt; fairly likely
</em><br>
<p>Do you really think it's possible to make that sort of prediction
<br>
without a deep knowledge of performance of candidate architectures on
<br>
all the relevant cognitive competence hurdles?
<br>
<p><em>&gt; I still believe that 5 years from now or even 3 years from now is not
</em><br>
<em>&gt; absurd to think about.
</em><br>
<p>Tomorrow is not unreasonable to think about if you're willing to
<br>
consider the various unpleasant (and probably fatal) shortcuts
<br>
available.
<br>
<p>&nbsp;* Michael Wilson
<br>
<p>'For every complex problem, there is a solution that is simple,
<br>
&nbsp;neat and wrong.' - H.L. Mencken
<br>
<p><p><p><p><p><p><p><p><p>.
<br>
<p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
____________________________________________________________
<br>
Yahoo! Messenger - Communicate instantly...&quot;Ping&quot; 
<br>
your friends today! Download Messenger Now 
<br>
<a href="http://uk.messenger.yahoo.com/download/index.html">http://uk.messenger.yahoo.com/download/index.html</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8462.html">Ben Goertzel: "RE: Shapers, protocols and timescales."</a>
<li><strong>Previous message:</strong> <a href="8460.html">Ben Goertzel: "RE: AI timeframes"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8462.html">Ben Goertzel: "RE: Shapers, protocols and timescales."</a>
<li><strong>Reply:</strong> <a href="8462.html">Ben Goertzel: "RE: Shapers, protocols and timescales."</a>
<li><strong>Reply:</strong> <a href="8463.html">Ben Goertzel: "RE: Shapers, protocols and timescales."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8461">[ date ]</a>
<a href="index.html#8461">[ thread ]</a>
<a href="subject.html#8461">[ subject ]</a>
<a href="author.html#8461">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
