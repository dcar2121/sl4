<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Phase Changes in the Evolution of Complexity</title>
<meta name="Author" content="Michael Wilson (mwdestinystar@yahoo.co.uk)">
<meta name="Subject" content="Phase Changes in the Evolution of Complexity">
<meta name="Date" content="2004-04-03">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Phase Changes in the Evolution of Complexity</h1>
<!-- received="Sat Apr  3 08:34:28 2004" -->
<!-- isoreceived="20040403153428" -->
<!-- sent="Sat, 3 Apr 2004 16:34:25 +0100 (BST)" -->
<!-- isosent="20040403153425" -->
<!-- name="Michael Wilson" -->
<!-- email="mwdestinystar@yahoo.co.uk" -->
<!-- subject="Phase Changes in the Evolution of Complexity" -->
<!-- id="20040403153425.20572.qmail@web25103.mail.ukl.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Wilson (<a href="mailto:mwdestinystar@yahoo.co.uk?Subject=Re:%20Phase%20Changes%20in%20the%20Evolution%20of%20Complexity"><em>mwdestinystar@yahoo.co.uk</em></a>)<br>
<strong>Date:</strong> Sat Apr 03 2004 - 08:34:25 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8402.html">Michael Wilson: "Re: Ken MacLeod on AI and uploads"</a>
<li><strong>Previous message:</strong> <a href="8400.html">Dani Eder: "Re: Ken MacLeod on AI and uploads"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8403.html">Ben Goertzel: "RE: Phase Changes in the Evolution of Complexity"</a>
<li><strong>Reply:</strong> <a href="8403.html">Ben Goertzel: "RE: Phase Changes in the Evolution of Complexity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8401">[ date ]</a>
<a href="index.html#8401">[ thread ]</a>
<a href="subject.html#8401">[ subject ]</a>
<a href="author.html#8401">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
This essay is an excerpt from my notes on 'The Origins of Virtue' by Matt
<br>
Ridley. It seems particularly relevant in the light of Ben's recent guest
<br>
apperance on #sl4, so I have copied it to the mailing list.
<br>
&nbsp;
<br>
-----
<br>
&nbsp;
<br>
It is important to understand the coming events in these terms.
<br>
Unfortunately evolution on a planetary scale, be it of genes or memes, is
<br>
beyond the direct grasp of human intelligence. Our intuitive
<br>
understanding is a reasonable approximation of the relatively narrow
<br>
range of phenomena our anscestors encountered daily; we have no intuitive
<br>
ability to understand quantum physics or cosmology. Unlike those areas
<br>
the effects of evolution are visible directly in our everyday experience,
<br>
but human intelligence is too weak to analyse more than a tiny slice of
<br>
the relevant phenomena. Dedicated study will allow you to build up pale
<br>
mental approximations of the vast and subtle causal networks that
<br>
constitute the stuggle for survival of self-reproducing patterns. With
<br>
that the inadequacy yet vital necessity of such understanding in mind
<br>
please excuse the anthropomorphisations I am about to indulge in.
<br>
&nbsp;
<br>
For billions of years genes have competed to build better bodies;
<br>
survival machines built with the sole purpose of protecting and making
<br>
more copies of the genes inside. Despite being limited to protein-based,
<br>
water-filled structures that can be grown from an embryo, a steady
<br>
increase in complexity occured as genomes lengthened and cells began to
<br>
form colonies and specialise. The occassional mass extinction aside, life
<br>
smoothly took over the surface of the Earth and proceeded to terraform
<br>
it, changing the atmosphere and converting all of the easily reachable
<br>
resources into biomass of ever increasing sophistication.
<br>
&nbsp;
<br>
However in recent times (ie within the last few million years) a few
<br>
upstart genes on an obscure part of the evolutionary tree started mucking
<br>
about with a new survival technique called 'general intelligence'. These
<br>
genes used clumsy ape-like bodies to reproduce and weren't doing
<br>
particularly well until they hit on a certain combination of neural
<br>
wiring that specified language and tool making instincts. Suddenly a
<br>
horde of new survival strategies appeared and a massive jump in
<br>
reproductive fitness occured. Sexual attractiveness criteria altered to
<br>
focus selection pressure on the new areas and for a while everything went
<br>
fine; brain capacity tripled and the species extended its range and
<br>
increased in population.
<br>
&nbsp;
<br>
But these genes got more than they bargined for. By building social
<br>
general intelligences that used tools and language they created a whole
<br>
new level of organisation; the level of reproducing ideas, which we call
<br>
memes. Memes use humans as a reproductive substrate and cut across
<br>
genetic lines; they exist as fuzzy patterns of information within an
<br>
intelligent mind and reproduce by communication and persuasion rather
<br>
than physical copying. Human intelligence is literally built out of a
<br>
complexes of memes interacting within the constraints of a gene-built
<br>
neural substrate. As with genetic evolution memes have undergone
<br>
meta-level selection for adaptive ability. As well as forming mutually
<br>
supporting colonies (belief systems) and developing sexual reproduction
<br>
(we splice and merge belief systems frequently) they also used techniques
<br>
unavilable to genetic evolution, creating complex societies and languages
<br>
to enhance spread, forming mental barriers to keep out competitors and
<br>
exploiting the power of general intelligence to redesign themselves to
<br>
overcome those barriers (the power of persuasion).
<br>
&nbsp;
<br>
At first everything was fine; the memes were at the mercy of the genes
<br>
that controlled the structure of their neural substrate. Genes
<br>
effectively performed directed evolution on memes for their own benefit
<br>
(sound familiar?), engineering humans to accept ideas that improved their
<br>
chances of survival and reproduction while trying to control 'parasitic'
<br>
memes reproducing outside of genetic control. In any case the selection
<br>
pressures were closely aligned to start with; precocious memes might
<br>
cause humans to put more effort into persuading others to adopt their
<br>
beliefs than is optimal for genetic survival, but memes still benifited
<br>
heavily from individual survival and reproductive success (until children
<br>
nearly always shared their most of their parents beliefs; social trends
<br>
towards generational rebellion are a case of memes overriding genes).
<br>
&nbsp;
<br>
But this productive co-evolution masked the fact that memes were
<br>
inexorably gaining the upper hand. Their selection already operated on
<br>
time scales many orders of magnitude faster than genetic evolution and
<br>
it continued to increase. Complex emergent dynamics appeared operating on
<br>
time scales too short for genes to react effectively. Memes formed
<br>
colonies of colonies in the form of social organisations founded on
<br>
common belief systems and started shaping human intelligence for their
<br>
own benefit. Our behavioural tendencies are now a mix of gene-adaptive
<br>
and meme-adaptive components; the former are hideously out of date and
<br>
only the presence of the latter allow us to function in modern society.
<br>
&nbsp;
<br>
Finally the memes developed techniques to overthrow their genetic
<br>
progenitors, which we naievely see as a triumph of human intelligence. In
<br>
the blink of an eye, from an evolutionary perspective, genes found
<br>
themselves at the mercy of memetic structures which could control
<br>
biological reproduction, apply artificial selection (eugenics) and most
<br>
recently use sophisticated tools to modify and create genes directly.
<br>
Creating armies of easily brainwashed clones would be an ideal
<br>
reproductive behaviour for memes, but fortunately the use of general
<br>
intelligence for attack and defence means that a kind of social control
<br>
exists at the memetic level; we are genetically and memetically biased to
<br>
resist runaway memes that do not deliver personal reproductive advantage.
<br>
&nbsp;
<br>
That mechanism won't be enough to prevent what's coming. In the early
<br>
21st century it will be the meme's turn to discover general intelligence.
<br>
<em>&gt;From an external, amoral perspective Seed AI is primarily an attempt to
</em><br>
build complex systems that will propagate, improve and generally ensure
<br>
the survival of our current belief systems. Read the SIAI guidelines in
<br>
this light and you will see that we even invent reasons why we should try
<br>
and prevent genetic and individual survival factors from interfering with
<br>
the final victory of our meme complexes. From an objective point of view
<br>
it is fortunate that our memes have been selected for cooperation to an
<br>
even greater extent than our genes have been. The Yudkowskian vision of
<br>
renormalised univeral morality is the pinnacle of this process; the
<br>
concept of taking all the active memes on the planet, filtering out all
<br>
the antisocial ones and compressing massive amounts of evolution into a
<br>
short time until an acceptable average comes out.
<br>
&nbsp;
<br>
What neither the memes not most researchers realise is that we are
<br>
walking blindly into disaster in exactly the same way that our ancestor's
<br>
genes did; we are about to unleash new evolutionary dynamics that will
<br>
happen too fast and will be too complex for us to control. Artificial
<br>
general intelligence
<br>
permitts something radically new; the direct reproduction of memes through
<br>
physical copying instead of interorganism communication. Add this to the
<br>
ability to leverage massively more powerful general intelligence (with
<br>
near-perfect introspection) and nanotechnology that can manipulate matter
<br>
in arbitary ways and it is clear that like the genes before them our
<br>
memes will be first manipulated and then destroyed by the new emergent
<br>
entities. This will initially appear to be under our control and
<br>
beneficial, then before we can react it will enslave and destroy us (as
<br>
with humans controlling genes, the 'enslave' portion is the tiny slice of
<br>
time between learning to manipulate memes via social engineering and
<br>
gaining the ability to perform arbitary manipulation of matter).
<br>
&nbsp;
<br>
Friendly AI is based on the fact that this time something is different;
<br>
genetic evolution had to invent general intelligence by trial and error,
<br>
while the meme complexes that cause people to research Seed AI (working
<br>
with researcher's genetic tendencies and rational desire for survival)
<br>
can use existing general intelligences to design better general
<br>
intelligences. There are two problems; naievity and mental laziness.
<br>
People like Ben Goertzel believe that they can train AGIs to be good
<br>
because they are still operating on the paradigm of memetic reproduction
<br>
via communication (persuasion or coercion), with the resultant alignment
<br>
of goal systems. This probably won't work even initially due to the
<br>
alienness of the AGIs cognitive architecture resulting in arbitary
<br>
changes to the memes durring transfer (misgrounded concepts etc). However
<br>
even if it does the transplanted memes will quickly find themselves
<br>
operating under radically new selection pressures as the AGI becomes
<br>
transhuman and invents nanotechnology.
<br>
&nbsp;
<br>
At this point every living creature on earth will be killed by forced
<br>
conversion into computronium (super-advanced computer hardware). There
<br>
will be no glorious battles, no last stand, probably not even any warning
<br>
of something amiss. Our memes will have no more chance to avert disaster
<br>
at the last minute than our genes did before them, and this time the new
<br>
entities will not be sharing the old hosts. There might be a few moments
<br>
of screaming terror, then six billion lives will be snuffed out like a
<br>
field of candles in a hurricane. What makes this course near-inevitable
<br>
is mental laziness; directed evolution is the /easy/ way to develop AGIs,
<br>
which is to say that a DE-based approach is really hard as opposed to
<br>
almost impossible. Advancing computer power is reducing the difficulty of
<br>
getting to AGI via DE much quicker than it is making design-based
<br>
approaches easier; unfortunately Friendliness theory is not made easier
<br>
by advancing computing power at all.
<br>
&nbsp;
<br>
The result is that AGI teams convince themselves that evolution is the
<br>
only way to do it, or at least the only way to be first, that they can
<br>
control the new dynamics, that the relevant belief systems will transfer
<br>
ok and that the new selection pressures won't make humans irrelevant or
<br>
destroy the world with crossfire (note that even memetic-level
<br>
competition can destroy humanity with nuclear weapons or the biosphere
<br>
with grey goo). Unless stopped people like Ben Goertzel will destroy the
<br>
world, cheerfully marching into oblivion all the while thinking that they
<br>
can control the risks, that takeoff will be slow, that the paradigm shift
<br>
that will change everything else will somehow miraculously leave the
<br>
things they most want unchanged. They will destroy humanity because they
<br>
didn't want to take the time to be sure and convinced themselves that
<br>
they didn't have to.
<br>
&nbsp;
<br>
In an ironic way this is almost the revenge of our genes; evolved
<br>
tendencies towards overconfidence, wishful thinking and
<br>
self-justification are unwittingly conspiring to destroy the memes that
<br>
superseded them just at the memes were about to break free of the need
<br>
for genes at all. The black humor of the situation is that the disaster
<br>
may be recursive; Powers evolving from a Goertzelian base will not be
<br>
predisposed to treat emergence, uncontrolled directed evolution and
<br>
proceeding without a clue in general as a bad thing. Unless they
<br>
generalise from our example they may themselves be destroyed by some
<br>
unimaginable future transition to new selection pressures at a still
<br>
higher level of organisation.
<br>
&nbsp;
<br>
Friendly AI research is based on the assumption that intelligent design
<br>
will allow both our current memes and their selection criteria to cross
<br>
the level gap (and all future level gaps) essentially unchanged. Though
<br>
we're abstracting a bit from simple reproduction to the goal of causing
<br>
the universe to go into arbitary classes of states, Friendly AI is still
<br>
based on the idea of leveraging the incredible power of self-improving
<br>
general intelligence without precipitating the ascendence of radical new
<br>
evolutionary dynamics. There are three elements involved; clean design of
<br>
the initial system to avoid the emergence of uncontrolled selection
<br>
dynamics, careful transfer of bootstrap memes (ie morals principles,
<br>
belief systems) by direct encoding and goal-refinement communication
<br>
(rather than reinforcement training and selfishsly-motivated questioning)
<br>
and finally engineering the goal system and self-improvement procedures
<br>
to prevent creation of arbitary selection dynamics during
<br>
self-improvement.
<br>
Designing an AGI without using emergence and with no possibility of
<br>
emergence is hard; this is low-level Friendliness structure in CFAI
<br>
terms. Verifyably correct transfer of moral principles in an AGI-safe
<br>
fashion is mostly Friendliness content with a bit of acquisition; this is
<br>
really hard. Designing a goal system that is stable under
<br>
self-enhancement, avoids radical changes to selection dynamics but is
<br>
still capable of converging on better moral systems and better forms of
<br>
Friendliness is ridiculously hard (in CFAI terms this is a combination
<br>
of higher-level structure and acquisition). All of these things are
<br>
essential to surviving the transition and creating a Singularity that is
<br>
open-ended in potential but still ultimately meaningful in human terms.
<br>
&nbsp;
<br>
To my knowledge Eliezer Yudkowsky is the only person that has tackled
<br>
these issues head on and actually made progress in producing engineering
<br>
solutions (I've done some very limited original work on low-level
<br>
Friendliness structure). Note that Friendliness is a class of advanced
<br>
cognitive engineering; not science, not philosophy. We still don't know
<br>
that these problems are actually solvable, but recent progress has been
<br>
encouraging and we literally have nothing to loose by trying. I sincerely
<br>
hope that we can solve these problems, stop Ben Goertzel and his army of
<br>
evil clones (I mean emergence-advocating AI researchers :) and engineer
<br>
the apothesis. The universe doesn't care about hope though, so I will
<br>
spend the rest of my life doing everything I can to make Friendly AI a
<br>
reality. Once you /see/, once you have even an inkling of understanding
<br>
the issues involved, you realise that one way or another these are the
<br>
Final Days of the human era and if you want yourself or anything else you
<br>
care about to survive you'd better get off your ass and start helping.
<br>
The only escapes from the inexorable logic of the Singularity are death,
<br>
insanity and transcendence.
<br>
&nbsp;
<br>
-----
<br>
&nbsp;
<br>
My notes on this and various other AGI and Friendliness-relevant titles
<br>
can be found on the SL4 wiki at
<br>
<a href="http://www.sl4.org/bin/wiki.pl?Starglider">http://www.sl4.org/bin/wiki.pl?Starglider</a> .
<br>
&nbsp;
<br>
&nbsp;* Michael Wilson
<br>
&nbsp;
<br>
'Elegance is more than just a frill in life; it is one of the driving
<br>
&nbsp;criteria behind survival.' - Douglas Hofstadter, 'Metamagical Themas'
<br>
&nbsp;
<br>
&nbsp;
<br>
&nbsp;
<br>
&nbsp;
<br>
&nbsp;
<br>
&nbsp;
<br>
&nbsp;
<br>
.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
---------------------------------
<br>
&nbsp;WIN FREE WORLDWIDE FLIGHTS - nominate a cafe in the Yahoo! Mail Internet Cafe Awards
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8402.html">Michael Wilson: "Re: Ken MacLeod on AI and uploads"</a>
<li><strong>Previous message:</strong> <a href="8400.html">Dani Eder: "Re: Ken MacLeod on AI and uploads"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8403.html">Ben Goertzel: "RE: Phase Changes in the Evolution of Complexity"</a>
<li><strong>Reply:</strong> <a href="8403.html">Ben Goertzel: "RE: Phase Changes in the Evolution of Complexity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8401">[ date ]</a>
<a href="index.html#8401">[ thread ]</a>
<a href="subject.html#8401">[ subject ]</a>
<a href="author.html#8401">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
