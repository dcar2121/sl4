<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))</title>
<meta name="Author" content="M.>h (m.transhumanist@gmail.com)">
<meta name="Subject" content="Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))">
<meta name="Date" content="2009-12-06">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))</h1>
<!-- received="Sun Dec  6 23:58:24 2009" -->
<!-- isoreceived="20091207065824" -->
<!-- sent="Mon, 7 Dec 2009 07:58:00 +0100" -->
<!-- isosent="20091207065800" -->
<!-- name="M.>h" -->
<!-- email="m.transhumanist@gmail.com" -->
<!-- subject="Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))" -->
<!-- id="D9BF0045-9DA5-4C2F-9288-828A8749EEB2@gmail.com" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="676371.16890.qm@web65704.mail.ac4.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> M.>h (<a href="mailto:m.transhumanist@gmail.com?Subject=Re:%20Copying%20nonsense%20(was%20Re:%20[sl4]%20Uploading%20(was%20:%20goals%20of%20AI))"><em>m.transhumanist@gmail.com</em></a>)<br>
<strong>Date:</strong> Sun Dec 06 2009 - 23:58:00 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20921.html">Glenn Neff: "[sl4] I saved the world.  I can prove it."</a>
<li><strong>Previous message:</strong> <a href="20919.html">Stathis Papaioannou: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<li><strong>In reply to:</strong> <a href="20914.html">Thomas Buckner: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20932.html">Matt Mahoney: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<li><strong>Reply:</strong> <a href="20932.html">Matt Mahoney: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20920">[ date ]</a>
<a href="index.html#20920">[ thread ]</a>
<a href="subject.html#20920">[ subject ]</a>
<a href="author.html#20920">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
... sorry, but i do not get the whole problem. even if a clone of me  
<br>
would walk up to me right here and now, having sufficiently enough of  
<br>
my memories and claiming to have my 'identity', i would not care if  
<br>
this 'double' would not use my resources (e.g. credit card) and  
<br>
bureaucrats would leave me alone!
<br>
<p>cheers,
<br>
<p>miriam
<br>
<p><p><p>Am 06.12.2009 um 22:12 schrieb Thomas Buckner &lt;<a href="mailto:tcbevolver@yahoo.com?Subject=Re:%20Copying%20nonsense%20(was%20Re:%20[sl4]%20Uploading%20(was%20:%20goals%20of%20AI))">tcbevolver@yahoo.com</a>&gt;:
<br>
<p><em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; From: Matt Mahoney &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20Copying%20nonsense%20(was%20Re:%20[sl4]%20Uploading%20(was%20:%20goals%20of%20AI))">matmahoney@yahoo.com</a>&gt;
</em><br>
<em>&gt; To: <a href="mailto:sl4@sl4.org?Subject=Re:%20Copying%20nonsense%20(was%20Re:%20[sl4]%20Uploading%20(was%20:%20goals%20of%20AI))">sl4@sl4.org</a>
</em><br>
<em>&gt; Sent: Sun, December 6, 2009 2:44:53 PM
</em><br>
<em>&gt; Subject: Re: Copying nonsense (was Re: [sl4] Uploading (was : goals  
</em><br>
<em>&gt; of AI))
</em><br>
<em>&gt;
</em><br>
<em>&gt; Rewot Fetterkey wrote:
</em><br>
<em>&gt; &gt; Can you clarify that? How, exactly, is consciousness nonexistent?
</em><br>
<em>&gt;
</em><br>
<em>&gt; By consciousness, I mean that which makes you different from a  
</em><br>
<em>&gt; philosophical zombie as described in <a href="http://en.wikipedia.org/wiki/Philosophical_zombie">http://en.wikipedia.org/wiki/Philosophical_zombie</a>
</em><br>
<em>&gt; But by definition, a zombie is not distinguishable from you at all.  
</em><br>
<em>&gt; I really don't know how much more clear the logic could be.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The problem arises because all animals, including those that have no  
</em><br>
<em>&gt; concept of death, have evolved a fear of those things that can kill  
</em><br>
<em>&gt; them. Humans do have such a concept, which we associate with a lack  
</em><br>
<em>&gt; of conscious experience. So we all desperately want to preserve this  
</em><br>
<em>&gt; thing that does not exist. We can't help it. We are programmed that  
</em><br>
<em>&gt; way.
</em><br>
<em>&gt;
</em><br>
<em>&gt; One way to deal with this conflict is to argue that the zombie  
</em><br>
<em>&gt; argument is wrong and create ever more convoluted arguments to  
</em><br>
<em>&gt; refute it. My preferred approach is as follows:
</em><br>
<em>&gt;
</em><br>
<em>&gt; 1. I believe that I have conscious experience. (I am programmed to).
</em><br>
<em>&gt; 2. I know that conscious experience does not exist.. (Logic  
</em><br>
<em>&gt; irrefutably says so).
</em><br>
<em>&gt; 3. I realize that 1 and 2 are inconsistent. I leave it at that.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; -- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20Copying%20nonsense%20(was%20Re:%20[sl4]%20Uploading%20(was%20:%20goals%20of%20AI))">matmahoney@yahoo.com</a>
</em><br>
<em>&gt;
</em><br>
<em>&gt; I'm with Daniel Dennet on this: the P-zombie is (to paraphrase an  
</em><br>
<em>&gt; earlier poster) 2+2 = 5. Purely hypothetical, a character in a  
</em><br>
<em>&gt; gendankenexperiment, The Man Who Wasn't There. In practice, any  
</em><br>
<em>&gt; creature with a human brain that could say &quot;Ouch, that hurt&quot; has an  
</em><br>
<em>&gt; internal process isomorphic to what we experience as consciousness.  
</em><br>
<em>&gt; Please see my post of a few hours ago on the Edge talk.  <a href="http://www.edge.org/3rd_culture/dehaene09/dehaene09_index.html">http://www.edge.org/3rd_culture/dehaene09/dehaene09_index.html</a>
</em><br>
<em>&gt; Consciousness in the human brain is a global pattern of activation  
</em><br>
<em>&gt; and we now have methods of scanning and can say whether that pattern  
</em><br>
<em>&gt; appears or not. This scanning has been applied to comatose/ 
</em><br>
<em>&gt; vegetative patients. From Dr. Dehaene's talk:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;Let me just give you a very basic idea about the test. We stimulate  
</em><br>
<em>&gt; the patient with five tones. The first four tones are identical, but  
</em><br>
<em>&gt; the fifth can be different. So you hear something like dit-dit-dit- 
</em><br>
<em>&gt; dit-tat. When you do this, a very banal observation, dating back 25  
</em><br>
<em>&gt; years, is that the brain reacts to the different tone at the end.  
</em><br>
<em>&gt; That reaction, which is called mismatch negativity, is completely  
</em><br>
<em>&gt; automatic. You get it even in coma, in sleep, or when you do not  
</em><br>
<em>&gt; attend to the stimulus. It's a non-conscious response.
</em><br>
<em>&gt; Following it, however, there is also, typically, a later brain  
</em><br>
<em>&gt; response called the P3. This is exactly the large-scale global  
</em><br>
<em>&gt; response that we found in our previous experiments, that must be  
</em><br>
<em>&gt; specifically associated with consciousness.
</em><br>
<em>&gt;  (snip)
</em><br>
<em>&gt; The P3 response (a marker is absent in coma patients. It is also  
</em><br>
<em>&gt; gone in most vegetative state patients â€” but it remains present in m 
</em><br>
<em>&gt; ost minimally conscious patients. It is always present in locked-in  
</em><br>
<em>&gt; patients and in any other conscious subject.&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Consciousness, according to Dr. Dehaene's findings, is how the human  
</em><br>
<em>&gt; brain gets around certain limitations of being an analog computer.  
</em><br>
<em>&gt; If you've read Eliezer Yudkowsky's posts you'll know that his  
</em><br>
<em>&gt; approach to AGI would not necessarily call for the AGI to be  
</em><br>
<em>&gt; conscious in the sense we understand. I recall he said &quot;I'm not  
</em><br>
<em>&gt; looking for the AGI to be a new drinking buddy, at least not at  
</em><br>
<em>&gt; first&quot; or words close to that. Paramount, to him, is that the AGI be  
</em><br>
<em>&gt; Friendly, and not damage us intentionally or otherwise. While the  
</em><br>
<em>&gt; human brain is a kind of analog computer, and much research is now  
</em><br>
<em>&gt; afoot to emulate it on digital computers, our minds are not exactly  
</em><br>
<em>&gt; computer programs. They are certainly not fungible programs running  
</em><br>
<em>&gt; on a general computing machine, but rather embedded in the  
</em><br>
<em>&gt; structure. The mind is not fungible unless the neural structure is  
</em><br>
<em>&gt; made fungible, which may or may not ever be possible.
</em><br>
<em>&gt; To sum up, there's no real-world way a zombie could react as if  
</em><br>
<em>&gt; conscious, using human brain architecture, without being conscious.  
</em><br>
<em>&gt; Unless you believe in magic. And the subject of zombies, even if  
</em><br>
<em>&gt; such could exist, probably doesn't really apply to the problems of  
</em><br>
<em>&gt; building an AGI.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Tom Buckner
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20921.html">Glenn Neff: "[sl4] I saved the world.  I can prove it."</a>
<li><strong>Previous message:</strong> <a href="20919.html">Stathis Papaioannou: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<li><strong>In reply to:</strong> <a href="20914.html">Thomas Buckner: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20932.html">Matt Mahoney: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<li><strong>Reply:</strong> <a href="20932.html">Matt Mahoney: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20920">[ date ]</a>
<a href="index.html#20920">[ thread ]</a>
<a href="subject.html#20920">[ subject ]</a>
<a href="author.html#20920">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:05 MDT
</em></small></p>
</body>
</html>
