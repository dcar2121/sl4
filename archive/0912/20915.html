<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))</title>
<meta name="Author" content="Matt Mahoney (matmahoney@yahoo.com)">
<meta name="Subject" content="Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))">
<meta name="Date" content="2009-12-06">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))</h1>
<!-- received="Sun Dec  6 15:47:12 2009" -->
<!-- isoreceived="20091206224712" -->
<!-- sent="Sun, 6 Dec 2009 14:46:48 -0800 (PST)" -->
<!-- isosent="20091206224648" -->
<!-- name="Matt Mahoney" -->
<!-- email="matmahoney@yahoo.com" -->
<!-- subject="Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))" -->
<!-- id="464488.56748.qm@web51904.mail.re2.yahoo.com" -->
<!-- charset="utf-8" -->
<!-- inreplyto="676371.16890.qm@web65704.mail.ac4.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Matt Mahoney (<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20Copying%20nonsense%20(was%20Re:%20[sl4]%20Uploading%20(was%20:%20goals%20of%20AI))"><em>matmahoney@yahoo.com</em></a>)<br>
<strong>Date:</strong> Sun Dec 06 2009 - 15:46:48 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20916.html">Stathis Papaioannou: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<li><strong>Previous message:</strong> <a href="20914.html">Thomas Buckner: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<li><strong>In reply to:</strong> <a href="20914.html">Thomas Buckner: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20917.html">Randall Randall: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<li><strong>Reply:</strong> <a href="20917.html">Randall Randall: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20915">[ date ]</a>
<a href="index.html#20915">[ thread ]</a>
<a href="subject.html#20915">[ subject ]</a>
<a href="author.html#20915">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Thomas Buckner wrote:
&gt; The P3 response (a marker is absent in coma patients. It is also gone in most vegetative state patients — but it remains present in most minimally conscious patients. It is always present in locked-in patients and in any other conscious subject.&quot;

Again, by &quot;consciousness&quot; I am not referring to the observable aspects, such as being awake vs. asleep. The word has more than one meaning, which causes confusion. What I claim doesn't exist is qualia, the aspect of having experience that is different from just writing into your brain's memory. The fact that we can even imagine a philosophical zombie is evidence for belief in qualia. There are two issues, really.

1. the belief that you have qualia and fear losing it (by dying).
2. the belief that it is unethical to kill anything that has qualia.

To illustrate. Suppose there was a program that observed you for many years and learned to predict your responses in a Turing test environment so well that none of your friends or relatives could tell the difference between it and you.

2. Would it be unethical (equivalent to murder) to stop the program and delete it?
1. Is the program &quot;you&quot;? If you were killed, would you continue to have experience as this program?

Most people would give answers that indicate a belief in qualia and that the program is a zombie. Do you?

 -- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20Copying%20nonsense%20(was%20Re:%20[sl4]%20Uploading%20(was%20:%20goals%20of%20AI))">matmahoney@yahoo.com</a>




________________________________
From: Thomas Buckner &lt;<a href="mailto:tcbevolver@yahoo.com?Subject=Re:%20Copying%20nonsense%20(was%20Re:%20[sl4]%20Uploading%20(was%20:%20goals%20of%20AI))">tcbevolver@yahoo.com</a>&gt;
To: <a href="mailto:sl4@sl4.org?Subject=Re:%20Copying%20nonsense%20(was%20Re:%20[sl4]%20Uploading%20(was%20:%20goals%20of%20AI))">sl4@sl4.org</a>
Sent: Sun, December 6, 2009 4:12:16 PM
Subject: Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))







________________________________
From: Matt Mahoney &lt;<a href="mailto:matmahoney@yahoo.com?Subject=Re:%20Copying%20nonsense%20(was%20Re:%20[sl4]%20Uploading%20(was%20:%20goals%20of%20AI))">matmahoney@yahoo.com</a>&gt;
To: <a href="mailto:sl4@sl4.org?Subject=Re:%20Copying%20nonsense%20(was%20Re:%20[sl4]%20Uploading%20(was%20:%20goals%20of%20AI))">sl4@sl4.org</a>
Sent: Sun, December 6, 2009 2:44:53 PM
Subject: Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))


Rewot Fetterkey wrote:
&gt; Can you clarify that? How, exactly, is consciousness nonexistent?

By consciousness, I mean that which makes you different from a philosophical zombie as described in <a href="http://en.wikipedia.org/wiki/Philosophical_zombie">http://en.wikipedia.org/wiki/Philosophical_zombie</a>
But by definition, a zombie is not distinguishable from you at all. I really don't know how much more clear the logic could be.

The problem arises because all animals, including those that have no concept of death, have evolved a fear of those things that can kill them. Humans do have such a concept, which we associate with a lack of conscious experience. So we all desperately want to preserve this thing that does not exist. We can't help it. We are programmed that way.

One way to deal with this conflict is to argue that the zombie argument is wrong and create ever more convoluted arguments to refute it. My preferred approach is as follows:

1. I believe that I have conscious experience. (I am programmed to).
2. I know that conscious experience does not exist.. (Logic irrefutably says so).
3. I realize that 1 and 2 are inconsistent. I leave it at that.

 -- Matt Mahoney, <a href="mailto:matmahoney@yahoo.com?Subject=Re:%20Copying%20nonsense%20(was%20Re:%20[sl4]%20Uploading%20(was%20:%20goals%20of%20AI))">matmahoney@yahoo.com</a>

I'm with Daniel Dennet on this: the P-zombie is (to paraphrase an earlier poster) 2+2 = 5. Purely hypothetical, a character in a gendankenexperiment, The Man Who Wasn't There. In practice, any creature with a human brain that could say &quot;Ouch, that hurt&quot; has an internal process isomorphic to what we experience as consciousness. Please see my post of a few hours ago on the Edge talk.  <a href="http://www.edge.org/3rd_culture/dehaene09/dehaene09_index.html">http://www.edge.org/3rd_culture/dehaene09/dehaene09_index.html</a>

Consciousness in the human brain is a global pattern of activation and we now have methods of scanning and can say whether that pattern appears or not. This scanning has been applied to comatose/vegetative patients. From Dr. Dehaene's talk: 

&quot;Let me just give you a very basic idea about the test. We stimulate the patient with five tones. The first four tones are identical, but the fifth can be different. So you hear something like dit-dit-dit-dit-tat. When you do this, a very banal observation, dating back 25 years, is that the brain reacts to the different tone at the end. That reaction, which is called mismatch negativity, is completely automatic. You get it even in coma, in sleep, or when you do not attend to the stimulus. It's a non-conscious response.
Following it, however, there is also, typically, a later brain response called the P3. This is exactly the large-scale global response that we found in our previous experiments, that must be specifically associated with consciousness.
 (snip)
The P3 response (a marker is absent in coma patients. It is also gone in most vegetative state patients — but it remains present in most minimally conscious patients. It is always present in locked-in patients and in any other conscious subject.&quot;

Consciousness, according to Dr. Dehaene's findings, is how the human brain gets around certain limitations of being an analog computer. If you've read Eliezer Yudkowsky's posts you'll know that his approach to AGI would not necessarily call for the AGI to be conscious in the sense we understand. I recall he said &quot;I'm not looking for the AGI to be a new drinking buddy, at least not at first&quot; or words close to that. Paramount, to him, is that the AGI be Friendly, and not damage us intentionally or otherwise. While the human brain is a kind of analog computer, and much research is now afoot to emulate it on digital computers, our minds are not exactly computer programs. They are certainly not fungible programs running on a general computing machine, but rather embedded in the structure. The mind is not fungible unless the neural structure is made fungible, which may or may not ever be possible.
To sum up, there's no real-world way a zombie could react as if conscious, using human brain architecture, without being conscious. Unless you believe in magic. And the subject of zombies, even if such could exist, probably doesn't really apply to the problems of building an AGI.

Tom Buckner

<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20916.html">Stathis Papaioannou: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<li><strong>Previous message:</strong> <a href="20914.html">Thomas Buckner: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<li><strong>In reply to:</strong> <a href="20914.html">Thomas Buckner: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20917.html">Randall Randall: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<li><strong>Reply:</strong> <a href="20917.html">Randall Randall: "Re: Copying nonsense (was Re: [sl4] Uploading (was : goals of AI))"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20915">[ date ]</a>
<a href="index.html#20915">[ thread ]</a>
<a href="subject.html#20915">[ subject ]</a>
<a href="author.html#20915">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:05 MDT
</em></small></p>
</body>
</html>
