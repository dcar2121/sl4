<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: META: Killthread; (Re: Edge.org: Jaron Lanier)</title>
<meta name="Author" content="Perry E.Metzger (perry@piermont.com)">
<meta name="Subject" content="Re: META: Killthread; (Re: Edge.org: Jaron Lanier)">
<meta name="Date" content="2003-11-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: META: Killthread; (Re: Edge.org: Jaron Lanier)</h1>
<!-- received="Sat Nov 29 22:45:01 2003" -->
<!-- isoreceived="20031130054501" -->
<!-- sent="Sun, 30 Nov 2003 00:44:57 -0500" -->
<!-- isosent="20031130054457" -->
<!-- name="Perry E.Metzger" -->
<!-- email="perry@piermont.com" -->
<!-- subject="Re: META: Killthread; (Re: Edge.org: Jaron Lanier)" -->
<!-- id="87r7zqxvdy.fsf@snark.piermont.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="20031129204107.65847.qmail@web11701.mail.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Perry E.Metzger (<a href="mailto:perry@piermont.com?Subject=Re:%20META:%20Killthread;%20(Re:%20Edge.org:%20Jaron%20Lanier)"><em>perry@piermont.com</em></a>)<br>
<strong>Date:</strong> Sat Nov 29 2003 - 22:44:57 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7306.html">Perry E.Metzger: "Re: Edge.org: Jaron Lanier"</a>
<li><strong>Previous message:</strong> <a href="7304.html">Colin: "RE: Edge.org: Jaron Lanier"</a>
<li><strong>In reply to:</strong> <a href="7299.html">Tommy McCabe: "Re: META: Killthread; (Re: Edge.org: Jaron Lanier)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7311.html">Brian Atkins: "Where'd those sacred cows go?"</a>
<li><strong>Reply:</strong> <a href="7311.html">Brian Atkins: "Where'd those sacred cows go?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7305">[ date ]</a>
<a href="index.html#7305">[ thread ]</a>
<a href="subject.html#7305">[ subject ]</a>
<a href="author.html#7305">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Tommy McCabe &lt;<a href="mailto:rocketjet314@yahoo.com?Subject=Re:%20META:%20Killthread;%20(Re:%20Edge.org:%20Jaron%20Lanier)">rocketjet314@yahoo.com</a>&gt; writes:
<br>
<em>&gt; Since when is there any evidence that Moore's Law is
</em><br>
<em>&gt; petering out? people have been claiming that for
</em><br>
<em>&gt; fifteen years and chips continue to grow faster.
</em><br>
<p>Right now, we're hitting the fundamental limits on
<br>
photolithographically produced circuits. And yes, we really are. If
<br>
you look at the electron micrographs of the transistors we're
<br>
producing at the 90nm scale, it is pretty obvious that we're hitting
<br>
the limits -- anything below 10-15nm is not going to be within our
<br>
abilities, and the folks at the semi houses pretty much say that up
<br>
front.
<br>
<p>We're also hitting serious problems with power dissipation. A chip of
<br>
maximal density using 10nm processes will be beyond our power to cool,
<br>
even if we can run it slow. That's because leakage currents have
<br>
gotten far too high. (By &quot;beyond our ability to cool&quot; I mean
<br>
&quot;dissipate more than 10kw/cm^2&quot;.)
<br>
<p>Now, it is entirely possible we could turn around and start using some
<br>
other technology -- say Drexlerian rod logic -- and get increases in
<br>
density past that, and lower power usage. However, we don't have true
<br>
molecular nanotechnology yet, and it seems very likely that we're
<br>
going to hit the end of the road for silicon before we do. Even if we
<br>
do manage to hop off of the silicon train and onto MNT, however, we do
<br>
eventually get to certain fundamental limits.
<br>
<p>The .5kt limit isn't one we can avoid (though we can try to minimize
<br>
the effect by using reversible logic as much as possible), and
<br>
associated with .5kt is the cooling problem -- you have to dissipate
<br>
what you generate. Presumably we'll have to cool our machines to lower
<br>
and lower temperature to make .5kt lower, but there are limits there,
<br>
too. We also have no idea how to make components smaller than
<br>
individual atoms (and the uncertainty principle seems to give one
<br>
pause about any possibility of doing that even on a neutron star.)
<br>
<p>In any case, however, Moore's Law ends within 40 years, period. If you
<br>
do the back of the envelope calculation, there are perhaps 2^77th
<br>
carbon atoms in a cc of diamond, and you aren't going to store many
<br>
more bits than that per cc, at least with forseeable
<br>
technologies. (I'd argue you can't even store that many if you expect
<br>
speed, but...)
<br>
<p><em>&gt; Since when does AI require specialized hardware? Fast
</em><br>
<em>&gt; hardware, quite possibly, but specialized hardware?
</em><br>
<p>We don't know yet, as we don't yet have AI -- or perhaps you think
<br>
that because it is easy to sit about speculating about AI that you
<br>
actually know how to build it?
<br>
<p>Perhaps it will turn out that, for better or ill, the best we know how
<br>
to do until we have improved ourselves a lot and understand brains
<br>
more is doing neural net simulations of natural brains. That might
<br>
very well require specialized hardware to achieve sufficient speeds.
<br>
<p><em>&gt; Fast hardware can be obtained by linking slow hardware together.
</em><br>
<p>That's called &quot;parallel processing&quot;. Many of us were doing that sort
<br>
of work some years ago. It turns out it requires alternative
<br>
programming techniques, and it also turns out not to be a panacea.
<br>
<p><em>&gt; Specialized hardware requires a redesign of the chip. We might need
</em><br>
<em>&gt; the former, but why would we need the latter?
</em><br>
<p>Because, sadly, specialized designs continue to be faster than more
<br>
general ones.
<br>
<p><em>&gt;&gt; &gt; thorough knowledge of the hardware it is being
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Absolutely.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I wasn't talking about it in the sense of &quot;which chip
</em><br>
<em>&gt; you are running it on&quot;. You need to know if it's on a
</em><br>
<em>&gt; PC-type computer or a Mac-type computer, but there is
</em><br>
<em>&gt; no need to program in binary or even assembly code,
</em><br>
<em>&gt; which requires a lot of knowledge of the chip
</em><br>
<em>&gt; architecture. High-level languages will work just as
</em><br>
<em>&gt; well.
</em><br>
<p>Spoken like someone who doesn't hack on operating systems much. :)
<br>
Also spoken like someone who doesn't hack on high performance apps.
<br>
<p><em>&gt;&gt; &gt; programmed on, there is no need to waste time
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; If both of your premises weren't wrong, I'd
</em><br>
<em>&gt;&gt; be agreeing with your conclusion. 
</em><br>
<em>&gt;
</em><br>
<em>&gt; Please explain how my premises are wrong. AI is
</em><br>
<em>&gt; obviously harder and has more things on the line than
</em><br>
<em>&gt; a conventional programming project, but why can't it
</em><br>
<em>&gt; be done on regular hardware?
</em><br>
<p>Don't know yet. I think we'll know when we've finished the work.
<br>
<p>I will say this -- when I was doing vision work (many years ago I must
<br>
admit), the state of the art work was being done on artificial retinas
<br>
and processing networks implemented in hardware. That wasn't because
<br>
it wasn't possible to do the work on conventional architectures -- but
<br>
because the researchers wanted to get their results within their
<br>
lifetimes.
<br>
<p><em>&gt; And why can't it be done
</em><br>
<em>&gt; in a high-level language that doesn't require a lot of
</em><br>
<em>&gt; knowledge of the chip?
</em><br>
<p>Don't know yet. We'll know when we're done, won't we?
<br>
<p><em>&gt;&gt; &gt; discussing it. If it isn't broken, don't fix it,
</em><br>
<em>&gt;&gt; and
</em><br>
<em>&gt;&gt; &gt; don't spend valuable time discussing it. Quote
</em><br>
<em>&gt;&gt; from
</em><br>
<em>&gt;&gt; &gt; Staring into the Singularity- &quot;Ever since the late
</em><br>
<em>&gt;&gt; &gt; 90's, the Singularity has been only a problem of
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; I'm completely immune to quotes. As long as you can
</em><br>
<em>&gt;&gt; show me that hardware is not a problem, and more and
</em><br>
<em>&gt;&gt; better hardware isn't a very powerful tool to
</em><br>
<em>&gt;&gt; circumvent
</em><br>
<em>&gt;&gt; this software (the separation between software and 
</em><br>
<em>&gt;&gt; hardware is a yet another sterile meme of the
</em><br>
<em>&gt;&gt; complex
</em><br>
<em>&gt;&gt; we started this discussion with) you could be as 
</em><br>
<em>&gt;&gt; well quoting from Mao's Little Red Book.
</em><br>
<em>&gt;
</em><br>
<em>&gt; You can have to most powerful chip on the planet, but
</em><br>
<em>&gt; you need software to run it on, and that's the tricky
</em><br>
<em>&gt; part.
</em><br>
<p>The tricky part is understanding what you're doing. We don't know what
<br>
we're doing yet, so we don't really know what tools we'll need.
<br>
<p>BTW, I agree with Eugen -- quit quoting manifestos. This is science
<br>
and engineering, not communism.
<br>
<p><em>&gt; You can get faster computers by stringing slower
</em><br>
<em>&gt; computers together, but you can't get better programs
</em><br>
<em>&gt; by stringing bad programs together.
</em><br>
<p>Daniel Dennett notes that most people are only comfortable with the
<br>
idea of complex systems building less complex systems, and Darwin's
<br>
most revolutionary idea was that it was possible for an essentially
<br>
dumb and non-complicated process to construct exquisitely complicated
<br>
things.
<br>
<p>The way evolution works is precisely by stringing bad programs
<br>
together, and twisting them until they work.
<br>
<p><em>&gt; I agree that better hardware makes the software problems easier, but
</em><br>
<em>&gt; even incredibly simple scenarios like software processes that were
</em><br>
<em>&gt; mutated by another low-intelligence process and selected for their
</em><br>
<em>&gt; ability to play chess require a good deal of software design. And
</em><br>
<em>&gt; that scenario would probably end with an AI that wants to demolish
</em><br>
<em>&gt; the solar system to make more room for hardware to play chess
</em><br>
<em>&gt; better.
</em><br>
<p>Why would it necessarily end that way? We were built by such a process
<br>
and are not particularly awful in terms of desire to destroy
<br>
vs. desire to build. (Of course, I could go and quote Bakunin on the
<br>
urge to destroy here, but that would just be tweaking you more than I
<br>
am already.)
<br>
<p><em>&gt;&gt; &gt; software.&quot; The hardware companies can handle the
</em><br>
<em>&gt;&gt; &gt; problem of making fast chips- but we need the code
</em><br>
<em>&gt;&gt; to
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; No, they can't. That's the whole point of this discussion.  Johnny
</em><br>
<em>&gt;&gt; can't make fast chips, and if you want AI, you better understand
</em><br>
<em>&gt;&gt; why.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Even if modern PCs are too slow for AI, you can use a
</em><br>
<em>&gt; supercomputer or distributed computing (or lots of
</em><br>
<em>&gt; PC's working parallelly in some warehouse.) And even
</em><br>
<em>&gt; if that doesn't work, chips are getting faster.
</em><br>
<p>And what if no such technique produces something fast enough?
<br>
<p>I remember a few years ago when Jim Gillogly tried to write a simple
<br>
computer program to simulate the operation of the Bombe -- that was
<br>
the electromechanical system that was used to break the daily keys
<br>
used on the Enigma. He discovered, much to his shock, that 50 or 60
<br>
years of computer development haven't made a general purpose computer
<br>
fast enough to do what a simple arrangement of wires and rotors could
<br>
do in the '40s.
<br>
<p>Or, to put it another way: every computer out there today has graphics
<br>
accelerators that do in a few million transistors what no amount of
<br>
general purpose computing would do for speeding up real time
<br>
animation.
<br>
<p>It may easily turn out that a few simple circuits speed up neural net
<br>
simulations enough that we'll use specialized hardware instead of
<br>
general purpose for our AI work. Or, maybe we won't. Who knows?
<br>
<p>The real point here, though, is this: quit being arrogant. You and I
<br>
are ignorant. We don't know how to build an AI, except in the most
<br>
general terms useful for philosophical arguments. Neither of us know
<br>
what technologies will be required in the end. Therefore, being humble
<br>
in the face of that ignorance is in order.
<br>
<p><em>&gt;&gt; &gt; make the chips become a Friendly Seed AI. And that's
</em><br>
<em>&gt;&gt; &gt; where SIAI comes in.
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; I'm not feeling like joining the F issue before the
</em><br>
<em>&gt;&gt; hardware and the software part isn't addressed.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Even Eurisko shouldn't have been done without a
</em><br>
<em>&gt; coherent theory of Friendliness.
</em><br>
<p>I suspect (I'm sorry to say) that assuring Friendliness is impossible,
<br>
both on a formal level (see Rice's Theorem) and on a practical level
<br>
(see informal points made by folks like Vinge on the impossibility of
<br>
understanding and thus controlling that which is vastly smarter than
<br>
you are.)  I may be wrong, of course, but it doesn't look very good to
<br>
me.
<br>
<p>(I realize that I've just violated the religion many people here on
<br>
this list subscribe to, but I have no respect for religion.)
<br>
<p>However, given how lame the hardware Eurisko was run on was, the odds
<br>
of it getting &quot;out of hand&quot; seem utterly unwarranted. Eurisko wasn't
<br>
even as smart as a grasshopper.
<br>
<p>(As an aside, I'll say this out loud even though some of Doug Lenat's
<br>
victims live here -- the joke about Lenat in the Hacker's Dictionary
<br>
was hardly severe enough. Cyc is one of the most massive wastes of
<br>
money I've ever seen.)
<br>
<p><em>&gt; When you're planning on making a being that has the potential to
</em><br>
<em>&gt; blow up the planet, you don't want to take any unnecessary risks by
</em><br>
<em>&gt; something as easily remedied as putting the AI before the
</em><br>
<em>&gt; Friendliness theory.
</em><br>
<p>Keep in mind that likely, out there there are intelligent creatures
<br>
created without regard to &quot;Friendliness theory&quot; that whatever you
<br>
create is going to have to survive against. Someday, they'll encounter
<br>
each other. I'd prefer that my successors not be wiped out at first
<br>
glance in such an encounter, which likely requires that such designs
<br>
need to be stupendous badasses (to use the Neil Stephenson term).
<br>
<p>Again, though, I'm probably violating the local religion in saying
<br>
that.
<br>
<p><em>&gt;&gt; Unless, of course, that's off-topic for this list.
</em><br>
<em>&gt;&gt; It it is so, this list is about plucking virtual
</em><br>
<em>&gt;&gt; lint from our nonexisting navels.
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; -- Eugen* Leitl <a href="http://leitl.org">leitl</a>
</em><br>
<p>Eugen and I seem to be in violent agreement about far too many
<br>
things. :)
<br>
<p>Perry
<br>
<pre>
-- 
Perry E. Metzger		<a href="mailto:perry@piermont.com?Subject=Re:%20META:%20Killthread;%20(Re:%20Edge.org:%20Jaron%20Lanier)">perry@piermont.com</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7306.html">Perry E.Metzger: "Re: Edge.org: Jaron Lanier"</a>
<li><strong>Previous message:</strong> <a href="7304.html">Colin: "RE: Edge.org: Jaron Lanier"</a>
<li><strong>In reply to:</strong> <a href="7299.html">Tommy McCabe: "Re: META: Killthread; (Re: Edge.org: Jaron Lanier)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7311.html">Brian Atkins: "Where'd those sacred cows go?"</a>
<li><strong>Reply:</strong> <a href="7311.html">Brian Atkins: "Where'd those sacred cows go?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7305">[ date ]</a>
<a href="index.html#7305">[ thread ]</a>
<a href="subject.html#7305">[ subject ]</a>
<a href="author.html#7305">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:43 MDT
</em></small></p>
</body>
</html>
