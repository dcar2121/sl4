<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Where'd those sacred cows go?</title>
<meta name="Author" content="Perry E.Metzger (perry@piermont.com)">
<meta name="Subject" content="Re: Where'd those sacred cows go?">
<meta name="Date" content="2003-11-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Where'd those sacred cows go?</h1>
<!-- received="Sun Nov 30 15:56:05 2003" -->
<!-- isoreceived="20031130225605" -->
<!-- sent="Sun, 30 Nov 2003 17:56:01 -0500" -->
<!-- isosent="20031130225601" -->
<!-- name="Perry E.Metzger" -->
<!-- email="perry@piermont.com" -->
<!-- subject="Re: Where'd those sacred cows go?" -->
<!-- id="87llpxo48u.fsf@snark.piermont.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3FCA4647.10508@posthuman.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Perry E.Metzger (<a href="mailto:perry@piermont.com?Subject=Re:%20Where'd%20those%20sacred%20cows%20go?"><em>perry@piermont.com</em></a>)<br>
<strong>Date:</strong> Sun Nov 30 2003 - 15:56:01 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7314.html">James Rogers: "Pei Wang's NARS"</a>
<li><strong>Previous message:</strong> <a href="7312.html">ktpr: "an off-side comment about Friendliness"</a>
<li><strong>In reply to:</strong> <a href="7311.html">Brian Atkins: "Where'd those sacred cows go?"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7313">[ date ]</a>
<a href="index.html#7313">[ thread ]</a>
<a href="subject.html#7313">[ subject ]</a>
<a href="author.html#7313">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Brian Atkins &lt;<a href="mailto:brian@posthuman.com?Subject=Re:%20Where'd%20those%20sacred%20cows%20go?">brian@posthuman.com</a>&gt; writes:
<br>
<em>&gt; Perry E.Metzger wrote:
</em><br>
<em>&gt;&gt; I suspect (I'm sorry to say) that assuring Friendliness is
</em><br>
<em>&gt;&gt; impossible,
</em><br>
<em>&gt;&gt; both on a formal level (see Rice's Theorem) and on a practical level
</em><br>
<em>&gt;&gt; (see informal points made by folks like Vinge on the impossibility of
</em><br>
<em>&gt;&gt; understanding and thus controlling that which is vastly smarter than
</em><br>
<em>&gt;&gt; you are.)  I may be wrong, of course, but it doesn't look very good to
</em><br>
<em>&gt;&gt; me.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I think you have some misconceptions... First off, the concept isn't
</em><br>
<em>&gt; to provide perfect 100% assurance. No one is claiming that they can do
</em><br>
<em>&gt; so. Although that would be great, in practice or even on paper it
</em><br>
<em>&gt; isn't doable... we must settle for a more practical &quot;best shot&quot;.
</em><br>
<p>For a number of reasons I'm not sure a &quot;best shot&quot; is very likely to
<br>
succeed, either. However, that's a long and involved argument.
<br>
<p><em>&gt; Secondly, as you say, &quot;controlling&quot; something like this is an
</em><br>
<em>&gt; impossibility. Which is why we have never talked about attempting such
</em><br>
<em>&gt; a thing. You have to build something that will be ok on its own, as it
</em><br>
<em>&gt; outgrows our intelligence level, or else don't build it.
</em><br>
<p>What you're talking about is attempting to construct something that
<br>
has internal controls that will prevent it from becoming
<br>
&quot;unFriendly&quot;. Said internal controls are necessarily devised by a
<br>
creature less intelligent than the creature you are constructing
<br>
(they are after all devised by ordinary humans.)
<br>
<p>I'm not sure that people have much of a way of coping with such
<br>
problems, except with the use of proof techniques, and unfortunately
<br>
proof techniques would fail (see Rice's Theorem).
<br>
<p>But again, perhaps this is an argument for another day.
<br>
<p><em>&gt;&gt; (I realize that I've just violated the religion many people here on
</em><br>
<em>&gt;&gt; this list subscribe to, but I have no respect for religion.)
</em><br>
[...]
<br>
<em>&gt; So... I don't see any sacred cows to slaughter. Everyone here realizes
</em><br>
<em>&gt; (or should realize) that this is still a very new and very unfinished
</em><br>
<em>&gt; area of AI research. There are no guarantees it will ultimately pan
</em><br>
<em>&gt; out.
</em><br>
<p>Not everyone has that degree of realism here, I think. There are, in
<br>
particular, those that speak of bringing on the singularity in much
<br>
the same way that some religions speak of bringing the
<br>
messiah. Perhaps I'm wrong about how many have that mindset -- who
<br>
knows. It is in any case my (fallible) observation. Take it with or
<br>
without a grain of salt, depending on your restrictions on dietary
<br>
sodium.
<br>
<p><em>&gt;&gt; Keep in mind that likely, out there there are intelligent creatures
</em><br>
<em>&gt;&gt; created without regard to &quot;Friendliness theory&quot; that whatever you
</em><br>
<em>&gt;&gt; create is going to have to survive against. Someday, they'll encounter
</em><br>
<em>&gt;&gt; each other. I'd prefer that my successors not be wiped out at first
</em><br>
<em>&gt;&gt; glance in such an encounter, which likely requires that such designs
</em><br>
<em>&gt;&gt; need to be stupendous badasses (to use the Neil Stephenson term).
</em><br>
<em>&gt;&gt; Again, though, I'm probably violating the local religion in saying
</em><br>
<em>&gt;&gt; that.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Nope, this idea has been brought up at least one time previously
</em><br>
<em>&gt; (couple years back I guess). Specifically, the idea that for some
</em><br>
<em>&gt; reason a FAI is limited or unable to win a conflict with an external
</em><br>
<em>&gt; UFAI. I don't see any reason why this would be so, and I don't recall
</em><br>
<em>&gt; anyone being able to make a convincing argument for it last time
</em><br>
<em>&gt; around, but feel free...
</em><br>
<p>I'm merely noting that a creature without any constraints on its
<br>
behavior might have certain operational advantages against one that
<br>
has constraints on its behavior, and one that had evolved in a
<br>
dangerous environment might be better equipped for danger than one
<br>
unused to such trouble -- though you are correct that these might not
<br>
be real problems. It is hard to say.
<br>
<p><pre>
-- 
Perry E. Metzger		<a href="mailto:perry@piermont.com?Subject=Re:%20Where'd%20those%20sacred%20cows%20go?">perry@piermont.com</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7314.html">James Rogers: "Pei Wang's NARS"</a>
<li><strong>Previous message:</strong> <a href="7312.html">ktpr: "an off-side comment about Friendliness"</a>
<li><strong>In reply to:</strong> <a href="7311.html">Brian Atkins: "Where'd those sacred cows go?"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7313">[ date ]</a>
<a href="index.html#7313">[ thread ]</a>
<a href="subject.html#7313">[ subject ]</a>
<a href="author.html#7313">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:43 MDT
</em></small></p>
</body>
</html>
