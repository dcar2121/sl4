<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Where'd those sacred cows go?</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Where'd those sacred cows go?">
<meta name="Date" content="2003-11-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Where'd those sacred cows go?</h1>
<!-- received="Sun Nov 30 12:35:34 2003" -->
<!-- isoreceived="20031130193534" -->
<!-- sent="Sun, 30 Nov 2003 13:34:31 -0600" -->
<!-- isosent="20031130193431" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Where'd those sacred cows go?" -->
<!-- id="3FCA4647.10508@posthuman.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="87r7zqxvdy.fsf@snark.piermont.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Where'd%20those%20sacred%20cows%20go?"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Sun Nov 30 2003 - 12:34:31 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7312.html">ktpr: "an off-side comment about Friendliness"</a>
<li><strong>Previous message:</strong> <a href="7310.html">Randall Randall: "Re: Edge.org: Jaron Lanier"</a>
<li><strong>In reply to:</strong> <a href="7305.html">Perry E.Metzger: "Re: META: Killthread; (Re: Edge.org: Jaron Lanier)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7312.html">ktpr: "an off-side comment about Friendliness"</a>
<li><strong>Reply:</strong> <a href="7312.html">ktpr: "an off-side comment about Friendliness"</a>
<li><strong>Reply:</strong> <a href="7313.html">Perry E.Metzger: "Re: Where'd those sacred cows go?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7311">[ date ]</a>
<a href="index.html#7311">[ thread ]</a>
<a href="subject.html#7311">[ subject ]</a>
<a href="author.html#7311">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Perry E.Metzger wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; I suspect (I'm sorry to say) that assuring Friendliness is impossible,
</em><br>
<em>&gt; both on a formal level (see Rice's Theorem) and on a practical level
</em><br>
<em>&gt; (see informal points made by folks like Vinge on the impossibility of
</em><br>
<em>&gt; understanding and thus controlling that which is vastly smarter than
</em><br>
<em>&gt; you are.)  I may be wrong, of course, but it doesn't look very good to
</em><br>
<em>&gt; me.
</em><br>
<p>I think you have some misconceptions... First off, the concept isn't to 
<br>
provide perfect 100% assurance. No one is claiming that they can do so. 
<br>
Although that would be great, in practice or even on paper it isn't 
<br>
doable... we must settle for a more practical &quot;best shot&quot;.
<br>
<p>Secondly, as you say, &quot;controlling&quot; something like this is an 
<br>
impossibility. Which is why we have never talked about attempting such a 
<br>
thing. You have to build something that will be ok on its own, as it 
<br>
outgrows our intelligence level, or else don't build it.
<br>
<p>Thirdly, be careful not to confuse Friendliness with the Sysop scenario 
<br>
idea, which is where Google shows me you brought up Rice's Theorem 
<br>
previously. Two completely different things, where development of a FAI 
<br>
does not imply such a scenario coming into existence.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; (I realize that I've just violated the religion many people here on
</em><br>
<em>&gt; this list subscribe to, but I have no respect for religion.)
</em><br>
<em>&gt; 
</em><br>
<p>Historically, the &quot;F word&quot; represents an ongoing attempt to come up with 
<br>
some technical means to greatly increase the odds of safe AI. The 
<br>
attempt remains unfinished, and is an area I wish more research was done 
<br>
in by others. It's a technical area that any person or group attempting 
<br>
work on real AI should face and address before proceeding with 
<br>
construction of a full attempt. We can argue over the best form of it 
<br>
(or even whether it really is needed) here just as if we were arguing 
<br>
whether to use a SCSI or SATA RAID controller in a server we were 
<br>
constructing, and that is one of the things this list was created for 
<br>
and has been used for in the past.
<br>
<p>So... I don't see any sacred cows to slaughter. Everyone here realizes 
<br>
(or should realize) that this is still a very new and very unfinished 
<br>
area of AI research. There are no guarantees it will ultimately pan out. 
<br>
At most, I think you will find hope among some participants here that 
<br>
this problem will ultimately be solvable to a degree that will allow 
<br>
development of AI to proceed with real knowledge of the odds, and that 
<br>
those odds will be much better than they are at the moment. We all 
<br>
realize that this may yet turn out to be a dead end, but for now we feel 
<br>
it is worth continuing its exploration.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; Keep in mind that likely, out there there are intelligent creatures
</em><br>
<em>&gt; created without regard to &quot;Friendliness theory&quot; that whatever you
</em><br>
<em>&gt; create is going to have to survive against. Someday, they'll encounter
</em><br>
<em>&gt; each other. I'd prefer that my successors not be wiped out at first
</em><br>
<em>&gt; glance in such an encounter, which likely requires that such designs
</em><br>
<em>&gt; need to be stupendous badasses (to use the Neil Stephenson term).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Again, though, I'm probably violating the local religion in saying
</em><br>
<em>&gt; that.
</em><br>
<p>Nope, this idea has been brought up at least one time previously (couple 
<br>
years back I guess). Specifically, the idea that for some reason a FAI 
<br>
is limited or unable to win a conflict with an external UFAI. I don't 
<br>
see any reason why this would be so, and I don't recall anyone being 
<br>
able to make a convincing argument for it last time around, but feel free...
<br>
<pre>
-- 
Brian Atkins
Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7312.html">ktpr: "an off-side comment about Friendliness"</a>
<li><strong>Previous message:</strong> <a href="7310.html">Randall Randall: "Re: Edge.org: Jaron Lanier"</a>
<li><strong>In reply to:</strong> <a href="7305.html">Perry E.Metzger: "Re: META: Killthread; (Re: Edge.org: Jaron Lanier)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7312.html">ktpr: "an off-side comment about Friendliness"</a>
<li><strong>Reply:</strong> <a href="7312.html">ktpr: "an off-side comment about Friendliness"</a>
<li><strong>Reply:</strong> <a href="7313.html">Perry E.Metzger: "Re: Where'd those sacred cows go?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7311">[ date ]</a>
<a href="index.html#7311">[ thread ]</a>
<a href="subject.html#7311">[ subject ]</a>
<a href="author.html#7311">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:43 MDT
</em></small></p>
</body>
</html>
