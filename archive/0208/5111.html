<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Why is Friendliness sacrosanct?</title>
<meta name="Author" content="Alden Streeter (astreeter@msn.com)">
<meta name="Subject" content="Re: Why is Friendliness sacrosanct?">
<meta name="Date" content="2002-08-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Why is Friendliness sacrosanct?</h1>
<!-- received="Sat Aug 24 22:26:14 2002" -->
<!-- isoreceived="20020825042614" -->
<!-- sent="Sat, 24 Aug 2002 21:20:56 -0400" -->
<!-- isosent="20020825012056" -->
<!-- name="Alden Streeter" -->
<!-- email="astreeter@msn.com" -->
<!-- subject="Re: Why is Friendliness sacrosanct?" -->
<!-- id="F20LjbUifDETYDipkTk00014112@hotmail.com" -->
<!-- inreplyto="Why is Friendliness sacrosanct?" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Alden Streeter (<a href="mailto:astreeter@msn.com?Subject=Re:%20Why%20is%20Friendliness%20sacrosanct?"><em>astreeter@msn.com</em></a>)<br>
<strong>Date:</strong> Sat Aug 24 2002 - 19:20:56 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5112.html">James Rogers: "Re: Reason, intuition, and AI (was: Metarationality)"</a>
<li><strong>Previous message:</strong> <a href="5110.html">Ben Goertzel: "RE: Metarationality (was: JOIN: Alden Streeter)"</a>
<li><strong>Maybe in reply to:</strong> <a href="5067.html">Alden Streeter: "Why is Friendliness sacrosanct?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5136.html">Michael Roy Ames: "Re: Why is Friendliness sacrosanct?"</a>
<li><strong>Reply:</strong> <a href="5136.html">Michael Roy Ames: "Re: Why is Friendliness sacrosanct?"</a>
<li><strong>Reply:</strong> <a href="5162.html">Samantha Atkins: "Re: Why is Friendliness sacrosanct?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5111">[ date ]</a>
<a href="index.html#5111">[ thread ]</a>
<a href="subject.html#5111">[ subject ]</a>
<a href="author.html#5111">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;From: &quot;Michael Roy Ames&quot; &lt;<a href="mailto:michaelroyames@hotmail.com?Subject=Re:%20Why%20is%20Friendliness%20sacrosanct?">michaelroyames@hotmail.com</a>&gt;
</em><br>
<em>&gt;Alden Streeter &lt;<a href="mailto:astreeter@msn.com?Subject=Re:%20Why%20is%20Friendliness%20sacrosanct?">astreeter@msn.com</a>&gt; wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; So then the same question can be asked of a Sysop-level AI - instead of
</em><br>
<em>&gt; &gt; working to help humans to achieve their petty, primitive, evolutionarily
</em><br>
<em>&gt; &gt; determined goals, why not just use its power to change the humans so 
</em><br>
<em>&gt;they
</em><br>
<em>&gt; &gt; have different goals?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;Why not?  Well, I for one, want to be empowered... not overpowered.  I 
</em><br>
<em>&gt;would
</em><br>
<em>&gt;certainly listen to advice from a Super Intelligence (SI), and would
</em><br>
<em>&gt;probably decide to take it ;) but I would definitely not want to be cut out
</em><br>
<em>&gt;of the decision loop.  So, *that's* why not.
</em><br>
<p>But if the Sysop changed your goals, you might afterwards have a different 
<br>
opinion of whether that change empowered instead of overpowered you.  It 
<br>
seems irrational that your present goals should be considered superior to 
<br>
the new, better goals that the vastly more intelligent AI would choose for 
<br>
you.
<br>
<p><em>&gt;Also, commenting on the &quot;petty, primitive, evolutionarily determined goals&quot;
</em><br>
<em>&gt;phrase... for any given being, except one, there will always be some other
</em><br>
<em>&gt;beings more advanced and more intelligent than ver.  This applies to SI's
</em><br>
<em>&gt;too.  Therefore, the question boils down to: who decides what levels of
</em><br>
<em>&gt;intelligence gets to decide?  Answer: the highest intelligence on the 
</em><br>
<em>&gt;ladder
</em><br>
<em>&gt;who gives a damn about those beneath ver.
</em><br>
<p>Is &quot;gives a damn&quot; a technical term in this field?  How is it defined? ;-)
<br>
<p><em>&gt;Friendly AI is about making sure
</em><br>
<em>&gt;the AI 'gives a damn' and, to the maximum possible extent, assists us in a
</em><br>
<em>&gt;manner we would consider friendly - even at our lower level of 
</em><br>
<em>&gt;intelligence.
</em><br>
<p>Why should the AI be hampered by having to cater to the possibly irrational 
<br>
demands of those of lower intelligence?  How do you know that what you 
<br>
consider friendly at our lower level of intelligence you would still 
<br>
consider friendly if you intelligence were enhanced?  Isn't part of the 
<br>
principle of the Friendly AI that the AI should be able to decide, and 
<br>
actively change its system of deciding if it decides to, what is friendly or 
<br>
not? (I seem to recall reading that somewhere.) Then it seems to me that the 
<br>
AI, being more intelligent than you will ever be, should be more qualified 
<br>
to decide what is friendly.
<br>
<p><em>&gt; &gt; And why should humans not want the AI to have
</em><br>
<em>&gt; &gt; this type of power? - if the AI changed their goals for them, they would
</em><br>
<em>&gt;of
</em><br>
<em>&gt; &gt; course immediately realize that their new goals were the right goals all
</em><br>
<em>&gt; &gt; along.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;In a word: autonomy.  Another word: freedom.  Most humans don't want these
</em><br>
<em>&gt;things _taken_ from them, even if the Being taking them is much greater 
</em><br>
<em>&gt;than
</em><br>
<em>&gt;they are.  However, it is also true that most humans would willingly
</em><br>
<em>&gt;_give_up_ some of these very same treasures, if convinced they will benefit
</em><br>
<em>&gt;in other ways.  Way: Security.  Way: Community.  Way: Power.
</em><br>
<p>Again, the Sysop could just change you so that you didn't mind having your 
<br>
freedom taken away.  And you only can say that would be a bad thing now, 
<br>
because the Sysop hasn't changed you yet.
<br>
<p>The only two ways I can think of out of this paradox are to:
<br>
1. Turn the AI lose without restrictions, including the one prohibiting the 
<br>
destruction of humans.
<br>
2. Arbitrarily forbid the AI from ever altering human goal systems.
<br>
<p><em>&gt; &gt;  if I am covering old ground just let me know.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;You are definitely covering old ground, this reply has barely scratched the
</em><br>
<em>&gt;surface...  :)
</em><br>
<em>&gt;Suggestion: Read through the archives.  They contain many excellent
</em><br>
<em>&gt;discussions, and you will understand why I put the smiley face on the end 
</em><br>
<em>&gt;of
</em><br>
<em>&gt;the last sentence.  Afterwards, blow holes in the Friendly AI idea... if 
</em><br>
<em>&gt;you
</em><br>
<em>&gt;can... no, really - please try.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Michael Roy Ames
</em><br>
<p>These seem like holes right now to me, and your responses don't seem to 
<br>
conclusively plug them.  But maybe I am jumping the gun and these issues 
<br>
have already been comprehensively addressed in the archive.  So I'll keep 
<br>
reading the archives to see what else I can find on this subject. :)
<br>
<p><p><p>_________________________________________________________________
<br>
Join the world’s largest e-mail service with MSN Hotmail. 
<br>
<a href="http://www.hotmail.com">http://www.hotmail.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5112.html">James Rogers: "Re: Reason, intuition, and AI (was: Metarationality)"</a>
<li><strong>Previous message:</strong> <a href="5110.html">Ben Goertzel: "RE: Metarationality (was: JOIN: Alden Streeter)"</a>
<li><strong>Maybe in reply to:</strong> <a href="5067.html">Alden Streeter: "Why is Friendliness sacrosanct?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5136.html">Michael Roy Ames: "Re: Why is Friendliness sacrosanct?"</a>
<li><strong>Reply:</strong> <a href="5136.html">Michael Roy Ames: "Re: Why is Friendliness sacrosanct?"</a>
<li><strong>Reply:</strong> <a href="5162.html">Samantha Atkins: "Re: Why is Friendliness sacrosanct?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5111">[ date ]</a>
<a href="index.html#5111">[ thread ]</a>
<a href="subject.html#5111">[ subject ]</a>
<a href="author.html#5111">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:40 MDT
</em></small></p>
</body>
</html>
