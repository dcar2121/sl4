<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re[2]: project COSA</title>
<meta name="Author" content="Cliff Stabbert (cps46@earthlink.net)">
<meta name="Subject" content="Re[2]: project COSA">
<meta name="Date" content="2002-08-10">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re[2]: project COSA</h1>
<!-- received="Sat Aug 10 23:53:29 2002" -->
<!-- isoreceived="20020811055329" -->
<!-- sent="Sat, 10 Aug 2002 22:36:50 -0400" -->
<!-- isosent="20020811023650" -->
<!-- name="Cliff Stabbert" -->
<!-- email="cps46@earthlink.net" -->
<!-- subject="Re[2]: project COSA" -->
<!-- id="1209507450.20020810223650@earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="LAEGJLOGJIOELPNIOOAJIEMLDGAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Cliff Stabbert (<a href="mailto:cps46@earthlink.net?Subject=Re[2]:%20project%20COSA"><em>cps46@earthlink.net</em></a>)<br>
<strong>Date:</strong> Sat Aug 10 2002 - 20:36:50 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="5044.html">Ben Goertzel: "RE: Re[2]: project COSA"</a>
<li><strong>Previous message:</strong> <a href="5042.html">mike99: "RE: Are we Gods yet?"</a>
<li><strong>In reply to:</strong> <a href="5040.html">Ben Goertzel: "RE: project COSA"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5044.html">Ben Goertzel: "RE: Re[2]: project COSA"</a>
<li><strong>Reply:</strong> <a href="5044.html">Ben Goertzel: "RE: Re[2]: project COSA"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5043">[ date ]</a>
<a href="index.html#5043">[ thread ]</a>
<a href="subject.html#5043">[ subject ]</a>
<a href="author.html#5043">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Saturday, August 10, 2002, 11:08:33 AM, Ben Goertzel wrote:
<br>
<p>BG&gt; I agree with that -- advanced AGI's will develop nonhuman ways of
<br>
BG&gt; programming.  Our programming paradigms are based on the linear-syntax
<br>
BG&gt; nature of human language, whereas AGI's won't communicate using linear
<br>
BG&gt; syntax in the human-language sense.
<br>
<p>I actually wonder about that.  Human brains, massively parallel as
<br>
they are, exhibit &quot;awareness&quot; and &quot;identity&quot; precisely in the sense
<br>
that there is some sort of top-level linear, sequential and strongly
<br>
language-bound process: the ego.  To what degree that is an
<br>
&quot;accidental&quot; evolutionary result (i.e., one physical body = one
<br>
&quot;awareness&quot;) versus an essential component is IMO unclear.  (During
<br>
dreamstates, meditative states, drug- and ritual-induced states, etc.,
<br>
something called ego-loss can occur, and one can become aware of, or
<br>
feel the illusion of, a multitude of subprograms (or the absence of
<br>
any program).  But one would probably not pass a Turing test in such a
<br>
state.)
<br>
<p>But by and large I suspect we won't recognize an intelligence _as_
<br>
intelligent unless it has some sort of top-level &quot;main thread&quot;.  This
<br>
main thread quality is precisely what language is so suited to (or
<br>
co-evolved with, or what have you).
<br>
<p>I realize the above remarks are very vague, but I'm having a
<br>
difficult time putting this into words.  Basically, if not only the
<br>
underlying processing is parallel, but the whole thing, it goes way
<br>
beyond our capacity to recognize let alone understand it.  I would
<br>
imagine that for the foreseeable future we want to build AIs we can in
<br>
some form or another communicate with -- to give them problems to
<br>
solve, say, and to receive solutions.  IMO, this requires some form of
<br>
linear, sequential language (whether represented as such, or visually
<br>
or otherwise, is irrelevant).
<br>
<p>(This ties back to some earlier questions I had about the concept of
<br>
an AI having an unconscious, which I'm more and more starting to
<br>
expect will be a feature of any AI we recognize as I.)
<br>
<p>To give an example of what a &quot;superintelligence&quot; or &quot;intelligence&quot;
<br>
that we cannot recognize as such, I could point to the earth as a
<br>
whole system, or the universe, or what have you.  Any complex system
<br>
that does not have a clearly (to us) definable /center/, some obvious
<br>
/locus/ of decision/motivation.
<br>
<p>In an earlier post in this thread, you wrote:
<br>
<p>BG&gt; Sorta like the idea of recording music by humming the notes instead
<br>
BG&gt; of using your fingers on an instrument.  Sure, it seems easier at
<br>
BG&gt; first, if you have the proper tech.  But ultimately, humming isn't
<br>
BG&gt; going to give you the ability to play Shostakovich or Yngwie Malmsteen
<br>
BG&gt; within a reasonable amount of effort...
<br>
<p>An excellent (if discouraging for lazy theoretical guitar soloists)
<br>
point.  Nonetheless most music can be and is represented by linear
<br>
symbolic languages.  (And given the right neural interfaces, it may be
<br>
possible at some point to have a good conductor record a full symphony
<br>
without an orchestra -- I recall reading somewhere about direct interfaces
<br>
to early-audio-processing neurons being able to pick up &quot;imagined&quot;
<br>
sound, but I 1) could be distorting and 2) don't know if they've
<br>
progressed.)
<br>
<p>The reliability factor is a complex one.  We can make simple programs
<br>
and simple components as reliable as we want (including up to
<br>
mathematically proven).  The problem is with complex systems and even
<br>
more so, evolving/learning systems.  The ideal of software is allowing
<br>
us to abstract, but so far most efforts seem to fail or get stuck at a
<br>
certain level: there are so many languages promising reusability,
<br>
etc., and so few real world projects that seem to successfully use it.
<br>
<p>The great hope of infinite abstractability -- i.e., specify 0-level
<br>
(language level) things, 1-level things built on 0-level things, ...
<br>
n-level programs built on (n-1)-level programs -- that aspect seems to
<br>
me to be missing, at least in a practical sense.  (Note that I have
<br>
yet to learn Lisp, let alone create its monster hybrid with Forth).
<br>
<p>With visual languages that work on some sort of signal-processing or
<br>
neural network level, I fail to see how we can build or inspect
<br>
anything even somewhat complex -- it doesn't appear to cater to levels
<br>
of abstraction at all.
<br>
<p>Now, human language appears ideal in the abstraction sense: I can say
<br>
&quot;make me a Space Invaders, but where the aliens are students throwing
<br>
chalks and I have three protective desks&quot;.  But human languages are of
<br>
course ambiguous, metaphorical, etc.  There is some sort of Ideal that
<br>
is being quested for here and it's hard to put a finger on it.  COSA
<br>
is trying to put a finger on it, a million projects are trying to put
<br>
their finger on it.  But abstracting without loss of precision seems
<br>
to me /inherently/ impossible and thus all such efforts are doomed to
<br>
fail.  If it's complex enough to be interesting, it won't be
<br>
verifiable.
<br>
<p>A further, and even more off-topic than the rest of this post, spanner
<br>
I'd like to throw in the works here:  I suspect that although we tend
<br>
to *think* of certain types of logic and thought as a visual (or more
<br>
accurately, graph-like) phenomenon, there's IMO a strong kinesthetic/
<br>
proprioceptive component to human reasoning.  This last point is utter
<br>
speculation on my part based on introspection and I have no evidence
<br>
for it at all.
<br>
<p>Regardless, even if a program can be represented in some neat
<br>
visual/graph paradigm, one still has to sit there &quot;imagining the flow&quot;
<br>
to understand what it does.  And that IMO is its essential flaw: it
<br>
might simplify the /notation/ but it does nothing for the amount of
<br>
effort required to /comprehend/ what's going on.
<br>
<p>And that is the essence of the challenge: a representational system
<br>
rich enough for AI that can be understood by humans.  Personally, I
<br>
don't think that's a winnable challenge, but I'll gladly listen to
<br>
those who disagree.
<br>
<p><p><pre>
--
Cliff
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="5044.html">Ben Goertzel: "RE: Re[2]: project COSA"</a>
<li><strong>Previous message:</strong> <a href="5042.html">mike99: "RE: Are we Gods yet?"</a>
<li><strong>In reply to:</strong> <a href="5040.html">Ben Goertzel: "RE: project COSA"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="5044.html">Ben Goertzel: "RE: Re[2]: project COSA"</a>
<li><strong>Reply:</strong> <a href="5044.html">Ben Goertzel: "RE: Re[2]: project COSA"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#5043">[ date ]</a>
<a href="index.html#5043">[ thread ]</a>
<a href="subject.html#5043">[ subject ]</a>
<a href="author.html#5043">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:40 MDT
</em></small></p>
</body>
</html>
