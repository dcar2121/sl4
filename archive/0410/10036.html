<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Why I donate to the SIAI</title>
<meta name="Author" content="Robin Lee Powell (rlpowell@digitalkingdom.org)">
<meta name="Subject" content="Why I donate to the SIAI">
<meta name="Date" content="2004-10-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Why I donate to the SIAI</h1>
<!-- received="Fri Oct 22 11:26:52 2004" -->
<!-- isoreceived="20041022172652" -->
<!-- sent="Fri, 22 Oct 2004 10:26:41 -0700" -->
<!-- isosent="20041022172641" -->
<!-- name="Robin Lee Powell" -->
<!-- email="rlpowell@digitalkingdom.org" -->
<!-- subject="Why I donate to the SIAI" -->
<!-- id="20041022172641.GW32722@chain.digitalkingdom.org" -->
<!-- charset="us-ascii" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Robin Lee Powell (<a href="mailto:rlpowell@digitalkingdom.org?Subject=Re:%20Why%20I%20donate%20to%20the%20SIAI"><em>rlpowell@digitalkingdom.org</em></a>)<br>
<strong>Date:</strong> Fri Oct 22 2004 - 11:26:41 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10037.html">Eliezer Yudkowsky: "Re: SIAI:  Donate Today and Tomorrow"</a>
<li><strong>Previous message:</strong> <a href="10035.html">David S. Hansen: "Re: SIAI:  Donate Today and Tomorrow"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10040.html">Eliezer Yudkowsky: "Re: Why I donate to the SIAI"</a>
<li><strong>Reply:</strong> <a href="10040.html">Eliezer Yudkowsky: "Re: Why I donate to the SIAI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10036">[ date ]</a>
<a href="index.html#10036">[ thread ]</a>
<a href="subject.html#10036">[ subject ]</a>
<a href="author.html#10036">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
This is completely unsolicited.  For the record, I find Eliezer's
<br>
apparent confusion over people not donating truly bizarre, but then
<br>
I haven't been following the thread.  This is pretty rambling.  If
<br>
you want to skip to the punch line, look for the numbered points.
<br>
<p>I donate regularily, and in fairly substantial amounts, to the SIAI.
<br>
I am not particularily wealthy (although I would say that I'm well
<br>
off); these donations represent a visible portion of my total
<br>
income.
<br>
<p>Having encountered the Singularity a few years ago, it became
<br>
obvious to me that this was The Most Important Thing In The World.
<br>
Anyone who truly disagrees with me on that point will, of course,
<br>
never donate to SIAI or any similar organization.  But if you truly
<br>
disagree on that point, WTF are you doing on the sl4 list??
<br>
<p>As an aside: unlike many people on this list, I still think that
<br>
there's a good chance that the Singularity won't come about; I'm
<br>
betting it will, but I don't know for sure.  If I did, I would
<br>
likely be beggaring myself with donations.
<br>
<p>Given that I think the Singularity is The Most Important Thing In
<br>
The World, it behooves me to contribute to it.  Reading some of the
<br>
works surrounding this issue (Robin Hanson's, Eliezer's, some
<br>
others) it quickly became obvious to me that I am simply not smart
<br>
enough to be one of the coders, which is disappointing given that
<br>
I've dreamed of creating the first general AI since I was about
<br>
eleven years old.  Besides, I like my lifestyle, and if the
<br>
Singularity doesn't arrive I'd like to be well prepared.  So, if I'm
<br>
not going to code, I guess I'm going to donate.
<br>
<p>If I'm going to donate, I reasoned, who do I donate too?  Well, to
<br>
only one group, first of all.  I don't have quite enough spare
<br>
income to make substantial donations to more than one group, and
<br>
that strikes me as indecisive anyways.
<br>
<p>I then spent several months researching the various ways that people
<br>
were moving towards the Singularity and how they were each
<br>
approaching it.  I settled on giving money to the SIAI because:
<br>
<p>1.  Various things I read (mostly Eliezer) convinced me that the
<br>
existential threat of human-controlled nanotech was real and potent,
<br>
so anything that isn't going for non-human superintelligence was
<br>
right out.
<br>
<p>2.  Eliezer is the only person whose stuff I can read.  That sounds
<br>
simplistic, but it is absolutely paramount to me.  I've read all of
<br>
CFAI and GISAI.  In fact, I've read just about everything he's
<br>
written.  If I didn't:
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;a)  Agree with his point of view in as much as I understand it
<br>
&nbsp;&nbsp;&nbsp;&nbsp;and
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;b)  Believe utterly from his writings that he is immensely
<br>
&nbsp;&nbsp;&nbsp;&nbsp;smarter than me
<br>
<p>then I wouldn't be contributing to the SIAI none-the-less.  But
<br>
Eliezer's writings *are* available, I can mostly follow them, and
<br>
they make sense to me.
<br>
<p>There may be someone better than Eliezer for the job, but 
<br>
*I wouldn't know* because they are all protecting their beliefs as
<br>
trade secrets!
<br>
<p>If I had to place money on who other than Eliezer was likely to bet
<br>
better than him for the purposes of creating the mind that will get
<br>
us safely through the Singularity, my picks are:
<br>
<p>1.  Someone I've never heard of.  This is a trivial first entry, and
<br>
indeed a degenerate case.
<br>
<p>2.  Ben Goertzel.
<br>
<p>3.  Everyone else.
<br>
<p>I picked Eliezer over Ben partly because I have no idea what Ben's
<br>
plans really are, and partly because I am *scared* *shitless* at the
<br>
idea of waiting until animal-level intelligence to implement
<br>
Friendliness.  I believe, very strongly, in hard takeoff.  Or, more
<br>
relevantly, in planning as though an arbitrarily fast takeoff were
<br>
going to happen.  When his book comes out, I will need to
<br>
re-evaluate. Ben certainly has less lunatic fringe to him, but
<br>
that's not a deciding criteria.
<br>
<p>Other candidates:
<br>
<p>Someone mentioned Kurzweil.  First of all, I can't find anything
<br>
that explains how he intends to approach the problem.  I can't
<br>
evaluate what I don't know.  Secondly, I found this *lovely* gem:
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The siren calls for broad relinquishment are effective because
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;they paint a picture of future dangers as if they were released
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;on today's unprepared world. The reality is that the
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sophistication and power of our defensive technologies and
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;knowledge will grow along with the dangers. When we have &quot;gray
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;goo&quot; (unrestrained nanobot replication), we will also have
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;blue goo&quot; (&quot;police&quot; nanobots that combat the &quot;bad&quot; nanobots). 
<br>
<p>This was from
<br>
<a href="http://www.kurzweilai.net/meme/frame.html?main=memelist.html?m=2%23612">http://www.kurzweilai.net/meme/frame.html?main=memelist.html?m=2%23612</a>,
<br>
where he *does* mention friendliness as a problem to be considered,
<br>
which is a point in his favour, but not nearly enough to make up for
<br>
the terrifying paragraph above.  Has he never heard of nuclear
<br>
weapons???
<br>
<p>a2i2 is even worse; I can't find a mention of friendliness as even a
<br>
problem worth considering anywhere on
<br>
<a href="http://www.adaptiveai.com/research/index.htm">http://www.adaptiveai.com/research/index.htm</a>, although I admit that
<br>
with so little content in the first place I didn't feel the need to
<br>
spend a lot of time on it.
<br>
<p>So, that's that.  I have yet to find anyone that I am capable of
<br>
judging as better for the job than Eliezer.  Maybe he's *not* the
<br>
best for the job, who knows, but he's the best I've been able to
<br>
find and evaluate.
<br>
<p>-Robin
<br>
<p><pre>
-- 
<a href="http://www.digitalkingdom.org/~rlpowell/">http://www.digitalkingdom.org/~rlpowell/</a> *** <a href="http://www.lojban.org/">http://www.lojban.org/</a>
Reason #237 To Learn Lojban: &quot;Homonyms: Their Grate!&quot;
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10037.html">Eliezer Yudkowsky: "Re: SIAI:  Donate Today and Tomorrow"</a>
<li><strong>Previous message:</strong> <a href="10035.html">David S. Hansen: "Re: SIAI:  Donate Today and Tomorrow"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10040.html">Eliezer Yudkowsky: "Re: Why I donate to the SIAI"</a>
<li><strong>Reply:</strong> <a href="10040.html">Eliezer Yudkowsky: "Re: Why I donate to the SIAI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10036">[ date ]</a>
<a href="index.html#10036">[ thread ]</a>
<a href="subject.html#10036">[ subject ]</a>
<a href="author.html#10036">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:49 MDT
</em></small></p>
</body>
</html>
