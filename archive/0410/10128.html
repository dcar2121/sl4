<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Philosophy vs. rigor</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Philosophy vs. rigor">
<meta name="Date" content="2004-10-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Philosophy vs. rigor</h1>
<!-- received="Sun Oct 24 16:31:37 2004" -->
<!-- isoreceived="20041024223137" -->
<!-- sent="Sun, 24 Oct 2004 18:31:40 -0400" -->
<!-- isosent="20041024223140" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Philosophy vs. rigor" -->
<!-- id="JNEIJCJJHIEAILJBFHILGECPCJAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="417BFA4F.10809@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Philosophy%20vs.%20rigor"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sun Oct 24 2004 - 16:31:40 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10129.html">Thomas Buckner: "RE: Why I (will) donate to the SIAI"</a>
<li><strong>Previous message:</strong> <a href="10127.html">Ben Goertzel: "RE: Why SIAI is a nonprofit"</a>
<li><strong>In reply to:</strong> <a href="10121.html">Eliezer Yudkowsky: "Re: Philosophy vs. rigor"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10123.html">Damien Broderick: "RE: Philosophy vs. rigor"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10128">[ date ]</a>
<a href="index.html#10128">[ thread ]</a>
<a href="subject.html#10128">[ subject ]</a>
<a href="author.html#10128">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi Eli --
<br>
<p>The notion of &quot;rigor&quot; I outlined for you is not my invention, it's just my
<br>
summary of &quot;conventional wisdom&quot; in the intellectual world today about what
<br>
constitutes a rigorous argument.  You're free to believe that rigorous
<br>
argumentation in this conventional sense is not valuable.  However, if you
<br>
want to convince contemporary scientists that your conclusions are good
<br>
ones, you should be aware that adhering to this notion of rigor will make
<br>
your job a lot easier!
<br>
<p><em>&gt; All men are mortal.
</em><br>
<em>&gt; Socrates is a man.
</em><br>
<em>&gt; Therefore, Socrates is mortal.
</em><br>
<em>&gt;
</em><br>
<em>&gt; This is a valid syllogism.  Is it a rigorous, technically sophisticated
</em><br>
<em>&gt; theory of biology?
</em><br>
<p>It's rigorous, but pretty boring ... and the assumptions are not necessarily
<br>
going to be accepted by the listener (since as an optimistic transhumanist I
<br>
don't buy &quot;all men are mortal&quot; ;-)
<br>
<p><em>&gt; Suppose I &quot;axiomatized&quot; Friendly AI in such a way that my conclusions
</em><br>
<em>&gt; followed from my assumptions, but using silly verbal definitions as of
</em><br>
<em>&gt; Greek philosophy.  Would you call that rigorous?  Rigorous but wrong?
</em><br>
<p>Well, rigor takes place in the context of a set of reasoning rules, and a
<br>
way of describing heuristic assumptions, that is agreed upon by the
<br>
community in question.  In this sense rigor is culturally relative.
<br>
<p><em>&gt; Is this the kind of rigor that you *want* from Friendly AI
</em><br>
<em>&gt; theory?  I have
</em><br>
<em>&gt; little use for conclusions that are absolutely certain given their
</em><br>
<em>&gt; assumptions.  I want conclusions that are correct.  A Friendly AI is a
</em><br>
<em>&gt; physical object in a physical universe, not a mathematical theorem.  We
</em><br>
<em>&gt; need a way to predict the real-world behavior of the physical object.  In
</em><br>
<em>&gt; particular, I would consider it a bad idea to build a Friendly AI
</em><br>
<em>&gt; that goes
</em><br>
<em>&gt; mad given one bitflip.  Yet the very same Friendly AI might (we can
</em><br>
<em>&gt; imagine) be provably Friendly *assuming* that no bitflip ever
</em><br>
<em>&gt; occurs in any
</em><br>
<em>&gt; transistor.
</em><br>
<p>To convince scientific listeners of your points, you need to make rigorous
<br>
arguments that begin from assumptions that your listeners believe.
<br>
<p><em>&gt; But mostly, my objection to your definition of &quot;rigor&quot; (and if you change
</em><br>
<em>&gt; your mind and decide that you want something other than &quot;rigor&quot; from a
</em><br>
<em>&gt; Friendly AI theory, feel free to say so) is that (a) it seems to rule out
</em><br>
<em>&gt; probabilistic conclusions of very high probability, which is the best we
</em><br>
<em>&gt; can ever do in the real world, and (b) it doesn't detect the difference
</em><br>
<em>&gt; between Aristotle and Newton so long as both use technically valid
</em><br>
<em>&gt; syllogisms.  It could even penalize Newton, if he didn't bother
</em><br>
<em>&gt; to pretend
</em><br>
<em>&gt; that his experimental predictions were absolutely certain syllogisms.
</em><br>
<p>I never stated that rigor was the ONLY valuable thing in a body of
<br>
knowledge, just that it's a valuable thing ... and a valuable thing that
<br>
seems to be missing from most of your own work.  Most of your own arguments
<br>
are full of ambiguities and holes, so when I read them I think they're
<br>
interesting, but I'm not really convinced.
<br>
<p>My own arguments as to why I believe Novamente will achieve superhuman
<br>
intelligence when completed, tuned and tested -- are *also* nonrigorous in
<br>
this sense.  I don't know how to make them rigorous -- appropriate math
<br>
doesn't exist -- so I've chosen to focus on making the thing rather than
<br>
rigorously proving it would work if I made it...
<br>
<p>Aristotelian theory is fairly rigorous, but it's founded on empirically
<br>
wrong assumptions...
<br>
<p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10129.html">Thomas Buckner: "RE: Why I (will) donate to the SIAI"</a>
<li><strong>Previous message:</strong> <a href="10127.html">Ben Goertzel: "RE: Why SIAI is a nonprofit"</a>
<li><strong>In reply to:</strong> <a href="10121.html">Eliezer Yudkowsky: "Re: Philosophy vs. rigor"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10123.html">Damien Broderick: "RE: Philosophy vs. rigor"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10128">[ date ]</a>
<a href="index.html#10128">[ thread ]</a>
<a href="subject.html#10128">[ subject ]</a>
<a href="author.html#10128">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:49 MDT
</em></small></p>
</body>
</html>
