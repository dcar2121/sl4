<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Ben vs. the AI academics...</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="Ben vs. the AI academics...">
<meta name="Date" content="2004-10-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Ben vs. the AI academics...</h1>
<!-- received="Sat Oct 23 20:05:06 2004" -->
<!-- isoreceived="20041024020506" -->
<!-- sent="Sat, 23 Oct 2004 22:05:09 -0400" -->
<!-- isosent="20041024020509" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="Ben vs. the AI academics..." -->
<!-- id="JNEIJCJJHIEAILJBFHILAEBBCJAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=Re:%20Ben%20vs.%20the%20AI%20academics..."><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sat Oct 23 2004 - 20:05:09 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10098.html">Wei Dai: "SIAI's direction"</a>
<li><strong>Previous message:</strong> <a href="10096.html">Eliezer Yudkowsky: "Approaching the end of Today and Tomorrow"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10097">[ date ]</a>
<a href="index.html#10097">[ thread ]</a>
<a href="subject.html#10097">[ subject ]</a>
<a href="author.html#10097">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hmmm...
<br>
<p>I just had a somewhat funny experience with the &quot;traditional AI research
<br>
community&quot;....
<br>
<p>Moshe Looks and I gave a talk Friday at the AAAI Symposium on &quot;Achieving
<br>
Human-Level Intelligence Through Integrated Systems and Research.&quot;  Our talk
<br>
was an overview of Novamente; if you're curious our conference paper is at
<br>
<p><a href="http://www.realai.net/AAAI04.pdf">http://www.realai.net/AAAI04.pdf</a>
<br>
<p>Anyway, I began my talk by noting that, in my opinion, &quot;Seeking human-level
<br>
intelligence is not necessarily the best approach to AI.  We humans aren't
<br>
all that smart anyway, in the grand scheme of things; and it may be that the
<br>
best approach to superintelligence doesn't even pass through humanlike
<br>
intelligence, since human wetware is pretty different from computer
<br>
hardware.&quot;  Wow, did that piss off the audience!! (an audience which, as I
<br>
later found out, consisted largely of advocates of the SOAR and ACT-R
<br>
cognitive modeling systems, which seek to model human cognition in detail,
<br>
not by modeling human brain function but via tuning various logic and search
<br>
algorithms to have similar properties to human cognition.)  Moshe and I went
<br>
on to give a talk on Novamente, which was hard to do because we (like many
<br>
others who were accepted for the symposium but not part of the AAAI inner
<br>
circle) were allocated only 12 minutes plus 3 minutes for questions....  (Of
<br>
course, it's not hard to summarize Novamente at a certain level of
<br>
abstraction in 12 minutes, but it's pretty much impossible to be at all
<br>
*convincing* to skeptical AI &quot;experts&quot; in that time-frame.)  So far as I
<br>
could tell, no one really understood much of what we were talking about --
<br>
because they were so irritated at me for belittling humanity, and because
<br>
the Novamente architecture is too different from &quot;the usual&quot; for these guys
<br>
to really understand it from such a compressed presentation.
<br>
<p>After our talk, one of the more esteemed members of the audience irritatedly
<br>
asked me how I knew human intelligence wasn't the maximal possible
<br>
intelligence -- had I actually experienced superior intelligences myself?  I
<br>
was tempted to refer him to Terrence McKenna and his superintelligent
<br>
9-dimensional machine-elves, but instead I just referred to computation
<br>
theory and the obvious limitations of the human brain.  Then he asked
<br>
whether our system actually did anything, and I mentioned the Biomind and
<br>
language-processing applications, which seemed to surprise him even though
<br>
we had just talked about them in our prsentation.
<br>
<p>Most of the talks on Friday and Saturday were fairly unambitious, though
<br>
some of them were interesting technically -- the only other person
<br>
presenting a real approach to human-level intelligence, besides me and
<br>
Moshe, was Pei Wang.  Nearly all of the work presented was from a
<br>
logic-based approach to AI.  Then there were some folks who posited that
<br>
logic is a bad approach and AI researchers should focus entirely on
<br>
perception and action, and let cognition emerge directly from these.  Then
<br>
someone proposed that if you get the right knowledge representation,
<br>
human-level AI is solved and you can use just about any algorithms for
<br>
learning and reasoning, etc.  In general I didn't think the discussion ever
<br>
dug into the really deep and hard issues of achieving human-level AI, though
<br>
it came close a couple times.  For instance, there was a talk describing
<br>
work using robot vision and arm-motion to ground linguistic concepts -- but
<br>
it never got beyond the trivial level of using supervised categorization to
<br>
ground particular words in sets of pictures, or using preprogrammed
<br>
arm-control schema triggered by the output of a language parser in
<br>
preprogrammed ways..
<br>
<p>There was a lot of talk about how hard it is for academics to get funding
<br>
for academic research aimed at human-level AI, and tomorrow morning's
<br>
session (which I plan to skip -- better to stay home and work on Novamente!)
<br>
will include some brainstorming on how to improve this situation gradually
<br>
over the next N years.  It seemed that the only substantial funding source
<br>
for the work presented in the symposium was DARPA.
<br>
<p>Then, Sat. night, there was a session in which the people from our symposium
<br>
got together with the people from the 5 other AAAI symposia being held in
<br>
the same hotel.  One member from each symposium was supposed to get up and
<br>
give a talk.  I was surprised that the material described by some of the
<br>
other symposium leaders (e.g. agent-based computing, cognitive robotics)
<br>
actually was a little more relevant to human-level AI than most of the
<br>
material in our human-level AI symposium.  For some reason, nearly all of
<br>
the human-level-AI folks were from a GOFAI-ish perspective, even though the
<br>
other symposia had a lot more diversity, with people focusing on neural
<br>
nets, evolutionary programming, and so forth as well as logic.
<br>
<p>The speech of the person who summarized our symposium for the larger group
<br>
was particularly amusing.  He began by quoting me (not by name) about how
<br>
humans aren't that smart and we should be aiming higher.  He then showed
<br>
some video clips illustrating how smart humans are and how dumb robots are.
<br>
For instance: a human expertly navigating through a crowd to get to an
<br>
attractive woman, versus a robot awkwardly crashing into a wall.  Quite
<br>
funny and all.  Hey, I was pleased to have made an impression!!  The summary
<br>
of our symposium, in his view, was that human-level intelligence is
<br>
inestimably far away and no one has any idea of how to come remotely close
<br>
to achieving it.  But nevertheless, he posited, we should promote journals
<br>
and conferences on human-level AI, and the creation of test suites for the
<br>
comparison of wannabe-human-level AI systems, so as to encourage progress.
<br>
<p>Welll....
<br>
<p>It's great, of course, that a small segment of the  mainstream AI community
<br>
is willing to admit that the field of AI has wandered far from its roots,
<br>
and needs to get back to its original ambitions.  It's unfortunate that
<br>
nearly all of these folks see no hope of the field of AI achieving
<br>
human-level intelligence anytime soon, however....  They have so little hope
<br>
that they're not really willing to entertain concrete hypotheses as to how
<br>
to achieve human-level or superior AI in the near term....
<br>
<p>Anyway, in addition to catching up with Pei and Bill Hibbard, I made a
<br>
couple useful new contacts at the conference -- and interestingly, both were
<br>
industry scientists rather than academics.  For some reason there was more
<br>
broad AI vision in the industry AI researchers than the academics, in this
<br>
symposium at any rate.
<br>
<p>-- Ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10098.html">Wei Dai: "SIAI's direction"</a>
<li><strong>Previous message:</strong> <a href="10096.html">Eliezer Yudkowsky: "Approaching the end of Today and Tomorrow"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10097">[ date ]</a>
<a href="index.html#10097">[ thread ]</a>
<a href="subject.html#10097">[ subject ]</a>
<a href="author.html#10097">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:49 MDT
</em></small></p>
</body>
</html>
