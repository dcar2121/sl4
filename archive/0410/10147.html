<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Questions for Eliezer, SIAI and consciousness</title>
<meta name="Author" content="Eliezer Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Questions for Eliezer, SIAI and consciousness">
<meta name="Date" content="2004-10-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Questions for Eliezer, SIAI and consciousness</h1>
<!-- received="Tue Oct 26 14:58:39 2004" -->
<!-- isoreceived="20041026205839" -->
<!-- sent="Tue, 26 Oct 2004 16:58:37 -0400" -->
<!-- isosent="20041026205837" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Questions for Eliezer, SIAI and consciousness" -->
<!-- id="417EBA7D.9070105@pobox.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="002501c4bb8f$bcd63990$3e6f8351@mcbluecafe" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Questions%20for%20Eliezer,%20SIAI%20and%20consciousness"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Tue Oct 26 2004 - 14:58:37 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10148.html">J. Andrew Rogers: "Re: Questions for Eliezer, SIAI and consciousness"</a>
<li><strong>Previous message:</strong> <a href="10146.html">sam kayley: "Questions for Eliezer, SIAI and consciousness"</a>
<li><strong>In reply to:</strong> <a href="10146.html">sam kayley: "Questions for Eliezer, SIAI and consciousness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10148.html">J. Andrew Rogers: "Re: Questions for Eliezer, SIAI and consciousness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10147">[ date ]</a>
<a href="index.html#10147">[ thread ]</a>
<a href="subject.html#10147">[ subject ]</a>
<a href="author.html#10147">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
sam kayley wrote:
<br>
<em>&gt; What probability do you give for consciousness involving strange physics?
</em><br>
<p>I'm now as confident that consciousness does not involve strange physics as 
<br>
I was once confident that it did.  I would say &quot;No&quot; with great force, and 
<br>
expect to be wrong on at least one in three questions of equal difficulty.
<br>
<p><em>&gt; An AI, even one designed to self-improve has some basic assumptions which it
</em><br>
<em>&gt; does not make sense to change, such as its goal, and probably several more
</em><br>
<em>&gt; subtle ontological assumptions. Is it a design goal for SIAI not to include
</em><br>
<em>&gt; assumptions likely to result in nonconsensual uploading of humans even if
</em><br>
<em>&gt; evidence is found that physical effects occur in brains that do not occur
</em><br>
<em>&gt; elsewhere in the observable universe?
</em><br>
<p>Back when I thought consciousness was strange physics, yeah, this was one 
<br>
of the mental tests I threw at FAI designs.  But this is an example of a 
<br>
behavior that should arise naturally from a good design, *not* something 
<br>
that should need explicit patching - explicit patching indicates a poor 
<br>
design.  I threw that challenge at potential FAI designs to see if they 
<br>
solved the problem naturally.  In this case, if human brains involve 
<br>
strange physics and human consciousness intrinsically requires strange 
<br>
physics, then until you duplicate the strange physics and find some way to 
<br>
transfer state from one strange-physics phenomenon to another, any attempt 
<br>
to upload a human or even a laboratory sample of living brain tissue will 
<br>
fail visibly when it is impossible to formulate a non-strange-physics 
<br>
device that predicts the neurons' behaviors.  An FAI's direct physical 
<br>
examination of neurons and of human brain designs should yield the same 
<br>
conclusion, that strange physics is involved and faithful uploading to a 
<br>
normal computing device is not possible, via abstract reasoning.
<br>
<p>Incidentally, Roger Penrose explicitly does not deny that it is possible to 
<br>
create artificial consciousness.  He just denies that you can do it on 
<br>
Turing machines.  Penrose explicitly accepts that if you fathom the 
<br>
postulated strange physics of neurobiology, you should be able to do 
<br>
artificial consciousness.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10148.html">J. Andrew Rogers: "Re: Questions for Eliezer, SIAI and consciousness"</a>
<li><strong>Previous message:</strong> <a href="10146.html">sam kayley: "Questions for Eliezer, SIAI and consciousness"</a>
<li><strong>In reply to:</strong> <a href="10146.html">sam kayley: "Questions for Eliezer, SIAI and consciousness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10148.html">J. Andrew Rogers: "Re: Questions for Eliezer, SIAI and consciousness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10147">[ date ]</a>
<a href="index.html#10147">[ thread ]</a>
<a href="subject.html#10147">[ subject ]</a>
<a href="author.html#10147">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:49 MDT
</em></small></p>
</body>
</html>
