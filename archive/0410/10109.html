<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: [agi] Ben vs. the AI academics...</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: [agi] Ben vs. the AI academics...">
<meta name="Date" content="2004-10-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: [agi] Ben vs. the AI academics...</h1>
<!-- received="Sun Oct 24 08:05:15 2004" -->
<!-- isoreceived="20041024140515" -->
<!-- sent="Sun, 24 Oct 2004 10:05:16 -0400" -->
<!-- isosent="20041024140516" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: [agi] Ben vs. the AI academics..." -->
<!-- id="JNEIJCJJHIEAILJBFHILCEBMCJAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="Pine.GSO.4.44.0410240440590.6504-100000@demedici.ssec.wisc.edu" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20[agi]%20Ben%20vs.%20the%20AI%20academics..."><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sun Oct 24 2004 - 08:05:16 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10110.html">Eliezer Yudkowsky: "Philosophy vs. rigor"</a>
<li><strong>Previous message:</strong> <a href="10108.html">Ben Goertzel: "RE: SIAI: Donate Today and Tomorrow"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10109">[ date ]</a>
<a href="index.html#10109">[ thread ]</a>
<a href="subject.html#10109">[ subject ]</a>
<a href="author.html#10109">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; A lot of the systems had impressive behavior, but most were
</em><br>
<em>&gt; dead end approaches, in my opinion, because they made logical
</em><br>
<em>&gt; reasoning fundamental with learning as an add-on. The most
</em><br>
<em>&gt; impressive talk from the main stream AI community was by Deb
</em><br>
<em>&gt; Roy, who is achieving interesting vision-language coordination
</em><br>
<em>&gt; with systems that are fundamentally about learning.
</em><br>
<em>&gt;
</em><br>
<em>&gt; It was good to see Ben again, and to meet Moshe Looks and Pei
</em><br>
<em>&gt; Wang.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Cheers,
</em><br>
<em>&gt; Bill
</em><br>
<p>Hey Bill --
<br>
<p>Just a brief comment about Deb Roy's work., then some more comments on
<br>
human-level AI in general.
<br>
<p>Deb's work is really interesting, however it actually represents a move AWAY
<br>
from learning, as compared to his thesis work a few years ago.  Then he was
<br>
focusing on having his software system learn visuomotor groundings for
<br>
linguistic terms (nouns like &quot;apple&quot;, etc.).  Now he has been making his
<br>
system do more complex stuff, but via hard-coding control schema into it,
<br>
rather than via learning.  When Moshe and I talked to him after his talk,
<br>
however, he said his next step would be to implement some approach to
<br>
learning these control schemata.  But he didn't seem to have such a clear
<br>
idea about how he'd do it.  When Moshe asked him about how he's implement
<br>
grounding of prepositional and subject-argument relationships (arguably the
<br>
nontrivial part of language-grounding), he said he didn't have an approach
<br>
to that yet because he didn't know any good way to represent that kind of
<br>
knowledge on the cognitive level.
<br>
<p>So, I think his work has tremendous promise; but yet, I couldn't help wish
<br>
he'd pushed it in a more learning-based direction during the last few years.
<br>
<p>On the other hand, I can sympathize, because -- for instance -- over the
<br>
last year we've had a Novamente team member (Mike Ross) create a hard-coded
<br>
language processing module.  Why?  Because we needed it for a commercial
<br>
project.  (Deb Roy is an academic -- academics don't have revenue pressures,
<br>
but they often have demo pressures associated with funding sources!).  Now,
<br>
during 2005 Mike will replace this hard-coded language processing module
<br>
with a learning-oriented language processing module.  Basically, the need
<br>
for incremental useful results can be a burden.  It's good because it keeps
<br>
you from moving a long way in a useless direction, but it can also
<br>
tremendously slow down progress toward long-term goals.
<br>
<p>Earlier this year, in the US Virgin Islands, Marvin Minsky and his friends
<br>
had a private AI symposium on the topic of human-level intelligence.  It was
<br>
written in up the June 2004 issue of the AI Magazine, and it seems to have
<br>
been a bit more interesting than the AAAI symposium that we just attended.
<br>
No real solutions were proposed, though; the focus was on Minsky's and
<br>
Sloman's architectures for human-level AI (e.g. Minsky's Emotion  Machine
<br>
stuff).
<br>
<p>One idea proposed by Minsky at that conference is something I disagree with
<br>
pretty radically.  He says that until we understand human-level
<br>
intelligence, we should make our theories of mind as complex as possible,
<br>
rather than simplifying them -- for fear of leaving something out!  This
<br>
reminds me of some of the mistakes we made at Webmind Inc.  I believe our
<br>
approach to AI there was fundamentally sound, yet the theory underlying it
<br>
(not the philosophy of mind, but the intermediate level
<br>
computational-cog-sci theory) was too complex which led to a software system
<br>
that was too large and complex and hard to maintain and tune.  Contra Minsky
<br>
and Webmind, in Novamente I've sought to create the simplest possible design
<br>
that accounts for all the diverse phenomena of mind on an emergent level.
<br>
Minsky is really trying to jam every aspect of the mind into his design on
<br>
the explicit level.
<br>
<p>Another idea that came up at the Virgin Islands symposium was to create a
<br>
simulation world in which AI systems control agents that collectively try to
<br>
solve simple object-manipulation tasks.  The prototype case is a bunch of
<br>
kids collaborating to build towers out of blocks.  The idea was also raised
<br>
of making the simulation more realistic by making the block-building take
<br>
place in a simulated livingroom or restaurant or some such.  I like this
<br>
line of thinking because it is closely related to the AGI-SIM simulation
<br>
world project that we're currently working on (an open-source sim-world to
<br>
be used for Novamente bue also by other projects).
<br>
<p>-- Ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10110.html">Eliezer Yudkowsky: "Philosophy vs. rigor"</a>
<li><strong>Previous message:</strong> <a href="10108.html">Ben Goertzel: "RE: SIAI: Donate Today and Tomorrow"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10109">[ date ]</a>
<a href="index.html#10109">[ thread ]</a>
<a href="subject.html#10109">[ subject ]</a>
<a href="author.html#10109">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:49 MDT
</em></small></p>
</body>
</html>
