<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: What I think is wrong with Eli's current approach</title>
<meta name="Author" content="Marc Geddes (marc_geddes@yahoo.co.nz)">
<meta name="Subject" content="What I think is wrong with Eli's current approach">
<meta name="Date" content="2004-10-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>What I think is wrong with Eli's current approach</h1>
<!-- received="Sun Oct 24 23:30:55 2004" -->
<!-- isoreceived="20041025053055" -->
<!-- sent="Mon, 25 Oct 2004 18:30:54 +1300 (NZDT)" -->
<!-- isosent="20041025053054" -->
<!-- name="Marc Geddes" -->
<!-- email="marc_geddes@yahoo.co.nz" -->
<!-- subject="What I think is wrong with Eli's current approach" -->
<!-- id="20041025053054.46154.qmail@web20227.mail.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Marc Geddes (<a href="mailto:marc_geddes@yahoo.co.nz?Subject=Re:%20What%20I%20think%20is%20wrong%20with%20Eli's%20current%20approach"><em>marc_geddes@yahoo.co.nz</em></a>)<br>
<strong>Date:</strong> Sun Oct 24 2004 - 23:30:54 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10140.html">Marc Geddes: "RE: A funding suggestion: Solve The Riemann hypothesis ;)"</a>
<li><strong>Previous message:</strong> <a href="10138.html">Ben Goertzel: "RE: JOIN: Ralph's Intro"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10143.html">Ben Goertzel: "RE: What I think is wrong with Eli's current approach"</a>
<li><strong>Reply:</strong> <a href="10143.html">Ben Goertzel: "RE: What I think is wrong with Eli's current approach"</a>
<li><strong>Maybe reply:</strong> <a href="10187.html">Marc Geddes: "Re: What I think is wrong with Eli's current approach"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10139">[ date ]</a>
<a href="index.html#10139">[ thread ]</a>
<a href="subject.html#10139">[ subject ]</a>
<a href="author.html#10139">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eli said&gt;
<br>
<p><em>&gt;Someone other than me needs to talk to Marc Geddes
</em><br>
before he snaps completely and becomes another
<br>
Mentifex, complete with incomprehensible ASCII
<br>
diagrams. I don't have the time and I don't have the
<br>
tact, but Geddes was once a promising mind and there
<br>
might be some way to pull him out of this.
<br>
<p>Heh.  The philosophical schematic was designed only to
<br>
make sense to someone who already has an inkling of my
<br>
general theory.  It wouldn’t mean much to you, but it
<br>
does to me.  Be assured I do have a general theory
<br>
that makes some degree of sense.  I suggest you come
<br>
back and take a another look at my schematic after
<br>
you’ve been working on FAI theory for 10 more years ;)
<br>
<p>But O.K Eli I promise that I will not continue to
<br>
discuss my own ill-formed ideas on Sl4 (excepting this
<br>
one post).  I am simply going to try to explain, as
<br>
best I can, what I think is wrong with your current
<br>
approach. 
<br>
<p>My schematic on the SL4 wiki:
<br>
<p><a href="http://www.sl4.org/bin/wiki.pl?FundamentalTheoremofMorality">http://www.sl4.org/bin/wiki.pl?FundamentalTheoremofMorality</a>
<br>
<p>You'll notice in my schematic the entry for 'POLITICS'
<br>
and 'POSSIBILITY' in my matrix reads 'MARKET', which
<br>
in my explanation of terms I said was referring to CV
<br>
(Collective Volition is a kind of highly sophisticated
<br>
'futures market').  In fact you'll see that a lot of
<br>
the issues that Eli is dealing with I have placed in
<br>
the POLITICS row of the Cognition matrix, instead of
<br>
the ETHICS row.
<br>
<p>In short I think that CV (Collective Volition) is 'a
<br>
nice place to live', or *a good political system*.  It
<br>
is *not*, I believe, something that can be
<br>
comprehended by or embodied in a single agent.  So CV
<br>
is the operational *global outcome* of morality, *not*
<br>
something that a singleton AI  *does*.  What exactly
<br>
do I mean?  Well, I'm really saying that I think that
<br>
the whole top-down approach *can't work* 
<br>
<p>Eli's requirement that his AI *not* be sentient should
<br>
be the tip-off that there is something highly suspect
<br>
and peculiar about his proposed RPOP.   Should actual
<br>
consciousness emerge in simulations of sentients, then
<br>
RPOP is immediately stymied, since it would not be
<br>
able to make effective simulations of sentients
<br>
without violations of *person-hood*.  Worse, a
<br>
conscious (sentient) RPOP would immediately run into a
<br>
problem with self-reference.  A conscious RPOP would
<br>
be a *person* itself, and a suitably generalized
<br>
definition of *person-hood* would end up with the RPOP
<br>
having to include its own volition in the calculation
<br>
of CV.  This leads a fatal infinite regress. 
<br>
<p>Is general intelligence without sentience possible?  I
<br>
say not, not in any *practical* sense.  Of course we
<br>
can imagine a theoretical general intelligence with
<br>
infinite computational power.  In that case, I agree
<br>
that general intelligence without sentience would be
<br>
possible.  One would simply take a pure Bayesian
<br>
reasoning machine, capable of duplicating any kind of
<br>
intelligence without sentience by burning up as much
<br>
computational resources as it needed.  
<br>
<p>But in the real world, there can be no such thing as
<br>
*infinite computational resources*.  Any real world AI
<br>
will only have access to *finite* computational
<br>
resources at any given time.  General intelligence
<br>
would require *useful computational short-cuts* in
<br>
order to do useful things in real-time.  Theoretically
<br>
ideal Bayesian reasoning won't work, because it will
<br>
quickly run into computational intractability for
<br>
complex problems.  So all finite resource AI's would
<br>
need *specialized computational short-cuts*.  And
<br>
these *computational short-cuts* I maintain, are what
<br>
*necessarily* give rise to qualia (consciousness and
<br>
sentience). 
<br>
<p>To sum up:  Any RPOP would quickly run into
<br>
computational intractability if it stuck with pure
<br>
Bayesian reasoning.  It would be forced to resort to
<br>
*computational short-cuts*.  These would, I claim,
<br>
inevitably give rise to consciousness.  With qualia
<br>
present the RPOP would now be a 'Person'.  A suitably
<br>
generalized definition of 'Person-Hood' would result
<br>
in the RPOP being forced to include its own volition
<br>
in the CV calculation.  This would give rise to an
<br>
infinite regress.  Ergo, Collective Volition cannot be
<br>
calculated by a singleton RPOP and the entire top-down
<br>
approach is flawed.    
<br>
<p>I should make it clear that I *do* agree that CV
<br>
(Collective Volition) is the ideal *political system*.
<br>
&nbsp;That is, I agree that CV is *a nice place to live*. 
<br>
But I disagree that CV is something capable of being
<br>
embodied in a singleton RPOP and imposed from the
<br>
top-down.  Eli's mistake is his insistence on the
<br>
top-down approach.  He has mistaken a *distributed
<br>
system* (Collective Volition) for a mind.  But in fact
<br>
CV is not a singleton.
<br>
<p>Under my theory, all working FAI's are necessarily
<br>
sentients which assign themselves *Person-hood*
<br>
status.  No singleton FAI can possibly implement
<br>
Collective Volition (since any FAI is itself
<br>
*included* in what constitutes Collective Volition). 
<br>
None the less, CV would still represent an ideal
<br>
*political system* for sentients, which the FAI's
<br>
would try to act in harmony with.  
<br>
<p>Under my theory no singeton FAI can fully calculate
<br>
CV, but it *can* still obtain some degree of
<br>
understanding and determine which actions are and are
<br>
not in harmony in CV.  That is,  FAI could still
<br>
perform calculations about CV sufficient to establish
<br>
a sort of 'futures market' to help determine which
<br>
actions were *Friendly* and which were *Unfriendly*. 
<br>
<p>CV places constraints on permissible sentient actions.
<br>
&nbsp;But it's a distributed *global system* and *not*
<br>
something that can be embodied in a Singleton as
<br>
Eliezer thinks.  
<br>
<p>Of course I've banging away with my objections on SL4
<br>
for a couple of years now ;)  Recall that I've always
<br>
said that;
<br>
<p>(1)  (Practical) general intelligence without
<br>
sentience is impossible
<br>
(2)  Completely selfless AI is impossible
<br>
<p>Now though, I think my objections are stronger because
<br>
I've got some plausible reasons for them and my own
<br>
general theory of FAI.
<br>
<p>Eliezer.  And me.  One of us has to be right out of
<br>
this, the other has to be wrong (Marc chuckles to
<br>
himself and nods his head).  The time is fast
<br>
approaching when we'll find out who's who...
<br>
<p><p>=====
<br>
&quot;Live Free or Die, Death is not the Worst of Evils.&quot;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Gen. John Stark
<br>
<p>&quot;The Universe...or nothing!&quot;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-H.G.Wells
<br>
<p><p>Please visit my web-sites.
<br>
<p>Sci-Fi and Fantasy                : <a href="http://www.prometheuscrack.com">http://www.prometheuscrack.com</a>
<br>
Mathematics, Mind and Matter      : <a href="http://www.riemannai.org">http://www.riemannai.org</a>
<br>
<p>Find local movie times and trailers on Yahoo! Movies.
<br>
<a href="http://au.movies.yahoo.com">http://au.movies.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10140.html">Marc Geddes: "RE: A funding suggestion: Solve The Riemann hypothesis ;)"</a>
<li><strong>Previous message:</strong> <a href="10138.html">Ben Goertzel: "RE: JOIN: Ralph's Intro"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10143.html">Ben Goertzel: "RE: What I think is wrong with Eli's current approach"</a>
<li><strong>Reply:</strong> <a href="10143.html">Ben Goertzel: "RE: What I think is wrong with Eli's current approach"</a>
<li><strong>Maybe reply:</strong> <a href="10187.html">Marc Geddes: "Re: What I think is wrong with Eli's current approach"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10139">[ date ]</a>
<a href="index.html#10139">[ thread ]</a>
<a href="subject.html#10139">[ subject ]</a>
<a href="author.html#10139">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:49 MDT
</em></small></p>
</body>
</html>
