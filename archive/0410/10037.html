<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: SIAI:  Donate Today and Tomorrow</title>
<meta name="Author" content="Eliezer Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: SIAI:  Donate Today and Tomorrow">
<meta name="Date" content="2004-10-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: SIAI:  Donate Today and Tomorrow</h1>
<!-- received="Fri Oct 22 11:29:22 2004" -->
<!-- isoreceived="20041022172922" -->
<!-- sent="Fri, 22 Oct 2004 13:28:58 -0400" -->
<!-- isosent="20041022172858" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: SIAI:  Donate Today and Tomorrow" -->
<!-- id="4179435A.8030608@pobox.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="2D9FC6D73BBC474DBBC979CE094CB33C2396D5@exchange-hou.velaw.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20SIAI:%20%20Donate%20Today%20and%20Tomorrow"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Fri Oct 22 2004 - 11:28:58 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10038.html">Aleksei Riikonen: "Re: SIAI: Donate Today and Tomorrow"</a>
<li><strong>Previous message:</strong> <a href="10036.html">Robin Lee Powell: "Why I donate to the SIAI"</a>
<li><strong>In reply to:</strong> <a href="10030.html">Aikin, Robert: "RE: SIAI:  Donate Today and Tomorrow"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10043.html">Robin Lee Powell: "Re: SIAI:  Donate Today and Tomorrow"</a>
<li><strong>Reply:</strong> <a href="10043.html">Robin Lee Powell: "Re: SIAI:  Donate Today and Tomorrow"</a>
<li><strong>Reply:</strong> <a href="10048.html">Nathan Russell: "Re: SIAI: Donate Today and Tomorrow"</a>
<li><strong>Reply:</strong> <a href="10058.html">Psy-Kosh: "Re: SIAI:  Donate Today and Tomorrow"</a>
<li><strong>Reply:</strong> <a href="10061.html">Mikko Rauhala: "Re: SIAI:  Donate Today and Tomorrow"</a>
<li><strong>Reply:</strong> <a href="10073.html">Christopher Healey: "RE: SIAI:  Donate Today and Tomorrow"</a>
<li><strong>Reply:</strong> <a href="10081.html">Giu1i0 Pri5c0: "Re: [extropy-chat] Re: SIAI: Donate Today and Tomorrow"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10037">[ date ]</a>
<a href="index.html#10037">[ thread ]</a>
<a href="subject.html#10037">[ subject ]</a>
<a href="author.html#10037">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On wta-talk and Extropians, Giulio Prisco recently noted that the Raelian
<br>
cult seems to have a surprising amount of transhumanist content, mixed in
<br>
with gibberish about flying saucers.
<br>
<p>Giulio concluded by asking:
<br>
<em>&gt; 
</em><br>
<em>&gt; I am sure Rael himself and other top officers never believed in the 
</em><br>
<em>&gt; flying-saucers layer so, again, I wonder why it is there when the 
</em><br>
<em>&gt; [transhumanist] message would stand on its own.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Then I think that: The Raelians have 60,000 paying members worldwide and
</em><br>
<em>&gt; a lot of money. All transhumanist associations together have perhaps
</em><br>
<em>&gt; 300 paying members. I wonder what conclusions we should make.
</em><br>
<p>I (Eliezer) replied:
<br>
<em>&gt; 
</em><br>
<em>&gt; You should conclude that... the other 100 cults that tried to get 
</em><br>
<em>&gt; started using flying-saucer nonsense didn't make it big, so you never 
</em><br>
<em>&gt; heard about them in the media?
</em><br>
<p>There are more people trying to start flying-saucer cults than 
<br>
transhumanist organizations, so you can't necessarily conclude that the 
<br>
probability of success for a flying-saucer cult is higher.
<br>
<p>Nonetheless, Giulio has a point.
<br>
<p>It is embarassing that rationalists have more trouble cooperating than 
<br>
flying-saucer nuts.  I'm glad that here on SL4, at least, the &quot;Donate Today 
<br>
and Tomorrow&quot; initiative made it nearly an entire day before the inevitable 
<br>
chorus of naysaying started.  The Extropians list was not so lucky.
<br>
<p>I draw the lesson that's dangerous to be half a rationalist.  If you pick 
<br>
up some rationalist skills, there are certain other skills you have to 
<br>
adopt to compensate.  If you learn to see the flaws in arguments, you also 
<br>
have to learn additional skills to make sure you apply the same level of 
<br>
criticism to the ideas you like as to those you dislike.  Otherwise, the 
<br>
effect of learning to nitpick is to lock you into ideas that make you feel 
<br>
good, which really isn't what rationality is about.
<br>
<p>If you learn not to be certain, you also need to learn to live and act 
<br>
without certainty, and not demand overwhelming evidence to compel you.  A 
<br>
rationalist knows that not even the theory of evolution is certain (though 
<br>
I would argue that it is the most strongly confirmed theory in the history 
<br>
of science).  Creationists think that as long as evolution is not certain, 
<br>
they don't have to believe it.  If you cast aside certainty and learn the 
<br>
art of skepticism, you'd better also cast aside the principle that only 
<br>
certainty can compel you to give up an idea.
<br>
<p>Cultists are like bosons.  Transhumanists are like fermions.  I am going to 
<br>
describe, as dispassionately as I can, the difference between Raelianism 
<br>
and transhumanism that makes transhumanism less effective.
<br>
<p>If a high-status Raelian says something, no one can question him; if you 
<br>
try you're out of the cult.  There's a chorus of agreement instead of a 
<br>
chorus of disagreement.  Everyone sees the atmosphere of agreement, and 
<br>
they feel more confident in the ideas presented.  Anyone who doesn't feel 
<br>
confident keeps their objections to themselves.  Anyone who really 
<br>
disagrees leaves the cult, and then the remaining people are more in 
<br>
agreement and reinforce each other.  Like evaporative cooling; fast-moving 
<br>
minds are ejected.  A counterintuitive observation of researchers who study 
<br>
cults is that cults often increase in fanaticism following what ought to be 
<br>
a setback - for example, a relevation that the founder clubbed cute baby 
<br>
seals or had an affair with Nathaniel Branden.  Part of what happens is 
<br>
that the people with a lingering trace of sanity leave first, and then 
<br>
they're no longer around to hold the others back, who reinforce each other 
<br>
still further.  When new people come in, they're confronted with 
<br>
wall-to-wall agreement, and the part of human nature that is vulnerable to 
<br>
peer pressure concludes that if everyone else agrees on something, it must 
<br>
be insane to think otherwise.  Raising a doubt is met with scorn and other 
<br>
forms of negative reinforcement, making people less likely to doubt again. 
<br>
&nbsp;&nbsp;Consensus builds, discord dies, the Raelians move in harmony and lase.
<br>
<p>And this also of the Raelians:  They are not afraid to be passionate about 
<br>
their ideas.
<br>
<p>Now let's look at transhumanism.  SIAI has already received on the order of 
<br>
20 donations.  I wasn't planning to reveal this number until afterward, but 
<br>
these strange circumstances compel me to do so.  Some of the donors 
<br>
included congratulatory notes saying how effective the essay was, or how it 
<br>
finally inspired them to get moving, and so on.  Here's a sample, quoted 
<br>
with permission from Jesse Merriman, who donated $111.11:  &quot;I decided to 
<br>
give SIAI a little bit more.  One more hundred, one more ten, one more 
<br>
single, one more dime, and one more penny.  All may not be for one, but 
<br>
this one is trying to be for all.&quot;
<br>
<p>But none of those donors posted their congratulations and agreement to a 
<br>
mailing list, not one.  As far as any of those donors knew, they were 
<br>
alone.  And now they're looking at people saying scornfully why they 
<br>
shouldn't have donated!  The criticism, the justifications or excuses for 
<br>
not donating, *that* part is displayed proudly in the open.  A newcomer 
<br>
would see wall-to-wall disagreement.
<br>
<p>This is, in its own warped way, just as wrong as what the Raelians are doing.
<br>
<p>If a bias toward credulity is wrong, you still can't go right by reversing 
<br>
the bias.  The opposite of a great mistake is nearly always another great 
<br>
mistake, the correct answer being something else entirely.
<br>
<p>Suppose that 20 donors *had* posted their agreement on the SL4 list.  You'd 
<br>
feel pretty uncomfortable joining them, wouldn't you?  I know that if I 
<br>
said something at a talk and twenty people in the audience stood up and 
<br>
shouted &quot;You're absolutely right!&quot;, I'd stand around with my mouth open, 
<br>
completely at a loss for words.  And you'd also be unnerved, right?  Much 
<br>
more unnerved than if you were at a conference and 20 people asked scathing 
<br>
questions of a speaker.  We're as uncomfortable together as the Raelians 
<br>
are apart.
<br>
<p>That's just as wrong, and if we ever want to get anywhere, we'll have to 
<br>
make a deliberate effort to get over it.  It's dangerous to be half a 
<br>
rationalist.  If you master some skills, you have to master others or end 
<br>
up worse off than before.  If you learn to disagree with authority without 
<br>
shame, you have to learn to agree with authority without shame.  If you 
<br>
challenge conventional ideas proudly, you have to accept conventional ideas 
<br>
proudly.  I know how to deal with disagreement, but hearing people agree 
<br>
with me makes me feel uncomfortable.  This I acknowledge as my failing, and 
<br>
I accept responsibility for getting over it.
<br>
<p>I think we can do, if not quite as well as flying-saucer nuts, maybe 
<br>
one-tenth as well.  But it's going to take a deliberate effort. 
<br>
Rationalists can hold their own against irrationalists, but not easily.
<br>
<p>We have to be strong without being certain, by a deliberate act of will, by 
<br>
the conscious decision that certainty is not required for strength.
<br>
<p>We have to act in unison without being conformist, by an act of will, by 
<br>
the conscious choice that it makes sense to cooperate even when we aren't 
<br>
in full agreement.
<br>
<p>We have to forsake peer pressure and the instinct to believe what others 
<br>
are saying, and consciously evaluate the probability that someone else 
<br>
knows more than we do, taking into account neither personal like nor 
<br>
personal dislike.
<br>
<p>We have to reject the common misconception that the art of finding the 
<br>
correct answer to questions of fact - the art some call &quot;rationality&quot; - 
<br>
means cynicism, ironic detachment, and the refusal to feel emotion.  Let us 
<br>
choose our beliefs on the sole basis of correspondence with reality.  If 
<br>
those beliefs call forth our passions, then let us feel!
<br>
<p>We have to learn to express our unity as well as our disagreement, speak 
<br>
our rational agreement along with our rational criticism, show newcomers 
<br>
*both* sides of the issue, swallow hard and defy our fear of public harmony.
<br>
<p>I ask of SIAI's donors:  Speak up, and hold your heads high without shame!
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10038.html">Aleksei Riikonen: "Re: SIAI: Donate Today and Tomorrow"</a>
<li><strong>Previous message:</strong> <a href="10036.html">Robin Lee Powell: "Why I donate to the SIAI"</a>
<li><strong>In reply to:</strong> <a href="10030.html">Aikin, Robert: "RE: SIAI:  Donate Today and Tomorrow"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10043.html">Robin Lee Powell: "Re: SIAI:  Donate Today and Tomorrow"</a>
<li><strong>Reply:</strong> <a href="10043.html">Robin Lee Powell: "Re: SIAI:  Donate Today and Tomorrow"</a>
<li><strong>Reply:</strong> <a href="10048.html">Nathan Russell: "Re: SIAI: Donate Today and Tomorrow"</a>
<li><strong>Reply:</strong> <a href="10058.html">Psy-Kosh: "Re: SIAI:  Donate Today and Tomorrow"</a>
<li><strong>Reply:</strong> <a href="10061.html">Mikko Rauhala: "Re: SIAI:  Donate Today and Tomorrow"</a>
<li><strong>Reply:</strong> <a href="10073.html">Christopher Healey: "RE: SIAI:  Donate Today and Tomorrow"</a>
<li><strong>Reply:</strong> <a href="10081.html">Giu1i0 Pri5c0: "Re: [extropy-chat] Re: SIAI: Donate Today and Tomorrow"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10037">[ date ]</a>
<a href="index.html#10037">[ thread ]</a>
<a href="subject.html#10037">[ subject ]</a>
<a href="author.html#10037">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:49 MDT
</em></small></p>
</body>
</html>
