<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: On Our Duty to Not Be Responsible for Artificial Minds</title>
<meta name="Author" content="Michael Roy Ames (michaelroyames@yahoo.com)">
<meta name="Subject" content="Re: On Our Duty to Not Be Responsible for Artificial Minds">
<meta name="Date" content="2005-08-14">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: On Our Duty to Not Be Responsible for Artificial Minds</h1>
<!-- received="Sun Aug 14 17:00:25 2005" -->
<!-- isoreceived="20050814230025" -->
<!-- sent="Sun, 14 Aug 2005 15:59:51 -0700" -->
<!-- isosent="20050814225951" -->
<!-- name="Michael Roy Ames" -->
<!-- email="michaelroyames@yahoo.com" -->
<!-- subject="Re: On Our Duty to Not Be Responsible for Artificial Minds" -->
<!-- id="007a01c5a123$e16e59c0$6401a8c0@MRA02" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="JNEIJCJJHIEAILJBFHILOEJAFFAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Roy Ames (<a href="mailto:michaelroyames@yahoo.com?Subject=Re:%20On%20Our%20Duty%20to%20Not%20Be%20Responsible%20for%20Artificial%20Minds"><em>michaelroyames@yahoo.com</em></a>)<br>
<strong>Date:</strong> Sun Aug 14 2005 - 16:59:51 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11910.html">Marc Geddes: "Shock Level 5 (SL5) - 'The Theory Of Everything'"</a>
<li><strong>Previous message:</strong> <a href="11908.html">Peter de Blanc: "Responsibility"</a>
<li><strong>In reply to:</strong> <a href="11906.html">Ben Goertzel: "RE: On Our Duty to Not Be Responsible for Artificial Minds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11887.html">Samantha Atkins: "Re: On Our Duty to Not Be Responsible for Artificial Minds"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11909">[ date ]</a>
<a href="index.html#11909">[ thread ]</a>
<a href="subject.html#11909">[ subject ]</a>
<a href="author.html#11909">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Goertzel wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; IMO, the appropriate standard for researchers in AGI, strong nanotech,
</em><br>
<em>&gt; or other highly powerful and dangerous areas is:
</em><br>
<em>&gt;
</em><br>
<em>&gt; 1) higher than the standard for scientists working in less obviously
</em><br>
<em>&gt; dangerous areas
</em><br>
<em>&gt;
</em><br>
<em>&gt; 2) lower than the unreasonable standard that you propose (&quot;total
</em><br>
<em>&gt; moral responsibility for all indirect consequences of one's work&quot;)
</em><br>
<em>&gt;
</em><br>
<em>&gt; [snip]
</em><br>
<em>&gt;
</em><br>
<em>&gt; I agree that the moral responsibilities are different, but I don't
</em><br>
<em>&gt; agree that they are as extreme as your prior email implied.
</em><br>
<em>&gt;
</em><br>
<p>Ben, I too think that the responsibility level was overstated, but my 
<br>
reasoning may differ from yours.  The human concept of responsibility is 
<br>
part of our social system, as pointed out tangentially by Peter de Blanc in 
<br>
an recent post (Subject: &quot;Responsibility&quot;).  Because of the existential 
<br>
risks involved in creating AI, the metaphorical concept of *levels of 
<br>
responsibility* breaks down. To give an example of how it breaks down: if 
<br>
humanity were to be wiped out there would be no-one around to hold or be 
<br>
held responsible.  Using the concept of 'responsibility' to talk about 
<br>
persons incurring existential risks is misleading, rather like using the 
<br>
concept of 'assertiveness' to talk about homicidal maniacs.  There is no 
<br>
level of 'responsibility', no matter how high, that is applicable to the 
<br>
possibility of ending of humanity.  Other words and concepts are needed.
<br>
<p>Eliezer wrote:
<br>
<em>&gt; I assign full responsibility to the AI researcher for all
</em><br>
<em>&gt; consequences, intended or unintended.  An AI researcher has a
</em><br>
<em>&gt; responsibility to choose an AI design with predictable
</em><br>
<em>&gt; consequences.
</em><br>
<p>This only makes sense if it is possible to choose an AI design with 
<br>
predictable consequences.  That is not possible.  If the phrase were changed 
<br>
to &quot;possible to choose an AI design with predictable behaviors&quot;, then the 
<br>
sentence makes sense.  It is possible to build something with predictable 
<br>
behaviors, and I would largely agree with assigning responsibility to the 
<br>
researcher in that case.  There is some smaller amount of responsibility 
<br>
that should be assigned to other people who know about the researcher's 
<br>
work, and an even smaller amount to society in general IMO.
<br>
<p>Consequences are things that happen whether our models predict them or not. 
<br>
An AI may have more sophisticated models with greater powers of prediction 
<br>
than a human being, but not infinite powers.  An AI could steer reality onto 
<br>
the paths we prefer, but we will never be 100% certain of the distant 
<br>
consequences of our, or its actions.  Consequences can be near or far from 
<br>
actions that are supposed to have caused them.  The distance between is 
<br>
usually measured in terms of other actions and events coming between the 
<br>
initial action and its supposed consequence.  Greater distance often (but 
<br>
not always) results in reduced attribution of causality to an action.
<br>
<p>A lot of things can happen in a universe as big as ours, things that were 
<br>
not and could not have been anticipated by an AI's designer, or the AI 
<br>
itself.  Should we then quail before the infinite possibilities and succumb 
<br>
to the first UFAI that gets cobbled together?  SIAI's very existence answers 
<br>
that question.
<br>
<p>Michael Roy Ames
<br>
Singularity Institute For Artificial Intelligence Canada Association
<br>
<a href="http://www.intelligence.org/canada">http://www.intelligence.org/canada</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11910.html">Marc Geddes: "Shock Level 5 (SL5) - 'The Theory Of Everything'"</a>
<li><strong>Previous message:</strong> <a href="11908.html">Peter de Blanc: "Responsibility"</a>
<li><strong>In reply to:</strong> <a href="11906.html">Ben Goertzel: "RE: On Our Duty to Not Be Responsible for Artificial Minds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11887.html">Samantha Atkins: "Re: On Our Duty to Not Be Responsible for Artificial Minds"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11909">[ date ]</a>
<a href="index.html#11909">[ thread ]</a>
<a href="subject.html#11909">[ subject ]</a>
<a href="author.html#11909">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:51 MDT
</em></small></p>
</body>
</html>
