<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: [JOIN] Chris Paget</title>
<meta name="Author" content="H C (lphege@hotmail.com)">
<meta name="Subject" content="RE: [JOIN] Chris Paget">
<meta name="Date" content="2005-08-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: [JOIN] Chris Paget</h1>
<!-- received="Mon Aug 22 18:53:05 2005" -->
<!-- isoreceived="20050823005305" -->
<!-- sent="Tue, 23 Aug 2005 00:53:02 +0000" -->
<!-- isosent="20050823005302" -->
<!-- name="H C" -->
<!-- email="lphege@hotmail.com" -->
<!-- subject="RE: [JOIN] Chris Paget" -->
<!-- id="BAY101-F7086AE4E21D8BFE7473ECDCA90@phx.gbl" -->
<!-- inreplyto="430A6F08.2060301@tombom.co.uk" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> H C (<a href="mailto:lphege@hotmail.com?Subject=RE:%20[JOIN]%20Chris%20Paget"><em>lphege@hotmail.com</em></a>)<br>
<strong>Date:</strong> Mon Aug 22 2005 - 18:53:02 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12065.html">Randall Randall: "Re: Transcript. please? (Re: AI-Box Experiment 3)"</a>
<li><strong>Previous message:</strong> <a href="12063.html">Chris Paget: "[JOIN] Chris Paget"</a>
<li><strong>In reply to:</strong> <a href="12063.html">Chris Paget: "[JOIN] Chris Paget"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12064">[ date ]</a>
<a href="index.html#12064">[ thread ]</a>
<a href="subject.html#12064">[ subject ]</a>
<a href="author.html#12064">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;The stuff I've had time to read on the SIAI website appears to be fairly 
</em><br>
<em>&gt;high-level; they've certainly solved some interesting problems before 
</em><br>
<em>&gt;they've even arisen, using some clever reasoning.  However, I disagree with 
</em><br>
<em>&gt;the statement that &quot;...the search for a single essence of intelligence lies 
</em><br>
<em>&gt;at the center of AI's previous failures&quot;.  I believe the problem is quite 
</em><br>
<em>&gt;the opposite; we have not yet looked hard enough at the overall problem to 
</em><br>
<em>&gt;realise that the most complex problem (as we see it) is actually the 
</em><br>
<em>&gt;simplest - that of how to integrate emotion into an artificial mind.
</em><br>
<em>&gt;
</em><br>
<em>&gt;My thinkings have largely focussed upon this problem, with some startling 
</em><br>
<em>&gt;conclusions.  I believe that emotion is a fundamental component of 
</em><br>
<em>&gt;intelligence, that the two are inextricably linked, and that it may even be 
</em><br>
<em>&gt;the case that they cannot exist without each other.  I won't go into too 
</em><br>
<em>&gt;much detail (just in case I'm emailing a black hole here), but I believe 
</em><br>
<em>&gt;that a simple system, constructed around some very basic principles (I 
</em><br>
<em>&gt;refer to it as emotional mechanics) can be emergent, and that the emerging 
</em><br>
<em>&gt;properties and behaviours are what we would classify as intelligence.
</em><br>
<p><p><p>Sounds promising to me, but I think Michael Wilson would probably vomit all 
<br>
over himself before agreeing with me on that point.
<br>
<p><p><p><p><p><em>&gt;From: Chris Paget &lt;<a href="mailto:ivegotta@tombom.co.uk?Subject=RE:%20[JOIN]%20Chris%20Paget">ivegotta@tombom.co.uk</a>&gt;
</em><br>
<em>&gt;Reply-To: <a href="mailto:sl4@sl4.org?Subject=RE:%20[JOIN]%20Chris%20Paget">sl4@sl4.org</a>
</em><br>
<em>&gt;To: <a href="mailto:sl4@sl4.org?Subject=RE:%20[JOIN]%20Chris%20Paget">sl4@sl4.org</a>
</em><br>
<em>&gt;Subject: [JOIN] Chris Paget
</em><br>
<em>&gt;Date: Tue, 23 Aug 2005 01:34:16 +0100
</em><br>
<em>&gt;
</em><br>
<em>&gt;Hi all,
</em><br>
<em>&gt;
</em><br>
<em>&gt;I've been pointed here by a couple of folks over at SIAI, since I have some 
</em><br>
<em>&gt;ideas about AGI - somewhat controversial ones by all counts.  So, by way of 
</em><br>
<em>&gt;a join post, I'll copy and paste the relevant bits from the SI list...
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;A quick disclaimer:  Today was the first time I even heard the phrase 
</em><br>
<em>&gt;&quot;technological singularity&quot;, although I've been exploring the idea for some 
</em><br>
<em>&gt;time now.  I'm definitely not &quot;up&quot; on the terminology, so apologies in 
</em><br>
<em>&gt;advance for any misnomers :)
</em><br>
<em>&gt;
</em><br>
<em>&gt;Not-quite-first, an introduction.  My name is Chris Paget, I'm a 
</em><br>
<em>&gt;27-year-old security consultant who lives and works in London.  I'm married 
</em><br>
<em>&gt;(for almost a year now) to an american, Erin, and we're in the process of 
</em><br>
<em>&gt;applying for a spousal visa so we can move back to Pennsylvania (where Erin 
</em><br>
<em>&gt;is from).  I've been programming since I was 3 years old, and a penetration 
</em><br>
<em>&gt;tester for about 4 years now, the last 3 of which have been with NGS 
</em><br>
<em>&gt;Software; if you're into security you will have probably heard of me from 
</em><br>
<em>&gt;security.tombom.co.uk/shatter.html, which I published in August 2002.  I'll 
</em><br>
<em>&gt;mention that I studied Computer Science at Cambridge Uni (here in the UK) 
</em><br>
<em>&gt;but if you want the rest of my (probably rather boring) history feel free 
</em><br>
<em>&gt;to ask me :)
</em><br>
<em>&gt;
</em><br>
<em>&gt;Now to the interesting stuff.  The idea that I have been working on 
</em><br>
<em>&gt;apparently fits into the Wikipedia definition of &quot;strong&quot; AI - I know very 
</em><br>
<em>&gt;little about neural nets, genetic algorithms and their ilk, and don't 
</em><br>
<em>&gt;really want to know - it seems like a blind alley to me.  Too much research 
</em><br>
<em>&gt;time is, IMHO, currently spent on AI as a system of complexity; it seems 
</em><br>
<em>&gt;like the current thinking is that if you add sufficient complexity to a 
</em><br>
<em>&gt;system it can &quot;appear&quot; intelligent, maybe even enough to pass a turing 
</em><br>
<em>&gt;test.  I believe this is wrong; my ideas are focussed around intelligence 
</em><br>
<em>&gt;as an emergent system based on some relatively simple rules.
</em><br>
<em>&gt;
</em><br>
<em>&gt;The stuff I've had time to read on the SIAI website appears to be fairly 
</em><br>
<em>&gt;high-level; they've certainly solved some interesting problems before 
</em><br>
<em>&gt;they've even arisen, using some clever reasoning.  However, I disagree with 
</em><br>
<em>&gt;the statement that &quot;...the search for a single essence of intelligence lies 
</em><br>
<em>&gt;at the center of AI's previous failures&quot;.  I believe the problem is quite 
</em><br>
<em>&gt;the opposite; we have not yet looked hard enough at the overall problem to 
</em><br>
<em>&gt;realise that the most complex problem (as we see it) is actually the 
</em><br>
<em>&gt;simplest - that of how to integrate emotion into an artificial mind.
</em><br>
<em>&gt;
</em><br>
<em>&gt;My thinkings have largely focussed upon this problem, with some startling 
</em><br>
<em>&gt;conclusions.  I believe that emotion is a fundamental component of 
</em><br>
<em>&gt;intelligence, that the two are inextricably linked, and that it may even be 
</em><br>
<em>&gt;the case that they cannot exist without each other.  I won't go into too 
</em><br>
<em>&gt;much detail (just in case I'm emailing a black hole here), but I believe 
</em><br>
<em>&gt;that a simple system, constructed around some very basic principles (I 
</em><br>
<em>&gt;refer to it as emotional mechanics) can be emergent, and that the emerging 
</em><br>
<em>&gt;properties and behaviours are what we would classify as intelligence.
</em><br>
<em>&gt;
</em><br>
<em>&gt;I'm looking at the problem from a much lower level than what I've read on 
</em><br>
<em>&gt;the SIAI site; they've solved a lot of the high-level problems I've thought 
</em><br>
<em>&gt;of (and many that I hadn't), but I'm more interested in the guts of the 
</em><br>
<em>&gt;system - actually translating it into code that can be written. I'm on the 
</em><br>
<em>&gt;verge of a simple implementation, essentially integrating emotions into an 
</em><br>
<em>&gt;intelligent tic-tac-toe system.  I haven't gotten further than the planning 
</em><br>
<em>&gt;yet, but it's already proving an interesting exercise.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Anyway, I think I've rambled enough for what was intended to be a brief 
</em><br>
<em>&gt;introduction, so I'll stop here.  Please feel free to ask for more detail 
</em><br>
<em>&gt;on anything I've mentioned in this mail; I'm happy to discuss anything.  Be 
</em><br>
<em>&gt;warned though, if you do wish to ask about my visa application the response 
</em><br>
<em>&gt;you get may be somewhat tedious and boring - US visas are not fun to apply 
</em><br>
<em>&gt;for :(
</em><br>
<em>&gt;
</em><br>
<em>&gt;Cheers,
</em><br>
<em>&gt;
</em><br>
<em>&gt;Chris
</em><br>
<em>&gt;
</em><br>
<em>&gt;--
</em><br>
<em>&gt;Chris Paget
</em><br>
<em>&gt;<a href="mailto:ivegotta@tombom.co.uk?Subject=RE:%20[JOIN]%20Chris%20Paget">ivegotta@tombom.co.uk</a>
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12065.html">Randall Randall: "Re: Transcript. please? (Re: AI-Box Experiment 3)"</a>
<li><strong>Previous message:</strong> <a href="12063.html">Chris Paget: "[JOIN] Chris Paget"</a>
<li><strong>In reply to:</strong> <a href="12063.html">Chris Paget: "[JOIN] Chris Paget"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12064">[ date ]</a>
<a href="index.html#12064">[ thread ]</a>
<a href="subject.html#12064">[ subject ]</a>
<a href="author.html#12064">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
