<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Problems with AI-boxing</title>
<meta name="Author" content="Jeff Medina (analyticphilosophy@gmail.com)">
<meta name="Subject" content="Re: Problems with AI-boxing">
<meta name="Date" content="2005-08-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Problems with AI-boxing</h1>
<!-- received="Fri Aug 26 19:57:43 2005" -->
<!-- isoreceived="20050827015743" -->
<!-- sent="Fri, 26 Aug 2005 21:57:41 -0400" -->
<!-- isosent="20050827015741" -->
<!-- name="Jeff Medina" -->
<!-- email="analyticphilosophy@gmail.com" -->
<!-- subject="Re: Problems with AI-boxing" -->
<!-- id="5844e22f0508261857662017ba@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="430FBE69.7060707@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Jeff Medina (<a href="mailto:analyticphilosophy@gmail.com?Subject=Re:%20Problems%20with%20AI-boxing"><em>analyticphilosophy@gmail.com</em></a>)<br>
<strong>Date:</strong> Fri Aug 26 2005 - 19:57:41 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12137.html">Mike Williams: "Re: Problems with AI-boxing"</a>
<li><strong>Previous message:</strong> <a href="12135.html">Eliezer S. Yudkowsky: "Re: Problems with AI-boxing"</a>
<li><strong>In reply to:</strong> <a href="12135.html">Eliezer S. Yudkowsky: "Re: Problems with AI-boxing"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12140.html">Phil Goetz: "The Eliezer Threat (Re: Problems with AI-boxing)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12136">[ date ]</a>
<a href="index.html#12136">[ thread ]</a>
<a href="subject.html#12136">[ subject ]</a>
<a href="author.html#12136">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Michael Wilson wrote, &quot;I'm not sure that this follows. A human trying
<br>
to convince another human only has the benefit of whatever
<br>
arguments/knowledge/tricks the AI can give them in advance.&quot;
<br>
<p>Certainly. And you and Eliezer are confident a superintelligent AI
<br>
couldn't arm a human with enough arguments, knowledge, and tricks
<br>
(nevermind IA, which is of course also a possibility) to convince
<br>
another human to let it out of the box?
<br>
<p>The indistinguishability refers to the point reiterated by Eliezer:
<br>
&quot;Humans cannot reliably estimate what they cannot be convinced of.
<br>
[...T]he whole strategy [is] unreliable, too unreliable for
<br>
existential risk.&quot;
<br>
<p>I assert that humans cannot reliably estimate whether another human
<br>
can avoid being convinced of something he is skeptical of, given the
<br>
convincer is another human with unspecified privileged knowledge and
<br>
persuasive skill.
<br>
<p>I also point out that the human-to-human discussion should be severely
<br>
guarded (let the human gatekeeper be in an undisclosed distant
<br>
location, for example), to minimize the chances of the human who spoke
<br>
with the AI from torturing the gatekeeper, administering truth serum
<br>
to get the gatekeeper to tell her/him how to unbox the AI, etc., on
<br>
the possibility that the AI convinced the human its release was
<br>
important enough to warrant such extreme measures.
<br>
<p>If the assertion in the paragraph before last holds, the 'firewall'
<br>
suggestion is indistinguishably unsafe. I think this is clear enough,
<br>
so perhaps what I meant by 'functionally indistinguishable' was not.
<br>
<p>Best,
<br>
<pre>
-- 
Jeff Medina
<a href="http://www.painfullyclear.com/">http://www.painfullyclear.com/</a>
Community Director
Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
Relationships &amp; Community Fellow
Institute for Ethics &amp; Emerging Technologies
<a href="http://www.ieet.org/">http://www.ieet.org/</a>
School of Philosophy, Birkbeck, University of London
<a href="http://www.bbk.ac.uk/phil/">http://www.bbk.ac.uk/phil/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12137.html">Mike Williams: "Re: Problems with AI-boxing"</a>
<li><strong>Previous message:</strong> <a href="12135.html">Eliezer S. Yudkowsky: "Re: Problems with AI-boxing"</a>
<li><strong>In reply to:</strong> <a href="12135.html">Eliezer S. Yudkowsky: "Re: Problems with AI-boxing"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12140.html">Phil Goetz: "The Eliezer Threat (Re: Problems with AI-boxing)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12136">[ date ]</a>
<a href="index.html#12136">[ thread ]</a>
<a href="subject.html#12136">[ subject ]</a>
<a href="author.html#12136">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
