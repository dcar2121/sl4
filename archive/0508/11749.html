<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: On the dangers of AI</title>
<meta name="Author" content="Randall Randall (randall@randallsquared.com)">
<meta name="Subject" content="Re: On the dangers of AI">
<meta name="Date" content="2005-08-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: On the dangers of AI</h1>
<!-- received="Wed Aug 17 03:03:37 2005" -->
<!-- isoreceived="20050817090337" -->
<!-- sent="Wed, 17 Aug 2005 05:03:34 -0400" -->
<!-- isosent="20050817090334" -->
<!-- name="Randall Randall" -->
<!-- email="randall@randallsquared.com" -->
<!-- subject="Re: On the dangers of AI" -->
<!-- id="7d0981d8c7639db644af119172e5c9a4@randallsquared.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="4302D206.8000908@lightlink.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Randall Randall (<a href="mailto:randall@randallsquared.com?Subject=Re:%20On%20the%20dangers%20of%20AI"><em>randall@randallsquared.com</em></a>)<br>
<strong>Date:</strong> Wed Aug 17 2005 - 03:03:34 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11750.html">Ben Goertzel: "RE: Shock Level 5 (SL5) - 'The Theory Of Everything'"</a>
<li><strong>Previous message:</strong> <a href="11748.html">Richard Loosemore: "Re: On the dangers of AI"</a>
<li><strong>In reply to:</strong> <a href="11742.html">Richard Loosemore: "Re: On the dangers of AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11754.html">Phil Goetz: "Re: On the dangers of AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11749">[ date ]</a>
<a href="index.html#11749">[ thread ]</a>
<a href="subject.html#11749">[ subject ]</a>
<a href="author.html#11749">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Aug 17, 2005, at 1:58 AM, Richard Loosemore wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; d) If the Seed AI does not make the choice to be Friendly (on the side 
</em><br>
<em>&gt; of &quot;convergence&quot; (see parallel post in reply to Ben)), then it will 
</em><br>
<em>&gt; allow rival projects, etc. etc.  It All Ends In Tears.  For reasons 
</em><br>
<em>&gt; discussed elsewhere, I think this extremely unlikely.  This is the 
</em><br>
<em>&gt; only case that could generate a paperclip maximiser that did not have 
</em><br>
<em>&gt; general intelligence and awareness of such issues as motivation.
</em><br>
<p>In service of what goal is such a choice made?  If a goal that
<br>
directs a choice to be &quot;Friendly&quot; exists, then it was so already.
<br>
If not, it cannot choose (except in error) that way.
<br>
<p>Choices imply reasons to choose, which are just another name
<br>
for goals.  Humans may not have a &quot;highest&quot; goal, but building
<br>
an optimization process without one would be leaving the
<br>
ultimate direction of the process unset.
<br>
<p>It may be that there is no way to build a system as intelligent
<br>
as a human with a single goal, but that doesn't seem the way to
<br>
bet right now.
<br>
<p><pre>
--
Randall Randall &lt;<a href="mailto:randall@randallsquared.com?Subject=Re:%20On%20the%20dangers%20of%20AI">randall@randallsquared.com</a>&gt;
&quot;Lisp will give you a kazillion ways to solve a problem.
  But (1- kazillion) are wrong.&quot; - Kenny Tilton
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11750.html">Ben Goertzel: "RE: Shock Level 5 (SL5) - 'The Theory Of Everything'"</a>
<li><strong>Previous message:</strong> <a href="11748.html">Richard Loosemore: "Re: On the dangers of AI"</a>
<li><strong>In reply to:</strong> <a href="11742.html">Richard Loosemore: "Re: On the dangers of AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11754.html">Phil Goetz: "Re: On the dangers of AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11749">[ date ]</a>
<a href="index.html#11749">[ thread ]</a>
<a href="subject.html#11749">[ subject ]</a>
<a href="author.html#11749">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:23:01 MST
</em></small></p>
</body>
</html>
