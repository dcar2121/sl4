<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Retrenchment</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Retrenchment">
<meta name="Date" content="2005-08-18">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Retrenchment</h1>
<!-- received="Thu Aug 18 17:14:17 2005" -->
<!-- isoreceived="20050818231417" -->
<!-- sent="Thu, 18 Aug 2005 16:14:25 -0700" -->
<!-- isosent="20050818231425" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Retrenchment" -->
<!-- id="43051651.5090309@pobox.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="4304E543.8020802@lightlink.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Retrenchment"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Thu Aug 18 2005 - 17:14:25 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11795.html">J. Andrew Rogers: "Hubris (was: Retrenchment)"</a>
<li><strong>Previous message:</strong> <a href="11793.html">Thomas Buckner: "Re: Goedel's theorem doesn't apply to robots (RE: SL5)"</a>
<li><strong>In reply to:</strong> <a href="11790.html">Richard Loosemore: "Retrenchment"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11800.html">Phil Goetz: "Re: Retrenchment"</a>
<li><strong>Reply:</strong> <a href="11800.html">Phil Goetz: "Re: Retrenchment"</a>
<li><strong>Reply:</strong> <a href="11801.html">Phil Goetz: "Communities, project management, Luke Skywalker"</a>
<li><strong>Reply:</strong> <a href="11916.html">Richard Loosemore: "Re: Retrenchment"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11794">[ date ]</a>
<a href="index.html#11794">[ thread ]</a>
<a href="subject.html#11794">[ subject ]</a>
<a href="author.html#11794">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Shades of the laundry list in 
<br>
<a href="http://www.sl4.org/bin/wiki.pl?SoYouWantToBeASeedAIProgrammer">http://www.sl4.org/bin/wiki.pl?SoYouWantToBeASeedAIProgrammer</a>...
<br>
<p>Richard Loosemore wrote:
<br>
<em> &gt; ************************************************************
</em><br>
<em> &gt;
</em><br>
<em> &gt; Now, some of these communities are more directly hands-on, while some
</em><br>
<em> &gt; just watch and comment and contribute from afar, but the six different
</em><br>
<em> &gt; language that they speak and the six different paradigms they bring to
</em><br>
<em> &gt; the table are all in some way relevant to the task of understanding how
</em><br>
<em> &gt; cognitive systems might work, and how we might go about building an AI.
</em><br>
<em> &gt;
</em><br>
<em> &gt; But the problem is that you can go into one of these communities and
</em><br>
<em> &gt; find very talented people who are completely ignorant of what is going
</em><br>
<em> &gt; on in the others.  Often, it is not just ignorance but actual scorn and
</em><br>
<em> &gt; disdain, as if they are proud not to know what is happening elsewhere,
</em><br>
<em> &gt; because they regard the ideas (and sometimes the people) in some of
</em><br>
<em> &gt; those other communities as irrelevant or stupid.  Frequently, people
</em><br>
<em> &gt; have a smattering of some other field and think that they therefore know
</em><br>
<em> &gt; it all.
</em><br>
<p>Some roads go on, if not forever, then a long long way.  It's a funny thing, 
<br>
you know; I was just about to ask you if you belonged to some communities, but 
<br>
apart from neuroscience they weren't on your list.  Incidentally, a decent 
<br>
neuroscience-user ought to know many special cases of human brain damage, and 
<br>
you did not say of that community that they would recognize the name of 
<br>
Phineas Gage.  I mention this because studying human brain-damage cases can 
<br>
also help defeat anthropomorphism.
<br>
<p>I recall from memory - though not, I fear, complete with a full citation - an 
<br>
experiment done in social psychology.  A person X asked another person Y a set 
<br>
of far-ranging questions, which could be drawn from any knowledge X had 
<br>
managed to accumulate, in front of another person Z.  Naturally, Y didn't know 
<br>
the answers to nearly all of the questions.  X and Y were randomly assigned to 
<br>
their roles, and there are *very* few people who know so much that they can 
<br>
readily answer questions from *any* other person's specialty.  The interesting 
<br>
part was when they asked the participants whether X or Y looked more 
<br>
intelligent.  X usually said that he did not think he had looked particularly 
<br>
intelligent; Y said that X looked somewhat more intelligent; Z said that X 
<br>
looked very much more intelligent.  The moral is that you can look very 
<br>
intelligent by asking people hard-to-answer questions.
<br>
<p>I expect you were not aware of this phenomenon, nor deliberately trying to 
<br>
exploit this known human bias.  But as for me, I recognized more than half of 
<br>
the obscure names you said, and less than all, and I know how good a showing 
<br>
that *really* is - after discounting the effects of the standard human bias 
<br>
which this situation happens to match.
<br>
<p>Having said that, then by all means, if it comes to showing off, two can play 
<br>
at *that* game.
<br>
<p>I have never encountered someone who might qualify as a member of all the 
<br>
communities I think to be necessary.  Possibly Eric B. Baum, but with him I 
<br>
have not yet spoken.  (Still reading through Baum's book, but he quotes the 
<br>
right people.)
<br>
<p>Here are the (G), (H), and (I) I'd add to your list.  I wouldn't be surprised 
<br>
to find that in another two years I add a (J) and (K).  Some roads go on 
<br>
forever, and others just go on a very long way, and sometimes also roads are 
<br>
much less long than they look.  Some roads we never know the length until we 
<br>
have arrived at our destination, and look back on our pathway; and I am not 
<br>
yet at my destination.
<br>
<p>COMMUNITY (G)
<br>
<p>The disciples of Tversky and Kahneman, they understand the details of human 
<br>
reasoning well enough to illustrate exactly how it fails, not just try to 
<br>
explain the mysteries of its success.  Those well-rounded in this field study 
<br>
social psychology as well as heuristics and biases, and they overlap 
<br>
communities (H) and (I) on Bayesian rationality and evolutionary psychology 
<br>
respectively.  They know the conjunction fallacy and sometimes they even avoid 
<br>
it; they know things about human overconfidence that would freeze the blood of 
<br>
most people who think themselves pessimists.  Infant and developmental 
<br>
psychology is of particular interest to AI builders.
<br>
<p>COMMUNITY (H)
<br>
<p>The students of an ancient art devised by Laplace, which is therefore called 
<br>
Bayesian.  Probability theory, decision theory, information theory, 
<br>
statistics; Kolmogorov and Solomonoff, Jaynes and Shannon.  The masters of 
<br>
this art can describe ignorance more precisely than most folk can describe 
<br>
their knowledge, and if you don't realize that's a pragmatically useful 
<br>
mathematics then you aren't in community (H).  These are the people to whom 
<br>
&quot;intelligence&quot; is not a sacred mystery... not to some of us, anyway.
<br>
<p>COMMUNITY (I)
<br>
<p>Down with the Standard Social Sciences Model!  Long live the Unified Causal 
<br>
Model!  If you recognized that as a parody of Tooby and Cosmides, you still 
<br>
may not know anywhere near as much as you think you do about evolutionary 
<br>
biology - not unless you know the difference between Hardy-Weinberg 
<br>
equilibrium and linkage equilibrium, or you can show how Price's Equation 
<br>
generalizes Fisher's Fundamental Theorem of Natural Selection.  Those who seek 
<br>
to build AI will have studied the evolutionary anthropology of human 
<br>
intelligence, a la Terrence Deacon.  But there is a more important use for 
<br>
evolutionary biology.  There are two known, studied, powerful optimization 
<br>
processes in this world: cumulative natural selection, and the human mind. 
<br>
And interestingly enough, science understands natural selection a lot more 
<br>
solidly than it understands humans.  The reason is simple enough; natural 
<br>
selection is a much simpler optimization process - so simple, in fact, that it 
<br>
can't help but accrete needlessly complex processes like human intelligence. 
<br>
If you really want to learn how not to anthropomorphize, study evolutionary 
<br>
biology with math.
<br>
<p>Loosemore, I commend to you the following documents with respect to community 
<br>
(H) of which you are most sorely in need of joining, followed thereafter by 
<br>
(I) and (G).
<br>
<p><a href="http://yudkowsky.net/bayes/bayes.html">http://yudkowsky.net/bayes/bayes.html</a>
<br>
<a href="http://yudkowsky.net/bayes/technical.html">http://yudkowsky.net/bayes/technical.html</a>
<br>
<p>Having read the second document, you will understand what is wrong, as a 
<br>
matter of scientific procedure and rational reasoning, with attributing human 
<br>
intelligence to &quot;the emergent properties of a hypercomplex network&quot; as though 
<br>
this were a hypothesis.
<br>
<p>You can skip the first document if you understand simple Bayesian reasoning 
<br>
*thoroughly*, by which I mean that you can write Bayes's Rule from memory and 
<br>
that you know why transforming probabilities to log-odds ratios can simplify 
<br>
bookkeeping.
<br>
<p>You may also be interested in the evolutionary psychology of human 
<br>
intelligence and my own take on human concepts, findable at the now-obsolete:
<br>
<p><a href="http://intelligence.org/LOGI/">http://intelligence.org/LOGI/</a>
<br>
<p><em>&gt; COMMUNITY (A)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Those who would understand completely if you started discussing 
</em><br>
<em>&gt; &quot;Shiffrin and Schneider&quot;, or &quot;Levels of Processing Theory&quot;, or &quot;Deep 
</em><br>
<em>&gt; Dyslexia.&quot;  They would also what a word-exhange error, a 
</em><br>
<em>&gt; morpheme-exchange error or a semantic substitution was.  They would 
</em><br>
<em>&gt; understand the power-law of skill acquisition.  They would know about 
</em><br>
<em>&gt; &quot;Smith and Medin&quot; if you asked them for their thoughts about classical, 
</em><br>
<em>&gt; prototype and feature theories of concepts, and what the current think 
</em><br>
<em>&gt; was on those issues, they might not be able to answer immediately, but 
</em><br>
<em>&gt; they would know what you were asking for, and would be able track it 
</em><br>
<em>&gt; down pretty quickly.  And if you mentioned &quot;motivation&quot;, &quot;compulsion&quot;, 
</em><br>
<em>&gt; &quot;obsession&quot; or &quot;pleasure&quot; they would assume you were just using these as 
</em><br>
<em>&gt; shorthand for certain mechanisms, rather than assuming you were talking 
</em><br>
<em>&gt; dualist philosophy.
</em><br>
<p>Smith and Medin?  Eleanor Rosch or George Lakoff would be more appropriate 
<br>
names to cite here, no?  You seem to have gotten stuck in an eddy of this 
<br>
field; your selected highlights don't sound like central exemplars of the 
<br>
category.  And why do you lump motivation in with that?
<br>
<p>It sounds like your community (A) is intended to stand for the whole of 
<br>
cognitive psychology, a field which includes also (G) as a special case.  If 
<br>
so, you need to study way more cognitive psychology.  A fine and classic book 
<br>
is &quot;Judgment Under Uncertainty&quot; from (G).
<br>
<p><em>&gt; COMMUNITY (B)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Those who know how to write serious amounts of LISP, who understand 
</em><br>
<em>&gt; pruning algorithms in state-space search, and who know the difference 
</em><br>
<em>&gt; between Blackboards, GAs, and neural nets.  They might well be able to 
</em><br>
<em>&gt; tell you about &quot;unification&quot; in Prolog, and be able to give you a 
</em><br>
<em>&gt; thoughtful discussion of the differences between John Koza's genetic 
</em><br>
<em>&gt; programming and genetic algorithms and evolutionary programming.  They 
</em><br>
<em>&gt; would definitely know about goal hierarchies and planning systems.
</em><br>
<p>Also known as Mainstream AI: the predicate logic users, connectionists, and 
<br>
artificial evolutionists.  What they know about goal hierarchies and planning 
<br>
systems is quite different from what decision theorists know about expected 
<br>
utility maximization, though of course there's some overlap.
<br>
<p>I note that FAI issues lie much closer to decision theory.  It is better, in 
<br>
discussing FAI, to know who first wrote about Newcomb's Problem than to know 
<br>
who built SHRDLU.
<br>
<p>I once wrote of this field that it is important primarily as a history of failure.
<br>
<p><em>&gt; COMMUNITY (C)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Those to whom the term &quot;edge of chaos&quot; is not just something they 
</em><br>
<em>&gt; learned from James Gleick.  These people are comfortable with the idea 
</em><br>
<em>&gt; that mathematics is a fringe activity that goes on at the tractable edge 
</em><br>
<em>&gt; of a vast abyss of completely intractable systems and equations.  When 
</em><br>
<em>&gt; they use the term &quot;non-linear&quot; they don't mean something that is not a 
</em><br>
<em>&gt; straight line, nor are they talking about finding tricks that yield 
</em><br>
<em>&gt; analytic solutions to certain nonlinear equations.  They are equally 
</em><br>
<em>&gt; comfortable talking about a national economy and a brain as a &quot;CAS&quot; and 
</em><br>
<em>&gt; they can point to meaningful similarities in the behavior of these two 
</em><br>
<em>&gt; sorts of system.  Almost all of these people are seriously well versed 
</em><br>
<em>&gt; in mathematics, but unlike the main body of mathematicians proper, they 
</em><br>
<em>&gt; understand the limitations of analytic attempts to characterize systems 
</em><br>
<em>&gt; in the real world.
</em><br>
<p>I'm not part of community C and I maintain an extreme skepticism of its 
<br>
popular philosophy, as opposed to particular successful technical 
<br>
applications, for reasons given in &quot;A Technical Explanation of Technical 
<br>
Explanation&quot;.
<br>
<p><em>&gt; COMMUNITY (D)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Those who have had the kind of experience in which they find themselves 
</em><br>
<em>&gt; fifty levels deep in a debugger, working on Final Candidate 7 of a piece 
</em><br>
<em>&gt; of software comprising 4000 source files of C and C++, in a hopeless 
</em><br>
<em>&gt; attempt to troubleshoot problems in a codebase that they have only 
</em><br>
<em>&gt; written tiny parts of, and in which the rest is mostly undocumented and 
</em><br>
<em>&gt; barely commented (by people who often did not have much English), with 
</em><br>
<em>&gt; the product due to ship in two weeks.  An experience that bears about as 
</em><br>
<em>&gt; much relationship to a computer science degree as Mrs Featherstone's 
</em><br>
<em>&gt; Finishing School For Young Ladies does to a whorehouse.
</em><br>
<p>I've stayed up 36 hours in a row, twelve levels deep in a debugger, hunting a 
<br>
mysterious stack smasher in a C++ application with at least 200 source files, 
<br>
which I did write myself.  Close enough.  Long live Python!
<br>
<p><em>&gt; COMMUNITY (E)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Those who could give you a reasonable account of where Penrose, Chalmers 
</em><br>
<em>&gt; and Dennett would stand with respect to one another.  They could easily 
</em><br>
<em>&gt; distinguish the Hard Problem from other versions of the consciousness 
</em><br>
<em>&gt; issue, even if they might disagree with Chalmers about the conclusion to 
</em><br>
<em>&gt; be drawn.  They know roughly what supervenience is.  The could certainly 
</em><br>
<em>&gt; distinguish functionalism (various breeds thereof) from epiphenomenalism 
</em><br>
<em>&gt; and physicalism, and they could talk about what various camps thought 
</em><br>
<em>&gt; about the issues of dancing, inverted and absent qualia.
</em><br>
<p>Sadly I recognize every word and phrase in this paragraph, legacy of a wasted 
<br>
childhood, like being able to sing the theme song from Thundercats.
<br>
<p><em>&gt; COMMUNITY (F)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Those who know enough about real neural hardware to think that there are 
</em><br>
<em>&gt; serious questions about whether the real computation takes place in 
</em><br>
<em>&gt; floods of junk in a synaptic cleft or in specific timings of incoming 
</em><br>
<em>&gt; spikes in the dendritic tree.  They know about programmed cell death and 
</em><br>
<em>&gt; how that might relate to learning.  They might know about the 
</em><br>
<em>&gt; Hodgkin-Huxley equations.  They understand what Marr had to say about 
</em><br>
<em>&gt; the possible role of Purkinje cells in fine motor control, and they 
</em><br>
<em>&gt; would know way too much about the architectural features of the brain.
</em><br>
<p>We *know* that dendritic computing exists, it's no longer a &quot;serious question&quot; 
<br>
but an answered one.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11795.html">J. Andrew Rogers: "Hubris (was: Retrenchment)"</a>
<li><strong>Previous message:</strong> <a href="11793.html">Thomas Buckner: "Re: Goedel's theorem doesn't apply to robots (RE: SL5)"</a>
<li><strong>In reply to:</strong> <a href="11790.html">Richard Loosemore: "Retrenchment"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11800.html">Phil Goetz: "Re: Retrenchment"</a>
<li><strong>Reply:</strong> <a href="11800.html">Phil Goetz: "Re: Retrenchment"</a>
<li><strong>Reply:</strong> <a href="11801.html">Phil Goetz: "Communities, project management, Luke Skywalker"</a>
<li><strong>Reply:</strong> <a href="11916.html">Richard Loosemore: "Re: Retrenchment"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11794">[ date ]</a>
<a href="index.html#11794">[ thread ]</a>
<a href="subject.html#11794">[ subject ]</a>
<a href="author.html#11794">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:23:01 MST
</em></small></p>
</body>
</html>
