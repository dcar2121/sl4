<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Retrenchment</title>
<meta name="Author" content="Richard Loosemore (rpwl@lightlink.com)">
<meta name="Subject" content="Re: Retrenchment">
<meta name="Date" content="2005-08-25">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Retrenchment</h1>
<!-- received="Thu Aug 25 20:16:11 2005" -->
<!-- isoreceived="20050826021611" -->
<!-- sent="Thu, 25 Aug 2005 22:15:39 -0400" -->
<!-- isosent="20050826021539" -->
<!-- name="Richard Loosemore" -->
<!-- email="rpwl@lightlink.com" -->
<!-- subject="Re: Retrenchment" -->
<!-- id="430E7B4B.5010608@lightlink.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="43051651.5090309@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Richard Loosemore (<a href="mailto:rpwl@lightlink.com?Subject=Re:%20Retrenchment"><em>rpwl@lightlink.com</em></a>)<br>
<strong>Date:</strong> Thu Aug 25 2005 - 20:15:39 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12110.html">Maru Dubshinki: "Re: AI-Box Experiment #4: Russell Wallace, Eliezer Yudkowsky"</a>
<li><strong>Previous message:</strong> <a href="12108.html">Mikko Särelä: "Re: Complexity tells us to maybe not fear UFAI"</a>
<li><strong>In reply to:</strong> <a href="11987.html">Eliezer S. Yudkowsky: "Re: Retrenchment"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0509/12201.html">Eliezer S. Yudkowsky: "Re: Retrenchment"</a>
<li><strong>Reply:</strong> <a href="../0509/12201.html">Eliezer S. Yudkowsky: "Re: Retrenchment"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12109">[ date ]</a>
<a href="index.html#12109">[ thread ]</a>
<a href="subject.html#12109">[ subject ]</a>
<a href="author.html#12109">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eliezer,
<br>
<p>I really did not want that &quot;Retrenchment&quot; post to be taken as a piece of 
<br>
oneupmanship and name-dropping.  It was meant to be an observation about 
<br>
what I saw as the sad state of a field of inquiry ... it is a shame that 
<br>
some people reacted as if it was nothing but a personal insult.
<br>
<p>Of the comments you make below, some appear to be of the sort &quot;You 
<br>
mentioned x and y in a certain field, but you didn't mention z ... don't 
<br>
you know about z?&quot;.
<br>
<p>For example:
<br>
<p><em> &gt; Smith and Medin?  Eleanor Rosch or George Lakoff would be more
</em><br>
<em> &gt; appropriate names to cite here, no?  You seem to have gotten stuck in
</em><br>
<em> &gt; an eddy of this field; your selected highlights don't sound like
</em><br>
<em> &gt; central exemplars of the category.  And why do you lump motivation in
</em><br>
<em> &gt; with that?
</em><br>
<p>The things I cited were randomly selected examples of topics in the 
<br>
field of Cognitive Psychology/Cognitive Science.  Am I to be faulted for 
<br>
only selecting those?  Did you really expect me to list every single 
<br>
topic of interest in that domain?
<br>
<p>Later, you cite a social psychology experiment in which people judge 
<br>
each other's intelligence after asking questions, and you conclude with 
<br>
the interesting remark:
<br>
<p><em> &gt;                                  The moral is that you can look
</em><br>
<em> &gt; very intelligent by asking people hard-to-answer questions.
</em><br>
<em> &gt;
</em><br>
<em> &gt; I expect you were not aware of this phenomenon, nor deliberately
</em><br>
<em> &gt; trying to exploit this known human bias.  But as for me, I recognized
</em><br>
<em> &gt; more than half of the obscure names you said, and less than all, and I
</em><br>
<em> &gt; know how good a showing that *really* is - after discounting the
</em><br>
<em> &gt; effects of the standard human bias which this situation happens to
</em><br>
<em> &gt; match.
</em><br>
<p>I did not try to &quot;look intelligent&quot; and I did not, in fact, mention any 
<br>
&quot;obscure names&quot;.  The purpose of that post was to define communities of 
<br>
people who were fluent in various fields, and I tried to define those 
<br>
communities by giving a kind of litmus test - lists of topics that a 
<br>
person in that field would instantly recognize as elementary, not 
<br>
&quot;obscure names&quot;.
<br>
<p><em> &gt; Having said that, then by all means, if it comes to showing off, two
</em><br>
<em> &gt; can play at *that* game.
</em><br>
<p>I did not have this kind of puerile, testosterone-ridden jousting in 
<br>
mind when I made the original post, but if you want to sidetrack the 
<br>
discussion in that direction, I will try to respond as best I can.....
<br>
<p><p>[ANYONE READING THIS WHO WAS ONLY INTERESTED IN THE SERIOUS SIDE OF MY 
<br>
ORIGINAL &quot;RETRENCHMENT&quot; POST CAN SAFELY STOP READING AT THIS POINT, 
<br>
BECAUSE NOW I AM GOING TO INDULGE IN A 100% PURE, UNADULTERATED SLANGING 
<br>
MATCH, JUST BECAUSE I FEEL IN THAT KIND OF MOOD THIS EVENING.]
<br>
<p>[AND BECAUSE ELIEZER STARTED IT.]
<br>
<p>[NO; SERIOUSLY FOLKS!  GO AWAY.  SAVE YOUR ENERGY FOR ONE OF THE OTHER 
<br>
POSTS.   I'M GOING TO BE UNSPEAKABLY ARROGANT AND REPLY TO ELIEZER'S 
<br>
POST ON A BLOW-BY-BLOW BASIS, JUST FOR FUN].
<br>
<p>:-) :-) :-) :-) :-) :-)
<br>
<p><p><p>Eliezer S. Yudkowsky wrote:
<br>
<em>&gt; Shades of the laundry list in 
</em><br>
<em>&gt; <a href="http://www.sl4.org/bin/wiki.pl?SoYouWantToBeASeedAIProgrammer">http://www.sl4.org/bin/wiki.pl?SoYouWantToBeASeedAIProgrammer</a>...
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Richard Loosemore wrote:
</em><br>
<em>&gt;  &gt; ************************************************************
</em><br>
<em>&gt;  &gt;
</em><br>
<em>&gt;  &gt; Now, some of these communities are more directly hands-on, while some
</em><br>
<em>&gt;  &gt; just watch and comment and contribute from afar, but the six different
</em><br>
<em>&gt;  &gt; language that they speak and the six different paradigms they bring to
</em><br>
<em>&gt;  &gt; the table are all in some way relevant to the task of understanding how
</em><br>
<em>&gt;  &gt; cognitive systems might work, and how we might go about building an AI.
</em><br>
<em>&gt;  &gt;
</em><br>
<em>&gt;  &gt; But the problem is that you can go into one of these communities and
</em><br>
<em>&gt;  &gt; find very talented people who are completely ignorant of what is going
</em><br>
<em>&gt;  &gt; on in the others.  Often, it is not just ignorance but actual scorn and
</em><br>
<em>&gt;  &gt; disdain, as if they are proud not to know what is happening elsewhere,
</em><br>
<em>&gt;  &gt; because they regard the ideas (and sometimes the people) in some of
</em><br>
<em>&gt;  &gt; those other communities as irrelevant or stupid.  Frequently, people
</em><br>
<em>&gt;  &gt; have a smattering of some other field and think that they therefore know
</em><br>
<em>&gt;  &gt; it all.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Some roads go on, if not forever, then a long long way.  It's a funny 
</em><br>
<em>&gt; thing, you know; I was just about to ask you if you belonged to some 
</em><br>
<em>&gt; communities, but apart from neuroscience they weren't on your list.  
</em><br>
<em>&gt; Incidentally, a decent neuroscience-user ought to know many special 
</em><br>
<em>&gt; cases of human brain damage, and you did not say of that community that 
</em><br>
<em>&gt; they would recognize the name of Phineas Gage.  I mention this because 
</em><br>
<em>&gt; studying human brain-damage cases can also help defeat anthropomorphism.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I recall from memory - though not, I fear, complete with a full citation 
</em><br>
<em>&gt; - an experiment done in social psychology.  A person X asked another 
</em><br>
<em>&gt; person Y a set of far-ranging questions, which could be drawn from any 
</em><br>
<em>&gt; knowledge X had managed to accumulate, in front of another person Z.  
</em><br>
<em>&gt; Naturally, Y didn't know the answers to nearly all of the questions.  X 
</em><br>
<em>&gt; and Y were randomly assigned to their roles, and there are *very* few 
</em><br>
<em>&gt; people who know so much that they can readily answer questions from 
</em><br>
<em>&gt; *any* other person's specialty.  The interesting part was when they 
</em><br>
<em>&gt; asked the participants whether X or Y looked more intelligent.  X 
</em><br>
<em>&gt; usually said that he did not think he had looked particularly 
</em><br>
<em>&gt; intelligent; Y said that X looked somewhat more intelligent; Z said that 
</em><br>
<em>&gt; X looked very much more intelligent.  The moral is that you can look 
</em><br>
<em>&gt; very intelligent by asking people hard-to-answer questions.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I expect you were not aware of this phenomenon, nor deliberately trying 
</em><br>
<em>&gt; to exploit this known human bias.  But as for me, I recognized more than 
</em><br>
<em>&gt; half of the obscure names you said, and less than all, and I know how 
</em><br>
<em>&gt; good a showing that *really* is - after discounting the effects of the 
</em><br>
<em>&gt; standard human bias which this situation happens to match.
</em><br>
<p>You only recognised &quot;more than half&quot; of the &quot;obscure names&quot;?  That's a 
<br>
pity:  I knew all of them.
<br>
<p>Which of them did you find obscure?  Did you only know half of each, or 
<br>
all of some and nothing of some others?  Can I help with some of the 
<br>
ones where you feel out of your depth?
<br>
<p><p><em>&gt; Having said that, then by all means, if it comes to showing off, two can 
</em><br>
<em>&gt; play at *that* game.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I have never encountered someone who might qualify as a member of all 
</em><br>
<em>&gt; the communities I think to be necessary.  Possibly Eric B. Baum, but 
</em><br>
<em>&gt; with him I have not yet spoken.  (Still reading through Baum's book, but 
</em><br>
<em>&gt; he quotes the right people.)
</em><br>
<p>Ahh!  Eric B. Baum.  You were impressed by him, huh?  So you must be one 
<br>
of those people who were fooled when he tried to explain qualia as a 
<br>
form of mechanism, calling this an answer to the &quot;hard problem&quot; [of 
<br>
consciousness] and making all the people who defined the term &quot;hard 
<br>
problem of consciousness&quot; piss themselves with laughter at his stupidity?
<br>
<p>Baum really looks pretty impressive if you don't read his actual words 
<br>
too carefully, doesn't he?
<br>
<p><em>&gt; Here are the (G), (H), and (I) I'd add to your list.  I wouldn't be 
</em><br>
<em>&gt; surprised to find that in another two years I add a (J) and (K).  Some 
</em><br>
<em>&gt; roads go on forever, and others just go on a very long way, and 
</em><br>
<em>&gt; sometimes also roads are much less long than they look.  Some roads we 
</em><br>
<em>&gt; never know the length until we have arrived at our destination, and look 
</em><br>
<em>&gt; back on our pathway; and I am not yet at my destination.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; COMMUNITY (G)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The disciples of Tversky and Kahneman, they understand the details of 
</em><br>
<em>&gt; human reasoning well enough to illustrate exactly how it fails, not just 
</em><br>
<em>&gt; try to explain the mysteries of its success.  Those well-rounded in this 
</em><br>
<em>&gt; field study social psychology as well as heuristics and biases, and they 
</em><br>
<em>&gt; overlap communities (H) and (I) on Bayesian rationality and evolutionary 
</em><br>
<em>&gt; psychology respectively.  They know the conjunction fallacy and 
</em><br>
<em>&gt; sometimes they even avoid it; they know things about human 
</em><br>
<em>&gt; overconfidence that would freeze the blood of most people who think 
</em><br>
<em>&gt; themselves pessimists.  Infant and developmental psychology is of 
</em><br>
<em>&gt; particular interest to AI builders.
</em><br>
<p>That's funny:  didn't you recognize that this is precisely the same as 
<br>
the Community A that I defined?  This is Cognitiuve Science/Cognitive 
<br>
Psychology.  Why would you think that Tversky and Kahneman are some kind 
<br>
of separate community?
<br>
<p>Why would you think that I don't know all of this stuff?
<br>
<p><p><p><em>&gt; COMMUNITY (H)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The students of an ancient art devised by Laplace, which is therefore 
</em><br>
<em>&gt; called Bayesian.  Probability theory, decision theory, information 
</em><br>
<em>&gt; theory, statistics; Kolmogorov and Solomonoff, Jaynes and Shannon.  The 
</em><br>
<em>&gt; masters of this art can describe ignorance more precisely than most folk 
</em><br>
<em>&gt; can describe their knowledge, and if you don't realize that's a 
</em><br>
<em>&gt; pragmatically useful mathematics then you aren't in community (H).  
</em><br>
<em>&gt; These are the people to whom &quot;intelligence&quot; is not a sacred mystery... 
</em><br>
<em>&gt; not to some of us, anyway.
</em><br>
<p>Boy, you are so right there!  They don't think of intelligence as a 
<br>
sacred mystery, they think it is so simple, it only involves Bayesian 
<br>
Inference!
<br>
<p>Like Behaviorists and Ptolemaic Astronomers, they mistake a formalism 
<br>
that approximately describes a system for the mechanism that is actually 
<br>
inside the system.  They can carry on like this for centuries, adding 
<br>
epicycles onto their models in order to refine them.  When Bayesian 
<br>
Inference does not seem to cut it, they assert that *in principle* a 
<br>
sufficiently complex Bayesian Inference system really would be able to 
<br>
cut it ... but they are not able to understand that the &quot;in principle&quot; 
<br>
bit of their argument depends on subtleties that they don't think much 
<br>
about.
<br>
<p>In particular, they don't notice when the mechanism that is supposed to 
<br>
do the mapping between internal symbols and external referents, in their 
<br>
kind of system, turns out to require more intelligence than the 
<br>
reasoning engine itself .... and they usually don't notice this because 
<br>
they write all their programs with programmer-defined symbols/concepts 
<br>
(implictly inserting the intelligence themselves, you see), thus sparing 
<br>
their system the pain of doing the work necessary to ground itself.
<br>
<p>If these people understood what was going on in the other communities, 
<br>
they might understand these issues.  Typically, they don't
<br>
<p><p><em>&gt; COMMUNITY (I)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Down with the Standard Social Sciences Model!  Long live the Unified 
</em><br>
<em>&gt; Causal Model!  If you recognized that as a parody of Tooby and Cosmides, 
</em><br>
<em>&gt; you still may not know anywhere near as much as you think you do about 
</em><br>
<em>&gt; evolutionary biology - not unless you know the difference between 
</em><br>
<em>&gt; Hardy-Weinberg equilibrium and linkage equilibrium, or you can show how 
</em><br>
<em>&gt; Price's Equation generalizes Fisher's Fundamental Theorem of Natural 
</em><br>
<em>&gt; Selection.  Those who seek to build AI will have studied the 
</em><br>
<em>&gt; evolutionary anthropology of human intelligence, a la Terrence Deacon.  
</em><br>
<em>&gt; But there is a more important use for evolutionary biology.  There are 
</em><br>
<em>&gt; two known, studied, powerful optimization processes in this world: 
</em><br>
<em>&gt; cumulative natural selection, and the human mind. And interestingly 
</em><br>
<em>&gt; enough, science understands natural selection a lot more solidly than it 
</em><br>
<em>&gt; understands humans.  The reason is simple enough; natural selection is a 
</em><br>
<em>&gt; much simpler optimization process - so simple, in fact, that it can't 
</em><br>
<em>&gt; help but accrete needlessly complex processes like human intelligence. 
</em><br>
<em>&gt; If you really want to learn how not to anthropomorphize, study 
</em><br>
<em>&gt; evolutionary biology with math.
</em><br>
<p>Here you remind me of John Searle, famous Bete Noir of the AI community, 
<br>
who will probably never understand the &quot;levels&quot; difference between 
<br>
systems that *are* intelligent (e.g. humans) and systems that are 
<br>
collections of interacting intelligences (e.g. human societies) and, 
<br>
jumping up almost but not quite a whole level again, systems that are 
<br>
interacting species of &quot;intelligences&quot; (evolution).
<br>
<p>This is one of the silliest mistakes that a person interested in AI 
<br>
could make.   You know Conway's game of Life?  I've got a dinky little 
<br>
simulation here on this machine that will show me a whole zoo of gliders 
<br>
and loaves and glider guns and traffic lights and whatnot.  Demanding 
<br>
that an AI person should study &quot;evolutionary biology with math&quot; is about 
<br>
as stupid as demanding that someone interested in the structure of 
<br>
computers should study every last detail of the gliders, loaves, glider 
<br>
guns and traffic lights, etc. in Conway's Life.
<br>
<p>Level of description fallacy.  Searle fell for it when he invented his 
<br>
ridiculous Chinese Room.  Why would yo make the same dumb mistake?
<br>
<p><p><em>&gt; Loosemore, I commend to you the following documents with respect to 
</em><br>
<em>&gt; community (H) of which you are most sorely in need of joining, followed 
</em><br>
<em>&gt; thereafter by (I) and (G).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; <a href="http://yudkowsky.net/bayes/bayes.html">http://yudkowsky.net/bayes/bayes.html</a>
</em><br>
<em>&gt; <a href="http://yudkowsky.net/bayes/technical.html">http://yudkowsky.net/bayes/technical.html</a>
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Having read the second document, you will understand what is wrong, as a 
</em><br>
<em>&gt; matter of scientific procedure and rational reasoning, with attributing 
</em><br>
<em>&gt; human intelligence to &quot;the emergent properties of a hypercomplex 
</em><br>
<em>&gt; network&quot; as though this were a hypothesis.
</em><br>
<p>I did read the documents.  I knew about Bayes Theorem already.
<br>
<p>A lot of sound and fury, signifying nothing.  You have no real 
<br>
conception of the limitations of mathematics, do you?  You don't seem to 
<br>
understand that the forces that shape thought and the forces that shape 
<br>
our evaluation of technical theories (each possibly separate forces, 
<br>
though related) might not be governed by your post-hoc bayesian analysis 
<br>
of them.  That entire concept of the separation between an approximate 
<br>
description of a process and the mechanisms that actually *is* the 
<br>
process, is completely lost on you.  Your technical.html document is one 
<br>
long stream-of-consciousness eulogy to the perfection of mathematics as 
<br>
applied to a couple of particular domains (thought, and the nature of 
<br>
scientific inquiry), without any indication that you can recite back to 
<br>
me clearly and succinctly the issue that a number of people would raise 
<br>
against your eulogy.  You cannot even comprehend this issue.
<br>
<p>[Oh, I forgot:  I know mathematics too.  I took it as far as some 
<br>
postgraduate courses in General Relativity and Mathematical Foundations 
<br>
of Quantum Mechanics.  I can see why you started this whole &quot;I can be 
<br>
smarter than you thing&quot; .... its a heck of a lot of fun to let your hair 
<br>
down occasionally, isn't it!!  I am normally very modest, so I am 
<br>
grateful that you gave me such a perfect excuse to be this silly for a 
<br>
while.]
<br>
<p>Isn't it a little arrogant to tell me to read stuff that I already 
<br>
understand, when you have a little catching up to do in the domains 
<br>
that, earlier, you said you only &quot;half&quot; knew?
<br>
<p>Especially since the very powerful arguments that people in other fields 
<br>
have levelled against the kind of approach to AI typified by Bayesian 
<br>
Inference cannot be understood or discussed unless you are familiar with 
<br>
those other fields?
<br>
<p>What if knowledge of all the six domains I mentioned gave a person the 
<br>
tools to understand that your approach was doomed?  That was my original 
<br>
point.
<br>
<p><p><em>&gt; You can skip the first document if you understand simple Bayesian 
</em><br>
<em>&gt; reasoning *thoroughly*, by which I mean that you can write Bayes's Rule 
</em><br>
<em>&gt; from memory and that you know why transforming probabilities to log-odds 
</em><br>
<em>&gt; ratios can simplify bookkeeping.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; You may also be interested in the evolutionary psychology of human 
</em><br>
<em>&gt; intelligence and my own take on human concepts, findable at the 
</em><br>
<em>&gt; now-obsolete:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; <a href="http://intelligence.org/LOGI/">http://intelligence.org/LOGI/</a>
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt; COMMUNITY (A)
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Those who would understand completely if you started discussing 
</em><br>
<em>&gt;&gt; &quot;Shiffrin and Schneider&quot;, or &quot;Levels of Processing Theory&quot;, or &quot;Deep 
</em><br>
<em>&gt;&gt; Dyslexia.&quot;  They would also what a word-exhange error, a 
</em><br>
<em>&gt;&gt; morpheme-exchange error or a semantic substitution was.  They would 
</em><br>
<em>&gt;&gt; understand the power-law of skill acquisition.  They would know about 
</em><br>
<em>&gt;&gt; &quot;Smith and Medin&quot; if you asked them for their thoughts about 
</em><br>
<em>&gt;&gt; classical, prototype and feature theories of concepts, and what the 
</em><br>
<em>&gt;&gt; current think was on those issues, they might not be able to answer 
</em><br>
<em>&gt;&gt; immediately, but they would know what you were asking for, and would 
</em><br>
<em>&gt;&gt; be able track it down pretty quickly.  And if you mentioned 
</em><br>
<em>&gt;&gt; &quot;motivation&quot;, &quot;compulsion&quot;, &quot;obsession&quot; or &quot;pleasure&quot; they would 
</em><br>
<em>&gt;&gt; assume you were just using these as shorthand for certain mechanisms, 
</em><br>
<em>&gt;&gt; rather than assuming you were talking dualist philosophy.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Smith and Medin?  Eleanor Rosch or George Lakoff would be more 
</em><br>
<em>&gt; appropriate names to cite here, no?  You seem to have gotten stuck in an 
</em><br>
<em>&gt; eddy of this field; your selected highlights don't sound like central 
</em><br>
<em>&gt; exemplars of the category.  And why do you lump motivation in with that?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It sounds like your community (A) is intended to stand for the whole of 
</em><br>
<em>&gt; cognitive psychology, a field which includes also (G) as a special 
</em><br>
<em>&gt; case.  If so, you need to study way more cognitive psychology.  A fine 
</em><br>
<em>&gt; and classic book is &quot;Judgment Under Uncertainty&quot; from (G).
</em><br>
<p>As I said at the outset, this is foolishness.  I have read &quot;Judgment 
<br>
Under Uncertainty&quot;, and Lakoff's &quot;Women, Fire and Dangerous Things&quot; ... 
<br>
sitting there on the shelf behind me.
<br>
<p>Why do I &quot;need to study way more cognitive psychology&quot;?
<br>
<p><p><em>&gt;&gt; COMMUNITY (B)
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Those who know how to write serious amounts of LISP, who understand 
</em><br>
<em>&gt;&gt; pruning algorithms in state-space search, and who know the difference 
</em><br>
<em>&gt;&gt; between Blackboards, GAs, and neural nets.  They might well be able to 
</em><br>
<em>&gt;&gt; tell you about &quot;unification&quot; in Prolog, and be able to give you a 
</em><br>
<em>&gt;&gt; thoughtful discussion of the differences between John Koza's genetic 
</em><br>
<em>&gt;&gt; programming and genetic algorithms and evolutionary programming.  They 
</em><br>
<em>&gt;&gt; would definitely know about goal hierarchies and planning systems.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Also known as Mainstream AI: the predicate logic users, connectionists, 
</em><br>
<em>&gt; and artificial evolutionists.  What they know about goal hierarchies and 
</em><br>
<em>&gt; planning systems is quite different from what decision theorists know 
</em><br>
<em>&gt; about expected utility maximization, though of course there's some overlap.
</em><br>
<p>I was conjoining the decision theorists with the hard AI group, since 
<br>
most of the AI people I know are perfectly familiar with the latter.
<br>
<p><p><p><em>&gt; I note that FAI issues lie much closer to decision theory.  It is 
</em><br>
<em>&gt; better, in discussing FAI, to know who first wrote about Newcomb's 
</em><br>
<em>&gt; Problem than to know who built SHRDLU.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I once wrote of this field that it is important primarily as a history 
</em><br>
<em>&gt; of failure.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt; COMMUNITY (C)
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Those to whom the term &quot;edge of chaos&quot; is not just something they 
</em><br>
<em>&gt;&gt; learned from James Gleick.  These people are comfortable with the idea 
</em><br>
<em>&gt;&gt; that mathematics is a fringe activity that goes on at the tractable 
</em><br>
<em>&gt;&gt; edge of a vast abyss of completely intractable systems and equations.  
</em><br>
<em>&gt;&gt; When they use the term &quot;non-linear&quot; they don't mean something that is 
</em><br>
<em>&gt;&gt; not a straight line, nor are they talking about finding tricks that 
</em><br>
<em>&gt;&gt; yield analytic solutions to certain nonlinear equations.  They are 
</em><br>
<em>&gt;&gt; equally comfortable talking about a national economy and a brain as a 
</em><br>
<em>&gt;&gt; &quot;CAS&quot; and they can point to meaningful similarities in the behavior of 
</em><br>
<em>&gt;&gt; these two sorts of system.  Almost all of these people are seriously 
</em><br>
<em>&gt;&gt; well versed in mathematics, but unlike the main body of mathematicians 
</em><br>
<em>&gt;&gt; proper, they understand the limitations of analytic attempts to 
</em><br>
<em>&gt;&gt; characterize systems in the real world.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I'm not part of community C and I maintain an extreme skepticism of its 
</em><br>
<em>&gt; popular philosophy, as opposed to particular successful technical 
</em><br>
<em>&gt; applications, for reasons given in &quot;A Technical Explanation of Technical 
</em><br>
<em>&gt; Explanation&quot;.
</em><br>
<p>You speak from a profound lack of depth in the one field where depth of 
<br>
understanding is most important.  You mistake &quot;particular successful 
<br>
technical applications&quot; for the issues of most importance to AI.
<br>
<p>There is nothing wrong with skepticism.  If it is based on 
<br>
understanding, rather than wilful, studied ignorance.
<br>
<p><p><p><em>&gt;&gt; COMMUNITY (D)
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Those who have had the kind of experience in which they find 
</em><br>
<em>&gt;&gt; themselves fifty levels deep in a debugger, working on Final Candidate 
</em><br>
<em>&gt;&gt; 7 of a piece of software comprising 4000 source files of C and C++, in 
</em><br>
<em>&gt;&gt; a hopeless attempt to troubleshoot problems in a codebase that they 
</em><br>
<em>&gt;&gt; have only written tiny parts of, and in which the rest is mostly 
</em><br>
<em>&gt;&gt; undocumented and barely commented (by people who often did not have 
</em><br>
<em>&gt;&gt; much English), with the product due to ship in two weeks.  An 
</em><br>
<em>&gt;&gt; experience that bears about as much relationship to a computer science 
</em><br>
<em>&gt;&gt; degree as Mrs Featherstone's Finishing School For Young Ladies does to 
</em><br>
<em>&gt;&gt; a whorehouse.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I've stayed up 36 hours in a row, twelve levels deep in a debugger, 
</em><br>
<em>&gt; hunting a mysterious stack smasher in a C++ application with at least 
</em><br>
<em>&gt; 200 source files, which I did write myself.  Close enough.  Long live 
</em><br>
<em>&gt; Python!
</em><br>
<p>You wrote the 200 files yourself?  So you didn't have to navigate 
<br>
through a codebase of 4000 files written by someone else?   What are 
<br>
you, wet behind the ears?  :-)
<br>
<p>Corel abandoned the Mac version of CorelDraw a couple of years ago, 
<br>
after putting me and my buddies through hell to get it ported across 
<br>
from Windows.  Their own team had tried to port it once, and failed. 
<br>
Then they tried a second time, and failed again.  The third time they 
<br>
asked for help, and the outfit I worked for took on the job and 
<br>
succeeded.  Corel went through another four or five upgrades before they 
<br>
abandoned it forever.
<br>
<p>I know why ;-).
<br>
<p><p><p><p><em>&gt;&gt; COMMUNITY (E)
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Those who could give you a reasonable account of where Penrose, 
</em><br>
<em>&gt;&gt; Chalmers and Dennett would stand with respect to one another.  They 
</em><br>
<em>&gt;&gt; could easily distinguish the Hard Problem from other versions of the 
</em><br>
<em>&gt;&gt; consciousness issue, even if they might disagree with Chalmers about 
</em><br>
<em>&gt;&gt; the conclusion to be drawn.  They know roughly what supervenience is.  
</em><br>
<em>&gt;&gt; The could certainly distinguish functionalism (various breeds thereof) 
</em><br>
<em>&gt;&gt; from epiphenomenalism and physicalism, and they could talk about what 
</em><br>
<em>&gt;&gt; various camps thought about the issues of dancing, inverted and absent 
</em><br>
<em>&gt;&gt; qualia.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Sadly I recognize every word and phrase in this paragraph, legacy of a 
</em><br>
<em>&gt; wasted childhood, like being able to sing the theme song from Thundercats.
</em><br>
<p>Shame.  There is valuable stuff buried in among the dross.
<br>
<p><p><em>&gt;&gt; COMMUNITY (F)
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Those who know enough about real neural hardware to think that there 
</em><br>
<em>&gt;&gt; are serious questions about whether the real computation takes place 
</em><br>
<em>&gt;&gt; in floods of junk in a synaptic cleft or in specific timings of 
</em><br>
<em>&gt;&gt; incoming spikes in the dendritic tree.  They know about programmed 
</em><br>
<em>&gt;&gt; cell death and how that might relate to learning.  They might know 
</em><br>
<em>&gt;&gt; about the Hodgkin-Huxley equations.  They understand what Marr had to 
</em><br>
<em>&gt;&gt; say about the possible role of Purkinje cells in fine motor control, 
</em><br>
<em>&gt;&gt; and they would know way too much about the architectural features of 
</em><br>
<em>&gt;&gt; the brain.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; We *know* that dendritic computing exists, it's no longer a &quot;serious 
</em><br>
<em>&gt; question&quot; but an answered one.
</em><br>
<p>What are you talking about?  Do you actually read my words, or just some 
<br>
fantasy version of what you think I wrote?
<br>
<p>I didn't say that dendritic computing was a serious question, I said 
<br>
that &quot;whether the *real computation* takes place [...] in the dendritic 
<br>
tree&quot; was a serious question.  Totally different issue.
<br>
<p><p>So, that pretty much wraps it up for your extra communities that you 
<br>
would like everyone to know about.  One was identical to the first one 
<br>
on my list, one is a narrow quasi-mathematical community who live in a 
<br>
world of their own, but who DO NEED TO BE UNDERSTOOD, AND SHOULD NOT BE 
<br>
IGNORED .... the only problem is that when you understand them, they 
<br>
don't understand you, and they cannot understand that they are building 
<br>
castles on sand.  And the other one was almost completely irrelevant - 
<br>
fun to keep up with, but no help.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12110.html">Maru Dubshinki: "Re: AI-Box Experiment #4: Russell Wallace, Eliezer Yudkowsky"</a>
<li><strong>Previous message:</strong> <a href="12108.html">Mikko Särelä: "Re: Complexity tells us to maybe not fear UFAI"</a>
<li><strong>In reply to:</strong> <a href="11987.html">Eliezer S. Yudkowsky: "Re: Retrenchment"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0509/12201.html">Eliezer S. Yudkowsky: "Re: Retrenchment"</a>
<li><strong>Reply:</strong> <a href="../0509/12201.html">Eliezer S. Yudkowsky: "Re: Retrenchment"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12109">[ date ]</a>
<a href="index.html#12109">[ thread ]</a>
<a href="subject.html#12109">[ subject ]</a>
<a href="author.html#12109">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
