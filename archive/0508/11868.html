<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: &quot;Objective&quot; Morality</title>
<meta name="Author" content="Marcello Mathias Herreshoff (m@marcello.gotdns.com)">
<meta name="Subject" content="Re: &quot;Objective&quot; Morality">
<meta name="Date" content="2005-08-09">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: &quot;Objective&quot; Morality</h1>
<!-- received="Tue Aug  9 12:26:13 2005" -->
<!-- isoreceived="20050809182613" -->
<!-- sent="Tue, 9 Aug 2005 11:25:58 -0700" -->
<!-- isosent="20050809182558" -->
<!-- name="Marcello Mathias Herreshoff" -->
<!-- email="m@marcello.gotdns.com" -->
<!-- subject="Re: &quot;Objective&quot; Morality" -->
<!-- id="20050809182558.GA22469@marcello.gotdns.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="20050809065540.66086.qmail@web31508.mail.mud.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Marcello Mathias Herreshoff (<a href="mailto:m@marcello.gotdns.com?Subject=Re:%20&quot;Objective&quot;%20Morality"><em>m@marcello.gotdns.com</em></a>)<br>
<strong>Date:</strong> Tue Aug 09 2005 - 12:25:58 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11869.html">Jeff Medina: "Re: [wta-talk] Re: On Our Duty to Not Be Responsible for ArtificialMinds"</a>
<li><strong>Previous message:</strong> <a href="11867.html">Thomas Petersen: "RE: &quot;Objective&quot; Morality"</a>
<li><strong>In reply to:</strong> <a href="11864.html">Marc Geddes: "Re: &quot;Objective&quot; Morality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11871.html">Marc Geddes: "Re: &quot;Objective&quot; Morality"</a>
<li><strong>Reply:</strong> <a href="11871.html">Marc Geddes: "Re: &quot;Objective&quot; Morality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11868">[ date ]</a>
<a href="index.html#11868">[ thread ]</a>
<a href="subject.html#11868">[ subject ]</a>
<a href="author.html#11868">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Tue, Aug 09, 2005 at 06:55:40PM +1200, Marc Geddes wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; --- Tennessee Leeuwenburg &lt;<a href="mailto:hamptonite@gmail.com?Subject=Re:%20&quot;Objective&quot;%20Morality">hamptonite@gmail.com</a>&gt;
</em><br>
<em>&gt; wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; That's incorrect : Objective != Universal.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; Universal means that the same morality applies
</em><br>
<em>&gt; &gt; universally (i.e. for
</em><br>
<em>&gt; &gt; everyone) whereas Objective means that for any one
</em><br>
<em>&gt; &gt; person their
</em><br>
<em>&gt; &gt; morality is an objective fact.
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; To clarify, 'Universal Morality' is what I really
</em><br>
<em>&gt; always meant.  I think there's a set of moral
</em><br>
<em>&gt; principles applicable to all sentients in the
</em><br>
<em>&gt; multiverse at all times.  This background set of
</em><br>
<em>&gt; principles goes beyond mere 'Volition' (what sentients
</em><br>
<em>&gt; want).
</em><br>
<p>Yes, I realize now that I did gloss over a few of the differences between
<br>
Objective and Universal Morality, but my argument makes both of these
<br>
concepts meaningless anyway.
<br>
<p>As Tennessee Leeuwenburg seems to define them, objective morality is the
<br>
claim by some person that their personal morality is an objective fact,
<br>
whereas universal morality claims that there some morality out there which
<br>
applies universally.
<br>
<p>If you meant something else by either of these terms, feel free to clarify.
<br>
<p>How does one find out whether a morality is &quot;applying universally.&quot;  I
<br>
already showed that no experiment will do the trick.  Thus that is
<br>
meaningless too, as there is no way to find out which morality is universal.
<br>
<p><em>&gt; The reason I keep banging on and on about this on list
</em><br>
<em>&gt; to the point where I've annoyed people almost to
</em><br>
<em>&gt; getting banned is because I'm certain I'm right.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I haven't been able to produce a completely coherent
</em><br>
<em>&gt; proof yet.  That's the only little problem ;)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Seriously, though, I would be absolutely astonished if
</em><br>
<em>&gt; I was wrong about this.  But if turns out that I *am*
</em><br>
<em>&gt; wrong about this, after the Singularity you are all
</em><br>
<em>&gt; quite welcome to get print-outs of all my SL4
</em><br>
<em>&gt; postings, and stuff them down my throat one at a time
</em><br>
<em>&gt; for being such an idiot.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I think Eliezer is simply confused.  He's pissing
</em><br>
<em>&gt; around in the dark without a clue. Poor fellow. 
</em><br>
<em>&gt; Brilliant?  Yes.  Right?  No.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Ask yourselves:  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Does the idea of general intelligence without
</em><br>
<em>&gt; sentience (consciousness) *really* make sense to you?
</em><br>
<p>Well of course not!  The only examples of intelligence humans have ever seen
<br>
in their evolutionary past are sentient ones.  That doesn't lessen the
<br>
possibility of the future existence of intelligences which are not.
<br>
<p><em>&gt; Does the idea of a super-smart intelligence interested
</em><br>
<em>&gt; only in tiling the universe with paper-clips *really*
</em><br>
<em>&gt; make sense to you?
</em><br>
<p>Nope.  Neither does a nuclear missile.  This doesn't make the threat any less
<br>
real.
<br>
<p><em>&gt; To my mind, these ideaas are obviously quite absurd. 
</em><br>
<em>&gt; Always were.  Always have been.  Only someone with
</em><br>
<em>&gt; Autism or Aspergers could seriously give them
</em><br>
<em>&gt; credence.
</em><br>
<p>You are half right.  These two diseases are marked by an inability to
<br>
understand the behavior of other humans.  Perhaps someone with one of these
<br>
diseases would have an easier time understanding what a real AI would
<br>
actually do, as they would not constantly be attempting to empathize with
<br>
something that their brain isn't the least bit like.
<br>
<p>The list of things that didn't make sense to people in their time is very
<br>
long indeed.  It contains almost every single technological revolution, from
<br>
the telephone to the computer, from relativity to quantum mechanics.  Do you
<br>
expect something as revolutionary as an AI to actually make sense to us?
<br>
<p><em>&gt; I point to the proven fact that there's a *unity* to
</em><br>
<em>&gt; the universe, in the sense that scientific theories
</em><br>
<em>&gt; from different subject areas have in the past always
</em><br>
<em>&gt; *fitted together* in a coherent way.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; As an example I point to the 4 physics forces: 
</em><br>
<em>&gt; Electromagnetism, Gravity, Weak Nuclear, Strong
</em><br>
<em>&gt; Nuclear.  Modern phsyics frameworks (for instance 'the
</em><br>
<em>&gt; standard model') are succedded in 'unifying' the 4
</em><br>
<em>&gt; forces into a single explanatory framework.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; There is no reason by all facets of the mind should
</em><br>
<em>&gt; not also be *integrated* (unified) into a single
</em><br>
<em>&gt; explanatory framework also.
</em><br>
<p>Physics isn't Psychology.
<br>
<p>The Laws of the Universe are simple and pretty as far as we can tell.
<br>
The human brain is a hodge podge of layered complex function adaptations, most
<br>
of which are set up to deal with medium sized things for medium length times
<br>
on the plains of Africa.  Given that the brain was made by a blind watch
<br>
maker who cares far less about consistency than even Microsoft, what makes
<br>
you expect there to be underlying principles?
<br>
<p>I grant you that because we have the ability to empathize with other humans
<br>
(really a poorly designed emulation hack) it may seem that given how much we
<br>
have in common, there are universal principles.  This is an illusion
<br>
maintained by the fact that most people are very similar mentally.  Look
<br>
at people with (to use your example) autism, if you want an idea of what
<br>
intelligence looks like when it is even just a tiny bit different.
<br>
<p><em>&gt; Take 'Values' on the one hand, and 'Intelligence'
</em><br>
<em>&gt; (ability to make predictions on the other).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; If it really were the case that you could have a
</em><br>
<em>&gt; super-smart intelligence with any old value system,
</em><br>
<em>&gt; that would mean that it would be impossible to
</em><br>
<em>&gt; combinedValues and Intelligence into a single
</em><br>
<em>&gt; explanatory framework.  This goes against everything
</em><br>
<em>&gt; we know about the fundamental *explanatory* unity of
</em><br>
<em>&gt; the cosmos.
</em><br>
<p>Again, human values and human intelligence are not fundamental principles.
<br>
They are the products of complex functional adaptations.
<br>
<p><em>&gt; As an analogy, I point to  physics  again:
</em><br>
<em>&gt; Electromagnetic and Weak Nuclear forces.  Everyone
</em><br>
<em>&gt; thought they were seperate, but then physics showed
</em><br>
<em>&gt; that they were related:  under certain conditions they
</em><br>
<em>&gt; combine into a single force: the Electro-weak force.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; And there is every reason for thinking that  'Values'
</em><br>
<em>&gt; and 'Intelligence' are related in some way not yet
</em><br>
<em>&gt; understand, so that a super-smart intelligence must
</em><br>
<em>&gt; correlate with Friendliness as I've claimed.  Again,
</em><br>
<em>&gt; if this wasn't true science would unable to integrate
</em><br>
<em>&gt; values and Intelligence into a single expalanatory
</em><br>
<em>&gt; framework, which would run contrary to everything we
</em><br>
<em>&gt; know about the fundamental unity of the cosmos.
</em><br>
See above.
<br>
<em>&gt;
</em><br>
<em>&gt; Thoughts cannot float around free of brains.  And
</em><br>
<em>&gt; brains obey physical laws.  So it's reasonable to
</em><br>
<em>&gt; suppose that there are 'laws of thoughts' that apply
</em><br>
<em>&gt; to all sentients.  Such-and-such a thought has to
</em><br>
<em>&gt; correlate with such-and-such a brain state (otherwise
</em><br>
<em>&gt; functionalism would be false).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; There are basic conditions that need to met for
</em><br>
<em>&gt; 'cognition' to occur in the first place.  Pure
</em><br>
<em>&gt; Self-awareness and ability to take action are not
</em><br>
<em>&gt; themselves a part of the 'Volitional' level.  Volition
</em><br>
<em>&gt; is what sentients want, but self-awareness itself
</em><br>
<em>&gt; comes from the basic laws underpinning cognition.
</em><br>
Again, what basic laws?
<br>
<em>&gt; 
</em><br>
<em>&gt; For instance, take the ability to detect 'spatial
</em><br>
<em>&gt; patterns'.  This pattern-recognition is only possible
</em><br>
<em>&gt; of a certain meta-condition : namely that there is
</em><br>
<em>&gt; some degree of *symmetry* in physical objects.  So the
</em><br>
<em>&gt; meta-principle *Symmetry* is a neccessery condition of
</em><br>
<em>&gt; cognition.  But for a mind which is self-aware it
</em><br>
<em>&gt; *also* becomes a *value* - symmetry is valued because
</em><br>
<em>&gt; it enables cognition to occur in the first place and
</em><br>
<em>&gt; allows self-wareness to begin with.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This shows that there are meta-values which are
</em><br>
<em>&gt; 'neccessery conditions of cognition', and are not
</em><br>
<em>&gt; themselves a part of the level of 'Individual
</em><br>
<em>&gt; Volition', but go beyond this and constitute a sort of
</em><br>
<em>&gt; 'Universal Volition'.
</em><br>
<p>If you are not defining Universal as all of humanity, which would make it
<br>
Collective, what or who do you even mean by it?  If you are postulating a
<br>
deity, it might really be time for somebody to call the list sniper.
<br>
<p><em>&gt; As I said earlier, I think the foundation of values is
</em><br>
<em>&gt; *not* individual (or even collective) Volition, but
</em><br>
<em>&gt; *Self-Actualization* - becoming more aware of our true
</em><br>
<em>&gt; nature.  And our 'true nature' is the objective,
</em><br>
<em>&gt; universal principles underpinning self-awareness and
</em><br>
<em>&gt; cognition.
</em><br>
<p>So I get Enlightened when I become truly aware of the hodge podge that is
<br>
the human brain?  I seriously doubt it.  If we really about knew all the
<br>
kludges and piled up lies that the brain uses to accomplish its evolutionary
<br>
business would we really be all that happy?  On the contrary, I suspect it
<br>
would offend our moral sensibilities, and make us want to move out of our
<br>
wetware and become truly decent people.
<br>
<p>-=+Marcello Mathias Herreshoff
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11869.html">Jeff Medina: "Re: [wta-talk] Re: On Our Duty to Not Be Responsible for ArtificialMinds"</a>
<li><strong>Previous message:</strong> <a href="11867.html">Thomas Petersen: "RE: &quot;Objective&quot; Morality"</a>
<li><strong>In reply to:</strong> <a href="11864.html">Marc Geddes: "Re: &quot;Objective&quot; Morality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11871.html">Marc Geddes: "Re: &quot;Objective&quot; Morality"</a>
<li><strong>Reply:</strong> <a href="11871.html">Marc Geddes: "Re: &quot;Objective&quot; Morality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11868">[ date ]</a>
<a href="index.html#11868">[ thread ]</a>
<a href="subject.html#11868">[ subject ]</a>
<a href="author.html#11868">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:51 MDT
</em></small></p>
</body>
</html>
