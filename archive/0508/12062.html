<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: does complexity tell us that there are probably exploits?</title>
<meta name="Author" content="Daniel Radetsky (daniel@radray.us)">
<meta name="Subject" content="does complexity tell us that there are probably exploits?">
<meta name="Date" content="2005-08-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>does complexity tell us that there are probably exploits?</h1>
<!-- received="Mon Aug 22 18:15:43 2005" -->
<!-- isoreceived="20050823001543" -->
<!-- sent="Mon, 22 Aug 2005 17:15:39 -0700" -->
<!-- isosent="20050823001539" -->
<!-- name="Daniel Radetsky" -->
<!-- email="daniel@radray.us" -->
<!-- subject="does complexity tell us that there are probably exploits?" -->
<!-- id="20050822171539.58922b86@localhost.localdomain" -->
<!-- charset="US-ASCII" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Daniel Radetsky (<a href="mailto:daniel@radray.us?Subject=Re:%20does%20complexity%20tell%20us%20that%20there%20are%20probably%20exploits?"><em>daniel@radray.us</em></a>)<br>
<strong>Date:</strong> Mon Aug 22 2005 - 18:15:39 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12063.html">Chris Paget: "[JOIN] Chris Paget"</a>
<li><strong>Previous message:</strong> <a href="12061.html">Russell Wallace: "Re: Transcript. please? (Re: AI-Box Experiment 3)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12068.html">Thomas Buckner: "Re: does complexity tell us that there are probably exploits?"</a>
<li><strong>Reply:</strong> <a href="12068.html">Thomas Buckner: "Re: does complexity tell us that there are probably exploits?"</a>
<li><strong>Reply:</strong> <a href="12070.html">Peter de Blanc: "Re: does complexity tell us that there are probably exploits?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12062">[ date ]</a>
<a href="index.html#12062">[ thread ]</a>
<a href="subject.html#12062">[ subject ]</a>
<a href="author.html#12062">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I decided I would respond at least once to Michael Vassar's objection before
<br>
putting it in my essay, just in case he's right. I'm writing this in a
<br>
non-conversational tone, partially because I'm practicing for the essay, and
<br>
partially because enough time has elapsed since Vassar's response that it no
<br>
longer feels like a conversation. I am also writing more verbosely than is
<br>
probably necessary to convey my response. This is because I recognize my
<br>
general ignorance about many of these topics, and writing verbosely will allow
<br>
a reader to diagnose errors of reasoning in my email, if any exist.
<br>
<p>Vassar wants to say that despite my objections, we ought worry about exploits
<br>
but not ninja hippos because the claim &quot;there are exploits&quot; has a higher prior
<br>
probability than &quot;there are ninja hippos.&quot; This is because, according to
<br>
Vassar, the Kolmogorov complexity of e, the first proposition, is greater than
<br>
the complexity of h, the second proposition.
<br>
<p>Obviously, e and h are not bitstrings and do not straightforwardly have
<br>
complexity. To discuss the complexity of objects in the sense of rocks and
<br>
fish, we need some sort of encoding scheme which maps real world objects to
<br>
bitstrings. Vassar must hold either:
<br>
<p>1. The encoding scheme is a matter of free choice on our part, and every
<br>
complexity is complexity-for-scheme-S.
<br>
<p>2. There is a universal, correct encoding scheme.
<br>
<p>I assume that Vassar holds (2), because (1) is too easy for someone holding my
<br>
position to get around. Briefly, I can pick an artificial encoding scheme where
<br>
ninja hippos have a simpler representation than exploits.
<br>
<p>If Vassar holds (2), then what is the encoding scheme, and what is the basis
<br>
for saying that this is THE scheme? I know of only one such basis, and will
<br>
assume that it is the only basis here. This basis is the idea that the universe
<br>
is fundamentally digital: it consists of a bunch of states that are either in
<br>
one fundamental state or another. I have heard this theory repeated by a lot of
<br>
SL4 types and would not be surprised if Vassar held it. I will call the theory
<br>
the Binary Universe Thesis (BUT). One who asserts the BUT will naturally hold
<br>
that any proposition p corresponds to some binary state of affairs (BSA), and 
<br>
can be expressed as a bitstring with a definite complexity. So e and h are
<br>
numbers or sets of numbers (just in case more than one BSA would count as there
<br>
being exploits or ninja hippos).
<br>
<p>I'm not entirely sure how one gets prior probability from complexity, but I'm
<br>
willing to accept that it can be done. We'll say there is a function f such
<br>
that for some proposition p with a corresponding BSA n, f(K(n))=P(p)=x, where x
<br>
is a real number, K is the complexity of a string, and P is a probability
<br>
function (I will sometimes use the same symbol to represent both the BSA and
<br>
the proposition, but I don't think this will be confusing. I suspect many of
<br>
the proponents of the BUT would assert that the proposition and the BSA are
<br>
identical, and so no distinction need be made).  Using some technique
<br>
resembling the above, Vassar holds that  P(e) &gt; P(h), and so we should worry
<br>
about e before we worry about h. This is a valid defense against my h-based
<br>
counterexample, but it doesn't actually get the job of defending a worry about
<br>
exploits done.
<br>
<p>The first problem with Vassar's position is a problem for Orthodox Bayesianism
<br>
in general. Suppose we want to know the prior probability of p, so we calculate
<br>
f(K(p)) and get x. However, to do this, we presuppose BUT. We have not
<br>
calculated P(p), but rather P(p|BUT), since we would be wrong to claim the
<br>
probability of p is x if BUT were false. However, to find P(p|BUT) we need to
<br>
know P(BUT), but we can't find this out by using f(K(BUT)), as this would be
<br>
begging the question. So we need to use ordinary, non-formal scientific
<br>
know-how to confirm BUT. I am under the impression the BUT is far from strongly
<br>
confirmed, but rather is merely another exciting theory. Is this true? How
<br>
confident can we be that BUT is the case? If we cannot be quite confident, we
<br>
cannot make the kind of claims about prior probability that Vassar needs to
<br>
make.
<br>
<p>The second problem has to do with the structure of an argument against my
<br>
position. If my intuition tells me that P(a) = P(b), and Vassar (or someone
<br>
else) wants to defeat my intuition, he can do it either mathematically or
<br>
intuitively. No doubt Vassar wishes he could make a mathematical argument that
<br>
P(e) != P(h), but this is not possible because to do this Vassar would have
<br>
possess knowledge which (as far as I know) he doesn't: the BSAs corresponding
<br>
to e and h. So he must defeat my intuition intuitively. Vassar simply claimed
<br>
that e was vague and h specific -&gt; K(e) &lt; K(h) -&gt; P(e) &gt; P(h). This is fine,
<br>
but it's not clear that m=&quot;There is magic&quot; (in the ordinary sense of the word)
<br>
or l=&quot;there is a lurking horror&quot; or g=&quot;there is a god&quot; are more specific than e.
<br>
<p>Vassar also points out that even if, for example, g and e are equally vague,
<br>
and hence have similar prior probability, it still may not be rational to treat
<br>
them the same way. Obviously, we need to worry about God just in case there is
<br>
something relevant about doing so. Let g'=&quot;God will send you to hell no matter
<br>
what.&quot; How should we respond to the possibility that g'? We shouldn't, because
<br>
nothing we can do will change it. On the other hand g''=&quot;God will send you to
<br>
hell unless you go to church on sunday&quot; should be responded to by going to
<br>
church on sunday iff we are justified in believing g''. In this case, we are
<br>
justified to the tune of f(K(g'')). However, the proposition g'''=&quot;God will
<br>
send you to hell unless you avoid going to church on sunday&quot; tells us to do the
<br>
opposite of what g'' tells us. Vassar would claim that f(K(g'')) is equal to
<br>
f(K(g''')), and so we can't use our worries about going to hell to decide
<br>
whether or not to attend church. The claim is encapsulated by the principle
<br>
that we are not justified in worrying about p if there is no evidence for p and
<br>
if, given that p will alter the utility of the world if we do X, the complexity
<br>
of p remains roughly constant for all X. If we wanted to make this principle
<br>
more mathematical, we could require that the distance between the highest and
<br>
lowest probability remain below a certain value, with the value perhaps related
<br>
to the mean probability or the disutility of the event.
<br>
<p>Here's the problem as I see it: I claim that a world which contains exploits
<br>
is about as complex as a world which does not (or, There are two possible
<br>
worlds w1 and w2 such that both are empirically equivalent to the actual world,
<br>
and w1 contains exploits, w2 does not, and K(w1) = K(w2)) (What is the symbol
<br>
for &quot;approximately equal to&quot; in text?). Suppose we were to engineer humans
<br>
which, for whatever reason, could not be mind-controlled by UFAI. Now we want
<br>
to decide whether or not we should box the AI, recognizing that if there are
<br>
exploits, we're screwed. Necessarily, we cannot have evidence that there are
<br>
exploits, so we consider our complexity-based priors. But since K(w1) = K(w2),
<br>
they should have the same prior probability. If w1 were the case, then we
<br>
should not box the AI, because if it is going to be friendly it would be a
<br>
waste of time and resources to box it, and if it is going to be unfriendly,
<br>
boxing won't do any good. But if w2 were the case, then we should box it,
<br>
because if the AI is friendly, we'll just have wasted a bit of time and
<br>
resources, but if it is unfriendly we've averted disaster. Hence we cannot use
<br>
our worry that e to decide between boxing and not boxing, as with the case of
<br>
God. Unless Vassar can compellingly argue that K(w1) != K(w2), I don't see how
<br>
the complexity argument can move forward.
<br>
<p>So, to sum up, arguing that complexity tells us to worry about exploits has two
<br>
major problems. It relies on a premise that even more controversial than the
<br>
conclusion, and it seems like the logical conclusion of the premises is the
<br>
opposite of the intended conclusion.
<br>
<p>Daniel
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12063.html">Chris Paget: "[JOIN] Chris Paget"</a>
<li><strong>Previous message:</strong> <a href="12061.html">Russell Wallace: "Re: Transcript. please? (Re: AI-Box Experiment 3)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12068.html">Thomas Buckner: "Re: does complexity tell us that there are probably exploits?"</a>
<li><strong>Reply:</strong> <a href="12068.html">Thomas Buckner: "Re: does complexity tell us that there are probably exploits?"</a>
<li><strong>Reply:</strong> <a href="12070.html">Peter de Blanc: "Re: does complexity tell us that there are probably exploits?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12062">[ date ]</a>
<a href="index.html#12062">[ thread ]</a>
<a href="subject.html#12062">[ subject ]</a>
<a href="author.html#12062">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
