<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: uncertainty in mathematics</title>
<meta name="Author" content="Wei Dai (weidai@weidai.com)">
<meta name="Subject" content="uncertainty in mathematics">
<meta name="Date" content="2005-08-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>uncertainty in mathematics</h1>
<!-- received="Wed Aug 24 16:46:21 2005" -->
<!-- isoreceived="20050824224621" -->
<!-- sent="Thu, 25 Aug 2005 06:46:06 +0800" -->
<!-- isosent="20050824224606" -->
<!-- name="Wei Dai" -->
<!-- email="weidai@weidai.com" -->
<!-- subject="uncertainty in mathematics" -->
<!-- id="BAY12-DAV10AE99931A62336E1206E7D8A80@phx.gbl" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Wei Dai (<a href="mailto:weidai@weidai.com?Subject=Re:%20uncertainty%20in%20mathematics"><em>weidai@weidai.com</em></a>)<br>
<strong>Date:</strong> Wed Aug 24 2005 - 16:46:06 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12099.html">Eliezer S. Yudkowsky: "AI-Box Experiment #4: Russell Wallace, Eliezer Yudkowsky"</a>
<li><strong>Previous message:</strong> <a href="12097.html">Michael Wilson: "Re: Complexity tells us to maybe not fear UFAI"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12098">[ date ]</a>
<a href="index.html#12098">[ thread ]</a>
<a href="subject.html#12098">[ subject ]</a>
<a href="author.html#12098">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
In order to make decisions, an AI may have to make use of mathematical conjectures which it's not able to either prove or disprove. (For example someone may ask the AI to bet directly on the truth of a conjecture.) Has there been any research on how this should be done? One idea would be to just apply decision theory and treat conjectures as statements about the state of the world to which probabilities can be assigned. We would have to extend standard decision theory in order to remove the assumption of logical omniscience, but supposing that is done, where do we get priors for mathematical statements?
<br>
<p>As a specific example, consider Goldbach's Conjecture, which states: every even number greater than 2 can be written as the sum of two primes. Intuitively, it seems that we can gain confidence in this conjecture by verifying that a large amount of even integers can be written as the sum of two primes. But to formalize this idea using Bayes' theorem would require the prior probability that Goldbach's Conjecture is true, and a function f(n) = P(there is at least one even number less than n that can't be written as the sum of two primes | Goldbach's conjecture is false). How does an AI come up with the prior and such a function?
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12099.html">Eliezer S. Yudkowsky: "AI-Box Experiment #4: Russell Wallace, Eliezer Yudkowsky"</a>
<li><strong>Previous message:</strong> <a href="12097.html">Michael Wilson: "Re: Complexity tells us to maybe not fear UFAI"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12098">[ date ]</a>
<a href="index.html#12098">[ thread ]</a>
<a href="subject.html#12098">[ subject ]</a>
<a href="author.html#12098">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
