<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Iterated Collective Volition Extrapolation</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="Iterated Collective Volition Extrapolation">
<meta name="Date" content="2005-08-31">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Iterated Collective Volition Extrapolation</h1>
<!-- received="Wed Aug 31 06:33:19 2005" -->
<!-- isoreceived="20050831123319" -->
<!-- sent="Wed, 31 Aug 2005 08:33:04 -0400" -->
<!-- isosent="20050831123304" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="Iterated Collective Volition Extrapolation" -->
<!-- id="JNEIJCJJHIEAILJBFHILGEEOGAAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=Re:%20Iterated%20Collective%20Volition%20Extrapolation"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Wed Aug 31 2005 - 06:33:04 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12173.html">Ben Goertzel: "META: sorry for the mis-posting"</a>
<li><strong>Previous message:</strong> <a href="12171.html">Ben Goertzel: "hmmmm"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12178.html">Ben Goertzel: "RE: Iterated Collective Volition Extrapolation"</a>
<li><strong>Reply:</strong> <a href="12178.html">Ben Goertzel: "RE: Iterated Collective Volition Extrapolation"</a>
<li><strong>Reply:</strong> <a href="../0509/12206.html">Olie Lamb: "General shock level qualitative differences (Re: SL5 TOE)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12172">[ date ]</a>
<a href="index.html#12172">[ thread ]</a>
<a href="subject.html#12172">[ subject ]</a>
<a href="author.html#12172">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hello all,
<br>
<p>I have been thinking a little more about &quot;extrapolated collective volition&quot;
<br>
(<a href="http://www.intelligence.org/friendly/collective-volition.html">http://www.intelligence.org/friendly/collective-volition.html</a> ), and have had
<br>
what seems to me a moderately interesting train of thought in this
<br>
direction.
<br>
<p>[Of course, as I've noted before, I consider all ideas in this direction
<br>
highly science-fictional and not that likely to have practical import for
<br>
the future of the universe.  I suspect that by the time it becomes possible
<br>
to build a Collective Volition Extrapolator machine, the human race will
<br>
have already either ceded power over the universe to its constructed
<br>
descendants, or will have realized that it never had this power in the first
<br>
place...]
<br>
<p>This email assumes the reader has familiarity with the above-referenced
<br>
document written by Eliezer Yudkowsky.
<br>
<p>First I will discuss some properties of collective volition extrapolation,
<br>
and then I will propose a modification to the collective volition
<br>
extrapolation methodology.
<br>
<p>Now for the &quot;discussion of properties&quot; part....
<br>
<p>Suppose it is true that there are N attractors that superhumanly intelligent
<br>
minds will tend to fall into: A_1, ..., A_N (where N is much smaller than
<br>
the number of humans).  [Let's call this Hypothesis A]
<br>
<p>Next, suppose that the trajectory of each individual human under conditions
<br>
of &quot;increasing knowledge and self-knowledge&quot; depends fairly sensitively on
<br>
the environment of that human -- so that, depending on the environment, each
<br>
human mind may wind up in more than one of the N attractors.  [Let's call
<br>
this Hypothesis B]
<br>
<p>Now, in this case, for the outcome of the &quot;collective volition
<br>
extrapolation&quot; process, do you want to choose the attractor (out of the N)
<br>
that would occur for the most humans in an average over all environments
<br>
considered plausible?
<br>
<p>I don't feel comfortable at all that this is a good way to determine the
<br>
initial state for the next phase of development of the universe.
<br>
<p>Of course, I don't know that Hypotheses A and B are true.  But you don't
<br>
know that they're false either.
<br>
<p>Suppose the volition extrapolator determines that they ARE true.  Then, as
<br>
Last Judge, would you decide to call off the Collective Volition approach to
<br>
guiding the future of the universe?
<br>
<p>Or would you prefer to, exerting some Last-Judgely universe-engineering
<br>
power, decide to build a machine that could partition the universe into N
<br>
partitions P_1,..., P_N , with P_i getting an amount of resources
<br>
proportional to the probability that a random mind in a random environment
<br>
(drawn from appropriate distributions) winds up in A_i.
<br>
<p>The problem with this Last-Judgely intervention, of course, is that it may
<br>
not be what ANY of the final attractors A_i want.  Or it may be what *your*
<br>
final attractor A_i wants, but not what any of the others want (and yours
<br>
may have a 3.2% probability weight...).
<br>
<p>My overall conclusion, at this point, is that
<br>
<p>1)
<br>
Yes, it would be really valuable and really cool to build and run a
<br>
collective-volition extrapolator, along with an individual-volition
<br>
extrapolator, of course
<br>
<p>2)
<br>
However, I am not going to just accept the results of such an extrapolator
<br>
as good, and nor am I going to accept it as &quot;good if subjected to the final
<br>
yea-or-nay-power of a Last Judge.&quot;  I'm afraid things are subtler than
<br>
yea-or-nay...
<br>
<p>This leads me to the second part of the e-mail, in which I outline a
<br>
somewhat amusing modification to the collective volition extrapolation
<br>
approach.
<br>
<p>Consider this series:
<br>
<p>S_0 = human race
<br>
<p>S_1 = human race, after collectively studying the results of the First
<br>
Collective Volition Extrapolator (which extrapolates the volition of S_0)
<br>
<p>S_2 =  human race, after collectively studying the results of the Second
<br>
Collective Volition Extrapolator (which extrapolates the volition of S_1)
<br>
<p>... etc. ...
<br>
<p>Note how this differs from simple Collective Volition extrapolation?
<br>
Partly, it's because the probability distribution over future environments
<br>
is being constrained: we're looking only at futures in which the human race
<br>
builds a series of volition extrapolators and studies their results.  This
<br>
may be a small percentage of all possible futures.
<br>
<p>Of course, if the First Collective Volition Extrapolator is *correct*, then
<br>
the results of all the later Volition Extrapolators should simply agree with
<br>
it.  But most likely this CEV_1 machine will involve a lot of
<br>
approximations, so that the series will not be completely repetitive....
<br>
<p>One can then hypothesize that, once CEV_n and CEV_(n+1) substantially agree
<br>
for a few iterations, one has a somewhat trustable approximation of CEV [the
<br>
Humean problem of induction aside.. ;-) ]
<br>
<p>What I like about this kind of approach (let's call it &quot;Iterated Collective
<br>
Volition Extrapolation&quot;) is that it involves the current human race
<br>
explicitly in the decision of its own fate, rather than placing the power in
<br>
the hands of some computational process that's suppose to extrapolate the
<br>
volition of the human race.
<br>
<p>I think that making accurate volition extrapolators is far more difficult
<br>
than making superhuman AI's, so I really doubt that this kind of speculation
<br>
is going to have any relevance to the future of the human race in the
<br>
pre-superhuman-AI period.  On the other hand, it may be that superhuman AI's
<br>
will decide this is an interesting way to determine THEIR future.
<br>
<p>This gives rise to the somewhat obvious idea of creating a superhuman,
<br>
sentient AI whose short-term goal is to make itself smart enough to build a
<br>
Collective Volition Extrapolator, and then apply it, starting off the series
<br>
above, but with a variation...
<br>
<p>T_0 = human race plus AI's
<br>
<p>T_1 = human race plus AI's, after collectively studying the results of the
<br>
First Collective Volition Extrapolator (which extrapolates the volition of
<br>
S_0)
<br>
<p>T_2 =  human race plus AI's, after collectively studying the results of the
<br>
Second Collective Volition Extrapolator (which extrapolates the volition of
<br>
S_1)
<br>
<p>... etc. ...
<br>
<p>Of course, there are the familiar dangers involved in creating a superhuman
<br>
AI oriented toward a particular goal --- how do we know that once it gets
<br>
smarter than us, it won't feel like doing something besides building a
<br>
Collective Volition Extrapolator?  However, at least building a CEV is a
<br>
concrete and easy-to-specify goal, with a brief time-horizon associated to
<br>
it.
<br>
<p>A final caveat: In case I haven't already made it clear, let me re-emphasize
<br>
that I do NOT consider the ideas in this email to be any kind of solution to
<br>
the problem of FAI, nor to be particularly important for the future of the
<br>
universe.  I present them here primarly for intellectual stimulation and
<br>
amusement.
<br>
<p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12173.html">Ben Goertzel: "META: sorry for the mis-posting"</a>
<li><strong>Previous message:</strong> <a href="12171.html">Ben Goertzel: "hmmmm"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12178.html">Ben Goertzel: "RE: Iterated Collective Volition Extrapolation"</a>
<li><strong>Reply:</strong> <a href="12178.html">Ben Goertzel: "RE: Iterated Collective Volition Extrapolation"</a>
<li><strong>Reply:</strong> <a href="../0509/12206.html">Olie Lamb: "General shock level qualitative differences (Re: SL5 TOE)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12172">[ date ]</a>
<a href="index.html#12172">[ thread ]</a>
<a href="subject.html#12172">[ subject ]</a>
<a href="author.html#12172">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
