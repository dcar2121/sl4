<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: On Our Duty to Not Be Responsible for Artificial Minds</title>
<meta name="Author" content="Mark Walker (mdwalker@quickclic.net)">
<meta name="Subject" content="Re: On Our Duty to Not Be Responsible for Artificial Minds">
<meta name="Date" content="2005-08-10">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: On Our Duty to Not Be Responsible for Artificial Minds</h1>
<!-- received="Wed Aug 10 08:28:02 2005" -->
<!-- isoreceived="20050810142802" -->
<!-- sent="Wed, 10 Aug 2005 10:28:05 -0400" -->
<!-- isosent="20050810142805" -->
<!-- name="Mark Walker" -->
<!-- email="mdwalker@quickclic.net" -->
<!-- subject="Re: On Our Duty to Not Be Responsible for Artificial Minds" -->
<!-- id="010f01c59db7$b9153d00$9a00a8c0@markcomputer" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="42F96043.5090108@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Mark Walker (<a href="mailto:mdwalker@quickclic.net?Subject=Re:%20On%20Our%20Duty%20to%20Not%20Be%20Responsible%20for%20Artificial%20Minds"><em>mdwalker@quickclic.net</em></a>)<br>
<strong>Date:</strong> Wed Aug 10 2005 - 08:28:05 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11873.html">Marcello Mathias Herreshoff: "Re: &quot;Objective&quot; Morality"</a>
<li><strong>Previous message:</strong> <a href="11871.html">Marc Geddes: "Re: &quot;Objective&quot; Morality"</a>
<li><strong>In reply to:</strong> <a href="11870.html">Eliezer S. Yudkowsky: "Re: On Our Duty to Not Be Responsible for Artificial Minds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11880.html">Ben Goertzel: "RE: On Our Duty to Not Be Responsible for Artificial Minds"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11872">[ date ]</a>
<a href="index.html#11872">[ thread ]</a>
<a href="subject.html#11872">[ subject ]</a>
<a href="author.html#11872">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
----- Original Message ----- 
<br>
From: &quot;Eliezer S. Yudkowsky&quot;
<br>
<em>&gt;
</em><br>
<em>&gt; Providing the parents didn't abuse the child so greatly as to prevent 
</em><br>
<em>&gt; his/her &quot;normal&quot; human growth.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I presently see two incompatible views of this point, with only a slight 
</em><br>
<em>&gt; overlap:
</em><br>
<em>&gt;
</em><br>
<em>&gt; 1)  If you create an AI that is as good as an average human and provide a 
</em><br>
<em>&gt; decent upbringing, you're off the hook after it grows up.  If you tilt the 
</em><br>
<em>&gt; cognitive scales so hugely in favor of kindness and love that the outcome 
</em><br>
<em>&gt; is deterministic, then you have deprived the offspring of moral autonomy 
</em><br>
<em>&gt; (a sin) and you are never off the hook.
</em><br>
<em>&gt;
</em><br>
<em>&gt; 2)  Creating an average human, if you have the opportunity to do better, 
</em><br>
<em>&gt; constitutes child abuse (a sin).  You are obligated to do better than 
</em><br>
<em>&gt; average - how much better not being specified.
</em><br>
<p>I agree. Critics often use the autonomy argument against transhumanist 
<br>
aspirations, that is, any attempt to alter humans is to violate their 
<br>
autonomy. My &quot;inverted autonomy argument&quot; 
<br>
(<a href="http://www.permanentend.org/PrincipleOfPotentialPlentitude.html">http://www.permanentend.org/PrincipleOfPotentialPlentitude.html</a>) agrees 
<br>
with your conclusion: to the extent that we don't try to do better then we 
<br>
violate the autonomy of our children.
<br>
<p><em>&gt;
</em><br>
<em>&gt; &gt; or is there something fundamentally different about
</em><br>
<em>&gt; &gt; creating an AI?
</em><br>
<em>&gt;
</em><br>
<em>&gt; *Yes*, there is something fundamentally different about creating an AI! 
</em><br>
<em>&gt; There is something *hugely* different about creating an AI!  The decisions 
</em><br>
<em>&gt; and moral responsibilities are those of creating a new sentient species, 
</em><br>
<em>&gt; not those of raising a child.
</em><br>
<em>&gt;
</em><br>
<em>&gt; One who seeks to create a child of humankind is a higher-order parent, 
</em><br>
<em>&gt; faced with a vastly greater space of options than a human mother caring 
</em><br>
<em>&gt; for the product of her inscrutable womb.  A higher-order parent must 
</em><br>
<em>&gt; possess far more knowledge and far deeper understanding than a 
</em><br>
<em>&gt; conventional human parent just to be in the game.  Consequently I hold a 
</em><br>
<em>&gt; higher-order parent to far higher standards; higher-order parents have far 
</em><br>
<em>&gt; greater power and, I judge, far stricter responsibility.  That is why, 
</em><br>
<em>&gt; contrary to my earlier aspirations, I no longer seek to create a child of 
</em><br>
<em>&gt; humankind - not this century, not if I can avoid it.
</em><br>
<em>&gt;
</em><br>
I agree. I think Nick's principles should say or emphasize that creating new 
<br>
and potentially powerful minds incurs new or higher sorts of 
<br>
responsibilities.
<br>
<p>Mark
<br>
<p>Dr. Mark Walker
<br>
Department of Philosophy
<br>
University Hall 310
<br>
McMaster University
<br>
1280 Main Street West
<br>
Hamilton, Ontario, L8S 4K1
<br>
Canada
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11873.html">Marcello Mathias Herreshoff: "Re: &quot;Objective&quot; Morality"</a>
<li><strong>Previous message:</strong> <a href="11871.html">Marc Geddes: "Re: &quot;Objective&quot; Morality"</a>
<li><strong>In reply to:</strong> <a href="11870.html">Eliezer S. Yudkowsky: "Re: On Our Duty to Not Be Responsible for Artificial Minds"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11880.html">Ben Goertzel: "RE: On Our Duty to Not Be Responsible for Artificial Minds"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11872">[ date ]</a>
<a href="index.html#11872">[ thread ]</a>
<a href="subject.html#11872">[ subject ]</a>
<a href="author.html#11872">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:51 MDT
</em></small></p>
</body>
</html>
