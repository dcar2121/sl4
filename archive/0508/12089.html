<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Terms of debate for Complex Systems Issues</title>
<meta name="Author" content="Phil Goetz (philgoetz@yahoo.com)">
<meta name="Subject" content="Re: Terms of debate for Complex Systems Issues">
<meta name="Date" content="2005-08-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Terms of debate for Complex Systems Issues</h1>
<!-- received="Tue Aug 23 22:05:30 2005" -->
<!-- isoreceived="20050824040530" -->
<!-- sent="Tue, 23 Aug 2005 21:05:26 -0700 (PDT)" -->
<!-- isosent="20050824040526" -->
<!-- name="Phil Goetz" -->
<!-- email="philgoetz@yahoo.com" -->
<!-- subject="Re: Terms of debate for Complex Systems Issues" -->
<!-- id="20050824040527.50633.qmail@web54501.mail.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="430BAA19.50308@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Phil Goetz (<a href="mailto:philgoetz@yahoo.com?Subject=Re:%20Terms%20of%20debate%20for%20Complex%20Systems%20Issues"><em>philgoetz@yahoo.com</em></a>)<br>
<strong>Date:</strong> Tue Aug 23 2005 - 22:05:26 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12090.html">Richard Loosemore: "Re: Terms of debate for Complex Systems Issues"</a>
<li><strong>Previous message:</strong> <a href="12088.html">Eliezer S. Yudkowsky: "Re: AI-Box Experiment 3: Carl Shulman, Eliezer Yudkowsky"</a>
<li><strong>In reply to:</strong> <a href="12087.html">Eliezer S. Yudkowsky: "Re: Terms of debate for Complex Systems Issues"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12090.html">Richard Loosemore: "Re: Terms of debate for Complex Systems Issues"</a>
<li><strong>Reply:</strong> <a href="12090.html">Richard Loosemore: "Re: Terms of debate for Complex Systems Issues"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12089">[ date ]</a>
<a href="index.html#12089">[ thread ]</a>
<a href="subject.html#12089">[ subject ]</a>
<a href="author.html#12089">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
--- &quot;Eliezer S. Yudkowsky&quot; &lt;<a href="mailto:sentience@pobox.com?Subject=Re:%20Terms%20of%20debate%20for%20Complex%20Systems%20Issues">sentience@pobox.com</a>&gt; wrote:
<br>
<p><em>&gt; Phil Goetz wrote:
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; CST might say things such as
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; - a plot of the number of goals of the system vs. the importance of
</em><br>
<em>&gt; &gt; those goals would show a power-law distribution
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; - there is some critical number of average possible action
</em><br>
<em>&gt; transitions
</em><br>
<em>&gt; &gt; above which the behavior of the system leads to an expansion rather
</em><br>
<em>&gt; &gt; than a contraction in state space
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; - there is a ratio of exploration of new hypotheses over
</em><br>
<em>&gt; exploitation
</em><br>
<em>&gt; &gt; of confirmed hypotheses, and there are two values for this ratio
</em><br>
<em>&gt; that
</em><br>
<em>&gt; &gt; locate phase shifts between &quot;static&quot;, &quot;dynamic&quot;, and
</em><br>
<em>&gt; &gt; &quot;unstable/devolving&quot; modes of operation
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Phil, I think those are the first three interesting (falsifiable)
</em><br>
<em>&gt; things I've 
</em><br>
<em>&gt; ever heard anyone say about CST and intelligence.  Did you make them
</em><br>
<em>&gt; up on the 
</em><br>
<em>&gt; spot, or would you seriously advocate/support any of them?  Are there
</em><br>
<em>&gt; relevant 
</em><br>
<em>&gt; papers/experiments?
</em><br>
<p>I just made them up.
<br>
<p>- Plotting number of goals per importance level:  There are
<br>
numerous examples in the CST literature about systems that
<br>
have events of different sizes.  Classic examples include
<br>
earthquakes, sandpile avalanches, percolation lattices,
<br>
and cellular automata (e.g., length of time that an initial
<br>
configuration in Conway's game of Life takes to converge).
<br>
For certain systems - which appear to be the systems with
<br>
the most computational power in information-theoretic terms
<br>
- the number of events of size s is described by the equation
<br>
P(size = s) = k / (s^c).
<br>
<p>These systems may have three modes of operation: mode 1
<br>
(&quot;solid&quot;), in which P(size = s) has something like a Poisson
<br>
distribution; mode 2 (&quot;liquid&quot;), in which P(size=s) = k/(s^c),
<br>
and mode 3 (&quot;gaseous&quot;), in which all events have infinite size
<br>
(never stop, or have no gaps in continuity, like an infinite
<br>
percolation lattice that is fully-connected).  In many cases,
<br>
specific numbers can be found that delineate the transition
<br>
between these nodes.  For infinite 2-dimensional percolation
<br>
lattices where each point has 8 neighbors, for instance,
<br>
the first infinite-size connected group occurs when the
<br>
lattice density (probability of a site being occupied) is
<br>
approximately .59275.
<br>
<p>I did some analysis which suggests that there is a single
<br>
distribution underlying all three phases, which is dominated
<br>
by a power-law term within the &quot;liquid&quot; region.
<br>
<p>I have no good reason to think that the importance of goals
<br>
would have such a distribution.  I would expect that the number
<br>
of inferences made to plan for a goal, including dead-end inferences,
<br>
could have such a distribution, depending on how many possible
<br>
inferences can be made from each new fact.  The average number of
<br>
possible inferences to make from a just-derived fact plays
<br>
the same role as the average number of neighbors that an occupied
<br>
point in a percolation lattice, or the probability of turning
<br>
a randomly-chosen cell on in the next iteration of a Life game.
<br>
<p>- there is some critical number of average possible action
<br>
transitions: That wasn't stated well.  I was thinking of
<br>
behavior networks, like Pattie Maes' Do the Right Thing
<br>
network, in which each behavior enables some other behaviors,
<br>
and of probabilistic finite-state automata.  But the notion
<br>
of an organism's state space isn't well-defined enough for
<br>
real organisms for the statement to make sense.  For simple
<br>
simulated organisms, the state space is finite, so again it
<br>
doesn't make sense.
<br>
<p>A better use of the ideas going into it (stuff from
<br>
Stu Kauffman's 1993 book The Origins of Order on networks
<br>
constructed from random Boolean transition tables)
<br>
might be to say:
<br>
<p>Suppose a reactive organism observes v variables
<br>
at each timestep, and is trying to learn which n of these
<br>
v variables it should pay attention to in order to choose
<br>
its next action.  Let H be the average information content,
<br>
in bits, of a proposed set of n variables (the entropy of
<br>
the distribution of possible next actions based on them).
<br>
There is some value c such that, for H &lt;&lt; c,
<br>
the organism always takes (uninteresting) short action
<br>
sequences; for H &gt;&gt; c, the set of outcomes to explore
<br>
will be too large for learning to take place.  The number
<br>
of variables n to consider should be chosen so as to set H = c.
<br>
<p>One might do this by using PCA on your original v variables,
<br>
and pulling off the highest-ranked principal components
<br>
as your operational variables until their entropy sums to c.
<br>
This brings us back to the utility of signal processing.
<br>
And information theory.  :)
<br>
<p>- ratio of exploration of new hypotheses over exploitation
<br>
of confirmed hypotheses:  The language comes from Holland's
<br>
genetic algorithm theory, which shows that the genetic
<br>
algorithm (without mutation) leads to an optimal
<br>
balance between exploration and exploitation (provided
<br>
the evaluation function provides scores for an organism
<br>
with a normal distribution around its average value).
<br>
The idea comes from simulations of evolution, or from
<br>
any other optimization method, in which, if you keep
<br>
mutation (or, say, the temperature in simulated annealing)
<br>
too low, you get too-slow convergence on a good solution,
<br>
but if you crank it up too high, you get poor solutions.
<br>
<p>- Phil Goetz
<br>
<p>__________________________________________________
<br>
Do You Yahoo!?
<br>
Tired of spam?  Yahoo! Mail has the best spam protection around 
<br>
<a href="http://mail.yahoo.com">http://mail.yahoo.com</a> 
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12090.html">Richard Loosemore: "Re: Terms of debate for Complex Systems Issues"</a>
<li><strong>Previous message:</strong> <a href="12088.html">Eliezer S. Yudkowsky: "Re: AI-Box Experiment 3: Carl Shulman, Eliezer Yudkowsky"</a>
<li><strong>In reply to:</strong> <a href="12087.html">Eliezer S. Yudkowsky: "Re: Terms of debate for Complex Systems Issues"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12090.html">Richard Loosemore: "Re: Terms of debate for Complex Systems Issues"</a>
<li><strong>Reply:</strong> <a href="12090.html">Richard Loosemore: "Re: Terms of debate for Complex Systems Issues"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12089">[ date ]</a>
<a href="index.html#12089">[ thread ]</a>
<a href="subject.html#12089">[ subject ]</a>
<a href="author.html#12089">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:52 MDT
</em></small></p>
</body>
</html>
