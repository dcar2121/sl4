<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: The hazards of writing fiction about post-humans</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: The hazards of writing fiction about post-humans">
<meta name="Date" content="2005-05-03">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: The hazards of writing fiction about post-humans</h1>
<!-- received="Tue May  3 10:29:43 2005" -->
<!-- isoreceived="20050503162943" -->
<!-- sent="Tue, 03 May 2005 09:29:38 -0700" -->
<!-- isosent="20050503162938" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: The hazards of writing fiction about post-humans" -->
<!-- id="4277A6F2.1000704@pobox.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="6.2.1.2.0.20050502225017.01dd7990@pop-server.satx.rr.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20The%20hazards%20of%20writing%20fiction%20about%20post-humans"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Tue May 03 2005 - 10:29:38 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11043.html">Ben Goertzel: "RE: The hazards of writing fiction about post-humans"</a>
<li><strong>Previous message:</strong> <a href="11041.html">fudley: "Re: Beating the rush."</a>
<li><strong>In reply to:</strong> <a href="11032.html">Damien Broderick: "The hazards of writing fiction about post-humans"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11043.html">Ben Goertzel: "RE: The hazards of writing fiction about post-humans"</a>
<li><strong>Reply:</strong> <a href="11043.html">Ben Goertzel: "RE: The hazards of writing fiction about post-humans"</a>
<li><strong>Reply:</strong> <a href="11051.html">Damien Broderick: "Re: The hazards of writing fiction about post-humans"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11042">[ date ]</a>
<a href="index.html#11042">[ thread ]</a>
<a href="subject.html#11042">[ subject ]</a>
<a href="author.html#11042">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Damien Broderick wrote:
<br>
<em>&gt; <a href="http://www.scifi.com/sfw/issue419/books.html">http://www.scifi.com/sfw/issue419/books.html</a>
</em><br>
<em>&gt; 
</em><br>
<em>&gt; is an interesting review of my new sf novel GODPLAYERS. The reviewer is 
</em><br>
<em>&gt; especially exercised by the fact that my posthuman characters are not 
</em><br>
<em>&gt; immediately understandable -- indeed, beyond empathy -- by human standards:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &lt;the frustration level mounts as one waits in vain... for characters... 
</em><br>
<em>&gt; to display any hint of a genuine inner life as they move randomly from 
</em><br>
<em>&gt; scene to scene, world to world, reality to reality. Perhaps Vorpal 
</em><br>
<em>&gt; homunculi do not possess inner lives, and Broderick's point is that 
</em><br>
<em>&gt; these seeming superhumans, for all their power, are soulless automatons 
</em><br>
<em>&gt; without a shred of humanity.... Surely there should be some character, 
</em><br>
<em>&gt; somewhere in a novel, to which human readers can feel connected. ...As 
</em><br>
<em>&gt; the sequence of events grows increasingly frenzied, with ever-greater 
</em><br>
<em>&gt; reliance placed on what might be termed info-splatters, the lack of a 
</em><br>
<em>&gt; deep humanistic substrate left this reader, at least, with no ground to 
</em><br>
<em>&gt; stand on. &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I'm torn in my response to this. On the one hand, it wouldn't make much 
</em><br>
<em>&gt; sense to write about posthumans as if they were representations of the 
</em><br>
<em>&gt; people down the road, or in the next room. On the other, I have tried to 
</em><br>
<em>&gt; ground the fairly breakneck narrative within thematic structures and 
</em><br>
<em>&gt; reverberations recognizable from myth, dream, and the traditions of 
</em><br>
<em>&gt; science-fiction itself when it ventures upon the superhuman. Greg Egan 
</em><br>
<em>&gt; met with this same objection, of course, and so, in various degrees, did 
</em><br>
<em>&gt; John C. Wright and Charlie Stross. Maybe it's an artistic problem beyond 
</em><br>
<em>&gt; solution -- for humans.
</em><br>
<p>I agree with this objection to Greg Egan's, Charlie Stross's, even some of 
<br>
Vernor Vinge's stuff, and yes, your own recent work.  (John C. Wright did okay 
<br>
in his first two books, haven't finished the third.)  Despite all Vingean 
<br>
rules there is no good reason why transhumans, especially in a work of 
<br>
fiction, should not have strong emotions the reader can empathize with.  If 
<br>
you need to explain why, tell your readers that Eliezer designed 'em or that 
<br>
they're outgrowths of humans.
<br>
<p>Rationality is not about emotionlessness, and neither is intelligence, whether 
<br>
&quot;intelligence&quot; is interpreted as g-factor or as the combination of g-factor 
<br>
and rationality that actually makes people powerful and effective. 
<br>
Rationality is the art of attaining a map that reflects the territory, of 
<br>
arriving to the correct answer on questions of simple fact.
<br>
<p>One comes to me and claims: the Way opposes this emotion, this goal, this 
<br>
morality.  I should reply:  Where is the false belief that I must hold, to 
<br>
feel this emotion, pursue this goal, propound this morality?  It is a subtle 
<br>
question, and the claimant may reply in a fashion I do not expect.  Being the 
<br>
person that I am, it may be that I must possess a false belief in order to 
<br>
feel that emotion, pursue that goal, propound that moral philosophy.  If I 
<br>
should feel fear and horror at the sight of an approaching wire I believe to 
<br>
be electrified, and the wire is not electrified, then I shall relinquish my 
<br>
fear and horror if I pursue the Way.  If I should feel calm at the approach of 
<br>
the wire, believing it not to be electrified, and the wire is electrified, 
<br>
then the Way opposes my calm.  If I believe that the members of the tribe 
<br>
across the water are subhuman, and propound a moral philosophy which advocates 
<br>
their casual killing, I may reconsider upon learning of our shared DNA and 
<br>
shared neural architecture, learning they are not different from me as people. 
<br>
&nbsp;&nbsp;And the experience may lead me to reconsider not only the conclusion, but 
<br>
the premise, wonder if the hatred which leads to such mistakes is a part of 
<br>
myself I wish to keep.  I may come to a different conclusion in that moral 
<br>
introspection, depending on whether I believe the hatred was placed in me by 
<br>
Zeus, or if I know the underlying emotion of hatred was inscribed in me by 
<br>
natural selection.  I wish to feel those emotions, pursue those goals, 
<br>
propound those moralities, which, being myself, I would feel and pursue and 
<br>
propound if I knew the correct answers.
<br>
<p>That's rationality according to a rationalist.  Spock is an idiot designed by 
<br>
Hollywood scriptwriters who knew less than nothing of rationality.  Spock 
<br>
forms the template for most fictional transhumans.  Small wonder that the 
<br>
audience has nothing to empathize with, if the writer thinks that rationality 
<br>
requires the rejection of empathizable emotion.
<br>
<p>The Singularity is not an ironic commentary on the rate of change.  Many 
<br>
people in the futurist crowd - especially those who think that futurism is all 
<br>
about being ever so avant-garde and hip and ironically detached - seem to have 
<br>
picked up on the Singularity this way.  I am speaking specifically here of 
<br>
Cory Doctorow and Charlie Stross.  So they write hip, avant-garde, and 
<br>
ironically detached Singularity fiction, where the Singularity is interpreted 
<br>
as an excuse to toss in various bits of technobabble, throw the main character 
<br>
out of a job, and show a background social fabric in the process of 
<br>
disintegration under too-rapid change.   Ooh, avant-garde!  Post-modern! 
<br>
Artistic!  Emotionally uninteresting!  And they treat the Singularity the same 
<br>
way in real life - a concept that makes them feel more detached, not more 
<br>
involved.  Compare to _Staring into the Singularity_.  Artistic?  No. 
<br>
Avant-garde?  No.  Hip?  No.  Ironically detached?  No.  Well-written?  No. 
<br>
Passionate?  Yes.  _SitS_ is not intended as a work of fiction, but frankly, 
<br>
it has a more interesting central plotline than most that which is billed as 
<br>
Singularity fiction.
<br>
<p>When you wrote about _SitS_ in _The Spike_, you wrote, &quot;Well, of course, one 
<br>
smiles, recalling the exaggerated postures of adolescence.&quot;  Being rather fond 
<br>
of that youthful Eliezer, you attached no particular utility to hurting his 
<br>
feelings; yet you found it necessary to insert *something* that would make 
<br>
clear your emotional detachment.  Why?  Because you had to avoid, and 
<br>
automatically avoided, a scenario in which your readers might think you cared 
<br>
about something - which would be a terribly unhip flaw in a self-consciously 
<br>
hip book about the future.  In nonfiction you can plead the requirement of 
<br>
believability, of making the reader go on treating your nonfiction as 
<br>
nonfiction.  But if you apply the same reasoning to your fiction, and your 
<br>
readers then complain that your fiction lacks passion, well, jeebers man, what 
<br>
else did you expect?  How do you expect to make your readers feel passion if 
<br>
you yourself regard passion as terribly unhip?  Characters in fiction are 
<br>
supposed to feel, feel intensely, to scream in the night when the plot calls 
<br>
for it, and if you flinch back from that you have no story.  The &quot;thematic 
<br>
structures and reverberations recognizable from myth, dream, and the 
<br>
traditions of science-fiction itself when it ventures upon the superhuman&quot; 
<br>
cannot repair this flaw.  No amount of thematic dressing and mythological 
<br>
allusion can repair a plot that lacks drama or characters that lack emotion. 
<br>
First you have to feel passion, and then you have to put it into your writing; 
<br>
and if you have forgotten how to do this, or even just forgotten to do it in 
<br>
this particular case, then all craftsmanship is for nought - just as passion 
<br>
is futile without writing craftsmanship.
<br>
<p>It does require a certain amount of creativity to write transhumans who end up 
<br>
in enough trouble that they have something to feel about.  You have to invent 
<br>
new plots and break loose of the conventions of the transhuman genre, since 
<br>
these conventions are wrong and destructive of story.  The first and most 
<br>
fundamental error is to think of your fictional transhumans as gods beyond all 
<br>
troubles.  The second fundamental error is to think that if you don't festoon 
<br>
your characters with emotional incomprehensibility then the readers will not 
<br>
know they are transhumans.  These are the conventions of the Singularity genre 
<br>
that were laid down by self-consciously hip authors; they are conventions 
<br>
which are destructive of story.  So do better.  Place human characters in a 
<br>
world where transhumans exist in some fashion that does *not* make the 
<br>
transhumans cold and remote, nor hiply detached and postmodern, nor festooned 
<br>
with decorative incomprehensibility.  Or let your characters be transhumans 
<br>
themselves, if you dare, and give them something to care passionately about. 
<br>
John C. Wright managed this, and I therefore do not accept that it is impossible.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11043.html">Ben Goertzel: "RE: The hazards of writing fiction about post-humans"</a>
<li><strong>Previous message:</strong> <a href="11041.html">fudley: "Re: Beating the rush."</a>
<li><strong>In reply to:</strong> <a href="11032.html">Damien Broderick: "The hazards of writing fiction about post-humans"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11043.html">Ben Goertzel: "RE: The hazards of writing fiction about post-humans"</a>
<li><strong>Reply:</strong> <a href="11043.html">Ben Goertzel: "RE: The hazards of writing fiction about post-humans"</a>
<li><strong>Reply:</strong> <a href="11051.html">Damien Broderick: "Re: The hazards of writing fiction about post-humans"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11042">[ date ]</a>
<a href="index.html#11042">[ thread ]</a>
<a href="subject.html#11042">[ subject ]</a>
<a href="author.html#11042">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:22:56 MST
</em></small></p>
</body>
</html>
