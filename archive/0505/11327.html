<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Robot that thinks like a human</title>
<meta name="Author" content="Russell Wallace (russell.wallace@gmail.com)">
<meta name="Subject" content="Re: Robot that thinks like a human">
<meta name="Date" content="2005-05-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Robot that thinks like a human</h1>
<!-- received="Fri May 20 04:39:31 2005" -->
<!-- isoreceived="20050520103931" -->
<!-- sent="Fri, 20 May 2005 11:39:25 +0100" -->
<!-- isosent="20050520103925" -->
<!-- name="Russell Wallace" -->
<!-- email="russell.wallace@gmail.com" -->
<!-- subject="Re: Robot that thinks like a human" -->
<!-- id="8d71341e050520033920defc62@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20050520010136.13866.qmail@web26705.mail.ukl.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Russell Wallace (<a href="mailto:russell.wallace@gmail.com?Subject=Re:%20Robot%20that%20thinks%20like%20a%20human"><em>russell.wallace@gmail.com</em></a>)<br>
<strong>Date:</strong> Fri May 20 2005 - 04:39:25 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11328.html">Dani Eder: "Re: Systems engineering"</a>
<li><strong>Previous message:</strong> <a href="11326.html">J. Andrew Rogers: "Re: Proposed Universal data types"</a>
<li><strong>In reply to:</strong> <a href="11323.html">Michael Wilson: "Re: Robot that thinks like a human"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11327">[ date ]</a>
<a href="index.html#11327">[ thread ]</a>
<a href="subject.html#11327">[ subject ]</a>
<a href="author.html#11327">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 5/20/05, Michael Wilson &lt;<a href="mailto:mwdestinystar@yahoo.co.uk?Subject=Re:%20Robot%20that%20thinks%20like%20a%20human">mwdestinystar@yahoo.co.uk</a>&gt; wrote:
<br>
<em>&gt; I've had someone seriously propose to me that we use limited AI to
</em><br>
<em>&gt; rapidly develop nanotech, which would then be used to take over the world
</em><br>
<em>&gt; and shut down all other AI/nanotech/biotech projects to prevent anything
</em><br>
<em>&gt; bad from happening (things got rather hazy after that). I don't worry
</em><br>
<em>&gt; about it because 'highly restricted human-level AGI' is very, very hard
</em><br>
<em>&gt; and ultimately pointless (if you know how to make a 'human-level AGI'
</em><br>
<em>&gt; controllable, then you know how to make a transhuman AGI controllable).
</em><br>
<em>&gt; People less convinced about hard takeoff will doubtless be more concerned
</em><br>
<em>&gt; about this sort of thing.
</em><br>
<p>Heh. Yeah, I haven't seen many actual proposals to do it - but I have
<br>
seen a lot of technical folk who clearly want to believe it can be
<br>
done.
<br>
<p>I'm not convinced about hard takeoff... I also think it's unlikely
<br>
that someone whose thought processes haven't risen above that level
<br>
will be able to create anything beyond smart-weapon or paperclip AI at
<br>
most.
<br>
<p>Still, I think I'll toss in my two cents' worth here, not because I
<br>
believe Ben or the SIAI are in it for power, but because SL4 is a
<br>
public archived list and the above line of thought might look just a
<br>
little too tempting for some:
<br>
<p>1. Wannabe world-conquerors should first read Eliezer's comments on
<br>
the difficulty of creating superintelligent AI that doesn't just turn
<br>
you into grey goo. Then reread them until you understand them.
<br>
<p>2. Taking over the world, even with ultratechnology, would be a far
<br>
harder and more dangerous task than a lot of technical people seem to
<br>
realize. (Please note: this is not a proposal to discuss ideas for it!
<br>
:))
<br>
<p>3. A failed attempt would not only be likely to kill the mad
<br>
scientist, it could very well be the start of a chain of events that
<br>
led to the extinction of life on Earth. (Scenario 1: half a dozen
<br>
nations, having seen the live demo of AI and nanotechnology,
<br>
immediately start Manhattan Projects. Etc. Scenario 2: for fear of
<br>
scenario 1, a world government is set up to suppress development of
<br>
dangerous technology. Etc.)
<br>
<p>So if one wants power, politics is a more rewarding field of activity
<br>
than AI research. It really is.
<br>
<p>- Russell
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11328.html">Dani Eder: "Re: Systems engineering"</a>
<li><strong>Previous message:</strong> <a href="11326.html">J. Andrew Rogers: "Re: Proposed Universal data types"</a>
<li><strong>In reply to:</strong> <a href="11323.html">Michael Wilson: "Re: Robot that thinks like a human"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11327">[ date ]</a>
<a href="index.html#11327">[ thread ]</a>
<a href="subject.html#11327">[ subject ]</a>
<a href="author.html#11327">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:51 MDT
</em></small></p>
</body>
</html>
