<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Robot that thinks like a human</title>
<meta name="Author" content="Michael Wilson (mwdestinystar@yahoo.co.uk)">
<meta name="Subject" content="RE: Robot that thinks like a human">
<meta name="Date" content="2005-05-18">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Robot that thinks like a human</h1>
<!-- received="Wed May 18 15:27:24 2005" -->
<!-- isoreceived="20050518212724" -->
<!-- sent="Wed, 18 May 2005 22:27:21 +0100 (BST)" -->
<!-- isosent="20050518212721" -->
<!-- name="Michael Wilson" -->
<!-- email="mwdestinystar@yahoo.co.uk" -->
<!-- subject="RE: Robot that thinks like a human" -->
<!-- id="20050518212721.84190.qmail@web26709.mail.ukl.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Wilson (<a href="mailto:mwdestinystar@yahoo.co.uk?Subject=RE:%20Robot%20that%20thinks%20like%20a%20human"><em>mwdestinystar@yahoo.co.uk</em></a>)<br>
<strong>Date:</strong> Wed May 18 2005 - 15:27:21 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11117.html">Nick Bostrom: "RE: Robot that thinks like a human"</a>
<li><strong>Previous message:</strong> <a href="11115.html">Eliezer S. Yudkowsky: "Re: Domain Protection"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11117.html">Nick Bostrom: "RE: Robot that thinks like a human"</a>
<li><strong>Reply:</strong> <a href="11117.html">Nick Bostrom: "RE: Robot that thinks like a human"</a>
<li><strong>Reply:</strong> <a href="11122.html">Ben Goertzel: "Re: Robot that thinks like a human"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11116">[ date ]</a>
<a href="index.html#11116">[ thread ]</a>
<a href="subject.html#11116">[ subject ]</a>
<a href="author.html#11116">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; I believe that any project in which cognition is a possible outcome
</em><br>
<em>&gt; should be monitored at the very least
</em><br>
<p>Sure, thanks for volunteering. :)
<br>
<p><em>&gt; and approached should it appear that progress is being made.
</em><br>
<p>Unfortunately the prognosis for this isn't good. Most researchers
<br>
simply don't see the problem and tend to refuse to do so when
<br>
confronted with the possibility. The basic reason for this is that
<br>
takeoff and unfriendliness are counter-intuitive and have
<br>
unpleasant implications, both in terms of risk and the amount of
<br>
work the researcher would have to do. AGI researchers who didn't
<br>
start with a good idea of the necessity and difficulty of
<br>
Friendliness will almost automatically attempt to find reasons why
<br>
they don't have to think about it, and the power of wishful
<br>
thinking and rationalisation usually means that they succeed. Nick
<br>
Bostrom is trying to kick-start a debate that might manage to
<br>
convince (reasonable chunks of) academia otherwise, but don't hold
<br>
your breath.
<br>
<p><em>&gt; Unfortunately I don't know how to tell, from the outside of a
</em><br>
<em>&gt; project, when or if progress is made.
</em><br>
<p>That's the other problem. Apart from the fact that PR is only loosely
<br>
correlated with actual progress (suffering from delay, distortion,
<br>
oversimplification and hyperbole), progress towards takeoff capability
<br>
(and hence existential risk) isn't even necessarily correlated with
<br>
observable progress towards the project goals.
<br>
<p><em>&gt; As Mr. Yudkowsky frequently points out, the time to go from the &quot;We
</em><br>
<em>&gt; have succesfully simulated a human brain in a computing substrate.&quot;
</em><br>
<em>&gt; announcement to &quot;Oh My God, Singularity!!&quot; is possibly vanishingly
</em><br>
<em>&gt; small.
</em><br>
<p>Brain simulation is the least risky method because the brain is so
<br>
opaque. If you were handed the complete wiring diagram for your own
<br>
brain and a nanotech brain surgery device, would you be able to
<br>
reliably rewire yourself to be more intelligent? An infrahuman AGI
<br>
based on evolved NNs is in roughly the same boat, though with the
<br>
advantage of being able to revert to backups, run instances with
<br>
several different candidate enhancements in parallel and possibly a
<br>
faster effective clock frequency than humans. As designs get less
<br>
opaque and search techniques for effective self-modification get
<br>
more efficient the takeoff risk rises dramatically.
<br>
<p><em>&gt; I have done some searching of the SL4 archives and did not
</em><br>
<em>&gt; immediately find a policy suggestion for dealing with non-SIAI
</em><br>
<em>&gt; AGI projects.
</em><br>
<p>The SIAI has tried to influence several projects, and the results have
<br>
been fairly futile. A few researchers have acknowledged that their
<br>
designs won't be automatically Friendly, but in general there is blind
<br>
optimism that their designs have the capacity to be Friendly and that
<br>
getting them to do so will be a simple matter of reinforcement learning
<br>
or similar. There is some minimal appreciation of the existential risks
<br>
involved, but /everyone/ not associated with the SIAI appears to believe
<br>
that it is a problem that can be solved 'later'. The minimal discussion
<br>
of structural Friendliness issues that has occured on SL4 has been
<br>
treated as wholly theoretical and irrelevant to actual AGI architecture.
<br>
Even if we did succeed in convincing a researcher that Friendliness is
<br>
vital, the large personal investment in an existing architecture that
<br>
is almost certainly not Friendliness-compatible would most probably
<br>
render the effort futile. Rather than discard the broken design and
<br>
reengineer from scratch, they'd think up some superficially plausible
<br>
patch, probably based on a half-baked idea of what we actually want, and
<br>
then proceed to destroy the world anyway.
<br>
<p>In short we'll keep trying, but we don't expect success. Getting people
<br>
to stop and consider the problem might buy a little extra time. However
<br>
the only realistic way for humanity to win is for the AGI race to be won
<br>
by a project that explicitly sets out to build an AGI that can be proven
<br>
to be Friendly (to a high degree of confidence, prior to actually
<br>
building it). Right now the SIAI appears to be the only such project in
<br>
existence.
<br>
<p>&nbsp;* Michael Wilson
<br>
<p><p><p><p><p><p><p><p><p><p><p><p>.
<br>
<p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
___________________________________________________________ 
<br>
Yahoo! Messenger - want a free and easy way to contact your friends online? <a href="http://uk.messenger.yahoo.com">http://uk.messenger.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11117.html">Nick Bostrom: "RE: Robot that thinks like a human"</a>
<li><strong>Previous message:</strong> <a href="11115.html">Eliezer S. Yudkowsky: "Re: Domain Protection"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11117.html">Nick Bostrom: "RE: Robot that thinks like a human"</a>
<li><strong>Reply:</strong> <a href="11117.html">Nick Bostrom: "RE: Robot that thinks like a human"</a>
<li><strong>Reply:</strong> <a href="11122.html">Ben Goertzel: "Re: Robot that thinks like a human"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11116">[ date ]</a>
<a href="index.html#11116">[ thread ]</a>
<a href="subject.html#11116">[ subject ]</a>
<a href="author.html#11116">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:22:56 MST
</em></small></p>
</body>
</html>
