<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Beating the rush</title>
<meta name="Author" content="Peter C. McCluskey (pcm@rahul.net)">
<meta name="Subject" content="Re: Beating the rush">
<meta name="Date" content="2005-05-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Beating the rush</h1>
<!-- received="Thu May 26 10:13:13 2005" -->
<!-- isoreceived="20050526161313" -->
<!-- sent="Thu, 26 May 2005 09:13:11 -0700 (PDT)" -->
<!-- isosent="20050526161311" -->
<!-- name="Peter C. McCluskey" -->
<!-- email="pcm@rahul.net" -->
<!-- subject="Re: Beating the rush" -->
<!-- id="20050526161311.02091BE8BE@green.rahul.net" -->
<!-- inreplyto="4293B738.50306@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Peter C. McCluskey (<a href="mailto:pcm@rahul.net?Subject=Re:%20Beating%20the%20rush"><em>pcm@rahul.net</em></a>)<br>
<strong>Date:</strong> Thu May 26 2005 - 10:13:11 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11156.html">Peter de Blanc: "Re: Proposed Universal data types"</a>
<li><strong>Previous message:</strong> <a href="11154.html">Daniel Radetsky: "Re: Proposed Universal data types"</a>
<li><strong>In reply to:</strong> <a href="11144.html">Eliezer S. Yudkowsky: "Re: Beating the rush"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0511/12573.html">Peter C. McCluskey: "Hard takeoff vs slow takeoff"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11155">[ date ]</a>
<a href="index.html#11155">[ thread ]</a>
<a href="subject.html#11155">[ subject ]</a>
<a href="author.html#11155">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&nbsp;<a href="mailto:sentience@pobox.com?Subject=Re:%20Beating%20the%20rush">sentience@pobox.com</a> (&quot;Eliezer S. Yudkowsky&quot;) writes:
<br>
<em>&gt;Have you read <a href="http://intelligence.org/LOGI/seedAI.html">http://intelligence.org/LOGI/seedAI.html</a>?  I ask for purposes of 
</em><br>
<em>&gt;information.
</em><br>
<p>&nbsp;I read it a few months ago after Tyler told me it made an argument for
<br>
a hard takeoff. All I could find was an argument that we would have a
<br>
takeoff of some sort. It didn't look like you were trying to say how
<br>
fast it would happen.
<br>
&nbsp;(I will try to comment on your objection to Baum, but I can't do it this
<br>
week).
<br>
<p><em>&gt;You'd build a temporary goal system marked reflectively as an approximation to 
</em><br>
<em>&gt;CEV (collective extrapolated volition).  You can toss as much safety as you 
</em><br>
<em>&gt;want into the temporary goal system, and the safeties will stay there until 
</em><br>
<em>&gt;the CEV is defined enough to execute a complete rewrite and wash out all the 
</em><br>
<p>&nbsp;This isn't clear enough to tell me whether it would resemble my idea of
<br>
an obedient AI, whether it would (temporarily?) impose some subset of
<br>
your opinions on the world, or something else.
<br>
&nbsp;If this temporary goal system can be trusted to allow you to replace its
<br>
goal system with one based on CEV, then doesn't that imply that you've
<br>
made it benevolent and/or obedient enough that we could rely on it to
<br>
tell us how to do CEV (or some alternative) wisely? And shouldn't we then
<br>
conclude that most of our thought should go into ensuring that the temporary
<br>
RPOP goal system is as safe as it can be, since we should expect the RPOP
<br>
will tell us how to avoid the remaining risks?
<br>
&nbsp;Yet the effort you have put into describing CEV versus the effort you have
<br>
put into describing the temporary RPOP goal system suggests you haven't
<br>
reached this conclusion.
<br>
<p><em>&gt;ornamentation and tinsel.  I don't think humans could build an AI that had no 
</em><br>
<em>&gt;goal system at all until it was already a superintelligence.
</em><br>
<p>&nbsp;I have trouble imagining what a goal-less AI would be like.
<br>
<pre>
--
------------------------------------------------------------------------------
Peter McCluskey         | Everyone complains about the laws of physics, but no
www.bayesianinvestor.com| one does anything about them. - from Schild's Ladder
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11156.html">Peter de Blanc: "Re: Proposed Universal data types"</a>
<li><strong>Previous message:</strong> <a href="11154.html">Daniel Radetsky: "Re: Proposed Universal data types"</a>
<li><strong>In reply to:</strong> <a href="11144.html">Eliezer S. Yudkowsky: "Re: Beating the rush"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0511/12573.html">Peter C. McCluskey: "Hard takeoff vs slow takeoff"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11155">[ date ]</a>
<a href="index.html#11155">[ thread ]</a>
<a href="subject.html#11155">[ subject ]</a>
<a href="author.html#11155">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:22:56 MST
</em></small></p>
</body>
</html>
