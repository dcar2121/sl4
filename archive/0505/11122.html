<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Robot that thinks like a human</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="Re: Robot that thinks like a human">
<meta name="Date" content="2005-05-18">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Robot that thinks like a human</h1>
<!-- received="Thu May 19 03:31:06 2005" -->
<!-- isoreceived="20050519093106" -->
<!-- sent="Wed, 18 May 2005 22:40:28 -0400" -->
<!-- isosent="20050519024028" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="Re: Robot that thinks like a human" -->
<!-- id="012001c55c55$760bd670$0f010a0a@CUTIOIDE" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="20050518212721.84190.qmail@web26709.mail.ukl.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=Re:%20Robot%20that%20thinks%20like%20a%20human"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Wed May 18 2005 - 20:40:28 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11123.html">Michael Wilson: "Re: Robot that thinks like a human"</a>
<li><strong>Previous message:</strong> <a href="11121.html">Marc Geddes: "Proposed Universal data types"</a>
<li><strong>In reply to:</strong> <a href="11116.html">Michael Wilson: "RE: Robot that thinks like a human"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11122">[ date ]</a>
<a href="index.html#11122">[ thread ]</a>
<a href="subject.html#11122">[ subject ]</a>
<a href="author.html#11122">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; the only realistic way for humanity to win is for the AGI race to be won
</em><br>
<em>&gt; by a project that explicitly sets out to build an AGI that can be proven
</em><br>
<em>&gt; to be Friendly (to a high degree of confidence, prior to actually
</em><br>
<em>&gt; building it). Right now the SIAI appears to be the only such project in
</em><br>
<em>&gt; existence.
</em><br>
<em>&gt;
</em><br>
<em>&gt; * Michael Wilson
</em><br>
<p>Michael,
<br>
<p>I've had this argument with you and Eli on this list many times, so I'm not 
<br>
going to pursue it at length once more... but I'll mention the point briefly 
<br>
just for list newbies...
<br>
<p>I have a great deal of doubt that it's possible for anyone to achieve a good 
<br>
understanding of AGI Friendliness prior to building and experimenting with 
<br>
some AGI's (considerably more general and powerful than any of the narrow-AI 
<br>
programs or crude AGI prototypes that exist today).
<br>
<p>So far none of the ideas published online by the SIAI staff have done 
<br>
anything to assuage this doubt.  Plenty of interesting speculative ideas, 
<br>
but nothing even vaguely approaching a framework that could be used to 
<br>
construct a proof of Friendliness of an AGI design.
<br>
<p>Sure, you can argue that it's better to spend 10-20 years trying to 
<br>
construct theoretical foundations of Friendly AGI in the absence of any AGI 
<br>
systems to play with --- just in the off chance that such theorization does 
<br>
turn out to be productive.  But the risk then is that in the interim someone 
<br>
else who's less conservative is going to build a nasty AI to ensure their 
<br>
own world domination.
<br>
<p>IMO a more productive direction is think about how to design an AGI that 
<br>
will teach us a lot about AGI and Friendly AGI, but won't have much 
<br>
potential of hard takeoff.  I think this is much more promising than trying 
<br>
to make a powerful  theory of Friendly AI based on a purely theoretical 
<br>
rathern than empirical approach.
<br>
<p>The Novamente project seeks to build a benevolent, superhuman AGI (I'm not 
<br>
using the word Friendly because in fact I'm not entirely sure what Eli means 
<br>
by that defined term these days).  We are committed not to create an AGI 
<br>
that appears likely capable of hard takeoff unless it seems highly clear 
<br>
that this AGI will be benevolent.  We are not committed to avoid building 
<br>
*any* AGI until we have a comprehensive theory of Friendliness/benevolence, 
<br>
because
<br>
<p>a) we think such a theory will come only from experimenting with 
<br>
appropriately constructed AGI's
<br>
b) we think other existential risks (including the risks of others' nasty 
<br>
AGI's) are too great to be able to afford a maximally careful approach in 
<br>
regard to our own AGI
<br>
<p>So anyway, it is just not true that the SIAI is the only group seeking to 
<br>
build a demonstrably/arguably benevolent AGI system.  Novamente is, and 
<br>
probably other groups are as well.  Rather, SIAI has a particular approach 
<br>
toward this goal, which involves the belief that a theory of Friendly AI can 
<br>
be arrived at purely theoretically rather than empirically -- and this 
<br>
approach appears to be unique to SIAI.
<br>
<p>-- Ben Goertzel
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11123.html">Michael Wilson: "Re: Robot that thinks like a human"</a>
<li><strong>Previous message:</strong> <a href="11121.html">Marc Geddes: "Proposed Universal data types"</a>
<li><strong>In reply to:</strong> <a href="11116.html">Michael Wilson: "RE: Robot that thinks like a human"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11122">[ date ]</a>
<a href="index.html#11122">[ thread ]</a>
<a href="subject.html#11122">[ subject ]</a>
<a href="author.html#11122">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:22:56 MST
</em></small></p>
</body>
</html>
