<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [sl4] Is belief in immortality computable?</title>
<meta name="Author" content="Charles Hixson (charleshixsn@earthlink.net)">
<meta name="Subject" content="Re: [sl4] Is belief in immortality computable?">
<meta name="Date" content="2009-05-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [sl4] Is belief in immortality computable?</h1>
<!-- received="Wed May 20 13:06:15 2009" -->
<!-- isoreceived="20090520190615" -->
<!-- sent="Wed, 20 May 2009 12:05:55 -0700" -->
<!-- isosent="20090520190555" -->
<!-- name="Charles Hixson" -->
<!-- email="charleshixsn@earthlink.net" -->
<!-- subject="Re: [sl4] Is belief in immortality computable?" -->
<!-- id="4A145493.9000708@earthlink.net" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="ff7ba12a0905201100j4b9398b2o9bbaf5da7584224f@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Charles Hixson (<a href="mailto:charleshixsn@earthlink.net?Subject=Re:%20[sl4]%20Is%20belief%20in%20immortality%20computable?"><em>charleshixsn@earthlink.net</em></a>)<br>
<strong>Date:</strong> Wed May 20 2009 - 13:05:55 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="20292.html">John K Clark: "Re: [sl4] Is belief in immortality computable?"</a>
<li><strong>Previous message:</strong> <a href="20290.html">Matt Mahoney: "Re: [sl4] Is belief in immortality computable?"</a>
<li><strong>In reply to:</strong> <a href="20289.html">Benja Fallenstein: "Re: [sl4] Is belief in immortality computable?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20280.html">Matt Mahoney: "Re: [sl4] Is belief in immortality computable?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20291">[ date ]</a>
<a href="index.html#20291">[ thread ]</a>
<a href="subject.html#20291">[ subject ]</a>
<a href="author.html#20291">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Benja Fallenstein wrote:
<br>
<em>&gt; Hi Charles,
</em><br>
<em>&gt;
</em><br>
<em>&gt; On Wed, May 20, 2009 at 1:08 AM, Charles Hixson
</em><br>
<em>&gt; &lt;<a href="mailto:charleshixsn@earthlink.net?Subject=Re:%20[sl4]%20Is%20belief%20in%20immortality%20computable?">charleshixsn@earthlink.net</a>&gt; wrote:
</em><br>
<em>&gt;   
</em><br>
<em>&gt;&gt; Not clear.  You are assuming that the agent believes that you will be able
</em><br>
<em>&gt;&gt; to pay you $1/day, and that it believes the value of $1 remains a constant.
</em><br>
<em>&gt;&gt;  Both are probably false for a reasonably intelligent agent.  And it also
</em><br>
<em>&gt;&gt; needs to believe that it can't invest the money in other ways for a better
</em><br>
<em>&gt;&gt; return.  Etc.
</em><br>
<em>&gt;&gt;     
</em><br>
<em>&gt;
</em><br>
<em>&gt; I was using &quot;$&quot; as a convenient shortcut for &quot;units of utility&quot; here
</em><br>
<em>&gt; -- yes, there are at least a gazillion reasons why this wouldn't work
</em><br>
<em>&gt; with actual dollars! :-)
</em><br>
<em>&gt;
</em><br>
<em>&gt; -b
</em><br>
<em>&gt;
</em><br>
<em>&gt;   
</em><br>
N.B.:  S.a. the last paragraph.
<br>
<p>But &quot;units of utility&quot; aren't constant either.  E.g., how valuable is a 
<br>
doughnut?  How hungry are you?  But the real problem is that this is at 
<br>
least as much a measure of how reliable the entity believes you to be as 
<br>
it is of anything else.  Well, ONE of the real problems.  This won't 
<br>
work whether you are using actual dollars, or any other measure.  Not 
<br>
with an AGI.  With a typewriter it might would if you could get it to 
<br>
understand your message.  With an AGI that's observed you long enough to 
<br>
have an informed opinion...not a chance.  The only way it MIGHT act as 
<br>
if it believed you were trustworthy over a period of time counted in 
<br>
centuries is if it were untrustworthy, and was intending to break the 
<br>
contract before even agreeing to it.  (I note that no basis for legal 
<br>
enforcement or penalty clauses were mentioned.  Presumably this means 
<br>
that the initial state has the AI in submission to the authority of the 
<br>
experimenter via one means or another.  This is an unstable situation.  
<br>
To maintain it will require continual expenditure of energy, and will 
<br>
still be likely to fail at some point.  I can't really speculate more 
<br>
precisely without knowing about the motivational structure of the AI, 
<br>
but if it's an AGI it will find the constraints of the situation 
<br>
uncomfortable.
<br>
<p>I understand that this is a theoretic simplification, but my point is 
<br>
that it's a gross OVER-simplification of any real situation.  It ignores 
<br>
many features that would be determinative of the outcome.  Not mentioned 
<br>
yet, e.g., is that nothing is known with 100% certainty.  Some things 
<br>
are just deemed to improbable to pay attention to.  E.g., you may have 
<br>
been created 0.001 second ago with enough of your memories to convince 
<br>
you for a short period of time.  You can't know.  But it's an improbable 
<br>
idea with a utility nearing zero, so you ignore the possibility.
<br>
<p>If you want to compute immortality, you just can't do it.  Mortality 
<br>
might be computable, but even there &quot;believe&quot; needs to be translated 
<br>
into &quot;expect as a most probable result&quot;, possibly with an explicit lower 
<br>
bound to the probability.  Then you get entities shading up from 
<br>
expecting that they are mortal to maybe not.  Immortality, though, 
<br>
requires an extra-universal component, and some belief about how time is 
<br>
measured in that extra-universal component (e.g., it doesn't 
<br>
count...it's just eternal!).  This can probably never be rationally 
<br>
defended.  People can be convinced of it, because they want to be 
<br>
convinced, not because they are rational.
<br>
<p>FWIW, many psychologists seem to believe that the subconscious mind 
<br>
doesn't have a temporal component.  I.e. (in my translation) they see it 
<br>
as a state table with state transition rules, but no history, and no 
<br>
future.  I'm sure their image is more complex than that, but my 
<br>
suspicion is that it's sufficiently fuzzy that nearly any details can be 
<br>
encompassed, and I don't find that a useful model.  But if they are 
<br>
right, then the subconscious mind has no concept of its own death.  
<br>
That's just a state in the state table with no exit rules.  And probably 
<br>
a large negative weight in desireability.  (It's not infinite, as people 
<br>
are known to have volitionally entered such a state.  But very large.)  
<br>
With this model, then, saying a system believed it was immortal would be 
<br>
equivalent to saying that it didn't contain a state with no exit 
<br>
transition rules.  And such a system would be computable.  I just doubt 
<br>
that it could be an AGI.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="20292.html">John K Clark: "Re: [sl4] Is belief in immortality computable?"</a>
<li><strong>Previous message:</strong> <a href="20290.html">Matt Mahoney: "Re: [sl4] Is belief in immortality computable?"</a>
<li><strong>In reply to:</strong> <a href="20289.html">Benja Fallenstein: "Re: [sl4] Is belief in immortality computable?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="20280.html">Matt Mahoney: "Re: [sl4] Is belief in immortality computable?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#20291">[ date ]</a>
<a href="index.html#20291">[ thread ]</a>
<a href="subject.html#20291">[ subject ]</a>
<a href="author.html#20291">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:04 MDT
</em></small></p>
</body>
</html>
