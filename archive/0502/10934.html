<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: AGI Prototying Project</title>
<meta name="Author" content="J. Andrew Rogers (andrew@ceruleansystems.com)">
<meta name="Subject" content="RE: AGI Prototying Project">
<meta name="Date" content="2005-02-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: AGI Prototying Project</h1>
<!-- received="Sun Feb 20 12:03:57 2005" -->
<!-- isoreceived="20050220190357" -->
<!-- sent="Sun, 20 Feb 2005 11:03:28 -0800" -->
<!-- isosent="20050220190328" -->
<!-- name="J. Andrew Rogers" -->
<!-- email="andrew@ceruleansystems.com" -->
<!-- subject="RE: AGI Prototying Project" -->
<!-- id="1108926208.11300@whirlwind.he.net" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="AGI Prototying Project" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> J. Andrew Rogers (<a href="mailto:andrew@ceruleansystems.com?Subject=RE:%20AGI%20Prototying%20Project"><em>andrew@ceruleansystems.com</em></a>)<br>
<strong>Date:</strong> Sun Feb 20 2005 - 12:03:28 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10935.html">Russell Wallace: "Re: AGI Prototying Project"</a>
<li><strong>Previous message:</strong> <a href="10933.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<li><strong>Maybe in reply to:</strong> <a href="10932.html">Tyler Emerson: "RE: AGI Prototying Project"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10936.html">Michael Wilson: "RE: AGI Prototying Project"</a>
<li><strong>Reply:</strong> <a href="10936.html">Michael Wilson: "RE: AGI Prototying Project"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10934">[ date ]</a>
<a href="index.html#10934">[ thread ]</a>
<a href="subject.html#10934">[ subject ]</a>
<a href="author.html#10934">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Michael Wilson wrote:
<br>
<em>&gt; Yes, I am. AGI is an incredibly hard problem. Thousands of very
</em><br>
<em>&gt; talented researchers have been attacking it for decades. Tens of
</em><br>
<em>&gt; thousands of part-time dabblers have had a go by now. If this
</em><br>
<em>&gt; was something that could be solved by conventional methods, it
</em><br>
<em>&gt; would've been solved by now.
</em><br>
<p><p>All current AGI projects are standing on the shoulders of giants.  The vast majority of 
<br>
projects have not had the benefit of the math and theory we have now.  All real technology is 
<br>
developed incrementally, and AGI is one particular technology that does not produce much in 
<br>
the way of very obvious qualitative results until it is at a very advanced stage.
<br>
<p><p><em>&gt; We have brilliant, dedicated
</em><br>
<em>&gt; people, we have a uniquely cross-field perspective, we have a
</em><br>
<em>&gt; very advanced theory. That won't be enough; we still need more
</em><br>
<em>&gt; funding and recruits, but I think we have enough to try some
</em><br>
<em>&gt; exploratory implementation.
</em><br>
<p><p>This is not a differentiator.  Everyone else claims to have the same, and they are mostly 
<br>
correct.
<br>
<p><p><em>&gt; Again I wish this wasn't the case, as I don't like elitism either,
</em><br>
<em>&gt; but reams of past experience (just look at the SL4 archives) have
</em><br>
<em>&gt; shown that though many people think they have something to contribute
</em><br>
<em>&gt; to AGI, very few people actually do.
</em><br>
<p><p>So what you are saying is that there is ample evidence that people are easily capable of 
<br>
deluding themselves into thinking that they are smart enough to figure out the One True 
<br>
Path to AGI?  And this does not apply to the folks at SIAI because...?
<br>
<p>Don't bother answering that question.  Whatever you are going to say, it is what we would 
<br>
expect a self-deluded SIAI person to say.
<br>
<p><p><em>&gt; It's clear that making stuff up just doesn't cut it; if we did that
</em><br>
<em>&gt; we'd have no more chance of success than all of the above projects
</em><br>
<em>&gt; (i.e. almost none). Our theory must be /different in kind/, in
</em><br>
<em>&gt; particular the way in which we validate and justify it.
</em><br>
<p><p>My biggest criticism of AI designs generally is that almost none of them really offer a 
<br>
theoretically solid reason why the design can be expected to produce AI in the first place.  
<br>
Engineering design based on things that &quot;sound good&quot; does not fly (no pun intended) in any 
<br>
other domain (except perhaps social engineering) and it has never produced good results 
<br>
anywhere it has been tried as a general rule.  Justification and validation is a very necessary 
<br>
prerequisite that cannot be glossed over because it is difficult or inconvenient.
<br>
<p><p><em>&gt; I haven't published anything yet and I won't be doing so in the
</em><br>
<em>&gt; near future. I'd like to, but Eliezer has convinced me that the
</em><br>
<em>&gt; expected returns (in constructive criticism) aren't worth the
</em><br>
<em>&gt; risk. As such I'm not asking anyone to accept that my design is
</em><br>
<em>&gt; the best, or even that it will work. Frankly I'm not that sure
</em><br>
<em>&gt; that it will work, despite having a deep understanding of the
</em><br>
<em>&gt; theory and advanced validation techniques; that's why this is
</em><br>
<em>&gt; exploratory prototyping (note that many other projects are quite
</em><br>
<em>&gt; happy to claim certainty that they've got it right despite being
</em><br>
<em>&gt; unable to verify cognitive competence and/or blatantly wrong).
</em><br>
<p><p>I've been going back and forth on the &quot;publish or not&quot; thing for a long time, but have finally 
<br>
come to the conclusion that publication is a net negative.  I agree with Eliezer and Michael 
<br>
Wilson on this.  Publication has its uses, particularly in academia, but to a large extent it is 
<br>
attention whoring.  You can get the same constructive criticism value via very limited private 
<br>
circulation.  
<br>
<p>As for &quot;certainty&quot;, you can also say something is &quot;certain&quot; to the extent that one can validate 
<br>
the model in implementation.  And even then, you can only say that which has been 
<br>
demonstrated is a certainty; &quot;the house is painted white on the side&quot;.  Nothing beats a killer 
<br>
demo.
<br>
<p>&nbsp;
<br>
<em>&gt; The problem is that AGI theories are very
</em><br>
<em>&gt; hard to validate; to the untrained (or even moderately trained)
</em><br>
<em>&gt; eye one looks as good as another.
</em><br>
<p><p>This is to be expected, since most of the people interested in validating an AGI theory are 
<br>
interested in exploiting it rather than understanding it.  And of these people, the smart ones 
<br>
are rightly skeptical.  Nothing beats a killer demo.
<br>
<p><p><em>&gt; I've spent a bit more than a year working on AGI design before
</em><br>
<em>&gt; attempting a full-scale architecture. In my opinion this is the
</em><br>
<em>&gt; bare minimum required; if we weren't up against such a pressing
</em><br>
<em>&gt; deadline I'd insist on another year or two. 
</em><br>
<p><p>One can burn a lot of resources on iterative verification by implementation.  It will get the job 
<br>
done, but it ain't cheap.  On the other hand, there are often subtle problems that you 
<br>
discover in implementation that would have taken a lot longer to discover doing high-level 
<br>
design.  I wish I hadn't spent so much time on iterative implementation, but I'm not sure that 
<br>
I would have been obviously better off doing it another way.  
<br>
<p><p><em>&gt; We don't know exactly what
</em><br>
<em>&gt; we're going to do yet, but we're light-years ahead of all other AGI
</em><br>
<em>&gt; projects in this regard.
</em><br>
<p><p>So to clarify: 1) you don't know what you are doing, 2) you have used your powers of 
<br>
omniscience to divine what everyone else is doing, and so it follows that 3) your ideas are far 
<br>
ahead of everyone else.  A compelling argument to be sure, but it sounds like you should 
<br>
have used your powers of omniscience to figure out your own plan rather than trying to 
<br>
figure out what everyone else does or does not know.
<br>
<p><p><em>&gt; All of the SIAI staff are dedicated to the principle of the most
</em><br>
<em>&gt; good for the greatest number. Friendly AI will be a project undertaken
</em><br>
<em>&gt; on behalf of humanity as a whole; Collective Volition ensures that
</em><br>
<em>&gt; the result will be drawn from the sum of what we each consider our
</em><br>
<em>&gt; best attributes.
</em><br>
<p><p>What organization in the world, good or evil, does NOT profess these very things?  The anti-
<br>
Singularity organizations will have the same statement pasted on their homepage.
<br>
<p><p><em>&gt; Because the inner circle are known to be moral...
</em><br>
<p><p>Is it any wonder that SIAI is sometimes painted as a cult?  While I have no reason to believe 
<br>
The Inner Circle is Evil, statements such as this give skeptics a reason to be skeptical.
<br>
<p><p>cheers,
<br>
<p>j. andrew rogers
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10935.html">Russell Wallace: "Re: AGI Prototying Project"</a>
<li><strong>Previous message:</strong> <a href="10933.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<li><strong>Maybe in reply to:</strong> <a href="10932.html">Tyler Emerson: "RE: AGI Prototying Project"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10936.html">Michael Wilson: "RE: AGI Prototying Project"</a>
<li><strong>Reply:</strong> <a href="10936.html">Michael Wilson: "RE: AGI Prototying Project"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10934">[ date ]</a>
<a href="index.html#10934">[ thread ]</a>
<a href="subject.html#10934">[ subject ]</a>
<a href="author.html#10934">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
