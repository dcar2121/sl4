<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: The Gun Is Always Loaded</title>
<meta name="Author" content="Thomas Buckner (tcbevolver@yahoo.com)">
<meta name="Subject" content="The Gun Is Always Loaded">
<meta name="Date" content="2005-02-18">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>The Gun Is Always Loaded</h1>
<!-- received="Fri Feb 18 05:09:27 2005" -->
<!-- isoreceived="20050218120927" -->
<!-- sent="Fri, 18 Feb 2005 04:09:02 -0800 (PST)" -->
<!-- isosent="20050218120902" -->
<!-- name="Thomas Buckner" -->
<!-- email="tcbevolver@yahoo.com" -->
<!-- subject="The Gun Is Always Loaded" -->
<!-- id="20050218120902.70512.qmail@web60004.mail.yahoo.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="20050218023630.10202.qmail@web60008.mail.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Thomas Buckner (<a href="mailto:tcbevolver@yahoo.com?Subject=Re:%20The%20Gun%20Is%20Always%20Loaded"><em>tcbevolver@yahoo.com</em></a>)<br>
<strong>Date:</strong> Fri Feb 18 2005 - 05:09:02 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10735.html">Tyler Emerson: "Seeking SIAI Volunteer Coordinator"</a>
<li><strong>Previous message:</strong> <a href="10733.html">Robin Lee Powell: "Re: About the changing one's mind thing."</a>
<li><strong>In reply to:</strong> <a href="10732.html">Thomas Buckner: "Re: About the changing one's mind thing."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10758.html">Phil Goetz: "Re: The Gun Is Always Loaded"</a>
<li><strong>Reply:</strong> <a href="10758.html">Phil Goetz: "Re: The Gun Is Always Loaded"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10734">[ date ]</a>
<a href="index.html#10734">[ thread ]</a>
<a href="subject.html#10734">[ subject ]</a>
<a href="author.html#10734">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Eliezer keeps saying it, and it keeps being true.
<br>
The gun is always loaded, and there's no such
<br>
thing as too careful. Here, an essay by James
<br>
Oberg on 'not taking it seriously' at NASA. Note
<br>
the last para.
<br>
<p>Tom Buckner
<br>
<p><em>&gt;From <a href="http://www.thespacereview.com/article/318/1">http://www.thespacereview.com/article/318/1</a>
</em><br>
<p>What does a sick “space safety culture” smell
<br>
like?
<br>
by James Oberg
<br>
Monday, February 7, 2005
<br>
<p>In the months following the Columbia shuttle
<br>
disaster two years ago, the independent Columbia
<br>
Accident Investigation Board (CAIB) sought both
<br>
the immediate cause of the accident and the
<br>
cultural context that had allowed it to happen.
<br>
They pinpointed a “flawed safety culture”, and
<br>
admitted that 90% of their critique could have
<br>
been discovered and written before the astronauts
<br>
had been killed—but NASA officials hadn’t
<br>
noticed.
<br>
<p>The challenge to NASA workers in the future is to
<br>
learn to recognize this condition and react to
<br>
it, not to “go along” to be team players who
<br>
don’t rock the boat. NASA has supposedly spent
<br>
the last two years training its work force to
<br>
“know better” in the future, and this is the
<br>
greatest challenge it has had to face. It’s
<br>
harder than the engineering problems, harder than
<br>
the budget problems, harder than the political
<br>
problems—and in fact might just be too hard.
<br>
<p><em>&gt;From personal experience, perhaps I can offer a
</em><br>
case study to help in this would-be cultural
<br>
revolution.
<br>
Fixing NASA’s “flawed safety culture” will be
<br>
harder than the engineering problems, harder than
<br>
the budget problems, harder than the political
<br>
problems—and in fact might just be too hard.
<br>
<p>I remember what a flawed safety culture smelled
<br>
like—I was there once. It was mid-1985, and the
<br>
space shuttle program was a headlong juggernaut
<br>
with the distinct sense among the “working
<br>
troops” that things were coming apart. My job was
<br>
at Mission Control, earlier as a specialist in
<br>
formation flying and then as a technical analyst
<br>
of how the flight design and flight control teams
<br>
interacted.
<br>
<p>Very deliberately, I’ve tried to insure that this
<br>
memory wasn’t an edited version, with impressions
<br>
added after the loss of the Challenger and its
<br>
crew the following January. No, I recall the hall
<br>
conversations and the wide-eyed anxiety of my
<br>
fellow workers at the Johnson Space Center in
<br>
Houston. Something didn’t smell right, and it
<br>
frightened us, even at the time—but we felt
<br>
helpless, because we knew we had no control over
<br>
the course of the program.
<br>
<p>In June there had been a particularly
<br>
embarrassing screw-up at Mission Control. On STS
<br>
51-G, the shuttle was supposed to turn itself so
<br>
that a special UV-transparent window faced a test
<br>
laser in Maui, allowing atmospheric transmission
<br>
characteristics to be measured for a US Air Force
<br>
experiment.
<br>
<p>Instead, the shuttle rolled the window to face
<br>
high into space, ruining the experiment. When it
<br>
happened, some people in the control room
<br>
actually laughed, but the flight director—a
<br>
veteran of the Apollo program—sternly lectured
<br>
them on their easy acceptance of a major human
<br>
error. Privately, many of the younger workers
<br>
later laughed at him some more.
<br>
<p>The error was caused by smugness, lack of
<br>
communications, assumptions of goodness, and no
<br>
fear of consequences of errors. All of these
<br>
traits were almost immediately obvious. Nothing
<br>
changed afterwards, until seven people died. And
<br>
then, for a while only, things did change, only
<br>
to tragically change back until another seven
<br>
lives were lost.
<br>
<p>The following description of the event ventures
<br>
into technical areas and terminology, but I’m
<br>
doing my best to keep it “real world” because the
<br>
process was so analogous to the more serious
<br>
errors that would, at other times, kill people.
<br>
It was a portent—one of many—that NASA’s
<br>
leadership failed to heed.
<br>
Then, as with the ancestry of many, many
<br>
engineering errors, somebody had a good idea to
<br>
improve the system.
<br>
<p>The plan had been to use a feature of the
<br>
shuttle’s computerized autopilot that could point
<br>
any desired “body vector” (a line coming out of
<br>
the shuttle’s midpoint) toward any of a variety
<br>
of targets in space. You could select a celestial
<br>
object, the center of the Earth, or even another
<br>
orbiting satellite. Or, you could select a point
<br>
on Earth’s surface.
<br>
<p>That point would be specified by latitude,
<br>
longitude, and elevation. The units for the first
<br>
two parameters were degrees, of course, but for
<br>
some odd reason—pilot-astronaut preference,
<br>
apparently—the elevation value was in nautical
<br>
miles.
<br>
<p>This was no problem at first, when only two
<br>
digits were allowed on the computer screen for
<br>
the value. Clearly the maximum altitude wasn’t 99
<br>
feet, so operators who were puzzled could look up
<br>
the display in a special on-board dictionary and
<br>
see what was really required.
<br>
<p>Then, as with the ancestry of many, many
<br>
engineering errors, somebody had a good idea to
<br>
improve the system.
<br>
<p>Because the pan-tilt pointing system of the
<br>
shuttle’s high-gain dish antenna was considered
<br>
unreliable, NASA approved a backup plan for
<br>
orienting the antenna directly towards a relay
<br>
satellite. The antenna would be manually locked
<br>
into a “straight-up” position, and the shuttle
<br>
would use the pointing autopilot to aim that body
<br>
axis at an earth-centered point: the
<br>
“mountaintop” 22,000 miles above the equator
<br>
where the relay satellite was in stationary
<br>
orbit.
<br>
<p>It was a clever usage of one software package to
<br>
an unanticipated application. All that was
<br>
required was that the allowable input for
<br>
altitude (in nautical miles) be increased from
<br>
two digits to five. It seemed simple and safe, as
<br>
long as all operators read the user’s manual.
<br>
“If it can go wrong in space, it will”
<br>
<p>The backup control plan was never needed, since
<br>
the antenna pointing motors proved perfectly
<br>
reliable. In addition, the ground-site pointing
<br>
option was rarely used, so Mission Control got
<br>
rusty in its quirks.
<br>
<p>Then came the Air Force request to point a
<br>
shuttle window at a real mountaintop. Simple
<br>
enough, it seemed, and the responsible operator
<br>
developed the appropriate numbers and tested them
<br>
at his desktop computer, then entered them in the
<br>
mission’s flight plan.
<br>
<p>The altitude of the Air Force site was 9,994
<br>
feet. That’s 1.65 nautical miles—but that number
<br>
never showed up in the flight plan.
<br>
<p>Instead, because the pointing experts used a
<br>
desktop program they had written that required
<br>
feet be entered (they weren’t pilots, after all),
<br>
they had tested and verified the shuttle’s
<br>
performance when the number “9994” was entered.
<br>
So that’s what they submitted for the crew’s
<br>
checklist.
<br>
<p>As the hour approached for the test, one clue
<br>
showed up at Mission Control that something was
<br>
amiss. The pointing experts had used longitude
<br>
units as degrees east, ranging from 0 to 360, and
<br>
had entered “203.74” for the longitude. Aboard
<br>
the shuttle, the autopilot rejected that number
<br>
as “out of range”.
<br>
<p>A quick check of the user’s manual showed that
<br>
the autopilot was expecting longitude in degrees
<br>
with a range of plus or minus 0 to 180. The
<br>
correct figure, “–156.26”, was quickly computed
<br>
and entered, with an “oops” and a shoulder shrug
<br>
from the pointing officer. He did not ask
<br>
himself—and nobody else asked him—that if one
<br>
parameter had used improper units and range, was
<br>
it worth the 30 seconds it would take to verify
<br>
the other parameters as well? No, it was assumed,
<br>
since the other values were “accepted” by the
<br>
autopilot, they must be correct.
<br>
<p>So as ordered, when the time came, the shuttle
<br>
obediently turned its instrument window to face a
<br>
point in space 9,994 nautical miles directly over
<br>
Hawaii. The astronauts in space and the flight
<br>
controllers on Earth were at first alarmed by the
<br>
apparent malfunction that ruined the experiment.
<br>
But then came the explanation, which most thought
<br>
funny. After all, nobody had been hurt. The alarm
<br>
subsided.
<br>
The breadth of the stink
<br>
<p>A young engineer from a contract team that
<br>
supported the pointing experts later showed me
<br>
the memo he had written, months earlier,
<br>
correctly identifying the errors in the two
<br>
parameters that had been written down in the crew
<br>
checklist. They were inconsistent with the user’s
<br>
manual, he had pointed out, and wouldn’t work—and
<br>
he also showed the computer simulation program
<br>
that verified it. The memo was never answered,
<br>
and the engineer’s manager didn’t want to pester
<br>
the pointing experts further because his group
<br>
was up for contract renewal and didn’t want any
<br>
black marks for making trouble.
<br>
Other friends of mine in other disciplines
<br>
confided in me their growing desperation of
<br>
encountering a more and more sloppy approach to
<br>
spaceflight, as repeated successes showed that
<br>
“routine” was becoming real and that carelessness
<br>
was turning out to have no negative consequences.
<br>
<p>Nor was the space press all that interested in
<br>
drawing alarming conclusions from this and other
<br>
“straws in the space wind” that were becoming
<br>
widely known. NASA had announced its program for
<br>
sending a journalist into space. The classic
<br>
penchant of big bureaucracies to adore press
<br>
praise and resent press criticism was well known,
<br>
and NASA wasn’t immune to this urge, as space
<br>
reporters well knew. So it was safer for their
<br>
own chances to fly in space if they just passed
<br>
over this negative angle.
<br>
<p>Other friends of mine in other disciplines—in the
<br>
robot arm, in electrical power budgeting, in life
<br>
science experiments—confided in me their growing
<br>
desperation of encountering a more and more
<br>
sloppy approach to spaceflight, as repeated
<br>
successes showed that “routine” was becoming real
<br>
and that carelessness was turning out to have no
<br>
negative consequences. People all around them,
<br>
they lamented, had lost their fear of failure,
<br>
and had lost respect for the strict discipline
<br>
that forbade convenient, comfortable “assumptions
<br>
of goodness” unless they were backed up by solid
<br>
testing and analysis.
<br>
<p>It was precisely this sort of thinking that led
<br>
to the management decision flaws that would lose
<br>
Challenger (that specific flaw was at Cape
<br>
Canaveral, but it reflected a NASA-wide cultural
<br>
malaise), and a generation later, lose Columbia
<br>
(the flaws then were squarely in the Houston
<br>
space team and at the Alabama center that built
<br>
the fuel tank whose falling insulation mortally
<br>
wounded the spaceship’s wing).
<br>
<p>It is that sort of thinking that space workers,
<br>
and workers in any activity where misjudgment can
<br>
have grievous impact, must vigorously learn to
<br>
smell out. This time, too, they must know that
<br>
they must act, and not “go along”, or else it’s
<br>
only a matter of time that the real world finds
<br>
another technical path that leads to a new
<br>
disaster.
<br>
<p>James Oberg (www.jamesoberg.com) is a 22-year
<br>
veteran of NASA mission control. He is now a
<br>
writer and consultant in Houston.
<br>
<p><p>__________________________________________________
<br>
Do You Yahoo!?
<br>
Tired of spam?  Yahoo! Mail has the best spam protection around 
<br>
<a href="http://mail.yahoo.com">http://mail.yahoo.com</a> 
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10735.html">Tyler Emerson: "Seeking SIAI Volunteer Coordinator"</a>
<li><strong>Previous message:</strong> <a href="10733.html">Robin Lee Powell: "Re: About the changing one's mind thing."</a>
<li><strong>In reply to:</strong> <a href="10732.html">Thomas Buckner: "Re: About the changing one's mind thing."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10758.html">Phil Goetz: "Re: The Gun Is Always Loaded"</a>
<li><strong>Reply:</strong> <a href="10758.html">Phil Goetz: "Re: The Gun Is Always Loaded"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10734">[ date ]</a>
<a href="index.html#10734">[ thread ]</a>
<a href="subject.html#10734">[ subject ]</a>
<a href="author.html#10734">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:22:53 MST
</em></small></p>
</body>
</html>
