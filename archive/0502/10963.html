<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AGI Prototying Project</title>
<meta name="Author" content="Tennessee Leeuwenburg (tennessee@tennessee.id.au)">
<meta name="Subject" content="Re: AGI Prototying Project">
<meta name="Date" content="2005-02-21">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AGI Prototying Project</h1>
<!-- received="Mon Feb 21 20:37:39 2005" -->
<!-- isoreceived="20050222033739" -->
<!-- sent="Tue, 22 Feb 2005 14:35:24 +1100" -->
<!-- isosent="20050222033524" -->
<!-- name="Tennessee Leeuwenburg" -->
<!-- email="tennessee@tennessee.id.au" -->
<!-- subject="Re: AGI Prototying Project" -->
<!-- id="421AA87C.2040902@tennessee.id.au" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="8d71341e050221171263780f93@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Tennessee Leeuwenburg (<a href="mailto:tennessee@tennessee.id.au?Subject=Re:%20AGI%20Prototying%20Project"><em>tennessee@tennessee.id.au</em></a>)<br>
<strong>Date:</strong> Mon Feb 21 2005 - 20:35:24 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10964.html">Ben Goertzel: "Some new ideas on Friendly AI"</a>
<li><strong>Previous message:</strong> <a href="10962.html">Brian Atkins: "Re: Overconfidence and meta-rationality"</a>
<li><strong>In reply to:</strong> <a href="10959.html">Russell Wallace: "Re: AGI Prototying Project"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10970.html">Russell Wallace: "Re: AGI Prototying Project"</a>
<li><strong>Reply:</strong> <a href="10970.html">Russell Wallace: "Re: AGI Prototying Project"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10963">[ date ]</a>
<a href="index.html#10963">[ thread ]</a>
<a href="subject.html#10963">[ subject ]</a>
<a href="author.html#10963">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
-----BEGIN PGP SIGNED MESSAGE-----
<br>
Hash: SHA1
<br>
<p><p>It remains unclear to me what &quot;RPOP&quot; is an acronym for; Google has no
<br>
suggestions.
<br>
<p>|&gt; If the end point of evolutions is not sentient we are screwed, if
<br>
|&gt; it is sentient we are safe, subject on both sides to the
<br>
|&gt; vaguaries of horizon problems. This is a truism if you believe
<br>
|&gt; that all evolutionary paths are eventually explored. Evolution is
<br>
|&gt; not a circumventable process, we can only do our best to build a
<br>
|&gt; fittest organism which is interesting rather than not.
<br>
|
<br>
|
<br>
| I'm not sure about this... maybe you're right, in which case we're
<br>
| toast. But I think this one _is_ a matter of probability.
<br>
|
<br>
| However, I'm going to suggest an equivalent of Pascal's Wager: If
<br>
| evolution can't be circumvented, it doesn't matter what we do for
<br>
| good or bad. If it can, then it does matter what we do. So I put it
<br>
| to you that we should act on the assumption that I'm right and it's
<br>
| both possible and necessary to circumvent evolution.
<br>
|
<br>
| - Russell
<br>
<p>Your argument :
<br>
1) If Friendliness is a fitter being, everything will be fine
<br>
2) If mindless nanotech is a fitter being, we're screwed
<br>
3) If (1) is true, then we are fine if we pursue Friendliness
<br>
4) If (2) is true, then we are screwed, but you maintain hope that we
<br>
could work to not be screwed.
<br>
<p>Your argument is the counterpoint to my argument, which I shall
<br>
express in my terms.
<br>
<p>It's a horizon thing. If we can get to friendliness FIRST, then
<br>
evolution might not explore mindlessness. Evolution is a tool to be
<br>
harnessed, not one to be circumvented. The trick is not to assume that
<br>
we need to work against AI, and brainstorm a way of making a moral
<br>
invariant that can survive a chaotic system, but to understand the
<br>
system such that there will be a natural convergence towards Friendliness.
<br>
<p>It's not about 'escaping' evolutionary pressure - that is like saying
<br>
that everything would be easier if the laws of the universe were
<br>
different. Survival of the fittest /will/ happen. We need to ensure
<br>
that something interesting is the fittest thing.
<br>
<p>This came about due to my claim that
<br>
<p>| Survival of the fittest is how I got here, and damned if I'm going
<br>
| to starve to death for the sake of some rats. I think it's fair
<br>
| enough to apply the same standard to something smarter and higher
<br>
| on the food chain.
<br>
<p>Your response was that you were worried about being out-competed by
<br>
nanobots, and so we need to build in some kind of invariant morality
<br>
into AGI in order that AGI doesn't evolve itself into nanobots due to
<br>
some screwball horizon problem in its reward mechanism that we didn't see.
<br>
<p>My argument is that evolution can be a tool, and that we shouldn't try
<br>
to pretend that it can be circumvented. If we 'nobble' the AGI into
<br>
putting human existence ahead of self-existence, then perhaps that is
<br>
precisely the edge that the evil nanobots need in order to take over
<br>
the universe?
<br>
<p>Oh, and I read some of the mail archive, and ended up on a page by Ben
<br>
Goetzel talking about &quot;Solomonoff Induction&quot;. Is anyone interested in
<br>
my pointing out some implied assumptions I found in there, or has this
<br>
already been done to death?
<br>
<p>Cheers,
<br>
- -T
<br>
-----BEGIN PGP SIGNATURE-----
<br>
Version: GnuPG v1.2.4 (GNU/Linux)
<br>
Comment: Using GnuPG with Thunderbird - <a href="http://enigmail.mozdev.org">http://enigmail.mozdev.org</a>
<br>
<p>iD8DBQFCGqh8Fp/Peux6TnIRAgF6AJ9Uv8mH1xPKb2OSzSh1r3tB6JDEcgCgjwrx
<br>
zeQ2m4dzfD4m84aizSrKOmQ=
<br>
=P3KG
<br>
-----END PGP SIGNATURE-----
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10964.html">Ben Goertzel: "Some new ideas on Friendly AI"</a>
<li><strong>Previous message:</strong> <a href="10962.html">Brian Atkins: "Re: Overconfidence and meta-rationality"</a>
<li><strong>In reply to:</strong> <a href="10959.html">Russell Wallace: "Re: AGI Prototying Project"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10970.html">Russell Wallace: "Re: AGI Prototying Project"</a>
<li><strong>Reply:</strong> <a href="10970.html">Russell Wallace: "Re: AGI Prototying Project"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10963">[ date ]</a>
<a href="index.html#10963">[ thread ]</a>
<a href="subject.html#10963">[ subject ]</a>
<a href="author.html#10963">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
