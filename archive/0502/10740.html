<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: AGI Prototying Project</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: AGI Prototying Project">
<meta name="Date" content="2005-02-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: AGI Prototying Project</h1>
<!-- received="Sun Feb 20 10:03:01 2005" -->
<!-- isoreceived="20050220170301" -->
<!-- sent="Sun, 20 Feb 2005 12:02:25 -0500" -->
<!-- isosent="20050220170225" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: AGI Prototying Project" -->
<!-- id="JNEIJCJJHIEAILJBFHILAELHDPAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="200502201216.j1KCGGh13278@tick.javien.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20AGI%20Prototying%20Project"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sun Feb 20 2005 - 10:02:25 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10741.html">J. Andrew Rogers: "RE: AGI Prototying Project"</a>
<li><strong>Previous message:</strong> <a href="10739.html">Tyler Emerson: "RE: AGI Prototying Project"</a>
<li><strong>In reply to:</strong> <a href="10739.html">Tyler Emerson: "RE: AGI Prototying Project"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10742.html">Russell Wallace: "Re: AGI Prototying Project"</a>
<li><strong>Reply:</strong> <a href="10742.html">Russell Wallace: "Re: AGI Prototying Project"</a>
<li><strong>Reply:</strong> <a href="10744.html">Michael Wilson: "RE: AGI Prototying Project"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10740">[ date ]</a>
<a href="index.html#10740">[ thread ]</a>
<a href="subject.html#10740">[ subject ]</a>
<a href="author.html#10740">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi,
<br>
<p><em>&gt; Unfortunately very, very few people are qualified to work directly
</em><br>
<em>&gt; on AGI; my guess would be fewer than 1 in 10,000,000 (we haven't
</em><br>
<em>&gt; found many of these yet).
</em><br>
<p>I agree that the percentage of people who have the right combination of
<br>
skills and attitudes and interests for AGI work is very small, but that
<br>
figure seems absurdly small to me.
<br>
<p>My own guess is that out of a given graduating class of undergraduate
<br>
computer scientists at a reasonably university, there will probably be 5-10
<br>
people with the combination of technical ability, work ethic, and
<br>
cognitive-science intuition to be productive at working on AGI, given the
<br>
current state of AGI-related technologies.
<br>
<p>Of course, as supporting technologies develop, the technical ability
<br>
required for AGI work will decrease and the percentage of capable people
<br>
will increase.
<br>
<p><em>&gt; Again I wish this wasn't the case, as I don't like elitism either,
</em><br>
<em>&gt; but reams of past experience (just look at the SL4 archives) have
</em><br>
<em>&gt; shown that though many people think they have something to contribute
</em><br>
<em>&gt; to AGI, very few people actually do.
</em><br>
<p>Well, most people on the SL4 list lack the technical knowledge to really
<br>
contribute to making an AGI.
<br>
<p>And most of those that have the technical knowledge are just responding to
<br>
emails on the list in a cursory way -- their contributions, made in this
<br>
way, are quite different from the ones they would make if they were deeply
<br>
involved in an AGI project.
<br>
<p>I can think of a few folks on this list who would probably be good
<br>
contributors to an AGI project, IF they chose to devote enough of their time
<br>
to it....
<br>
<p><em>&gt; &gt; AGI isn't any harder than Speech Recognition application development
</em><br>
<em>&gt; &gt; to me.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Speech recognition is a largely solved problem that was and is amenable
</em><br>
<em>&gt; to standard engineering methods. The key point is that it's well
</em><br>
<em>&gt; defined; we know exactly what we want, we just need to find algorithms
</em><br>
<em>&gt; that can do it.
</em><br>
<p>I think the key point is that it's easier than AGI, not that it's more
<br>
exactly defined.
<br>
<p><em>&gt; I haven't published anything yet and I won't be doing so in the
</em><br>
<em>&gt; near future. I'd like to, but Eliezer has convinced me that the
</em><br>
<em>&gt; expected returns (in constructive criticism) aren't worth the
</em><br>
<em>&gt; risk.
</em><br>
<p>Well, it's always a difficult decision to make, when to allocate time to
<br>
writing things up for publication.
<br>
<p>In principle I'm in favor of it, because I do think there are many folks out
<br>
there in the world with constructive criticisms to make about AGI designs.
<br>
<p>However, in practice I have been dragging my heels for many years in making
<br>
a decent write-up of the Novamente design --- because making such a write-up
<br>
is a LOT of work.  I only have a certain percentage of my time to spend on
<br>
AGI work, due to the need to generate income via narrow-AI work as well as
<br>
family responsibilities etc., and it's usually tempting to spend this time
<br>
actually working toward AGI rather than writing about it in a way that would
<br>
be comprehensible to outsiders...
<br>
<p><em>&gt; AGI is mostly a
</em><br>
<em>&gt; high-level design challenge, not an implementation challenge
</em><br>
<p>This is certainly correct
<br>
<p><em>&gt;However we cannot
</em><br>
<em>&gt; operate that way; firstly once you acknowledge the sheer difficulty
</em><br>
<em>&gt; of AGI you realise that there just aren't that many qualified
</em><br>
<em>&gt; people available (and the unqualified ones would just waste time
</em><br>
<em>&gt; with plausible-looking but unworkable ideas), and that we cannot
</em><br>
<em>&gt; take the risk of releasing powerful techniques to all comers.
</em><br>
<p>It seems that the latter point must be the main one.
<br>
<p>I don't believe that ALL of us on this list would just waste your time with
<br>
useless discussions, if you were to post your detailed AGI design ideas
<br>
publicly.
<br>
<p><em>&gt; &gt; SIAI itself seems to have an intuitive grasp of 'what
</em><br>
<em>&gt; &gt; comes after,' even if it is not laid out for all to see.
</em><br>
<em>&gt;
</em><br>
<em>&gt; It is laid out for all to see here;
</em><br>
<em>&gt;
</em><br>
<em>&gt; <a href="http://www.sl4.org/wiki/CollectiveVolition">http://www.sl4.org/wiki/CollectiveVolition</a>
</em><br>
<em>&gt;
</em><br>
<em>&gt; Please read this if you haven't already. It's a statement of what
</em><br>
<em>&gt; the SIAI intends to do. If you don't agree that this is better
</em><br>
<em>&gt; than the alternative (which is basically allowing other projects
</em><br>
<em>&gt; to build badly understood AGIs that will destroy the world in a
</em><br>
<em>&gt; randomly choosen fashion), you shouldn't be volunteering to help.
</em><br>
<p>CV is an interesting philosophical theory that so far as I can tell has very
<br>
little practical value.
<br>
<p>Maybe it can be turned into something with some practical value, I'm not
<br>
sure.
<br>
<p>To state with such confidence that any AGI not based on this particular
<br>
not-fully-baked philosophical theory &quot;will destroy the world in a randomly
<br>
chosen fashion&quot; is just ridiculous.
<br>
<p><p><em>&gt; &gt; Obviously there's no easy way to answer this, but I ask instead,
</em><br>
<em>&gt; &gt; what -are- the security reasons for a select inner circle on this
</em><br>
<em>&gt; &gt; project?
</em><br>
<em>&gt;
</em><br>
<em>&gt; Because the inner circle are known to be moral,
</em><br>
<p>Hmmm... nothing personal, but that sounds like a dangerous assumption!!
<br>
<p>I believe this sort of error has been made before in human history ;-p
<br>
<p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10741.html">J. Andrew Rogers: "RE: AGI Prototying Project"</a>
<li><strong>Previous message:</strong> <a href="10739.html">Tyler Emerson: "RE: AGI Prototying Project"</a>
<li><strong>In reply to:</strong> <a href="10739.html">Tyler Emerson: "RE: AGI Prototying Project"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10742.html">Russell Wallace: "Re: AGI Prototying Project"</a>
<li><strong>Reply:</strong> <a href="10742.html">Russell Wallace: "Re: AGI Prototying Project"</a>
<li><strong>Reply:</strong> <a href="10744.html">Michael Wilson: "RE: AGI Prototying Project"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10740">[ date ]</a>
<a href="index.html#10740">[ thread ]</a>
<a href="subject.html#10740">[ subject ]</a>
<a href="author.html#10740">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:22:53 MST
</em></small></p>
</body>
</html>
