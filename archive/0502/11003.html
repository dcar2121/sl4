<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: ITSSIM (was Some new ideas on Friendly AI)</title>
<meta name="Author" content="Tennessee Leeuwenburg (tennessee@tennessee.id.au)">
<meta name="Subject" content="Re: ITSSIM (was Some new ideas on Friendly AI)">
<meta name="Date" content="2005-02-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: ITSSIM (was Some new ideas on Friendly AI)</h1>
<!-- received="Wed Feb 23 14:25:39 2005" -->
<!-- isoreceived="20050223212539" -->
<!-- sent="Thu, 24 Feb 2005 08:22:44 +1100" -->
<!-- isosent="20050223212244" -->
<!-- name="Tennessee Leeuwenburg" -->
<!-- email="tennessee@tennessee.id.au" -->
<!-- subject="Re: ITSSIM (was Some new ideas on Friendly AI)" -->
<!-- id="421CF424.8080100@tennessee.id.au" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20050223170342.53325.qmail@web54503.mail.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Tennessee Leeuwenburg (<a href="mailto:tennessee@tennessee.id.au?Subject=Re:%20ITSSIM%20(was%20Some%20new%20ideas%20on%20Friendly%20AI)"><em>tennessee@tennessee.id.au</em></a>)<br>
<strong>Date:</strong> Wed Feb 23 2005 - 14:22:44 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11004.html">Tennessee Leeuwenburg: "Re: AGI Prototying Project"</a>
<li><strong>Previous message:</strong> <a href="11002.html">Ben Goertzel: "RE: [agi] Future AGI's based on theorem-proving"</a>
<li><strong>In reply to:</strong> <a href="10999.html">Phil Goetz: "Re: ITSSIM (was Some new ideas on Friendly AI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10989.html">Thomas Buckner: "HTML E-mail"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11003">[ date ]</a>
<a href="index.html#11003">[ thread ]</a>
<a href="subject.html#11003">[ subject ]</a>
<a href="author.html#11003">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
-----BEGIN PGP SIGNED MESSAGE-----
<br>
Hash: SHA1
<br>
<p><p><p>Phil Goetz wrote:
<br>
| --- Tennessee Leeuwenburg &lt;<a href="mailto:tennessee@tennessee.id.au?Subject=Re:%20ITSSIM%20(was%20Some%20new%20ideas%20on%20Friendly%20AI)">tennessee@tennessee.id.au</a>&gt;
<br>
| wrote:
<br>
|
<br>
|
<br>
|&gt;Ben,
<br>
|&gt;
<br>
|&gt;I read your idea on actions based on proven
<br>
|&gt;theories, subject to a
<br>
|&gt;blacklist against which unsafe options are blocked.
<br>
|&gt;You seemed to be
<br>
|&gt;worried that such a system would be susceptible to
<br>
|&gt;improve itself to a
<br>
|&gt;local minima - that is, it would be hill-climbing to
<br>
|&gt;a potentially
<br>
|&gt;limiting endpoint.
<br>
|&gt;
<br>
|&gt;...
<br>
|&gt;
<br>
|&gt;Let Mag(OPTIONS) represent the number of elements
<br>
|&gt;contained in the set
<br>
|&gt;OPTIONS.
<br>
|&gt;
<br>
|&gt;Mag(OPTIONS) is proportional to IQ(AGI).
<br>
|&gt;
<br>
|&gt;Here's my argument :
<br>
|&gt;
<br>
|&gt;X = Max(OPTIONS)
<br>
|&gt;If X != now &amp; V(X) &gt; V(now) then IQ(AGI,X) &gt;
<br>
|&gt;IQ(AGI,now) which implies
<br>
|&gt;Mag(OPTIONS,AGI, X) &gt; Mag(OPTIONS, AGI, now).
<br>
|
<br>
|
<br>
| This doesn't show that Mag(OPTIONS) is proportional to
<br>
| IQ(AGI).
<br>
<p>No, that was an assumption, which you are welcome to query. What it
<br>
shows is that Mag(OPTIONS) increases with each iterative improvement, if
<br>
it improves at all, and that the maximum is not limited by the an
<br>
interative model...
<br>
<p>|&gt;Corrolary : Regardless of the speed at which the
<br>
|&gt;intelligence of the
<br>
|&gt;AGI grows, the options available to the AGI increase
<br>
|&gt;with the
<br>
|&gt;intelligence of AGI. Incremental increases to IQ do
<br>
|&gt;not result in
<br>
|&gt;local minima, because the horizon of the AGI is
<br>
|&gt;pushed wider with each
<br>
|&gt;improvement.
<br>
<p>What I have shown, I believe, is this :
<br>
<p>Under an iterative model, AGI may escape any local minima at which the
<br>
peak IQ(AGI) is sufficient to see beyond the local minima. What I
<br>
proposed which I think was new, was that local minima can be escaped AT
<br>
ALL. This simply is true, and quite defensible.
<br>
<p>Ben's point was that he thought that an AGI factoring in Safety would be
<br>
much more susceptible to this than ordinary - my response is that in
<br>
fact, I think the difference will be in extent, not in kind. Let me know
<br>
what about my argument you disagree with, and I will speak to that.
<br>
<p>Cheers,
<br>
- -T
<br>
-----BEGIN PGP SIGNATURE-----
<br>
Version: GnuPG v1.4.0 (MingW32)
<br>
Comment: Using GnuPG with Thunderbird - <a href="http://enigmail.mozdev.org">http://enigmail.mozdev.org</a>
<br>
<p>iD8DBQFCHPQkFp/Peux6TnIRAoT2AJ93jEcssWWARQsjxxTM5uiRPEvm7ACggC2Z
<br>
RiGhMfsOvbho1xb9FnzCH6I=
<br>
=JPnQ
<br>
-----END PGP SIGNATURE-----
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11004.html">Tennessee Leeuwenburg: "Re: AGI Prototying Project"</a>
<li><strong>Previous message:</strong> <a href="11002.html">Ben Goertzel: "RE: [agi] Future AGI's based on theorem-proving"</a>
<li><strong>In reply to:</strong> <a href="10999.html">Phil Goetz: "Re: ITSSIM (was Some new ideas on Friendly AI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10989.html">Thomas Buckner: "HTML E-mail"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11003">[ date ]</a>
<a href="index.html#11003">[ thread ]</a>
<a href="subject.html#11003">[ subject ]</a>
<a href="author.html#11003">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
