<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Crack-pots [was Perspex Space]</title>
<meta name="Author" content="Marc Geddes (marc_geddes@yahoo.co.nz)">
<meta name="Subject" content="Crack-pots [was Perspex Space]">
<meta name="Date" content="2005-02-09">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Crack-pots [was Perspex Space]</h1>
<!-- received="Wed Feb  9 23:00:16 2005" -->
<!-- isoreceived="20050210060016" -->
<!-- sent="Thu, 10 Feb 2005 18:59:52 +1300 (NZDT)" -->
<!-- isosent="20050210055952" -->
<!-- name="Marc Geddes" -->
<!-- email="marc_geddes@yahoo.co.nz" -->
<!-- subject="Crack-pots [was Perspex Space]" -->
<!-- id="20050210055952.90086.qmail@web20225.mail.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="20050207062251.37220.qmail@web25309.mail.ukl.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Marc Geddes (<a href="mailto:marc_geddes@yahoo.co.nz?Subject=Re:%20Crack-pots%20[was%20Perspex%20Space]"><em>marc_geddes@yahoo.co.nz</em></a>)<br>
<strong>Date:</strong> Wed Feb 09 2005 - 22:59:52 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10700.html">Dimitry Volfson: "AGI and Contact with &quot;Reality&quot;"</a>
<li><strong>Previous message:</strong> <a href="10698.html">Phil Goetz: "Re: Friendliness and social intelligence"</a>
<li><strong>In reply to:</strong> <a href="10668.html">Michael Wilson: "Re: Perspex Space"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10699">[ date ]</a>
<a href="index.html#10699">[ thread ]</a>
<a href="subject.html#10699">[ subject ]</a>
<a href="author.html#10699">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&nbsp;--- Michael Wilson &lt;<a href="mailto:mwdestinystar@yahoo.co.uk?Subject=Re:%20Crack-pots%20[was%20Perspex%20Space]">mwdestinystar@yahoo.co.uk</a>&gt; wrote:
<br>
<p><p><em>&gt; 
</em><br>
<em>&gt; You've been playing word games for a long time. Over
</em><br>
<em>&gt; time the
</em><br>
<em>&gt; words acquired particular sympathies and antipathies
</em><br>
<em>&gt; in your mind
</em><br>
<em>&gt; that cause them to fit together in certain
</em><br>
<em>&gt; structures. But those
</em><br>
<em>&gt; structures were not built by careful combination of
</em><br>
<em>&gt; objective
</em><br>
<em>&gt; axioms and empirical evidence and show no (apparent)
</em><br>
<em>&gt; concern for
</em><br>
<em>&gt; plausibility as a predictive, descriptive model of a
</em><br>
<em>&gt; real world
</em><br>
<em>&gt; intelligent agent. Your attempts to formalise them
</em><br>
<em>&gt; amount to
</em><br>
<em>&gt; rationalisation of the wild guess that managed to
</em><br>
<em>&gt; gather enough
</em><br>
<em>&gt; cognitive support for itself over repeated mental
</em><br>
<em>&gt; shufflings.
</em><br>
<p>Gee thanks for this amazingly detailed insight into
<br>
the workings of my brain.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; This isn't a problem you can solve by connecting a
</em><br>
<em>&gt; few formal
</em><br>
<em>&gt; models with an overarching grid of fuzzy, ungrounded
</em><br>
<em>&gt; concepts
</em><br>
<em>&gt; that forms a cool-sounding pattern. The problem must
</em><br>
<em>&gt; be solved
</em><br>
<em>&gt; by large scale combination of those formal models
</em><br>
<em>&gt; into a vast,
</em><br>
<em>&gt; intricate, multilayered yet consistent pattern.
</em><br>
<em>&gt; There is no a
</em><br>
<em>&gt; priori requirement that the pattern look plausible
</em><br>
<em>&gt; or
</em><br>
<em>&gt; comprehensible to untrained perception, and indeed
</em><br>
<em>&gt; given the
</em><br>
<em>&gt; history we should expect this result. The solution
</em><br>
<em>&gt; /does/ have
</em><br>
<em>&gt; a kind beauty to it, but what legions of AI
</em><br>
<em>&gt; researchers missed
</em><br>
<em>&gt; is that you can't produce a rose without massive
</em><br>
<em>&gt; amounts of
</em><br>
<em>&gt; intertwined biochemical complexity (on top of the
</em><br>
<em>&gt; basic
</em><br>
<em>&gt; principles of molecular physics and natural
</em><br>
<em>&gt; selection).
</em><br>
<p>O.K, but no one has 'the solution' yet.
<br>
<p><p>&nbsp;
<br>
<em>&gt; Probabilistic reasoning is a formal model created in
</em><br>
<em>&gt; a space
</em><br>
<em>&gt; very different from reality. Application of it
</em><br>
<em>&gt; requires a lot
</em><br>
<em>&gt; of human cognitive effort to dynamically create maps
</em><br>
<em>&gt; that are
</em><br>
<em>&gt; both descriptive of the target problem and compliant
</em><br>
<em>&gt; with the
</em><br>
<em>&gt; logical requirements of probability theory, followed
</em><br>
<em>&gt; by
</em><br>
<em>&gt; further effort to manipulate the model in useful
</em><br>
<em>&gt; ways. Clearly
</em><br>
<em>&gt; any constructive and complete theory of AI based on
</em><br>
<em>&gt; Bayesian
</em><br>
<em>&gt; principles must account for how this activity is
</em><br>
<em>&gt; accomplished.
</em><br>
<p>What makes you so sure that even Bayesian reasoning is
<br>
up to the job of handling FAI?  For sure, Bayesian
<br>
reasoning is powerful framework, but there are some
<br>
curious gaps and problems aren't there?  For instance
<br>
'The problem of the reference class' (see Bostrom). 
<br>
Or the inability to determine what the a priori
<br>
probabilities should be.
<br>
<p>Had it ever ocurred to you that there is another as
<br>
yet undiscovered *even more powerful epistemology* as
<br>
far beyond Bayes as Bayes is beyond Aristotle?  This
<br>
putative super-powerful epistemology would subsume
<br>
Bayes as a special case, whilst extending beyond the
<br>
Bayesian framework.  And *this*, not Bayes, is the
<br>
REAL ultimate epistemology?
<br>
<p>I bet you and Eli never thought of that.  
<br>
<p>*Marc glances and Wilson and Yudkowsky*
<br>
<p>...only human *sigh*
<br>
<p><p><em>&gt; Epistemologists tend to forget that reality does not
</em><br>
<em>&gt; contain
</em><br>
<em>&gt; 'knowledge' any more than in contains 'flowers'; in
</em><br>
<em>&gt; fact in
</em><br>
<em>&gt; practice 'knowledge' is a much more difficult class
</em><br>
<em>&gt; of
</em><br>
<em>&gt; regularity to define.
</em><br>
<p>Fascinating.  I take it you're right.
<br>
<p><p><em>&gt; 
</em><br>
<em>&gt; I will keep it in mind in case I ever need to
</em><br>
<em>&gt; license your
</em><br>
<em>&gt; Gibberish Matrix Technology (TM) for use in
</em><br>
<em>&gt; producing
</em><br>
<em>&gt; meaningless yet superficially impressive press
</em><br>
<em>&gt; statements.
</em><br>
<em>&gt; Meanwhile I have to wonder if your real goal is to
</em><br>
<em>&gt; cement
</em><br>
<em>&gt; yourself as /the/ definitive, canonical crackpot
</em><br>
<em>&gt; that will
</em><br>
<em>&gt; be remembered as such for the rest of human history.
</em><br>
<p>What on Earth are you talking about?  At the moment
<br>
SL4 is just a tiny backwater messageboard somewhere on
<br>
the net that no one really cares about.  And Sing Inst
<br>
is only a small non-profit that few take seriously.
<br>
<p>You've become a conspiracy theorist now have you?  I'm
<br>
the biggest crack-pot in history and I've showed up at
<br>
SL4 specifically to cement my reputation.  Yeah,
<br>
right.
<br>
<p>Those in greenhouses shouldn't throw stones.  As far
<br>
as I know, Singularity Institute are doing some good
<br>
work but nothing there as yet been recognized in
<br>
academia as a 'major advance' or anything.  A bit rich
<br>
for you to run around dismissing everyone else as
<br>
'dabblers' (Eli's favourite derogatory term) or
<br>
'crack-pots' (Your favourite term).
<br>
<p><p><em>&gt; 
</em><br>
<em>&gt; Seriously, you've used just about the most
</em><br>
<em>&gt; indirectly
</em><br>
<em>&gt; grounded and hence fuzzily defined concepts in the
</em><br>
<em>&gt; human
</em><br>
<em>&gt; cognitive repertoire, both in the table and the
</em><br>
<em>&gt; supporting
</em><br>
<em>&gt; text. It's a standard human tendency to assume that
</em><br>
<em>&gt; the
</em><br>
<em>&gt; most abstract concepts have the most descriptive
</em><br>
<em>&gt; power, but
</em><br>
<em>&gt; as as several posters have pointed out /engineering,
</em><br>
<em>&gt; and AI
</em><br>
<em>&gt; in particular, does not work like that/. Your output
</em><br>
<em>&gt; to
</em><br>
<em>&gt; date hardly constrains the design space of
</em><br>
<em>&gt; implementations
</em><br>
<em>&gt; at all; I suspect it would take very little
</em><br>
<em>&gt; additional
</em><br>
<em>&gt; rationalisation to characterise any sufficiently
</em><br>
<em>&gt; complex,
</em><br>
<em>&gt; superficially plausible AGI architecture as obeying
</em><br>
<em>&gt; these
</em><br>
<em>&gt; principles (should one so desire). Nor does it make
</em><br>
<em>&gt; any
</em><br>
<em>&gt; detailed predictions on the behavior of AGI or
</em><br>
<em>&gt; proto-AGI
</em><br>
<em>&gt; systems, and as such it is worthless as a
</em><br>
<em>&gt; constructive or
</em><br>
<em>&gt; predictive theory.
</em><br>
<p>Um... let me point out that Sing Inst started with the
<br>
most fuzzily defined concept of the friggin
<br>
lot...Friendliness.  What the heck is that anyway? 
<br>
It's not even comprehensible to most people.
<br>
<p>I, on the other hand, start with 16 words fully
<br>
describing a friendly intelligence, which while fuzzy,
<br>
are at least comprehensible:
<br>
<p><a href="http://www.sl4.org/wiki/TheWay">http://www.sl4.org/wiki/TheWay</a>
<br>
<p>As to predictions, I made 10 falsifiable predictions
<br>
for fun in an earlier thread (where I listed 10
<br>
guesses):
<br>
<p><a href="http://www.sl4.org/archive/0501/10623.html">http://www.sl4.org/archive/0501/10623.html</a>
<br>
<p>By all means lets invite the posthumans around to
<br>
examine them and give their verdict.  They can then
<br>
contrast my ideas with you and Eli's.  I look forward
<br>
to a bit of light entertainment.
<br>
<p><p><em>&gt; 
</em><br>
<em>&gt; I suspect that your preconceptions will prevent you
</em><br>
<em>&gt; from
</em><br>
<em>&gt; extracting anything of value; you need a delicate
</em><br>
<em>&gt; combination of open mindedness, rigorous filtering
</em><br>
<em>&gt; for
</em><br>
<em>&gt; clue and creativity within logical constraints to
</em><br>
<em>&gt; elicit
</em><br>
<em>&gt; a constructive, predictive understanding of AGI from
</em><br>
<em>&gt; the
</em><br>
<em>&gt; AI literature.
</em><br>
<p>Interesting.  Well I imagine that you know what you're
<br>
talking here and that a lot of hard work and careful
<br>
thinking is required for sure, but I would have
<br>
thought that it's most important to have the correct
<br>
'top down strategy' first.
<br>
<p>Put it this way:  Suppose someone with no detailed
<br>
background knowledge of AGI theory hit on the correct
<br>
top down strategy leading to FAI.  Then I suppose that
<br>
all that would be required would be say 6 months of
<br>
intense full-time study of the books and journals and
<br>
they would have absorbed enough information to
<br>
actually implement the strategy and usher in the
<br>
Singularity.
<br>
<p>But the converse is not true.  Someone with a detailed
<br>
knowledge of AGI theory but no good top down strategy
<br>
could sit there sifting through the books and journals
<br>
for another 30 years and it would do them no good.  
<br>
<p>&nbsp;
<br>
<em>&gt; Entertainment value aside, I suppose we can both
</em><br>
<em>&gt; hope that
</em><br>
<em>&gt; it will serve as an object lesson in the value of
</em><br>
<em>&gt; philosophical
</em><br>
<em>&gt; intuition in the future, albeit from perfectly
</em><br>
<em>&gt; opposed
</em><br>
<em>&gt; motives.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;  * Michael Wilson
</em><br>
<em>&gt; 
</em><br>
<em>&gt; <a href="http://www.sl4.org/wiki/Starglider">http://www.sl4.org/wiki/Starglider</a>
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<p>Sure ;)
<br>
<p>=====
<br>
<p><p>Find local movie times and trailers on Yahoo! Movies.
<br>
<a href="http://au.movies.yahoo.com">http://au.movies.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10700.html">Dimitry Volfson: "AGI and Contact with &quot;Reality&quot;"</a>
<li><strong>Previous message:</strong> <a href="10698.html">Phil Goetz: "Re: Friendliness and social intelligence"</a>
<li><strong>In reply to:</strong> <a href="10668.html">Michael Wilson: "Re: Perspex Space"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10699">[ date ]</a>
<a href="index.html#10699">[ thread ]</a>
<a href="subject.html#10699">[ subject ]</a>
<a href="author.html#10699">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:22:53 MST
</em></small></p>
</body>
</html>
