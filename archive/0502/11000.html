<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: [agi] Future AGI's based on theorem-proving</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: [agi] Future AGI's based on theorem-proving">
<meta name="Date" content="2005-02-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: [agi] Future AGI's based on theorem-proving</h1>
<!-- received="Wed Feb 23 12:38:10 2005" -->
<!-- isoreceived="20050223193810" -->
<!-- sent="Wed, 23 Feb 2005 14:36:49 -0500" -->
<!-- isosent="20050223193649" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: [agi] Future AGI's based on theorem-proving" -->
<!-- id="JNEIJCJJHIEAILJBFHILEEGCEAAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="038f01c519d9$f4901c90$66adfc80@jh" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20[agi]%20Future%20AGI's%20based%20on%20theorem-proving"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Wed Feb 23 2005 - 12:36:49 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="11001.html">Jef Allbright: "Re: [agi] Future AGI's based on theorem-proving"</a>
<li><strong>Previous message:</strong> <a href="10999.html">Phil Goetz: "Re: ITSSIM (was Some new ideas on Friendly AI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11001.html">Jef Allbright: "Re: [agi] Future AGI's based on theorem-proving"</a>
<li><strong>Reply:</strong> <a href="11001.html">Jef Allbright: "Re: [agi] Future AGI's based on theorem-proving"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11000">[ date ]</a>
<a href="index.html#11000">[ thread ]</a>
<a href="subject.html#11000">[ subject ]</a>
<a href="author.html#11000">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Moshe,
<br>
<p><em>&gt; Now, lets say that AI0 and AI1 are both evaluating an improved
</em><br>
<em>&gt; system, AI'.
</em><br>
<em>&gt; If AI0 accepts AI', that implies that, to the best of its knowledge, AI'
</em><br>
<em>&gt; will not only be nice to puppies, but lead to puppy-niceness
</em><br>
<em>&gt; going forward
</em><br>
<em>&gt; in time as well (possible including any future AI''s). Now, a subgoal of
</em><br>
<em>&gt; this should be the ITSSIM property &quot;I will only take an action if I can
</em><br>
<em>&gt; prove that it is expected not to decrease safety.&quot;, because
</em><br>
<em>&gt; decreased safety
</em><br>
<em>&gt; (in the ITSSIM sense) should clearly lead to decreased
</em><br>
<em>&gt; puppy-niceness over
</em><br>
<em>&gt; the future course of the universe.
</em><br>
<p>This latter sentence is the part of your argument I don't agree with.
<br>
<p>It is not clear that decreased safety on the part of the AI is necessarily
<br>
going to decrease puppy-niceness.
<br>
<p>It could well be that the AI can prove that the way for it to maximize
<br>
expected puppy-niceness is for it to take a big risk by no longer being so
<br>
methodical -- by giving up on preceding each of its actions with a formal
<br>
proof, and just devoting its time to helping puppies rather than to proving
<br>
each of its actions.  In fact it will usually be the case that most goals
<br>
can be achieved better, on average, without going through so much formal
<br>
proof.
<br>
<p>The purpose of ITSSIM is to prevent such decisions.  The purpose of the
<br>
fancy &quot;emergency&quot; modifications to ITSSIM is to allow it to make such an
<br>
decision in cases of severe emergency.
<br>
<p>A different way to put your point, however, would be to speak not just about
<br>
averages but also about extreme values.  One could say &quot;The AI should act in
<br>
such a way as to provably increase the expected amount of puppy-niceness,
<br>
and provably not increase the odds that the probability of puppy-niceness
<br>
falls below 5%.&quot;  That would be closer to what ITSSIM does: it tries to
<br>
mitigate against the AI taking risks in the interest of maximizing expected
<br>
gain.
<br>
<p>The problem is that this relies really heavily on the correct generalization
<br>
of puppy-niceness.  Note that ITSSIM in itself doesn't rely on
<br>
generalization very heavily at all -- the only use of generalization is in
<br>
the measurement of &quot;amounts of knowledge.&quot;  I think that a safety mechanism
<br>
that relies heavily on the quality of generalization is, conceptually at
<br>
least, less safe than one that doesn't.  Of course this conclusion might be
<br>
disproven once we have a solid theoretical understanding of this type of
<br>
generalization.  I see no choice but to rely heavily on generalization in
<br>
the context of &quot;emergency measures&quot;, though, unfortunately...
<br>
<p>-- Ben
<br>
<p><p>-- Ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="11001.html">Jef Allbright: "Re: [agi] Future AGI's based on theorem-proving"</a>
<li><strong>Previous message:</strong> <a href="10999.html">Phil Goetz: "Re: ITSSIM (was Some new ideas on Friendly AI)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="11001.html">Jef Allbright: "Re: [agi] Future AGI's based on theorem-proving"</a>
<li><strong>Reply:</strong> <a href="11001.html">Jef Allbright: "Re: [agi] Future AGI's based on theorem-proving"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#11000">[ date ]</a>
<a href="index.html#11000">[ thread ]</a>
<a href="subject.html#11000">[ subject ]</a>
<a href="author.html#11000">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
