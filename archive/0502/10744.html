<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: AGI Prototying Project</title>
<meta name="Author" content="Michael Wilson (mwdestinystar@yahoo.co.uk)">
<meta name="Subject" content="RE: AGI Prototying Project">
<meta name="Date" content="2005-02-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: AGI Prototying Project</h1>
<!-- received="Sun Feb 20 15:07:45 2005" -->
<!-- isoreceived="20050220220745" -->
<!-- sent="Sun, 20 Feb 2005 22:07:21 +0000 (GMT)" -->
<!-- isosent="20050220220721" -->
<!-- name="Michael Wilson" -->
<!-- email="mwdestinystar@yahoo.co.uk" -->
<!-- subject="RE: AGI Prototying Project" -->
<!-- id="20050220220721.47485.qmail@web25305.mail.ukl.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="JNEIJCJJHIEAILJBFHILAELHDPAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Wilson (<a href="mailto:mwdestinystar@yahoo.co.uk?Subject=RE:%20AGI%20Prototying%20Project"><em>mwdestinystar@yahoo.co.uk</em></a>)<br>
<strong>Date:</strong> Sun Feb 20 2005 - 15:07:21 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10745.html">Michael Wilson: "Re: AGI Prototying Project"</a>
<li><strong>Previous message:</strong> <a href="10743.html">Michael Wilson: "RE: AGI Prototying Project"</a>
<li><strong>In reply to:</strong> <a href="10740.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10746.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<li><strong>Reply:</strong> <a href="10746.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10744">[ date ]</a>
<a href="index.html#10744">[ thread ]</a>
<a href="subject.html#10744">[ subject ]</a>
<a href="author.html#10744">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;&gt; Unfortunately very, very few people are qualified to work directly
</em><br>
<em>&gt;&gt; on AGI; my guess would be fewer than 1 in 10,000,000 (we haven't
</em><br>
<em>&gt;&gt; found many of these yet).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I agree that the percentage of people who have the right combination of
</em><br>
<em>&gt; skills and attitudes and interests for AGI work is very small, but that
</em><br>
<em>&gt; figure seems absurdly small to me.
</em><br>
<p>Sorry; wrong description, my fault. The estimate was actually of how
<br>
many people would be qualified to work on Friendly AI, which is to
<br>
say the probability of their being suitable for the SIAI's
<br>
implementation team. FAI is a higher bar than AGI; it requires the
<br>
same AI knowledge and raw intelligence, but it also rules out all
<br>
the easy ways out (i.e. probabilistic self-modification, brute force
<br>
GAs) and requires the right attitude to existential risk. Actually
<br>
developing FAI theory from scratch is even worse; I'm not aware of
<br>
anyone other than Eliezer who has made significent progress with it.
<br>
&nbsp;
<br>
<em>&gt; I can think of a few folks on this list who would probably be good
</em><br>
<em>&gt; contributors to an AGI project, IF they chose to devote enough of their
</em><br>
<em>&gt; time to it....
</em><br>
<p>Ditto. I can also think of a few folks already working on AGI who
<br>
would probably be good contributors to an FAI project, IF they chose
<br>
to change their approach to the problem.
<br>
<p><em>&gt;&gt; Speech recognition is a largely solved problem that was and is
</em><br>
<em>&gt;&gt; amenable to standard engineering methods. The key point is that
</em><br>
<em>&gt;&gt; it's well defined; we know exactly what we want, we just need
</em><br>
<em>&gt;&gt; to find algorithms that can do it.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I think the key point is that it's easier than AGI, not that it's
</em><br>
<em>&gt; more exactly defined.
</em><br>
<p>Speech recognition is a problem far smaller in scope than AGI, but
<br>
I think the type of definition is at least as important. The Apollo
<br>
project is a good example of a very difficult technical challenge
<br>
that was tractable because it was well defined and relatively easy
<br>
to break down into manageable chunks that could be tackled by narrow
<br>
specialists. For speech recognition we have representative training
<br>
sets detailing the expected input and output; we just have to work
<br>
out what the mapping function is. For artificial intelligence we
<br>
have no such representative set of problems; we can't characterise
<br>
exactly what we want the system to do in a black-box fashion.
<br>
&nbsp;
<br>
<em>&gt; I don't believe that ALL of us on this list would just waste
</em><br>
<em>&gt; your time with useless discussions, if you were to post your
</em><br>
<em>&gt; detailed AGI design ideas publicly.
</em><br>
<p>No, but it's easy to get sucked into trying to answer everyone.
<br>
<p><em>&gt; CV is an interesting philosophical theory that so far as I can
</em><br>
<em>&gt; tell has very little practical value.
</em><br>
<p>It's true that there aren't any implementation details provided,
<br>
but wouldn't you agree that it is a clear statement of intent?
<br>
<p><em>&gt; To state with such confidence that any AGI not based on this
</em><br>
<em>&gt; particular not-fully-baked philosophical theory &quot;will destroy
</em><br>
<em>&gt; the world in a randomly chosen fashion&quot; is just ridiculous.
</em><br>
<p>True, which is why I didn't make that statement. If you recall
<br>
Eliezer's breakdown of FAI, there are the structural aspects
<br>
required to make an AGI do anything predictable, and then there
<br>
is a description of what you want it to do. Technically the
<br>
structural aspects (maintaining an abstract invariant that
<br>
doesn't automatically wipe out the human race) aren't FAI; you'd
<br>
need the same thing to implement any personal agenda. If you
<br>
converted your 'joyous growth' philosophy into a provably stable
<br>
goal system I'd personally consider it a valid FAI theory, though
<br>
I'd still prefer CV because I don't trust any one human to come
<br>
up with universal moral principles.
<br>
&nbsp;
<br>
<em>&gt;&gt; Because the inner circle are known to be moral,
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Hmmm... nothing personal, but that sounds like a dangerous assumption!!
</em><br>
<p>Again, yes this is a dangerous assumption. I don't like it and I'm
<br>
one of the people I'm proposing to trust with the responsibility.
<br>
However I don't see any alternative; you're asking people to believe
<br>
that you're moral enough to be trusted with AGI, James Rogers is
<br>
asking us to believe that he is and so on. The only slight advantage
<br>
the SIAI has in this area is that we're proposing to have a diverse
<br>
team of implementers all of whom have a personal veto on continuing
<br>
with the project. It's a slight advantage because groupthink can
<br>
easily set in even when you're watching for it, but it's better than
<br>
a single person laying down the moral principles for a seed AI.
<br>
&nbsp;
<br>
&nbsp;* Michael Wilson
<br>
<p><p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<br>
___________________________________________________________ 
<br>
ALL-NEW Yahoo! Messenger - all new features - even more fun! <a href="http://uk.messenger.yahoo.com">http://uk.messenger.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10745.html">Michael Wilson: "Re: AGI Prototying Project"</a>
<li><strong>Previous message:</strong> <a href="10743.html">Michael Wilson: "RE: AGI Prototying Project"</a>
<li><strong>In reply to:</strong> <a href="10740.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10746.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<li><strong>Reply:</strong> <a href="10746.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10744">[ date ]</a>
<a href="index.html#10744">[ thread ]</a>
<a href="subject.html#10744">[ subject ]</a>
<a href="author.html#10744">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Tue Feb 21 2006 - 04:22:53 MST
</em></small></p>
</body>
</html>
