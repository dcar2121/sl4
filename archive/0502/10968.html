<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: ITSSIM (was Some new ideas on Friendly AI)</title>
<meta name="Author" content="David Hart (dhart@atlantisblue.com.au)">
<meta name="Subject" content="Re: ITSSIM (was Some new ideas on Friendly AI)">
<meta name="Date" content="2005-02-21">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: ITSSIM (was Some new ideas on Friendly AI)</h1>
<!-- received="Mon Feb 21 23:12:58 2005" -->
<!-- isoreceived="20050222061258" -->
<!-- sent="Tue, 22 Feb 2005 17:12:09 +1100" -->
<!-- isosent="20050222061209" -->
<!-- name="David Hart" -->
<!-- email="dhart@atlantisblue.com.au" -->
<!-- subject="Re: ITSSIM (was Some new ideas on Friendly AI)" -->
<!-- id="421ACD39.4060206@atlantisblue.com.au" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="JNEIJCJJHIEAILJBFHILAEPMDPAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> David Hart (<a href="mailto:dhart@atlantisblue.com.au?Subject=Re:%20ITSSIM%20(was%20Some%20new%20ideas%20on%20Friendly%20AI)"><em>dhart@atlantisblue.com.au</em></a>)<br>
<strong>Date:</strong> Mon Feb 21 2005 - 23:12:09 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10969.html">Damien Broderick: "Re: Overconfidence and meta-rationality"</a>
<li><strong>Previous message:</strong> <a href="10967.html">Tennessee Leeuwenburg: "Re: Overconfidence and meta-rationality"</a>
<li><strong>In reply to:</strong> <a href="10964.html">Ben Goertzel: "Some new ideas on Friendly AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10977.html">Ben Goertzel: "RE: ITSSIM (was Some new ideas on Friendly AI)"</a>
<li><strong>Reply:</strong> <a href="10977.html">Ben Goertzel: "RE: ITSSIM (was Some new ideas on Friendly AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10968">[ date ]</a>
<a href="index.html#10968">[ thread ]</a>
<a href="subject.html#10968">[ subject ]</a>
<a href="author.html#10968">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi Ben,
<br>
<p>I understand how ITSSIM  is designed to &quot;optimize for S&quot;, and also how 
<br>
it might work in practice with the one of many possible qualitative 
<br>
definitions of &quot;Safety&quot; being the concept that if we [humans] desire 
<br>
that our mind-offspring respect our future &quot;growth, joy and choice&quot;, the 
<br>
next N+1 incrementally improved generation should want the same for 
<br>
themselves and their mind-offspring.
<br>
<p>In such a system, supergoals (like, e.g., CV) and their subgoals, 
<br>
interacting with their environments, generate A (possible actions), to 
<br>
which R (safety rule) is applied.
<br>
<p>I'm very curious to learn how S and SG might interact -- might one 
<br>
eventually dominate the other, or might they become co-attractors?
<br>
<p>Of course, we're still stuck with quantifying this and other definitions 
<br>
for &quot;Safety&quot;, including acceptable margins.
<br>
<p>NB: I believe we cannot create an S or an SG that are provably 
<br>
invariant, but that both should be cleverly designed with the highest 
<br>
probability of being invariant in the largest possible |U| we can muster 
<br>
computationally (to our best knowledge for the longest possible 
<br>
extrapolation, which may, arguably, still be too puny to be comfortably 
<br>
&quot;safe&quot; or &quot;friendly&quot;).
<br>
<p>Perhaps the matrix of S/_B /, S/_E /, S/_N  / and SG/_B /, SG/_E /, 
<br>
SG/_N /should duke-it-out in simulation. Although, at some point, we 
<br>
will simply need to choose our S and our SG and take our chances, taking 
<br>
into account the probability that Big Red, True Blue, et al, may not 
<br>
have terribly conservative values for S or SG slowing their progress. :-(
<br>
<p>David
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10969.html">Damien Broderick: "Re: Overconfidence and meta-rationality"</a>
<li><strong>Previous message:</strong> <a href="10967.html">Tennessee Leeuwenburg: "Re: Overconfidence and meta-rationality"</a>
<li><strong>In reply to:</strong> <a href="10964.html">Ben Goertzel: "Some new ideas on Friendly AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10977.html">Ben Goertzel: "RE: ITSSIM (was Some new ideas on Friendly AI)"</a>
<li><strong>Reply:</strong> <a href="10977.html">Ben Goertzel: "RE: ITSSIM (was Some new ideas on Friendly AI)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10968">[ date ]</a>
<a href="index.html#10968">[ thread ]</a>
<a href="subject.html#10968">[ subject ]</a>
<a href="author.html#10968">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
