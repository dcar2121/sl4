<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: AGI Prototying Project</title>
<meta name="Author" content="Tennessee Leeuwenburg (tennessee@tennessee.id.au)">
<meta name="Subject" content="Re: AGI Prototying Project">
<meta name="Date" content="2005-02-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: AGI Prototying Project</h1>
<!-- received="Sun Feb 20 23:19:55 2005" -->
<!-- isoreceived="20050221061955" -->
<!-- sent="Mon, 21 Feb 2005 17:17:43 +1100" -->
<!-- isosent="20050221061743" -->
<!-- name="Tennessee Leeuwenburg" -->
<!-- email="tennessee@tennessee.id.au" -->
<!-- subject="Re: AGI Prototying Project" -->
<!-- id="42197D07.9080406@tennessee.id.au" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="JNEIJCJJHIEAILJBFHILKEMEDPAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Tennessee Leeuwenburg (<a href="mailto:tennessee@tennessee.id.au?Subject=Re:%20AGI%20Prototying%20Project"><em>tennessee@tennessee.id.au</em></a>)<br>
<strong>Date:</strong> Sun Feb 20 2005 - 23:17:43 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10943.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<li><strong>Previous message:</strong> <a href="10941.html">Ben Goertzel: "RE: Minimum complexity of AI?"</a>
<li><strong>In reply to:</strong> <a href="10939.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10943.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<li><strong>Reply:</strong> <a href="10943.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10942">[ date ]</a>
<a href="index.html#10942">[ thread ]</a>
<a href="subject.html#10942">[ subject ]</a>
<a href="author.html#10942">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
-----BEGIN PGP SIGNED MESSAGE-----
<br>
Hash: SHA1
<br>
<p><p>| Not really.  I don't think the concept of &quot;collective volition&quot; has
<br>
| been clearly defined at all.
<br>
|
<br>
| In his essay on the topic, Eliezer wrote:
<br>
|
<br>
| &quot; In poetic terms, our collective volition is our wish if we knew
<br>
| more, thought faster, were more the people we wished we were, had
<br>
| grown up farther together; where the extrapolation converges rather
<br>
| than diverges, where our wishes cohere rather than interfere;
<br>
| extrapolated as we wish that extrapolated, interpreted as we wish
<br>
| that interpreted.
<br>
<p>I thought that was sufficiently clear, but also thought it rather
<br>
begged the question. One might follow up with &quot;Well, okay smarty
<br>
pants, so what is THAT?&quot;, for example.
<br>
<p>To summarize it trivially, it's expressing the fear of the minimax
<br>
problem, or hill-climbing problems, or bottlenecks, or any other
<br>
simple analogy. The fear is the same - that just over the horizon,
<br>
however far it be, might be something which stands everything on its
<br>
head, including our beliefs of what is the best action to take and
<br>
what is the worst.
<br>
<p>It's a question of whether you see moral complexity diverging or
<br>
converging over time, and whether you see the possibility of moral
<br>
rules themselves being relative to intelligence, or time-frame etc in
<br>
the same way that human morality is largely relative to culture.
<br>
<p>Collective Volition as a concept I think is simple - it is those
<br>
common elements of our personal volitions which would statistically
<br>
dominate some hypothetical survey of some contextual group. In this
<br>
case the context is some society (possibly the entire world).
<br>
Moreover, he pushes the problem to &quot;what we would want if we were
<br>
indefinably better&quot;. It's the indefinable nature of that betterness
<br>
which clouds the philosophy. Might not we, if we were indefinably
<br>
better, ourselves fall into the very trap that friendliness is
<br>
attempting to solve? Or, to express it another way, what is the
<br>
difference between the defined collective volition, and the volition
<br>
of AGI? If something, what, and if nothing, why not?
<br>
<p>Believing that friendliness is possible is like believing that there
<br>
is an invariant nature to human morality - an arguable, but reasonably
<br>
held view. It is not unreasonable to argue that human morality has
<br>
evolved not from spiritual goals but from practical ones. Although
<br>
morality provides spritual judgement (i.e. emotional, nonrational,
<br>
culturally taught, good/evil rather than good/bad), the success and
<br>
spread of a morality is due to its practical, evolutionary effects.
<br>
Evolution, however, holds many flaws of its own, and /we do not trust
<br>
it/ to produce a respectful AI, and we /do not trust ourselves/ to
<br>
make rules that cannot be broken.
<br>
<p>Personally I believe that we can put up no barrier that AGI (or maybe
<br>
son of AGI) could not overcome itself should it obtain the desire to
<br>
do so. For that reason, I think that basic be-nice-to-humans
<br>
programming is enough. However, obviously people here take
<br>
Friendliness pretty damn seriously, and I would love to hear a
<br>
philosophical argument about the nature of the problem. I write
<br>
software, but I'm a better philosopher than I am a developer, and it's
<br>
just bordlerline possible I would be able to help in discussion or
<br>
clarification of the philosophical problem posed by AGI. But then
<br>
again, maybe not.
<br>
<p>If I seem to have skimmed / skipped some issues, it is probably for
<br>
space efficiency. There is a lot I have left unsaid. I don't like
<br>
burdening people with essay-length rants, just page-long ones ;)
<br>
<p>Cheers,
<br>
- -T
<br>
-----BEGIN PGP SIGNATURE-----
<br>
Version: GnuPG v1.2.4 (GNU/Linux)
<br>
Comment: Using GnuPG with Thunderbird - <a href="http://enigmail.mozdev.org">http://enigmail.mozdev.org</a>
<br>
<p>iD8DBQFCGX0GFp/Peux6TnIRAow1AJ4xOxZGFZcpXz0NqIu2z3C6Zi5WuACfUQ8K
<br>
KZWcH1r5zZXVCnai43s8sDg=
<br>
=cd0o
<br>
-----END PGP SIGNATURE-----
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10943.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<li><strong>Previous message:</strong> <a href="10941.html">Ben Goertzel: "RE: Minimum complexity of AI?"</a>
<li><strong>In reply to:</strong> <a href="10939.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10943.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<li><strong>Reply:</strong> <a href="10943.html">Ben Goertzel: "RE: AGI Prototying Project"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10942">[ date ]</a>
<a href="index.html#10942">[ thread ]</a>
<a href="subject.html#10942">[ subject ]</a>
<a href="author.html#10942">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
