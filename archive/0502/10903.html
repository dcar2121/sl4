<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: State of the SI's AI and FAI research</title>
<meta name="Author" content="Eliezer Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: State of the SI's AI and FAI research">
<meta name="Date" content="2005-02-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: State of the SI's AI and FAI research</h1>
<!-- received="Tue Feb 15 11:13:10 2005" -->
<!-- isoreceived="20050215181310" -->
<!-- sent="Tue, 15 Feb 2005 10:12:45 -0800" -->
<!-- isosent="20050215181245" -->
<!-- name="Eliezer Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: State of the SI's AI and FAI research" -->
<!-- id="42123B9D.9040201@pobox.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="BAY22-DAV128DB97A450ACD45FCF5FEA76B0@phx.gbl" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20State%20of%20the%20SI's%20AI%20and%20FAI%20research"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Tue Feb 15 2005 - 11:12:45 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="10904.html">sam kayley: "Re: State of the SI's AI and FAI research"</a>
<li><strong>Previous message:</strong> <a href="10902.html">Aaron McBride: "NEWS: CNN on Kurzweil"</a>
<li><strong>In reply to:</strong> <a href="10901.html">Slawomir Paliwoda: "State of the SI's AI and FAI research"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10904.html">sam kayley: "Re: State of the SI's AI and FAI research"</a>
<li><strong>Reply:</strong> <a href="10904.html">sam kayley: "Re: State of the SI's AI and FAI research"</a>
<li><strong>Reply:</strong> <a href="10905.html">Jay Dugger: "Re: State of the SI's AI and FAI research"</a>
<li><strong>Reply:</strong> <a href="10906.html">Slawomir Paliwoda: "Re: State of the SI's AI and FAI research"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10903">[ date ]</a>
<a href="index.html#10903">[ thread ]</a>
<a href="subject.html#10903">[ subject ]</a>
<a href="author.html#10903">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Slawomir Paliwoda wrote:
<br>
<em>&gt; I'm curious about the amount of theoretical progress SI has made since CFAI
</em><br>
<em>&gt; and LOGI in the areas of FAI and AI research.
</em><br>
<p>How do you measure theoretical progress?  In LOGI there are only a few 
<br>
passing mentions of Bayes or probability theory, which today seems utterly 
<br>
alien to me.  In &quot;A Technical Explanation of Technical Explanation&quot;, the 
<br>
most recent work I published, there is no explicit discussion of LOGI or 
<br>
CFAI; but I think that if one read TechExp and understood it, and then read 
<br>
LOGI or CFAI, the one would see that LOGI and CFAI cannot possibly be 
<br>
enough because they are not technical models - and that is progress.  There 
<br>
are those who will say, &quot;But, LOGI is not technical!&quot;, though they cannot 
<br>
give a technical definition of what they mean by the criticism.  TechExp 
<br>
gives a mathematical definition of why the criticism is correct, and that 
<br>
is progress.  It says something about the form a final theory needs to take.
<br>
<p>My thinking has changed dramatically.  I just don't know how to measure 
<br>
that.  Progress is not the same as visible progress.  Now that I have a 
<br>
better idea of what it means to understand something, I also understand a 
<br>
little better what it means to &quot;explain&quot; something, and it's clear that my 
<br>
earlier explanations failed - people did not apply or build on the 
<br>
knowledge.  So now I try to explain simpler things at greater length, for 
<br>
that it is better to understand just one thing than to be confused by two 
<br>
dozen.  But the flip side is that my progress past LOGI is something that I 
<br>
wouldn't try to explain until the reader had already understood basic 
<br>
things on the order of Bayesian probability, expected utility, and the 
<br>
character of mathematical logic, and of these things I have so far only 
<br>
tried to explain my thoughts about Bayesian probability.  So there is 
<br>
progress but it is not easily visible progress.  If you look at my recent 
<br>
works they have a different character than my earlier works and in some 
<br>
cases I have given mathematical explanations of what's wrong with my 
<br>
earlier works.  That's visible progress.
<br>
<p><em>&gt; How far is SI currently from
</em><br>
<em>&gt; the point at which its programmers can begin writing code?
</em><br>
<p>How on Earth am I supposed to know this?  I could make up a number.  Where 
<br>
would it come from?  I hope I am not to be penalized if, unlike other 
<br>
futurists, I know better than to make stuff up.
<br>
<p><em>&gt; And, generally,
</em><br>
<em>&gt; what else besides completing theoretical framework(s) needs to happen 
</em><br>
<em>&gt; before SI is ready to launch its project?
</em><br>
<p>1) Framework
<br>
2) People
<br>
3) Funding
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="10904.html">sam kayley: "Re: State of the SI's AI and FAI research"</a>
<li><strong>Previous message:</strong> <a href="10902.html">Aaron McBride: "NEWS: CNN on Kurzweil"</a>
<li><strong>In reply to:</strong> <a href="10901.html">Slawomir Paliwoda: "State of the SI's AI and FAI research"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="10904.html">sam kayley: "Re: State of the SI's AI and FAI research"</a>
<li><strong>Reply:</strong> <a href="10904.html">sam kayley: "Re: State of the SI's AI and FAI research"</a>
<li><strong>Reply:</strong> <a href="10905.html">Jay Dugger: "Re: State of the SI's AI and FAI research"</a>
<li><strong>Reply:</strong> <a href="10906.html">Slawomir Paliwoda: "Re: State of the SI's AI and FAI research"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#10903">[ date ]</a>
<a href="index.html#10903">[ thread ]</a>
<a href="subject.html#10903">[ subject ]</a>
<a href="author.html#10903">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:50 MDT
</em></small></p>
</body>
</html>
