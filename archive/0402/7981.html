<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Positive Transcension 2</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Positive Transcension 2">
<meta name="Date" content="2004-02-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Positive Transcension 2</h1>
<!-- received="Fri Feb 20 09:34:15 2004" -->
<!-- isoreceived="20040220163415" -->
<!-- sent="Fri, 20 Feb 2004 11:41:22 -0500" -->
<!-- isosent="20040220164122" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Positive Transcension 2" -->
<!-- id="BMECIIDGKPGNFPJLIDNPIEMACNAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="4036C6E1.25283.D5D146@localhost" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Positive%20Transcension%202"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Fri Feb 20 2004 - 09:41:22 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7982.html">Philip Sutton: "The &quot;democracy&quot; question"</a>
<li><strong>Previous message:</strong> <a href="7980.html">Christian Szegedy: "Re: Positive Transcension 2"</a>
<li><strong>In reply to:</strong> <a href="7978.html">Philip Sutton: "RE: Positive Transcension 2"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7984.html">Philip Sutton: "RE: Positive Transcension 2"</a>
<li><strong>Reply:</strong> <a href="7984.html">Philip Sutton: "RE: Positive Transcension 2"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7981">[ date ]</a>
<a href="index.html#7981">[ thread ]</a>
<a href="subject.html#7981">[ subject ]</a>
<a href="author.html#7981">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Philip,
<br>
<p>OK -- You win!!
<br>
<p>I think you made a lot of wrong points in your response to my essay, but you
<br>
made one VERY important point which -- though it occurred to me before --
<br>
was nowhere near prominent enough in my mind when I wrote the Positive
<br>
Transcension essay...
<br>
<p>My article was oriented toward the open exploration of ideas and
<br>
possibilities -- BUT some of these ideas are too shocking for most people to
<br>
deal with.  This is in line with Eliezer's &quot;shock level&quot; idea that gave this
<br>
email list its name.
<br>
<p>The plus of discussing things openly on a list like this is that I get good
<br>
feedback from smart, interested people who have also thought about these
<br>
issues.
<br>
<p>The minus is that an e-mail trail is left, that conceivably could cause
<br>
trouble among other humans who don't share the common conceptual mindset of
<br>
the transhumanist community...
<br>
<p>Your good point is that
<br>
<p>IF launching a Transcension of type Y is the best strategy according to
<br>
Ethical System E
<br>
<p>AND the odds of successfully launching a Transcension are a lot higher with
<br>
the acceptance of a greater number of humans
<br>
<p>THEN it is worth exploring whether either
<br>
<p>a) a Transcension of type Y is acceptable to the vast majority of humans, or
<br>
if not whether
<br>
b) there is a Transcension of type Y' that is also a very good outcome
<br>
according to E, but that IS acceptable a lot more humans
<br>
<p><p>If such a Transcension Y' is found, then it's a lot better to pursue Y' than
<br>
Y, because the odds of achieving Y' are significantly greater.
<br>
<p>If
<br>
<p>Y = a Transcension supporting Voluntary Joyous Growth
<br>
<p>and
<br>
<p>Y' = a Transcension supporting Voluntary Joyous Growth, but making every
<br>
possible effort to enable all humans to continue to have the opportunity to
<br>
live life on Earth as-is, if they wish to
<br>
<p>then it may well be that the conditions of the above are met.
<br>
<p>I think you overestimate the extent to which Y' is acceptable to the vast
<br>
mass of humans.  After all, as I said, if people will outlaw hallucinogens
<br>
and stem cell research and require government approval for putting chips in
<br>
one's own brain -- and plague Alcor with endless lawsuits -- then it's naive
<br>
to think people won't stand in the way of the Transcension.
<br>
<p>But, definitely Y' is easier to sell than Y, and will create LESS
<br>
opposition, thus increasing odds of achievement.
<br>
<p>However, this doesn't get around my skepticism as to the possibility of
<br>
guaranteeing that &quot;all humans [will] continue to have the opportunity to
<br>
live life on Earth as-is, if they wish to.&quot;   The problem is, I think it is
<br>
not very easy to make this guarantee about post-Transcension dynamics.  If
<br>
I'm right, then the options come down to,
<br>
<p>a) Lie about it, and convince people that they CAN have this guarantee after
<br>
all, or
<br>
<p>b) [Try to] convince people that the risk is acceptable given the rewards
<br>
and the other risks at play
<br>
<p>c) Launch a Transcension against most peoples' will
<br>
<p><p>So, ethically, the best hope is that through a systematic process of
<br>
education, the majority of humans will come to realization b) ... that
<br>
although there are no guarantees, the rewards are worth the risks.  Then
<br>
democracy is satisfied, growth is satisfied, etc. etc.  But this kind of
<br>
education is going to prove very hard to do -- though for sure a very very
<br>
worthwhile endeavor...
<br>
<p>-- Ben
<br>
<p><p><p><p><p><p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Positive%20Transcension%202">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Positive%20Transcension%202">owner-sl4@sl4.org</a>]On Behalf Of Philip
</em><br>
<em>&gt; Sutton
</em><br>
<em>&gt; Sent: Friday, February 20, 2004 11:48 AM
</em><br>
<em>&gt; To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Positive%20Transcension%202">sl4@sl4.org</a>
</em><br>
<em>&gt; Subject: RE: Positive Transcension 2
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Hi  Ben,
</em><br>
<em>&gt;
</em><br>
<em>&gt; My  guess is that, optimistically, it is going to be a decade or
</em><br>
<em>&gt; two before
</em><br>
<em>&gt; we see AGIs capabable of driving a fast take-off to
</em><br>
<em>&gt; transcension/singularity or whatever.  During this time the AGIs
</em><br>
<em>&gt; together with their human designers/ programmer/ trainers/ educators /
</em><br>
<em>&gt; etc. are going to have to co-exisit with the rest of humanity - so that
</em><br>
<em>&gt; resources can be devoted to the support of AGI (computing
</em><br>
<em>&gt; power/design&amp;programming skill etc.) and the simple right to continue
</em><br>
<em>&gt; with the work/to have AGIs operating is granted by society.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If during this time people come to fear AGIs (or their potential) they
</em><br>
<em>&gt; may engage in all sorts of blocking activities (legal/direct
</em><br>
<em>&gt; action etc.) of
</em><br>
<em>&gt; a more or less extreme nature. Also people developing AGIs (and the
</em><br>
<em>&gt; AGIs themselves) will need supporters to defend AGI development so
</em><br>
<em>&gt; that the work and the AGIs can continue.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If AGI promoters are projecting vibes that they are not 100% behind the
</em><br>
<em>&gt; protection/welfare of humans and that somehow AGIs might be
</em><br>
<em>&gt; engaged in the 'demise of humanity' then some people might get a bit
</em><br>
<em>&gt; jumpy and might flip into active opposition mode - and you have to
</em><br>
<em>&gt; admit - if they did it would not be surprising!
</em><br>
<em>&gt;
</em><br>
<em>&gt; Ben, I really admire the way that you have been openly exploring a
</em><br>
<em>&gt; huge number of the issues related to the development of AGI via the
</em><br>
<em>&gt; email lists and in other ways - so I would hate to see your style, or
</em><br>
<em>&gt; anyone else's, cramped by a need for formulaic 'political correctness'.
</em><br>
<em>&gt; But I think you need to keep putting yourself in the shoes of other
</em><br>
<em>&gt; people who are not closely involved in the development of AGI - you've
</em><br>
<em>&gt; got to be able to feel what they might feel (after the style of the
</em><br>
<em>&gt; universal mind simulator! :)
</em><br>
<em>&gt;
</em><br>
<em>&gt; Evolution (even the radical-leap forward-variety represented for
</em><br>
<em>&gt; example by the first trilobite with eyes, the first human with advanced
</em><br>
<em>&gt; language and the first AGI with competent self-upgrading skills)
</em><br>
<em>&gt; is still a
</em><br>
<em>&gt; game of making steps where *each one* is viable so that future
</em><br>
<em>&gt; potential can survive the present moment to be able to unfold later.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I think the safest way to get to AGIs with competently self-upgrading
</em><br>
<em>&gt; skills going is to make a compact with humanity (all of them/us - even
</em><br>
<em>&gt; including the vast mass of ignorant people!) that AGIs will be
</em><br>
<em>&gt; developed in a way that does not violate people's desire for continued
</em><br>
<em>&gt; exisitence and desire for autonomy over the nature of their lives.  If
</em><br>
<em>&gt; AGIs are designed/ trained so that they do not threaten the exisitence/
</em><br>
<em>&gt; autonomy desires of people then I think there is a much better chance
</em><br>
<em>&gt; that enough people will support or tolerate the creation of AGIs so that
</em><br>
<em>&gt; AGIs actually emerge and persist long enough to be able to look after
</em><br>
<em>&gt; themselves and be able to assure their own survival.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I'm NOT pushing for political correctness - I'm pushing for a politically-
</em><br>
<em>&gt; savvy and compassionately-sensitive approach to co-exisitence
</em><br>
<em>&gt; between the AGI developers/AGI and the rest of humanity.
</em><br>
<em>&gt;
</em><br>
<em>&gt; As I mentioned a moment ago, I admire your intellectual openness -
</em><br>
<em>&gt; and I'm not saying this to suck up to you.  It's how I feel.
</em><br>
<em>&gt;
</em><br>
<em>&gt; But I think you have to be very sensitive to the feelings of
</em><br>
<em>&gt; others - your
</em><br>
<em>&gt; &quot;Encouraging positive transcension&quot; article has a major pre-occupation
</em><br>
<em>&gt; with the notion of the demise of humanity as a conceivable outcome of
</em><br>
<em>&gt; the development of AGI - and in saying this I'm not saying that you are
</em><br>
<em>&gt; actually advocating the demise of humanity.  But run the text through
</em><br>
<em>&gt; the Novamente inference engine and see if I'm wrong about the
</em><br>
<em>&gt; preoccupation!
</em><br>
<em>&gt;
</em><br>
<em>&gt; I think this line-of-thought/this outcome (the demise of humanity
</em><br>
<em>&gt; through either evolution to something else or through reassignment of
</em><br>
<em>&gt; mass energy(!!)) is simply not necessary to the development of AGI or
</em><br>
<em>&gt; the wonderous flowering of the universe.  Once AGIs have access to
</em><br>
<em>&gt; the physical environment, production processes and transport -
</em><br>
<em>&gt; especially if they can access places off-earth - they will not be 'held
</em><br>
<em>&gt; back' by people.  But leading up to this stage, AGIs and their human
</em><br>
<em>&gt; designers/developers/trainers etc. could be held back or totally blocked
</em><br>
<em>&gt; if an anti-AGI panic set in.
</em><br>
<em>&gt;
</em><br>
<em>&gt; That is why I think humans working on AGI development and (later the
</em><br>
<em>&gt; AGIs themselves) need to make (and honour) a pact with humanity that
</em><br>
<em>&gt; the AGIs will not threaten humans exisitence and lifestyle autonomy.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If the AGIs can also help humanity to solve our many current problems
</em><br>
<em>&gt; so much the better - then there will be a sound basis for mutal
</em><br>
<em>&gt; recognition and cooperation.
</em><br>
<em>&gt;
</em><br>
<em>&gt; This humanity-AGI pact is a different thing from the problem of creating
</em><br>
<em>&gt; 'friendly' ethics in AGI.  I have no skills in AGI design or development
</em><br>
<em>&gt; but your intuition that 'friendliness' will be easier to implant
</em><br>
<em>&gt; and retain
</em><br>
<em>&gt; through massive cycles of self-modification if it is more all-
</em><br>
<em>&gt; encompassing or more generally stated makes sense to me.  So I'm
</em><br>
<em>&gt; suggesting that we need TWO processes:
</em><br>
<em>&gt;
</em><br>
<em>&gt; 1.  building in meta-friendliness towards all sentients or even to all
</em><br>
<em>&gt;     life that unfailingly generates, amongst other responses,
</em><br>
<em>&gt;     friendliness towards humans.
</em><br>
<em>&gt;
</em><br>
<em>&gt; 2.  a conscious pact with humanity that AGIs with respect humans desire
</em><br>
<em>&gt;     to exist and have lifestyle autonomy/self-determination.
</em><br>
<em>&gt;
</em><br>
<em>&gt; This pact is necessary in my view to reassure people that tolerating or
</em><br>
<em>&gt; supporting the emergence of AGIs in not a threat to themselves or their
</em><br>
<em>&gt; children or humanity in general.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If as a consequence of the freedom protected under this this pact,
</em><br>
<em>&gt; some or all people decide to turn their back on the possibilities of
</em><br>
<em>&gt; transcension *for themselves* it doesn't matter in the wider sweep of
</em><br>
<em>&gt; cosmic history. Personally I think a large number of people *will* avail
</em><br>
<em>&gt; themselves of the benefits of transcension - if for no other reason than
</em><br>
<em>&gt; to extend their lives.  Many people will also be excited at the prospect
</em><br>
<em>&gt; of communicating with advanced AGIs and many people will want to be
</em><br>
<em>&gt; able to personally tap the wonders of intellectual expansion that come
</em><br>
<em>&gt; from augmentation or uploading.
</em><br>
<em>&gt;
</em><br>
<em>&gt; But if other people choose not to go this way, if they even wanted to
</em><br>
<em>&gt; stay exactly as they are, it doesn't matter two hoots - it should
</em><br>
<em>&gt; be their
</em><br>
<em>&gt; choice.  I don't think AGI developers/promoters should project one iota
</em><br>
<em>&gt; of concern about people making such a conservative choice.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I think the AGI-human pact could start off as a one way offer - offered
</em><br>
<em>&gt; by the AGI development community freely and unilaterally to the rest of
</em><br>
<em>&gt; the community.  If the heat builds up on AGI development then it might
</em><br>
<em>&gt; be necessary later to make a formal two-way pact via the formal
</em><br>
<em>&gt; political processes operating around the globe at the time.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Can I clarify - the whole of the foregoing is NOT premised on the
</em><br>
<em>&gt; simple notion that the preservation of humanity is paramount over
</em><br>
<em>&gt; anything else in the universe.  What I'm saying is more prosaic than
</em><br>
<em>&gt; that.......if you want the least-hassle path to the creation of self-
</em><br>
<em>&gt; upgrading AGI then my intuition is that this is best facilitated by an
</em><br>
<em>&gt; historical pact that AGIs will be designed so that as an emergent of
</em><br>
<em>&gt; their ethics they are unfailingly friendly to people - allowing humans to
</em><br>
<em>&gt; continue to exist and shape their own lifestyles.  I do not see humans
</em><br>
<em>&gt; as the centre of the universe.  I don't care personally if they
</em><br>
<em>&gt; evolve into
</em><br>
<em>&gt; something that I would not recognise as being like humanity-2004 style.
</em><br>
<em>&gt; But I just want personally and for my children and for their descendents
</em><br>
<em>&gt; and for other people and their descendents the freedom to exist and
</em><br>
<em>&gt; shape our lifestyles.  My guess also is that if there are other sentients
</em><br>
<em>&gt; around the universe many of them would also be likely to want this sort
</em><br>
<em>&gt; of freedom.
</em><br>
<em>&gt;
</em><br>
<em>&gt; -------
</em><br>
<em>&gt;
</em><br>
<em>&gt; Ben, it seems to me that your favoured ethical structure is that all (?)
</em><br>
<em>&gt; AGIs should embody a core ethical commitment to &quot;voluntary joyous
</em><br>
<em>&gt; growth&quot; or some variant of this?
</em><br>
<em>&gt;
</em><br>
<em>&gt; My feeling is that we should allow for a greater diversity of prime goals
</em><br>
<em>&gt; than this and that if there is a greater diversity then it is
</em><br>
<em>&gt; necessary to
</em><br>
<em>&gt; build in friendliness as an unfailing companion of whatever other goals
</em><br>
<em>&gt; the AGIs might have.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I think it would be relatively easy to get concensus amongst people that
</em><br>
<em>&gt; AGIs (should they exist) should be friendly to people.  But beyond that
</em><br>
<em>&gt; human consensus will be hard to find - even on the SL4 list or the AGI
</em><br>
<em>&gt; list.  I don't see this as a problem.  There will be enough people
</em><br>
<em>&gt; involved in AGI development who are motivated to see the wonderous
</em><br>
<em>&gt; complexity and patterns of the universe unfold and so I'm sure they will
</em><br>
<em>&gt; ensure that a fair number of AGIs are motivated to pursue &quot;voluntary
</em><br>
<em>&gt; joyous growth&quot;.  But there are lots of other
</em><br>
<em>&gt; (friendliness-friendly) goals
</em><br>
<em>&gt; that could motivate people and AGIs and I think the outcome of AGI
</em><br>
<em>&gt; development will be even more beneficial overall if there is a diversity
</em><br>
<em>&gt; of goals among AGIs.
</em><br>
<em>&gt;
</em><br>
<em>&gt; It seems to me that you often write Ben as if you think in terms of there
</em><br>
<em>&gt; being only one or a few AGIs.  If I'm right about this, then I
</em><br>
<em>&gt; suspect this
</em><br>
<em>&gt; mindset tends to lead you and perhaps others to think that there might
</em><br>
<em>&gt; be only one best AGI goal set.  My own default position is to imagine
</em><br>
<em>&gt; that there will be lots of AGIs (with lots of different origins) and that
</em><br>
<em>&gt; their goal sets could be quite divergent.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I think it is safest and most practical to start with a presumption that
</em><br>
<em>&gt; there will be a diversity of AGIs with a diversity of cognitive
</em><br>
<em>&gt; architectures and a diversity of goal sets.
</em><br>
<em>&gt;
</em><br>
<em>&gt; So I'm interested in the resulting population or group dynamics that
</em><br>
<em>&gt; results from interactions between people and AGIs, and AGIs and
</em><br>
<em>&gt; AGIs.  I think some of the outcomes we hope for from AGIs should be
</em><br>
<em>&gt; sought as emergent properties arising from a diverse population of
</em><br>
<em>&gt; AGIs working with a diverse population of people.
</em><br>
<em>&gt;
</em><br>
<em>&gt; The one common feature that I think is needed for *all* AGIs
</em><br>
<em>&gt; *individually* (and also all people!) is an ethic of co-
</em><br>
<em>&gt; existence/friendliness or whatever we choose to call it.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Cheers,   Philip
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7982.html">Philip Sutton: "The &quot;democracy&quot; question"</a>
<li><strong>Previous message:</strong> <a href="7980.html">Christian Szegedy: "Re: Positive Transcension 2"</a>
<li><strong>In reply to:</strong> <a href="7978.html">Philip Sutton: "RE: Positive Transcension 2"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7984.html">Philip Sutton: "RE: Positive Transcension 2"</a>
<li><strong>Reply:</strong> <a href="7984.html">Philip Sutton: "RE: Positive Transcension 2"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7981">[ date ]</a>
<a href="index.html#7981">[ thread ]</a>
<a href="subject.html#7981">[ subject ]</a>
<a href="author.html#7981">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:45 MDT
</em></small></p>
</body>
</html>
