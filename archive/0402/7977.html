<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Ethical theories</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Ethical theories">
<meta name="Date" content="2004-02-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Ethical theories</h1>
<!-- received="Fri Feb 20 08:01:02 2004" -->
<!-- isoreceived="20040220150102" -->
<!-- sent="Fri, 20 Feb 2004 10:08:03 -0500" -->
<!-- isosent="20040220150803" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Ethical theories" -->
<!-- id="BMECIIDGKPGNFPJLIDNPGELJCNAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="OJEHKDIANIFPAJPDBDGLCEOFCPAA.rafal@smigrodzki.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Ethical%20theories"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Fri Feb 20 2004 - 08:08:03 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7978.html">Philip Sutton: "RE: Positive Transcension 2"</a>
<li><strong>Previous message:</strong> <a href="7976.html">Ben Goertzel: "RE: Positive Transcension 2"</a>
<li><strong>In reply to:</strong> <a href="7973.html">Rafal Smigrodzki: "RE: Ethical theories"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7988.html">Rafal Smigrodzki: "RE: Ethical theories"</a>
<li><strong>Reply:</strong> <a href="7988.html">Rafal Smigrodzki: "RE: Ethical theories"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7977">[ date ]</a>
<a href="index.html#7977">[ thread ]</a>
<a href="subject.html#7977">[ subject ]</a>
<a href="author.html#7977">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Rafal,
<br>
<p>If I understand you correctly, you now seem to be saying something like
<br>
<p>&quot;Create goals, and rules that, if followed, will lead to the achievement of
<br>
these goals&quot;
<br>
<p>or
<br>
<p>&quot;Create goals, and rules that, if followed, will lead to the achievement of
<br>
these goals, with as few side-effects as possible.&quot;
<br>
<p>I understand that the goals and rules are typically presented in a combined
<br>
format rather than separately, but I'm not sure it does harm to separate
<br>
them, and it provides some conceptual simplification.
<br>
<p>I agree that these statements are more meta-ethical than your previous
<br>
proposal, which in this language was basically like
<br>
<p>&quot;Create goal-rule systems that will be accepted&quot;
<br>
<p>Your new statement is indeed more general, and is inclusive of the previous
<br>
one.  &quot;Will be accepted&quot; seems to add a very substantial additional
<br>
condition to your new, very abstract meta-ethic.
<br>
<p>Because, consider the &quot;ethical&quot; system:
<br>
<p>DESTROY ALL LIVING BEINGS BY
<br>
1) FIRST STUDYING ALL OTHER LIVING BEINGS SCIENTIFICALLY TO DETERMINE HOW TO
<br>
KILL THEM MOST EFFECTIVELY AND AT LOWEST RISK, AND THEN KILLING THEM
<br>
2) FINALLY, KILLING ONESELF
<br>
<p>This posits a goal and also some rules for how to achieve the goal.  It is
<br>
rational and consistent.  It obeys your new, more abstract meta-ethic.
<br>
<p>However, in practice, it fails your former, more concrete almost-meta-ethic,
<br>
because at least among MOST OF the sentient beings I know, it is unlikely to
<br>
be accepted.  (Now and then various psychopaths have of course accepted this
<br>
&quot;ethic&quot;).
<br>
<p>So, to me, by further abstracting your meta-ethic, you have moved from
<br>
<p>-- a very abstract formulation of &quot;the good&quot; [&quot;Create goal-rule systems that
<br>
will be accepted&quot;]
<br>
<p>to
<br>
<p>-- a very abstract formulation of the general process of goal-seeking
<br>
<p><p>Seeking the good is a special case of goal-seeking in general....
<br>
<p>I think your previous formulation succeeded in getting about as abstract as
<br>
&quot;ethics&quot; can get.  Your new formulation is *so* abstract it seems more
<br>
&quot;meta&quot; than &quot;ethical&quot; ;-)
<br>
<p>-- Ben G
<br>
<p><p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Ethical%20theories">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Ethical%20theories">owner-sl4@sl4.org</a>]On Behalf Of Rafal
</em><br>
<em>&gt; Smigrodzki
</em><br>
<em>&gt; Sent: Thursday, February 19, 2004 5:17 PM
</em><br>
<em>&gt; To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Ethical%20theories">sl4@sl4.org</a>
</em><br>
<em>&gt; Subject: RE: Ethical theories
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Ben wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;Rafal wrote
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt; I think we could begin by making the metaethical statement
</em><br>
<em>&gt; &gt;&gt; &quot;Formulate rules which will be accepted&quot; (although this statement is
</em><br>
<em>&gt; &gt;&gt; actually a high-level link in a very long-term recursive mental
</em><br>
<em>&gt; &gt;&gt; process, rather than a starting logical premise).
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; That's interesting.  It's a little deeper than it seems at first, and
</em><br>
<em>&gt; &gt; I need to think about it more.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; At first it seems a pure triviality, but then you realize what the
</em><br>
<em>&gt; &gt; preconditions are, in order for the statement to be meaningful.  For
</em><br>
<em>&gt; &gt; &quot;be accepted&quot; to be meaningful, one needs to assume there is some
</em><br>
<em>&gt; &gt; mind or community of minds that has the intelligence and the freedom
</em><br>
<em>&gt; &gt; to accept or to not accept.  So one is implicitly assuming the
</em><br>
<em>&gt; &gt; existence of mind and freedom.  So your rule is really equivalent to
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; &quot;Ensure that one or more minds with some form of volition exist, and
</em><br>
<em>&gt; &gt; then formulate rules that these minds will 'freely' choose to accept&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; ### You are close to getting to the bottom of the issue here, but
</em><br>
<em>&gt; let me try
</em><br>
<em>&gt; to reformulate the initial meta-ethical statement. As you point out, this
</em><br>
<em>&gt; statement is actually applicable only to ethical systems professed by
</em><br>
<em>&gt; creatures interested in survival - but creatures which don't care about
</em><br>
<em>&gt; their own lives can have ethical systems, too. Let me then make a
</em><br>
<em>&gt; hopefully
</em><br>
<em>&gt; more general meta-ethical statement - &quot;Formulate rules that make
</em><br>
<em>&gt; themselves
</em><br>
<em>&gt; into accepted rules, or, make themselves come true&quot; (cause the
</em><br>
<em>&gt; existence of
</em><br>
<em>&gt; states of the universe, including conscious states, in agreement
</em><br>
<em>&gt; with goals
</em><br>
<em>&gt; stated in the rules). Or &quot;Formulate rules which, if applied, will as their
</em><br>
<em>&gt; outcomes have the goals explicitly understood to be inherent in these
</em><br>
<em>&gt; rules&quot;. Or &quot;Do not formulate rules which have outcomes *opposite* to
</em><br>
<em>&gt; intended&quot;. If the goal of the rule is to have a &quot;good&quot; outcome, where
</em><br>
<em>&gt; goodness is defined within the rule itself, then only rules which
</em><br>
<em>&gt; have good
</em><br>
<em>&gt; outcomes are good rules, and ethical systems which have good outcomes are
</em><br>
<em>&gt; worth considering. Ethical systems which by their very structure have
</em><br>
<em>&gt; results opposite to or uncorrelated with goals of these systems
</em><br>
<em>&gt; would appear
</em><br>
<em>&gt; to be inferior to those which produce intended outcomes, because the very
</em><br>
<em>&gt; essence of ethics is to define desired outcomes, no matter what they
</em><br>
<em>&gt; actually are. I think that this is the basic meta-ethical statement we can
</em><br>
<em>&gt; make, essentially demanding rationality in ethics.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;From the demand for rationality in ethics one can derive further
</em><br>
<em>&gt; meta-ethical statements. Need for computability - a system which does not
</em><br>
<em>&gt; provide rules sufficient to compute desirability of concrete
</em><br>
<em>&gt; actions open to
</em><br>
<em>&gt; decision-makers (such as the system consisting of the sole statement &quot;Be
</em><br>
<em>&gt; good&quot;), is useless, uncorrelated with outcomes. Internal consistency - the
</em><br>
<em>&gt; system should not make contradictory recommendations for a single
</em><br>
<em>&gt; situation.
</em><br>
<em>&gt; Wide applicability - a system that guides only in a few situations is less
</em><br>
<em>&gt; useful (less correlated with outcomes) than a system applying everywhere.
</em><br>
<em>&gt; Stability under changes of input - systems which totally change
</em><br>
<em>&gt; recommendations after minor changes in inputs are likely to be affected by
</em><br>
<em>&gt; random misinformation and therefore uncorrelated with outcomes. I think
</em><br>
<em>&gt; similar points were made in this thread, sorry for repetition.
</em><br>
<em>&gt;
</em><br>
<em>&gt; All these considerations seem at first approximation to be independent of
</em><br>
<em>&gt; the content of ethical systems, but depend on epistemological features of
</em><br>
<em>&gt; existing minds - which in turn *are* linked to ethics via the shared
</em><br>
<em>&gt; physical environment which caused both our desires and our truth-finding
</em><br>
<em>&gt; faculties to develop. This represents a bit of circularity between ethics,
</em><br>
<em>&gt; and epistemology, but I don't think that such circularity would invalidate
</em><br>
<em>&gt; the meta-ethical statements - it merely makes them contingent on
</em><br>
<em>&gt; the current
</em><br>
<em>&gt; state of our (physical) truth-finding capabilities - but,
</em><br>
<em>&gt; everything we say
</em><br>
<em>&gt; shares this feature.
</em><br>
<em>&gt;
</em><br>
<em>&gt; ---------------------------------
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; If we define happiness_* (one variant of the vague notion of
</em><br>
<em>&gt; &gt; &quot;happiness&quot;) as &quot;the state of mind a volitional agent assumes when
</em><br>
<em>&gt; &gt; it's obtained what it wants&quot;, then your rule is really equivalent to
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; &quot;Ensure that one or more minds with some form of volition exist, and
</em><br>
<em>&gt; &gt; then formulate rules that these minds will 'freely' choose to accept,
</em><br>
<em>&gt; &gt; because they assess that accepting these rules will bring them an
</em><br>
<em>&gt; &gt; acceptable level of happiness_*&quot;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; My point in tautologously unfolding your rule in this way, is to show
</em><br>
<em>&gt; &gt; that (as you obviously realize) it contains more than it might at
</em><br>
<em>&gt; &gt; first appear to...
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; However, the shortcoming it has, is that it doesn't protect against
</em><br>
<em>&gt; &gt; minds being stupid and self-delusional.  Volitional agents may accept
</em><br>
<em>&gt; &gt; something even if it's bad for them in many senses.  (This is because
</em><br>
<em>&gt; &gt; happiness_* is not the only meaningful sense of happiness).
</em><br>
<em>&gt;
</em><br>
<em>&gt; ### Well, as I mentioned above I wanted to say something even
</em><br>
<em>&gt; less dependent
</em><br>
<em>&gt; on our current structure of volition, which for most humans contains a
</em><br>
<em>&gt; desire to exist. I hope that the reworked statement is more general, and
</em><br>
<em>&gt; then it wouldn't entail the need for continued existence of minds
</em><br>
<em>&gt; espousing
</em><br>
<em>&gt; a given ethics, much less the specific content of joyousness or growth. I
</em><br>
<em>&gt; understand that this makes it even less intuitively compelling that my
</em><br>
<em>&gt; initial statement, but it is more meta-ethical.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Rafal
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7978.html">Philip Sutton: "RE: Positive Transcension 2"</a>
<li><strong>Previous message:</strong> <a href="7976.html">Ben Goertzel: "RE: Positive Transcension 2"</a>
<li><strong>In reply to:</strong> <a href="7973.html">Rafal Smigrodzki: "RE: Ethical theories"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7988.html">Rafal Smigrodzki: "RE: Ethical theories"</a>
<li><strong>Reply:</strong> <a href="7988.html">Rafal Smigrodzki: "RE: Ethical theories"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7977">[ date ]</a>
<a href="index.html#7977">[ thread ]</a>
<a href="subject.html#7977">[ subject ]</a>
<a href="author.html#7977">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:45 MDT
</em></small></p>
</body>
</html>
