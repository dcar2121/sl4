<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Ethics was In defense of physics</title>
<meta name="Author" content="Keith Henson (hkhenson@rogers.com)">
<meta name="Subject" content="Re: Ethics was In defense of physics">
<meta name="Date" content="2004-02-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Ethics was In defense of physics</h1>
<!-- received="Sun Feb 15 01:11:56 2004" -->
<!-- isoreceived="20040215081156" -->
<!-- sent="Sun, 15 Feb 2004 03:17:58 -0500" -->
<!-- isosent="20040215081758" -->
<!-- name="Keith Henson" -->
<!-- email="hkhenson@rogers.com" -->
<!-- subject="Re: Ethics was In defense of physics" -->
<!-- id="5.1.0.14.0.20040215015856.02f5e820@pop.bloor.is.net.cable.rogers.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="402EE658.2090201@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Keith Henson (<a href="mailto:hkhenson@rogers.com?Subject=Re:%20Ethics%20was%20In%20defense%20of%20physics"><em>hkhenson@rogers.com</em></a>)<br>
<strong>Date:</strong> Sun Feb 15 2004 - 01:17:58 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7928.html">Metaqualia: "Re: In defense of physics"</a>
<li><strong>Previous message:</strong> <a href="7926.html">Eliezer S. Yudkowsky: "Re: In defense of physics"</a>
<li><strong>In reply to:</strong> <a href="7925.html">Eliezer S. Yudkowsky: "Re: Ethics was In defense of physics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7932.html">Eliezer S. Yudkowsky: "Re: Ethics was In defense of physics"</a>
<li><strong>Reply:</strong> <a href="7932.html">Eliezer S. Yudkowsky: "Re: Ethics was In defense of physics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7927">[ date ]</a>
<a href="index.html#7927">[ thread ]</a>
<a href="subject.html#7927">[ subject ]</a>
<a href="author.html#7927">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
At 10:24 PM 14/02/04 -0500, you wrote:
<br>
<em>&gt;Keith Henson wrote:
</em><br>
<em>&gt;&gt;This is important because the *ethics* of superhuman intelligences depend 
</em><br>
<em>&gt;&gt;on the underlying physics.
</em><br>
<em>&gt;&gt;If you have FTL, the ethics of the future are more on the scale of taking 
</em><br>
<em>&gt;&gt;care of your body vs having to deal with other independent superhuman 
</em><br>
<em>&gt;&gt;intelligences.
</em><br>
<em>&gt;
</em><br>
<em>&gt;You're natural-selection-o-morphizing here.  You deal with cognitive 
</em><br>
<em>&gt;systems that tend to have &quot;utility functions&quot; (not real utility functions, 
</em><br>
<em>&gt;of course, but cognitive dynamics that make choices) centered around their 
</em><br>
<em>&gt;own physical locations.  Actually, the utility doesn't follow the 
</em><br>
<em>&gt;location, it follows the genes - but one's own genes tend to be reliably 
</em><br>
<em>&gt;located in the same place as one's own brain.  In biological cases where 
</em><br>
<em>&gt;this is violated, and to the exact extent it is violated, the &quot;utility&quot; 
</em><br>
<em>&gt;always follows the genes, not the physical location.
</em><br>
<em>&gt;
</em><br>
<em>&gt;&quot;Self&quot;-centered utility with copying deixis is an easy idiom for natural 
</em><br>
<em>&gt;selection (though, even there, it is frequently violated).  It need not 
</em><br>
<em>&gt;apply at all to superintelligences.  There is no reason why an 
</em><br>
<em>&gt;optimization control process transforming distant matter into a copy of 
</em><br>
<em>&gt;the optimization control process would need to imbue that copy of the 
</em><br>
<em>&gt;control process with different optimization criteria than the original, 
</em><br>
<em>&gt;i.e., an expected utility optimization process extending itself throughout 
</em><br>
<em>&gt;space has no conflicts of interest with distant parts of itself.  This can 
</em><br>
<em>&gt;hold true for arbitrarily great communication delays without introducing 
</em><br>
<em>&gt;any obvious difficulties I can see.
</em><br>
<p>I see what you are saying here.  The idea is analogous to cells in a body 
<br>
(with common genes) not being in conflict.  Cells in a body sometimes do go 
<br>
wild (cancer) but with good error correcting codes whatever is at the core 
<br>
of an AI could copy to end of the universe without making an error.
<br>
<p>It seems to me that the core would have to be absolutely impervious to 
<br>
outside influences--which is in conflict with intelligence--to the extent 
<br>
that intelligence has to do with learning. Otherwise units at the ends of 
<br>
communication delays would diverge.  I suppose every AI could be 
<br>
broadcasting its total information stream into memory and receiving the 
<br>
memory dumps from every other AI.  It would have to treat the experience 
<br>
(memory) of other AIs with equal weight to its own.  That would keep at 
<br>
least close ones in sync, but if there are growing numbers of these things, 
<br>
the storage problem will get out of hand no matter what media is being 
<br>
used.  (In fact, it might make the case for very few AIs.  Even on per star 
<br>
would get out of hand.)
<br>
<p>The problems this creates are bad enough that far apart AI cores would be 
<br>
forced to consider themselves as different &quot;individuals&quot; just by weight of 
<br>
different (unsync'ed) post creation experiences.  I think this is true even 
<br>
if closer ones engaged in total mind melding.
<br>
<p>I like the idea that AIs could avoid having conflicts of interests in more 
<br>
ways than humans can.  People would probably fight a lot less if they 
<br>
walked away from every meeting not knowing which one they were.
<br>
<p>I am sure you will point out flaws in the above reasoning.  Please do, it 
<br>
is an interesting topic.
<br>
<p><em>&gt; &gt; It also leads to some very interesting questions about how physically
</em><br>
<em>&gt; &gt; large a superhuman intelligence can be.  At some point there is no
</em><br>
<em>&gt; &gt; utility in absorbing more matter.
</em><br>
<em>&gt;
</em><br>
<em>&gt;I'm planning to talk about this part with Ben.
</em><br>
<p>With FTL there doesn't seem to be an obvious limit.  Without . . . 
<br>
eventually your brain undergoes a gravitational singularity.
<br>
<p>Keith Henson
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7928.html">Metaqualia: "Re: In defense of physics"</a>
<li><strong>Previous message:</strong> <a href="7926.html">Eliezer S. Yudkowsky: "Re: In defense of physics"</a>
<li><strong>In reply to:</strong> <a href="7925.html">Eliezer S. Yudkowsky: "Re: Ethics was In defense of physics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7932.html">Eliezer S. Yudkowsky: "Re: Ethics was In defense of physics"</a>
<li><strong>Reply:</strong> <a href="7932.html">Eliezer S. Yudkowsky: "Re: Ethics was In defense of physics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7927">[ date ]</a>
<a href="index.html#7927">[ thread ]</a>
<a href="subject.html#7927">[ subject ]</a>
<a href="author.html#7927">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:45 MDT
</em></small></p>
</body>
</html>
