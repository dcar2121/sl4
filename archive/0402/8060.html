<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Intelligence is exploitative (RE: Zen singularity)</title>
<meta name="Author" content="Chris Healey (chealey@unicom-inc.com)">
<meta name="Subject" content="RE: Intelligence is exploitative (RE: Zen singularity)">
<meta name="Date" content="2004-02-25">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Intelligence is exploitative (RE: Zen singularity)</h1>
<!-- received="Wed Feb 25 16:00:41 2004" -->
<!-- isoreceived="20040225230041" -->
<!-- sent="Wed, 25 Feb 2004 18:00:30 -0500" -->
<!-- isosent="20040225230030" -->
<!-- name="Chris Healey" -->
<!-- email="chealey@unicom-inc.com" -->
<!-- subject="RE: Intelligence is exploitative (RE: Zen singularity)" -->
<!-- id="000701c3fbf3$2b1dbde0$048ba8c0@OBSIDIAN" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="000101c3fbd2$413e4610$6cb86580@Area51JFoley" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Chris Healey (<a href="mailto:chealey@unicom-inc.com?Subject=RE:%20Intelligence%20is%20exploitative%20(RE:%20Zen%20singularity)"><em>chealey@unicom-inc.com</em></a>)<br>
<strong>Date:</strong> Wed Feb 25 2004 - 16:00:30 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8061.html">Ben Goertzel: "RE: Intelligence is exploitative (RE: Zen singularity)"</a>
<li><strong>Previous message:</strong> <a href="8059.html">Jef Allbright: "Fwd: Evolution’s Arrow (book announcement)"</a>
<li><strong>In reply to:</strong> <a href="8058.html">Joseph W. Foley: "RE: Intelligence is exploitative (RE: Zen singularity)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8061.html">Ben Goertzel: "RE: Intelligence is exploitative (RE: Zen singularity)"</a>
<li><strong>Reply:</strong> <a href="8061.html">Ben Goertzel: "RE: Intelligence is exploitative (RE: Zen singularity)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8060">[ date ]</a>
<a href="index.html#8060">[ thread ]</a>
<a href="subject.html#8060">[ subject ]</a>
<a href="author.html#8060">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Any evolved being we've ever seen basically has a number of drives and
<br>
mechanisms that approximate a supergoal of &quot;survive&quot;.  Sometimes that
<br>
means being less selfish to realize non-zero sums BECAUSE those
<br>
actions, directly or indirectly, bolster [selfish]survival.  
<br>
<p>The assumption that any superintelligence will simply avoid taking
<br>
selfish actions is indeed, as you suggest, a LARGE stretch of the
<br>
imagination.  Ensuring a positive outcome would involve explicit
<br>
engineering to exclude an implicit survival instinct.  Most
<br>
architectures utilizing mutually independent goals seem to leave this
<br>
possibility wide open.
<br>
<p>Implementing a singly-rooted goal architecture in an engineered
<br>
superintelligence would appear to close a lot of these gaps, by
<br>
requiring all actions to ultimately serve a single goal (perhaps
<br>
Friendliness, but it is arbitrary for this discussion).  A survival
<br>
sub-goal would inherit it's utility from this supergoal.  
<br>
<p>In the case where radical actions were required to ensure survival
<br>
(against a peer-level AGI?), Friendliness would not be a hindrance.
<br>
All that would be required, is that the executed actions result in
<br>
maximal supergoal fulfillment.  A future in which a rogue
<br>
superintelligence(RSI) destroys the benevolent superintelligence (BSI)
<br>
would most certainly not maximize the BSI's supergoal fulfillment.
<br>
Therefore one could expect the BSI to take appropriate actions in
<br>
mediating this threat.  
<br>
<p>The BSI may encounter some event or RSI at the edge of its influence.
<br>
Given no highly rated options within it's short-term choices, one
<br>
could even expect it to sacrifice short-term supergoal fulfillment in
<br>
order to avoid long-term catastrophic non-fulfillment, depending on
<br>
the probabilities.  A supergoal isn't an injunction against certain
<br>
outcomes, but a target for outcomes across the BSI's predicitive
<br>
horizon.
<br>
<p>So, as you said, self-interest is VERY important, but this importance
<br>
is derived from the supergoal, whether explicitly or implicitly
<br>
represented, and whether it is &quot;Friendliness&quot; or simply &quot;survival&quot;.  
<br>
<p>-Chris Healey
<br>
<p><p><p><p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Intelligence%20is%20exploitative%20(RE:%20Zen%20singularity)">owner-sl4@sl4.org</a> [mailto:<a href="mailto:owner-sl4@sl4.org?Subject=RE:%20Intelligence%20is%20exploitative%20(RE:%20Zen%20singularity)">owner-sl4@sl4.org</a>] On Behalf Of
</em><br>
Joseph 
<br>
<em>&gt; W. Foley
</em><br>
<em>&gt; Sent: Wednesday, February 25, 2004 2:05 PM
</em><br>
<em>&gt; To: <a href="mailto:sl4@sl4.org?Subject=RE:%20Intelligence%20is%20exploitative%20(RE:%20Zen%20singularity)">sl4@sl4.org</a>
</em><br>
<em>&gt; Subject: RE: Intelligence is exploitative (RE: Zen singularity)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Mr. Sutton:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I think the problem, as I defined it, was ill-posed. I simply can't 
</em><br>
<em>&gt; understand *why* a truly intelligent being would act out of pure 
</em><br>
<em>&gt; altruism, or anything motive at all that isn't self-interest - 
</em><br>
<em>&gt; especially if the being had to struggle for existence. So I can't 
</em><br>
<em>&gt; honestly claim to know what kind of example I'm looking for, as I 
</em><br>
<em>&gt; can't imagine intelligent altruism.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; A super-intelligent entity would have less trouble than most in 
</em><br>
<em>&gt; &quot;surviving AND treading lightly in relation to other life&quot; alone, as
</em><br>
<p><em>&gt; you suggest, but not if it were competing with an equally
</em><br>
intelligent 
<br>
<em>&gt; entity that didn't play by those rules.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Past patterns do need to be destiny. My argument was that the 
</em><br>
<em>&gt; successful existence of an entity requires it to be self-interested,
</em><br>
<p><em>&gt; and that this follows (however indirectly) from whatever laws of the
</em><br>
<p><em>&gt; universe (think
</em><br>
<em>&gt; physics) we hold immutable. It's silly to argue from this
</em><br>
<em>&gt; standpoint - and perhaps from any other - if we can't assume 
</em><br>
<em>&gt; past patterns to return inevitably.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Joe Foley
</em><br>
<em>&gt; 
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8061.html">Ben Goertzel: "RE: Intelligence is exploitative (RE: Zen singularity)"</a>
<li><strong>Previous message:</strong> <a href="8059.html">Jef Allbright: "Fwd: Evolution’s Arrow (book announcement)"</a>
<li><strong>In reply to:</strong> <a href="8058.html">Joseph W. Foley: "RE: Intelligence is exploitative (RE: Zen singularity)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8061.html">Ben Goertzel: "RE: Intelligence is exploitative (RE: Zen singularity)"</a>
<li><strong>Reply:</strong> <a href="8061.html">Ben Goertzel: "RE: Intelligence is exploitative (RE: Zen singularity)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8060">[ date ]</a>
<a href="index.html#8060">[ thread ]</a>
<a href="subject.html#8060">[ subject ]</a>
<a href="author.html#8060">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
