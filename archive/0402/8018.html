<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Intelligence is exploitative (RE: Zen singularity)</title>
<meta name="Author" content="Joseph W. Foley (fole0091@umn.edu)">
<meta name="Subject" content="Intelligence is exploitative (RE: Zen singularity)">
<meta name="Date" content="2004-02-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Intelligence is exploitative (RE: Zen singularity)</h1>
<!-- received="Sun Feb 22 22:16:25 2004" -->
<!-- isoreceived="20040223051625" -->
<!-- sent="Sun, 22 Feb 2004 23:16:23 -0600" -->
<!-- isosent="20040223051623" -->
<!-- name="Joseph W. Foley" -->
<!-- email="fole0091@umn.edu" -->
<!-- subject="Intelligence is exploitative (RE: Zen singularity)" -->
<!-- id="000c01c3f9cc$2e52f8a0$6cb86580@Area51JFoley" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="DAEGJDAIEMCEKLOPODAKMEDHDKAA.mike99@lascruces.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Joseph W. Foley (<a href="mailto:fole0091@umn.edu?Subject=Re:%20Intelligence%20is%20exploitative%20(RE:%20Zen%20singularity)"><em>fole0091@umn.edu</em></a>)<br>
<strong>Date:</strong> Sun Feb 22 2004 - 22:16:23 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8019.html">Metaqualia: "Re: Zen singularity"</a>
<li><strong>Previous message:</strong> <a href="8017.html">Ben Goertzel: "RE: Zen singularity"</a>
<li><strong>In reply to:</strong> <a href="8015.html">mike99: "RE: Zen singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8020.html">Philip Sutton: "Re: Intelligence is exploitative (RE: Zen singularity)"</a>
<li><strong>Reply:</strong> <a href="8020.html">Philip Sutton: "Re: Intelligence is exploitative (RE: Zen singularity)"</a>
<li><strong>Maybe reply:</strong> <a href="8062.html">Christopher Healey: "RE: Intelligence is exploitative (RE: Zen singularity)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8018">[ date ]</a>
<a href="index.html#8018">[ thread ]</a>
<a href="subject.html#8018">[ subject ]</a>
<a href="author.html#8018">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Greetings.
<br>
<p><a href="mailto:entropy@farviolet.com?Subject=Re:%20Intelligence%20is%20exploitative%20(RE:%20Zen%20singularity)">entropy@farviolet.com</a> said:
<br>
<em>&gt; However I'm talking about the distant (or even not so distant) future.
</em><br>
<em>&gt; Already the human race has reached a point where we have decided to
</em><br>
limit
<br>
<em>&gt; our expansion.
</em><br>
<p>...
<br>
<p><em>&gt; It seems quite possible that a 'higher' being might be even more so
</em><br>
this
<br>
<em>&gt; way.
</em><br>
<p>mike99 said: 
<br>
<em>&gt; Maybe. Or maybe not. I haven't heard any good reasons why this would
</em><br>
be so.
<br>
<p>...
<br>
<p><em>&gt; Obviously, there are many questions on this topic that we are simply
</em><br>
not
<br>
<em>&gt; capable of answering at this time. It would seem merely prudent, then,
</em><br>
to
<br>
<em>&gt; minimize the number of assumptions we make about what other, smarter
</em><br>
<em>&gt; beings might want to do, or be capable of doing. All we can be sure of
</em><br>
is &gt; what the most intelligent species on our planet has done and is
<br>
doing.
<br>
<em>&gt; Extrapolating the behavior of this species into the future would seem
</em><br>
to
<br>
<em>&gt; be less problematic than assuming that a still higher intelligence
</em><br>
would
<br>
<em>&gt; automatically behave in a radically different fashion.
</em><br>
<p>Indeed, we must be careful not to assume that a singularly intelligent
<br>
being would be singularly ethical (by standards that vary among members
<br>
of our species anyway). Yes, its ethos or goal-system could probably be
<br>
influenced somewhat by its creators, for Friendliness or just about
<br>
anything else. However, as Darwin realized about biology, all we can
<br>
infer from the existence of creatures is that those creatures must be
<br>
really good at existing, because most conceivable alternatives lost the
<br>
struggle for survival (and most of those before the struggle even
<br>
started).
<br>
<p>So, what can we infer about a hypothetical Higher being, if we assume
<br>
its existence? Well, it may have always been a seamlessly integrated
<br>
part of the universe, or that it may have arisen from the
<br>
biological/cybernetic evolution of Lesser beings. If the former, we
<br>
can't infer very much about the being at all; if the latter, then we can
<br>
infer that it was somehow better able to rise to power than any of its
<br>
contemporaries. The ethos that leads most directly to that status seems
<br>
to me what many of us would consider the *least* agreeable of all: it
<br>
would have to be adept at assimilating or destroying all external
<br>
competition. No goal-based decision-maker is without some kind of
<br>
competition for existence, though this doesn't always mean the
<br>
competition of other goal-based decision-makers.
<br>
<p><a href="mailto:entropy@farviolet.com?Subject=Re:%20Intelligence%20is%20exploitative%20(RE:%20Zen%20singularity)">entropy@farviolet.com</a> said:
<br>
<em>&gt; Just as we feel we don't have the right to remake all of nature
</em><br>
according
<br>
to our rules,...
<br>
<p>But the opposite feeling is exactly what we expect out of any
<br>
intentional agent that succeeds at existing. It's impossible for a
<br>
rule-making entity to exist if it doesn't do so by remaking part of
<br>
nature (remaking all of nature is an issue of feasibility, not rights).
<br>
Of course, it seems obvious that a successful goal-based existence
<br>
machine will remake nature into less arbitrary tools than a Zen garden.
<br>
This is really the point of worrying about Friendly AI: we assume that a
<br>
super-intelligence that comes into being on its own, without our
<br>
tampering, will want to exploit us; the best exister we can imagine is
<br>
decidedly unFriendly.
<br>
<p>So, it might limit its expansion (the assimilation of the external)
<br>
temporarily, but only if that investment could actually boost long-run
<br>
expansion. For example, humans might decide not to destroy the
<br>
environment, but only because in the long run it's actually bad for us,
<br>
and not because it's bad for the environment itself.
<br>
<p>As mike99 suggested, we can only extrapolate from what we've seen on our
<br>
planet. As species become more intelligent, they modify their
<br>
environments more. After all, that's what intelligence is: the ability
<br>
to modify the environment toward one's goals (see postscript).
<br>
<p><p>Joe Foley
<br>
&quot;Ignorance is bliss, but knowledge is power.&quot;
<br>
<p><p>P.S. 
<br>
<p>Compare:
<br>
<p><em>&gt; My current working def'n of &quot;intelligence&quot; is &quot;able to achieve complex
</em><br>
<em>&gt; goals in complex environments&quot; but it may be there are other useful
</em><br>
<em>&gt; characterizations of intelligence that don't involve goals, or useful
</em><br>
<em>&gt; definitions of mind that don't involve &quot;intelligence&quot; ...
</em><br>
<p>- Ben Goertzel, Sun, 22 Feb 2004 23:17:51 -0500
<br>
<p>My informal definition adds that modifying the complex environments is
<br>
the way by which intelligences are able to achieve goals in them. I am
<br>
not aware of a form of intelligence that doesn't involve goals, and I
<br>
would like very much to see an example described.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8019.html">Metaqualia: "Re: Zen singularity"</a>
<li><strong>Previous message:</strong> <a href="8017.html">Ben Goertzel: "RE: Zen singularity"</a>
<li><strong>In reply to:</strong> <a href="8015.html">mike99: "RE: Zen singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8020.html">Philip Sutton: "Re: Intelligence is exploitative (RE: Zen singularity)"</a>
<li><strong>Reply:</strong> <a href="8020.html">Philip Sutton: "Re: Intelligence is exploitative (RE: Zen singularity)"</a>
<li><strong>Maybe reply:</strong> <a href="8062.html">Christopher Healey: "RE: Intelligence is exploitative (RE: Zen singularity)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8018">[ date ]</a>
<a href="index.html#8018">[ thread ]</a>
<a href="subject.html#8018">[ subject ]</a>
<a href="author.html#8018">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
