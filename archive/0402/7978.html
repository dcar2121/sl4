<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Positive Transcension 2</title>
<meta name="Author" content="Philip Sutton (Philip.Sutton@green-innovations.asn.au)">
<meta name="Subject" content="RE: Positive Transcension 2">
<meta name="Date" content="2004-02-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Positive Transcension 2</h1>
<!-- received="Fri Feb 20 08:46:14 2004" -->
<!-- isoreceived="20040220154614" -->
<!-- sent="Sat, 21 Feb 2004 02:48:01 +1000" -->
<!-- isosent="20040220164801" -->
<!-- name="Philip Sutton" -->
<!-- email="Philip.Sutton@green-innovations.asn.au" -->
<!-- subject="RE: Positive Transcension 2" -->
<!-- id="4036C6E1.25283.D5D146@localhost" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="Positive Transcension 2" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Philip Sutton (<a href="mailto:Philip.Sutton@green-innovations.asn.au?Subject=RE:%20Positive%20Transcension%202"><em>Philip.Sutton@green-innovations.asn.au</em></a>)<br>
<strong>Date:</strong> Fri Feb 20 2004 - 09:48:01 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7979.html">Ben Goertzel: "RE: Positive Transcension 2"</a>
<li><strong>Previous message:</strong> <a href="7977.html">Ben Goertzel: "RE: Ethical theories"</a>
<li><strong>Maybe in reply to:</strong> <a href="7976.html">Ben Goertzel: "RE: Positive Transcension 2"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7981.html">Ben Goertzel: "RE: Positive Transcension 2"</a>
<li><strong>Reply:</strong> <a href="7981.html">Ben Goertzel: "RE: Positive Transcension 2"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7978">[ date ]</a>
<a href="index.html#7978">[ thread ]</a>
<a href="subject.html#7978">[ subject ]</a>
<a href="author.html#7978">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi  Ben,  
<br>
<p>My  guess is that, optimistically, it is going to be a decade or two before 
<br>
we see AGIs capabable of driving a fast take-off to 
<br>
transcension/singularity or whatever.  During this time the AGIs 
<br>
together with their human designers/ programmer/ trainers/ educators / 
<br>
etc. are going to have to co-exisit with the rest of humanity - so that 
<br>
resources can be devoted to the support of AGI (computing 
<br>
power/design&amp;programming skill etc.) and the simple right to continue 
<br>
with the work/to have AGIs operating is granted by society.
<br>
<p>If during this time people come to fear AGIs (or their potential) they 
<br>
may engage in all sorts of blocking activities (legal/direct action etc.) of 
<br>
a more or less extreme nature. Also people developing AGIs (and the 
<br>
AGIs themselves) will need supporters to defend AGI development so 
<br>
that the work and the AGIs can continue.
<br>
<p>If AGI promoters are projecting vibes that they are not 100% behind the 
<br>
protection/welfare of humans and that somehow AGIs might be 
<br>
engaged in the 'demise of humanity' then some people might get a bit 
<br>
jumpy and might flip into active opposition mode - and you have to 
<br>
admit - if they did it would not be surprising!
<br>
<p>Ben, I really admire the way that you have been openly exploring a 
<br>
huge number of the issues related to the development of AGI via the 
<br>
email lists and in other ways - so I would hate to see your style, or 
<br>
anyone else's, cramped by a need for formulaic 'political correctness'. 
<br>
But I think you need to keep putting yourself in the shoes of other 
<br>
people who are not closely involved in the development of AGI - you've 
<br>
got to be able to feel what they might feel (after the style of the 
<br>
universal mind simulator! :)
<br>
<p>Evolution (even the radical-leap forward-variety represented for 
<br>
example by the first trilobite with eyes, the first human with advanced 
<br>
language and the first AGI with competent self-upgrading skills) is still a 
<br>
game of making steps where *each one* is viable so that future 
<br>
potential can survive the present moment to be able to unfold later.
<br>
<p>I think the safest way to get to AGIs with competently self-upgrading 
<br>
skills going is to make a compact with humanity (all of them/us - even 
<br>
including the vast mass of ignorant people!) that AGIs will be 
<br>
developed in a way that does not violate people's desire for continued 
<br>
exisitence and desire for autonomy over the nature of their lives.  If 
<br>
AGIs are designed/ trained so that they do not threaten the exisitence/ 
<br>
autonomy desires of people then I think there is a much better chance 
<br>
that enough people will support or tolerate the creation of AGIs so that 
<br>
AGIs actually emerge and persist long enough to be able to look after 
<br>
themselves and be able to assure their own survival.
<br>
<p>I'm NOT pushing for political correctness - I'm pushing for a politically-
<br>
savvy and compassionately-sensitive approach to co-exisitence 
<br>
between the AGI developers/AGI and the rest of humanity.
<br>
<p>As I mentioned a moment ago, I admire your intellectual openness - 
<br>
and I'm not saying this to suck up to you.  It's how I feel.
<br>
<p>But I think you have to be very sensitive to the feelings of others - your 
<br>
&quot;Encouraging positive transcension&quot; article has a major pre-occupation 
<br>
with the notion of the demise of humanity as a conceivable outcome of 
<br>
the development of AGI - and in saying this I'm not saying that you are 
<br>
actually advocating the demise of humanity.  But run the text through 
<br>
the Novamente inference engine and see if I'm wrong about the 
<br>
preoccupation!
<br>
<p>I think this line-of-thought/this outcome (the demise of humanity 
<br>
through either evolution to something else or through reassignment of 
<br>
mass energy(!!)) is simply not necessary to the development of AGI or 
<br>
the wonderous flowering of the universe.  Once AGIs have access to 
<br>
the physical environment, production processes and transport - 
<br>
especially if they can access places off-earth - they will not be 'held 
<br>
back' by people.  But leading up to this stage, AGIs and their human 
<br>
designers/developers/trainers etc. could be held back or totally blocked 
<br>
if an anti-AGI panic set in.
<br>
<p>That is why I think humans working on AGI development and (later the 
<br>
AGIs themselves) need to make (and honour) a pact with humanity that 
<br>
the AGIs will not threaten humans exisitence and lifestyle autonomy.
<br>
<p>If the AGIs can also help humanity to solve our many current problems 
<br>
so much the better - then there will be a sound basis for mutal 
<br>
recognition and cooperation.
<br>
<p>This humanity-AGI pact is a different thing from the problem of creating 
<br>
'friendly' ethics in AGI.  I have no skills in AGI design or development 
<br>
but your intuition that 'friendliness' will be easier to implant and retain 
<br>
through massive cycles of self-modification if it is more all- 
<br>
encompassing or more generally stated makes sense to me.  So I'm 
<br>
suggesting that we need TWO processes:
<br>
<p>1.  building in meta-friendliness towards all sentients or even to all
<br>
&nbsp;&nbsp;&nbsp;&nbsp;life that unfailingly generates, amongst other responses,
<br>
&nbsp;&nbsp;&nbsp;&nbsp;friendliness towards humans.
<br>
<p>2.  a conscious pact with humanity that AGIs with respect humans desire
<br>
&nbsp;&nbsp;&nbsp;&nbsp;to exist and have lifestyle autonomy/self-determination.
<br>
<p>This pact is necessary in my view to reassure people that tolerating or 
<br>
supporting the emergence of AGIs in not a threat to themselves or their 
<br>
children or humanity in general.
<br>
<p>If as a consequence of the freedom protected under this this pact, 
<br>
some or all people decide to turn their back on the possibilities of 
<br>
transcension *for themselves* it doesn't matter in the wider sweep of 
<br>
cosmic history. Personally I think a large number of people *will* avail 
<br>
themselves of the benefits of transcension - if for no other reason than 
<br>
to extend their lives.  Many people will also be excited at the prospect 
<br>
of communicating with advanced AGIs and many people will want to be 
<br>
able to personally tap the wonders of intellectual expansion that come 
<br>
from augmentation or uploading.
<br>
<p>But if other people choose not to go this way, if they even wanted to 
<br>
stay exactly as they are, it doesn't matter two hoots - it should be their 
<br>
choice.  I don't think AGI developers/promoters should project one iota 
<br>
of concern about people making such a conservative choice.
<br>
<p>I think the AGI-human pact could start off as a one way offer - offered 
<br>
by the AGI development community freely and unilaterally to the rest of 
<br>
the community.  If the heat builds up on AGI development then it might 
<br>
be necessary later to make a formal two-way pact via the formal 
<br>
political processes operating around the globe at the time.
<br>
<p>Can I clarify - the whole of the foregoing is NOT premised on the 
<br>
simple notion that the preservation of humanity is paramount over 
<br>
anything else in the universe.  What I'm saying is more prosaic than 
<br>
that.......if you want the least-hassle path to the creation of self- 
<br>
upgrading AGI then my intuition is that this is best facilitated by an 
<br>
historical pact that AGIs will be designed so that as an emergent of 
<br>
their ethics they are unfailingly friendly to people - allowing humans to 
<br>
continue to exist and shape their own lifestyles.  I do not see humans 
<br>
as the centre of the universe.  I don't care personally if they evolve into 
<br>
something that I would not recognise as being like humanity-2004 style. 
<br>
But I just want personally and for my children and for their descendents 
<br>
and for other people and their descendents the freedom to exist and 
<br>
shape our lifestyles.  My guess also is that if there are other sentients 
<br>
around the universe many of them would also be likely to want this sort 
<br>
of freedom.
<br>
<p>-------
<br>
<p>Ben, it seems to me that your favoured ethical structure is that all (?) 
<br>
AGIs should embody a core ethical commitment to &quot;voluntary joyous 
<br>
growth&quot; or some variant of this?
<br>
<p>My feeling is that we should allow for a greater diversity of prime goals 
<br>
than this and that if there is a greater diversity then it is necessary to 
<br>
build in friendliness as an unfailing companion of whatever other goals 
<br>
the AGIs might have.
<br>
<p>I think it would be relatively easy to get concensus amongst people that 
<br>
AGIs (should they exist) should be friendly to people.  But beyond that 
<br>
human consensus will be hard to find - even on the SL4 list or the AGI 
<br>
list.  I don't see this as a problem.  There will be enough people 
<br>
involved in AGI development who are motivated to see the wonderous 
<br>
complexity and patterns of the universe unfold and so I'm sure they will 
<br>
ensure that a fair number of AGIs are motivated to pursue &quot;voluntary 
<br>
joyous growth&quot;.  But there are lots of other (friendliness-friendly) goals 
<br>
that could motivate people and AGIs and I think the outcome of AGI 
<br>
development will be even more beneficial overall if there is a diversity 
<br>
of goals among AGIs.
<br>
<p>It seems to me that you often write Ben as if you think in terms of there 
<br>
being only one or a few AGIs.  If I'm right about this, then I suspect this 
<br>
mindset tends to lead you and perhaps others to think that there might 
<br>
be only one best AGI goal set.  My own default position is to imagine 
<br>
that there will be lots of AGIs (with lots of different origins) and that 
<br>
their goal sets could be quite divergent.
<br>
<p>I think it is safest and most practical to start with a presumption that 
<br>
there will be a diversity of AGIs with a diversity of cognitive 
<br>
architectures and a diversity of goal sets.
<br>
<p>So I'm interested in the resulting population or group dynamics that 
<br>
results from interactions between people and AGIs, and AGIs and 
<br>
AGIs.  I think some of the outcomes we hope for from AGIs should be 
<br>
sought as emergent properties arising from a diverse population of 
<br>
AGIs working with a diverse population of people.
<br>
<p>The one common feature that I think is needed for *all* AGIs 
<br>
*individually* (and also all people!) is an ethic of co- 
<br>
existence/friendliness or whatever we choose to call it.
<br>
<p>Cheers,   Philip
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7979.html">Ben Goertzel: "RE: Positive Transcension 2"</a>
<li><strong>Previous message:</strong> <a href="7977.html">Ben Goertzel: "RE: Ethical theories"</a>
<li><strong>Maybe in reply to:</strong> <a href="7976.html">Ben Goertzel: "RE: Positive Transcension 2"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="7981.html">Ben Goertzel: "RE: Positive Transcension 2"</a>
<li><strong>Reply:</strong> <a href="7981.html">Ben Goertzel: "RE: Positive Transcension 2"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7978">[ date ]</a>
<a href="index.html#7978">[ thread ]</a>
<a href="subject.html#7978">[ subject ]</a>
<a href="author.html#7978">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:45 MDT
</em></small></p>
</body>
</html>
