<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: All sentient have to be observer-centered!  My theory of FAI morality</title>
<meta name="Author" content="Marc Geddes (marc_geddes@yahoo.co.nz)">
<meta name="Subject" content="RE: All sentient have to be observer-centered!  My theory of FAI morality">
<meta name="Date" content="2004-02-27">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: All sentient have to be observer-centered!  My theory of FAI morality</h1>
<!-- received="Fri Feb 27 00:12:57 2004" -->
<!-- isoreceived="20040227071257" -->
<!-- sent="Fri, 27 Feb 2004 20:12:56 +1300 (NZDT)" -->
<!-- isosent="20040227071256" -->
<!-- name="Marc Geddes" -->
<!-- email="marc_geddes@yahoo.co.nz" -->
<!-- subject="RE: All sentient have to be observer-centered!  My theory of FAI morality" -->
<!-- id="20040227071256.37236.qmail@web20203.mail.yahoo.com" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="OJEHKDIANIFPAJPDBDGLOEEGDAAA.rafal@smigrodzki.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Marc Geddes (<a href="mailto:marc_geddes@yahoo.co.nz?Subject=RE:%20All%20sentient%20have%20to%20be%20observer-centered!%20%20My%20theory%20of%20FAI%20morality"><em>marc_geddes@yahoo.co.nz</em></a>)<br>
<strong>Date:</strong> Fri Feb 27 2004 - 00:12:56 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8076.html">Tommy McCabe: "Re: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<li><strong>Previous message:</strong> <a href="8074.html">Marc Geddes: "Oops.  Slight correction to my last post..."</a>
<li><strong>In reply to:</strong> <a href="8069.html">Rafal Smigrodzki: "RE: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8078.html">Rafal Smigrodzki: "RE: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<li><strong>Reply:</strong> <a href="8078.html">Rafal Smigrodzki: "RE: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8075">[ date ]</a>
<a href="index.html#8075">[ thread ]</a>
<a href="subject.html#8075">[ subject ]</a>
<a href="author.html#8075">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&nbsp;--- Rafal Smigrodzki &lt;<a href="mailto:rafal@smigrodzki.org?Subject=RE:%20All%20sentient%20have%20to%20be%20observer-centered!%20%20My%20theory%20of%20FAI%20morality">rafal@smigrodzki.org</a>&gt; wrote: &gt;
<br>
Marc wrote:
<br>
<em>&gt; &gt; morality
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; My main worry with Eliezer's ideas is that I don't
</em><br>
<em>&gt; &gt; think that a non observer-centered sentient is
</em><br>
<em>&gt; &gt; logically possible.  Or if it's possible, such a
</em><br>
<em>&gt; &gt; sentient would not be stable.  Can I prove this? 
</em><br>
<em>&gt; No.
</em><br>
<em>&gt; &gt; But all the examples of stable sentients (humans)
</em><br>
<em>&gt; that
</em><br>
<em>&gt; &gt; we have are observer centered.  I can only point
</em><br>
<em>&gt; to
</em><br>
<em>&gt; &gt; this, combined with the fact that so many people
</em><br>
<em>&gt; &gt; posting to sl4 agree with me.  I can only strongly
</em><br>
<em>&gt; &gt; urge Eliezer and others working on AI NOT to
</em><br>
<em>&gt; attempt
</em><br>
<em>&gt; &gt; the folly of trying to create a non observer
</em><br>
<em>&gt; centered
</em><br>
<em>&gt; &gt; AI.  For goodness sake don't try it!  It could
</em><br>
<em>&gt; mean
</em><br>
<em>&gt; &gt; the doom of us all.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; ### Marc, remember that every single human you have
</em><br>
<em>&gt; met is a product of
</em><br>
<em>&gt; evolution, and replicates his genes autonomously
</em><br>
<em>&gt; (not vicariously like a
</em><br>
<em>&gt; worker bee). Self-centered goal systems are a
</em><br>
<em>&gt; natural result of this
</em><br>
<em>&gt; evolutionary history. Making an FAI is however
</em><br>
<em>&gt; totally different from
</em><br>
<em>&gt; evolving it - and the limitation to self-centered
</em><br>
<em>&gt; goal systems no longer
</em><br>
<em>&gt; applies. In fact, it would be a folly to abide by
</em><br>
<em>&gt; this limitation, and
</em><br>
<em>&gt; non-observer-centered systems should have a much
</em><br>
<em>&gt; better chance of staying
</em><br>
<em>&gt; friendly (since there is no self-centered goal
</em><br>
<em>&gt; system component shifting
</em><br>
<em>&gt; them away from friendliness).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Rafal
</em><br>
<em>&gt;  
</em><br>
<p>Yeah Rafal,
<br>
<p>I don't regard the evolutionary arguments as very
<br>
convincing.  They're based on observation, not
<br>
experiment.  Besides, it's only very recently in
<br>
evolutionary history that the first sentients (humans)
<br>
appeared.  It's the class of sentients that is
<br>
revelent to FAI work.  Evolutionary observations about
<br>
non-sentients is not likely to say much of relevence.
<br>
<p>In any event, I don't regard non observer based
<br>
sentients as even desireable (See my other replies). 
<br>
If you strip out all observer centered goals, you're
<br>
left with normative altruism.  All sentients would
<br>
converge on this, and all individual uniqueness would
<br>
be stripped away.  You'd be left with bland
<br>
uniformity.  An empty husk.  Universal morality is
<br>
probably just a very general set of contrainsts, and
<br>
FAI's following this alone would be qute unable to
<br>
distinguish between the myraid of interesting personal
<br>
goals that are consistent with it.  Everything that
<br>
didn't hurt others (assuming that Universal Morality
<br>
is volition based) whould be equally 'Good' to such an
<br>
FAI.  There would be no possibility of anything
<br>
unquinely human or personal.  For instance the two
<br>
outcomes 'Rafal kills himself', 'Rafal doesn't kill
<br>
humself' would be designated as morally equivalent
<br>
under Volitional Morality.
<br>
<p>In short, totally non-observer centered FAI's just
<br>
wouldn't make interesting drinking buddies.
<br>
<p>Now, let's get back to bashing Dr J's socialism ;)
<br>
<p>=====
<br>
Please visit my web-site at:  <a href="http://www.prometheuscrack.com">http://www.prometheuscrack.com</a>
<br>
<p>Find local movie times and trailers on Yahoo! Movies.
<br>
<a href="http://au.movies.yahoo.com">http://au.movies.yahoo.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8076.html">Tommy McCabe: "Re: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<li><strong>Previous message:</strong> <a href="8074.html">Marc Geddes: "Oops.  Slight correction to my last post..."</a>
<li><strong>In reply to:</strong> <a href="8069.html">Rafal Smigrodzki: "RE: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8078.html">Rafal Smigrodzki: "RE: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<li><strong>Reply:</strong> <a href="8078.html">Rafal Smigrodzki: "RE: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8075">[ date ]</a>
<a href="index.html#8075">[ thread ]</a>
<a href="subject.html#8075">[ subject ]</a>
<a href="author.html#8075">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
