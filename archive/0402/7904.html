<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Creating a Positive Transcension</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="Creating a Positive Transcension">
<meta name="Date" content="2004-02-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Creating a Positive Transcension</h1>
<!-- received="Fri Feb 13 21:55:07 2004" -->
<!-- isoreceived="20040214045507" -->
<!-- sent="Sat, 14 Feb 2004 00:01:44 -0500" -->
<!-- isosent="20040214050144" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="Creating a Positive Transcension" -->
<!-- id="BMECIIDGKPGNFPJLIDNPOEJKCMAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=Re:%20Creating%20a%20Positive%20Transcension"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Fri Feb 13 2004 - 22:01:44 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="7905.html">Mikko Särelä: "RE: Encouraging a Positive Transcension"</a>
<li><strong>Previous message:</strong> <a href="7903.html">Ben Goertzel: "RE: Encouraging a Positive Transcension"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7904">[ date ]</a>
<a href="index.html#7904">[ thread ]</a>
<a href="subject.html#7904">[ subject ]</a>
<a href="author.html#7904">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
In an off-list conversation with Michael Vassar, he has raised some very
<br>
valid and simple points regarding my futurological extrapolation.
<br>
<p>What I take from my conversation from him (which is not exactly the same as
<br>
his perspective) is as follows.
<br>
<p>Firstly: Having human governments work in collaboration with an AI big
<br>
brother would lead to profound corruption (and consequentially to
<br>
existential risks) UNLESS these governments were truly democratic in a sense
<br>
that arguably is not the case right now
<br>
<p>Therefore, two possibilities exist for getting an AI Big Brother in place:
<br>
<p>A) Create a more democratic, less corrupt political system here on Earth,
<br>
and then have the AI Big Brother created as a part of this system
<br>
<p>or
<br>
<p>B) Create an AI that's several times smarter than humans but NOT oriented
<br>
toward unlimited iterative self-improvement, and use it to take over the
<br>
world, hence imposing AI-Big-Brother-dom on the world
<br>
<p><p>Michael thinks that AI's are more dangerous than MNT or biotech, and hence
<br>
he suspects that a better course would be to create an AI-free Big Brother
<br>
using MNT and biotech or some other future technologies.  However, I feel
<br>
strongly that the task of being Big Brother is too hard for any human or
<br>
group of humans, and that AGI would be needed to pull it off.
<br>
<p>Please note, I am not a fan of fascism.  The kind of AI Big Brother I am
<br>
discussing is one whose ONLY function is to prevent humans from doing things
<br>
estimated likely to incur significant existential risks.  And its purpose is
<br>
not to halt progress toward the Singularity, but rather to give humanity
<br>
more time to do careful research on self-improving AI, theoretical ethics,
<br>
and related issues, so as to be able to launch our Transcension in the most
<br>
careful possible way.
<br>
<p>However, there are two major problems with this kind of AI Big Brother:
<br>
<p>A) Creating a more democratic, less corrupt political system is very, very
<br>
hard
<br>
<p>B) Taking over the world is very risky in many ways
<br>
<p><p>I.e., each of the two routes mentioned above is very problematic
<br>
<p>For these reasons, it will really be much nicer if early experiments
<br>
indicate that creation of an AI Buddha is a responsible thing to do...
<br>
<p>Well, isn't reality pesky???
<br>
<p>Some version of these thoughts will go into the revised version of the
<br>
essay.  (These are really just minor variations on the thoughts in the essay
<br>
already, of course.)
<br>
<p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="7905.html">Mikko Särelä: "RE: Encouraging a Positive Transcension"</a>
<li><strong>Previous message:</strong> <a href="7903.html">Ben Goertzel: "RE: Encouraging a Positive Transcension"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#7904">[ date ]</a>
<a href="index.html#7904">[ thread ]</a>
<a href="subject.html#7904">[ subject ]</a>
<a href="author.html#7904">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:45 MDT
</em></small></p>
</body>
</html>
