<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: All sentient have to be observer-centered!  My theory of FAI morality</title>
<meta name="Author" content="Michael Anissimov (michael@acceleratingfuture.com)">
<meta name="Subject" content="Re: All sentient have to be observer-centered!  My theory of FAI morality">
<meta name="Date" content="2004-02-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: All sentient have to be observer-centered!  My theory of FAI morality</h1>
<!-- received="Thu Feb 26 21:19:28 2004" -->
<!-- isoreceived="20040227041928" -->
<!-- sent="Thu, 26 Feb 2004 20:19:26 -0800" -->
<!-- isosent="20040227041926" -->
<!-- name="Michael Anissimov" -->
<!-- email="michael@acceleratingfuture.com" -->
<!-- subject="Re: All sentient have to be observer-centered!  My theory of FAI morality" -->
<!-- id="403EC54E.1010206@acceleratingfuture.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="OJEHKDIANIFPAJPDBDGLOEEGDAAA.rafal@smigrodzki.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Anissimov (<a href="mailto:michael@acceleratingfuture.com?Subject=Re:%20All%20sentient%20have%20to%20be%20observer-centered!%20%20My%20theory%20of%20FAI%20morality"><em>michael@acceleratingfuture.com</em></a>)<br>
<strong>Date:</strong> Thu Feb 26 2004 - 21:19:26 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="8072.html">Marc Geddes: "Re: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<li><strong>Previous message:</strong> <a href="8070.html">Chris Healey: "(no subject)"</a>
<li><strong>In reply to:</strong> <a href="8069.html">Rafal Smigrodzki: "RE: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8073.html">Marc Geddes: "Re: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<li><strong>Reply:</strong> <a href="8073.html">Marc Geddes: "Re: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8071">[ date ]</a>
<a href="index.html#8071">[ thread ]</a>
<a href="subject.html#8071">[ subject ]</a>
<a href="author.html#8071">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Marc, have you carefully read <a href="http://www.intelligence.org/CFAI/anthro.html">http://www.intelligence.org/CFAI/anthro.html</a>?  
<br>
It poses very convincing rebuttals to what you are currently arguing.  
<br>
Quote:
<br>
<p>&quot;There is no reason why an evolved goal system would be anything /but/ 
<br>
observer-focused.  Since the days when we were competing chemical blobs, 
<br>
the primary focus of selection has been the individual.  Even in cases 
<br>
where fitness or inclusive fitness 
<br>
&lt;<a href="http://www.intelligence.org/CFAI/info/glossary.html#gloss_inclusive_reproductive_fitness">http://www.intelligence.org/CFAI/info/glossary.html#gloss_inclusive_reproductive_fitness</a>&gt; 
<br>
is augmented by behaving nicely towards your children, your close 
<br>
relatives, or your reciprocal-altruism trade partners, the selection 
<br>
pressures are still spilling over onto /your/ kin, /your/ children, 
<br>
/your/ partners.  We started out as competing blobs in a sea, each blob 
<br>
with its own measure of fitness.  We grew into competing players in a 
<br>
social network, each player with a different set of goals and subgoals, 
<br>
sometimes overlapping, sometimes not.&quot;
<br>
<p>When selection pressures no longer adhere to single organisms strongly 
<br>
(as in ant colonies), &quot;selfish&quot; behavior gets distributed across the 
<br>
entire colony rather than each unique individual.  Many simple forms of 
<br>
life share most or all of their genetic material with their bretheren, 
<br>
and therefore behave in purely selfless ways.  This happens in a very 
<br>
predictable way... if a selection pressure came into existence that 
<br>
selected for genuine benevolence and/or pure selflessness, then 
<br>
eventually the species in question would evolve that way.  But no such 
<br>
selection pressures exist.  Here is something I once wrote on another list;
<br>
<p>'Try to imagine an animal that evolving for millions of years in an 
<br>
environment where benevolence is the only effective survival strategy, 
<br>
and while a certain amount of psuedoselfish behavior exists as a 
<br>
coincidental subgoal of efficiency. I'm not saying that all beings in 
<br>
the future should be forced to be like this, but it's just a thought 
<br>
experiment to show that the existence of perfectly selfless beings could 
<br>
be possible. If the selection pressures towards altruism were intense 
<br>
enough, not only would benevolence be the only externally observable 
<br>
behavior amongst these entities, but the *tendencies to resort to 
<br>
egotism or notice opportunities for selfish deeds* would not be absent - 
<br>
they would not even be cognitively capable of being egoistic unless they 
<br>
performed neurosurgery on themselves (or whatever.) And why would they 
<br>
want to do such a thing? They might use computational models to see what 
<br>
it would have been like they had evolved more &quot;selfishly&quot;, (a vague, 
<br>
theoretical, abstract concept to them) and see only war, 
<br>
negative-sumness, and counterproductivity. One of the most disturbing 
<br>
things they might notice is that such  a culture could develop memetic 
<br>
patterns which act strongly to preserve the existing cognitive template, 
<br>
and disbelieve proposed designs for minds reliably possessing 
<br>
selflessness, even in the context of a highly selfish world.&quot;
<br>
<p>Maybe you are conflating the idea of an observer-*instantiated* morality 
<br>
and an observer-biased one.  Personal moralities will be instantiated in 
<br>
some observer, by definition, but this doesn't mean that the observer is 
<br>
necessarily *biased* towards him/herself.  Instead of asking whether 
<br>
genuinely selfless beliefs and actions are &quot;logically possible&quot; 
<br>
(philosophical appealing), maybe you should ask if they are physically 
<br>
possible; given a long enough time, could a neuroscientist modify a 
<br>
human brain such that the resulting human was almost entirely selfless?  
<br>
Heck, there is already evidence that the drug E can compel people to act 
<br>
selflessly, and that approach is incredibly untargeted in comparison to 
<br>
what an advanced neurosurgeon could do, never mind an AGI researcher 
<br>
designing an AI from scratch...
<br>
<p>Michael Anissimov
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="8072.html">Marc Geddes: "Re: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<li><strong>Previous message:</strong> <a href="8070.html">Chris Healey: "(no subject)"</a>
<li><strong>In reply to:</strong> <a href="8069.html">Rafal Smigrodzki: "RE: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="8073.html">Marc Geddes: "Re: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<li><strong>Reply:</strong> <a href="8073.html">Marc Geddes: "Re: All sentient have to be observer-centered!  My theory of FAI morality"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#8071">[ date ]</a>
<a href="index.html#8071">[ thread ]</a>
<a href="subject.html#8071">[ subject ]</a>
<a href="author.html#8071">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:46 MDT
</em></small></p>
</body>
</html>
