<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Review of Novamente</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Review of Novamente">
<meta name="Date" content="2002-05-04">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Review of Novamente</h1>
<!-- received="Sat May 04 13:44:53 2002" -->
<!-- isoreceived="20020504194453" -->
<!-- sent="Sat, 4 May 2002 11:41:28 -0600" -->
<!-- isosent="20020504174128" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Review of Novamente" -->
<!-- id="LAEGJLOGJIOELPNIOOAJOEFPCHAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3CD407EA.7576724A@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Review%20of%20Novamente"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sat May 04 2002 - 11:41:28 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3582.html">Ben Goertzel: "RE: Review of A2I2"</a>
<li><strong>Previous message:</strong> <a href="3580.html">Ben Goertzel: "RE: Review of A2I2"</a>
<li><strong>In reply to:</strong> <a href="3577.html">Eliezer S. Yudkowsky: "Review of Novamente"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3586.html">Peter Voss: "RE: Review of Novamente &amp; a2i2"</a>
<li><strong>Reply:</strong> <a href="3586.html">Peter Voss: "RE: Review of Novamente &amp; a2i2"</a>
<li><strong>Reply:</strong> <a href="3639.html">Eliezer S. Yudkowsky: "Re: Review of Novamente"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3581">[ date ]</a>
<a href="index.html#3581">[ thread ]</a>
<a href="subject.html#3581">[ subject ]</a>
<a href="author.html#3581">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi,
<br>
<p>Here is a brief reaction to Eli's reaction to Novamente.
<br>
<p>A fairly high-level overview of NOvamente is at www.realai.net/article.htm
<br>
<p>What Eliezer read was a book-length rough-draft overview of the design.
<br>
I've distributed this manuscript only to a handful of people because it's in
<br>
very crude rough form and in need of many months of editing and rewriting
<br>
and improving.
<br>
<p>Unfortunately, I think that Eliezer did not really understand the basic
<br>
concepts underlying the design, based on his reading of the manuscript.
<br>
Obviously, since Eliezer is very smart and has a fair bit of relevant
<br>
knowledge, this means that the book manuscript is in piss-poor shape.  We
<br>
should have a much better draft within 6 months or so.  My feeling is that
<br>
Eliezer's understanding of the desing was impaired significantly by his
<br>
strong philosophical biases which are different from my own strong
<br>
philosophical biases.
<br>
<p>To sum up before giving details, basically, Eliezer's critique is that
<br>
<p>1) he doesn't see how a collection of relatively simple, generic processes
<br>
working together can give rise to a rich enough set of emergent dynamics and
<br>
structures to support AGI
<br>
<p>2) he doesn't think it's sensible to create a network *some of whose basic
<br>
nodes and links have explicit semantic meaning*, but whose basic cognitive
<br>
dynamics is based on *emergent meaning resident in patterns in the basic
<br>
node-and-link-network&quot;
<br>
<p>Since I can't prove he's wrong or I'm right on these points, I guess it's
<br>
just gonna remain a difference of intuition for a while.
<br>
<p>One nice thing about this sort of work is that it's empirical.  Assuming the
<br>
team holds together, we will finish implementing and testing the mofo and
<br>
see if we're right or wrong.
<br>
<p><em>&gt; My overall reaction is that Novamente is much, much simpler than
</em><br>
<em>&gt; I had been
</em><br>
<em>&gt; visualizing from Ben's descriptions;
</em><br>
<p>Actually we have been explicitly *striving* for simplicity.  Webmind was
<br>
more complex with  more functionally specialized parts.  I look at the
<br>
greater simplicity of Novamente as an advantage.  Of course, the design is
<br>
highly flexible so that we can create greater specialization if it's needed.
<br>
<p>This is a philosophical difference however.  You seem to believe that an AI
<br>
design has to be very complicated.  I think Novamente is still too
<br>
complicated, and that in a good design, a heck of a lot of the complexity of
<br>
mind should emerge rather than being part of the explicit design.   Of
<br>
course the design has to be made with the proper sorts of emergence
<br>
explicitly in mind, and one of the many shortcomings of the current
<br>
Novamente manuscript version is that it doesn't focus on this enough.
<br>
<p><em>&gt; Capsule description of Novamente's architecture:  Novamente's core
</em><br>
<em>&gt; representation is a semantic net, with nodes such as &quot;cat&quot; and &quot;fish&quot;, and
</em><br>
<em>&gt; relations such as &quot;eats&quot;.  Some kind of emotional reaction is called for
</em><br>
<em>&gt; here, lest others suspect me of secret sympathies for semantic networks:
</em><br>
<em>&gt; &quot;AAAARRRRGGGHHH!&quot;  Having gotten that over with, let's forge ahead.
</em><br>
<p>This is not a correct statement; the core data representation is not a
<br>
semantic network.
<br>
<p>It is a NETWORK, with nodes and links.  Some nodes and links may have
<br>
transparent semantic meaning, such as &quot;cat&quot; or &quot;eats&quot;.  Others -- the vast
<br>
majority -- will not.  And if a node has a transparent meaning like &quot;cat&quot;,
<br>
this meaning (and the node) must be built by the system, not loaded in
<br>
externally.
<br>
<p>The intention is that much of the semantics of the system resides, not
<br>
directly in individual nodes and links, but rather in &quot;maps&quot; or
<br>
&quot;attractors&quot; -- patterns of connectivity and interconnection involving large
<br>
numbers of nodes and links.
<br>
<p>Quite explicitly, the node-and-link structure and dynamics aims to combine
<br>
aspects of semantic networks and neural networks.
<br>
<p>It is not a semantic network according to standard definitions, far from it,
<br>
because the majority of nodes do not have any individual semantic meaning
<br>
easily translatable into English or any other human language.
<br>
<p>It may be too close to semantic networks for your taste, but this does not
<br>
make it a semantic network.
<br>
<p><em>&gt; Novamente's core representation is not entirely that of a
</em><br>
<em>&gt; classical AI; Ben
</em><br>
<em>&gt; insists that it be described as &quot;term logic&quot; rather than
</em><br>
<em>&gt; &quot;predicate logic&quot;,
</em><br>
<em>&gt; meaning that it has quantitative truth values and quantitative attention
</em><br>
<em>&gt; values (actually, Novamente can express more complex kinds of truth values
</em><br>
<em>&gt; and attention values than simple quantities).
</em><br>
<p>Okay, there two different confusions in this paragraph.
<br>
<p>1) Logical inference is only one among very many dynamics involved in
<br>
Novamente.  &quot;Term logic&quot; is not a representation, it is a way of combining
<br>
some links to form new links.  The node-and-link representation is designed
<br>
to support probabilistic term logic among many other important dynamics.
<br>
<p>2) The difference between predicate logic and term logic has nothing to do
<br>
with the use of probabilistic truth values.  The difference between
<br>
predicate logic and term logic has to do with the structure of the inference
<br>
rules involved.  In term logic two statements can only be combined if they
<br>
share common terms; this is not true in predicate logic.  This difference
<br>
has a lot of philosophical implications: it means that term logic is not
<br>
susceptible to the same logical paradoxes as predicate logic, and that term
<br>
logic is better suited for implementation in a distributed self-organizing
<br>
knowledge system like Novamente.
<br>
<p><em>&gt; Similarly, Novamente's
</em><br>
<em>&gt; logical inference processes are also quantitative; fuzzy logic rather than
</em><br>
<em>&gt; theorem proving.
</em><br>
<p>Again there are two different confusions overlaid.
<br>
<p>First, &quot;Fuzzy logic&quot; in the technical sense has no role in Novamente.
<br>
<p>Next, there is a whole chapter in the  manuscript on theorem-proving.  I
<br>
think this is one thing the system will eventually be able to do quite well.
<br>
In fact, I think that probabilistic inference and other non-inferential
<br>
cognitive aspects like evolutionary concept creation and
<br>
association-formation, are highly critical to mathematical theorem-proving.
<br>
<p>And I think that expertise at theorem-proving will be an important partway
<br>
step towards intelligent goal-directed self-modification.  There was an SL4
<br>
thread on the possible use of the Mizar theorem/proof database for this
<br>
purpose, about a year ago.
<br>
<p><p><em>&gt;&gt; However, from my perspective, Novamente has very *simple* behaviors for
</em><br>
<em>&gt; inference, attention, generalization, and evolutionary programming.
</em><br>
<p>We have tried to simplify these basic cognitive processes as much as
<br>
possible.
<br>
<p>The complexity of cognition is intended to emerge from the self-organizing
<br>
interaction of the right set of simple processes on a large set of
<br>
information.  NOT from complexity of the basic behaviors.
<br>
<p><em>&gt;  For
</em><br>
<em>&gt; example, Novamente notices spontaneous regularities by handing off the
</em><br>
<em>&gt; problem to a generic data-mining algorithm on a separate server.  The
</em><br>
<em>&gt; evolutionary programming is classical evolutionary programming.
</em><br>
<em>&gt; The logical
</em><br>
<em>&gt; inference has classical Bayesian semantics.  Attention spreads
</em><br>
<em>&gt; outward like
</em><br>
<em>&gt; ripples in a pond.
</em><br>
<p>All of these statements are wrong, Eliezer.
<br>
<p>Novamente notices regularities in internal and external by many different
<br>
mechanisms.  The Apriori datamining algorithm that you mention is a simple
<br>
preprocessing technique used to suggest potentially interesting regularities
<br>
to the main cognition algorithms.  It is by no means the sum total or even
<br>
the centerpiece of the system's approach to recognizing regularities.
<br>
<p>The evolutionary programming in Novamente is not classical ev. programming;
<br>
it has at least two huge innovations (only one of which has been tested so
<br>
far): 1) evolution is hybridized with probabilistic inference, which can
<br>
improve efficiency by a couple orders of magnitude, 2) evolution takes place
<br>
on node-and-link structures interpretable as combinatory logic expressions,
<br>
which  means that functions with loops and recursion can be much  more
<br>
efficiently learned (this is not yet tested).  These may sound like small
<br>
technical improvements, but they are specifically improvements that allow
<br>
ev. prog. to become smarter &amp; more effective thru feedback with other parts
<br>
of the mind.
<br>
<p>The logical inference system does not have classical Bayesian semantics, not
<br>
at all.  No single consistent prior or posterior distribution is assumed
<br>
over all knowledge available to the system.  Rather, each individual
<br>
inference constructs its own distributions prior to inference.  This means
<br>
that the inference behavior of the system as a whole involves many
<br>
overlapping pdf's rather than one big pdf.  This is just NOT classical
<br>
Bayesian semantics in any sense, sorry.
<br>
<p><em>&gt; Novamente does not have the complexity that
</em><br>
<em>&gt; would render
</em><br>
<em>&gt; these problems tractable; the processes may intersect in a common
</em><br>
<em>&gt; representation but the processes themselves are generic.
</em><br>
<p>If by &quot;generic&quot; you mean that Novamente's basic cognitive processes are not
<br>
functionally specialized, you are correct.
<br>
<p>And I think this is as it should be.
<br>
<p><p><em>&gt; Ben believes that Novamente will support another level of
</em><br>
<em>&gt; organization above
</em><br>
<em>&gt; the current behaviors, so that inference/attention/mining/evolution of the
</em><br>
<em>&gt; low level can support complex constructs on the high level.  While I
</em><br>
<em>&gt; naturally agree that having more than one level of organization is a step
</em><br>
<em>&gt; forward, the idea of trying to build a mind on top of low-level behaviors
</em><br>
<em>&gt; originally constructed to imitate inference and attention is... well,
</em><br>
<em>&gt; Novamente is already the most alien thing I've ever tried to wrap my mind
</em><br>
<em>&gt; around;
</em><br>
<p>I am afraid that, because the description you read was a very sloppy rough
<br>
draft, and because the design is so intuitively alien to you, you have
<br>
managed to achieve only a very partial understanding of the system.  Many
<br>
things that, to me, are highly conceptually and philosophically significant,
<br>
you seem to pass off as &quot;implementation details&quot; or &quot;tweaks to existing
<br>
algorithms.&quot;
<br>
<p><em>&gt; if Novamente's current behaviors can give rise to full
</em><br>
<em>&gt; cognition at
</em><br>
<em>&gt; higher levels of organization, it would make Novamente a mind so
</em><br>
<em>&gt; absolutely
</em><br>
<em>&gt; alien that it would make a human and a Friendly AI look like
</em><br>
<em>&gt; cousins.
</em><br>
<p>Yes, I agree, if Novamente becomes a mind it will be a very alien mind.  We
<br>
are not trying to emulate human intelligence, not at all.  Equal and
<br>
surpass, but not emulate.
<br>
<p>To emulate human intelligence on a digital computer, we need: a) way bigger
<br>
computers, b) way  more understanding of how the brain works.
<br>
<p>The only hope for the short run, in my view, is to seek to build a very
<br>
alien intelligence, one that exploits the unique power of digital computers
<br>
rather than trying to emulate the brain and its dynamics in any detail.
<br>
<p><em>&gt;  The lower
</em><br>
<em>&gt; levels of Novamente were designed with the belief that these lower levels,
</em><br>
<em>&gt; in themselves, implemented cognition, not with the intent that these low
</em><br>
<em>&gt; levels should support higher levels of organization.
</em><br>
<p>This is completely untrue.  You were not there when we designed these
<br>
levels, so how on Earth can you make this presumption??
<br>
<p>I spent the 8 years before starting designing Webmind, writing books and
<br>
paper on self-organization and emergence in the mind.  (See especially
<br>
Chaotic Logic and From Complexity to Creativity)
<br>
<p>OF COURSE, I did not design the lower levels of the system without the
<br>
emergence of a higher level of structure and dynamics as a key goal.
<br>
<p><p><em>&gt; For example, Ben has
</em><br>
<em>&gt; indicated that while he expects high-level inference on a
</em><br>
<em>&gt; separate level of
</em><br>
<em>&gt; organization to emerge above the current low-level inferential
</em><br>
<em>&gt; behaviors, he
</em><br>
<em>&gt; believes that it would be good to summarize the high-level patterns as
</em><br>
<em>&gt; individual Novamente nodes so that the faster and more powerful low-level
</em><br>
<em>&gt; inference mechanisms can operate on them directly.
</em><br>
<p>I think that the automated recognition *by the system* of high-level
<br>
patterns in the system's mind, and the encapsulation of these patterns in
<br>
individual nodes, is *one valuable cognitive heuristic* among many.
<br>
<p>The interplay between the concretely implemented structures/dynamics and the
<br>
emergent ones, in Novamente, is going to be quite complex and interesting.
<br>
This is where the complexity SHOULD lie, not at the level of the basic
<br>
implemented structures and dynamics.
<br>
<p><em>&gt; To see a genuine AI capability, you have to strip away the suggestive
</em><br>
<em>&gt; English names and look at what behaviors the system supports even
</em><br>
<em>&gt; if nobody
</em><br>
<em>&gt; is interpreting it.  When I look at Novamente through that lens, I see a
</em><br>
<em>&gt; pattern-recognition system that may be capable of achieving limited goals
</em><br>
<em>&gt; within the patterns it can recognize, although the goal system currently
</em><br>
<em>&gt; described (and, as I understand, not yet implemented or tested)
</em><br>
<p>Webmind's goal system was implemented and tested, Novamente's is not (yet).
<br>
<p><em>&gt; would permit
</em><br>
<em>&gt; Novamente to achieve only a small fraction of the goals it should
</em><br>
<em>&gt; be capable
</em><br>
<em>&gt; of representing.  Checking with Ben confirmed that all of the old Webmind
</em><br>
<em>&gt; system's successes were in the domain of pattern recognition, so
</em><br>
<em>&gt; it doesn't
</em><br>
<em>&gt; look like my intuitions are off.
</em><br>
<p>Yes, we were developing Webmind in the context of a commercial corporation,
<br>
and so most of our practical testing concerned pragmatic data analysis
<br>
tasks.  This doesn't mean that the architecture was designed to support ONLY
<br>
this kind of behavior, nor even that it was the most natural stuff for us to
<br>
be doing, in AI terms.  In fact, we ended up using the system for a lot of
<br>
&quot;text analysis&quot; work that it was really relatively *ill-suited* for, because
<br>
that was what the business's products needed.  (And the system performed
<br>
well at text analysis, even though this really wasn't an appropriate
<br>
application for it at that stage of its development).
<br>
<p>Developing AI in a biz context has its plusses and minuses.  The big plus is
<br>
plenty of resources.  The big minus is that you get pushed into spending a
<br>
lot of time on applications that distract the focus from real AI.
<br>
<p><em>&gt; By the standards I would apply to real AI, Novamente is
</em><br>
<em>&gt; architecturally very
</em><br>
<em>&gt; simple and is built around a relative handful of generic
</em><br>
<em>&gt; behaviors; I do not
</em><br>
<em>&gt; believe that Novamente as it stands can support Ben's stated goals of
</em><br>
<em>&gt; general intelligence, seed AI, or even the existence of substantial
</em><br>
<em>&gt; intelligence on higher levels of organization.
</em><br>
<p>You are right: Novamente is architecturally relatively simple and is built
<br>
around a relative handful of generic behaviors.
<br>
<p>It is not all THAT simple of course: it will definitely be 100,000-200,000
<br>
lines of C++ code when finished, and it involves around 20 different mental
<br>
dynamics.  But it is a lot simpler than Eliezer would like.  And I think its
<br>
*relative* simplicity is a good thing.
<br>
<p>I suspect that an AI system with 200 more specialized mental dynamics,
<br>
rather than 20 generic ones, would be effectively impossible for a team of
<br>
humans to program, debug and test.  So: Eliezer, I think that IF you're
<br>
right about the level of complexity needed (which I doubt), THEN Kurzweil is
<br>
also right that the only viable approach to real AI is to emulate human
<br>
brain-biology in silico.  Because I think that implementing a system 10
<br>
times more complex than Novamente via software engineering rather than
<br>
brain-emulation is not going to be feasible.
<br>
<p>Anyway, I do not claim to have proved that Novamente will lead to seed AI or
<br>
AGI.  Obviously, right now, whether it will or will not is largely a matter
<br>
of intuition.
<br>
<p>However, I should add that I am not the *only* person on Earth who believes
<br>
Novamente has a fighting chance at achieving its goals; there are at least a
<br>
dozen others who understand the design pretty well and feel as I do.  So  my
<br>
intuition is not a unique one.
<br>
<p>The book draft that I sent Eliezer to read was really quite rough and hard
<br>
to understand.  It is obvious from the comments in his e-mail to SL4 that he
<br>
missed a few rather basic points, for which I blame myself for not writing a
<br>
better book (though it will be much better before we distribute it widely).
<br>
However, I suspect that even when the book is in great form, Eliezer still
<br>
won't like the design, because he has radically different intuitions than me
<br>
about what an AGI design should look like.
<br>
<p>And I think that's just fine.
<br>
<p>I look forward to, one day in the future, Eliezer sending *me* a detailed
<br>
description of his own design for an AGI/seed-AI, so I can tell him why
<br>
according to my intuition, his design can't possibly work ;&gt;   Or maybe not,
<br>
maybe I'll be convinced, who knows!!
<br>
<p>I definitely don't claim that Novamente is the ONLY path to AGI/seed-AI.  In
<br>
spite of Eliezer's criticisms, I still believe it is *a* feasible path.  And
<br>
I think that Peter Voss's approach *may be* a path -- I don't know all the
<br>
details of his work, and I haven't thought nearly as hard about his approach
<br>
as about my own.
<br>
<p><p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3582.html">Ben Goertzel: "RE: Review of A2I2"</a>
<li><strong>Previous message:</strong> <a href="3580.html">Ben Goertzel: "RE: Review of A2I2"</a>
<li><strong>In reply to:</strong> <a href="3577.html">Eliezer S. Yudkowsky: "Review of Novamente"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3586.html">Peter Voss: "RE: Review of Novamente &amp; a2i2"</a>
<li><strong>Reply:</strong> <a href="3586.html">Peter Voss: "RE: Review of Novamente &amp; a2i2"</a>
<li><strong>Reply:</strong> <a href="3639.html">Eliezer S. Yudkowsky: "Re: Review of Novamente"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3581">[ date ]</a>
<a href="index.html#3581">[ thread ]</a>
<a href="subject.html#3581">[ subject ]</a>
<a href="author.html#3581">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
