<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Request for Trans Guide.</title>
<meta name="Author" content="Michael Anissimov (altima@yifan.net)">
<meta name="Subject" content="Re: Request for Trans Guide.">
<meta name="Date" content="2002-05-02">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Request for Trans Guide.</h1>
<!-- received="Thu May 02 17:23:57 2002" -->
<!-- isoreceived="20020502232357" -->
<!-- sent="Thu, 2 May 2002 16:06:02 -0400" -->
<!-- isosent="20020502200602" -->
<!-- name="Michael Anissimov" -->
<!-- email="altima@yifan.net" -->
<!-- subject="Re: Request for Trans Guide." -->
<!-- id="3cd19c2a.5eea.0@yifan.net" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="Request for Trans Guide." -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Anissimov (<a href="mailto:altima@yifan.net?Subject=Re:%20Request%20for%20Trans%20Guide."><em>altima@yifan.net</em></a>)<br>
<strong>Date:</strong> Thu May 02 2002 - 14:06:02 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3522.html">Eliezer S. Yudkowsky: "Re: The Ultimate Connection Machine."</a>
<li><strong>Previous message:</strong> <a href="3520.html">ben goertzel: "RE: The Ultimate Connection Machine."</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3521">[ date ]</a>
<a href="index.html#3521">[ thread ]</a>
<a href="subject.html#3521">[ subject ]</a>
<a href="author.html#3521">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
When we start making guesses about entities with perceptual schemata 
<br>
more complex than our own, we run into inherent cognitive limits.  
<br>
See &quot;Staring Into the Singularity&quot;.  If you've played the Game of Life 
<br>
and its closely related cousins, you can see how even a minor change in 
<br>
underlying rules of the behavior of the system can yield radical 
<br>
emergent differences.  So conversations regarding the ethics of 
<br>
Transition Guides should not be confused with plotting out the course 
<br>
of the Spike itself as we near the creation of AI.  Outsiders will 
<br>
never take us seriously if they think we are lumping our post-
<br>
Singularity predictions together with our pre-Singularity plans.  I 
<br>
think this is another fundamental difference between an 'Extropian' and 
<br>
a 'Singularitarian' as well; we don't talk about the future so much as 
<br>
we *make* the future right now.  
<br>
<p>As for my guess, which I readily admit is only based on personal ethics 
<br>
and foundationless speculation, is that everything will immediately 
<br>
change entirely, yet in a way we are comfortable with.  A Power would 
<br>
able to subtly play with the 'underlying rules of the game' that we 
<br>
don't even notice in a skilled act of applied systems theory.  I don't 
<br>
think volition will be 'respected' in the strict reified sense we use 
<br>
to describe it now, but I don't think we'll mind, or maybe we won't 
<br>
even notice.  I personally think that a benevolent, 'omnipotent' 
<br>
normative altruistic sentience (not I don't say 'superintelligent', 
<br>
because there's no way I can project that - I can only guess for an 
<br>
idealized altruistic sentience) will seamlessly upload the entire 
<br>
Earth, and let individual sentients transcend to higher levels of 
<br>
existence if their own 'volition', if such a thing exists, permits.  
<br>
But I don't think it will be a question of volition alone.  A SI could 
<br>
*anticipate* a human being's deepest desires and fullfill them before 
<br>
the human being ever thought of them verself.  Some people might want 
<br>
this.  I don't think you'll necessarily have to say &quot;I want such and 
<br>
such&quot; out loud for a Sysop to know that you want something.  
<br>
Fullfillment-of-desires type scenarios can lead to odd circumstances, 
<br>
from the human perspective:
<br>
<p>~Singularity occurs~
<br>
~Sysop subprogram manifests
<br>
in Michael's room as a NeoAtlantean
<br>
digital angel~
<br>
<p>Angel:  How may I help you?
<br>
Michael:  *drops the vase he was holding.*  FINALLY!
<br>
Michael:  *CRASH*  I want A, B, and C.
<br>
Angel:  *gives Michael A, B, and C.*  Are you satisfied?  Scanning your 
<br>
cognitive matrix now, I can see that the desire for Aa, Ba, and Ca are 
<br>
manifesting.  Extruxtrapolating* to what you will do after you get 
<br>
those, I can see that you will want Ab, Bb, and Cb.  Each subsequent 
<br>
desire will subsume the others, so in a way you are wasting your time 
<br>
with the earlier ones.  But if your intelligence were fundamentally 
<br>
enhanced, none of these other things would concern you, you would be 
<br>
interested in D, E, and F.
<br>
Michael:  Enhance my intelligence so it goes through the roof, then!
<br>
Angel:  If I enhanced your intelligence using all my available 
<br>
computing power, your identity would fragment and you would experience 
<br>
a death forward.  This is not compatible with your current desires.
<br>
Michael1:  Oh dear...just set me up with a sharp upwards curve in 
<br>
enhancement, supplemented by a complex hierarchial scheme of novel 
<br>
problems and corresponding modified and enhanced emotional drives, in 
<br>
that case.
<br>
Michael2: Screw my current desires!  Full speed ahead!
<br>
I want to be an ArchPower!
<br>
<p>*The Sysop anticipated that I would appreciate ver making up a new 
<br>
word!  Clever folk, those Sysop subprograms.
<br>
<p>What's a Sysop Angel to do in a scenario like this?  Who is right, what 
<br>
is going on?  Is Michael2 caving into his hidden desire to become 
<br>
tribal chief?  Does the Sysop have a responsibility to stop this?  Is 
<br>
Michael1 being a wuss?  Is the only way that a Sysop can fullfill 
<br>
people's desires is by continuously anticipating what they want to know 
<br>
or do in any given situation?  Will any of these concepts make sense 
<br>
after the Singularity?  If we are destroyed by nukes, we will never 
<br>
know.  If we are good Singularitarians, and think about AI and spread 
<br>
the correct memes, we may one day figure it out.
<br>
<p>I harbor a degree of panpsychist sentiment myself; and since a Power 
<br>
would so rapidly transcend everything that had every previously 
<br>
existed, I think the differences between rocks and humans will seem 
<br>
like much much less.  If there is a &quot;magical threshold&quot; 
<br>
called &quot;sentience&quot;, then a Power will cross another billion &quot;magical 
<br>
thresholds&quot; in the first week of the Singularity.  I believe a Power 
<br>
would implement a &quot;scalable morality model&quot; - and everyone will agree 
<br>
its fair.  The presence of this &quot;double standard&quot; will be 
<br>
indistinguishable to any one being - the moral scale will be so gradual 
<br>
that no individual being will be able to communicate with another being 
<br>
and feel like they are being &quot;deprived of morality&quot;.  What I'm speaking 
<br>
of isn't &quot;morality&quot; in the human sense either - it's a sort of 
<br>
cognitive architecture-transcending &quot;morality&quot; that we would probably 
<br>
understand more readily as &quot;delegation of resources&quot;.  If you give a 
<br>
Power an ExaExabyte of memory, ve will be able to make use of it.  If 
<br>
you give that to a static upload, it's pointless.  So I think &quot;Zones&quot; 
<br>
will be created in which more sophisticated beings live in more 
<br>
compressed, complex, fluxacious (ah, yes, I made up a word.  I don't 
<br>
care.), intense environments, and more mild beings can live in &quot;Fringe 
<br>
Zones&quot;.  A Power can fragment into a legion of mild beings, each one 
<br>
going exploring in a novel, 'lesser-density' area of Fun Space, then 
<br>
perhaps remerging at a later date.  Who really knows, this is all 
<br>
worthless, unimaginative, pathetic homo sapiens sapiens gibberish.  All 
<br>
I can do is hope the future shock of our idle speculations have a 
<br>
positive memetic effect.
<br>
<p>Michael Anissimov
<br>
<p>-----------------------------------------------------
<br>
<a href="http://eo.yifan.net">http://eo.yifan.net</a>
<br>
Free POP3/Web Email, File Manager, Calendar and Address Book
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3522.html">Eliezer S. Yudkowsky: "Re: The Ultimate Connection Machine."</a>
<li><strong>Previous message:</strong> <a href="3520.html">ben goertzel: "RE: The Ultimate Connection Machine."</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3521">[ date ]</a>
<a href="index.html#3521">[ thread ]</a>
<a href="subject.html#3521">[ subject ]</a>
<a href="author.html#3521">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
