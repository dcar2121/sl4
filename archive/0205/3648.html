<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: A Hard Take Off.</title>
<meta name="Author" content="Spudboy100@aol.com (Spudboy100@aol.com)">
<meta name="Subject" content="Re: A Hard Take Off.">
<meta name="Date" content="2002-05-10">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: A Hard Take Off.</h1>
<!-- received="Sat May 11 04:48:30 2002" -->
<!-- isoreceived="20020511104830" -->
<!-- sent="Fri, 10 May 2002 21:21:34 EDT" -->
<!-- isosent="20020511012134" -->
<!-- name="Spudboy100@aol.com" -->
<!-- email="Spudboy100@aol.com" -->
<!-- subject="Re: A Hard Take Off." -->
<!-- id="152.dbc1302.2a0dcc1e@aol.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="A Hard Take Off." -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> <a href="mailto:Spudboy100@aol.com?Subject=Re:%20A%20Hard%20Take%20Off."><em>Spudboy100@aol.com</em></a><br>
<strong>Date:</strong> Fri May 10 2002 - 19:21:34 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3649.html">Eliezer S. Yudkowsky: "Re: Review of Novamente"</a>
<li><strong>Previous message:</strong> <a href="3647.html">Mike & Donna Deering: "AI on the Web"</a>
<li><strong>Maybe in reply to:</strong> <a href="3645.html">Mike & Donna Deering: "A Hard Take Off."</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3648">[ date ]</a>
<a href="index.html#3648">[ thread ]</a>
<a href="subject.html#3648">[ subject ]</a>
<a href="author.html#3648">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
In a message dated 5/10/2002 11:46:38 AM Eastern Daylight Time, 
<br>
<a href="mailto:deering9@mchsi.com?Subject=Re:%20A%20Hard%20Take%20Off.">deering9@mchsi.com</a> writes:
<br>
<p><em>&gt; Joe: &quot;Common resources?&quot;
</em><br>
<em>&gt;  Melissa: &quot;There are lots of common resources.  Public spaces, energy,
</em><br>
<em>&gt;  computational resources.  The general situation is, three days ago a super
</em><br>
<em>&gt;  intelligent computer system can into existence.  It built the structure and
</em><br>
<em>&gt;  some other infrastructure inside the Earth and Moon.  If a human's
</em><br>
<em>&gt;  intelligence is 100 and mine is 641 FAI's is 3 X 10 ^ 43.  FAI's
</em><br>
<em>&gt;  capabilities are not unlimited but are quite significant.
</em><br>
<p>This brings up a query of mine which impacts the arrival of a singularity. 
<br>
Has the Foresight Institute, or any other business or educational 
<br>
organization (technological forecasters?) ever undertaken a delphi poll on 
<br>
when a singularity may arrive?
<br>
<p>A delphi poll, for the mildly interested, is the practice of asking a 
<br>
question, frequently in both essay and typical poll-taker format; regarding 
<br>
the likelihood, and and effective date, for the arrival of a technology, or 
<br>
event.  The first run, the interviewee' is asked in private what their 
<br>
opinions are, and if necessary, to elaborate with a short essay on why they 
<br>
hold a certain view.  The second run, is where they are asked the same 
<br>
question, but others of the group of interviewee's are able to read each 
<br>
others' answers. Supposedly, this is a useful means of technological 
<br>
forecasting.  
<br>
<p>I wonder when a take-off, hard or smoother is really due? Who would be the 
<br>
experts or cohorts in such a estimation? Would physicists, chemists, 
<br>
engineers, who work in nanotech or materials science be the people to ask? 
<br>
Would people in this list be the primary interviewee's, since most here are 
<br>
involved as programmer/analysts and computer scientists?
<br>
<p>&lt;&lt;Joe: &quot;Common resources?&quot;
<br>
Melissa: &quot;There are lots of common resources.  Public spaces, energy,
<br>
computational resources.  The general situation is, three days ago a super
<br>
intelligent computer system can into existence.  It built the structure and
<br>
some other infrastructure inside the Earth and Moon.  If a human's
<br>
intelligence is 100 and mine is 641 FAI's is 3 X 10 ^ 43.  FAI's
<br>
capabilities are not unlimited but are quite significant.&gt;&gt;
<br>
(A very entertaining conjecture-worthy of Drexler)
<br>
<p>Moreover, what is the practical computational limit for matter we know 
<br>
exists, rather then likely exists (neutonium/computronium/unobtainium). Is it 
<br>
reasonable to expect a hyperintelligence to be so many times the unit of a 
<br>
human intelligence? I wonder if intelligence, like the speed of light, has a 
<br>
embedded limit?  Does &quot;smartness&quot; cut off at 4 times human intelligence, or 4 
<br>
trillion times or, does it exponentiate, asymtotically?
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3649.html">Eliezer S. Yudkowsky: "Re: Review of Novamente"</a>
<li><strong>Previous message:</strong> <a href="3647.html">Mike & Donna Deering: "AI on the Web"</a>
<li><strong>Maybe in reply to:</strong> <a href="3645.html">Mike & Donna Deering: "A Hard Take Off."</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3648">[ date ]</a>
<a href="index.html#3648">[ thread ]</a>
<a href="subject.html#3648">[ subject ]</a>
<a href="author.html#3648">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
