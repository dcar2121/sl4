<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: supergoal stability</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: supergoal stability">
<meta name="Date" content="2002-05-03">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: supergoal stability</h1>
<!-- received="Fri May 03 20:36:49 2002" -->
<!-- isoreceived="20020504023649" -->
<!-- sent="Fri, 3 May 2002 18:19:08 -0600" -->
<!-- isosent="20020504001908" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: supergoal stability" -->
<!-- id="LAEGJLOGJIOELPNIOOAJGEFFCHAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3CD32272.70F48E88@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20supergoal%20stability"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Fri May 03 2002 - 18:19:08 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3557.html">Ben Goertzel: "RE: supergoal stability"</a>
<li><strong>Previous message:</strong> <a href="3555.html">Max Comess: "Top down vs. bottom up AI synthesis, a(n attempt at) clarification of my previous posts"</a>
<li><strong>In reply to:</strong> <a href="3554.html">Eliezer S. Yudkowsky: "Re: supergoal stability"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3557.html">Ben Goertzel: "RE: supergoal stability"</a>
<li><strong>Reply:</strong> <a href="3557.html">Ben Goertzel: "RE: supergoal stability"</a>
<li><strong>Reply:</strong> <a href="3561.html">Eliezer S. Yudkowsky: "Re: supergoal stability"</a>
<li><strong>Reply:</strong> <a href="3562.html">Peter Voss: "RE: supergoal stability"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3556">[ date ]</a>
<a href="index.html#3556">[ thread ]</a>
<a href="subject.html#3556">[ subject ]</a>
<a href="author.html#3556">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi,
<br>
<p><em>&gt; Is a complex nonlinear dynamical system really the right way to look at a
</em><br>
<em>&gt; Friendly AI?  This is an intelligent being we're talking about, capable of
</em><br>
<em>&gt; making choices.
</em><br>
<p>I do think that minds are *necessarily* complex nonlinear dynamical systems.
<br>
This is an intuition, I certainly haven't proved it.
<br>
<p>As for &quot;capable of making choices&quot;, this comment opens up a huge
<br>
philosophical debate.  As you know the neurophysiological evidence
<br>
(Gazzaniga etc.) is that most of our &quot;felt conscious choices&quot; are actually
<br>
determined by unconscious processes.  List members who don't know this work
<br>
should look up Gazzaniga's split-brain experiments, which are terribly
<br>
convincing in this regard.
<br>
<p>So I think what we call &quot;choice&quot; is a pretty complex nonlinear dynamical
<br>
phenomenon itself.  Nietzsche said, &quot;Consciousness is like the general who
<br>
takes responsibility for the spontaneous actions of his troops.&quot;  This is a
<br>
lot though not all of the story.  Consciousness also, by fallaciously taking
<br>
responsibility for decisions it did not in any real sense make, provides a
<br>
valuable role of clarifying and crystallizing the nature of decisions that
<br>
the unconscious has already made.  I think Nietzsche knew this but did not
<br>
emphasize it.  The general, when he takes credit for what the troops did,
<br>
explains clearly what the troops did, in a way that may help the troops to
<br>
spontaneously and self-organizingly do even better things next time.
<br>
<p><em>&gt; The Singularity is not a complex nonlinear dynamical
</em><br>
<em>&gt; process - it is alive
</em><br>
<p>I don't see how you can say the Singularity is &quot;alive.&quot;  How are you
<br>
defining life?  Normally it is defined in terms of metabolism and
<br>
reproduction.
<br>
<p><em>&gt; there is an intelligence, in fact a transhuman
</em><br>
<em>&gt; intelligence, standing behind it and making choices.
</em><br>
<p>The half-illusion of &quot;choice&quot; is, in my view, a complex nonlinear dynamical
<br>
process itself
<br>
<p><em>&gt;You can't create
</em><br>
<em>&gt; Friendly AI by blindly expecting it to be intelligent and alive;
</em><br>
<p>Well, this is kind of obvious, and I'm certainly not taking that sort of
<br>
approach.  No one is, actually.  This is a bit of a &quot;straw man&quot; type
<br>
argument, I'm afraid.
<br>
<p><em>&gt; If, when you've created Friendly AI
</em><br>
<em>&gt; through your design understanding, someone with a surface understanding
</em><br>
<em>&gt; looks at the system and says:  &quot;Oh, look, a self-modifying goal
</em><br>
<em>&gt; system that
</em><br>
<em>&gt; follows a complex nonlinear dynamic,&quot; instead of &quot;Oh, look, a mind that
</em><br>
<em>&gt; understands philosophy and is trying to improve itself,&quot; then
</em><br>
<em>&gt; you've screwed
</em><br>
<em>&gt; up the job completely.
</em><br>
<p>I think those two perspectives are complementary and not contradictory.
<br>
<p>I can look at YOU, Eliezer, and make both those statements honestly and
<br>
without contradiction
<br>
<p><em>&gt; If you see the process of a mind improving itself as randomly
</em><br>
<em>&gt; drifting, then
</em><br>
<em>&gt; you won't be able to create Friendly AI because you won't be
</em><br>
<em>&gt; looking at the
</em><br>
<em>&gt; forces that make it more than random drift.
</em><br>
<p>Again this straw man argument.  No, I don't see the process of a mind
<br>
improving itself as randomly drifting.  No one does, probably.
<br>
<p>Clearly &quot;complex nonlinear dynamic&quot; is not equal to &quot;random drift&quot;
<br>
<p><em>&gt; &quot;a Friendly AI reasoning
</em><br>
<em>&gt; about morality is A NONLINEAR DYNAMIC SYSTEM&quot;.  But to actually *build*
</em><br>
<em>&gt; Friendly AI, the only appropriate and useful metaphor is &quot;A Friendly AI
</em><br>
<em>&gt; reasoning about morality is A FRIENDLY AI REASONING ABOUT MORALITY.&quot;
</em><br>
<p>Eliezer,  &quot;a Friendly AI reasoning about morality is A NONLINEAR DYNAMIC
<br>
SYSTEM&quot; is not intended by me as a METAPHOR.
<br>
<p>It is actually a precise mathematical statement, using commonly defined
<br>
mathematical terms.
<br>
<p><p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3557.html">Ben Goertzel: "RE: supergoal stability"</a>
<li><strong>Previous message:</strong> <a href="3555.html">Max Comess: "Top down vs. bottom up AI synthesis, a(n attempt at) clarification of my previous posts"</a>
<li><strong>In reply to:</strong> <a href="3554.html">Eliezer S. Yudkowsky: "Re: supergoal stability"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3557.html">Ben Goertzel: "RE: supergoal stability"</a>
<li><strong>Reply:</strong> <a href="3557.html">Ben Goertzel: "RE: supergoal stability"</a>
<li><strong>Reply:</strong> <a href="3561.html">Eliezer S. Yudkowsky: "Re: supergoal stability"</a>
<li><strong>Reply:</strong> <a href="3562.html">Peter Voss: "RE: supergoal stability"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3556">[ date ]</a>
<a href="index.html#3556">[ thread ]</a>
<a href="subject.html#3556">[ subject ]</a>
<a href="author.html#3556">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
