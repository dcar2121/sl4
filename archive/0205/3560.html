<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Top down vs. bottom up AI synthesis, a(n attempt at) clarification of my previous posts</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Top down vs. bottom up AI synthesis, a(n attempt at) clarification of my previous posts">
<meta name="Date" content="2002-05-03">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Top down vs. bottom up AI synthesis, a(n attempt at) clarification of my previous posts</h1>
<!-- received="Fri May 03 21:04:37 2002" -->
<!-- isoreceived="20020504030437" -->
<!-- sent="Fri, 3 May 2002 18:56:02 -0600" -->
<!-- isosent="20020504005602" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Top down vs. bottom up AI synthesis, a(n attempt at) clarification of my previous posts" -->
<!-- id="LAEGJLOGJIOELPNIOOAJEEFHCHAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="004b01c1f2e6$f9d0dfe0$8500a8c0@we.client2.attbi.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Top%20down%20vs.%20bottom%20up%20AI%20synthesis,%20a(n%20attempt%20at)%20clarification%20of%20my%20previous%20posts"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Fri May 03 2002 - 18:56:02 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3561.html">Eliezer S. Yudkowsky: "Re: supergoal stability"</a>
<li><strong>Previous message:</strong> <a href="3559.html">Max Comess: "Re: Singularity Consortium Inquiry"</a>
<li><strong>In reply to:</strong> <a href="3555.html">Max Comess: "Top down vs. bottom up AI synthesis, a(n attempt at) clarification of my previous posts"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3558.html">Peter Voss: "RE: supergoal stability"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3560">[ date ]</a>
<a href="index.html#3560">[ thread ]</a>
<a href="subject.html#3560">[ subject ]</a>
<a href="author.html#3560">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Max, I think there is some truth to this approach.  But it's also true that
<br>
the requirements of, say, a standalone NLP system are very different from
<br>
the requirements for an NLP component of a general intelligence.
<br>
<p>So I don't think that the &quot;piecing together separately functional
<br>
subsystems&quot; approach to general intelligence can work.  However, I do think
<br>
that we can learn a lot from narrow AI systems that is useful in building
<br>
general intelligence systems.
<br>
<p>For instance Peter Voss's AI system is certainly inspired to some extent by
<br>
narrow-focused NN systems, among other things.  My system is inspired by a
<br>
lot of narrow AI work but incorporates none of it exactly...
<br>
<p>Ben G
<br>
&nbsp;&nbsp;-----Original Message-----
<br>
&nbsp;&nbsp;From: <a href="mailto:owner-sl4@sysopmind.com?Subject=RE:%20Top%20down%20vs.%20bottom%20up%20AI%20synthesis,%20a(n%20attempt%20at)%20clarification%20of%20my%20previous%20posts">owner-sl4@sysopmind.com</a> [mailto:<a href="mailto:owner-sl4@sysopmind.com?Subject=RE:%20Top%20down%20vs.%20bottom%20up%20AI%20synthesis,%20a(n%20attempt%20at)%20clarification%20of%20my%20previous%20posts">owner-sl4@sysopmind.com</a>]On Behalf Of
<br>
Max Comess
<br>
&nbsp;&nbsp;Sent: Friday, May 03, 2002 3:11 PM
<br>
&nbsp;&nbsp;To: <a href="mailto:sl4@sysopmind.com?Subject=RE:%20Top%20down%20vs.%20bottom%20up%20AI%20synthesis,%20a(n%20attempt%20at)%20clarification%20of%20my%20previous%20posts">sl4@sysopmind.com</a>; Kevin Bermeister; <a href="mailto:amara@kurzweilai.net?Subject=RE:%20Top%20down%20vs.%20bottom%20up%20AI%20synthesis,%20a(n%20attempt%20at)%20clarification%20of%20my%20previous%20posts">amara@kurzweilai.net</a>
<br>
&nbsp;&nbsp;Subject: Top down vs. bottom up AI synthesis, a(n attempt at)
<br>
clarification of my previous posts
<br>
<p><p>&nbsp;&nbsp;To me, it seems like the problem of mind building can be viewed from two
<br>
perspectives, top down and bottom up, just like nanotech. Top down
<br>
approaches consist of trying to form an entire mind structure; e.g. Friendly
<br>
AI, Novamente, Adaptive intelligence. Bottom up synthesis represents more
<br>
fine grained approaches working on creating a small slice of intelligence in
<br>
more limited settings; e.g. cyc, natural language, 3d vision, pattern
<br>
recognition, mind mapping, etc. Both approaches are important!
<br>
<p>&nbsp;&nbsp;Just because what we all really want is true AI doesnt mean that we should
<br>
discount the importance of dumb IA subsystems. What should happen is that
<br>
these IA subsystems should be incorporated into the development of AI. They
<br>
should be used both as development platforms, as the tools run the
<br>
computer(s) that the AI coders use. And, where possible, they should also be
<br>
used in the design of the AI itself. These IA systems are like tiny pieces
<br>
of a dynamic AI jigsaw puzzle, and as they are found and placed they can
<br>
&quot;fill in&quot; much of the gaps in our knowledge about AI, and eventually, in the
<br>
AI's knowledge about us. This saves us from having to design an entire AI
<br>
mind algorithm from scratch that can fill in all the gaps of it's knowledge
<br>
on it's own. As more &quot;pieces&quot; are created the islands of intelligence and
<br>
capability will grow larger. All this could be incorporated into the
<br>
development of any top down AI system to make development occur faster.
<br>
<p>&nbsp;&nbsp;Or, said another way, why not use general top down AI principles to sculpt
<br>
and synthesize many of these dumb IA subsystems into the real working AI
<br>
that we all want. AI will never be able to help in it's own development
<br>
until it becomes aware, but IA should allow us to help in the development of
<br>
AI in the same accelerated fasion, because it provides so many of the same
<br>
forward feedback processes. Only difference is that right now, humans have
<br>
to act as the will and the purpose for the system.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3561.html">Eliezer S. Yudkowsky: "Re: supergoal stability"</a>
<li><strong>Previous message:</strong> <a href="3559.html">Max Comess: "Re: Singularity Consortium Inquiry"</a>
<li><strong>In reply to:</strong> <a href="3555.html">Max Comess: "Top down vs. bottom up AI synthesis, a(n attempt at) clarification of my previous posts"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3558.html">Peter Voss: "RE: supergoal stability"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3560">[ date ]</a>
<a href="index.html#3560">[ thread ]</a>
<a href="subject.html#3560">[ subject ]</a>
<a href="author.html#3560">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
