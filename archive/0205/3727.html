<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: AI in &lt;what?&gt;</title>
<meta name="Author" content="Justin Corwin (thesweetestdream@hotmail.com)">
<meta name="Subject" content="AI in &lt;what?&gt;">
<meta name="Date" content="2002-05-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>AI in &lt;what?&gt;</h1>
<!-- received="Sun May 19 08:16:37 2002" -->
<!-- isoreceived="20020519141637" -->
<!-- sent="Sun, 19 May 2002 06:07:23 -0600" -->
<!-- isosent="20020519120723" -->
<!-- name="Justin Corwin" -->
<!-- email="thesweetestdream@hotmail.com" -->
<!-- subject="AI in &lt;what?&gt;" -->
<!-- id="F891nBUfjtX7bjsH4aU0001ef7e@hotmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Justin Corwin (<a href="mailto:thesweetestdream@hotmail.com?Subject=Re:%20AI%20in%20&lt;what?&gt;"><em>thesweetestdream@hotmail.com</em></a>)<br>
<strong>Date:</strong> Sun May 19 2002 - 06:07:23 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3728.html">Ben Goertzel: "RE: AI in &lt;what?&gt;"</a>
<li><strong>Previous message:</strong> <a href="3726.html">Max Comess: "Current issue of Wired"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3728.html">Ben Goertzel: "RE: AI in &lt;what?&gt;"</a>
<li><strong>Reply:</strong> <a href="3728.html">Ben Goertzel: "RE: AI in &lt;what?&gt;"</a>
<li><strong>Reply:</strong> <a href="3729.html">Michael Roy Ames: "Re: AI in &lt;what?&gt;"</a>
<li><strong>Maybe reply:</strong> <a href="3733.html">Justin Corwin: "RE: AI in &lt;what?&gt;"</a>
<li><strong>Maybe reply:</strong> <a href="3737.html">Justin Corwin: "Re: AI in &lt;what?&gt;"</a>
<li><strong>Maybe reply:</strong> <a href="3739.html">Justin Corwin: "RE: AI in &lt;what?&gt;"</a>
<li><strong>Maybe reply:</strong> <a href="3740.html">Justin Corwin: "Re: AI in &lt;what?&gt;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3727">[ date ]</a>
<a href="index.html#3727">[ thread ]</a>
<a href="subject.html#3727">[ subject ]</a>
<a href="author.html#3727">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Environment.
<br>
<p>This is the question which has been bugging me for the past few days. I've 
<br>
been focusing my middling-to-high brainpower on the writing of my response 
<br>
to several AI approaches, and one issue I've been encountering is my various 
<br>
problems with the proposed environment for the AI to live in.
<br>
<p>Is an explicit environment for a developing AImind desireable, and what kind 
<br>
of environment is best?
<br>
<p>Now, bear with me, these ideas of mine are new-formed, and thus contain a 
<br>
fair bit of anthropomorphism, simplistic modelling, and unattributed 
<br>
assumptions. I'm presenting this in an informal email, so the focus is on 
<br>
the concepts, rather than my poor formalization skills. Once the concepts 
<br>
are in a more final form, I'll worry about precise representation. If you 
<br>
have comments, please post to SL4, so a record is kept, and more comments 
<br>
can be generated.
<br>
<p>As I see it, there are four reasons an AI needs an environment:
<br>
<p>1. For training the AImind to accept input.
<br>
2. For allowing the AImind to develop mental skills in an interactive 
<br>
setting.(action/response kind of stuff)
<br>
3. Possibly for keeping the AImind close to us, in it's mental landscape. 
<br>
While it may be possible to make a mind with an entirely disembodied 
<br>
intelligence, just I/O ports and internet access, such a mind may have 
<br>
problems relating to us, as physically oriented many of our language-objects 
<br>
are.
<br>
4. To allow the AImind to more effective when it begins acting in the real 
<br>
world. If it has to extrapolate 'everything' it'll take longer and be more 
<br>
error-prone.
<br>
<p>While it's certainly not a closed book, I would like to believe that an 
<br>
environment's importance is accepted and accounted for by most parties 
<br>
reading this.
<br>
<p>There are, of course, downsides. Providing an environment for an AImind ups 
<br>
complexity. Such an AImind requires modalities for relating to the input it 
<br>
recieves, and possibly specialized mental structuring to interpret the 
<br>
significance of what it sees/feels/hears/smells. But, as we see with Homo 
<br>
Sapiens Sapiens, such modalities come in handy in surprisingly disparate 
<br>
situations.
<br>
<p>ex: Visual-Spatial orientation of memory: Memory Palaces, The Amphitheatre 
<br>
of Knowldge, Cicero's Room, etc. Such entanglement of visual processing in 
<br>
memory can lead to great gains in accessibility and reliability of memory 
<br>
data.
<br>
<p>ex: State-Associative Skills. Many humans report skills that are associated 
<br>
with kinesthetic environment, but have little to do with kinesthetics. An 
<br>
example would be many military personel's inability to think strategically 
<br>
while sitting down.(Patton, Napoleon, etc) Or a mathematicians need to use 
<br>
his hands while exploring a multidimensional problem(personal example: my 
<br>
Applied Bio-mathmatics professor at UofUtah)
<br>
<p>These examples make a case that mental organization often proceeds by 
<br>
present and dominant modalities. This implies two things: That modalities 
<br>
may improve cognition with their detail and organization, and that minds may 
<br>
be significantly different, given different modalities.
<br>
<p>This leads me to conclude that richer modalities may lead to richer mental 
<br>
organization.
<br>
<p>But do richer environments really bring a quantifiable advantage? 
<br>
Unfortunately, there is little experiential data one can use to resolve such 
<br>
a question, So I beg the user's indulgence, and apply the following thought 
<br>
experiment;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Suppose a human was born, whose eyes were twice as acute.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;He might have a problem initially, as our eyes are a result of
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;environmental balance, and would already be more acute, if this
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;presented an evolutionary advantage. However, living a life of
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a higher resolution, as it were, does seem to imply some
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;advantages that may not be obvious to an evolutionary process.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;For one, his visual cortex would be working harder all the
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;time(given twice the input), and such training may serve as a
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;faster bootstrap time, for certain processes. (Recognizing
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;objects, visual categorization, etc). Also, such increased data
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;implies that such a human may be able to apply categorization
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;of visual data that would be non-obvious to normal humans(by
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;half-shade, by smaller differences in size, shape, etc) Such
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;increased categorization in visual matter, could in theory mean
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;that increased categorization would occur in Manydifferent area.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Given that visual-like categorization in other mental area
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;have already been shown to exist.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This implies that such an improvement may lead to an
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;improvement in mental state, in both complexity and
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;precision.  This may lead to problems later (the human brain can
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;presumably only take so much complexity) but for the purposes of
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;our discussion may be taken as a proto-proof of concept.
<br>
<p>So richer environments may in fact lead to richer mental structure. However, 
<br>
this doesn't immediately answer the question, whether an explicit 
<br>
environment is desirable, and if so, what kind of environment is best?
<br>
<p>So tradeoffs must be examined.
<br>
<p>1.High mental complexity post-design is certainly desirable, so a process 
<br>
that leads to faster training is very valuable. However, such environmental 
<br>
complexity also adds to complexity of design, and may contribute to design 
<br>
failure.
<br>
<pre>
--
I believe that in this case, complexity is too important to let go, and the 
design hit should be taken. We don't want an AImind we have to relate to 
using 786432 pixel 2D metaphors. That would be annoying, and may represent a 
difficulty the AI may have trouble fixing when in the Self-Modification 
stage.
2.Design failure. It's possible that a given design for an AI may fail(whee, 
I'm a geeeeenius...) and it's important to evaluate what may cause this. A 
high complexity module relating to an environment may very well be the death 
knell for such a project, given how high the complexity is anyway. However, 
the question is, do you want your AIproject to succeed as a software 
project, or as an AI? Because insufficient mental complexity may cause your 
AI to fail not because of coding failure, but just because of nothing 
happening. Thus, environmental richness may play a crucial factor in 
allowing emergent mindstructures to emerge at all.
3. Relationship to humans. Humans have a pretty rich environment. 6 senses, 
good recall. An AI with a less rich environment may have difficulty relating 
to us. By contrast, one with a freakish 12D environment would probably find 
us funny looking. Upside, really complexish environments are probably beyond 
us anyway.
Hm. since it's late, and I don't want to muddle my thinking by touching it 
up, I'm sending this in now.
My basic conclusion is that the optimal tradeoff seems to be in a concrete 
instatiation of the AI in a virtual or sandboxed environment slightly lower 
in detail than our own. It seems to offer the best of all the options, while 
raising the complexity to a reasonable (if still ridiculous) level. I would 
like an AI that has a concrete concept of itself in space, and learns in an 
environment similar to my own. It seems that such an AI would be the most 
useful, relatable, and intelligent; given other tradeoffs.
Again, I apologise for informalism, and for the bad spelling, grammar, and 
thought.
hatemail to:
Justin Corwin
outlawpoet@****.com
&quot;the stars are: hell&quot;
_________________________________________________________________
Get your FREE download of MSN Explorer at <a href="http://explorer.msn.com/intl.asp">http://explorer.msn.com/intl.asp</a>.
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3728.html">Ben Goertzel: "RE: AI in &lt;what?&gt;"</a>
<li><strong>Previous message:</strong> <a href="3726.html">Max Comess: "Current issue of Wired"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3728.html">Ben Goertzel: "RE: AI in &lt;what?&gt;"</a>
<li><strong>Reply:</strong> <a href="3728.html">Ben Goertzel: "RE: AI in &lt;what?&gt;"</a>
<li><strong>Reply:</strong> <a href="3729.html">Michael Roy Ames: "Re: AI in &lt;what?&gt;"</a>
<li><strong>Maybe reply:</strong> <a href="3733.html">Justin Corwin: "RE: AI in &lt;what?&gt;"</a>
<li><strong>Maybe reply:</strong> <a href="3737.html">Justin Corwin: "Re: AI in &lt;what?&gt;"</a>
<li><strong>Maybe reply:</strong> <a href="3739.html">Justin Corwin: "RE: AI in &lt;what?&gt;"</a>
<li><strong>Maybe reply:</strong> <a href="3740.html">Justin Corwin: "Re: AI in &lt;what?&gt;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3727">[ date ]</a>
<a href="index.html#3727">[ thread ]</a>
<a href="subject.html#3727">[ subject ]</a>
<a href="author.html#3727">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
