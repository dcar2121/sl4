<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: singularity arrival estimate...</title>
<meta name="Author" content="ben goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: singularity arrival estimate...">
<meta name="Date" content="2002-05-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: singularity arrival estimate...</h1>
<!-- received="Fri May 17 15:26:00 2002" -->
<!-- isoreceived="20020517212600" -->
<!-- sent="Fri, 17 May 2002 13:13:50 -0600" -->
<!-- isosent="20020517191350" -->
<!-- name="ben goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: singularity arrival estimate..." -->
<!-- id="01C1FDA4.B2102170.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="singularity arrival estimate..." -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> ben goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20singularity%20arrival%20estimate..."><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Fri May 17 2002 - 13:13:50 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3713.html">James Rogers: "Complexity, universal predictors, wrong answers, and psychotic episodes"</a>
<li><strong>Previous message:</strong> <a href="3711.html">Eliezer S. Yudkowsky: "Re: singularity arrival estimate..."</a>
<li><strong>Maybe in reply to:</strong> <a href="3696.html">Ben Goertzel: "singularity arrival estimate..."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3741.html">Evan Reese: "Re: singularity arrival estimate..."</a>
<li><strong>Reply:</strong> <a href="3741.html">Evan Reese: "Re: singularity arrival estimate..."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3712">[ date ]</a>
<a href="index.html#3712">[ thread ]</a>
<a href="subject.html#3712">[ subject ]</a>
<a href="author.html#3712">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I suppose we all react differently to these various existential 
<br>
realizations
<br>
<p>For me, realizing there's a high chance we are living in a &quot;simulation&quot; was 
<br>
part of a larger process of recognizing the semi-reality of the world 
<br>
around me (&quot;semireal&quot; being a PhilDickian term) -- and not just recognizing 
<br>
it intellectually, but learning to live with it as a part of everyday, 
<br>
minute-by-minut existence.  I did not react by deciding to feel &quot;as if the 
<br>
world were probably real anyway&quot;, nor by becoming entirely nihilistic, but 
<br>
quite differently in fact.
<br>
<p>I am sure that, similarly, as the Singularity becomes more tangible to more 
<br>
people, we will see a fascinating diversity of reactions and 
<br>
interpretations -- we already have a hint of this in the diversity of views 
<br>
on this list
<br>
<p>ben g
<br>
<p>-----Original Message-----
<br>
From:	Eliezer S. Yudkowsky [SMTP:<a href="mailto:sentience@pobox.com?Subject=RE:%20singularity%20arrival%20estimate...">sentience@pobox.com</a>]
<br>
Sent:	Friday, May 17, 2002 12:34 PM
<br>
To:	<a href="mailto:sl4@sysopmind.com?Subject=RE:%20singularity%20arrival%20estimate...">sl4@sysopmind.com</a>
<br>
Subject:	Re: singularity arrival estimate...
<br>
<p>ben goertzel wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; I am befuddled by your sudden insertion of a quantitative figure, 10%, 
</em><br>
into
<br>
<em>&gt; this conversation
</em><br>
<em>&gt;
</em><br>
<em>&gt; How did you derive this?? ;)
</em><br>
<em>&gt;
</em><br>
<em>&gt; This seems like what, at Webmind Inc., we used to call an &quot;ass number&quot; 
</em><br>
...
<br>
<em>&gt; [I will omit the .gif file showing the production of an ass number
</em><br>
<em>&gt; graphically...]
</em><br>
<p>10% is my standard figure for &quot;Minimum, irreduceable chance that you don't
<br>
know what the heck you're talking about, for any given really complex
<br>
problem.&quot;  I.e., the chance that the whole &quot;simulation&quot; business is
<br>
fundamentally a case of barking up the wrong tree.  Of course this is only 
<br>
a
<br>
numerical name for a special kind of subjective probability.  My point is
<br>
that even if Nick Bostrum should come up with an argument that the chances
<br>
are billions to one against our occupying bottom-level physical reality, 
<br>
the
<br>
chance that this argument and all similar arguments are barking up the 
<br>
wrong
<br>
tree - wrongly framed against the backdrop of genuine reality - will have a
<br>
certain minimum subjective probability which, to me, feels like it should
<br>
translate into around 10%.
<br>
<p><em>&gt; Eliezer wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I challenge this.  If this world is a simulation and [insert speaker
</em><br>
<em>&gt; &gt; variable] is the main character, then at most one life is at stake and
</em><br>
<em>&gt; &gt; probably not even that.  If it's a mass communal simulation, then six
</em><br>
<em>&gt; &gt; billion lives are at stake and there is little or nothing we can do 
</em><br>
about
<br>
<em>&gt; &gt; it in any case except trying for the Singularity - which, if there's 
</em><br>
any
<br>
<em>&gt; &gt; remotely helpful exit scenario, is likely to be it.  If this world is 
</em><br>
real,
<br>
<em>&gt; &gt; then six billion lives and the entire (*)illionfold greater future of
</em><br>
<em>&gt; &gt; Earth-originating intelligent life is at stake.  So as long as there's 
</em><br>
at
<br>
<em>&gt; &gt; least a 10% chance that this world is not a computer simulation, and 
</em><br>
it's
<br>
<em>&gt; &gt; hard to see how the probability could drop below that, it makes sense 
</em><br>
for
<br>
<em>&gt; &gt; me to act as if the world I see is the real one.
</em><br>
<p>--              --              --              --              --
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3713.html">James Rogers: "Complexity, universal predictors, wrong answers, and psychotic episodes"</a>
<li><strong>Previous message:</strong> <a href="3711.html">Eliezer S. Yudkowsky: "Re: singularity arrival estimate..."</a>
<li><strong>Maybe in reply to:</strong> <a href="3696.html">Ben Goertzel: "singularity arrival estimate..."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3741.html">Evan Reese: "Re: singularity arrival estimate..."</a>
<li><strong>Reply:</strong> <a href="3741.html">Evan Reese: "Re: singularity arrival estimate..."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3712">[ date ]</a>
<a href="index.html#3712">[ thread ]</a>
<a href="subject.html#3712">[ subject ]</a>
<a href="author.html#3712">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
