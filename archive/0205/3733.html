<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: AI in &lt;what?&gt;</title>
<meta name="Author" content="Justin Corwin (thesweetestdream@hotmail.com)">
<meta name="Subject" content="RE: AI in &lt;what?&gt;">
<meta name="Date" content="2002-05-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: AI in &lt;what?&gt;</h1>
<!-- received="Sun May 19 18:27:11 2002" -->
<!-- isoreceived="20020520002711" -->
<!-- sent="Sun, 19 May 2002 16:24:02 -0600" -->
<!-- isosent="20020519222402" -->
<!-- name="Justin Corwin" -->
<!-- email="thesweetestdream@hotmail.com" -->
<!-- subject="RE: AI in &lt;what?&gt;" -->
<!-- id="F23fSDTeeY5BG8XNS8A00004283@hotmail.com" -->
<!-- inreplyto="AI in &lt;what?&gt;" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Justin Corwin (<a href="mailto:thesweetestdream@hotmail.com?Subject=RE:%20AI%20in%20&lt;what?&gt;"><em>thesweetestdream@hotmail.com</em></a>)<br>
<strong>Date:</strong> Sun May 19 2002 - 16:24:02 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3734.html">Ben Goertzel: "RE: Complexity of AGI"</a>
<li><strong>Previous message:</strong> <a href="3732.html">Mike & Donna Deering: "Re: Complexity of AGI"</a>
<li><strong>Maybe in reply to:</strong> <a href="3727.html">Justin Corwin: "AI in &lt;what?&gt;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3738.html">Ben Goertzel: "RE: AI in &lt;what?&gt;"</a>
<li><strong>Reply:</strong> <a href="3738.html">Ben Goertzel: "RE: AI in &lt;what?&gt;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3733">[ date ]</a>
<a href="index.html#3733">[ thread ]</a>
<a href="subject.html#3733">[ subject ]</a>
<a href="author.html#3733">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;From: &quot;Ben Goertzel&quot; &lt;<a href="mailto:ben@goertzel.org?Subject=RE:%20AI%20in%20&lt;what?&gt;">ben@goertzel.org</a>&gt;
</em><br>
<em>&gt;My own intuition is that
</em><br>
<em>&gt;1) Of course, a great diversity of powerful sense-inputs and actuators &gt; is 
</em><br>
<em>&gt;a good thing*
</em><br>
<p>Of course. The question I have is whether environmental richness is 
<br>
inextricably tied to internal mental complexity. Certain behaviors and 
<br>
interdepencies in human minds lead me to think that Environmental complexity 
<br>
may lead to internal organization. However this is an attempt to push this 
<br>
issue out from within the complex lump of interdepencies the brain is, and 
<br>
deal with this issue as one of Design.
<br>
<p><p><em>&gt;2) Unlike Eliezer, I think that interacting with humans and software agents
</em><br>
<em>&gt;on the Net [considered broadly, including financial datafeeds, 
</em><br>
<em>&gt;biodatabases,
</em><br>
<em>&gt;weather satellite data etc. etc., not just Web pages], will probably 
</em><br>
<em>&gt;provide
</em><br>
<em>&gt;an adequate environment for AGI, though it certainly won't lead to a
</em><br>
<em>&gt;human-like mind
</em><br>
<p>Adequate for what? Generally, environment seems to lead to mental structure. 
<br>
While the Net may have lots of data, it's a rather wonky world to live in, 
<br>
with bizarre rules. I would feel badly about an AI that reflexively tried to 
<br>
apply a directory structure to concepts, the same way humans try to organize 
<br>
visual-spatially.
<br>
<p><p><em>&gt;
</em><br>
<em>&gt;3) I think that in the early stages of an AGI project (and yes, Novamente 
</em><br>
<em>&gt;is
</em><br>
<em>&gt;*still* early-stage, because we don't have our mind-engine fully 
</em><br>
<em>&gt;implemented
</em><br>
<em>&gt;yet, not by a long shot.  Webmind AI Engine was almost out of the early
</em><br>
<em>&gt;stage of implementation &amp; software testing and into the mid-stage of basic
</em><br>
<em>&gt;testing and teaching, but I think it would not have passed thru the
</em><br>
<em>&gt;mid-stage due to various implementation and design issues), it is best NOT
</em><br>
<em>&gt;to focus on the building of elaborate perception and action systems.
</em><br>
<p>&lt;snip&gt;
<br>
<p>I think you may be right. But my question is an eventual design issue, not 
<br>
an initial one. I'm not arguing that environment needs to be included, RIGHT 
<br>
NOW. Just what level of complexity in environment is needed for AI to make 
<br>
it all the way to AGI?
<br>
<p><p><p><em>&gt;
</em><br>
<em>&gt;Partly, one's view on this issue depends on how humanlike one wants one's
</em><br>
<em>&gt;AGI to be.  I am not aiming at a humanlike AGI, just a very smart one,
</em><br>
<em>&gt;because I think that the latter is an easier problem.  Compared to more
</em><br>
<em>&gt;closely brain-inspired approaches like DGI and A2I2, my approach has less
</em><br>
<em>&gt;data to use for motivation (as the human brain is only a loose inspiration
</em><br>
<em>&gt;rather than a close guide), but has a lot fewer problems to solve in terms
</em><br>
<em>&gt;of efficient harmonization with current hardware platforms (though these
</em><br>
<em>&gt;problems are *still* very severe even for Novamente and we've put a lot of
</em><br>
<em>&gt;work in on them).
</em><br>
<p>Well, yes and no. I like the Novamente approach because it's additive. The 
<br>
supersystem you have allows for massive tweaking that may not even be 
<br>
thought of yet, because framework is flexible in mindstuff(for lack of a 
<br>
better way of explaining it. And you can always add something you missed 
<br>
later.
<br>
<p>But I have an intuition that mental organization is dependent on environment 
<br>
and what tools the AI has to interpret that. So an AI that lives on the Net 
<br>
might never work at all, because of insufficient environmental feedback.
<br>
<p>Oh, and about socialization. I agree Socialization is a huge part of 
<br>
environment. But it's not neccesarily a part of explicit environment. I can 
<br>
talk to people who aren't next to me. And there's no reason to assume that 
<br>
the AI can't use chat windows either. So I left such interaction out of my 
<br>
exploration of the subject because it can be dealt with without physical 
<br>
representation.(or whatever the AI would call something it relates to as a 
<br>
'real' object)
<br>
<p>Justin Corwin
<br>
<p>&quot;two men walking, two men walking, more different than another than they 
<br>
know....&quot;
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-Scat Singer I can't recall in a Cincinnati Night Club.
<br>
<p>_________________________________________________________________
<br>
Chat with friends online, try MSN Messenger: <a href="http://messenger.msn.com">http://messenger.msn.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3734.html">Ben Goertzel: "RE: Complexity of AGI"</a>
<li><strong>Previous message:</strong> <a href="3732.html">Mike & Donna Deering: "Re: Complexity of AGI"</a>
<li><strong>Maybe in reply to:</strong> <a href="3727.html">Justin Corwin: "AI in &lt;what?&gt;"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3738.html">Ben Goertzel: "RE: AI in &lt;what?&gt;"</a>
<li><strong>Reply:</strong> <a href="3738.html">Ben Goertzel: "RE: AI in &lt;what?&gt;"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3733">[ date ]</a>
<a href="index.html#3733">[ thread ]</a>
<a href="subject.html#3733">[ subject ]</a>
<a href="author.html#3733">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
