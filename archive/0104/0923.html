<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Deliver Us from Evil...?</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: Deliver Us from Evil...?">
<meta name="Date" content="2001-04-06">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Deliver Us from Evil...?</h1>
<!-- received="Fri Apr 06 03:44:36 2001" -->
<!-- isoreceived="20010406094436" -->
<!-- sent="Fri, 06 Apr 2001 00:40:10 -0700" -->
<!-- isosent="20010406074010" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: Deliver Us from Evil...?" -->
<!-- id="3ACD72DA.62586C52@objectent.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3ACCADBE.63AAF699@posthuman.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20Deliver%20Us%20from%20Evil...?"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Fri Apr 06 2001 - 01:40:10 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0924.html">Samantha Atkins: "Re: Deliver Us from Evil...?"</a>
<li><strong>Previous message:</strong> <a href="0922.html">Eliezer S. Yudkowsky: "Re: Deliver Us from Evil...?"</a>
<li><strong>In reply to:</strong> <a href="0908.html">Brian Atkins: "Re: Deliver Us from Evil...?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0963.html">Brian Atkins: "Re: Deliver Us from Evil...?"</a>
<li><strong>Reply:</strong> <a href="0963.html">Brian Atkins: "Re: Deliver Us from Evil...?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#923">[ date ]</a>
<a href="index.html#923">[ thread ]</a>
<a href="subject.html#923">[ subject ]</a>
<a href="author.html#923">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Brian Atkins wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Samantha Atkins wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; &quot;Eliezer S. Yudkowsky&quot; wrote:
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; I'm also more inclined to trust an AI more than a person... maybe even
</em><br>
<em>&gt; &gt; &gt; more than I'd trust myself, since I'm not designed for recursive
</em><br>
<em>&gt; &gt; &gt; self-improvement.  Actually, I should amend that:  After I've been around
</em><br>
<em>&gt; &gt; &gt; an AI and had a chance to chat with ver, then I expect to wind up
</em><br>
<em>&gt; &gt; &gt; justifiably trusting that AI's seed morality around as much as I'd trust a
</em><br>
<em>&gt; &gt; &gt; human seed morality, and I can also foresee the possibility of standing in
</em><br>
<em>&gt; &gt; &gt; the AI's presence and just being overawed by vis seed morality.  Either
</em><br>
<em>&gt; &gt; &gt; way, I also expect to wind up trusting that AI's transcendence protocol to
</em><br>
<em>&gt; &gt; &gt; preserve morality significantly more than I'd trust a human-based
</em><br>
<em>&gt; &gt; &gt; transcendence protocol to preserve morality.
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I don't see how this follows.  If you upload a human who quickly
</em><br>
<em>&gt; &gt; self-improves ver capabilities and becomes an SI and if
</em><br>
<em>&gt; &gt; super-intelligence brings with it expanded moral/ethical understanding
</em><br>
<em>&gt; &gt; then I see no reason this combination is less trustworthy than starting
</em><br>
<em>&gt; &gt; from scratch and only putting in what you believe should be there in the
</em><br>
<em>&gt; &gt; beginning.  Yes a lot of evolved complicated behavior and conditioning
</em><br>
<em>&gt; &gt; is not present in the AI.  But some of that complicated behavior and
</em><br>
<em>&gt; &gt; conditioning is also the bed of universal compassion and utter
</em><br>
<em>&gt; &gt; Friendliness.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Lot of ifs there...
</em><br>
<em>&gt; 
</em><br>
<em>&gt; What it seems to come down to is you are either relying on objective
</em><br>
<em>&gt; morality (in which an AI should do better since it has less evolved
</em><br>
<em>&gt; crap to deal with), or a natural convergence to the &quot;Friendly zone&quot;. In
</em><br>
<em>&gt; which case we also argue that a properly designed AI should easily
</em><br>
<em>&gt; outperform a human attempting to upgrade him/herself. The reason I think
</em><br>
<em>&gt; is easy to see: you can't really predict in advance which particular
</em><br>
<em>&gt; human will become utterly Friendly vs. which particular human will become
</em><br>
<em>&gt; the next Hitler when presented with the total power uploading/becoming a
</em><br>
<em>&gt; SI would give them. History has shown a tendency for power to corrupt
</em><br>
<em>&gt; humans. At least with an AI we can sharply reduce the risks by a) designing
</em><br>
<em>&gt; it right b) testing testing testing
</em><br>
<p>I think you may have accidentally palmed a card there.  If you assume
<br>
morality is objective then increasing intelligence will tend toward it
<br>
whether that intelligence is posthuman or AI.  Similarly, if the
<br>
Friendly Zone is what things naturally converge to with higher
<br>
intelligence then again I don't see that it would matter.  History is
<br>
irrelevant.  Total power for what?  By definition the posthuman is no
<br>
longer human.  Power over the relative equivalent mentally of ants?  Who
<br>
would care for that?  
<br>
<p>I don't agree the AI reduces the risk.  You have to put in selectively
<br>
much of the good that humans have as well as avoiding the ill.  
<br>
<p><p><em>&gt; 
</em><br>
<em>&gt; You want to talk about who designs the first AI? Well who decides who gets
</em><br>
<em>&gt; to be the first upload?
</em><br>
<p>Actually, no, I don't want to talk about either one.  
<br>
<p>- samantha
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0924.html">Samantha Atkins: "Re: Deliver Us from Evil...?"</a>
<li><strong>Previous message:</strong> <a href="0922.html">Eliezer S. Yudkowsky: "Re: Deliver Us from Evil...?"</a>
<li><strong>In reply to:</strong> <a href="0908.html">Brian Atkins: "Re: Deliver Us from Evil...?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0963.html">Brian Atkins: "Re: Deliver Us from Evil...?"</a>
<li><strong>Reply:</strong> <a href="0963.html">Brian Atkins: "Re: Deliver Us from Evil...?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#923">[ date ]</a>
<a href="index.html#923">[ thread ]</a>
<a href="subject.html#923">[ subject ]</a>
<a href="author.html#923">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
