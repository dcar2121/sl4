<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Open Source Friendly AI? (was Singularity and the generalpublic)</title>
<meta name="Author" content="Ben Goertzel (ben@webmind.com)">
<meta name="Subject" content="RE: Open Source Friendly AI? (was Singularity and the generalpublic)">
<meta name="Date" content="2001-04-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Open Source Friendly AI? (was Singularity and the generalpublic)</h1>
<!-- received="Fri Apr 13 12:20:29 2001" -->
<!-- isoreceived="20010413182029" -->
<!-- sent="Fri, 13 Apr 2001 09:07:02 -0400" -->
<!-- isosent="20010413130702" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@webmind.com" -->
<!-- subject="RE: Open Source Friendly AI? (was Singularity and the generalpublic)" -->
<!-- id="NDBBIBGFAPPPBODIPJMMAEMNFFAA.ben@webmind.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3AD699FB.6D1EB01A@posthuman.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@webmind.com?Subject=RE:%20Open%20Source%20Friendly%20AI?%20(was%20Singularity%20and%20the%20generalpublic)"><em>ben@webmind.com</em></a>)<br>
<strong>Date:</strong> Fri Apr 13 2001 - 07:07:02 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1080.html">Ben Goertzel: "Webmind Inc."</a>
<li><strong>Previous message:</strong> <a href="1078.html">Samantha Atkins: "Re: No Biological Singularity"</a>
<li><strong>In reply to:</strong> <a href="1077.html">Brian Atkins: "Re: Open Source Friendly AI? (was Singularity and the generalpublic)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1080.html">Ben Goertzel: "Webmind Inc."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1079">[ date ]</a>
<a href="index.html#1079">[ thread ]</a>
<a href="subject.html#1079">[ subject ]</a>
<a href="author.html#1079">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
FWIW, here's my current tentative plan for open-sourcing parts of Webmind AI
<br>
development
<br>
<p>First, open-sourcing all of the Webmind AI Engine code isn't an option for
<br>
us because of our investors.  If it were, though, I imagine the result would
<br>
be this.  A ~small~ in-group of people would become interested enough to
<br>
work on it, and this group would be the only ones who understood it.  It
<br>
seems to me that a similar effect can be achieved by inviting a small
<br>
in-group of people to join a closed-source effort.
<br>
<p>Second, having said this, we ~are~ seriously considering open-sourcing a lot
<br>
of our code.  All but the most important parts!  As it stands now, we have
<br>
some nice NL processing code, a lovely Java GP system, a distributed Java
<br>
agents system called the &quot;psycore&quot; or Mind Os (which is a couple hundred
<br>
thousand lines of Java), complete with a couple scripting languages, etc.
<br>
All these things are built to interact with each other and with the
<br>
&quot;cognitive core&quot; of the system, but they also have meaning on their own.
<br>
<p>But the crux of the Webmind brain is contained in about 2000 lines of C code
<br>
which is the &quot;cognitive core&quot;, embodying reasoning, association-finding,
<br>
associative memory, attention allocation, concept formation, and
<br>
cognitive/perceptual/active schema execution.  Frankly, getting this sort of
<br>
thing to function well is pretty intense work, and seems best done by a
<br>
small, tightly-knit group of, say, 4-7 people.
<br>
<p>Once it's achieved a high degree of functionality &amp; intelligence, could it
<br>
benefit from a larger team?  Sure.  At that point there's a serious choice
<br>
between open-sourcing it and obtaining enough money to build a huge
<br>
proprietary research team around it.
<br>
<p>About Linux, BTW, it obviously is less buggy than windows, but it's a
<br>
different kind of development than AI development.  Linux is founded on
<br>
well-understood principles; it's engineering work.  AI development requires
<br>
a very difficult and peculiar combination of conceptual, scientific and
<br>
engineering work, which is difficult to manage whether in a closed-source or
<br>
open-source situation.  My guess is that until there is a well-functioning
<br>
AI system to seed the effort, managing such an effort in an open-source
<br>
situation would be close to impossible.  The reason is that, although there
<br>
are a lot of people interested in AI, most of them have their own
<br>
ideosyncratic ideas about how to do it, and to get everyone's intuition
<br>
working in harmony in a globally distributed, everyone's-his-own-boss
<br>
setting, would require truly fantastic, perhaps superhuman visionary
<br>
leadership.
<br>
<p><p>-- Ben
<br>
<p><p><p><p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sysopmind.com?Subject=RE:%20Open%20Source%20Friendly%20AI?%20(was%20Singularity%20and%20the%20generalpublic)">owner-sl4@sysopmind.com</a> [mailto:<a href="mailto:owner-sl4@sysopmind.com?Subject=RE:%20Open%20Source%20Friendly%20AI?%20(was%20Singularity%20and%20the%20generalpublic)">owner-sl4@sysopmind.com</a>]On Behalf
</em><br>
<em>&gt; Of Brian Atkins
</em><br>
<em>&gt; Sent: Friday, April 13, 2001 2:18 AM
</em><br>
<em>&gt; To: <a href="mailto:sl4@sysopmind.com?Subject=RE:%20Open%20Source%20Friendly%20AI?%20(was%20Singularity%20and%20the%20generalpublic)">sl4@sysopmind.com</a>
</em><br>
<em>&gt; Subject: Re: Open Source Friendly AI? (was Singularity and the
</em><br>
<em>&gt; generalpublic)
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; James Higgins wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; At 11:41 PM 4/12/2001 -0400, Decan McCullagh wrote:
</em><br>
<em>&gt; &gt; &gt;On Fri, Apr 06, 2001 at 08:33:09PM -0400, Eliezer S. Yudkowsky wrote:
</em><br>
<em>&gt; &gt; &gt;Secrecy, even discussions of it, will increase their fear and
</em><br>
<em>&gt; distrust of
</em><br>
<em>&gt; &gt; &gt;you. Your only option is to play a game of chess, where the
</em><br>
<em>&gt; moves are open,
</em><br>
<em>&gt; &gt; &gt;rather then poker.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I quote the above merely because it gave me the spark to think
</em><br>
<em>&gt; about the below.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Has there been any serious discussion about making this an open source
</em><br>
<em>&gt; &gt; project?  Instead of debating how open to be, if/when to hide,
</em><br>
<em>&gt; etc. maybe
</em><br>
<em>&gt; &gt; you should consider the exact opposite.  I believe it has many
</em><br>
<em>&gt; advantages.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Yep we've thought about it
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; 1) It becomes nearly impossible (definitely impractical) to
</em><br>
<em>&gt; stop the work
</em><br>
<em>&gt; &gt; since everyone has access to it and could continue to build
</em><br>
<em>&gt; upon it if the
</em><br>
<em>&gt; &gt; original authors could not continue.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Maybe, but why bother unless you have to? Perhaps we'll set up a remote
</em><br>
<em>&gt; location with a copy of all our work to be released just in case the
</em><br>
<em>&gt; government cracks down (highly unlikely...) on us. Isn't it sad that we
</em><br>
<em>&gt; even have to worry about such stuff happening?
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; 2) It would pull in some of the rogue groups who would go it alone.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I don't see how this would help. By releasing our code and ideas
</em><br>
<em>&gt; we actually
</em><br>
<em>&gt; encourage/help along splinter groups. If we keep the code and ideas more
</em><br>
<em>&gt; private then they have to come and chat with us if they don't want to try
</em><br>
<em>&gt; to reinvent the wheel.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; 3) Open Source could massively speed up the process.  Instead
</em><br>
<em>&gt; of having a
</em><br>
<em>&gt; &gt; few coders working on it, thousands or more would be able to
</em><br>
<em>&gt; &gt; contribute.  (with very high quality control, of course)
</em><br>
<em>&gt;
</em><br>
<em>&gt; Actually open source has so far in general proven itself to be a
</em><br>
<em>&gt; much slower
</em><br>
<em>&gt; method of software development. And it gets worse on larger/more complex
</em><br>
<em>&gt; projects. How many hackers do you think will really be able to contribute
</em><br>
<em>&gt; much to an AI project? Many fewer than can contribute to something like
</em><br>
<em>&gt; Mozilla, and look how slow that thing has gone.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; 4) Probably the #1 biggest benefit is improved quality.  Open Source in
</em><br>
<em>&gt; &gt; many ways is the pinnacle of code reviews.  Having so many
</em><br>
<em>&gt; ideas study the
</em><br>
<em>&gt; &gt; source would reveal far more errors and problems than an isolated team
</em><br>
<em>&gt; &gt; could ever accomplish.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Actually I've seen that Linux has more bugs reported on Bugtraq than any
</em><br>
<em>&gt; other operating system. Is this because it is buggier, or because more
</em><br>
<em>&gt; stuff gets found? Perhaps someday Mozilla will become better than Internet
</em><br>
<em>&gt; Explorer in terms of stability, but for now the closed source approach
</em><br>
<em>&gt; using highly skilled programmers has worked better.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; 5) Providing a common, open source Friendly AI system would allow other
</em><br>
<em>&gt; &gt; groups who insist on pursuing this themselves to incorporate
</em><br>
<em>&gt; your friendly
</em><br>
<em>&gt; &gt; tech.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Or allow Saddam Hussein to get his evil AI up and running that
</em><br>
<em>&gt; much faster.
</em><br>
<em>&gt; To be realistic, real AI is an extremely powerful technology, and our view
</em><br>
<em>&gt; is to not hand it over to people we don't know and trust.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; If your ultimate goal really is to get to the singularity as soon as
</em><br>
<em>&gt; &gt; possible, before a non-friendly singularity can occur I think this is an
</em><br>
<em>&gt; &gt; ideal path to follow.
</em><br>
<em>&gt;
</em><br>
<em>&gt; We disagree, and would only pursue such a pathway as a last resort.
</em><br>
<em>&gt; --
</em><br>
<em>&gt; Brian Atkins
</em><br>
<em>&gt; Director, Singularity Institute for Artificial Intelligence
</em><br>
<em>&gt; <a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1080.html">Ben Goertzel: "Webmind Inc."</a>
<li><strong>Previous message:</strong> <a href="1078.html">Samantha Atkins: "Re: No Biological Singularity"</a>
<li><strong>In reply to:</strong> <a href="1077.html">Brian Atkins: "Re: Open Source Friendly AI? (was Singularity and the generalpublic)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1080.html">Ben Goertzel: "Webmind Inc."</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1079">[ date ]</a>
<a href="index.html#1079">[ thread ]</a>
<a href="subject.html#1079">[ subject ]</a>
<a href="author.html#1079">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
