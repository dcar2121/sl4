<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Convincing wealthy benefactors to back real AI research</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Convincing wealthy benefactors to back real AI research">
<meta name="Date" content="2001-04-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Convincing wealthy benefactors to back real AI research</h1>
<!-- received="Fri Apr 27 01:06:38 2001" -->
<!-- isoreceived="20010427070638" -->
<!-- sent="Fri, 27 Apr 2001 01:04:50 -0400" -->
<!-- isosent="20010427050450" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Convincing wealthy benefactors to back real AI research" -->
<!-- id="3AE8FDF2.5FC389C6@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="JBEPKOGDDIKKAHFPOEFIAEEECIAA.ben@webmind.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Convincing%20wealthy%20benefactors%20to%20back%20real%20AI%20research"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Thu Apr 26 2001 - 23:04:50 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1250.html">Brian Atkins: "Re: Computational reflection"</a>
<li><strong>Previous message:</strong> <a href="1248.html">Damien Broderick: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>In reply to:</strong> <a href="1242.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1262.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>Reply:</strong> <a href="1262.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1249">[ date ]</a>
<a href="index.html#1249">[ thread ]</a>
<a href="subject.html#1249">[ subject ]</a>
<a href="author.html#1249">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Goertzel wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Hi Brian,
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Your points are very well taken
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I am seriously considering raising funds for 2 separate entities
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -- a nonprofit org dedicated to creating &quot;real AI&quot; by continuing the work on
</em><br>
<em>&gt; the Webmind AI Engine
</em><br>
<p>Ben, I'd strongly advise against this.  In part, this is because of basic
<br>
disagreements we have about Webmind's architecture.  I don't think you can
<br>
create a Singularity as a nonprofit.  I do think you can make enormous
<br>
amounts of money as a for-profit.  I can see a day when &quot;Webmind&quot; means
<br>
&quot;AI&quot; the same way that Microsoft means software or GE means lightbulbs.  I
<br>
would really like to see you taking Webmind public and making a huge
<br>
amount of money, because then I can hit you up for funding for the
<br>
Singularity Institute.  But Webmind *isn't* advanced enough to build a
<br>
Transition Guide in the basement - it's just advanced enough to make a ton
<br>
of money.
<br>
<p>If you turn Webmind into a nonprofit - if you turn the Webmind AI Engine
<br>
into a nonprofit - then I don't see where the ton of money comes in.  I
<br>
realize you have unlimited faith in the ability of lawyers to diddle the
<br>
System, but you'll still be seriously limiting your total ability to
<br>
profit by giving the core IP to a nonprofit, because the system is set up
<br>
so that once the property enters the nonprofit universe, that property is
<br>
forever after used in a way consonant with the public benefit.  I can
<br>
easily see, say, Microsoft suing webmind.org for its heinous self-dealing
<br>
in licensing its software only to webmind.com.  Once the government makes
<br>
you tax-exempt for the public benefit, they have an almost unlimited right
<br>
to demand that you act for the public benefit.  Selling a product can
<br>
sometimes be a public benefit, but selling a product for whatever the
<br>
market can bear is not a public benefit.  There have already been, in
<br>
recent times, legal complaints about nonprofit corporations that are
<br>
behaving too much like real corporations.  There are features of the
<br>
System intended to prevent, for example, a corporation making all its R&amp;D
<br>
work tax-deductible while retaining sole control of it.  The IRS examiner
<br>
will *ask*.  (They asked *us*.)
<br>
<p>Now, maybe you can get away with diddling the System as long as only one
<br>
side has expensive lawyers, but I don't think you can do it if another
<br>
company, like Microsoft, opposes you with *their* own expensive lawyers. 
<br>
Or maybe I'm being naive and the whole thing is a sham intended to impress
<br>
a gullible public.  Feel free to tell me, if so.
<br>
<p>You also can't make nearly as much money taking a company public if a
<br>
nonprofit is licensing you all your IP, and you certainly can't become a
<br>
Microsoft.  The stock-market investors will notice.  Right?
<br>
<p><em>&gt; I think I can get $$ for this, in a modest amount sufficient to support,
</em><br>
<em>&gt; say, 12 guys in Brazil and 3 in the US. This should be enough to get the
</em><br>
<em>&gt; system finished within a couple years.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I note that some of the investors I think I can get, may be too mentally
</em><br>
<em>&gt; conservative to believe in the Singularity, but  may still believe that
</em><br>
<em>&gt; &quot;real AI&quot; research is a cool thing and should be funded
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -- a for-profit company focusing on the existing and proven technology
</em><br>
<em>&gt; components leveraging particular technologies from within the AI ENgine.
</em><br>
<em>&gt; This company of course will use further results as they come out of the real
</em><br>
<em>&gt; AI research group, under some appropriate legal arrangement, but won't fund
</em><br>
<em>&gt; far-reaching AI Dev in itself
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I'm suspecting that this bifurcation will make fundraising easier, as
</em><br>
<em>&gt; investors rightly like to see a tight focus in the organizations they invest
</em><br>
<em>&gt; in.
</em><br>
<p>I think bifurcating would totally blow Webmind's potential to become the
<br>
next Microsoft.  In the case of the Singularity Institute, we're a
<br>
nonprofit because we *are* in this for the Singularity.  I at first
<br>
thought of using a dual corporate structure like the one you describe, but
<br>
then, on reconsidering, decided I wasn't even sure that I wanted to
<br>
release interim versions of the AI for use in data-mining and so on.  And,
<br>
and I emphasize this, if the Singularity Institute *did* decide that some
<br>
product was beneficial to civilization and that it would be a good idea to
<br>
sell it, or fork off a for-profit to sell it, we don't *need* to become
<br>
the next Microsoft.  It's not our mission in life.  We could make a
<br>
*modest* profit, as much as we need to go on ticking, and no more.
<br>
<p>Webmind has the potential to become the next Microsoft; furthermore, in my
<br>
humble evaluation, AI Engines present no threat to civilization.  And -
<br>
unless I miss my guess - you, Ben Goertzel, want to be the next Bill
<br>
Gates.  It matters to you.  Now, I might someday make a comfortable living
<br>
as an AI programmer at SIAI, maybe even be on the Board of Directors or
<br>
consultant to some spinoff company that goes public, and make a couple mil
<br>
off my half-percent of the shares in the IPO, but anything above a few
<br>
million dollars would be totally unnecessary to reaching the Singularity. 
<br>
I decided that when I decided to go the nonprofit route, and it was an
<br>
emotional wrench.  Because previously I had, in the back of my mind,
<br>
retained some hope of being the next Bill Gates.  I had to deliberately
<br>
say, &quot;This isn't necessary to the Singularity.  This is just me wanting to
<br>
play hero.&quot;  I would now, of course, phrase it as being &quot;The human bias
<br>
towards context-insensitive personal power at the expense of
<br>
context-sensitive altruistic power.&quot;  A million dollars would be useful to
<br>
me personally, but if I have to get to the Singularity on an entirely
<br>
ordinary salary, I can do it.  And I wouldn't mind.
<br>
<p>Unless your goal system has seriously changed in the last month, my
<br>
reading on you says that you believe in a balance between personal goals
<br>
and altruistic goals, rather than trying for total altruism.  And I
<br>
respect that.  The point I'm making is that, when I personally decided to
<br>
go the nonprofit route, I noticed that the decision was strictly dependent
<br>
on a very strong skew towards altruism.  My bet is that you would tell me
<br>
that - in terms of emotional balance - I was being stupid and
<br>
ostentatiously self-sacrificing.  Well, I disagre.  But according to your
<br>
current goal system, as I understand it, it makes far more sense to take a
<br>
little extra risk to keep it a for-profit endeavor.
<br>
<p>Just shift to talking to the investors about the humanistic and scientific
<br>
tragedy of letting Webmind die, and ask for enough funding to keep the
<br>
Brazilian team together, while explaining that you don't want to shift
<br>
entirely to the nonprofit sphere because you don't want to limit the
<br>
commercial potential of the project if you do succeed.  Speaking as a
<br>
nonprofit guy who doesn't own any stock in Webmind, I think that the
<br>
benefit to humanity of Webmind lies in your becoming a megacorporation and
<br>
marketing and selling lots and lots of products, and that there wouldn't
<br>
be as much benefit to humanity if you gave your stuff away or sold it at
<br>
breakeven.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1250.html">Brian Atkins: "Re: Computational reflection"</a>
<li><strong>Previous message:</strong> <a href="1248.html">Damien Broderick: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>In reply to:</strong> <a href="1242.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1262.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>Reply:</strong> <a href="1262.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1249">[ date ]</a>
<a href="index.html#1249">[ thread ]</a>
<a href="subject.html#1249">[ subject ]</a>
<a href="author.html#1249">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
