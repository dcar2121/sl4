<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: A Sysop alternative</title>
<meta name="Author" content="James Higgins (jameshiggins@earthlink.net)">
<meta name="Subject" content="Re: A Sysop alternative">
<meta name="Date" content="2001-04-09">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: A Sysop alternative</h1>
<!-- received="Mon Apr 09 10:18:21 2001" -->
<!-- isoreceived="20010409161821" -->
<!-- sent="Mon, 09 Apr 2001 06:44:12 -0700" -->
<!-- isosent="20010409134412" -->
<!-- name="James Higgins" -->
<!-- email="jameshiggins@earthlink.net" -->
<!-- subject="Re: A Sysop alternative" -->
<!-- id="4.3.2.7.2.20010409061319.00b67f08@mail.earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="f05001904b6f7009a4ed2@[10.0.1.2]" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Higgins (<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20A%20Sysop%20alternative"><em>jameshiggins@earthlink.net</em></a>)<br>
<strong>Date:</strong> Mon Apr 09 2001 - 07:44:12 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1030.html">Gordon Worley: "Re: A Sysop alternative"</a>
<li><strong>Previous message:</strong> <a href="1028.html">gabriel C: "Re: Singularity and the general public"</a>
<li><strong>In reply to:</strong> <a href="1027.html">Gordon Worley: "A Sysop alternative"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1031.html">Gordon Worley: "Re: A Sysop alternative"</a>
<li><strong>Reply:</strong> <a href="1031.html">Gordon Worley: "Re: A Sysop alternative"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1029">[ date ]</a>
<a href="index.html#1029">[ thread ]</a>
<a href="subject.html#1029">[ subject ]</a>
<a href="author.html#1029">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
At 02:45 AM 4/9/2001 -0400, Gordon Worley wrote:
<br>
<em>&gt;Now, what I propose we do is that, rather than creating a Sysop, program 
</em><br>
<em>&gt;into the system morals as natural laws and make them be enforced.  In 
</em><br>
<em>&gt;other words, the system actively makes it not possible to act outside of 
</em><br>
<em>&gt;what is moral by the natural laws.  How will we figure those laws 
</em><br>
<em>&gt;out?  Why, we have some AIs around first that are SIs and are more or less 
</em><br>
<em>&gt;Friendly and maybe some post humans that we trust will not set up their 
</em><br>
<em>&gt;own morals or drag along their human ones, let them live in a system for a 
</em><br>
<em>&gt;while, figure out what the naturaly emergent laws are, and then impliment 
</em><br>
<em>&gt;them at the most basic levels of the system.  Then, everyone who wants to 
</em><br>
<em>&gt;use the Earth created Singulartiy technology will have to do so based on 
</em><br>
<em>&gt;what we determine to be the natural laws.  No more allowing the 
</em><br>
<em>&gt;intelligent to break their own laws, we just make it impossible.  I 
</em><br>
<em>&gt;realize already that most of the complaints about the Sysop (SIs outside 
</em><br>
<em>&gt;of ver control, bugs, et al.), but it is free from some others, like the 
</em><br>
<em>&gt;Sysop's potential to abuse power, ver limited ability to enforce morality 
</em><br>
<em>&gt;(after all, there's only so much Sysop to go around), ver need to be 
</em><br>
<em>&gt;watched to ensure that there are not bugs and the ability to decide that 
</em><br>
<em>&gt;there is a bug, etc..
</em><br>
<p>Well, I can already see the 1st objection.  Go back and look at 
<br>
Brian/Eliezer's arguments about not uploading a human first.  If you need 
<br>
to have AIs &amp; SIs to do this, how do you prevent them from just taking 
<br>
over?  I'm a little less worried about this than some on the list, but it 
<br>
is an important question.  The first AIs must have something like 
<br>
Friendliness, &quot;more or less Friendly&quot; just won't cut it.
<br>
<p>Second, I can't personally imagine an implementation to enforce morals that 
<br>
wouldn't require intelligence.  Making these decisions requires the ability 
<br>
to reason.  A good example of this is some of the latest Airbus 
<br>
planes.  They have &quot;enforced morals&quot;, as such, in that they prevent the 
<br>
pilot from taking the plane past certain angles they have preset.  Now, 
<br>
99.999% of the time that's great, but what if your about to hit a 
<br>
mountain?  I'd rather be uncomfortable for a short time and live, than be 
<br>
comfortable right up to my grave.  The plane can't reason, though, so in 
<br>
this scenario you'd be dead (there is no manual override, I understand, 
<br>
btw).  This is the kind of thinking I want to avoid.  One wrong moral, and 
<br>
it could artificially force the whole group into extinction.
<br>
<p>I would also say that Intelligence breaking the &quot;natural morals&quot; is 
<br>
probably a good thing, on the whole.  Our natural morals are such that we 
<br>
should run around kill &amp; eat animals, and screwing any female we can to 
<br>
propagate the species.  Well over 90% of the population has probably never 
<br>
killed anything larger than a mouse; Some would say this is a good 
<br>
thing.  We have also created trade, computers, video games, written 
<br>
language, etc.  These are not, strictly speaking, required by our 
<br>
morals.  Morals really represent &quot;common sense&quot; most accurately.  They are 
<br>
not, and should not be, hard and fast rules.  Rather, they are guidelines.
<br>
<p>Having a non-intelligent system that enforces morals would be terribly 
<br>
dangerous for all inside if one or more external SIs existed.  In such a 
<br>
situation the free SIs could do anything they wished to the SIs in the 
<br>
moral reality, who would be restrained in protecting themselves.  Without a 
<br>
Sysop around to help, they would be at the mercy of the external SIs.  Not 
<br>
that I personally love the Sysop scenario, but having a non-intelligent 
<br>
system is even worse.
<br>
<p>Lastly, I'd like to point out that everyone pretty much has different 
<br>
morals.  Some of these are good, some wacky and some just plain wrong (in 
<br>
my opinion).  Morals tie quite closely to beliefs, and I don't think we 
<br>
have any business going around and forcing people to have certain 
<br>
beliefs.  That said, though, there are some &quot;common&quot; root morals that 
<br>
should apply to humanity as a whole.  I guess my point here is that 
<br>
&quot;friendly&quot; is less restrictive than &quot;moral&quot;, which is probably a good 
<br>
thing.  After all, would you like to be forced to follow a moral saying 
<br>
that your not allowed to dance?  If I *have* to be forced into anything I'd 
<br>
rather be forced into friendliness.  Although I still think we need to 
<br>
consider a future where we don't need to force anyone into anything.
<br>
<p><em>&gt;Also, I've been thinking.  Back when the industrial revolution started, 
</em><br>
<em>&gt;many people looked at the new technology and wondered how the world would 
</em><br>
<em>&gt;ever work unless the state stepped in and managed things (thus the rise in 
</em><br>
<em>&gt;the popularity of socialism around these times in various 
</em><br>
<em>&gt;locations).  Today, it is easy to see how our industrial and now 
</em><br>
<em>&gt;informational society could work without state intervention, but the 
</em><br>
<em>&gt;future looks uncertain.  It seems again that the state (or our equivilant 
</em><br>
<em>&gt;of it) will have to step in and regulate to make things work out 
</em><br>
<em>&gt;alright.  Considering the past, I have to wonder if we'll see the same 
</em><br>
<em>&gt;thing again in the future or if these technologies really are going to be 
</em><br>
<em>&gt;capable of destroying everything to the extent that what bit of natural 
</em><br>
<em>&gt;laws survive on their own will not be enough to prevent the End of Everything.
</em><br>
<p>Interesting comparison.
<br>
<p>I personally think we would probably be just fine individually 
<br>
uploaded.  Well, as long as a large group of mostly reasonable people 
<br>
uploaded at the same time.  If SI has a natural attractor for friendliness, 
<br>
everything is good.  If it does not, things continue *mostly* as they are 
<br>
now.  Except that everyone is incredibly intelligent, no one is handicapped 
<br>
(unless they want to be) and everyone has incredible power over the 
<br>
physical universe.  At first this sounds scary, but most people will want 
<br>
to do the right thing.  So if 1% of the population is inherently 
<br>
unfriendly, 99% of the population would be able to gang up (as it were) and 
<br>
protect against that 1%.  Maybe putting them in a Sysop controlled virtual 
<br>
reality for eternity if they are really bad (ie: a very nice &amp; cushy 
<br>
prison, where you can do anything except affect the &quot;real&quot; world).
<br>
<p>In a short amount of time I imagine order would occur and everyone could be 
<br>
free to live their lives among peers that were reasonable.  Maybe not 
<br>
&quot;friendly&quot; all the time, but that is good (I'd go nuts if I had to live 
<br>
inside &quot;It's a small world&quot; after all).
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1030.html">Gordon Worley: "Re: A Sysop alternative"</a>
<li><strong>Previous message:</strong> <a href="1028.html">gabriel C: "Re: Singularity and the general public"</a>
<li><strong>In reply to:</strong> <a href="1027.html">Gordon Worley: "A Sysop alternative"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1031.html">Gordon Worley: "Re: A Sysop alternative"</a>
<li><strong>Reply:</strong> <a href="1031.html">Gordon Worley: "Re: A Sysop alternative"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1029">[ date ]</a>
<a href="index.html#1029">[ thread ]</a>
<a href="subject.html#1029">[ subject ]</a>
<a href="author.html#1029">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
