<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Deliver Us from Evil...?</title>
<meta name="Author" content="James Higgins (jameshiggins@earthlink.net)">
<meta name="Subject" content="Re: Deliver Us from Evil...?">
<meta name="Date" content="2001-04-04">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Deliver Us from Evil...?</h1>
<!-- received="Thu Apr 05 00:59:37 2001" -->
<!-- isoreceived="20010405065937" -->
<!-- sent="Wed, 04 Apr 2001 22:08:49 -0700" -->
<!-- isosent="20010405050849" -->
<!-- name="James Higgins" -->
<!-- email="jameshiggins@earthlink.net" -->
<!-- subject="Re: Deliver Us from Evil...?" -->
<!-- id="4.3.2.7.2.20010404215237.00b4e620@mail.earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3ACBF65E.70406290@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Higgins (<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20Deliver%20Us%20from%20Evil...?"><em>jameshiggins@earthlink.net</em></a>)<br>
<strong>Date:</strong> Wed Apr 04 2001 - 23:08:49 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0898.html">Eliezer S. Yudkowsky: "Re: Deliver Us from Evil...?"</a>
<li><strong>Previous message:</strong> <a href="0896.html">Eliezer S. Yudkowsky: "Re: Deliver Us from Evil...?"</a>
<li><strong>In reply to:</strong> <a href="0896.html">Eliezer S. Yudkowsky: "Re: Deliver Us from Evil...?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0898.html">Eliezer S. Yudkowsky: "Re: Deliver Us from Evil...?"</a>
<li><strong>Reply:</strong> <a href="0898.html">Eliezer S. Yudkowsky: "Re: Deliver Us from Evil...?"</a>
<li><strong>Reply:</strong> <a href="0900.html">Brian Atkins: "Re: Deliver Us from Evil...?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#897">[ date ]</a>
<a href="index.html#897">[ thread ]</a>
<a href="subject.html#897">[ subject ]</a>
<a href="author.html#897">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
At 12:36 AM 4/5/2001 -0400, Eliezer S. Yudkowsky wrote:
<br>
<em>&gt;Samantha Atkins wrote:
</em><br>
<em>&gt; &gt; Or we might find that the Sysop no matter how wise and benevolent and
</em><br>
<em>&gt; &gt; transparent intolerable for the types of creatures we are but be unable
</em><br>
<em>&gt; &gt; to choose differently.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Well, then, I guess the challenge lies in creating a Friendly AI that
</em><br>
<em>&gt;doesn't like intolerability.  Your statement also implicitly assumes that
</em><br>
<em>&gt;less frustration exists in a Sysop-free Universe, which doesn't
</em><br>
<em>&gt;necessarily follow; the next most probable alternative to a Sysop might be
</em><br>
<em>&gt;imprisonment within a less benevolent entity.  If a nonSysop scenario is
</em><br>
<em>&gt;both desirable and temporally stable, then it still looks to me like
</em><br>
<em>&gt;you'll need a superintelligent, Friendly, Transition Guide as a means of
</em><br>
<em>&gt;getting there without any single human upload taking over until there's a
</em><br>
<em>&gt;stable base population.  Friendly AI is still the best tactic in either
</em><br>
<em>&gt;case.
</em><br>
<p>I'm not personally convinced that uploading a human first isn't the correct 
<br>
answer.  I'm rather inclined to trust a person more than an AI to map out 
<br>
our destiny.  I think this boils down to 2 possibilities:
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) Superintelligence does not end hatred, jealousy, prejudice, 
<br>
envy, etc.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;or
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) Superintelligence provides a perspective that makes such things 
<br>
un-important
<br>
<p>If it turns out that 2 is true for any SI, then we don't need a sysop and 
<br>
it would be safe to upload (nearly) any human into being the 1st SI.
<br>
<p>If 1 is the case, I honestly think we're screwed long-term anyway.  A sysop 
<br>
environment will just breed contempt, jealously, etc in the SIs within its 
<br>
domain.  Eventually you end up with either a breakout of the sysop 
<br>
environment or a mostly unhappy population.
<br>
<p>So far I haven't read anything that convinces me that creating a Sysop is 
<br>
the correct path.
<br>
<p><em>&gt; &gt; We are spinning the barrel and pulling the trigger in a cosmic game of
</em><br>
<em>&gt; &gt; russian roulette.  The barrel holds thousands of rounds and only a few
</em><br>
<em>&gt; &gt; chambers are empty.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Where do you get *that* set of Bayesian priors from?  Not that it makes
</em><br>
<em>&gt;much of a difference, I suppose; all that counts are the proportional
</em><br>
<em>&gt;qualities of the empty chambers, not how many empty chambers there are.
</em><br>
<p>Hmm, well more like their would be 3 possibilities for any given pull.
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A) Jackpot (everyone's version of heaven wrapped into 1 neat bundle)
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;B) No (perceivable) effect
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;C) Boom (use your imagination)
<br>
<p>Now, the real question is how likely are each of those to happen.  I have a 
<br>
feeling A is on the order of 10% or less.  If we are really lucky, C is 
<br>
also 10% or less.  But I'm not feeling very lucky.
<br>
<p><em>&gt; &gt; If we &quot;win&quot; we either are set for all eternity or
</em><br>
<em>&gt; &gt; get the chance to play again some other time. Except that it is the
</em><br>
<em>&gt; &gt; entire world and all of us forever that the gun is pointing at.  To do
</em><br>
<em>&gt; &gt; that we have to be very, very damn sure that there is no other way
</em><br>
<em>&gt; &gt; and/or that this (building the SI) is the best odds we have.
</em><br>
<em>&gt;
</em><br>
<em>&gt;One, all we need is the conviction that (a) time is running out and (b)
</em><br>
<em>&gt;the conviction that building the SI is better than any other perceived
</em><br>
<em>&gt;course of action.  Certainty is a luxury if you live in a burning house.
</em><br>
<p>Time is running out for what?
<br>
<p>How can we say that building the SI is better than any other perceived 
<br>
course of action?  I can actually imagine life on the other side of 
<br>
creating an SI being rather bleak.  Imagine a reality where we know 
<br>
everything (to a reasonable approximation) and can do anything 
<br>
(ditto).  This would get boring very quickly.  Since the major driving 
<br>
force behind human nature seems to be continual learning, what do you do 
<br>
when you have learned everything?  I think this reality would be more like 
<br>
my personal hell than anything else.
<br>
<p><em>&gt;Two, I am very, very damn sure.
</em><br>
<p>Very, very damn sure of exactly what?
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0898.html">Eliezer S. Yudkowsky: "Re: Deliver Us from Evil...?"</a>
<li><strong>Previous message:</strong> <a href="0896.html">Eliezer S. Yudkowsky: "Re: Deliver Us from Evil...?"</a>
<li><strong>In reply to:</strong> <a href="0896.html">Eliezer S. Yudkowsky: "Re: Deliver Us from Evil...?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0898.html">Eliezer S. Yudkowsky: "Re: Deliver Us from Evil...?"</a>
<li><strong>Reply:</strong> <a href="0898.html">Eliezer S. Yudkowsky: "Re: Deliver Us from Evil...?"</a>
<li><strong>Reply:</strong> <a href="0900.html">Brian Atkins: "Re: Deliver Us from Evil...?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#897">[ date ]</a>
<a href="index.html#897">[ thread ]</a>
<a href="subject.html#897">[ subject ]</a>
<a href="author.html#897">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
