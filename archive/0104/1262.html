<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Convincing wealthy benefactors to back real AI research</title>
<meta name="Author" content="Ben Goertzel (ben@webmind.com)">
<meta name="Subject" content="RE: Convincing wealthy benefactors to back real AI research">
<meta name="Date" content="2001-04-27">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Convincing wealthy benefactors to back real AI research</h1>
<!-- received="Fri Apr 27 13:39:35 2001" -->
<!-- isoreceived="20010427193935" -->
<!-- sent="Fri, 27 Apr 2001 10:13:56 -0400" -->
<!-- isosent="20010427141356" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@webmind.com" -->
<!-- subject="RE: Convincing wealthy benefactors to back real AI research" -->
<!-- id="NDBBIBGFAPPPBODIPJMMMEGKFHAA.ben@webmind.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3AE8FDF2.5FC389C6@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@webmind.com?Subject=RE:%20Convincing%20wealthy%20benefactors%20to%20back%20real%20AI%20research"><em>ben@webmind.com</em></a>)<br>
<strong>Date:</strong> Fri Apr 27 2001 - 08:13:56 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1263.html">Ben Goertzel: "RE: A fairly concrete path to the Singularity"</a>
<li><strong>Previous message:</strong> <a href="1261.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>In reply to:</strong> <a href="1249.html">Eliezer S. Yudkowsky: "Re: Convincing wealthy benefactors to back real AI research"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1252.html">Eliezer S. Yudkowsky: "Re: Convincing wealthy benefactors to back real AI research"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1262">[ date ]</a>
<a href="index.html#1262">[ thread ]</a>
<a href="subject.html#1262">[ subject ]</a>
<a href="author.html#1262">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi Eliezer,
<br>
<p>Obviously, your perception of the strengths of myself and the Webmind AI
<br>
Engine, is very different from my perception of these things
<br>
<p>Firstly: I believe the Webmind AI architecture is adequate to lead to the
<br>
Singularity.  You don't.  That's fine.  For one thing, you don't understand
<br>
the AI architecture because it's never been explained to you in detail.  For
<br>
another thing, this is a topic on which differences of opinion are naturally
<br>
going to occur.
<br>
<p>Let's suppose I gave you enough info to let you study the AI Engine design
<br>
in detail -- which would take you a couple months.  After that, there would
<br>
be a couple-months period of question-answering and arguing, and ~then~,
<br>
after all that, I'd be really interested to know your evaluation of the
<br>
Singularity potential of the system.  Before that, your opinion isn't
<br>
adequately informed to be valuable to me.  I don't say this to fault you;
<br>
since you don't know how the system works, you of course are forming your
<br>
best opinion based on the information available to you.
<br>
<p>Secondly: The notion that Webmind Inc. has a good chance of becoming the
<br>
next M$ is naive.  I am not a great businessman.  I am a scientist,
<br>
philosopher and writer (and weekend musician ;).  Through 3 years in
<br>
business I have begun to understand what qualities make a great businessman.
<br>
I believe I could help build a great business team, my second time around --
<br>
by recruiting people who ~are~ great businessmen to run the business, and
<br>
restricting myself to a combination evangelist/chief-scientist role.
<br>
<p>But building a great business like M$ is ~hard~, and taking on this goal at
<br>
the same time as the goal of building real AI is perhaps foolish.  One thing
<br>
I've learned about business is that in business as in science and
<br>
engineering ~focus~ is important.  Having dual goals of building real AI and
<br>
making money in the same organization is confusing; one is trying to solve 2
<br>
hard problems at once.  At very least, I feel that, going forward, the two
<br>
goals need to be somehow separated.  There can be a business that seeks to
<br>
leverage the real AI for the purpose of making profit, but the business also
<br>
needs to be free to use less-than-real-AI technology if this seems to be the
<br>
best way to make money.
<br>
<p>This is my  motivation for thinking about there being 2 different Webmind
<br>
Inc. successors (aside from the Market Predictor hedge fund successor that's
<br>
being posited, but isn't relevant to this discussion):
<br>
<p>-- a nonprofit focused on making real AI
<br>
<p>-- a for-profit company focused on bringing AI to various niche markets,
<br>
using a combination of whatever techniques (advances or simple) seem to best
<br>
meet market needs
<br>
<p><p>In this way each organization has a clear focus.
<br>
<p>If the WM design has its shortcomings, we will discover them through ongoing
<br>
R&amp;D.  I believe the design is in the right direction and won't need a total
<br>
overhaul, but only some tweaks.  The kind of R&amp;D required to get real AI to
<br>
work is in many ways different from the kind of R&amp;D required to make the AI
<br>
Engine useful in current commercial products -- another life lesson of the
<br>
last couple years.
<br>
<p>If the AI Engine is to be a commercial project, it needs to be in a
<br>
big-company research lab setting.  But the big companies with AI research
<br>
labs appear to be too conservative at the moment to take such a project on.
<br>
In the current market, there is no WAY to raise $$ for a start-up with a
<br>
substantial &quot;pure R&amp;D&quot; function.  That I managed to create such a start-up
<br>
and maintain it for a few years was a wonderful thing, but was a consequence
<br>
of the INternet bubble which is gone.  With more business savvy and luck we
<br>
might have parlayed our lucky start into an ongoing business with enough
<br>
profitability to support an ongoing real AI R&amp;D group,  but, well, we blew
<br>
that chance and now have to move on, and craft a new future consistent with
<br>
the current market situation and our position within it.
<br>
<p><p>-- Ben
<br>
<p><p><p><p><p><p><p><p><em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-sl4@sysopmind.com?Subject=RE:%20Convincing%20wealthy%20benefactors%20to%20back%20real%20AI%20research">owner-sl4@sysopmind.com</a> [mailto:<a href="mailto:owner-sl4@sysopmind.com?Subject=RE:%20Convincing%20wealthy%20benefactors%20to%20back%20real%20AI%20research">owner-sl4@sysopmind.com</a>]On Behalf
</em><br>
<em>&gt; Of Eliezer S. Yudkowsky
</em><br>
<em>&gt; Sent: Friday, April 27, 2001 1:05 AM
</em><br>
<em>&gt; To: <a href="mailto:sl4@sysopmind.com?Subject=RE:%20Convincing%20wealthy%20benefactors%20to%20back%20real%20AI%20research">sl4@sysopmind.com</a>
</em><br>
<em>&gt; Subject: Re: Convincing wealthy benefactors to back real AI research
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; Ben Goertzel wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Hi Brian,
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Your points are very well taken
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I am seriously considering raising funds for 2 separate entities
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; -- a nonprofit org dedicated to creating &quot;real AI&quot; by
</em><br>
<em>&gt; continuing the work on
</em><br>
<em>&gt; &gt; the Webmind AI Engine
</em><br>
<em>&gt;
</em><br>
<em>&gt; Ben, I'd strongly advise against this.  In part, this is because of basic
</em><br>
<em>&gt; disagreements we have about Webmind's architecture.  I don't think you can
</em><br>
<em>&gt; create a Singularity as a nonprofit.  I do think you can make enormous
</em><br>
<em>&gt; amounts of money as a for-profit.  I can see a day when &quot;Webmind&quot; means
</em><br>
<em>&gt; &quot;AI&quot; the same way that Microsoft means software or GE means lightbulbs.  I
</em><br>
<em>&gt; would really like to see you taking Webmind public and making a huge
</em><br>
<em>&gt; amount of money, because then I can hit you up for funding for the
</em><br>
<em>&gt; Singularity Institute.  But Webmind *isn't* advanced enough to build a
</em><br>
<em>&gt; Transition Guide in the basement - it's just advanced enough to make a ton
</em><br>
<em>&gt; of money.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If you turn Webmind into a nonprofit - if you turn the Webmind AI Engine
</em><br>
<em>&gt; into a nonprofit - then I don't see where the ton of money comes in.  I
</em><br>
<em>&gt; realize you have unlimited faith in the ability of lawyers to diddle the
</em><br>
<em>&gt; System, but you'll still be seriously limiting your total ability to
</em><br>
<em>&gt; profit by giving the core IP to a nonprofit, because the system is set up
</em><br>
<em>&gt; so that once the property enters the nonprofit universe, that property is
</em><br>
<em>&gt; forever after used in a way consonant with the public benefit.  I can
</em><br>
<em>&gt; easily see, say, Microsoft suing webmind.org for its heinous self-dealing
</em><br>
<em>&gt; in licensing its software only to webmind.com.  Once the government makes
</em><br>
<em>&gt; you tax-exempt for the public benefit, they have an almost unlimited right
</em><br>
<em>&gt; to demand that you act for the public benefit.  Selling a product can
</em><br>
<em>&gt; sometimes be a public benefit, but selling a product for whatever the
</em><br>
<em>&gt; market can bear is not a public benefit.  There have already been, in
</em><br>
<em>&gt; recent times, legal complaints about nonprofit corporations that are
</em><br>
<em>&gt; behaving too much like real corporations.  There are features of the
</em><br>
<em>&gt; System intended to prevent, for example, a corporation making all its R&amp;D
</em><br>
<em>&gt; work tax-deductible while retaining sole control of it.  The IRS examiner
</em><br>
<em>&gt; will *ask*.  (They asked *us*.)
</em><br>
<em>&gt;
</em><br>
<em>&gt; Now, maybe you can get away with diddling the System as long as only one
</em><br>
<em>&gt; side has expensive lawyers, but I don't think you can do it if another
</em><br>
<em>&gt; company, like Microsoft, opposes you with *their* own expensive lawyers.
</em><br>
<em>&gt; Or maybe I'm being naive and the whole thing is a sham intended to impress
</em><br>
<em>&gt; a gullible public.  Feel free to tell me, if so.
</em><br>
<em>&gt;
</em><br>
<em>&gt; You also can't make nearly as much money taking a company public if a
</em><br>
<em>&gt; nonprofit is licensing you all your IP, and you certainly can't become a
</em><br>
<em>&gt; Microsoft.  The stock-market investors will notice.  Right?
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; I think I can get $$ for this, in a modest amount sufficient to support,
</em><br>
<em>&gt; &gt; say, 12 guys in Brazil and 3 in the US. This should be enough to get the
</em><br>
<em>&gt; &gt; system finished within a couple years.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I note that some of the investors I think I can get, may be too mentally
</em><br>
<em>&gt; &gt; conservative to believe in the Singularity, but  may still believe that
</em><br>
<em>&gt; &gt; &quot;real AI&quot; research is a cool thing and should be funded
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; -- a for-profit company focusing on the existing and proven technology
</em><br>
<em>&gt; &gt; components leveraging particular technologies from within the AI ENgine.
</em><br>
<em>&gt; &gt; This company of course will use further results as they come
</em><br>
<em>&gt; out of the real
</em><br>
<em>&gt; &gt; AI research group, under some appropriate legal arrangement,
</em><br>
<em>&gt; but won't fund
</em><br>
<em>&gt; &gt; far-reaching AI Dev in itself
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I'm suspecting that this bifurcation will make fundraising easier, as
</em><br>
<em>&gt; &gt; investors rightly like to see a tight focus in the
</em><br>
<em>&gt; organizations they invest
</em><br>
<em>&gt; &gt; in.
</em><br>
<em>&gt;
</em><br>
<em>&gt; I think bifurcating would totally blow Webmind's potential to become the
</em><br>
<em>&gt; next Microsoft.  In the case of the Singularity Institute, we're a
</em><br>
<em>&gt; nonprofit because we *are* in this for the Singularity.  I at first
</em><br>
<em>&gt; thought of using a dual corporate structure like the one you describe, but
</em><br>
<em>&gt; then, on reconsidering, decided I wasn't even sure that I wanted to
</em><br>
<em>&gt; release interim versions of the AI for use in data-mining and so on.  And,
</em><br>
<em>&gt; and I emphasize this, if the Singularity Institute *did* decide that some
</em><br>
<em>&gt; product was beneficial to civilization and that it would be a good idea to
</em><br>
<em>&gt; sell it, or fork off a for-profit to sell it, we don't *need* to become
</em><br>
<em>&gt; the next Microsoft.  It's not our mission in life.  We could make a
</em><br>
<em>&gt; *modest* profit, as much as we need to go on ticking, and no more.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Webmind has the potential to become the next Microsoft; furthermore, in my
</em><br>
<em>&gt; humble evaluation, AI Engines present no threat to civilization.  And -
</em><br>
<em>&gt; unless I miss my guess - you, Ben Goertzel, want to be the next Bill
</em><br>
<em>&gt; Gates.  It matters to you.  Now, I might someday make a comfortable living
</em><br>
<em>&gt; as an AI programmer at SIAI, maybe even be on the Board of Directors or
</em><br>
<em>&gt; consultant to some spinoff company that goes public, and make a couple mil
</em><br>
<em>&gt; off my half-percent of the shares in the IPO, but anything above a few
</em><br>
<em>&gt; million dollars would be totally unnecessary to reaching the Singularity.
</em><br>
<em>&gt; I decided that when I decided to go the nonprofit route, and it was an
</em><br>
<em>&gt; emotional wrench.  Because previously I had, in the back of my mind,
</em><br>
<em>&gt; retained some hope of being the next Bill Gates.  I had to deliberately
</em><br>
<em>&gt; say, &quot;This isn't necessary to the Singularity.  This is just me wanting to
</em><br>
<em>&gt; play hero.&quot;  I would now, of course, phrase it as being &quot;The human bias
</em><br>
<em>&gt; towards context-insensitive personal power at the expense of
</em><br>
<em>&gt; context-sensitive altruistic power.&quot;  A million dollars would be useful to
</em><br>
<em>&gt; me personally, but if I have to get to the Singularity on an entirely
</em><br>
<em>&gt; ordinary salary, I can do it.  And I wouldn't mind.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Unless your goal system has seriously changed in the last month, my
</em><br>
<em>&gt; reading on you says that you believe in a balance between personal goals
</em><br>
<em>&gt; and altruistic goals, rather than trying for total altruism.  And I
</em><br>
<em>&gt; respect that.  The point I'm making is that, when I personally decided to
</em><br>
<em>&gt; go the nonprofit route, I noticed that the decision was strictly dependent
</em><br>
<em>&gt; on a very strong skew towards altruism.  My bet is that you would tell me
</em><br>
<em>&gt; that - in terms of emotional balance - I was being stupid and
</em><br>
<em>&gt; ostentatiously self-sacrificing.  Well, I disagre.  But according to your
</em><br>
<em>&gt; current goal system, as I understand it, it makes far more sense to take a
</em><br>
<em>&gt; little extra risk to keep it a for-profit endeavor.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Just shift to talking to the investors about the humanistic and scientific
</em><br>
<em>&gt; tragedy of letting Webmind die, and ask for enough funding to keep the
</em><br>
<em>&gt; Brazilian team together, while explaining that you don't want to shift
</em><br>
<em>&gt; entirely to the nonprofit sphere because you don't want to limit the
</em><br>
<em>&gt; commercial potential of the project if you do succeed.  Speaking as a
</em><br>
<em>&gt; nonprofit guy who doesn't own any stock in Webmind, I think that the
</em><br>
<em>&gt; benefit to humanity of Webmind lies in your becoming a megacorporation and
</em><br>
<em>&gt; marketing and selling lots and lots of products, and that there wouldn't
</em><br>
<em>&gt; be as much benefit to humanity if you gave your stuff away or sold it at
</em><br>
<em>&gt; breakeven.
</em><br>
<em>&gt;
</em><br>
<em>&gt; --              --              --              --              --
</em><br>
<em>&gt; Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
</em><br>
<em>&gt; Research Fellow, Singularity Institute for Artificial Intelligence
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1263.html">Ben Goertzel: "RE: A fairly concrete path to the Singularity"</a>
<li><strong>Previous message:</strong> <a href="1261.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>In reply to:</strong> <a href="1249.html">Eliezer S. Yudkowsky: "Re: Convincing wealthy benefactors to back real AI research"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1252.html">Eliezer S. Yudkowsky: "Re: Convincing wealthy benefactors to back real AI research"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1262">[ date ]</a>
<a href="index.html#1262">[ thread ]</a>
<a href="subject.html#1262">[ subject ]</a>
<a href="author.html#1262">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
