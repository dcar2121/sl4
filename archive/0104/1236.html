<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Convincing wealthy benefactors to back real AI research</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Convincing wealthy benefactors to back real AI research">
<meta name="Date" content="2001-04-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Convincing wealthy benefactors to back real AI research</h1>
<!-- received="Thu Apr 26 20:37:08 2001" -->
<!-- isoreceived="20010427023708" -->
<!-- sent="Thu, 26 Apr 2001 19:19:47 -0400" -->
<!-- isosent="20010426231947" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Convincing wealthy benefactors to back real AI research" -->
<!-- id="3AE8AD13.44163EF7@posthuman.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="NDBBIBGFAPPPBODIPJMMCEEOFHAA.ben@webmind.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Convincing%20wealthy%20benefactors%20to%20back%20real%20AI%20research"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Thu Apr 26 2001 - 17:19:47 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1237.html">Brian Atkins: "Re: intentional programming progress"</a>
<li><strong>Previous message:</strong> <a href="1235.html">Peter Voss: "RE: intentional programming progress"</a>
<li><strong>In reply to:</strong> <a href="1233.html">Ben Goertzel: "RE: A fairly concrete path to the Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1242.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>Reply:</strong> <a href="1242.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>Reply:</strong> <a href="1243.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>Maybe reply:</strong> <a href="1264.html">doug.bailey@ey.com: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>Maybe reply:</strong> <a href="1270.html">doug.bailey@ey.com: "RE: Convincing wealthy benefactors to back real AI research"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1236">[ date ]</a>
<a href="index.html#1236">[ thread ]</a>
<a href="subject.html#1236">[ subject ]</a>
<a href="author.html#1236">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Goertzel wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; &gt; O.k., but I'm not &quot;a skeptic&quot;.  I could be convinced by
</em><br>
<em>&gt; &gt; considerably less than
</em><br>
<em>&gt; &gt; a complete working system -- but also by significantly more than
</em><br>
<em>&gt; &gt; you've said.
</em><br>
<em>&gt; &gt; (That's not a criticism.)
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Understood.  There's a 370-page book that describes how our system works,
</em><br>
<em>&gt; and it's currently available only to people who need to see it, and under
</em><br>
<em>&gt; NDA....
</em><br>
<em>&gt; 
</em><br>
<p>Obviously this is a critical issue for both SIAI and Webmind. Personally
<br>
I was convinced through a combination of three things:
<br>
<p>1. Humanity seems to be in an unstable state now, and will eventually attract
<br>
to either: a) killing itself off, b) achieving some sort of technology-
<br>
stable-state post-Singularity. If you accept this, then obviously speeding up
<br>
B is better than waiting around for A to possibly occur.
<br>
<p>2. Becoming convinced that either the Singularity is going to automatically
<br>
be a good thing for humanity, OR if it could go either way that whoever gets
<br>
there first will determine which way it goes. Sitting by and watching it
<br>
happen (ESPECIALLY if you have spare cash that you could use to influence
<br>
it) is not a rational position if you believe there are risks involved in
<br>
how the Singularity turns out.
<br>
<p>3. There is a concrete path to influencing the Singularity: fund an org that
<br>
creates a real AI. In fact, one of the nice (or really bad, depending on your
<br>
viewpoint) things about the Singularity is that as we get closer to it, it
<br>
takes less and less funds to be able to have a super-large impact. Never
<br>
before in history has there been an opportunity for such a huge return on
<br>
investment :-)
<br>
<p>I don't see how anyone that fully internalizes those three items can come
<br>
to any other conclusions regarding the use of any totally unused funds they
<br>
may have sitting around. The hard part is getting potential funders to fully
<br>
internalize/accept these things... some people don't believe a Singularity
<br>
can occur, others think it will be bad, and others think that AI is too hard.
<br>
It certainly requires some optimism... SIAI at least is doing its best to
<br>
attack #2 with our Friendly AI document.
<br>
<p>As for Webmind you are in a different zone- you are trying to get investors
<br>
to fund it based on giving them an economic return later on. That approach
<br>
might actually be harder, except for the fact that you guys already  have
<br>
some good demo applications, working code, and even some revenue-generating
<br>
clients. I'm surprised no one so far has been willing to revive it! 
<br>
<pre>
-- 
Brian Atkins
Director, Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1237.html">Brian Atkins: "Re: intentional programming progress"</a>
<li><strong>Previous message:</strong> <a href="1235.html">Peter Voss: "RE: intentional programming progress"</a>
<li><strong>In reply to:</strong> <a href="1233.html">Ben Goertzel: "RE: A fairly concrete path to the Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1242.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>Reply:</strong> <a href="1242.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>Reply:</strong> <a href="1243.html">Ben Goertzel: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>Maybe reply:</strong> <a href="1264.html">doug.bailey@ey.com: "RE: Convincing wealthy benefactors to back real AI research"</a>
<li><strong>Maybe reply:</strong> <a href="1270.html">doug.bailey@ey.com: "RE: Convincing wealthy benefactors to back real AI research"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1236">[ date ]</a>
<a href="index.html#1236">[ thread ]</a>
<a href="subject.html#1236">[ subject ]</a>
<a href="author.html#1236">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
