<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt</title>
<meta name="Author" content="Declan McCullagh (declan@well.com)">
<meta name="Subject" content="Re: FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt">
<meta name="Date" content="2001-04-19">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt</h1>
<!-- received="Thu Apr 19 12:29:36 2001" -->
<!-- isoreceived="20010419182936" -->
<!-- sent="Thu, 19 Apr 2001 12:26:49 -0400" -->
<!-- isosent="20010419162649" -->
<!-- name="Declan McCullagh" -->
<!-- email="declan@well.com" -->
<!-- subject="Re: FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt" -->
<!-- id="20010419122649.A15652@cluebot.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="LOBBLDGHBFLPJDFBIPFEAEOFGKAA.patrick@kia.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Declan McCullagh (<a href="mailto:declan@well.com?Subject=Re:%20FW:%20Group%20releases%20&quot;Friendly%20AI%20guidelines,&quot;%20Webmind%20goes%20bankrupt"><em>declan@well.com</em></a>)<br>
<strong>Date:</strong> Thu Apr 19 2001 - 10:26:49 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1161.html">Ben Goertzel: "RE: FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt"</a>
<li><strong>Previous message:</strong> <a href="1159.html">Patrick McCuller: "FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt"</a>
<li><strong>In reply to:</strong> <a href="1159.html">Patrick McCuller: "FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1161.html">Ben Goertzel: "RE: FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt"</a>
<li><strong>Reply:</strong> <a href="1161.html">Ben Goertzel: "RE: FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1160">[ date ]</a>
<a href="index.html#1160">[ thread ]</a>
<a href="subject.html#1160">[ subject ]</a>
<a href="author.html#1160">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Patrick,
<br>
Thanks for forwarding. If I may quibble with your quibble,
<br>
my Subject: line did not say &quot;Friendly AI released&quot; but
<br>
&quot;Friendly AI guidelines released.&quot;
<br>
<p>There's a big difference, as I'm sure you can appreciate. :)
<br>
<p>-Declan
<br>
<p><p>On Thu, Apr 19, 2001 at 12:18:03PM -0400, Patrick McCuller wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; 	The only problem I have with the story is that Friendly AI isn't exactly
</em><br>
<em>&gt; 'released'. But it is an entertaining read.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 	(Forwarding allowed by restricted license; see below.)
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Patrick McCuller
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: <a href="mailto:owner-politech@politechbot.com?Subject=Re:%20FW:%20Group%20releases%20&quot;Friendly%20AI%20guidelines,&quot;%20Webmind%20goes%20bankrupt">owner-politech@politechbot.com</a>
</em><br>
<em>&gt; [mailto:<a href="mailto:owner-politech@politechbot.com?Subject=Re:%20FW:%20Group%20releases%20&quot;Friendly%20AI%20guidelines,&quot;%20Webmind%20goes%20bankrupt">owner-politech@politechbot.com</a>]On Behalf Of Declan McCullagh
</em><br>
<em>&gt; Sent: Thursday, April 19, 2001 11:29 AM
</em><br>
<em>&gt; To: <a href="mailto:politech@politechbot.com?Subject=Re:%20FW:%20Group%20releases%20&quot;Friendly%20AI%20guidelines,&quot;%20Webmind%20goes%20bankrupt">politech@politechbot.com</a>
</em><br>
<em>&gt; Subject: FC: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes
</em><br>
<em>&gt; bankrupt
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; <a href="http://www.wired.com/news/business/0,1367,43158,00.html">http://www.wired.com/news/business/0,1367,43158,00.html</a>
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    Intelligenesis Faces Dim Future
</em><br>
<em>&gt;    By Declan McCullagh (<a href="mailto:declan@wired.com?Subject=Re:%20FW:%20Group%20releases%20&quot;Friendly%20AI%20guidelines,&quot;%20Webmind%20goes%20bankrupt">declan@wired.com</a>)
</em><br>
<em>&gt;    2:00 a.m. Apr. 19, 2001 PDT
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    A pioneering New York company that once hoped to develop the first
</em><br>
<em>&gt;    artificial intelligence is preparing to declare bankruptcy.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    Intelligenesis Corp., which was creating the Webmind software, has
</em><br>
<em>&gt;    been evicted from its Broadway office suite and plans to file for
</em><br>
<em>&gt;    Chapter 7 bankruptcy next week.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    [...]
</em><br>
<em>&gt; 
</em><br>
<em>&gt; **********
</em><br>
<em>&gt; 
</em><br>
<em>&gt; <a href="http://www.wired.com/news/technology/1,1282,43080,00.html">http://www.wired.com/news/technology/1,1282,43080,00.html</a>
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    Making HAL Your Pal
</em><br>
<em>&gt;    by Declan McCullagh (<a href="mailto:declan@wired.com?Subject=Re:%20FW:%20Group%20releases%20&quot;Friendly%20AI%20guidelines,&quot;%20Webmind%20goes%20bankrupt">declan@wired.com</a>)
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    2:00 a.m. Apr. 19, 2001 PDT
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    Eliezer Yudkowsky has devoted his young life to an undeniably unusual
</em><br>
<em>&gt;    pursuit: planning for what happens when computers become far smarter
</em><br>
<em>&gt;    than us.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    Yudkowsky, a 21-year-old researcher at the Singularity Institute, has
</em><br>
<em>&gt;    spent the last eight months writing an essay that's half precaution,
</em><br>
<em>&gt;    half thought exercise, and entirely in earnest.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    This 750 KB treatise, released Wednesday, is not as much speculative
</em><br>
<em>&gt;    as predictive. If a computer becomes sufficiently smart, the argument
</em><br>
<em>&gt;    goes, and if it gains the ability to harm humans through
</em><br>
<em>&gt;    nanotechnology or some means we don't expect, it may decide it doesn't
</em><br>
<em>&gt;    need us or want us around.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    One solution: Unconditional &quot;friendliness,&quot; built into the AI as
</em><br>
<em>&gt;    surely as our genes are coded into us.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    &quot;I've devoted my life to this,&quot; says Yudkowsky, a self-proclaimed
</em><br>
<em>&gt;    &quot;genius&quot; who lives in Atlanta and opted out of attending high school
</em><br>
<em>&gt;    and college.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    It's not for lack of smarts. He's a skilled, if verbose, writer and an
</em><br>
<em>&gt;    avid science-fiction reader who reports he scored 1410 on his SATs,
</em><br>
<em>&gt;    not far below the average score for Stanford or MIT students.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    Yudkowsky's reason for shunning formal education is that he believes
</em><br>
<em>&gt;    the danger of unfriendly AI to be so near -- as early as tomorrow --
</em><br>
<em>&gt;    that there was no time for a traditional adolescence. &quot;If you take the
</em><br>
<em>&gt;    Singularity seriously, you tend to live out your life on a shorter
</em><br>
<em>&gt;    time scale,&quot; he said.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    Mind you, that's &quot;Singularity&quot; in capital letters. Even so-called
</em><br>
<em>&gt;    Singularitians like Yudkowsky admit that the term has no precise
</em><br>
<em>&gt;    meaning, but a commonly accepted definition is a point when human
</em><br>
<em>&gt;    progress, particularly technological progress, accelerates so
</em><br>
<em>&gt;    dramatically that predicting what will happen next is futile.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    The term appears to have been coined by John von Neumann, the great
</em><br>
<em>&gt;    mathematician and computer scientist who used it not to refer to
</em><br>
<em>&gt;    superhuman intelligence, but to the everyday pace of science and
</em><br>
<em>&gt;    technology.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    Science-fiction author Vernor Vinge popularized the concept in the
</em><br>
<em>&gt;    1980s, capitalizing the word and writing about whether mankind would
</em><br>
<em>&gt;    approach Singularity by way of machine intelligence alone or through
</em><br>
<em>&gt;    augmented mental processes. Predictions vary wildly about what happens
</em><br>
<em>&gt;    at the Singularity, but the consensus seems to be that life as
</em><br>
<em>&gt;    humanity currently knows it will come to a sudden end.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    Vinge is the closest thing Singularitians have to a thought leader,
</em><br>
<em>&gt;    spokesman and hero. He offers predictions based on measures of
</em><br>
<em>&gt;    technological progress such as Moore's Law, and sees the Singularity
</em><br>
<em>&gt;    as arriving between 2005 and 2030 -- though some Vinge aficionados
</em><br>
<em>&gt;    hope the possibility of uploading their brains into an immortal
</em><br>
<em>&gt;    computer is just around the corner.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    One of them is Yudkowsky, who credits Vinge for turning him onto the
</em><br>
<em>&gt;    Singularity at age 11. &quot;I read True Names,&quot; he said, referring to a
</em><br>
<em>&gt;    Vinge novel. &quot;I got to page 47 and found out what I was going to be
</em><br>
<em>&gt;    doing for the rest of my life.&quot;
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    Since then, Yudkowsky has become not just someone who predicts the
</em><br>
<em>&gt;    Singularity, but a committed activist trying to speed its arrival. &quot;My
</em><br>
<em>&gt;    first allegiance is to the Singularity, not humanity,&quot; he writes in
</em><br>
<em>&gt;    one essay. &quot;I don't know what the Singularity will do with us. I don't
</em><br>
<em>&gt;    know whether Singularities upgrade mortal races, or disassemble us for
</em><br>
<em>&gt;    spare atoms.... If it comes down to Us or Them, I'm with Them.&quot;
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    [...]
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    Like a character from science fiction, Yudkowsky sees his efforts as
</em><br>
<em>&gt;    humanity's only hope.
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    In an autobiographical essay, he writes: &quot;I think my efforts could
</em><br>
<em>&gt;    spell the difference between life and death for most of humanity, or
</em><br>
<em>&gt;    even the difference between a Singularity and a lifeless, sterilized
</em><br>
<em>&gt;    planet... I think that I can save the world, not just because I'm the
</em><br>
<em>&gt;    one who happens to be making the effort, but because I'm the only one
</em><br>
<em>&gt;    who can make the effort.&quot;
</em><br>
<em>&gt; 
</em><br>
<em>&gt;    ###
</em><br>
<em>&gt; 
</em><br>
<em>&gt; [Clarification: Yudkowsky just emailed me to say he received a 1600 on his
</em><br>
<em>&gt; SATs when he took them again. --Declan]
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -------------------------------------------------------------------------
</em><br>
<em>&gt; POLITECH -- Declan McCullagh's politics and technology mailing list
</em><br>
<em>&gt; You may redistribute this message freely if it remains intact.
</em><br>
<em>&gt; To subscribe, visit <a href="http://www.politechbot.com/info/subscribe.html">http://www.politechbot.com/info/subscribe.html</a>
</em><br>
<em>&gt; This message is archived at <a href="http://www.politechbot.com/">http://www.politechbot.com/</a>
</em><br>
<em>&gt; -------------------------------------------------------------------------
</em><br>
<em>&gt; 
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1161.html">Ben Goertzel: "RE: FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt"</a>
<li><strong>Previous message:</strong> <a href="1159.html">Patrick McCuller: "FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt"</a>
<li><strong>In reply to:</strong> <a href="1159.html">Patrick McCuller: "FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1161.html">Ben Goertzel: "RE: FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt"</a>
<li><strong>Reply:</strong> <a href="1161.html">Ben Goertzel: "RE: FW: Group releases &quot;Friendly AI guidelines,&quot; Webmind goes bankrupt"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1160">[ date ]</a>
<a href="index.html#1160">[ thread ]</a>
<a href="subject.html#1160">[ subject ]</a>
<a href="author.html#1160">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
