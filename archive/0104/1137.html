<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: PAPER: Theory of Universal AI based on Algorithmic Complexity</title>
<meta name="Author" content="Ben Goertzel (ben@webmind.com)">
<meta name="Subject" content="RE: PAPER: Theory of Universal AI based on Algorithmic Complexity">
<meta name="Date" content="2001-04-16">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: PAPER: Theory of Universal AI based on Algorithmic Complexity</h1>
<!-- received="Mon Apr 16 09:28:28 2001" -->
<!-- isoreceived="20010416152828" -->
<!-- sent="Mon, 16 Apr 2001 07:24:29 -0400" -->
<!-- isosent="20010416112429" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@webmind.com" -->
<!-- subject="RE: PAPER: Theory of Universal AI based on Algorithmic Complexity" -->
<!-- id="NDBBIBGFAPPPBODIPJMMCEBCFGAA.ben@webmind.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="20010416043037.4508.qmail@web1205.mail.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@webmind.com?Subject=RE:%20PAPER:%20Theory%20of%20Universal%20AI%20based%20on%20Algorithmic%20Complexity"><em>ben@webmind.com</em></a>)<br>
<strong>Date:</strong> Mon Apr 16 2001 - 05:24:29 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1138.html">Ben Goertzel: "RE: ARTICLE: Memory bandwidth"</a>
<li><strong>Previous message:</strong> <a href="1136.html">Barbara Lamar: "RE: HYPE: &quot;Russians create 'artificial human brain'&quot;"</a>
<li><strong>In reply to:</strong> <a href="1135.html">Mitchell Porter: "Re: PAPER: Theory of Universal AI based on Algorithmic Complexity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1153.html">James Rogers: "Detailed Explanation re: PAPER: Theory of Universal AI based on Algorithmic Complexity"</a>
<li><strong>Reply:</strong> <a href="1153.html">James Rogers: "Detailed Explanation re: PAPER: Theory of Universal AI based on Algorithmic Complexity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1137">[ date ]</a>
<a href="index.html#1137">[ thread ]</a>
<a href="subject.html#1137">[ subject ]</a>
<a href="author.html#1137">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; &gt; The theory of Universal Intelligence isn't so
</em><br>
<em>&gt; &gt; valuable because it is a
</em><br>
<em>&gt; &gt; solution to the problem of AI (although it does give
</em><br>
<em>&gt; &gt; it an excellent
</em><br>
<em>&gt; &gt; mathematical basis), rather it is valuable because
</em><br>
<em>&gt; &gt; it gives us specific
</em><br>
<em>&gt; &gt; implementation problems to solve, that when solved,
</em><br>
<em>&gt; &gt; should theoretically
</em><br>
<em>&gt; &gt; result in a functional AI.  Being able to know what
</em><br>
<em>&gt; &gt; needs to be done is a
</em><br>
<em>&gt; &gt; big step in the right direction.
</em><br>
<em>&gt;
</em><br>
<em>&gt; This, I don't understand. What are the implementation
</em><br>
<em>&gt; problems it gives us to solve?
</em><br>
<p>I echo Mitch's skepticism.
<br>
<p>At the end of the paper, after lots of nice math, the author suggests that
<br>
in order to get a realistic AI to work, one will have to introduce lots of
<br>
specialized algorithms to deal with different particular types of learning
<br>
confronted by the mind.  But he doesn't go into details.
<br>
<p>With this small comment at the end, he's ~starting~ -- just barely -- to
<br>
veer toward the really interesting part of AI.  The next step to observe is
<br>
that you need a bunch of specialized methods, all able to learn from each
<br>
other rather than working against each other.  This is what I've called
<br>
&quot;emergent intelligence.&quot;
<br>
<p>As for the mind having a Universal Intelligence core, I believe that it
<br>
really works like this.  Among the many specialized modules in the mind,
<br>
there are some (more than one) with universal intelligence ability, as well
<br>
as some without it.  Since universal intelligence is only definable up to an
<br>
arbitrary constant, it's of at best ~heuristic~ value  in thinking about the
<br>
constructure of real AI systems.  In reality, different universally
<br>
intelligent modules may be practically applicable to different types of
<br>
problems.
<br>
<p>Examples of universally intelligent modules in Webmind are: the evolution
<br>
module (implementing a type of genetic programming) and the reason module
<br>
(implementing a kind of first-order &amp; higher-order term logic).  [There are
<br>
only two examples, there's at least one more.]  Both of these modules, like
<br>
the others with more limited scope (natural language, data processing,
<br>
association-finding, etc.), act on the same data structure (something called
<br>
a Relationship, of which semantic nodes and links are special cases).
<br>
<p><em>&gt; Now it looks as if the UI-core architecture
</em><br>
<em>&gt; is just too slow to plausibly be an SI architecture.
</em><br>
<em>&gt;
</em><br>
<p>I think that the space of UI algorithms is pretty large.
<br>
<p>For instance, of course UI algorithms based on exhaustively or randomly
<br>
searching a space of all programs carrying out some criterion, are too slow
<br>
to be usable.
<br>
<p>But, on the other hand, using GP to search a space of programs, while in the
<br>
worst case no better than exhaustive search of program space, in practice is
<br>
generally much better.  (For some types of problems, it's a good approach,
<br>
for others not, but I doubt there are any realistic problems where it's
<br>
worse than exhaustive or Monte Carlo search).
<br>
<p>As for GP, a similar thing can be said about higher-order inference using
<br>
uncertain term logic, which can be used to leverage past knowledge to help
<br>
create programs solving future problems in a way that is highly efficient in
<br>
certain domains.
<br>
<p><p>One might say that the UI concept is valuable in a theoretical sense: It
<br>
helps us clarify the nature of the problem of intelligence.  One the other
<br>
hand, I have found that what it mostly does is to make explicit what those
<br>
of us with a strong AI  predisposition already feel.  In many discussions
<br>
with AI skeptics, I have not found the UI arguments to help me to convince
<br>
them that AI is possible.  They'll reject the  mathematical definition of
<br>
intelligence underlying the UI approach, just as surely as they'll reject
<br>
the statement &quot;AI is possible.&quot;
<br>
<p>ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1138.html">Ben Goertzel: "RE: ARTICLE: Memory bandwidth"</a>
<li><strong>Previous message:</strong> <a href="1136.html">Barbara Lamar: "RE: HYPE: &quot;Russians create 'artificial human brain'&quot;"</a>
<li><strong>In reply to:</strong> <a href="1135.html">Mitchell Porter: "Re: PAPER: Theory of Universal AI based on Algorithmic Complexity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1153.html">James Rogers: "Detailed Explanation re: PAPER: Theory of Universal AI based on Algorithmic Complexity"</a>
<li><strong>Reply:</strong> <a href="1153.html">James Rogers: "Detailed Explanation re: PAPER: Theory of Universal AI based on Algorithmic Complexity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1137">[ date ]</a>
<a href="index.html#1137">[ thread ]</a>
<a href="subject.html#1137">[ subject ]</a>
<a href="author.html#1137">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
