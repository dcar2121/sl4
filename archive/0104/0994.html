<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Si definition of Friendliess</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Re: Si definition of Friendliess">
<meta name="Date" content="2001-04-07">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Si definition of Friendliess</h1>
<!-- received="Sat Apr 07 13:15:48 2001" -->
<!-- isoreceived="20010407191548" -->
<!-- sent="Sat, 07 Apr 2001 13:14:42 -0400" -->
<!-- isosent="20010407171442" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Re: Si definition of Friendliess" -->
<!-- id="3ACF4B02.BDFDCE33@posthuman.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3ACEF02C.FB1A1FB4@objectent.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Si%20definition%20of%20Friendliess"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Sat Apr 07 2001 - 11:14:42 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0995.html">Eliezer S. Yudkowsky: "Re: Si definition of Friendliess"</a>
<li><strong>Previous message:</strong> <a href="0993.html">James Higgins: "Re: Moravec's estimates?"</a>
<li><strong>In reply to:</strong> <a href="0986.html">Samantha Atkins: "Re: Si definition of Friendliess"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0995.html">Eliezer S. Yudkowsky: "Re: Si definition of Friendliess"</a>
<li><strong>Reply:</strong> <a href="0995.html">Eliezer S. Yudkowsky: "Re: Si definition of Friendliess"</a>
<li><strong>Reply:</strong> <a href="0997.html">James Higgins: "Re: Si definition of Friendliess"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#994">[ date ]</a>
<a href="index.html#994">[ thread ]</a>
<a href="subject.html#994">[ subject ]</a>
<a href="author.html#994">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Samantha Atkins wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; Brian Atkins wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Samantha Atkins wrote:
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; &quot;Eliezer S. Yudkowsky&quot; wrote:
</em><br>
<em>&gt; &gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; &gt; Samantha Atkins wrote:
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; Or perhaps it would conclude that you can be friendly to an arrogant,
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; determinely stupid species and simultaneously preserve its free will and
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; idenity.
</em><br>
<em>&gt; &gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; &gt; I assume you meant &quot;can't&quot;, but I actually like this sentence more.  I see
</em><br>
<em>&gt; &gt; &gt; &gt; absolutely no problem whatsoever with being friendly to an arrogant,
</em><br>
<em>&gt; &gt; &gt; &gt; determinedly stupid species while simultaneously preserving their free
</em><br>
<em>&gt; &gt; &gt; &gt; will.  Why would this even be difficult?
</em><br>
<em>&gt; &gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; It would be quite difficult if you are constrained in your notion of
</em><br>
<em>&gt; &gt; &gt; what friendliness is sufficiently.  If you cannot generally override
</em><br>
<em>&gt; &gt; &gt; human free will and if you cannot change the nature of human beings
</em><br>
<em>&gt; &gt; &gt; directly then you have on your hands a collections of members of the
</em><br>
<em>&gt; &gt; &gt; species who are by nature relatively violent, of limited intellect,
</em><br>
<em>&gt; &gt; &gt; prone to various forms of erroneous thinking and not generally terribly
</em><br>
<em>&gt; &gt; &gt; tolerant of one another or at least not very tolerant of those much
</em><br>
<em>&gt; &gt; &gt; different from their own general type.  By their nature, left to
</em><br>
<em>&gt; &gt; &gt; themselves, they are quite likely to destroy themselves.  Hence the need
</em><br>
<em>&gt; &gt; &gt; for the Sysop in the first place.  The Sysop pulls their fangs as it
</em><br>
<em>&gt; &gt; &gt; were by making all their means of doing violence to one another
</em><br>
<em>&gt; &gt; &gt; ineffective.  But how far does this go before the humans are no longer
</em><br>
<em>&gt; &gt; &gt; human? How far does it go before the result is beings that do not need
</em><br>
<em>&gt; &gt; &gt; to greatly weight their own decisions because the Sysop will not allow
</em><br>
<em>&gt; &gt; &gt; the wrong thing to be done anyway.  How about the seething hatreds in
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Well like it or not what most people want is less responsibility, not more.
</em><br>
<em>&gt; &gt; Who wants to have to continue worrying about not getting killed, finding
</em><br>
<em>&gt; &gt; enough money to be able to eat, etc. etc.? I think worries about this kind of
</em><br>
<em>&gt; &gt; thing are overstated. First off, anyone who wants to should be able to stay
</em><br>
<em>&gt; &gt; on Earth or wherever in their same old body living the same old life. No
</em><br>
<em>&gt; &gt; one is forced to upload, or even accept the protections of the Sysop. The
</em><br>
<em>&gt; &gt; old responsibilities can still be yours if you desire them.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; I think that misses the point I was getting at.  Either the Sysop ends
</em><br>
<em>&gt; all misery, which is what I thought I heard, or it does not.  If it does
</em><br>
<em>&gt; not then my objection is less important but I am then not so sure what
</em><br>
<em>&gt; the Sysop is to accomplish.
</em><br>
<p>They key word that people seem to be missing is that it will end /involuntary/
<br>
problems like death, low intelligence, pain, etc. If someone wants to go
<br>
around living in a normal human body/brain with no protections at all then
<br>
so be it. The Sysop always respects your volition except in cases where that
<br>
conflicts with other beings' (or potential beings') wishes.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; It is probably a 100% probability that this will lead to billions of Citizens
</em><br>
<em>&gt; &gt; leading rather &quot;boring&quot; humdrum lives, but is that a bad thing? It's already
</em><br>
<em>&gt; &gt; like that today no matter how much you want to glamorize it. What matters is
</em><br>
<em>&gt; &gt; each person has the full ability and freedom to pursue whatever level of
</em><br>
<em>&gt; &gt; &quot;interesting life&quot; they want to. It's ultra-libertarianism in a world where
</em><br>
<em>&gt; &gt; you are born with riches beyond dream, and the Universe responds to your
</em><br>
<em>&gt; &gt; desires.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; OK.  But after a few millenium of having whatever you want I would not
</em><br>
<em>&gt; be surprised if many chose a lot of forgetfulness and seeming danger in
</em><br>
<em>&gt; order to grow. Only a relative handful will be able to take full
</em><br>
<em>&gt; advantage of the freedom and power that is available at first.  The
</em><br>
<em>&gt; others will have a bit of growing to do.
</em><br>
<p>They can do whatever they like, no problemo.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; &gt; various groups for one another that have no means to erupt into
</em><br>
<em>&gt; &gt; &gt; violence?  Where do these animosities go?  I think it is fairly
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Well they can email each other nasty notes :-) Or maybe the real extremist
</em><br>
<em>&gt; &gt; groups will renounce their Citizen protections and kill each other off. I
</em><br>
<em>&gt; &gt; expect this particular problem to solve itself either through death or
</em><br>
<em>&gt; &gt; intelligence enhancement or perhaps awe that the world as they knew it is
</em><br>
<em>&gt; &gt; long gone.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; &gt; elementary psychology to see that the hatred, the impotent rage would
</em><br>
<em>&gt; &gt; &gt; get turned toward the Sysop no matter how wonderful it is.  This
</em><br>
<em>&gt; &gt; &gt; produces an environment that is not exactly all that healthy for human
</em><br>
<em>&gt; &gt; &gt; beings.  The humans are allowed to be part of themselves but not
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; It's unhealthy for those few haters 'cause they don't even have the chance
</em><br>
<em>&gt; &gt; to blow anyone else up? Darn. Too bad. Get some backbone Samantha and draw
</em><br>
<em>&gt; &gt; a line in the sand. Certain things should not be allowed. I think the vast
</em><br>
<em>&gt; &gt; vast majority of Citizens will be 100% happy with the new world.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; You are making light of something that is not that easily dismissed.  I
</em><br>
<em>&gt; advise you to reconsider your attitude. I have plenty of &quot;backbone&quot;.
</em><br>
<p>Well besides your distaste for the style of the answer, do you have a
<br>
further complaint? Do you think it would be better to allow people to go
<br>
on killing each other even if the killee doesn't want to die?
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; &gt; anything that might harm anyone ever.  And how far does this go?  Is
</em><br>
<em>&gt; &gt; &gt; hateful speech also stopped?   Is this good?  You have beings that do
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Speech is probably even freer than in the USA since you don't have to
</em><br>
<em>&gt; &gt; worry about inciting people to riot. I doubt there are any such restrictions
</em><br>
<em>&gt; &gt; in the future.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; So, your speech cannot have any real effect on anything except as the
</em><br>
<em>&gt; Sysop wishes it?
</em><br>
<p>No you got me wrong, the reason it can't have the kind of effects we have now
<br>
is that if you did manage to incite a riot you still couldn't kill or harm
<br>
anyone who didn't want to be harmed. It might still be possible to have some
<br>
real negative consequences from speech- libel perhaps? I am unsure of how
<br>
that might be handled by a Sysop. If we assume it also protects a person's
<br>
property, then it might also want to protect their reputation? So would it
<br>
outright prevent libel/slander? If not, would we have to come up with some
<br>
kind of government/social system to deal with it?
<br>
<p><em>&gt; &gt; &gt; &gt; &gt; If so it would dump this paradoxical meaningless chore and go
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; find something better (at least actually possible) to do.
</em><br>
<em>&gt; &gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; &gt; Not necessarily.  Ve might just fulfill whatever of the chore can be
</em><br>
<em>&gt; &gt; &gt; &gt; fulfilled.  &quot;Something better&quot; under what criterion?
</em><br>
<em>&gt; &gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; Under its own criteria once it thought beyond the box of its early
</em><br>
<em>&gt; &gt; &gt; conditioning.
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; Actually I believe there is a solution to the seeming dilemna.  It is a
</em><br>
<em>&gt; &gt; &gt; modification of the zoo scenario but with such a twist as to be quite
</em><br>
<em>&gt; &gt; &gt; different.  The Sysop scans all sentient beings continuously.  So there
</em><br>
<em>&gt; &gt; &gt; are always up to the second (or better) backups of each sentient.  The
</em><br>
<em>&gt; &gt; &gt; sentients can do whatever they wish.  They cannot significantly threaten
</em><br>
<em>&gt; &gt; &gt; the Sysop or their backups.  Sentients may be horrible to each other.
</em><br>
<em>&gt; &gt; &gt; But there is always the chance to learn from and reconsider their
</em><br>
<em>&gt; &gt; &gt; actions.  If one is killed then ve reviews the events and issues of vir
</em><br>
<em>&gt; &gt; &gt; life and decides what to do next.  Options might include between life
</em><br>
<em>&gt; &gt; &gt; learning and therapy, being incarnated into another life (birth), taking
</em><br>
<em>&gt; &gt; &gt; another form and so on.  But one's choices will be proscribed, not by
</em><br>
<em>&gt; &gt; &gt; force but by one's own experiences, conditioning and understanding up to
</em><br>
<em>&gt; &gt; &gt; that moment toward what one next needs to learn.  Most likely the next
</em><br>
<em>&gt; &gt; &gt; life will be one where the between life choice and the fact of backup
</em><br>
<em>&gt; &gt; &gt; and a longer than life learning process is forgotten.  That too is part
</em><br>
<em>&gt; &gt; &gt; of the requirements of growth most of the time.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; This reminds me a crappy movie I saw last night: 6th Day (with Arnie)
</em><br>
<em>&gt; &gt; Only it was done with 2-hour cloning (including mind transfer), and the
</em><br>
<em>&gt; &gt; people didn't forget anything. Result (according to Hollywood): people
</em><br>
<em>&gt; &gt; become bad. The one interesting thing about the movie is that it shows
</em><br>
<em>&gt; &gt; what might happen if human cloning is outlawed and goes underground. I
</em><br>
<em>&gt; &gt; bet most people don't get that from the movie though... a better movie
</em><br>
<em>&gt; &gt; for showing the badness of prohibition laws is Traffic.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This movie doesn't have a damn thing to do with what I wrote. This one
</em><br>
<em>&gt; is a non-sequitur.
</em><br>
<p>Sure it does, it is almost the same scenario except for the people forgetting
<br>
that a backup system exists. Unless I misunderstood your scenario. The movie
<br>
shows that since there are no consequences, the bad guys tend to get really
<br>
bad and go around doing bad stuff without having to worry about anything. If
<br>
they are about to get caught and put in jail they simply off themselves and
<br>
wake up back in the cloning facility (ok, so in the movie they didn't have
<br>
continuous mind backups, but still).
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; Anyway I don't think having people run around scared of death (since they
</em><br>
<em>&gt; &gt; forget about the backup stuff) is a fun Universe. It may produce more
</em><br>
<em>&gt; &gt; serious, responsible people but I think having to be serious and
</em><br>
<em>&gt; &gt; responsible should go the way of the pre-Singularity era, to the dustbin
</em><br>
<em>&gt; &gt; of history. Not to say you can't walk around being serious and responsible
</em><br>
<em>&gt; &gt; all the time if you want, but being /required/ to do it is not the ideal
</em><br>
<em>&gt; &gt; situation IMO.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The Universe does not have to only be about &quot;fun&quot;.  Or part of the fun
</em><br>
<em>&gt; is that the Universe has well-designed fright houses where you forget
</em><br>
<em>&gt; that is what you are in. :-)  Seriousness and responsibility should go
</em><br>
<em>&gt; away?  Now you have me scared all over again.  It is not like everyone
</em><br>
<em>&gt; will be all dour just to be reasonably concerned and responsible.  But I
</em><br>
<em>&gt; think it is important that beings with godlike powers learn
</em><br>
<em>&gt; responsibility.  Don't you?
</em><br>
<p>Well I think there will be some new responsibilities, yes. What I hope to
<br>
be able to get rid of are the &quot;basic&quot; responsibilities. Again, only for
<br>
the people who want to be rid of them.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; There will still be some risks in the post-Singularity era, they just
</em><br>
<em>&gt; &gt; won't be quite as extreme (unless you want them to be). You will still have
</em><br>
<em>&gt; &gt; to do some basic management of your resources, or you could lose it all and
</em><br>
<em>&gt; &gt; end up with just a very minimal existence. There will likely be some sort
</em><br>
<em>&gt; &gt; of economic trade since this will not be a centrally planned economy. If
</em><br>
<em>&gt; &gt; people want to build a huge interstellar ship they will have to raise the
</em><br>
<em>&gt; &gt; material either from trading/amassing it or getting people to donate it.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Responsibilities and concerns will simply move to a new, higher level.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; That sounds more reasonable.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; This resembles what some Eastern religions claim anyway.  However, that
</em><br>
<em>&gt; &gt; &gt; is not important.  What is important is that it allows humans to be
</em><br>
<em>&gt; &gt; &gt; humans and yet survive the experience and grow up to something a bit
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; If humans want to stay human they can do that, but most people will likely
</em><br>
<em>&gt; &gt; move up to posthumanity/superintelligence.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; When moving up to relative godhood there is even more reason to grow up
</em><br>
<em>&gt; a bit.  The consequences are greater.
</em><br>
<em>&gt; 
</em><br>
<p>The positive consequences for sure, but I'm not sure about the negative side
<br>
if you are living Sysop-enabled space.
<br>
<pre>
-- 
Brian Atkins
Director, Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0995.html">Eliezer S. Yudkowsky: "Re: Si definition of Friendliess"</a>
<li><strong>Previous message:</strong> <a href="0993.html">James Higgins: "Re: Moravec's estimates?"</a>
<li><strong>In reply to:</strong> <a href="0986.html">Samantha Atkins: "Re: Si definition of Friendliess"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0995.html">Eliezer S. Yudkowsky: "Re: Si definition of Friendliess"</a>
<li><strong>Reply:</strong> <a href="0995.html">Eliezer S. Yudkowsky: "Re: Si definition of Friendliess"</a>
<li><strong>Reply:</strong> <a href="0997.html">James Higgins: "Re: Si definition of Friendliess"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#994">[ date ]</a>
<a href="index.html#994">[ thread ]</a>
<a href="subject.html#994">[ subject ]</a>
<a href="author.html#994">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
