<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Si definition of Friendliess</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Re: Si definition of Friendliess">
<meta name="Date" content="2001-04-05">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Si definition of Friendliess</h1>
<!-- received="Thu Apr 05 15:48:13 2001" -->
<!-- isoreceived="20010405214813" -->
<!-- sent="Thu, 05 Apr 2001 14:46:55 -0400" -->
<!-- isosent="20010405184655" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Re: Si definition of Friendliess" -->
<!-- id="3ACCBD9F.9A632F72@posthuman.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3ACC370A.451A608F@objectent.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Si%20definition%20of%20Friendliess"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Thu Apr 05 2001 - 12:46:55 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="0913.html">James Higgins: "Re: Deliver Us from Evil...?"</a>
<li><strong>Previous message:</strong> <a href="0911.html">Chris Cooper: "Re: Deliver Us from Evil...?"</a>
<li><strong>In reply to:</strong> <a href="0903.html">Samantha Atkins: "Re: Si definition of Friendliess"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0915.html">James Higgins: "Re: Si definition of Friendliess"</a>
<li><strong>Reply:</strong> <a href="0915.html">James Higgins: "Re: Si definition of Friendliess"</a>
<li><strong>Reply:</strong> <a href="0986.html">Samantha Atkins: "Re: Si definition of Friendliess"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#912">[ date ]</a>
<a href="index.html#912">[ thread ]</a>
<a href="subject.html#912">[ subject ]</a>
<a href="author.html#912">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Samantha Atkins wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; &quot;Eliezer S. Yudkowsky&quot; wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Samantha Atkins wrote:
</em><br>
<em>&gt; &gt; &gt; Or perhaps it would conclude that you can be friendly to an arrogant,
</em><br>
<em>&gt; &gt; &gt; determinely stupid species and simultaneously preserve its free will and
</em><br>
<em>&gt; &gt; &gt; idenity.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I assume you meant &quot;can't&quot;, but I actually like this sentence more.  I see
</em><br>
<em>&gt; &gt; absolutely no problem whatsoever with being friendly to an arrogant,
</em><br>
<em>&gt; &gt; determinedly stupid species while simultaneously preserving their free
</em><br>
<em>&gt; &gt; will.  Why would this even be difficult?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It would be quite difficult if you are constrained in your notion of
</em><br>
<em>&gt; what friendliness is sufficiently.  If you cannot generally override
</em><br>
<em>&gt; human free will and if you cannot change the nature of human beings
</em><br>
<em>&gt; directly then you have on your hands a collections of members of the
</em><br>
<em>&gt; species who are by nature relatively violent, of limited intellect,
</em><br>
<em>&gt; prone to various forms of erroneous thinking and not generally terribly
</em><br>
<em>&gt; tolerant of one another or at least not very tolerant of those much
</em><br>
<em>&gt; different from their own general type.  By their nature, left to
</em><br>
<em>&gt; themselves, they are quite likely to destroy themselves.  Hence the need
</em><br>
<em>&gt; for the Sysop in the first place.  The Sysop pulls their fangs as it
</em><br>
<em>&gt; were by making all their means of doing violence to one another
</em><br>
<em>&gt; ineffective.  But how far does this go before the humans are no longer
</em><br>
<em>&gt; human? How far does it go before the result is beings that do not need
</em><br>
<em>&gt; to greatly weight their own decisions because the Sysop will not allow
</em><br>
<em>&gt; the wrong thing to be done anyway.  How about the seething hatreds in
</em><br>
<p>Well like it or not what most people want is less responsibility, not more.
<br>
Who wants to have to continue worrying about not getting killed, finding
<br>
enough money to be able to eat, etc. etc.? I think worries about this kind of
<br>
thing are overstated. First off, anyone who wants to should be able to stay
<br>
on Earth or wherever in their same old body living the same old life. No
<br>
one is forced to upload, or even accept the protections of the Sysop. The
<br>
old responsibilities can still be yours if you desire them.
<br>
<p>It is probably a 100% probability that this will lead to billions of Citizens
<br>
leading rather &quot;boring&quot; humdrum lives, but is that a bad thing? It's already
<br>
like that today no matter how much you want to glamorize it. What matters is
<br>
each person has the full ability and freedom to pursue whatever level of
<br>
&quot;interesting life&quot; they want to. It's ultra-libertarianism in a world where
<br>
you are born with riches beyond dream, and the Universe responds to your
<br>
desires.
<br>
<p><em>&gt; various groups for one another that have no means to erupt into
</em><br>
<em>&gt; violence?  Where do these animosities go?  I think it is fairly
</em><br>
<p>Well they can email each other nasty notes :-) Or maybe the real extremist
<br>
groups will renounce their Citizen protections and kill each other off. I
<br>
expect this particular problem to solve itself either through death or
<br>
intelligence enhancement or perhaps awe that the world as they knew it is
<br>
long gone.
<br>
<p><em>&gt; elementary psychology to see that the hatred, the impotent rage would
</em><br>
<em>&gt; get turned toward the Sysop no matter how wonderful it is.  This
</em><br>
<em>&gt; produces an environment that is not exactly all that healthy for human
</em><br>
<em>&gt; beings.  The humans are allowed to be part of themselves but not
</em><br>
<p>It's unhealthy for those few haters 'cause they don't even have the chance
<br>
to blow anyone else up? Darn. Too bad. Get some backbone Samantha and draw
<br>
a line in the sand. Certain things should not be allowed. I think the vast
<br>
vast majority of Citizens will be 100% happy with the new world.
<br>
<p><em>&gt; anything that might harm anyone ever.  And how far does this go?  Is
</em><br>
<em>&gt; hateful speech also stopped?   Is this good?  You have beings that do
</em><br>
<p>Speech is probably even freer than in the USA since you don't have to
<br>
worry about inciting people to riot. I doubt there are any such restrictions
<br>
in the future.
<br>
<p><em>&gt; not do any harm to one another but not because they have grown beyond
</em><br>
<em>&gt; the desire and need to do so but because they have been rendered
</em><br>
<em>&gt; incapable of it by the Sysop.
</em><br>
<p>Well I'm sure they can still go blow up birds and deer if they want.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &gt; &gt; If so it would dump this paradoxical meaningless chore and go
</em><br>
<em>&gt; &gt; &gt; find something better (at least actually possible) to do.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Not necessarily.  Ve might just fulfill whatever of the chore can be
</em><br>
<em>&gt; &gt; fulfilled.  &quot;Something better&quot; under what criterion?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Under its own criteria once it thought beyond the box of its early
</em><br>
<em>&gt; conditioning.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Actually I believe there is a solution to the seeming dilemna.  It is a
</em><br>
<em>&gt; modification of the zoo scenario but with such a twist as to be quite
</em><br>
<em>&gt; different.  The Sysop scans all sentient beings continuously.  So there
</em><br>
<em>&gt; are always up to the second (or better) backups of each sentient.  The
</em><br>
<em>&gt; sentients can do whatever they wish.  They cannot significantly threaten
</em><br>
<em>&gt; the Sysop or their backups.  Sentients may be horrible to each other.
</em><br>
<em>&gt; But there is always the chance to learn from and reconsider their
</em><br>
<em>&gt; actions.  If one is killed then ve reviews the events and issues of vir
</em><br>
<em>&gt; life and decides what to do next.  Options might include between life
</em><br>
<em>&gt; learning and therapy, being incarnated into another life (birth), taking
</em><br>
<em>&gt; another form and so on.  But one's choices will be proscribed, not by
</em><br>
<em>&gt; force but by one's own experiences, conditioning and understanding up to
</em><br>
<em>&gt; that moment toward what one next needs to learn.  Most likely the next
</em><br>
<em>&gt; life will be one where the between life choice and the fact of backup
</em><br>
<em>&gt; and a longer than life learning process is forgotten.  That too is part
</em><br>
<em>&gt; of the requirements of growth most of the time.
</em><br>
<p>This reminds me a crappy movie I saw last night: 6th Day (with Arnie)
<br>
Only it was done with 2-hour cloning (including mind transfer), and the
<br>
people didn't forget anything. Result (according to Hollywood): people
<br>
become bad. The one interesting thing about the movie is that it shows
<br>
what might happen if human cloning is outlawed and goes underground. I
<br>
bet most people don't get that from the movie though... a better movie
<br>
for showing the badness of prohibition laws is Traffic.
<br>
<p>Anyway I don't think having people run around scared of death (since they
<br>
forget about the backup stuff) is a fun Universe. It may produce more
<br>
serious, responsible people but I think having to be serious and
<br>
responsible should go the way of the pre-Singularity era, to the dustbin
<br>
of history. Not to say you can't walk around being serious and responsible
<br>
all the time if you want, but being /required/ to do it is not the ideal
<br>
situation IMO.
<br>
<p>There will still be some risks in the post-Singularity era, they just
<br>
won't be quite as extreme (unless you want them to be). You will still have
<br>
to do some basic management of your resources, or you could lose it all and
<br>
end up with just a very minimal existence. There will likely be some sort
<br>
of economic trade since this will not be a centrally planned economy. If
<br>
people want to build a huge interstellar ship they will have to raise the
<br>
material either from trading/amassing it or getting people to donate it.
<br>
<p>Responsibilities and concerns will simply move to a new, higher level.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; This resembles what some Eastern religions claim anyway.  However, that
</em><br>
<em>&gt; is not important.  What is important is that it allows humans to be
</em><br>
<em>&gt; humans and yet survive the experience and grow up to something a bit
</em><br>
<p>If humans want to stay human they can do that, but most people will likely
<br>
move up to posthumanity/superintelligence.
<br>
<p><em>&gt; better over time and it is something that is quite doable by a Sysop.
</em><br>
<em>&gt; This type of process could possibly be automated and the Sysop could
</em><br>
<em>&gt; branch out in whole or in part to other activities.
</em><br>
<em>&gt; 
</em><br>
<p>If some people wanted to live that way I'm sure the Sysop will oblige.
<br>
<pre>
-- 
Brian Atkins
Director, Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="0913.html">James Higgins: "Re: Deliver Us from Evil...?"</a>
<li><strong>Previous message:</strong> <a href="0911.html">Chris Cooper: "Re: Deliver Us from Evil...?"</a>
<li><strong>In reply to:</strong> <a href="0903.html">Samantha Atkins: "Re: Si definition of Friendliess"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0915.html">James Higgins: "Re: Si definition of Friendliess"</a>
<li><strong>Reply:</strong> <a href="0915.html">James Higgins: "Re: Si definition of Friendliess"</a>
<li><strong>Reply:</strong> <a href="0986.html">Samantha Atkins: "Re: Si definition of Friendliess"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#912">[ date ]</a>
<a href="index.html#912">[ thread ]</a>
<a href="subject.html#912">[ subject ]</a>
<a href="author.html#912">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
