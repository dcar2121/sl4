<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: SIAI's flawed friendliness analysis</title>
<meta name="Author" content="Barkley Vowk (bvowk@math.ualberta.ca)">
<meta name="Subject" content="Re: SIAI's flawed friendliness analysis">
<meta name="Date" content="2003-05-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: SIAI's flawed friendliness analysis</h1>
<!-- received="Thu May 29 15:56:53 2003" -->
<!-- isoreceived="20030529215653" -->
<!-- sent="Thu, 29 May 2003 15:54:12 -0600 (MDT)" -->
<!-- isosent="20030529215412" -->
<!-- name="Barkley Vowk" -->
<!-- email="bvowk@math.ualberta.ca" -->
<!-- subject="Re: SIAI's flawed friendliness analysis" -->
<!-- id="20030529155224.I63512@3jane.math.ualberta.ca" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="3ED67845.8060905@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Barkley Vowk (<a href="mailto:bvowk@math.ualberta.ca?Subject=Re:%20SIAI's%20flawed%20friendliness%20analysis"><em>bvowk@math.ualberta.ca</em></a>)<br>
<strong>Date:</strong> Thu May 29 2003 - 15:54:12 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="6849.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>Previous message:</strong> <a href="6847.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>In reply to:</strong> <a href="6846.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6849.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>Reply:</strong> <a href="6849.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>Reply:</strong> <a href="6892.html">Robin Lee Powell: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>Reply:</strong> <a href="../0306/6917.html">Samantha Atkins: "Re: SIAI's flawed friendliness analysis"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6848">[ date ]</a>
<a href="index.html#6848">[ thread ]</a>
<a href="subject.html#6848">[ subject ]</a>
<a href="author.html#6848">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I think they have a word for what your condition, If I'm not mistaken it
<br>
is &quot;paranoia&quot;. Some people worry about actual things coming to get them,
<br>
you've created a little dream world where future bad things are coming to
<br>
get you, you have a gifted imagination.
<br>
<p>-----------------------------------------------------------
<br>
Barkley C. Vowk -- Systems Analyst -- University of Alberta
<br>
Math Sciences Department - <a href="mailto:Barkley.Vowk@math.ualberta.ca?Subject=Re:%20SIAI's%20flawed%20friendliness%20analysis">Barkley.Vowk@math.ualberta.ca</a>
<br>
Office: CAB642A, 780-492-4064
<br>
<p>Opinions expressed are the responsibility of the author and
<br>
may not reflect the opinions of others or reality.
<br>
<p>On Thu, 29 May 2003, Eliezer S. Yudkowsky wrote:
<br>
<p><em>&gt; Ben Goertzel wrote:
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I think that Eliezer and Bill are interpreting the term &quot;human
</em><br>
<em>&gt; &gt; happiness&quot; differently.  I think Eliezer is assuming a simple
</em><br>
<em>&gt; &gt; pleasure-gratification definition, whereas Bill means something more
</em><br>
<em>&gt; &gt; complex.  I suspect Bill's definition of human happiness might not be
</em><br>
<em>&gt; &gt; fulfilled by a Humanoids-style scenario where all humans are pumped up
</em><br>
<em>&gt; &gt; with euphoride, for example ;-)
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; I'm not necessarily taking Bill's side here -- I don't think that &quot;human
</em><br>
<em>&gt; &gt; happiness&quot; in any reasonable definition is going to be the best
</em><br>
<em>&gt; &gt; supergoal for an AGI -- but, I suspect Bill's proposal is less absurd
</em><br>
<em>&gt; &gt; than it seems at first glance because of his nonobvious definition of
</em><br>
<em>&gt; &gt; &quot;happiness&quot;
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;Happiness in human facial expressions, voices and body language, as
</em><br>
<em>&gt; trained by human behavior experts&quot;.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Not only does this one get satisfied by euphoride, it gets satisfied by
</em><br>
<em>&gt; quintillions of tiny little micromachined mannequins.  Of course, it will
</em><br>
<em>&gt; appear to work for as long as the AI does not have the physical ability to
</em><br>
<em>&gt; replace humans with tiny little mannequins, or for as long as the AI
</em><br>
<em>&gt; calculates it cannot win such a battle once begun.  A nice, invisible,
</em><br>
<em>&gt; silent kill.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If you want an image of the future, imagine a picture of a boot stamping
</em><br>
<em>&gt; on a picture of a face forever, and remember that it is forever.
</em><br>
<em>&gt;
</em><br>
<em>&gt; --
</em><br>
<em>&gt; Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
</em><br>
<em>&gt; Research Fellow, Singularity Institute for Artificial Intelligence
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="6849.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>Previous message:</strong> <a href="6847.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>In reply to:</strong> <a href="6846.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6849.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>Reply:</strong> <a href="6849.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>Reply:</strong> <a href="6892.html">Robin Lee Powell: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>Reply:</strong> <a href="../0306/6917.html">Samantha Atkins: "Re: SIAI's flawed friendliness analysis"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6848">[ date ]</a>
<a href="index.html#6848">[ thread ]</a>
<a href="subject.html#6848">[ subject ]</a>
<a href="author.html#6848">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:42 MDT
</em></small></p>
</body>
</html>
