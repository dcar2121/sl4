<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: SIAI's flawed friendliness analysis</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Re: SIAI's flawed friendliness analysis">
<meta name="Date" content="2003-05-17">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: SIAI's flawed friendliness analysis</h1>
<!-- received="Sat May 17 19:14:56 2003" -->
<!-- isoreceived="20030518011456" -->
<!-- sent="Sat, 17 May 2003 20:14:21 -0500" -->
<!-- isosent="20030518011421" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Re: SIAI's flawed friendliness analysis" -->
<!-- id="3EC6DE6D.7030209@posthuman.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="Pine.GSO.4.44.0305171607140.1953-100000@demedici.ssec.wisc.edu" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20SIAI's%20flawed%20friendliness%20analysis"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Sat May 17 2003 - 19:14:21 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="6721.html">Gary Miller: "RE: SIAI's flawed friendliness analysis"</a>
<li><strong>Previous message:</strong> <a href="6719.html">Michael Roy Ames: "Flawed Risk Analysis (was Re: SIAI's flawed friendliness analysis)"</a>
<li><strong>In reply to:</strong> <a href="6716.html">Bill Hibbard: "Re: SIAI's flawed friendliness analysis"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6726.html">Bill Hibbard: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>Reply:</strong> <a href="6726.html">Bill Hibbard: "Re: SIAI's flawed friendliness analysis"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6720">[ date ]</a>
<a href="index.html#6720">[ thread ]</a>
<a href="subject.html#6720">[ subject ]</a>
<a href="author.html#6720">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Bill Hibbard wrote:
<br>
<em>&gt; chapter. It will be impossible for regulation to prevent all
</em><br>
<em>&gt; construction of unsafe AIs, just as it is impossible to prevent
</em><br>
<em>&gt; all crimes of any kind. But for an unsafe AI to pose a real
</em><br>
<em>&gt; threat it must have power in the world, meaning either control
</em><br>
<em>&gt; over significant weapons (including things like 767s), or access
</em><br>
<em>&gt; to significant numbers of humans. But having such power in the
</em><br>
<em>&gt; world will make the AI detectable, so that it can be inspected
</em><br>
<em>&gt; to determine whether it conforms to safety regulations.
</em><br>
<p>We are worrying about an UFAI that has reached the level of intelligence 
<br>
to be dangerous, yes? Somewhere above human level. AND, it has at least 
<br>
one very willing human servant at its disposal. Even IF (a huge and 
<br>
quite unlikely if IMO) it can't use the Net undetected to get what it 
<br>
needs done, the human will do its bidding. I'm sorry, but your scheme 
<br>
described above looks rather silly in the face of such an adversary. The 
<br>
current government can't even catch lowly human-intelligence-level 
<br>
terrorists very well.
<br>
<p>Remember, a being with such an intelligence level may very well not 
<br>
pursue power through the kinds of traditional means you may be 
<br>
imagining. It could for instance, if it was good enough, come up with a 
<br>
plan to build some working molecular nanotech and from there do whatever 
<br>
it wants. And it might be able to execute such a plan in an undetectable 
<br>
fashion, barring a 100% worldwide transparent society.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; The danger of outlaws will increase as the technology for
</em><br>
<em>&gt; intelligent artifacts becomes easier. But as time passes we
</em><br>
<em>&gt; will also have the help of safe AIs to help detect and
</em><br>
<em>&gt; inspect other AIs.
</em><br>
<em>&gt; 
</em><br>
<p>Even in such fictional books as Neuromancer, we see that such Turing 
<br>
Police do not function well enough to stop a determined superior 
<br>
intelligence. Realistically, such a police force will only have any real 
<br>
chance of success at all if we have a very transparent society... it 
<br>
would require societal changes on a very grand scale, and not just in 
<br>
one country. It all seems rather unlikely... I think we need to focus on 
<br>
solutions that have a chance at actual implementation.
<br>
<pre>
-- 
Brian Atkins
Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="6721.html">Gary Miller: "RE: SIAI's flawed friendliness analysis"</a>
<li><strong>Previous message:</strong> <a href="6719.html">Michael Roy Ames: "Flawed Risk Analysis (was Re: SIAI's flawed friendliness analysis)"</a>
<li><strong>In reply to:</strong> <a href="6716.html">Bill Hibbard: "Re: SIAI's flawed friendliness analysis"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6726.html">Bill Hibbard: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>Reply:</strong> <a href="6726.html">Bill Hibbard: "Re: SIAI's flawed friendliness analysis"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6720">[ date ]</a>
<a href="index.html#6720">[ thread ]</a>
<a href="subject.html#6720">[ subject ]</a>
<a href="author.html#6720">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:42 MDT
</em></small></p>
</body>
</html>
