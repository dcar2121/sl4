<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: SIAI's flawed friendliness analysis</title>
<meta name="Author" content="Bill Hibbard (test@demedici.ssec.wisc.edu)">
<meta name="Subject" content="Re: SIAI's flawed friendliness analysis">
<meta name="Date" content="2003-05-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: SIAI's flawed friendliness analysis</h1>
<!-- received="Fri May 30 06:27:57 2003" -->
<!-- isoreceived="20030530122757" -->
<!-- sent="Fri, 30 May 2003 07:27:42 -0500 (CDT)" -->
<!-- isosent="20030530122742" -->
<!-- name="Bill Hibbard" -->
<!-- email="test@demedici.ssec.wisc.edu" -->
<!-- subject="Re: SIAI's flawed friendliness analysis" -->
<!-- id="Pine.GSO.4.44.0305300725120.5974-100000@demedici.ssec.wisc.edu" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="3ED63FFA.1020600@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Bill Hibbard (<a href="mailto:test@demedici.ssec.wisc.edu?Subject=Re:%20SIAI's%20flawed%20friendliness%20analysis"><em>test@demedici.ssec.wisc.edu</em></a>)<br>
<strong>Date:</strong> Fri May 30 2003 - 06:27:42 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="6880.html">Christian Szegedy: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>Previous message:</strong> <a href="6878.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>In reply to:</strong> <a href="6840.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6883.html">Ben Goertzel: "RE: SIAI's flawed friendliness analysis"</a>
<li><strong>Reply:</strong> <a href="6883.html">Ben Goertzel: "RE: SIAI's flawed friendliness analysis"</a>
<li><strong>Reply:</strong> <a href="6890.html">Rafal Smigrodzki: "RE: SIAI's flawed friendliness analysis"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6879">[ date ]</a>
<a href="index.html#6879">[ thread ]</a>
<a href="subject.html#6879">[ subject ]</a>
<a href="author.html#6879">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Thu, 29 May 2003, Eliezer S. Yudkowsky wrote:
<br>
<p><em>&gt; &quot;Happiness in human facial expressions, voices and body language, as
</em><br>
<em>&gt; trained by human behavior experts&quot;.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Not only does this one get satisfied by euphoride, it gets satisfied by
</em><br>
<em>&gt; quintillions of tiny little micromachined mannequins.  Of course, it will
</em><br>
<em>&gt; appear to work for as long as the AI does not have the physical ability to
</em><br>
<em>&gt; replace humans with tiny little mannequins, or for as long as the AI
</em><br>
<em>&gt; calculates it cannot win such a battle once begun.  A nice, invisible,
</em><br>
<em>&gt; silent kill.
</em><br>
<p>The essence of intelligence is a simulation model of the world
<br>
that is used to predict the long-term effect of behavior on
<br>
values, and hence solve the credit assignment problem for
<br>
reinforcement learning. A tight stimulus-response loop
<br>
satisfying immediate values has nothing to do with intelligence.
<br>
<p>An intelligent mind will develop a model of the world that
<br>
equates human happiness with a loving family life, adequate
<br>
food and shelter, physical exercise, freedom, a meaningful
<br>
vocation, friends, etc. And it will equate human unhappiness
<br>
with abusive relations, loneliness, homelessness, hunger, lack
<br>
of freedon, poor health, drug addiction, etc. Its behavior
<br>
will be based on this model, trying to promote the long-term
<br>
happiness of humans.
<br>
<p>Human babies love their mothers based on simple values about
<br>
touch, warmth, milk, smiles and sounds. But as the baby's
<br>
mind learns, those simple values get connected to a rich set
<br>
of values about the mother, via a simulation model of the
<br>
mother and surroundings. This elaboration of simple values
<br>
will happen in any truly intelligent AI. I can't speak for
<br>
others, but what rocks my boat is the sound of happiness in
<br>
my wife's voice - a simple, grounded value. Not for a second
<br>
does my model of the world suggest giving her drugs or
<br>
replacing her with a doll and a tape recording.
<br>
<p>Your argument can be applied against any grounded defintion
<br>
of values. Hence the SIAI guidelines define a supergoal that
<br>
is not grounded, and hence allows whatever interpretation an
<br>
AI designer wants to apply. Similarly, various other SIAI
<br>
recommendations use lots of value words without defining them.
<br>
Lack of grounding for value words in safe AI guidelines are
<br>
intended to protect against the imagined dangers of a
<br>
non-intelligent stimulus-response loop satisfying immediate
<br>
values, but have the actual effect of providing a loophole to
<br>
those with motives to circumvent safe AI guidelines.
<br>
<p><em>&gt; There is no divine right of democracy; it does not confer infallibility.
</em><br>
<em>&gt; What it does confer is faith and the illusion of infallibility.  Congress
</em><br>
<em>&gt; is not capable of understanding how little it knows, which is what makes
</em><br>
<em>&gt; it dangerous.  Democracy has known bugs; and those bugs, applied to
</em><br>
<em>&gt; Singularity scenarios, result in predictable kills - one of which you
</em><br>
<em>&gt; have just demonstrated.
</em><br>
<p>Thanks for being honest about this. Everyone will have to decide
<br>
for themselves whether they trust their elected representatives
<br>
or the SIAI.
<br>
<p><em>&gt; Incidentally, Hibbard, if I were given to trying to pass regulations,
</em><br>
<em>&gt; which I'm not, I'd prohibit the use of your reinforcement architecture,
</em><br>
<em>&gt; which is, of course, invariably fatal...
</em><br>
<p>Prohibiting reinforcement learning would ensure safety by
<br>
eliminating intelligence.
<br>
<p>----------------------------------------------------------
<br>
Bill Hibbard, SSEC, 1225 W. Dayton St., Madison, WI  53706
<br>
<a href="mailto:test@demedici.ssec.wisc.edu?Subject=Re:%20SIAI's%20flawed%20friendliness%20analysis">test@demedici.ssec.wisc.edu</a>  608-263-4427  fax: 608-263-6738
<br>
<a href="http://www.ssec.wisc.edu/~billh/vis.html">http://www.ssec.wisc.edu/~billh/vis.html</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="6880.html">Christian Szegedy: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>Previous message:</strong> <a href="6878.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<li><strong>In reply to:</strong> <a href="6840.html">Eliezer S. Yudkowsky: "Re: SIAI's flawed friendliness analysis"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="6883.html">Ben Goertzel: "RE: SIAI's flawed friendliness analysis"</a>
<li><strong>Reply:</strong> <a href="6883.html">Ben Goertzel: "RE: SIAI's flawed friendliness analysis"</a>
<li><strong>Reply:</strong> <a href="6890.html">Rafal Smigrodzki: "RE: SIAI's flawed friendliness analysis"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#6879">[ date ]</a>
<a href="index.html#6879">[ thread ]</a>
<a href="subject.html#6879">[ subject ]</a>
<a href="author.html#6879">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:42 MDT
</em></small></p>
</body>
</html>
