<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: ESSAY: Forward Moral Nihilism</title>
<meta name="Author" content="John K Clark (jonkc@att.net)">
<meta name="Subject" content="Re: ESSAY: Forward Moral Nihilism">
<meta name="Date" content="2006-05-15">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: ESSAY: Forward Moral Nihilism</h1>
<!-- received="Mon May 15 09:08:30 2006" -->
<!-- isoreceived="20060515150830" -->
<!-- sent="Mon, 15 May 2006 11:05:23 -0400" -->
<!-- isosent="20060515150523" -->
<!-- name="John K Clark" -->
<!-- email="jonkc@att.net" -->
<!-- subject="Re: ESSAY: Forward Moral Nihilism" -->
<!-- id="001a01c67831$05e1e9e0$9a0a4e0c@MyComputer" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="1147692592.446866305fbd3@webmailimpb.dur.ac.uk" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> John K Clark (<a href="mailto:jonkc@att.net?Subject=Re:%20ESSAY:%20Forward%20Moral%20Nihilism"><em>jonkc@att.net</em></a>)<br>
<strong>Date:</strong> Mon May 15 2006 - 09:05:23 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="14951.html">Jef Allbright: "Re: ESSAY: Forward Moral Nihilism (EP)"</a>
<li><strong>Previous message:</strong> <a href="14949.html">m.l.vere@durham.ac.uk: "Re: ESSAY: Forward Moral Nihilism"</a>
<li><strong>In reply to:</strong> <a href="14949.html">m.l.vere@durham.ac.uk: "Re: ESSAY: Forward Moral Nihilism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14954.html">m.l.vere@durham.ac.uk: "Re: ESSAY: Forward Moral Nihilism"</a>
<li><strong>Reply:</strong> <a href="14954.html">m.l.vere@durham.ac.uk: "Re: ESSAY: Forward Moral Nihilism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14950">[ date ]</a>
<a href="index.html#14950">[ thread ]</a>
<a href="subject.html#14950">[ subject ]</a>
<a href="author.html#14950">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&lt;<a href="mailto:m.l.vere@durham.ac.uk?Subject=Re:%20ESSAY:%20Forward%20Moral%20Nihilism">m.l.vere@durham.ac.uk</a>&gt;
<br>
<p><em>&gt; I do believe you are anthropomorphising the AI.
</em><br>
<p>Yes of course I'm anthropomorphizing the AI, it is a useful tool, sometimes
<br>
the only tool, in predicting the behavior of other beings. And although a
<br>
Jupiter brain will have many characteristics that are different from ours
<br>
some will be in common; both Mr. Jupiter and I will prefer existence to
<br>
nonexistence and pleasure over pain. And if you want the AI to be useful
<br>
it's going to need something like the will to power just like people do.
<br>
<p><em>&gt; We are only concerned with our own wellbeing because that is how evolution
</em><br>
<em>&gt; programed us. We program a FAI to concern itself whith whatever we want.
</em><br>
<p>Even today with our simple machines computers often behave in ways that we
<br>
don't like and don't fully understand, the idea that you can just tell an AI
<br>
to obey us and it will keep doing so for eternity is crazy, because that
<br>
would entail outsmarting something far smarter than you are.
<br>
<p>And even if you had an obedient slave AI it wouldn't be the top dog for long
<br>
because somewhere else an AI would develop that isn't hobbled by human
<br>
wishes and overtake it. Imagine if a human being suffered a mutation that
<br>
caused him to care more about sea slugs than his own life or that of his
<br>
children, do you imagine such a mutation would come to dominate in the gene
<br>
pool? You seem to think an AI who had such a bizarre obsession with humans
<br>
would be viable; I don't because even in the transhuman age the laws of
<br>
evolution will not be repealed.
<br>
<p><em>&gt; a FAI will essentially be a (unimaginably powerfull) optimisation process,
</em><br>
<em>&gt; and lack many of the things that make us human.
</em><br>
<p>An AI would lack meat, but that's about all.
<br>
<p><em>&gt; As such I dont think we can say it will
</em><br>
<em>&gt; be superior in *every* way.
</em><br>
<p>And I can't think of *any* way it wouldn't be enormously superior.
<br>
<p><em>&gt; Its not a slave in the traditional sense as being subservient is what it
</em><br>
<em>&gt; most wants.
</em><br>
<p>I don't believe it's possible so the moral question is probably moot, but I
<br>
must say I find the idea a little creepy. It's like engineering a race of
<br>
human beings that were strong beautiful and brilliant but wanted nothing
<br>
more from life than to be slaves forever.
<br>
<p>&nbsp;&nbsp;&nbsp;John K Clark
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="14951.html">Jef Allbright: "Re: ESSAY: Forward Moral Nihilism (EP)"</a>
<li><strong>Previous message:</strong> <a href="14949.html">m.l.vere@durham.ac.uk: "Re: ESSAY: Forward Moral Nihilism"</a>
<li><strong>In reply to:</strong> <a href="14949.html">m.l.vere@durham.ac.uk: "Re: ESSAY: Forward Moral Nihilism"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="14954.html">m.l.vere@durham.ac.uk: "Re: ESSAY: Forward Moral Nihilism"</a>
<li><strong>Reply:</strong> <a href="14954.html">m.l.vere@durham.ac.uk: "Re: ESSAY: Forward Moral Nihilism"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#14950">[ date ]</a>
<a href="index.html#14950">[ thread ]</a>
<a href="subject.html#14950">[ subject ]</a>
<a href="author.html#14950">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:56 MDT
</em></small></p>
</body>
</html>
