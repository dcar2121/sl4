<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Floppy take-off</title>
<meta name="Author" content="Durant Schoon (durant@ilm.com)">
<meta name="Subject" content="Re: Floppy take-off">
<meta name="Date" content="2001-07-31">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Floppy take-off</h1>
<!-- received="Tue Jul 31 20:59:10 2001" -->
<!-- isoreceived="20010801025910" -->
<!-- sent="Tue, 31 Jul 2001 17:58:36 -0700 (PDT)" -->
<!-- isosent="20010801005836" -->
<!-- name="Durant Schoon" -->
<!-- email="durant@ilm.com" -->
<!-- subject="Re: Floppy take-off" -->
<!-- id="durant-1010731175835.A1D50342@sleeper" -->
<!-- inreplyto="20010731191811.R1153@aristotle.bomis.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Durant Schoon (<a href="mailto:durant@ilm.com?Subject=Re:%20Floppy%20take-off"><em>durant@ilm.com</em></a>)<br>
<strong>Date:</strong> Tue Jul 31 2001 - 18:58:36 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1988.html">Dan Clemmensen: "Re: qualia"</a>
<li><strong>Previous message:</strong> <a href="1986.html">Brian Phillips: "Re: Floppy take-off"</a>
<li><strong>In reply to:</strong> <a href="1982.html">Jimmy Wales: "Re: Floppy take-off"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0108/2013.html">Durant Schoon: "Cracking and Parasitic AI WAS: Floppy take-off"</a>
<li><strong>Reply:</strong> <a href="../0108/2013.html">Durant Schoon: "Cracking and Parasitic AI WAS: Floppy take-off"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1987">[ date ]</a>
<a href="index.html#1987">[ thread ]</a>
<a href="subject.html#1987">[ subject ]</a>
<a href="author.html#1987">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; From: Jimmy Wales &lt;<a href="mailto:jwales@bomis.com?Subject=Re:%20Floppy%20take-off">jwales@bomis.com</a>&gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Of course, a &quot;not quite human&quot; AI isn't likely to be much like a mentally retarded
</em><br>
<em>&gt; human.  Probably more like an &quot;idiot savant&quot;, i.e. hyperintelligence in some ways,
</em><br>
<em>&gt; but really stupid in other ways.  As an example, we are shocked to see some autistic
</em><br>
<p>Hmm, I'm beginning to think that if we have to go full circle back to using computers
<br>
which are like idiot-savants which are like retarded humans to understand computers,
<br>
the &quot;double-speed 0.5 human brain&quot; analogy isn't helping us get anywhere.
<br>
<p>We can accept Carl's back-of-the-envelope calculations to determine when an AI
<br>
singularity is likely to occur without worrying about relying on idiot savants
<br>
and the retarded to get us there :-)
<br>
<p><em>&gt; I believe that Gordon's original point can be expanded by saying that _depending on
</em><br>
<em>&gt; the particular *way* in which our AI is stupid, and the *reasons* for that stupidity,
</em><br>
<em>&gt; simply throwing more CPU cycles just makes a really fast moron.
</em><br>
<p>Yes, that point seems to be the right track, or at least familiarly known to AI. 
<br>
Please, someone step in and correct me if I'm wrong, but one school of AI has
<br>
maintained that what is missing is Common Sense(*). We can crack Freshman Calculus,
<br>
We can crack Grand-Master Human Chess, but we still can't carry out a conversation
<br>
(Turing Test(**)).  
<br>
<p>Cyc is supposed to &quot;understand&quot; our world, right? I really wonder if anyone has tried 
<br>
to use CYC to solve any of the problems that can only be solved with a decent Common 
<br>
Sense Engine. Give an agent with access to a CSE and a problematic situation, then 
<br>
see if the agent can solve the problem. 
<br>
<p>You are hungry. There is a banana in the refrigerator. In your pocket is a bundle
<br>
of lint. What do you do?
<br>
<p>Has someone put CYC in Zork, yet?
<br>
<p>Has anyone introduced CYC to Eliza?
<br>
<p>Has anyone used CYC to build a better bicycle or improve national foreign policy?
<br>
<p>You could even start devising and applying wisdom tournaments to CYC...
<br>
<p>All we have is tactical battlefield analysis and SecureCYC, which sounds like an
<br>
auotmated AI hacking program (or was it CYCSecure?)
<br>
<p>Did they succeed with Common Sense? Are they keeping the good stuff to themselves? 
<br>
<p>The Common Sense Problem seems to be a major reason why computers and idiot
<br>
savants *seem* stupid, but I suppose one could build a SeedAI without achieving 
<br>
Common Sense first (our notions of intelligence are very anthropomorphic). 
<br>
<p><p>I, for one, do think that &quot;learning to learn better&quot; *is* the whole shebang. Do
<br>
that well first, and you can figure out the rest. Having Common Sense allows an 
<br>
intelligence to apply verself to the surrounding world in order to understand
<br>
and solve practical problems. Something one would want eventually, but not
<br>
necessary as a starting point.
<br>
<p><p>(*) The idea is that computers don't have the millions of little rules of common
<br>
sense that every child has. &quot;You can pull something with a string, but not push 
<br>
with it.&quot; &quot;People are expected to wear clothes to school.&quot; &quot;People who live in
<br>
Russia typically speak Russian.&quot; &quot;A banana is something people eat.&quot; &quot;Don't put
<br>
bananas in the refrigerator because they turn brown. People don't like brown
<br>
bananas.&quot; &quot;You are supposed to share your bases with others.&quot; These are &quot;dumb&quot; 
<br>
things kids know, but computers don't. If computers knew these things, they might 
<br>
seem a lot smarter and could put all that logical inferencing power to use.
<br>
<p>This is the &quot;school&quot; seemingly favored by Minsky and Lenat...though I'm a 
<br>
Yudkowskiest these days ;-)
<br>
<p>Every AI project that attempts to understand the world will need to represent it
<br>
somehow, WebMind, SingInst's. Whether you call it &quot;Common Sense&quot; or not does not
<br>
matter. It's a big tedious problem. The Cyc team has tried to crack it with domain
<br>
experts. Bio/WebMind sounds like they are trying to understand human language first
<br>
and then &quot;parse the web&quot;. It has to come from somewhere.
<br>
<p>(**) The Turing Test is of some interest, but just a milestone on the road from
<br>
SeedAI to Singularity.
<br>
<p><pre>
--
Durant Schoon
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1988.html">Dan Clemmensen: "Re: qualia"</a>
<li><strong>Previous message:</strong> <a href="1986.html">Brian Phillips: "Re: Floppy take-off"</a>
<li><strong>In reply to:</strong> <a href="1982.html">Jimmy Wales: "Re: Floppy take-off"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="../0108/2013.html">Durant Schoon: "Cracking and Parasitic AI WAS: Floppy take-off"</a>
<li><strong>Reply:</strong> <a href="../0108/2013.html">Durant Schoon: "Cracking and Parasitic AI WAS: Floppy take-off"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1987">[ date ]</a>
<a href="index.html#1987">[ thread ]</a>
<a href="subject.html#1987">[ subject ]</a>
<a href="author.html#1987">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
