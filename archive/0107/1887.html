<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: IQ testing for half-baked AI's</title>
<meta name="Author" content="Ben Goertzel (ben@webmind.com)">
<meta name="Subject" content="RE: IQ testing for half-baked AI's">
<meta name="Date" content="2001-07-28">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: IQ testing for half-baked AI's</h1>
<!-- received="Sat Jul 28 17:32:57 2001" -->
<!-- isoreceived="20010728233257" -->
<!-- sent="Sat, 28 Jul 2001 17:32:45 -0400" -->
<!-- isosent="20010728213245" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@webmind.com" -->
<!-- subject="RE: IQ testing for half-baked AI's" -->
<!-- id="NDBBIBGFAPPPBODIPJMMAEIJFNAA.ben@webmind.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="3B63044B.3A60F074@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@webmind.com?Subject=RE:%20IQ%20testing%20for%20half-baked%20AI's"><em>ben@webmind.com</em></a>)<br>
<strong>Date:</strong> Sat Jul 28 2001 - 15:32:45 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1888.html">James Higgins: "Re: Augmenting humans is a better way"</a>
<li><strong>Previous message:</strong> <a href="1886.html">Ben Goertzel: "RE: Usefullness of computational linguists in reaching the Singularity"</a>
<li><strong>In reply to:</strong> <a href="1872.html">Eliezer S. Yudkowsky: "Re: IQ testing for half-baked AI's"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1875.html">Gordon Worley: "Re: IQ testing for half-baked AI's"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1887">[ date ]</a>
<a href="index.html#1887">[ thread ]</a>
<a href="subject.html#1887">[ subject ]</a>
<a href="author.html#1887">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
wer of Hanoi problem&quot;, etc.
<br>
<em>&gt;
</em><br>
<em>&gt; Actually, my thoughts have more focused on milestones than on benchmarks.
</em><br>
<em>&gt; I have a pretty strong feeling that there will be no good way to compare
</em><br>
<em>&gt; benchmarks.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Here are some of the milestones I've been thinking about for the GISAI
</em><br>
<em>&gt; architecture, in no particular order (some of them are early, some of them
</em><br>
<em>&gt; are really advanced).
</em><br>
<em>&gt;
</em><br>
<em>&gt; Milestone:  Teaching an AI to play tic-tac-toe using a purely verbal,
</em><br>
<em>&gt; communicational description and no programming whatsoever.
</em><br>
<p>Do you really  mean &quot;purely verbal&quot;?  I hope you mean &quot;verbal and visual&quot;,
<br>
as tic-tac-toe is a game very much tied to perception of a 2D physical
<br>
world.  Explaining and playing purely verbally with no diagrams is possible
<br>
but not very natural.
<br>
<p>With this emendation, I like this one very much.
<br>
<p>We have a similar goal for Webmind: to teach it to play Twenty Questions
<br>
purely based on verbal feedback.  (Here the &quot;purely verbal&quot; restriction
<br>
makes more sense.)
<br>
<p><em>&gt; Milestone:  Getting an AI to play humanstyle chess - chess without
</em><br>
<em>&gt; internally representing a search tree larger than humans use - at credible
</em><br>
<em>&gt; amateur levels.
</em><br>
<p>Welll... I don't like this one.
<br>
<p>I think one should stay away from milestones that place restrictions on the
<br>
internal functioning of the system.
<br>
<p>I much prefer milestones that refer only to the system's behavior rather
<br>
than to how the system does what it does...
<br>
<p><em>&gt; Milestone:  An AI being able to successfully determine when two pieces of
</em><br>
<em>&gt; code do &quot;the same thing&quot; even when they have different graphs.  The
</em><br>
<em>&gt; submilestones here are the various levels of &quot;the same thing&quot; - i.e.,
</em><br>
<em>&gt; recursive vs. iterative implementations of the Fibonacchi sequence; the
</em><br>
<em>&gt; different ways of computing Pascal's Triangle; the same piece of code
</em><br>
<em>&gt; written in Java and in Perl; an array container class written in Java and
</em><br>
<em>&gt; a linked-list container class written in C++; assembly language and C++
</em><br>
<em>&gt; source; a high-level verbal description of an algorithm... and so on.
</em><br>
<p>This is an interesting one, and could be broken down into many sub-goals,
<br>
some of which are suitable for a baby AI and some of which are very, ery
<br>
hard.
<br>
<p><em>&gt; Milestone:  As above, but being able to translate on demand between
</em><br>
<em>&gt; substrates.  (Quite a different problem - not necessarily a more advanced
</em><br>
<em>&gt; or less advanced version of the above.)
</em><br>
<em>&gt;
</em><br>
<em>&gt; Milestone:  Inventing a complex tool, through abstract reasoning rather
</em><br>
<em>&gt; than blind search or even heuristic search, within a complex toy world or
</em><br>
<em>&gt; the world of code.  Note that by &quot;abstract reasoning&quot; I mean something
</em><br>
<em>&gt; quite different than the use of blind symbols in classical AI!
</em><br>
<p>I don't mind tool-building as a task, but again, I don't like the
<br>
restriction on the system's internal functioning.
<br>
<p>I mean, who decides whether a symbol insidee some AI system is &quot;too blind&quot;
<br>
to be part of a valid train of &quot;abstract reasoning&quot;?  Eli?
<br>
<p><em>&gt; Milestone:  Inventing a complex plan to solve a complex solution, again
</em><br>
<em>&gt; through the use of abstract reasoning rather than blind search.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Milestone:  Successfully linking events observed in a billiard-ball
</em><br>
<em>&gt; modality image to higher-level symbols, such that a generic event (nine
</em><br>
<em>&gt; balls in three groups of three) can be translated into a symbolic
</em><br>
<em>&gt; structure and reconstructed in rough detail using only that structure.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Milestone:  As above, but communicated to a human in English, and then
</em><br>
<em>&gt; reconstructed from the human's description in English.  Both this and the
</em><br>
<em>&gt; above also come in gradiated versions depending on the complexity of the
</em><br>
<em>&gt; image.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Milestone:  Storing a billiard-ball image in memory and retrieving it from
</em><br>
<em>&gt; memory.
</em><br>
<p>I don't think we're that far off from each other on this topic...
<br>
<p>If we
<br>
<p>1) accept ONLY those of your milestones that don't refer to internal system
<br>
functioning, but only refer to external system behavior
<br>
<p>2) quantify performance on each of the milestones (tic-tac-toe is close to
<br>
all-or-nothing: did it learn the rules or not?  But determining functional
<br>
code equivalence, for example, is something where one could make many
<br>
different problems of different levels of difficulty and assess an objective
<br>
&quot;performance grade&quot; for each of a set of AI systems)
<br>
<p>then your milestones are the same as my benchmarks.
<br>
<p>I do feel pretty strongly that it's better to have
<br>
milestones/benchmarks/whatever that refer only to external behavior.  Within
<br>
this restriction, one could put Peter's &amp; my tests and your tests together
<br>
and we'd have a start toward the kind of system-independent &quot;IQ testing
<br>
framework&quot; I was talking about.
<br>
<p>ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1888.html">James Higgins: "Re: Augmenting humans is a better way"</a>
<li><strong>Previous message:</strong> <a href="1886.html">Ben Goertzel: "RE: Usefullness of computational linguists in reaching the Singularity"</a>
<li><strong>In reply to:</strong> <a href="1872.html">Eliezer S. Yudkowsky: "Re: IQ testing for half-baked AI's"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1875.html">Gordon Worley: "Re: IQ testing for half-baked AI's"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1887">[ date ]</a>
<a href="index.html#1887">[ thread ]</a>
<a href="subject.html#1887">[ subject ]</a>
<a href="author.html#1887">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
