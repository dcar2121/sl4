<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Friendly AI and Human Augmentation</title>
<meta name="Author" content="Jack Richardson (jrichard@empire.net)">
<meta name="Subject" content="Friendly AI and Human Augmentation">
<meta name="Date" content="2001-07-04">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Friendly AI and Human Augmentation</h1>
<!-- received="Wed Jul 04 20:56:42 2001" -->
<!-- isoreceived="20010705025642" -->
<!-- sent="Wed, 4 Jul 2001 08:50:22 -0400" -->
<!-- isosent="20010704125022" -->
<!-- name="Jack Richardson" -->
<!-- email="jrichard@empire.net" -->
<!-- subject="Friendly AI and Human Augmentation" -->
<!-- id="000b01c10487$e44e0920$088c90c6@oemcomputer" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Jack Richardson (<a href="mailto:jrichard@empire.net?Subject=Re:%20Friendly%20AI%20and%20Human%20Augmentation"><em>jrichard@empire.net</em></a>)<br>
<strong>Date:</strong> Wed Jul 04 2001 - 06:50:22 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1719.html">Christian L.: "Re: Friendly AI and Human Augmentation"</a>
<li><strong>Previous message:</strong> <a href="1717.html">J. R. Molloy: "Re: HUMOR: Re: Spoiler Review of A.I."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1719.html">Christian L.: "Re: Friendly AI and Human Augmentation"</a>
<li><strong>Maybe reply:</strong> <a href="1719.html">Christian L.: "Re: Friendly AI and Human Augmentation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1718">[ date ]</a>
<a href="index.html#1718">[ thread ]</a>
<a href="subject.html#1718">[ subject ]</a>
<a href="author.html#1718">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
We are in a period of time in which the notion of the Singularity, to the extent that it is thought of at all, is considered in the realm of science fiction by most of the human population. At the same time, some of those involved in developing AI have the optimistic view that the Singularity will arise in the relatively short time of ten to twenty years. During that same period, the methods of augmenting humans will develop rapidly and become much more sophisticated.
<br>
<p>The optimistic view that the Singularity will arise out of AI development on computer hardware assumes that the complexities of human intelligence can be replicated on machine hardware without any insoluble problems standing in the way. Historically, at least so far, this has not turned out to be the case. Although some progress is being made, we are still far away from that goal.
<br>
<p>But what if the development towards transhuman intelligence started with existing human intelligence. With the right sort of augmentation technology, humans could gain access to some of the key capabilities noted in the machines. In particular, I'm thinking of the ability to update with the latest, most efficient code as well as the ability to remember vast amounts of information.
<br>
<p>The danger of this course is that it puts vast new capabilities in the hands of flawed human beings. Here is where the research being done for friendly AI might be integrated into the augmentation features in such a way that it could ameliorate any flawed tendencies. It may be that that nature of the first transhuman AI could set the standard and greatly influence whatever comes next. An architecture maximized for ideal qualities might give us all the best chance that whatever flaws might emerge would not be massively destructive.
<br>
<p>Since there are real risks in whatever route we take towards the Singularity, once it begins to be perceived as a possibility by the larger population, it is highly likely there will be a massive reaction with the kind of protests we are seeing today towards the biotechnology companies. Without the convincing demonstration of the reliability of friendly AI controls, it may be impossible to continue to conduct open AI research.
<br>
&nbsp;
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1719.html">Christian L.: "Re: Friendly AI and Human Augmentation"</a>
<li><strong>Previous message:</strong> <a href="1717.html">J. R. Molloy: "Re: HUMOR: Re: Spoiler Review of A.I."</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1719.html">Christian L.: "Re: Friendly AI and Human Augmentation"</a>
<li><strong>Maybe reply:</strong> <a href="1719.html">Christian L.: "Re: Friendly AI and Human Augmentation"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1718">[ date ]</a>
<a href="index.html#1718">[ thread ]</a>
<a href="subject.html#1718">[ subject ]</a>
<a href="author.html#1718">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
