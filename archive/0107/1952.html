<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Floppy take-off</title>
<meta name="Author" content="Carl Feynman (carlf@abinitio.com)">
<meta name="Subject" content="Floppy take-off">
<meta name="Date" content="2001-07-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Floppy take-off</h1>
<!-- received="Mon Jul 30 19:29:39 2001" -->
<!-- isoreceived="20010731012939" -->
<!-- sent="Mon, 30 Jul 2001 18:05:45 -0400" -->
<!-- isosent="20010730220545" -->
<!-- name="Carl Feynman" -->
<!-- email="carlf@abinitio.com" -->
<!-- subject="Floppy take-off" -->
<!-- id="3B65DA38.ECB228E3@abinitio.com" -->
<!-- charset="us-ascii" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Carl Feynman (<a href="mailto:carlf@abinitio.com?Subject=Re:%20Floppy%20take-off"><em>carlf@abinitio.com</em></a>)<br>
<strong>Date:</strong> Mon Jul 30 2001 - 16:05:45 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1953.html">Gordon Worley: "Re: Floppy take-off"</a>
<li><strong>Previous message:</strong> <a href="1951.html">Brian Atkins: "Re: flare and SIAI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1953.html">Gordon Worley: "Re: Floppy take-off"</a>
<li><strong>Reply:</strong> <a href="1953.html">Gordon Worley: "Re: Floppy take-off"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1952">[ date ]</a>
<a href="index.html#1952">[ thread ]</a>
<a href="subject.html#1952">[ subject ]</a>
<a href="author.html#1952">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I'm going to try to estimate how much brainpower it takes to improve an
<br>
AI substantially.  And I'm going to be optimistic, but the results will
<br>
still be pretty bad.
<br>
<p>There are four potential sources of intellect increase with time:
<br>
1. Moore's law.  We all know how that works.
<br>
2. Increased funding to buy more hardware.  This is swamped by Moore's
<br>
Law.
<br>
3. Tighter coding-- translating everything from LISP to assembler.  This
<br>
is worthwhile, but produces at most a one-time gain of a factor of ten,
<br>
and probably less.
<br>
4. Improved algorithms.  This can make huge improvements.  From 1950 to
<br>
1980, computers got a million times faster.  But techniques for solving
<br>
elliptic PDEs also got a million times more efficient, producing an
<br>
overall gain of a trillion.  This is the kind of improvement Eliezer is
<br>
expecting when he talks about self-improving AI.  I will now try to
<br>
estimate the cost of such gains.
<br>
<p>The AI field has given up (by and large) trying to create general
<br>
intelligence.  This has been the case for about ten years.  But during
<br>
those ten years (which I will call &quot;the nineties&quot;) lots of progress has
<br>
been made on various subproblems.  (The AI field has picked the wrong
<br>
subproblems, but that's a polemic for another day.  The important thing
<br>
is that progress has been made on the chosen problems).  For example,
<br>
here's paper describing a technique that accelerates solutions to
<br>
satisfiability problems by between two and four orders of magnitude:
<br>
<p>Gomes, C.; Selman, B.; and Kautz, H. 1998. Boosting combinatorial search
<br>
through randomization. In Proceedings of 15th National Conference on
<br>
Artificial Intelligence, 431--437. AAAI Press/The MIT Press.
<br>
<p>And the insight of the paper can be squashed into a few sentences in its
<br>
abstract.  Now this seems like a nifty thing: a simple insight that
<br>
produces huge gains.  All we need is a few of those and we're golden.
<br>
But how long did it take to produce this insight?  Well, it took three
<br>
authors of the paper, working for a year or so.  And it also took many
<br>
thousands of hours of simulation to develop the statistical insight that
<br>
led to the improvement.  And it took all the time the authors were in
<br>
school being trained, but let's not count that, because if the authors
<br>
were AIs, we could amortize it over all of them.  So far it doesn't seem
<br>
too bad: three person-years, for three orders of magnitude of
<br>
improvement.  But let's look at all the avenues of investigation that
<br>
led nowhere.  Here's another example result:
<br>
<p>C.R. Feynman, H.L. Voorhees, L.W. Tucker, &quot;Massively parallel approach
<br>
to
<br>
object recognition&quot; (IRCV '88)
<br>
<p>I can confidently state that our development of a parallel feature-based
<br>
reconition algorithm has had no effect whatever on present-day AI.  But
<br>
at the time, we thought we were doing good stuff, and we spent years on
<br>
it.  The problem is that you can't tell, while you're doing it, whether
<br>
what you're doing will lead anywhere.  So we have to count the cost of
<br>
not just the research that worked, but of the whole field of AI, most of
<br>
which led nowhere.
<br>
<p>So let's say that during the nineties the field improved its algorithms
<br>
by a factor of a thousand (some areas improved more than this, some
<br>
less).  And let's say this was done by a thousand people working for ten
<br>
years (a low estimate of how many people are in the field).  So doubling
<br>
the power of an AI takes about 2000 person-years.  We will begin sliding
<br>
into a singularity when the rate of self-improvement exceeds the rate of
<br>
improvement due to Moore's law.  This will require an AI able to do 2000
<br>
person-years of thinking in eighteen months.  In other words, we will
<br>
need an AI of 1.3 kilobrain capacity.  I don't know what that is in
<br>
flops, but it's an awful lot no matter how you slice it.
<br>
<p>Let's be optimistic and say that Webmind had an AI with a capacity of
<br>
0.5 brains.  It will take Moore's Law about 16 years to upgrade their
<br>
machine to 1.3 kilobrains.  If we assume that the rate of progress in AI
<br>
algorithms (doubling every two years) continues, and that the AI field
<br>
is working on the right problems, the time is decreased to about ten
<br>
years.  Still pretty long.
<br>
<p>Boy, I hope I'm wrong.
<br>
<p>--Carl Feynman
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1953.html">Gordon Worley: "Re: Floppy take-off"</a>
<li><strong>Previous message:</strong> <a href="1951.html">Brian Atkins: "Re: flare and SIAI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1953.html">Gordon Worley: "Re: Floppy take-off"</a>
<li><strong>Reply:</strong> <a href="1953.html">Gordon Worley: "Re: Floppy take-off"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1952">[ date ]</a>
<a href="index.html#1952">[ thread ]</a>
<a href="subject.html#1952">[ subject ]</a>
<a href="author.html#1952">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
