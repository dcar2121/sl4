<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Augmenting humans is a better way</title>
<meta name="Author" content="Ben Goertzel (ben@webmind.com)">
<meta name="Subject" content="RE: Augmenting humans is a better way">
<meta name="Date" content="2001-07-28">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Augmenting humans is a better way</h1>
<!-- received="Sat Jul 28 13:20:24 2001" -->
<!-- isoreceived="20010728192024" -->
<!-- sent="Sat, 28 Jul 2001 08:31:44 -0400" -->
<!-- isosent="20010728123144" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@webmind.com" -->
<!-- subject="RE: Augmenting humans is a better way" -->
<!-- id="NDBBIBGFAPPPBODIPJMMKEHPFNAA.ben@webmind.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3B6278AE.FE914250@posthuman.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@webmind.com?Subject=RE:%20Augmenting%20humans%20is%20a%20better%20way"><em>ben@webmind.com</em></a>)<br>
<strong>Date:</strong> Sat Jul 28 2001 - 06:31:44 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1865.html">Brian Phillips: "Re: augmenting humans is difficult and slow..."</a>
<li><strong>Previous message:</strong> <a href="1863.html">Ben Goertzel: "RE: augmenting humans is difficult and slow..."</a>
<li><strong>In reply to:</strong> <a href="1860.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1873.html">Gordon Worley: "RE: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1873.html">Gordon Worley: "RE: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1880.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1864">[ date ]</a>
<a href="index.html#1864">[ thread ]</a>
<a href="subject.html#1864">[ subject ]</a>
<a href="author.html#1864">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; I'd much prefer us to get
</em><br>
<em>&gt; the first real self-enhancing AI up and running rather than someone like
</em><br>
<em>&gt; a Hugo de Garis who just scares me (from a scientific point of view too).
</em><br>
<p>Just a side comment here...
<br>
<p>I just spent a couple days with Hugo last month (in the emptied-out Starlab
<br>
building -- a beautiful building by the way, see
<br>
<a href="http://www.starlab.org/contactus/findus/">http://www.starlab.org/contactus/findus/</a> ), and I can assure you that while
<br>
he's got some really interesting technical work going, he's *nowhere near* a
<br>
workable path to a real AI.
<br>
<p>He think it'll be 50 years or so before we get a real AI.  What he has now
<br>
is a superpowerful hardware system for evolving neural nets by genetic
<br>
programming.  Some very cool aspects, such as a genotype/phenotype
<br>
distinction (the genotype gives initial positions of neurons, and there's an
<br>
epigenesis phase in which synapses grow, providing the phenotype, the actual
<br>
neural net).  A weakness is that fitness of an NN must be assessed by a list
<br>
of given fitness cases, and can't be done by some function not easily
<br>
encapsulated in a small table of cases (e.g. it can't be done by inference
<br>
relative to a database of experience, as is the case for most procedure
<br>
evolution/learning in the mind).
<br>
<p>As for his philosophical views, he believes that Friendly AI is possible,
<br>
but that even if AI's are friendly, people are not, and they won't accept
<br>
AI's, so there will be some kind of violent struggle between pro-AI people
<br>
and anti-AI people.  He believes that self-modifying AI can be a path to
<br>
superhuman intelligence, but he believes this path will take several hundred
<br>
years, and that during this time there is a decent change that the AI's and
<br>
all humans are wiped out by stupid paranoid human violence.
<br>
<p>On a personal level, while Hugo is definitely a very eccentric individual in
<br>
some ways, he was very friendly and took a lot of time out to talk to me in
<br>
spite of being in the midst of a huge crisis situation (Starlab just went
<br>
broke, he was out of a job and had no idea what he was doing next -- hmm, a
<br>
very familiar situation to me actually ;p ).  He offered his spare room to
<br>
me during my visit to Brussels (for the Global Brain Workshop
<br>
(<a href="http://pespmc1.vub.ac.be/Conf/GB-0.html">http://pespmc1.vub.ac.be/Conf/GB-0.html</a>, a gathering at which many
<br>
Singularity-ish topics were discussed, although the &quot;Singularity&quot; phrase got
<br>
little respect) even though we'd never met each other before in person, only
<br>
discussed things thru e-mail.
<br>
<p>Frankly, although I think it's unlikely, I would *much* rather see the first
<br>
real AI created by Hugo, who is basically a sweet guy who has thought deeply
<br>
about the philosophical ramifications of AI, than by oh, say, a US military
<br>
AI lab....  I don't think that mild-mannered eccentric scientists are our
<br>
greatest worry by any means.  Fortunately, at this point, the military and
<br>
other powerful entities whose ethics I question, apparently have no interest
<br>
in building real AI, because the academic establishment has convinced them
<br>
it's a very very long way off still.
<br>
<p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1865.html">Brian Phillips: "Re: augmenting humans is difficult and slow..."</a>
<li><strong>Previous message:</strong> <a href="1863.html">Ben Goertzel: "RE: augmenting humans is difficult and slow..."</a>
<li><strong>In reply to:</strong> <a href="1860.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1873.html">Gordon Worley: "RE: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1873.html">Gordon Worley: "RE: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1880.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1864">[ date ]</a>
<a href="index.html#1864">[ thread ]</a>
<a href="subject.html#1864">[ subject ]</a>
<a href="author.html#1864">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
