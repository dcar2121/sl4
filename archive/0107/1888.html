<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Augmenting humans is a better way</title>
<meta name="Author" content="James Higgins (jameshiggins@earthlink.net)">
<meta name="Subject" content="Re: Augmenting humans is a better way">
<meta name="Date" content="2001-07-28">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Augmenting humans is a better way</h1>
<!-- received="Sat Jul 28 17:37:57 2001" -->
<!-- isoreceived="20010728233757" -->
<!-- sent="Sat, 28 Jul 2001 14:46:23 -0700" -->
<!-- isosent="20010728214623" -->
<!-- name="James Higgins" -->
<!-- email="jameshiggins@earthlink.net" -->
<!-- subject="Re: Augmenting humans is a better way" -->
<!-- id="4.3.2.7.2.20010728141052.020ea6b8@mail.earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3B6324EB.4F6EB2AE@posthuman.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Higgins (<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20Augmenting%20humans%20is%20a%20better%20way"><em>jameshiggins@earthlink.net</em></a>)<br>
<strong>Date:</strong> Sat Jul 28 2001 - 15:46:23 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1889.html">James Higgins: "RE: Augmenting humans is a better way"</a>
<li><strong>Previous message:</strong> <a href="1887.html">Ben Goertzel: "RE: IQ testing for half-baked AI's"</a>
<li><strong>In reply to:</strong> <a href="1881.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1899.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1899.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="../0108/2045.html">Arona Ndiaye: "Re: Augmenting humans is a better way"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1888">[ date ]</a>
<a href="index.html#1888">[ thread ]</a>
<a href="subject.html#1888">[ subject ]</a>
<a href="author.html#1888">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
At 04:47 PM 7/28/2001 -0400, you wrote:
<br>
<em>&gt;James Higgins wrote:
</em><br>
<em>&gt; &gt; &gt;Exactly, it may well be impossible to come up with a one-size fits all
</em><br>
<em>&gt; &gt; &gt;technology for something as uniquely individual as the brain. And what
</em><br>
<em>&gt; &gt; &gt;company will take the risks to commercial it if they know that for many
</em><br>
<em>&gt; &gt; &gt;people it won't work, or they even risk getting sued? We live in a
</em><br>
<em>&gt; &gt; &gt;country where Dow Chemical got sued by women who got breast implants.
</em><br>
<em>&gt; &gt; &gt;Will companies really expose themselves to the kinds of risks involved
</em><br>
<em>&gt; &gt; &gt;with neural hacking?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Hello?  Sorry, but I just HAVE to point this out.  Did you know that there
</em><br>
<em>&gt; &gt; are more countries in the world than the United States?  Personally,
</em><br>
<em>&gt;
</em><br>
<em>&gt;Yes and almost all of them are less advanced when it comes to biological
</em><br>
<em>&gt;and computing sciences. Many of them are close or even equivalent, but
</em><br>
<em>&gt;those same countries are also the ones who will likely be even less
</em><br>
<em>&gt;likely to work on Really Scary Human Augmenting science. Think Europe.
</em><br>
<em>&gt;So if you have to bail out of the USA that is going to extend the
</em><br>
<em>&gt;bio-based Singularity timeline even farther than I am already thinking
</em><br>
<em>&gt;about.
</em><br>
<p>Same companies, different countries.  You can buy medication overseas that 
<br>
the FDA has not (or will not) approve for sale in the US.  Multi-national 
<br>
corporations make individual countries mostly irrelevant when it comes to 
<br>
holding back new technology/advances.
<br>
<p><em>&gt; &gt; if/when they come up with implants that offer a significant mental
</em><br>
<em>&gt; &gt; advantage and have a low chance of screwing you up I *will* be getting
</em><br>
<em>&gt; &gt; one.  I don't care if I have to go to Japan, Europe, Russia, Mexico or
</em><br>
<em>&gt; &gt; Chiba City (CyberPunk is my favorite fictional genre).  When it becomes
</em><br>
<em>&gt; &gt; possible to do, it will also become possible to get (and without waiting
</em><br>
<em>&gt; &gt; for FDA approval)!  Then, assuming these have a significant effect on
</em><br>
<em>&gt; &gt; intelligence, the next series will likely be available sooner than might be
</em><br>
<em>&gt; &gt; expected (you have to assume the developers are going to use their own
</em><br>
<em>&gt; &gt; product).  I also imagine that income for upgraded individuals will
</em><br>
<em>&gt; &gt; drastically go up, which will make affording the next upgrade much
</em><br>
<em>&gt; &gt; easier.  Which is another reason why I'd want to get on the boat early.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; But, that said, this will still take a very long time.  Possibly much
</em><br>
<em>&gt; &gt; longer than the AI path.  However, I will NOT say that the AI path is
</em><br>
<em>&gt; &gt; likely to be faster than this path since NO ONE IN THE WHOLE WORLD HAS EVER
</em><br>
<em>&gt; &gt; CREATED ANYTHING REMOTELY SIMILIAR TO REAL AI.  And thus it is IMPOSSIBLE
</em><br>
<em>&gt;
</em><br>
<em>&gt;Now you are the one making claims.. for all you know Webmind may very well
</em><br>
<em>&gt;be remotely similar to real AI. In fact you have Ben here making that
</em><br>
<em>&gt;claim. I do not see anyone around claiming to be near to finishing a
</em><br>
<em>&gt;Real Neural Interface. RNIs seem to be around the stage of development
</em><br>
<em>&gt;that AI was back when computers were using vacuum tubes.
</em><br>
<em>&gt;
</em><br>
<em>&gt;A different way to look at it is this: with the computing power of the
</em><br>
<em>&gt;near future, AI is at the stage now where we can do real scientific
</em><br>
<em>&gt;experimentation. That (being able to really experiment) almost always
</em><br>
<em>&gt;leads to breakthroughs. RNIs are not there yet. I think you will agree
</em><br>
<em>&gt;with me that the AI path /definitely/ seems to be much farther along from
</em><br>
<em>&gt;these two perspectives.
</em><br>
<p>No, I'm specifically NOT making claims.  I'm taking a show me attitude.
<br>
<p>IF/WHEN they come up with implants that A) make a significant difference in 
<br>
mental capacity and B) aren't likely to screw up the recipient.  I'm not 
<br>
making any claims there.
<br>
<p>&quot;When it becomes possible to do, it will also become possible to get&quot;.  If 
<br>
the time is taken to design such an implant, it will become available in 
<br>
one fashion or another.  With enough money you can even go buy a nuclear 
<br>
weapon, so you will be able to buy implants once they have been designed.
<br>
<p>If I had an implant that significantly enhanced my mental ability, I feel 
<br>
confidant that I could negotiate for much better pay.  I'm already quite 
<br>
good at this anyway.
<br>
<p>As for Real AI, when someone gets one working then we can talk.  The fact 
<br>
is that no one knows what Real AI is going to require.  I also think Ben is 
<br>
doing a great job and is probably the most likely (that I know of anyway) 
<br>
to succeed.  However, no one can predict with any credibility that he will 
<br>
succeed.  I like to think he will and I would bet that he would also.
<br>
<p><em>&gt; &gt; to estimate if/when we will ever get real AI.  Without incredibly massive
</em><br>
<em>&gt; &gt; funding it may take 15-20 years just to build a knowledge base sufficient
</em><br>
<em>&gt; &gt; to kick start the thing.  And you can't seriously argue the point because,
</em><br>
<em>&gt;
</em><br>
<em>&gt;Knowledge bases (shouldn't this be one word?) already exist both in natural
</em><br>
<em>&gt;form (the world, the Net) and in prepackaged formats like Cyc. Again, you see
</em><br>
<em>&gt;that AI is farther along in development.
</em><br>
<p>Yes, they exist.  Are they of the correct form?  Do they contain sufficient 
<br>
knowledge?
<br>
<p><em>&gt; &gt; honestly, you don't know otherwise.  I give very serious credit to Ben
</em><br>
<em>&gt; &gt; Goertzel's opinions on AI (keep up the great work) and I doubt he could, in
</em><br>
<em>&gt; &gt; all honesty, give any sort of realistic time line for the first Real AI
</em><br>
<em>&gt; &gt; (TM).  Thus I don't you, you don't know, we don't know.
</em><br>
<em>&gt;
</em><br>
<em>&gt;He may be unwilling to do so in public, but I can tell you that it
</em><br>
<em>&gt;won't take until 2030 according to rumors I hear...
</em><br>
<p>Certainly the hardware will be available before then (there is a strong 
<br>
track record to predict that on).  But there is no track record to predict 
<br>
Real AI.  In order to make predictions on how long it will take to 
<br>
understand it.  We don't understand Real AI yet.  I could just as easily 
<br>
say we will break the barrier for traveling faster than the speed of light 
<br>
by 2050, but that also requires knowledge that we don't yet have and thus 
<br>
we can not predict this.
<br>
<p>So everyone agrees that 2030 is the outside estimate, but that is just a 
<br>
hopeful guess (that I also share, BTW).
<br>
<p><em>&gt; &gt; Even self upgrading AI will take many steps to get there.  Same exact
</em><br>
<em>&gt; &gt; thing, just a different route.  No technology is going to just go *blip*
</em><br>
<em>&gt; &gt; and produce Singularity.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Steps at computer speed, not biological hacking speed. VAST difference.
</em><br>
<p>You're probably correct, but they both require steps.  And no one knows for 
<br>
certain, maybe an advanced biological implant would allow for reprogramming 
<br>
&amp; expendability, which could put both on similar terms.
<br>
<p><em>&gt;Actually you cannot say that for certain about AI. We definitely can
</em><br>
<em>&gt;say that about the biological route, at least up till the point we
</em><br>
<em>&gt;get nanotech/inloading. There is nothing to prevent an AI that is
</em><br>
<em>&gt;smart enough from developing a quick route to nanotech and then yes
</em><br>
<em>&gt;*blip* away we go.
</em><br>
<p>But it will most likely take many steps to get to that point, especially 
<br>
based on Eli's Seed AI.
<br>
<p><em>&gt; &gt; You know, producing the first Real AI may be so difficult that it may just
</em><br>
<em>&gt; &gt; require augmented humans to get their in any reasonable amount of
</em><br>
<em>&gt; &gt; time.  Have you considered that possible reality?
</em><br>
<em>&gt;
</em><br>
<em>&gt;No I do not see that as a reasonable possibility. Most AI scientists
</em><br>
<em>&gt;will agree that even if we can't design an AI, we can evolve one. By
</em><br>
<em>&gt;brute force if we have to by simply trying all possibile code. It's
</em><br>
<em>&gt;like picking a combination lock, if the lock is openable at all then
</em><br>
<em>&gt;you will eventually open it just by trying all ways. And the rise in
</em><br>
<em>&gt;computing power makes this almost inevitable by 2030 or even earlier.
</em><br>
<p>Don't agree, especially after your argument.  Trying &quot;all possible code&quot; 
<br>
would take a very, very long time.  Unless a significant percentage of 
<br>
available resources were devoted to this it could easily exceed 
<br>
2030.  Computing power does you no good when it comes to software 
<br>
development, a computer that runs 10 times faster has almost no effect on 
<br>
the speed of the developer.  Nural implants could, on the other hand, have 
<br>
incredible impact on the speed of developers as maybe they could think code 
<br>
instead of typing it.  I'm not saying that this is going to be necessary, 
<br>
but it would definitely be helpful and may be necessary in order to keep 
<br>
the proposed time line.
<br>
<p>Plus, it might be much more likely for enhanced humans to get friendliness 
<br>
right the first time.
<br>
<p><em>&gt; &gt; &gt; &gt; &gt; the singularity than the imho cringing one proposed by the 
</em><br>
<em>&gt; Institute of
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; building an AI and - if everything works out as hoped - maybe 
</em><br>
<em>&gt; humans will
</em><br>
<em>&gt; &gt; &gt; &gt; be
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; permitted to scale the heights; what I would call the &quot;singularity by
</em><br>
<em>&gt; &gt; &gt; &gt; proxy&quot;
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; path.  I, for one, intend to participate DIRECTLY in the 
</em><br>
<em>&gt; singularity.  I
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; hope there are at least a few others here as well.
</em><br>
<em>&gt; &gt; &gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;In order to participate directly in a transhuman based Singularity you
</em><br>
<em>&gt; &gt; &gt;would have to be one of the first humans enhanced into transhumanity. How
</em><br>
<em>&gt; &gt; &gt;do you plan to achieve that? Even if you do, the vast majority of humanity
</em><br>
<em>&gt; &gt; &gt;will just be riding your coattails no matter which path occurs first.
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;Secondly, without an AI to guide things, what prevents individuals 
</em><br>
<em>&gt; intra or
</em><br>
<em>&gt; &gt; &gt;post-Singularity from using nanotech or other ultratechnologies in 
</em><br>
<em>&gt; destructive
</em><br>
<em>&gt; &gt; &gt;ways in an anarchic fashion? I'd like to hear a brief but coherent 
</em><br>
<em>&gt; timeline/
</em><br>
<em>&gt; &gt; &gt;description of how you think this would play out. Our argument is that 
</em><br>
<em>&gt; while
</em><br>
<em>&gt; &gt; &gt;it all probably would turn out ok, it would generally be safer to get a
</em><br>
<em>&gt; &gt; &gt;Friendly AI in place first.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Well, personally, I'm still not sold on this whole Friendliness
</em><br>
<em>&gt;
</em><br>
<em>&gt;Care to answer my questions?
</em><br>
<p>Which questions?
<br>
<p>The participate directly one?  Don't care.  I would *like* to participate 
<br>
but if it happens without me and goes smoothly I'll happily ride someone's 
<br>
coattails.
<br>
<p>Destruction / Anarchic?  First, I have nothing against anarchy.  Actually, 
<br>
an anarchy where the individuals treat each other respectfully would be my 
<br>
preference.  As for destructive technologies, nothing.  My personal belief 
<br>
is that either super intelligence will promote friendliness or we're doomed.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1889.html">James Higgins: "RE: Augmenting humans is a better way"</a>
<li><strong>Previous message:</strong> <a href="1887.html">Ben Goertzel: "RE: IQ testing for half-baked AI's"</a>
<li><strong>In reply to:</strong> <a href="1881.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1899.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1899.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="../0108/2045.html">Arona Ndiaye: "Re: Augmenting humans is a better way"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1888">[ date ]</a>
<a href="index.html#1888">[ thread ]</a>
<a href="subject.html#1888">[ subject ]</a>
<a href="author.html#1888">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
