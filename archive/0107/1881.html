<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Augmenting humans is a better way</title>
<meta name="Author" content="Brian Atkins (brian@posthuman.com)">
<meta name="Subject" content="Re: Augmenting humans is a better way">
<meta name="Date" content="2001-07-28">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Augmenting humans is a better way</h1>
<!-- received="Sat Jul 28 16:47:57 2001" -->
<!-- isoreceived="20010728224757" -->
<!-- sent="Sat, 28 Jul 2001 16:47:39 -0400" -->
<!-- isosent="20010728204739" -->
<!-- name="Brian Atkins" -->
<!-- email="brian@posthuman.com" -->
<!-- subject="Re: Augmenting humans is a better way" -->
<!-- id="3B6324EB.4F6EB2AE@posthuman.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="4.3.2.7.2.20010728023348.0217ce78@mail.earthlink.net" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Brian Atkins (<a href="mailto:brian@posthuman.com?Subject=Re:%20Augmenting%20humans%20is%20a%20better%20way"><em>brian@posthuman.com</em></a>)<br>
<strong>Date:</strong> Sat Jul 28 2001 - 14:47:39 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1882.html">Ben Goertzel: "RE: Augmenting humans is a better way"</a>
<li><strong>Previous message:</strong> <a href="1880.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>In reply to:</strong> <a href="1861.html">James Higgins: "Re: Augmenting humans is a better way"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1888.html">James Higgins: "Re: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1888.html">James Higgins: "Re: Augmenting humans is a better way"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1881">[ date ]</a>
<a href="index.html#1881">[ thread ]</a>
<a href="subject.html#1881">[ subject ]</a>
<a href="author.html#1881">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
James Higgins wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; What is the problem is figuring out what exactly will make us smarter
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; and how to integrate that in to our existing brain architecture.  It's
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; not as simple as adding more memory -- there is tons of different types
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; of memory in the brain and they are highly distributed very connected
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; with the computations being preformed.  Also there are a lot of
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; calibration problems that have to be overcome if we would like to be
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; able to recognize meaningful patterns in the brain.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;Exactly, it may well be impossible to come up with a one-size fits all
</em><br>
<em>&gt; &gt;technology for something as uniquely individual as the brain. And what
</em><br>
<em>&gt; &gt;company will take the risks to commercial it if they know that for many
</em><br>
<em>&gt; &gt;people it won't work, or they even risk getting sued? We live in a
</em><br>
<em>&gt; &gt;country where Dow Chemical got sued by women who got breast implants.
</em><br>
<em>&gt; &gt;Will companies really expose themselves to the kinds of risks involved
</em><br>
<em>&gt; &gt;with neural hacking?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Hello?  Sorry, but I just HAVE to point this out.  Did you know that there
</em><br>
<em>&gt; are more countries in the world than the United States?  Personally,
</em><br>
<p>Yes and almost all of them are less advanced when it comes to biological
<br>
and computing sciences. Many of them are close or even equivalent, but
<br>
those same countries are also the ones who will likely be even less
<br>
likely to work on Really Scary Human Augmenting science. Think Europe.
<br>
So if you have to bail out of the USA that is going to extend the
<br>
bio-based Singularity timeline even farther than I am already thinking
<br>
about.
<br>
<p><em>&gt; if/when they come up with implants that offer a significant mental
</em><br>
<em>&gt; advantage and have a low chance of screwing you up I *will* be getting
</em><br>
<em>&gt; one.  I don't care if I have to go to Japan, Europe, Russia, Mexico or
</em><br>
<em>&gt; Chiba City (CyberPunk is my favorite fictional genre).  When it becomes
</em><br>
<em>&gt; possible to do, it will also become possible to get (and without waiting
</em><br>
<em>&gt; for FDA approval)!  Then, assuming these have a significant effect on
</em><br>
<em>&gt; intelligence, the next series will likely be available sooner than might be
</em><br>
<em>&gt; expected (you have to assume the developers are going to use their own
</em><br>
<em>&gt; product).  I also imagine that income for upgraded individuals will
</em><br>
<em>&gt; drastically go up, which will make affording the next upgrade much
</em><br>
<em>&gt; easier.  Which is another reason why I'd want to get on the boat early.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; But, that said, this will still take a very long time.  Possibly much
</em><br>
<em>&gt; longer than the AI path.  However, I will NOT say that the AI path is
</em><br>
<em>&gt; likely to be faster than this path since NO ONE IN THE WHOLE WORLD HAS EVER
</em><br>
<em>&gt; CREATED ANYTHING REMOTELY SIMILIAR TO REAL AI.  And thus it is IMPOSSIBLE
</em><br>
<p>Now you are the one making claims.. for all you know Webmind may very well
<br>
be remotely similar to real AI. In fact you have Ben here making that
<br>
claim. I do not see anyone around claiming to be near to finishing a
<br>
Real Neural Interface. RNIs seem to be around the stage of development
<br>
that AI was back when computers were using vacuum tubes.
<br>
<p>A different way to look at it is this: with the computing power of the
<br>
near future, AI is at the stage now where we can do real scientific
<br>
experimentation. That (being able to really experiment) almost always
<br>
leads to breakthroughs. RNIs are not there yet. I think you will agree
<br>
with me that the AI path /definitely/ seems to be much farther along from
<br>
these two perspectives.
<br>
<p><em>&gt; to estimate if/when we will ever get real AI.  Without incredibly massive
</em><br>
<em>&gt; funding it may take 15-20 years just to build a knowledge base sufficient
</em><br>
<em>&gt; to kick start the thing.  And you can't seriously argue the point because,
</em><br>
<p>Knowledge bases (shouldn't this be one word?) already exist both in natural
<br>
form (the world, the Net) and in prepackaged formats like Cyc. Again, you see
<br>
that AI is farther along in development.
<br>
<p><em>&gt; honestly, you don't know otherwise.  I give very serious credit to Ben
</em><br>
<em>&gt; Goertzel's opinions on AI (keep up the great work) and I doubt he could, in
</em><br>
<em>&gt; all honesty, give any sort of realistic time line for the first Real AI
</em><br>
<em>&gt; (TM).  Thus I don't you, you don't know, we don't know.
</em><br>
<p>He may be unwilling to do so in public, but I can tell you that it
<br>
won't take until 2030 according to rumors I hear...
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; &gt; &gt; Of course, if you can interface one human, then you can do it to a
</em><br>
<em>&gt; &gt; &gt; thousand
</em><br>
<em>&gt; &gt; &gt; &gt; or a billion.   You don't need detailed models of the brain for this kind
</em><br>
<em>&gt; &gt; &gt; of
</em><br>
<em>&gt; &gt; &gt; &gt; thing - at least to start.  You can begin with a &quot;what do you feel when I
</em><br>
<em>&gt; &gt; &gt; do
</em><br>
<em>&gt; &gt; &gt; &gt; this?&quot; kind of thing and once crude dni's are working, things can take
</em><br>
<em>&gt; &gt; &gt; off.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;And so theoretically if you can &quot;interface&quot; a human, what does that get
</em><br>
<em>&gt; &gt;you? Slightly quicker output for typing or controlling machines, maybe
</em><br>
<em>&gt; &gt;slightly quicker input than you could get by reading? Expanded access
</em><br>
<em>&gt; &gt;to memory, but I bet that would be very hard to do. But where does the
</em><br>
<em>&gt; &gt;massive intelligence increase we want come from?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Even self upgrading AI will take many steps to get there.  Same exact
</em><br>
<p>Steps at computer speed, not biological hacking speed. VAST difference.
<br>
<p><em>&gt; thing, just a different route.  No technology is going to just go *blip*
</em><br>
<em>&gt; and produce Singularity.
</em><br>
<p>Actually you cannot say that for certain about AI. We definitely can
<br>
say that about the biological route, at least up till the point we
<br>
get nanotech/inloading. There is nothing to prevent an AI that is
<br>
smart enough from developing a quick route to nanotech and then yes
<br>
*blip* away we go.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; You know, producing the first Real AI may be so difficult that it may just
</em><br>
<em>&gt; require augmented humans to get their in any reasonable amount of
</em><br>
<em>&gt; time.  Have you considered that possible reality?
</em><br>
<p>No I do not see that as a reasonable possibility. Most AI scientists
<br>
will agree that even if we can't design an AI, we can evolve one. By
<br>
brute force if we have to by simply trying all possibile code. It's
<br>
like picking a combination lock, if the lock is openable at all then
<br>
you will eventually open it just by trying all ways. And the rise in
<br>
computing power makes this almost inevitable by 2030 or even earlier.
<br>
<p><em>&gt; 
</em><br>
<em>&gt; &gt; &gt; &gt; the singularity than the imho cringing one proposed by the Institute of
</em><br>
<em>&gt; &gt; &gt; &gt; building an AI and - if everything works out as hoped - maybe humans will
</em><br>
<em>&gt; &gt; &gt; be
</em><br>
<em>&gt; &gt; &gt; &gt; permitted to scale the heights; what I would call the &quot;singularity by
</em><br>
<em>&gt; &gt; &gt; proxy&quot;
</em><br>
<em>&gt; &gt; &gt; &gt; path.  I, for one, intend to participate DIRECTLY in the singularity.  I
</em><br>
<em>&gt; &gt; &gt; &gt; hope there are at least a few others here as well.
</em><br>
<em>&gt; &gt; &gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;In order to participate directly in a transhuman based Singularity you
</em><br>
<em>&gt; &gt;would have to be one of the first humans enhanced into transhumanity. How
</em><br>
<em>&gt; &gt;do you plan to achieve that? Even if you do, the vast majority of humanity
</em><br>
<em>&gt; &gt;will just be riding your coattails no matter which path occurs first.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;Secondly, without an AI to guide things, what prevents individuals intra or
</em><br>
<em>&gt; &gt;post-Singularity from using nanotech or other ultratechnologies in destructive
</em><br>
<em>&gt; &gt;ways in an anarchic fashion? I'd like to hear a brief but coherent timeline/
</em><br>
<em>&gt; &gt;description of how you think this would play out. Our argument is that while
</em><br>
<em>&gt; &gt;it all probably would turn out ok, it would generally be safer to get a
</em><br>
<em>&gt; &gt;Friendly AI in place first.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Well, personally, I'm still not sold on this whole Friendliness
</em><br>
<p>Care to answer my questions?
<br>
<pre>
-- 
Brian Atkins
Director, Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1882.html">Ben Goertzel: "RE: Augmenting humans is a better way"</a>
<li><strong>Previous message:</strong> <a href="1880.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>In reply to:</strong> <a href="1861.html">James Higgins: "Re: Augmenting humans is a better way"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1888.html">James Higgins: "Re: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1888.html">James Higgins: "Re: Augmenting humans is a better way"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1881">[ date ]</a>
<a href="index.html#1881">[ thread ]</a>
<a href="subject.html#1881">[ subject ]</a>
<a href="author.html#1881">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
