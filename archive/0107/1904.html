<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Augmenting humans is a better way</title>
<meta name="Author" content="Ben Houston (ben@exocortex.org)">
<meta name="Subject" content="RE: Augmenting humans is a better way">
<meta name="Date" content="2001-07-28">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Augmenting humans is a better way</h1>
<!-- received="Sat Jul 28 22:54:49 2001" -->
<!-- isoreceived="20010729045449" -->
<!-- sent="Sat, 28 Jul 2001 22:35:00 -0400" -->
<!-- isosent="20010729023500" -->
<!-- name="Ben Houston" -->
<!-- email="ben@exocortex.org" -->
<!-- subject="RE: Augmenting humans is a better way" -->
<!-- id="IPEKIJJJKIMAFKAFMNAEOELODDAA.ben@exocortex.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3B63559E.66AE9E4C@posthuman.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Houston (<a href="mailto:ben@exocortex.org?Subject=RE:%20Augmenting%20humans%20is%20a%20better%20way"><em>ben@exocortex.org</em></a>)<br>
<strong>Date:</strong> Sat Jul 28 2001 - 20:35:00 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1905.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>Previous message:</strong> <a href="1903.html">Ben Goertzel: "RE: human augmentation, putting it into perspective"</a>
<li><strong>In reply to:</strong> <a href="1899.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1905.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1905.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1904">[ date ]</a>
<a href="index.html#1904">[ thread ]</a>
<a href="subject.html#1904">[ subject ]</a>
<a href="author.html#1904">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hi Brian,
<br>
<p><em>&gt;Just because a company may exist in a
</em><br>
<em>&gt;jurisdiction outside of the USA, does not mean that their research and
</em><br>
<em>&gt;development efforts won't be severely impacted by a clampdown on research
</em><br>
<em>&gt;into RNIs in the USA. Do you think IBM will just uproot all those people
</em><br>
<em>&gt;and make them move to Japan?
</em><br>
<p>I agree with this.  The world is becoming more integrated/cooperative at the
<br>
international level and such options are becoming much less viable.
<br>
<p><em>&gt;This seems to be getting away from my point, which is that biologically
</em><br>
<em>&gt;augmenting humans most likely will not enjoy the widespread support and
</em><br>
<em>&gt;resources that the original poster was predicting. It is unlikely in my
</em><br>
<em>&gt;opinion that companies in the USA or Europe will make attempts to
</em><br>
<em>&gt;commercialize such tech, and there is even a chance such products might
</em><br>
<em>&gt;be outlawed the same way that cloning has been in some countries already.
</em><br>
<p>Please understand that cloning was banned because it is currently quite
<br>
unsafe.  Did you know that for each successful cloned animal the researchers
<br>
had to induce hundreds of pregnancies that failed in various ways?  They
<br>
banned it because even though it wasn't safe people were stilling willing to
<br>
try it.
<br>
<p>I expect that non-FDA/FTC approved implants will be banned as well.  Just
<br>
like non-FDA/FTC artificial hearts are currently banned from being implanted
<br>
into humans.
<br>
<p><em>&gt; &gt; &gt; &gt;Exactly, it may well be impossible to come up with a one-size fits
</em><br>
all
<br>
<em>&gt; &gt; &gt; &gt;technology for something as uniquely individual as the brain.
</em><br>
<p>It probably is possible to come up with something that is similar to a
<br>
one-size-fits-all model?  What is your specific argument against such a
<br>
thing?
<br>
<p><em>&gt; &gt; &gt; &gt; And what
</em><br>
<em>&gt; &gt; &gt; &gt;company will take the risks to commercial it if they know that for
</em><br>
many
<br>
<em>&gt; &gt; &gt; &gt;people it won't work, or they even risk getting sued?
</em><br>
<p>Who said that neural implants would have a low probably of working with
<br>
individual patients?  What is your specific argument against such a thing?
<br>
<p><em>&gt; &gt; &gt; &gt;We live in a
</em><br>
<em>&gt; &gt; &gt; &gt;country where Dow Chemical got sued by women who got breast implants.
</em><br>
<em>&gt; &gt; &gt; &gt;Will companies really expose themselves to the kinds of risks
</em><br>
involved
<br>
<em>&gt; &gt; &gt; &gt;with neural hacking?
</em><br>
<p>You forget that overall Dow Chemical made a lot of money and that they did
<br>
make and sell the breast implants in the first place.
<br>
<p><em>&gt; The vast majority of potential users will probably be
</em><br>
<em>&gt;pretty satisfied with external wearable apparatus, and I think this is
</em><br>
<em>&gt;where the real action will be. Many of the things you want can be done
</em><br>
<em>&gt;with wearables- you only need to get access to the internals if you want
</em><br>
<em>&gt;to really try and increase the raw intelligence or speed of thought or
</em><br>
<em>&gt;direct memory capacity.
</em><br>
<p>Access to last three things is the Holy Grail.
<br>
<p><em>&gt;Actually there are some people around here that think they know that. They
</em><br>
<em>&gt;simply haven't proven it yet. This is quite different again than the state
</em><br>
<em>&gt;of progress in RNIs where no one really has any idea yet how to do much at
</em><br>
<em>&gt;all besides linking a few neurons to a computer.
</em><br>
<p>I would posit that you actually have no clue as to what the state of the art
<br>
is.
<br>
<p><em>&gt;No one knows how to
</em><br>
<em>&gt;increase your working memory so that you can remember 50 phone numbers at
</em><br>
<em>&gt;once.
</em><br>
<p>We know where it is instantiated in the brain.  We also know how to
<br>
modifying one's performance although not to the extreme you are talking
<br>
about.
<br>
<p><em>&gt;In fact, reverse engineering the evolved mess that is the brain may
</em><br>
<em>&gt;be very very hard.
</em><br>
<p>It may be hard but there are many well-funded professors and graduate
<br>
students working on it everyday.
<br>
<p><em>&gt;At least machine learning folks have created non-general
</em><br>
<em>&gt;AIs that can excel at specific tasks like chess. Even that puny
</em><br>
accomplishment
<br>
<em>&gt;Is much more than the progress so far in RNIs.
</em><br>
<p>Like I said before you don't seem to know what the current state of the art
<br>
in neural implants is.
<br>
<p><em>&gt;An AI should only be eventually constrained by how much computing power
</em><br>
<em>&gt;it has available. The same will hold for your RNI.
</em><br>
<p>Exactly right.
<br>
<p><em>&gt;How can a RNI that
</em><br>
<em>&gt;is internal to your skull, or at most wearable, possibly match the
</em><br>
<em>&gt;computing power available to an AI?
</em><br>
<p>Who said the bulk on the processing power must be done on person... maybe
<br>
one has an uplink to off person processors?  I don't see any hard limits to
<br>
the processing power available to a human with a neural interface.
<br>
<p><em>&gt;Actually with stuff like Flare we are beginning to see how computing
</em><br>
<em>&gt;power can help developers out. Just like how software helps Intel
</em><br>
<em>&gt;engineers create chip designs, software will eventually help software
</em><br>
<em>&gt;people create code. Actually it already does, but it is a pretty limited
</em><br>
<em>&gt;effect.
</em><br>
<p>The above idea of using computers to help out people out in their chores is
<br>
the basis of the computer revolution.  This includes helping Intel design
<br>
new chips or helping a developer write a new program or me to write this
<br>
email.  It is in no way what so ever a &quot;a pretty limited effect.&quot;
<br>
<p>Cheers,
<br>
-ben houston
<br>
<a href="http://www.exocortex.org/~ben">http://www.exocortex.org/~ben</a>
<br>
<p><p><p>-----Original Message-----
<br>
From: <a href="mailto:owner-sl4@sysopmind.com?Subject=RE:%20Augmenting%20humans%20is%20a%20better%20way">owner-sl4@sysopmind.com</a> [mailto:<a href="mailto:owner-sl4@sysopmind.com?Subject=RE:%20Augmenting%20humans%20is%20a%20better%20way">owner-sl4@sysopmind.com</a>]On Behalf Of
<br>
Brian Atkins
<br>
Sent: Saturday, July 28, 2001 8:15 PM
<br>
To: <a href="mailto:sl4@sysopmind.com?Subject=RE:%20Augmenting%20humans%20is%20a%20better%20way">sl4@sysopmind.com</a>
<br>
Subject: Re: Augmenting humans is a better way
<br>
<p>James Higgins wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; At 04:47 PM 7/28/2001 -0400, you wrote:
</em><br>
<em>&gt; &gt;James Higgins wrote:
</em><br>
<em>&gt; &gt; &gt; &gt;Exactly, it may well be impossible to come up with a one-size fits
</em><br>
all
<br>
<em>&gt; &gt; &gt; &gt;technology for something as uniquely individual as the brain. And
</em><br>
what
<br>
<em>&gt; &gt; &gt; &gt;company will take the risks to commercial it if they know that for
</em><br>
many
<br>
<em>&gt; &gt; &gt; &gt;people it won't work, or they even risk getting sued? We live in a
</em><br>
<em>&gt; &gt; &gt; &gt;country where Dow Chemical got sued by women who got breast implants.
</em><br>
<em>&gt; &gt; &gt; &gt;Will companies really expose themselves to the kinds of risks
</em><br>
involved
<br>
<em>&gt; &gt; &gt; &gt;with neural hacking?
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; Hello?  Sorry, but I just HAVE to point this out.  Did you know that
</em><br>
there
<br>
<em>&gt; &gt; &gt; are more countries in the world than the United States?  Personally,
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;Yes and almost all of them are less advanced when it comes to biological
</em><br>
<em>&gt; &gt;and computing sciences. Many of them are close or even equivalent, but
</em><br>
<em>&gt; &gt;those same countries are also the ones who will likely be even less
</em><br>
<em>&gt; &gt;likely to work on Really Scary Human Augmenting science. Think Europe.
</em><br>
<em>&gt; &gt;So if you have to bail out of the USA that is going to extend the
</em><br>
<em>&gt; &gt;bio-based Singularity timeline even farther than I am already thinking
</em><br>
<em>&gt; &gt;about.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Same companies, different countries.  You can buy medication overseas that
</em><br>
<em>&gt; the FDA has not (or will not) approve for sale in the US.  Multi-national
</em><br>
<em>&gt; corporations make individual countries mostly irrelevant when it comes to
</em><br>
<em>&gt; holding back new technology/advances.
</em><br>
<p>Ok, so how many PhDs does IBM employ in countries outside the USA compared
<br>
to how many it has working here? Just because a company may exist in a
<br>
jurisdiction outside of the USA, does not mean that their research and
<br>
development efforts won't be severely impacted by a clampdown on research
<br>
into RNIs in the USA. Do you think IBM will just uproot all those people
<br>
and make them move to Japan?
<br>
<p>This seems to be getting away from my point, which is that biologically
<br>
augmenting humans most likely will not enjoy the widespread support and
<br>
resources that the original poster was predicting. It is unlikely in my
<br>
opinion that companies in the USA or Europe will make attempts to
<br>
commercialize such tech, and there is even a chance such products might
<br>
be outlawed the same way that cloning has been in some countries already.
<br>
Some countries like Japan might make an attempt, but without support
<br>
of the other countries their progress will be slowed down or may not
<br>
even actually take off if they realize the potential market of users may
<br>
be very small. The vast majority of potential users will probably be
<br>
pretty satisfied with external wearable apparatus, and I think this is
<br>
where the real action will be. Many of the things you want can be done
<br>
with wearables- you only need to get access to the internals if you want
<br>
to really try and increase the raw intelligence or speed of thought or
<br>
direct memory capacity.
<br>
<p><em>&gt;
</em><br>
<em>&gt; &gt; &gt; if/when they come up with implants that offer a significant mental
</em><br>
<em>&gt; &gt; &gt; advantage and have a low chance of screwing you up I *will* be getting
</em><br>
<em>&gt; &gt; &gt; one.  I don't care if I have to go to Japan, Europe, Russia, Mexico or
</em><br>
<em>&gt; &gt; &gt; Chiba City (CyberPunk is my favorite fictional genre).  When it
</em><br>
becomes
<br>
<em>&gt; &gt; &gt; possible to do, it will also become possible to get (and without
</em><br>
waiting
<br>
<em>&gt; &gt; &gt; for FDA approval)!  Then, assuming these have a significant effect on
</em><br>
<em>&gt; &gt; &gt; intelligence, the next series will likely be available sooner than
</em><br>
might be
<br>
<em>&gt; &gt; &gt; expected (you have to assume the developers are going to use their own
</em><br>
<em>&gt; &gt; &gt; product).  I also imagine that income for upgraded individuals will
</em><br>
<em>&gt; &gt; &gt; drastically go up, which will make affording the next upgrade much
</em><br>
<em>&gt; &gt; &gt; easier.  Which is another reason why I'd want to get on the boat
</em><br>
early.
<br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; But, that said, this will still take a very long time.  Possibly much
</em><br>
<em>&gt; &gt; &gt; longer than the AI path.  However, I will NOT say that the AI path is
</em><br>
<em>&gt; &gt; &gt; likely to be faster than this path since NO ONE IN THE WHOLE WORLD HAS
</em><br>
EVER
<br>
<em>&gt; &gt; &gt; CREATED ANYTHING REMOTELY SIMILIAR TO REAL AI.  And thus it is
</em><br>
IMPOSSIBLE
<br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;Now you are the one making claims.. for all you know Webmind may very
</em><br>
well
<br>
<em>&gt; &gt;be remotely similar to real AI. In fact you have Ben here making that
</em><br>
<em>&gt; &gt;claim. I do not see anyone around claiming to be near to finishing a
</em><br>
<em>&gt; &gt;Real Neural Interface. RNIs seem to be around the stage of development
</em><br>
<em>&gt; &gt;that AI was back when computers were using vacuum tubes.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;A different way to look at it is this: with the computing power of the
</em><br>
<em>&gt; &gt;near future, AI is at the stage now where we can do real scientific
</em><br>
<em>&gt; &gt;experimentation. That (being able to really experiment) almost always
</em><br>
<em>&gt; &gt;leads to breakthroughs. RNIs are not there yet. I think you will agree
</em><br>
<em>&gt; &gt;with me that the AI path /definitely/ seems to be much farther along from
</em><br>
<em>&gt; &gt;these two perspectives.
</em><br>
<em>&gt;
</em><br>
<em>&gt; No, I'm specifically NOT making claims.  I'm taking a show me attitude.
</em><br>
<p>You did make a claim regarding the existence of something near real AI.
<br>
And you are using that claim to simultaneously claim that the AI path can
<br>
not be shown to be more likely to succeed first. Have you examined the
<br>
Webmind design and code in detail and determined that it is not remotely
<br>
similar to a real AI? Do you care to address my two points showing how
<br>
much more advanced AI research already is compared to research into real
<br>
neural interfaces?
<br>
<p><em>&gt;
</em><br>
<em>&gt; IF/WHEN they come up with implants that A) make a significant difference
</em><br>
in
<br>
<em>&gt; mental capacity and B) aren't likely to screw up the recipient.  I'm not
</em><br>
<em>&gt; making any claims there.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &quot;When it becomes possible to do, it will also become possible to get&quot;.  If
</em><br>
<em>&gt; the time is taken to design such an implant, it will become available in
</em><br>
<em>&gt; one fashion or another.  With enough money you can even go buy a nuclear
</em><br>
<em>&gt; weapon, so you will be able to buy implants once they have been designed.
</em><br>
<p>I am not disputing that of course.
<br>
<p><em>&gt;
</em><br>
<em>&gt; If I had an implant that significantly enhanced my mental ability, I feel
</em><br>
<em>&gt; confidant that I could negotiate for much better pay.  I'm already quite
</em><br>
<em>&gt; good at this anyway.
</em><br>
<em>&gt;
</em><br>
<em>&gt; As for Real AI, when someone gets one working then we can talk.  The fact
</em><br>
<em>&gt; is that no one knows what Real AI is going to require.  I also think Ben
</em><br>
is
<br>
<p>Actually there are some people around here that think they know that. They
<br>
simply haven't proven it yet. This is quite different again than the state
<br>
of progress in RNIs where no one really has any idea yet how to do much at
<br>
all besides linking a few neurons to a computer. No one knows how to
<br>
increase your working memory so that you can remember 50 phone numbers at
<br>
once. In fact, reverse engineering the evolved mess that is the brain may
<br>
be very very hard. At least machine learning folks have created non-general
<br>
AIs that can excel at specific tasks like chess. Even that puny
<br>
accomplishment
<br>
is much more than the progress so far in RNIs.
<br>
<p><em>&gt; doing a great job and is probably the most likely (that I know of anyway)
</em><br>
<em>&gt; to succeed.  However, no one can predict with any credibility that he will
</em><br>
<em>&gt; succeed.  I like to think he will and I would bet that he would also.
</em><br>
<p>Well it has already been shown to be able to learn and accomplish certain
<br>
specific tasks such as stock market prediction. Again, more progress than
<br>
in RNIs. When do you think we'll have a RNI that increases your IQ to 300?
<br>
And where do you think AI research will be by then? It'll probably have
<br>
already succeeded is the answer.
<br>
<p><em>&gt;
</em><br>
<em>&gt; &gt; &gt; to estimate if/when we will ever get real AI.  Without incredibly
</em><br>
massive
<br>
<em>&gt; &gt; &gt; funding it may take 15-20 years just to build a knowledge base
</em><br>
sufficient
<br>
<em>&gt; &gt; &gt; to kick start the thing.  And you can't seriously argue the point
</em><br>
because,
<br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;Knowledge bases (shouldn't this be one word?) already exist both in
</em><br>
natural
<br>
<em>&gt; &gt;form (the world, the Net) and in prepackaged formats like Cyc. Again, you
</em><br>
see
<br>
<em>&gt; &gt;that AI is farther along in development.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Yes, they exist.  Are they of the correct form?  Do they contain
</em><br>
sufficient
<br>
<em>&gt; knowledge?
</em><br>
<p>Between the existing bases, the Net, and the potential to interact with
<br>
the real world, I don't see any lack of information. This is an
<br>
uninteresting
<br>
issue- if a human kid can learn then so can a properly done AI.
<br>
<p><em>&gt;
</em><br>
<em>&gt; &gt; &gt; honestly, you don't know otherwise.  I give very serious credit to Ben
</em><br>
<em>&gt; &gt; &gt; Goertzel's opinions on AI (keep up the great work) and I doubt he
</em><br>
could, in
<br>
<em>&gt; &gt; &gt; all honesty, give any sort of realistic time line for the first Real
</em><br>
AI
<br>
<em>&gt; &gt; &gt; (TM).  Thus I don't you, you don't know, we don't know.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;He may be unwilling to do so in public, but I can tell you that it
</em><br>
<em>&gt; &gt;won't take until 2030 according to rumors I hear...
</em><br>
<em>&gt;
</em><br>
<em>&gt; Certainly the hardware will be available before then (there is a strong
</em><br>
<em>&gt; track record to predict that on).  But there is no track record to predict
</em><br>
<em>&gt; Real AI.  In order to make predictions on how long it will take to
</em><br>
<em>&gt; understand it.  We don't understand Real AI yet.  I could just as easily
</em><br>
<em>&gt; say we will break the barrier for traveling faster than the speed of light
</em><br>
<em>&gt; by 2050, but that also requires knowledge that we don't yet have and thus
</em><br>
<em>&gt; we can not predict this.
</em><br>
<em>&gt;
</em><br>
<em>&gt; So everyone agrees that 2030 is the outside estimate, but that is just a
</em><br>
<em>&gt; hopeful guess (that I also share, BTW).
</em><br>
<p>If we put 2010 and 2030 as the outside dates then the most probable time
<br>
is 2020? Do you think we'll have RNIs by then?
<br>
<p><em>&gt;
</em><br>
<em>&gt; &gt; &gt; Even self upgrading AI will take many steps to get there.  Same exact
</em><br>
<em>&gt; &gt; &gt; thing, just a different route.  No technology is going to just go
</em><br>
*blip*
<br>
<em>&gt; &gt; &gt; and produce Singularity.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;Steps at computer speed, not biological hacking speed. VAST difference.
</em><br>
<em>&gt;
</em><br>
<em>&gt; You're probably correct, but they both require steps.  And no one knows
</em><br>
for
<br>
<em>&gt; certain, maybe an advanced biological implant would allow for
</em><br>
reprogramming
<br>
<em>&gt; &amp; expendability, which could put both on similar terms.
</em><br>
<p>An AI should only be eventually constrained by how much computing power
<br>
it has available. The same will hold for your RNI. How can a RNI that
<br>
is internal to your skull, or at most wearable, possibly match the
<br>
computing power available to an AI? No matter what computing substrate
<br>
you use the physical space constraint on the RNI will limit it. The only
<br>
way a human could compete with an AI would be for the human to upload.
<br>
<p><em>&gt;
</em><br>
<p>(regarding a very quick Singularity)
<br>
<p><em>&gt; &gt;Actually you cannot say that for certain about AI. We definitely can
</em><br>
<em>&gt; &gt;say that about the biological route, at least up till the point we
</em><br>
<em>&gt; &gt;get nanotech/inloading. There is nothing to prevent an AI that is
</em><br>
<em>&gt; &gt;smart enough from developing a quick route to nanotech and then yes
</em><br>
<em>&gt; &gt;*blip* away we go.
</em><br>
<em>&gt;
</em><br>
<em>&gt; But it will most likely take many steps to get to that point, especially
</em><br>
<em>&gt; based on Eli's Seed AI.
</em><br>
<p>Ok, but you will agree that in a SI vs. somewhat augmented humans match,
<br>
the SI can get the Singularity done quicker, probably extremely quickly
<br>
by whipping up some very advanced replicating nanotech hardware. The
<br>
only real question is how long it takes to achieve SIness.
<br>
<p><em>&gt;
</em><br>
<em>&gt; &gt; &gt; You know, producing the first Real AI may be so difficult that it may
</em><br>
just
<br>
<em>&gt; &gt; &gt; require augmented humans to get their in any reasonable amount of
</em><br>
<em>&gt; &gt; &gt; time.  Have you considered that possible reality?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;No I do not see that as a reasonable possibility. Most AI scientists
</em><br>
<em>&gt; &gt;will agree that even if we can't design an AI, we can evolve one. By
</em><br>
<em>&gt; &gt;brute force if we have to by simply trying all possibile code. It's
</em><br>
<em>&gt; &gt;like picking a combination lock, if the lock is openable at all then
</em><br>
<em>&gt; &gt;you will eventually open it just by trying all ways. And the rise in
</em><br>
<em>&gt; &gt;computing power makes this almost inevitable by 2030 or even earlier.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Don't agree, especially after your argument.  Trying &quot;all possible code&quot;
</em><br>
<em>&gt; would take a very, very long time.  Unless a significant percentage of
</em><br>
<em>&gt; available resources were devoted to this it could easily exceed
</em><br>
<em>&gt; 2030.  Computing power does you no good when it comes to software
</em><br>
<p>Okay I'll give you 2040 max. Actually I misread your original message
<br>
and didn't the &quot;in a reasonable time&quot; part. But anyway, such a search
<br>
is very unlikely to be needed.
<br>
<p><em>&gt; development, a computer that runs 10 times faster has almost no effect on
</em><br>
<em>&gt; the speed of the developer.  Nural implants could, on the other hand, have
</em><br>
<em>&gt; incredible impact on the speed of developers as maybe they could think
</em><br>
code
<br>
<em>&gt; instead of typing it.  I'm not saying that this is going to be necessary,
</em><br>
<em>&gt; but it would definitely be helpful and may be necessary in order to keep
</em><br>
<em>&gt; the proposed time line.
</em><br>
<p>Actually with stuff like Flare we are beginning to see how computing
<br>
power can help developers out. Just like how software helps Intel
<br>
engineers create chip designs, software will eventually help software
<br>
people create code. Actually it already does, but it is a pretty limited
<br>
effect.
<br>
<p>I don't buy the argument that there is a major difference between the
<br>
speed we think and type. I know when I'm coding I spend MOST of the
<br>
time simply thinking about what to type next. And I was always the
<br>
fastest/most productive coder wherever I worked... if it was the case
<br>
that typing speeds were what was holding software creation back, you
<br>
could simply throw more developers at a project and it would get done
<br>
faster. Or hire professional typists and let the programmers talk really
<br>
fast :-)
<br>
<p><em>&gt;
</em><br>
<em>&gt; Plus, it might be much more likely for enhanced humans to get friendliness
</em><br>
<em>&gt; right the first time.
</em><br>
<p>If their IQ was higher then I agree. If they simply are faster typists
<br>
then I disagree. However, as you see above I don't think we'll have a
<br>
bunch of super high IQ people available until after 2030, which is too
<br>
late to have any effect. Furthermore if we do get to super high IQ
<br>
people before we get AI, then you run into the problem of worrying about
<br>
what else the high IQ folks will do with that brainpower, especially
<br>
if the brainpower becomes somewhat widespread. See below...
<br>
<p><em>&gt;
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; &gt; the singularity than the imho cringing one proposed by the
</em><br>
<em>&gt; &gt; Institute of
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; &gt; building an AI and - if everything works out as hoped - maybe
</em><br>
<em>&gt; &gt; humans will
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; be
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; &gt; permitted to scale the heights; what I would call the
</em><br>
&quot;singularity by
<br>
<em>&gt; &gt; &gt; &gt; &gt; proxy&quot;
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; &gt; path.  I, for one, intend to participate DIRECTLY in the
</em><br>
<em>&gt; &gt; singularity.  I
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; &gt; hope there are at least a few others here as well.
</em><br>
<em>&gt; &gt; &gt; &gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; &gt;In order to participate directly in a transhuman based Singularity
</em><br>
you
<br>
<em>&gt; &gt; &gt; &gt;would have to be one of the first humans enhanced into transhumanity.
</em><br>
How
<br>
<em>&gt; &gt; &gt; &gt;do you plan to achieve that? Even if you do, the vast majority of
</em><br>
humanity
<br>
<em>&gt; &gt; &gt; &gt;will just be riding your coattails no matter which path occurs first.
</em><br>
<em>&gt; &gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; &gt;Secondly, without an AI to guide things, what prevents individuals
</em><br>
<em>&gt; &gt; intra or
</em><br>
<em>&gt; &gt; &gt; &gt;post-Singularity from using nanotech or other ultratechnologies in
</em><br>
<em>&gt; &gt; destructive
</em><br>
<em>&gt; &gt; &gt; &gt;ways in an anarchic fashion? I'd like to hear a brief but coherent
</em><br>
<em>&gt; &gt; timeline/
</em><br>
<em>&gt; &gt; &gt; &gt;description of how you think this would play out. Our argument is
</em><br>
that
<br>
<em>&gt; &gt; while
</em><br>
<em>&gt; &gt; &gt; &gt;it all probably would turn out ok, it would generally be safer to get
</em><br>
a
<br>
<em>&gt; &gt; &gt; &gt;Friendly AI in place first.
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; Well, personally, I'm still not sold on this whole Friendliness
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;Care to answer my questions?
</em><br>
<em>&gt;
</em><br>
<em>&gt; Which questions?
</em><br>
<em>&gt;
</em><br>
<em>&gt; The participate directly one?  Don't care.  I would *like* to participate
</em><br>
<em>&gt; but if it happens without me and goes smoothly I'll happily ride someone's
</em><br>
<em>&gt; coattails.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Destruction / Anarchic?  First, I have nothing against anarchy.  Actually,
</em><br>
<em>&gt; an anarchy where the individuals treat each other respectfully would be my
</em><br>
<em>&gt; preference.  As for destructive technologies, nothing.  My personal belief
</em><br>
<em>&gt; is that either super intelligence will promote friendliness or we're
</em><br>
doomed.
<br>
<p>Sure that'd be great if everyone treated everyone perfectly. But in my
<br>
experience you are smoking crack if you think that is realistic. In a
<br>
world without a Sysop, how can that possibly last? If you're worried
<br>
that one very well tested AI can go wrong, I'm worried that 6 billion
<br>
uploaded humans just might have a few bad apples for whom access to IQ-
<br>
enhancing technologies just might enable to do very bad things with
<br>
very advanced technologies that quite possibly are much more difficult
<br>
to defend against than to use offensively. How do you prevent that from
<br>
happening?
<br>
<p>Finally, if you think SI (whether AI or human-based) is all we need,
<br>
then why the bias of wanting human-based ones instead of AI first?
<br>
<pre>
--
Brian Atkins
Director, Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1905.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>Previous message:</strong> <a href="1903.html">Ben Goertzel: "RE: human augmentation, putting it into perspective"</a>
<li><strong>In reply to:</strong> <a href="1899.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1905.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1905.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1904">[ date ]</a>
<a href="index.html#1904">[ thread ]</a>
<a href="subject.html#1904">[ subject ]</a>
<a href="author.html#1904">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
