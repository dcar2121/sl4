<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Augmenting humans is a better way</title>
<meta name="Author" content="James Higgins (jameshiggins@earthlink.net)">
<meta name="Subject" content="Re: Augmenting humans is a better way">
<meta name="Date" content="2001-07-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Augmenting humans is a better way</h1>
<!-- received="Sun Jul 29 13:02:28 2001" -->
<!-- isoreceived="20010729190228" -->
<!-- sent="Sun, 29 Jul 2001 01:20:48 -0700" -->
<!-- isosent="20010729082048" -->
<!-- name="James Higgins" -->
<!-- email="jameshiggins@earthlink.net" -->
<!-- subject="Re: Augmenting humans is a better way" -->
<!-- id="4.3.2.7.2.20010729004536.020fa500@mail.earthlink.net" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3B63559E.66AE9E4C@posthuman.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> James Higgins (<a href="mailto:jameshiggins@earthlink.net?Subject=Re:%20Augmenting%20humans%20is%20a%20better%20way"><em>jameshiggins@earthlink.net</em></a>)<br>
<strong>Date:</strong> Sun Jul 29 2001 - 02:20:48 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1907.html">James Higgins: "Re: Augmenting humans is a better way"</a>
<li><strong>Previous message:</strong> <a href="1905.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>In reply to:</strong> <a href="1899.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1908.html">Ben Goertzel: "RE: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1908.html">Ben Goertzel: "RE: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1917.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="../0108/2044.html">Arona Ndiaye: "Re: Augmenting humans is a better way"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1906">[ date ]</a>
<a href="index.html#1906">[ thread ]</a>
<a href="subject.html#1906">[ subject ]</a>
<a href="author.html#1906">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
At 08:15 PM 7/28/2001 -0400, Brian Atkins wrote:
<br>
<em>&gt; &gt; &gt;Now you are the one making claims.. for all you know Webmind may very well
</em><br>
<em>&gt; &gt; &gt;be remotely similar to real AI. In fact you have Ben here making that
</em><br>
<em>&gt; &gt; &gt;claim. I do not see anyone around claiming to be near to finishing a
</em><br>
<em>&gt; &gt; &gt;Real Neural Interface. RNIs seem to be around the stage of development
</em><br>
<em>&gt; &gt; &gt;that AI was back when computers were using vacuum tubes.
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt;A different way to look at it is this: with the computing power of the
</em><br>
<em>&gt; &gt; &gt;near future, AI is at the stage now where we can do real scientific
</em><br>
<em>&gt; &gt; &gt;experimentation. That (being able to really experiment) almost always
</em><br>
<em>&gt; &gt; &gt;leads to breakthroughs. RNIs are not there yet. I think you will agree
</em><br>
<em>&gt; &gt; &gt;with me that the AI path /definitely/ seems to be much farther along from
</em><br>
<em>&gt; &gt; &gt;these two perspectives.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; No, I'm specifically NOT making claims.  I'm taking a show me attitude.
</em><br>
<em>&gt;
</em><br>
<em>&gt;You did make a claim regarding the existence of something near real AI.
</em><br>
<em>&gt;And you are using that claim to simultaneously claim that the AI path can
</em><br>
<em>&gt;not be shown to be more likely to succeed first. Have you examined the
</em><br>
<em>&gt;Webmind design and code in detail and determined that it is not remotely
</em><br>
<em>&gt;similar to a real AI? Do you care to address my two points showing how
</em><br>
<em>&gt;much more advanced AI research already is compared to research into real
</em><br>
<em>&gt;neural interfaces?
</em><br>
<p>I don't have to examine the Webmind design or code because no one can in 
<br>
fact define exactly what Real AI is.  You can't compare to something that 
<br>
has no definition!  That's my point.  We don't have any idea of what Real 
<br>
AI looks like, and as such can't make any accurate statements about how to 
<br>
create one much less how long that will take.
<br>
<p>I know that researchers have been able to interface devices with the 
<br>
nervous system.  There is a vision system that can take a camera image and 
<br>
directly stimulates the optic nerve to produce rudimentary vision in some 
<br>
blind people.  Thus giving blind people real-time vision (albeit of a very 
<br>
low resolution currently).  So we can say that their has been success in 
<br>
neural interfaces.  On the other hand, as far as I know, no one has ever 
<br>
created a working general AI of any order.  Webmind/Biomind may be the most 
<br>
advanced in that field but if I remember correctly they have never run the 
<br>
system as a whole.  So I'd be tempted to say that, at the moment, research 
<br>
into neural interfaces seems further along than research into AI.
<br>
<p><em>&gt; &gt; Certainly the hardware will be available before then (there is a strong
</em><br>
<em>&gt; &gt; track record to predict that on).  But there is no track record to predict
</em><br>
<em>&gt; &gt; Real AI.  In order to make predictions on how long it will take to
</em><br>
<em>&gt; &gt; understand it.  We don't understand Real AI yet.  I could just as easily
</em><br>
<em>&gt; &gt; say we will break the barrier for traveling faster than the speed of light
</em><br>
<em>&gt; &gt; by 2050, but that also requires knowledge that we don't yet have and thus
</em><br>
<em>&gt; &gt; we can not predict this.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; So everyone agrees that 2030 is the outside estimate, but that is just a
</em><br>
<em>&gt; &gt; hopeful guess (that I also share, BTW).
</em><br>
<em>&gt;
</em><br>
<em>&gt;If we put 2010 and 2030 as the outside dates then the most probable time
</em><br>
<em>&gt;is 2020? Do you think we'll have RNIs by then?
</em><br>
<p>I'm arguing that we don't have any clue if we'll have RNIs OR AI by 
<br>
then!  All of these dates are just dreams at present, compelling dreams, 
<br>
but still dreams.
<br>
<p><em>&gt; &gt; You're probably correct, but they both require steps.  And no one knows for
</em><br>
<em>&gt; &gt; certain, maybe an advanced biological implant would allow for reprogramming
</em><br>
<em>&gt; &gt; &amp; expendability, which could put both on similar terms.
</em><br>
<em>&gt;
</em><br>
<em>&gt;An AI should only be eventually constrained by how much computing power
</em><br>
<em>&gt;it has available. The same will hold for your RNI. How can a RNI that
</em><br>
<em>&gt;is internal to your skull, or at most wearable, possibly match the
</em><br>
<em>&gt;computing power available to an AI? No matter what computing substrate
</em><br>
<em>&gt;you use the physical space constraint on the RNI will limit it. The only
</em><br>
<em>&gt;way a human could compete with an AI would be for the human to upload.
</em><br>
<p>Impossible to answer for certain.  If the implant could be connected to 
<br>
massive computing power via broadband wireless.  This *may* impose a slight 
<br>
delay compared to that of an AI, but then again this solution includes the 
<br>
human mind with all of its assets and capabilities.  At the far extreme of 
<br>
AI (getting near the Singularity) your probably right about the 
<br>
upload.  But an augmented human would be able to communicate with, plan for 
<br>
and participate in the final stages of an AI singularity a hell of a lot 
<br>
better than we can currently.
<br>
<p><em>&gt; &gt; But it will most likely take many steps to get to that point, especially
</em><br>
<em>&gt; &gt; based on Eli's Seed AI.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Ok, but you will agree that in a SI vs. somewhat augmented humans match,
</em><br>
<em>&gt;the SI can get the Singularity done quicker, probably extremely quickly
</em><br>
<em>&gt;by whipping up some very advanced replicating nanotech hardware. The
</em><br>
<em>&gt;only real question is how long it takes to achieve SIness.
</em><br>
<p>Given a fully functioning General AI, the availability of strong nanotech, 
<br>
and that this AI has access to nanotech (I find this VERY unlikely), then 
<br>
yes.  But what fool is going to give a seed AI access to nanotech?  And 
<br>
this still requires a functioning General AI that we still have no idea how 
<br>
to build.
<br>
<p><em>&gt; &gt; development, a computer that runs 10 times faster has almost no effect on
</em><br>
<em>&gt; &gt; the speed of the developer.  Nural implants could, on the other hand, have
</em><br>
<em>&gt; &gt; incredible impact on the speed of developers as maybe they could think code
</em><br>
<em>&gt; &gt; instead of typing it.  I'm not saying that this is going to be necessary,
</em><br>
<em>&gt; &gt; but it would definitely be helpful and may be necessary in order to keep
</em><br>
<em>&gt; &gt; the proposed time line.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Actually with stuff like Flare we are beginning to see how computing
</em><br>
<em>&gt;power can help developers out. Just like how software helps Intel
</em><br>
<em>&gt;engineers create chip designs, software will eventually help software
</em><br>
<em>&gt;people create code. Actually it already does, but it is a pretty limited
</em><br>
<em>&gt;effect.
</em><br>
<p>Don't get me started on Flare.  That is going to take a long time and a 
<br>
huge amount of effort.  Great idea, but I doubt it will get the necessary 
<br>
resources.
<br>
<p><em>&gt;I don't buy the argument that there is a major difference between the
</em><br>
<em>&gt;speed we think and type. I know when I'm coding I spend MOST of the
</em><br>
<em>&gt;time simply thinking about what to type next. And I was always the
</em><br>
<em>&gt;fastest/most productive coder wherever I worked... if it was the case
</em><br>
<em>&gt;that typing speeds were what was holding software creation back, you
</em><br>
<em>&gt;could simply throw more developers at a project and it would get done
</em><br>
<em>&gt;faster. Or hire professional typists and let the programmers talk really
</em><br>
<em>&gt;fast :-)
</em><br>
<p>More developers = longer development cycle.  It is a myth that adding 
<br>
developers speeds up development!  A professional typist would get in the 
<br>
way, try using voice recognition (even good ones) for coding some time.
<br>
<p>Personally, I can code at least as fast as I can type.  If I could type 
<br>
faster (85 wpm last time I checked) I'm fairly certain I could code 
<br>
faster.  But I am admittedly and oddity.  I once personally produced some 
<br>
350,000+ lines of working, clean &amp; (mostly) reusable code in a single year 
<br>
(while gathering requirements, doing architectural design &amp; technical 
<br>
management).  Maybe this is why *I* think a neural interface would be so 
<br>
darn helpful (because I want one now)!
<br>
<p><em>&gt; &gt; &gt;Care to answer my questions?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Which questions?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; The participate directly one?  Don't care.  I would *like* to participate
</em><br>
<em>&gt; &gt; but if it happens without me and goes smoothly I'll happily ride someone's
</em><br>
<em>&gt; &gt; coattails.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Destruction / Anarchic?  First, I have nothing against anarchy.  Actually,
</em><br>
<em>&gt; &gt; an anarchy where the individuals treat each other respectfully would be my
</em><br>
<em>&gt; &gt; preference.  As for destructive technologies, nothing.  My personal belief
</em><br>
<em>&gt; &gt; is that either super intelligence will promote friendliness or we're 
</em><br>
<em>&gt; doomed.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Sure that'd be great if everyone treated everyone perfectly. But in my
</em><br>
<em>&gt;experience you are smoking crack if you think that is realistic. In a
</em><br>
<em>&gt;world without a Sysop, how can that possibly last? If you're worried
</em><br>
<em>&gt;that one very well tested AI can go wrong, I'm worried that 6 billion
</em><br>
<em>&gt;uploaded humans just might have a few bad apples for whom access to IQ-
</em><br>
<em>&gt;enhancing technologies just might enable to do very bad things with
</em><br>
<em>&gt;very advanced technologies that quite possibly are much more difficult
</em><br>
<em>&gt;to defend against than to use offensively. How do you prevent that from
</em><br>
<em>&gt;happening?
</em><br>
<p>I don't worry about it.  If/when I ever do upload do you really think I 
<br>
plan to stick around here?  I'm building myself a fleet of ships, cloning 
<br>
myself a few dozen times and heading off in all directions to see the 
<br>
galaxy!  Maybe I'll even run into myself again down the road, that would be 
<br>
interesting...
<br>
<p><p><em>&gt;Finally, if you think SI (whether AI or human-based) is all we need,
</em><br>
<em>&gt;then why the bias of wanting human-based ones instead of AI first?
</em><br>
<p>I'm not biased!  I'm simply trying to state that we don't have any real, 
<br>
honest estimation of when we'll get either neural implants or general 
<br>
AI.  I might, personally slightly prefer the human path due to my end goals 
<br>
and my concern over the Sysop.  But any path that truly works and ends with 
<br>
myself + wife + friends uploading into a reasonable, non-restrictive 
<br>
environment is fine by me!
<br>
<p>James Higgins
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1907.html">James Higgins: "Re: Augmenting humans is a better way"</a>
<li><strong>Previous message:</strong> <a href="1905.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>In reply to:</strong> <a href="1899.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1908.html">Ben Goertzel: "RE: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1908.html">Ben Goertzel: "RE: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="1917.html">Brian Atkins: "Re: Augmenting humans is a better way"</a>
<li><strong>Reply:</strong> <a href="../0108/2044.html">Arona Ndiaye: "Re: Augmenting humans is a better way"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1906">[ date ]</a>
<a href="index.html#1906">[ thread ]</a>
<a href="subject.html#1906">[ subject ]</a>
<a href="author.html#1906">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
