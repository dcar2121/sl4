<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: [SL4] Employment vs. Singularity</title>
<meta name="Author" content="Samantha Atkins (samantha@objectent.com)">
<meta name="Subject" content="Re: [SL4] Employment vs. Singularity">
<meta name="Date" content="2000-08-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: [SL4] Employment vs. Singularity</h1>
<!-- received="Wed Aug 23 02:53:49 2000" -->
<!-- isoreceived="20000823085349" -->
<!-- sent="Tue, 22 Aug 2000 23:36:12 +0800" -->
<!-- isosent="20000822153612" -->
<!-- name="Samantha Atkins" -->
<!-- email="samantha@objectent.com" -->
<!-- subject="Re: [SL4] Employment vs. Singularity" -->
<!-- id="39A29DEC.13D13457@objectent.com" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="39A0CF0A.81E549A9@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Samantha Atkins (<a href="mailto:samantha@objectent.com?Subject=Re:%20[SL4]%20Employment%20vs.%20Singularity"><em>samantha@objectent.com</em></a>)<br>
<strong>Date:</strong> Tue Aug 22 2000 - 09:36:12 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="../0009/0052.html">Eliezer S. Yudkowsky: "[SL4] META: SL4 list about to move!"</a>
<li><strong>Previous message:</strong> <a href="0050.html">Samantha Atkins: "Re: [SL4] Employment vs. Singularity"</a>
<li><strong>In reply to:</strong> <a href="0046.html">Eliezer S. Yudkowsky: "Re: [SL4] Employment vs. Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0047.html">Brian Atkins: "Re: [SL4] Employment vs. Singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#51">[ date ]</a>
<a href="index.html#51">[ thread ]</a>
<a href="subject.html#51">[ subject ]</a>
<a href="author.html#51">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<body>
<tt>
&quot;Eliezer S. Yudkowsky&quot; wrote:<BR>
&gt; <BR>
&gt; Samantha wrote:<BR>
&gt; &gt;<BR>
&gt; &gt; If, just as a for instance I don't know how to get to, if every person<BR>
&gt; &gt; had a decent living wage and all the physical necessities taken care of<BR>
&gt; &gt; (a la cheap nano-tech matter assemblers for instance), then every person<BR>
&gt; &gt; can be quite busily employed - doing exactly what they themselves find<BR>
&gt; &gt; most meaningful and interesting regardless of whether they are getting a<BR>
&gt; &gt; conventional paycheck for it.&nbsp; Personally I would have a hell of a lot<BR>
&gt; &gt; more to do than watching TV if I no longer had to work for someone else<BR>
&gt; &gt; for a living.&nbsp; I have more things to do and explore and work on than I<BR>
&gt; &gt; could finish in a hundred lifetimes of such 'pointless empty leisure'.<BR>
&gt; <BR>
&gt; How about if everyone who wished was uploaded and had a decent amount of<BR>
&gt; computing power - at least a billion trillion brainpower, say?<BR>
&gt; <BR>
<BR>
YEAH.&nbsp; That's what I'm talking about!&nbsp; Heading out toward unlimited<BR>
where bean-counting and chasing of dollars makes utterly no sense.&nbsp; And<BR>
some of that senselessness may be in the way of us getting there quickly<BR>
enough.<BR>
<BR>
Sign me up!<BR>
<BR>
&gt; This scenario is basically the minimum SingInst is aiming for.&nbsp; With<BR>
&gt; luck, we won't see any major effects on the economy from any prehuman<BR>
&gt; AIs that reach the market before this point.&nbsp; (With less luck, there are<BR>
&gt; a few economic tweaks that could stabilize things; but that whole<BR>
&gt; scenario can ideally be avoided.)<BR>
&gt;<BR>
<BR>
Interesting.&nbsp; What do you mean to designate as &quot;prehuman AI&quot;? <BR>
Pre-augmented human AI?&nbsp; What do you believe is essential in stabilizing<BR>
the economy and what can and should change and why?<BR>
<BR>
 <BR>
&gt; You seem to be visualizing a slow, gradual, planetwide scenario.&nbsp; The<BR>
&gt; Slow Singularity model has all kinds of potential for ultratech<BR>
&gt; disaster, which is one reason why the SingInst model consists of one AI<BR>
&gt; in a research lab reaching the point of true self-enhancement and taking<BR>
&gt; off from there.&nbsp; The marketable AIs before that point will hopefully be<BR>
&gt; too dumb to have any major effect on the economy.<BR>
&gt;<BR>
<BR>
Not particularly slow but definitely having a few stages quite<BR>
noticeably different from now before we get to the full SingInst model. <BR>
I hope there are a few stages along the way for the simple reason that<BR>
even pro-Singularity people are not imho generally well equipped for<BR>
such a leap in a single go.&nbsp; On the other hand, my time grows shorter<BR>
daily and I am quite anxious to be on&nbsp; with it. <BR>
<BR>
I do not believe in a single AI in a research lab being a viable model. <BR>
No matter how brilliant any one team is I don't for an instance believe<BR>
they can go the whole way.&nbsp; Nor do I believe that one and only one such<BR>
AI is remotely likely or desirable.&nbsp; I don't think you can get there in<BR>
one jump even in the AI world (perhaps especially in the AI world).&nbsp; I<BR>
think you will need an interacting mass of AIs bumping up against the<BR>
world, us and each other before they bloom into full AI power.&nbsp;&nbsp;&nbsp; And I<BR>
think several of the self-enhancement capabilities will grow out of<BR>
things needed in the economic sphere.&nbsp; For instance, I think<BR>
self-modifying, self-improving and self-writing software will grow<BR>
fairly directly out of the dearth of programming skills and the<BR>
increasing complexity and criticality of our software systems.&nbsp; <BR>
<BR>
&gt; About the friendly AI thing:&nbsp; Complex issue; we think we know how to<BR>
&gt; handle it; no, it doesn't involve Asimov Laws or gratitude to creators<BR>
&gt; or anything else anthropomorphic; yes, given everything we know about,<BR>
&gt; it should work; no, success isn't certain; yes, we're pretty sure the AI<BR>
&gt; scenario offers the best available probability of survival for the human<BR>
&gt; race.<BR>
<BR>
Is the AI the cosmic guardian and caretaker or do we become one with it<BR>
or do we become it or some mixture of these and other possibilities?&nbsp; <BR>
<BR>
- samantha<BR>
</tt>


<!-- |**|begin egp html banner|**| -->

<hr>
<!-- |@|begin eGroups banner|@| runid: 8132 crid: 4100 -->
<a target="_blank" href="http://click.egroups.com/1/8132/12/_/626675/_/967012730/"><center>
<img width="468" height="60"
  border="0"
  alt="Don't just travel. Travel right."
  src="http://adimg.egroups.com/img/8132/12/_/626675/_/967012730/direct"></center><center><font color="black"></font></center></a>
<!-- |@|end eGroups banner|@| -->
<hr>

<!-- |**|end egp html banner|**| -->



</body>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="../0009/0052.html">Eliezer S. Yudkowsky: "[SL4] META: SL4 list about to move!"</a>
<li><strong>Previous message:</strong> <a href="0050.html">Samantha Atkins: "Re: [SL4] Employment vs. Singularity"</a>
<li><strong>In reply to:</strong> <a href="0046.html">Eliezer S. Yudkowsky: "Re: [SL4] Employment vs. Singularity"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="0047.html">Brian Atkins: "Re: [SL4] Employment vs. Singularity"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#51">[ date ]</a>
<a href="index.html#51">[ thread ]</a>
<a href="subject.html#51">[ subject ]</a>
<a href="author.html#51">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:35 MDT
</em></small></p>
</body>
</html>
