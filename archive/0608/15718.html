<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: A study comparing 150 IQ+ persons to 180 IQ+ persons</title>
<meta name="Author" content="Michael Vassar (michaelvassar@hotmail.com)">
<meta name="Subject" content="Re: A study comparing 150 IQ+ persons to 180 IQ+ persons">
<meta name="Date" content="2006-08-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: A study comparing 150 IQ+ persons to 180 IQ+ persons</h1>
<!-- received="Wed Aug 23 09:00:04 2006" -->
<!-- isoreceived="20060823150004" -->
<!-- sent="Wed, 23 Aug 2006 10:59:16 -0400" -->
<!-- isosent="20060823145916" -->
<!-- name="Michael Vassar" -->
<!-- email="michaelvassar@hotmail.com" -->
<!-- subject="Re: A study comparing 150 IQ+ persons to 180 IQ+ persons" -->
<!-- id="BAY101-F76CE35FC7469CAE7995F6AC470@phx.gbl" -->
<!-- inreplyto="638d4e150608230557i6eb31083ya364aa0d64020e90@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Michael Vassar (<a href="mailto:michaelvassar@hotmail.com?Subject=Re:%20A%20study%20comparing%20150%20IQ%2B%20persons%20to%20180%20IQ%2B%20persons"><em>michaelvassar@hotmail.com</em></a>)<br>
<strong>Date:</strong> Wed Aug 23 2006 - 08:59:16 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="15719.html">Richard Loosemore: "Apollo Project to get to the Singularity  [WAS Re: A study comparing 150 IQ+ persons to 180 IQ+ persons]"</a>
<li><strong>Previous message:</strong> <a href="15717.html">Michael Vassar: "Re: Anthropic Inference (Was study comparing 150 IQ+ persons to 180 IQ+ persons)"</a>
<li><strong>In reply to:</strong> <a href="15716.html">Ben Goertzel: "Re: A study comparing 150 IQ+ persons to 180 IQ+ persons"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15719.html">Richard Loosemore: "Apollo Project to get to the Singularity  [WAS Re: A study comparing 150 IQ+ persons to 180 IQ+ persons]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15718">[ date ]</a>
<a href="index.html#15718">[ thread ]</a>
<a href="subject.html#15718">[ subject ]</a>
<a href="author.html#15718">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;That [limit in the supply of high IQ teachers] is certainly true, but the 
</em><br>
<em>&gt;lack of teachers possessing high
</em><br>
<em>&gt;intelligence and other desirable qualities is not an inevitable fact, but 
</em><br>
<em>&gt;rather a consequence of the organization of the educational
</em><br>
<em>&gt;system.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Just as is, for instance, the lack of university AI professors who
</em><br>
<em>&gt;take AGI seriously ;-) ... these things all tie in together.  Given
</em><br>
<em>&gt;the deep cultural opposition to radical innovation and invention and
</em><br>
<em>&gt;deep individual insight, it is remarkable how much individuality and
</em><br>
<em>&gt;enterprise and creation actually comes about....  It is remarkable
</em><br>
<em>&gt;that the exponents on Kurzweil's graphs are still as big as they are.
</em><br>
<em>&gt;In large part I suppose this is because our culture values wealth, and
</em><br>
<em>&gt;even though it dislikes radical innovation, it rewards wealth which is
</em><br>
<em>&gt;sometimes a consequence of radical innovation...
</em><br>
<p>Fascinating.  In two paragraphs you have included 7 common (in Transhumanist 
<br>
circles)
<br>
assumptions or one step inferences that I vehemently disagree with, 
<br>
specifically
<br>
1) we could/can allocate more ability to some professions than we do via 
<br>
market or governmental mechanisms
<br>
2) non-experts with normal human motivational systems (with distinctions 
<br>
between causing and allowing to happen and diminishing returns to the 
<br>
motivational feature of a possibility as a function of it's scope) can have 
<br>
a rational basis for taking AGI seriously (MNT is different in this regard)
<br>
3) more common belief in Trans issues, and particularly in GAI, would be 
<br>
desriable.
<br>
4) our cultural opposition to innovation is unusually great (compared to 
<br>
where?).  I do believe that a few cultures (mostly between 1860 and 1950) 
<br>
may be (or have been) more friendly to innovation, but it isn't the norm.
<br>
5) I think that it is remarkable how little innovation comes out of our 
<br>
society, when one appreciates how many people there are.  This is an 
<br>
important point.  I think that most extremely innovative people project 
<br>
their own abilities and temprament onto a larger fraction of the global 
<br>
population than they should, and as a result, that they expect more of the 
<br>
things that they could do if they had the time and energy to be done by 
<br>
someone else, thus they expect more innovation to take place than does.  
<br>
This is important because an overestimation of how many people like them are 
<br>
out there leads to an erronious feeling of powerlessness in the face of 
<br>
historical forces, the fatal flaw of insufficient Hubris.  I think that Nick 
<br>
Bostrom, among others, could make Extremely large contributions to 
<br>
singularity safety if he could only be convinced to project less of himself 
<br>
onto his model of other people distributed throughout society.
<br>
6) I think that Kurzweil's graphs fail dramatically in &quot;predicting&quot; the 
<br>
past.  TSIN overtly claims that the last 20 years of change exceed that of 
<br>
the previous 86 years of the 19th century, which I consider laughable.  They 
<br>
are far less substantial than the previous 86 years in essentially every 
<br>
metric I can think of.  Population growth, life-expectancy growth, even 
<br>
linear economic growth (even though money's utility is closer to 
<br>
log-linear).  I think that those graphs are primarily useful in showing the 
<br>
inaccuracy of naive assumptions about the nature of historical technological 
<br>
change.  They do this by working out the implications of those assumptions 
<br>
overtly, as is rarely ever done, with no data mining &quot;corrections&quot; (often 
<br>
justified in terms of low-hanging fruit) for the sake of matching theory to 
<br>
history.  Basically, this makes TSIN the equivalent of a hypothetical 
<br>
cosmology book that took general relativity, ignored the cosmological 
<br>
constant (in this model equivalent to the &quot;low hanging fruit hypothesis), 
<br>
because there was no reason to believe in it, and pointed out that general 
<br>
relativity, in the absence of other assumptions, strongly suggests a 
<br>
contracting universe.
<br>
7) in the last 50 years or so I am almost at a loss to give examples of 
<br>
great wealth following radical innovation.  Great wealth almost always comes 
<br>
from small incremental innovations in the modern world.  (unlike the world 
<br>
of the late 19th century?)
<br>
<p><em>&gt;Forget about the test... if we
</em><br>
<em>&gt;-- took 100 technically, scientifically and conceptually gifted, and
</em><br>
<em>&gt;sane people from the membership of lists like SL4, extropy, AGI,
</em><br>
<em>&gt;wta-talk and the futurist community generally
</em><br>
<p>Are there 100 such people? Maybe a few dozen.  Then I'd round a community of 
<br>
100 or 200 with many mathematicians, a couple doctors, and some people with 
<br>
good practical technical skills for making the community work.  If we wanted 
<br>
to work on IA or MNT obviously, LOTS of people with chemistry, MEMS, 
<br>
cybernetics, biology, and other scientific backgrounds.
<br>
<p><em>&gt;-- put them all (er, us all ;-) in some isolated facility [Los Alamos is 
</em><br>
<em>&gt;nice, but I'll advocate a Caribbean island]
</em><br>
<p>Islands have major advantages, but there are other advantages to building a 
<br>
community in the US or Canada.  They are mostly empty.
<br>
<p><em>&gt;-- added in our in our families as well, as desired on a case by case 
</em><br>
<em>&gt;basis-- added in a crew of system administrators (not to imply that
</em><br>
<em>&gt;sys-admins aren't highly intelligent, many would be included in the
</em><br>
<em>&gt;above groups), cooks, maids, and other useful support staff, and some
</em><br>
<em>&gt;competent managers to rule them all
</em><br>
<em>&gt;-- added a couple hundred million dollars of standard and experimental
</em><br>
<em>&gt;computing equipment
</em><br>
<em>&gt;-- added a big annual budget to fund research in university labs, so
</em><br>
<em>&gt;as to bring other minds into the picture
</em><br>
<em>&gt;-- let everyone just work on creating a positive Singularity, without
</em><br>
<em>&gt;the need to earn $$ in other ways
</em><br>
<p>I'm working on it, but it will take at least 4 more years.
<br>
<p><em>&gt;How much faster would this bring the Singularity about, and how much
</em><br>
<em>&gt;would it increase the odds of the Singularity being positive?
</em><br>
<p>Quite a bit I imagine.
<br>
<p><em>&gt;Gee, this is a crazy fantasy -- except this, or some approximation of
</em><br>
<em>&gt;it, would easily be achievable if someone like Bill Gates or Larry
</em><br>
<em>&gt;Ellison or George W Bush decided it was important
</em><br>
<p>Agreed.  As stated, got people on it, though to re-iterate, Nick Bostrom is
<br>
in a relatively good position to make it happen sooner.  Any 3rd world
<br>
leader could also do it, or really any of the wealthiest few hundred people.
<br>
I doubt that the fourth or fifth hundred million add that much marginal 
<br>
value
<br>
<p><em>&gt;The point is: the problem has to do with the allocation of people and 
</em><br>
<em>&gt;funds, not with isolating who is good or not.
</em><br>
<p>Disagreed.  Both are essential.  Admittedly, tests probably have no 
<br>
advantage over
<br>
the judgment of existing capable people, but they are fast and can cover a 
<br>
large population quickly.  Still, I'm pretty sure that a group of 100 
<br>
excellent people can work faster and more effectively than a group of 500 
<br>
good people which includes those 100 excellent people.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="15719.html">Richard Loosemore: "Apollo Project to get to the Singularity  [WAS Re: A study comparing 150 IQ+ persons to 180 IQ+ persons]"</a>
<li><strong>Previous message:</strong> <a href="15717.html">Michael Vassar: "Re: Anthropic Inference (Was study comparing 150 IQ+ persons to 180 IQ+ persons)"</a>
<li><strong>In reply to:</strong> <a href="15716.html">Ben Goertzel: "Re: A study comparing 150 IQ+ persons to 180 IQ+ persons"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15719.html">Richard Loosemore: "Apollo Project to get to the Singularity  [WAS Re: A study comparing 150 IQ+ persons to 180 IQ+ persons]"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15718">[ date ]</a>
<a href="index.html#15718">[ thread ]</a>
<a href="subject.html#15718">[ subject ]</a>
<a href="author.html#15718">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:57 MDT
</em></small></p>
</body>
</html>
