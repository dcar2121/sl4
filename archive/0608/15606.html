<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Donaldson, Tegmark and AGI</title>
<meta name="Author" content="Russell Wallace (russell.wallace@gmail.com)">
<meta name="Subject" content="Donaldson, Tegmark and AGI">
<meta name="Date" content="2006-08-11">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Donaldson, Tegmark and AGI</h1>
<!-- received="Fri Aug 11 19:45:20 2006" -->
<!-- isoreceived="20060812014520" -->
<!-- sent="Sat, 12 Aug 2006 02:45:07 +0100" -->
<!-- isosent="20060812014507" -->
<!-- name="Russell Wallace" -->
<!-- email="russell.wallace@gmail.com" -->
<!-- subject="Donaldson, Tegmark and AGI" -->
<!-- id="8d71341e0608111845p1e59a934w414b74f10b9b6574@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Russell Wallace (<a href="mailto:russell.wallace@gmail.com?Subject=Re:%20Donaldson,%20Tegmark%20and%20AGI"><em>russell.wallace@gmail.com</em></a>)<br>
<strong>Date:</strong> Fri Aug 11 2006 - 19:45:07 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="15607.html">Robin Hanson: "Re: Donaldson, Tegmark and AGI"</a>
<li><strong>Previous message:</strong> <a href="15605.html">Charles D Hixson: "Re: What's going on this decade?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15607.html">Robin Hanson: "Re: Donaldson, Tegmark and AGI"</a>
<li><strong>Maybe reply:</strong> <a href="15607.html">Robin Hanson: "Re: Donaldson, Tegmark and AGI"</a>
<li><strong>Reply:</strong> <a href="15610.html">Brian Atkins: "Re: Donaldson, Tegmark and AGI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15606">[ date ]</a>
<a href="index.html#15606">[ thread ]</a>
<a href="subject.html#15606">[ subject ]</a>
<a href="author.html#15606">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
(Advance warning, I'm tired and the ideas herein are still somewhat inchoate
<br>
so I'm not sure how coherent all this is, but if I wait until I'm fresh as a
<br>
daisy and my thoughts are perfectly organized I may be some time, and it's
<br>
possible this may be of use to someone, in which case this version now is
<br>
better than a perfect version Real Soon Now. Also please disregard apparent
<br>
egotism: the point I'm trying to make is not about me, I merely perforce use
<br>
myself as an example.)
<br>
<p>The fantasy author Stephen Donaldson in my opinion belongs in the canon of
<br>
Western literature, on the criterion of depth: elements of sufficient
<br>
profundity that their significance may not be apparent until years after
<br>
first reading. A theme that pervades much of his work is _despair_, made
<br>
explicit in one memorable scene (no spoilers, you'll recognize it if you
<br>
read the book in question): There are certain insights that can only be
<br>
obtained in the extremity of despair.
<br>
<p>Douglas Lenat was, like da Vinci, Babbage and Drexler, a man ahead of his
<br>
time; Eurisko stood for perhaps two decades as the most advanced AI ever
<br>
created (though Novamente may be ahead of it by now; comparison is
<br>
difficult). And then he abandoned it, decades ahead of the rest of us in the
<br>
insight that recursive self-improvement is a mirage, there are no short
<br>
cuts; and moved on to tackle the problem of real-world knowledge.
<br>
<p>Yet Cyc achieved less than Eurisko, and we understand why: it handles only
<br>
ungrounded declarative sentences, which are far too shallow a subset of
<br>
knowledge for any significant use - sufficiently so that they're not even
<br>
worth bothering with if that's all you have; Google walks away from Cyc in
<br>
Cyc's strongest areas.
<br>
<p>Why did such a brilliant man fall into such an obvious dead end, and stay in
<br>
it for two decades and counting? The answer mocks with its banality: that
<br>
was all 20th century hardware could handle. One has to undertake a project
<br>
that is doable; failing that, one has to believe some undertakable project
<br>
is doable. (Disclaimer: obviously I'm not privy to Lenat's thoughts, so this
<br>
is speculation; but I believe it to be very much in accord with how our
<br>
minds work.)
<br>
<p>Today's hardware isn't up to it either of course. I've finally managed to
<br>
see, in very vague and shaky outline, how to create AGI - not as a blueprint
<br>
of course (I'm not _that_ good :)), and with lots of big unsolved problems
<br>
still, but as a path running decades into the fog of the future; if Moore's
<br>
Law holds out, if nothing goes disastrously wrong, if people and funding can
<br>
be assembled and kept together, there is a way. It doesn't involve
<br>
spectacular results in the next few years, and while I won't swear there's
<br>
no other way, this one looks marginal enough that I _think_ any substantial
<br>
deviation from it drops the chance of success by many orders of magnitude.
<br>
(I'll try and put something together on the actual how at some point, though
<br>
I don't have a precise enough idea yet to write a paper on it.)
<br>
<p>So why was I able to figure that out and Lenat wasn't? I don't think it's
<br>
because I'm smarter than him. I think it's because I was able to accept at
<br>
last that _we will probably fail_. Not in a near-future toss of the dice
<br>
that's emotionally comforting in its own way: Judgement Day comes, we're
<br>
uploaded to heaven or the world goes poof in one clean conflagration and no
<br>
more pain. No, if we succeed it will be after many long decades of
<br>
exhausting thankless work; and if we fail - it will be after many long
<br>
decades of exhausting thankless work followed by the agonizingly protracted
<br>
death that modern medicine and nursing deliver, leaving behind a world that
<br>
will die, not with a psychologically acceptable bang, but with a whimper;
<br>
and all because we were not smart and fast enough to do our jobs in whatever
<br>
window of opportunity was available.
<br>
<p>I do not, of course, know what the probabilities of each of these outcomes
<br>
are. (And there may be other paths; in particular, nanotechnology minus AGI
<br>
may yet suffice. I haven't studied that end of things as intensively; my
<br>
best guess is that AGI is the most likely route to success, but I'm not
<br>
sure. I'm much more sure AGI is the point of highest leverage, based on
<br>
resource requirements.) It could, for all I really know, be 50/50. But I
<br>
suspect it's more like 99/1. Decay is easier and faster than progress. Only
<br>
in the acceptance of despair did I arrive at these insights.
<br>
<p>Why was I able to do this? I don't think it's because I have some emotional
<br>
strength not given to other men. I think it's about belief systems. That's
<br>
not terribly surprising after all, religion has over the years given many
<br>
people the strength to endure unpleasant things; but that is not my path,
<br>
nor I think that of most of the people on this list.
<br>
<p>I've believed in the Tegmark multiverse (the many-worlds interpretation of
<br>
quantum mechanics and the Platonic philosophy of mathematics - a post I
<br>
found in the extropy-chat archives,
<br>
<a href="http://bbs.extropy.org/exi-lists/archive/9904/35948.html">http://bbs.extropy.org/exi-lists/archive/9904/35948.html</a> gives tantalizing
<br>
hints that the two may be connected - but I digress) since I was old enough
<br>
to ponder the issues; not at the time for emotional reasons, simply because
<br>
of its elegance, its elimination of the requirement for special assumptions,
<br>
its ability to explain albeit  not (usually - with one or two exceptions)
<br>
predict. Originally it was purely an intellectual thing, but over the years
<br>
the habit of mind ingrained itself.
<br>
<p>So finally I was able to understand that if I believe this is _true_ - which
<br>
I do - then I can accept a 99% probability that we will fail and the Grim
<br>
Reaper will take us, our civilization, our species, our world as it has
<br>
taken others in the past; for that means the other 1% of the probability
<br>
amplitude finds Ascension, and the total utility thus achieved far, far
<br>
outweighs our loss. In utilitarian logic the correct action is of course the
<br>
same either way, but in human psychology it is not.
<br>
<p>The reason I post this is that I have seen - not just on this list - a need
<br>
to deny the possibility of failure, of death, most particularly of the
<br>
emotionally unacceptable kinds of death that are in fact the ones reality
<br>
hands out, to believe there is some path that can deliver safety by
<br>
squelching danger; but if denial of the possibility of failure is followed
<br>
far enough, if everything that appears dangerous is squelched, the reality
<br>
of failure and death become certain.
<br>
<p>I'm a pessimist and the philosophy here offered is in accordance with that,
<br>
and I suspect most will not find it of use. But to any who do: there is
<br>
light the other side of despair.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="15607.html">Robin Hanson: "Re: Donaldson, Tegmark and AGI"</a>
<li><strong>Previous message:</strong> <a href="15605.html">Charles D Hixson: "Re: What's going on this decade?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="15607.html">Robin Hanson: "Re: Donaldson, Tegmark and AGI"</a>
<li><strong>Maybe reply:</strong> <a href="15607.html">Robin Hanson: "Re: Donaldson, Tegmark and AGI"</a>
<li><strong>Reply:</strong> <a href="15610.html">Brian Atkins: "Re: Donaldson, Tegmark and AGI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#15606">[ date ]</a>
<a href="index.html#15606">[ thread ]</a>
<a href="subject.html#15606">[ subject ]</a>
<a href="author.html#15606">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:57 MDT
</em></small></p>
</body>
</html>
