<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Egan dismisses Singularity, maybe</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Egan dismisses Singularity, maybe">
<meta name="Date" content="2002-04-22">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Egan dismisses Singularity, maybe</h1>
<!-- received="Mon Apr 22 16:55:42 2002" -->
<!-- isoreceived="20020422225542" -->
<!-- sent="Mon, 22 Apr 2002 16:49:36 -0400" -->
<!-- isosent="20020422204936" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Egan dismisses Singularity, maybe" -->
<!-- id="3CC47760.28A3C5BA@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3.0.6.32.20020422181405.007cfe90@ariel.its.unimelb.edu.au" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Egan%20dismisses%20Singularity,%20maybe"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Mon Apr 22 2002 - 14:49:36 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3430.html">Arona Ndiaye: "Re: Different View of IA"</a>
<li><strong>Previous message:</strong> <a href="3428.html">Eliezer S. Yudkowsky: "META: Reminder of list rules"</a>
<li><strong>In reply to:</strong> <a href="3418.html">Damien Broderick: "Egan dismisses Singularity, maybe"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3436.html">mike99: "RE: Egan dismisses Singularity, maybe"</a>
<li><strong>Reply:</strong> <a href="3436.html">mike99: "RE: Egan dismisses Singularity, maybe"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3429">[ date ]</a>
<a href="index.html#3429">[ thread ]</a>
<a href="subject.html#3429">[ subject ]</a>
<a href="author.html#3429">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Damien Broderick wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; It's a capital mistake to confuse a writer with the fiction, let alone one
</em><br>
<em>&gt; character in a cast.  Still this is a provocative passage in SCHILD'S
</em><br>
<em>&gt; LADDER. I'm still reading the book, so for all I know there's a fullblown
</em><br>
<em>&gt; Spike before the end, but I was struck by how Egan's moderately posthuman
</em><br>
<em>&gt; figures are placed 20,000 years hence with no mention of anyone having
</em><br>
<em>&gt; Sublimed. Then on p.55 [UK edition]:
</em><br>
<em>&gt;
</em><br>
<em>&gt; ==========
</em><br>
<em>&gt; 
</em><br>
<em>&gt; `What do you think you're going to find in there [a new region of altered
</em><br>
<em>&gt; spacetime]? Some great shining light of transcendence?'
</em><br>
<em>&gt;         `Hardly.' _Transcendence_ was a content-free word left over from religion,
</em><br>
<em>&gt; but in some moribund planetary cultures it had come to refer to a mythical
</em><br>
<em>&gt; process of mental restructuring that would result in vastly greater
</em><br>
<em>&gt; intelligence and a boundless cornucopia of hazy superpowers--if only the
</em><br>
<em>&gt; details could be perfected, preferably by someone else. It was probably an
</em><br>
<em>&gt; appealing notion if you were so lazy that you'd never actually learnt
</em><br>
<em>&gt; anything about the universe you inhabited, and couldn't quite conceive of
</em><br>
<em>&gt; putting in the effort to do so; this magical cargo of transmogrification
</em><br>
<em>&gt; was sure to come along eventually and render the need superfluous.
</em><br>
<em>&gt;         Tchicaya said, `I already possess general intelligence, thanks. I don't
</em><br>
<em>&gt; need anything more.' It was a rigorous result in information theory that
</em><br>
<em>&gt; once you learn in a sufficiently flexible manner--something humanity had
</em><br>
<em>&gt; achieved in the Bronze Age--the only limits you faced were speed and
</em><br>
<em>&gt; storage; all other structural changes were just a matter of style.
</em><br>
<em>&gt; ==================================
</em><br>
<p>Naturally, Greg Egan can't afford to have his characters Sublime off,
<br>
because then he wouldn't have anything to write about.  I personally feel
<br>
that the best way to deal with this plot hole is to never mention it; I
<br>
thought Iain Banks's Culture novels were seriously wounded by his later
<br>
attempts to explain away the lack of a Singularity.  Alternatively, the main
<br>
characters can be refuseniks or very junior sentients, although in neither
<br>
case are they likely to be dealing with the most difficult problems of
<br>
contemporary civilization.
<br>
<p>However, Tchicaya's tone sounds too harsh to be just patching up a plot
<br>
hole.  I strongly suspect that Violet Mosala of &quot;Distress&quot; is standing in
<br>
for Greg Egan when she attacks pseudoscience, and Tchicaya in the quoted
<br>
passage sounds a lot like Violet Mosala.  I think Greg Egan probably
<br>
believes what's written above - although, since Amazon still says &quot;Schild's
<br>
Ladder&quot; isn't available in the US, all I know about the entire novel is the
<br>
one paragraph Damien posted.  But it does seem consistent with the picture
<br>
painted in &quot;Diaspora&quot;, or for that matter Peer carving table legs in
<br>
&quot;Permutation City&quot;.
<br>
<p>Naturally, I'm not going to take Egan's comments personally (Greg Egan being
<br>
my favorite SF author of all time may have something to do with this).  I
<br>
expect Egan ran across one or two nontechnical writings on the Singularity
<br>
that took a worshipful tone and didn't back it up with specific arguments;
<br>
he thought that this was all there was to it; and he subsequently became
<br>
annoyed with the whole deal, or at least what he thought was the whole deal.
<br>
<p>Nonetheless, as one of the &quot;someone elses&quot; working out the details Greg Egan
<br>
refers to, I think Greg Egan's characterization of the enormous possible
<br>
variation within the design space of minds-in-general as &quot;matters of style&quot;
<br>
is yet more fallout from Standard Social Sciences Model genericity.  If you
<br>
break down general intelligence into a set of interacting, internally
<br>
specialized subsystems, then it becomes much clearer that pumping up the
<br>
computing resources available to a subsystem changes *what* you think and
<br>
not just how fast you think it or how well you remember it.  Take the
<br>
decomposition from &quot;Levels of Organization in General Intelligence&quot; as an
<br>
example; even if you leave the general architecture completely constant and:
<br>
<p>(1) Add computing resources to the subsystems handling categorization, so
<br>
that they can perceptually reify and perceptually match more complex
<br>
patterns within sensory modalities and abstract imagery (2.5.1).
<br>
(2) Pump up the number and kind of beliefs and expectations that are
<br>
automatically checked for resonance against mental imagery during the
<br>
resolution of a sequitur (2.6.3).
<br>
(3) Pump up the size of working memory: the size and resolution of
<br>
perceptual workspace in sensory modalities, the size and resolution of the
<br>
focus of attention, and the amount of mental imagery that can be
<br>
simultaneously compared against all other mental imagery (2.6.2).
<br>
<p>Then the end result should be an intelligence that is immediately bored by a
<br>
very large class of problems that humans find interesting, and which has fun
<br>
solving an even larger class of problems that humans would find permanently
<br>
intractable intuitively.  Even if, given infinite time and storage, a human
<br>
could simulate by hand a Turing machine that understood the problem, the
<br>
human would simply be standing in for the CPU and would not necessarily have
<br>
the cognitive capacity to represent internally an understanding of the
<br>
higher levels of organization.  And of course Part III of _Levels_ argues
<br>
directly that minds-in-general can access major cognitive advantages that
<br>
are not available to present-day evolved humans.
<br>
<p>It is more than our instincts and our sensory modalities that mark
<br>
present-day humans as thinly modified primates; our basic cognitive
<br>
architecture bears the signature of incremental evolution as well.  See
<br>
Terrence Deacon's &quot;The Symbolic Species&quot;, for example.  Or _Levels_, of
<br>
course.
<br>
<p>It seems pretty clear that tomorrow's sophisticated citizen will instantly
<br>
recognize Greg Egan's most exotic characters as (a) human-level
<br>
intelligences, (b) human-level intelligences with a roughly anthropomorphic
<br>
balance of domain competencies, (c) evolved human-level intelligences, and
<br>
even (d) modified primates.  One might excuse this on the grounds that
<br>
Egan's characters need basically human architectures in order to map onto
<br>
our own minds as sympathetic characters.  In fact, Greg Egan's characters
<br>
are already so far afield by contemporary standards that the only
<br>
sympathetic character left in Konishi polis is Inoshiro.  But of course
<br>
anthropomorphism is only excusable as a literary necessity if Greg Egan
<br>
knows it's anthropomorphism; I doubt that Egan would want to be held to
<br>
standards any lower than that.
<br>
<p>So, even in terms of what we can figure out today, I would have to say that
<br>
Tchicaya is, in all probability, flat wrong, and that this probably reflects
<br>
an identical mistake by Egan.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3430.html">Arona Ndiaye: "Re: Different View of IA"</a>
<li><strong>Previous message:</strong> <a href="3428.html">Eliezer S. Yudkowsky: "META: Reminder of list rules"</a>
<li><strong>In reply to:</strong> <a href="3418.html">Damien Broderick: "Egan dismisses Singularity, maybe"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3436.html">mike99: "RE: Egan dismisses Singularity, maybe"</a>
<li><strong>Reply:</strong> <a href="3436.html">mike99: "RE: Egan dismisses Singularity, maybe"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3429">[ date ]</a>
<a href="index.html#3429">[ thread ]</a>
<a href="subject.html#3429">[ subject ]</a>
<a href="author.html#3429">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
