<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: FW: DGI Paper</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="FW: DGI Paper">
<meta name="Date" content="2002-04-13">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>FW: DGI Paper</h1>
<!-- received="Sat Apr 13 17:45:28 2002" -->
<!-- isoreceived="20020413234528" -->
<!-- sent="Sat, 13 Apr 2002 15:35:48 -0600" -->
<!-- isosent="20020413213548" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="FW: DGI Paper" -->
<!-- id="LAEGJLOGJIOELPNIOOAJCEDBCGAA.ben@goertzel.org" -->
<!-- charset="iso-8859-1" -->
<!-- inreplyto="DGI Paper" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=FW:%20DGI%20Paper"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Sat Apr 13 2002 - 15:35:48 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3339.html">Samantha Atkins: "Re: Why bother (was Re: Introducing myself)"</a>
<li><strong>Previous message:</strong> <a href="3337.html">Josh Yotty: "Re: Singularitarian Directory"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3340.html">Eliezer S. Yudkowsky: "Re: FW: DGI Paper"</a>
<li><strong>Reply:</strong> <a href="3340.html">Eliezer S. Yudkowsky: "Re: FW: DGI Paper"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3338">[ date ]</a>
<a href="index.html#3338">[ thread ]</a>
<a href="subject.html#3338">[ subject ]</a>
<a href="author.html#3338">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hey Eliezer,
<br>
<p>Here are some fairly fine-grained comments on the theory of mind embodied in
<br>
your excellent paper on Deliberative General Intelligence.
<br>
<p>Overall I find the paper to be most outstanding, and I think the general
<br>
ideas you lay out there are highly consistent with the thinking underlying
<br>
my own AI work.  Of course, due to the generality of your ideas, they are
<br>
bound to be consistent with a great variety of different concrete AI
<br>
systems.
<br>
<p>In these comments I'll focus on areas of disagreement &amp; areas where your
<br>
statements confuse me, although these are relatively minor in the grand
<br>
scheme of the paper....
<br>
<p>-- ben
<br>
<p><p>*******************
<br>
<p>1)
<br>
Firstly, about Concepts:
<br>
<p>I think your characterization of concepts is in places too narrow.  Your
<br>
statement “concepts are patterns that mesh with sensory imagery”  seems to
<br>
me to miss abstract concepts and also concepts related to action rather than
<br>
perception.  I realize that later on you do mention abstract concepts.
<br>
<p>I define a concept as “a relationship between concepts, percepts and
<br>
&nbsp;actions”.
<br>
<p>Mathematical and spiritual concepts are examples of concepts that are
<br>
meaningful but not produced in any direct way by generalization from
<br>
perception or action.  You can say that &quot;5&quot; is produced by generalization
<br>
from perception, but what about &quot;differential operator&quot;?  What about &quot;God&quot;?
<br>
I'm afraid that to view these as generalizations from perception, you need a
<br>
terrribly general definition of generalization.  I think some concepts arise
<br>
through self-organizing mind-processes into which perception is just one of
<br>
many inputs, not always a very significant one.
<br>
<p>Overall, I think that you overemphasize perception as compared to action.
<br>
Pragmatically, in Novamente, I’ve found that the latter is at least as hard
<br>
of a problem to deal with, in terms of implementation and in terms of
<br>
working out the conceptual interface with cognition.
<br>
<p>Along theese same lines, the definition of a “concept kernel” you give seems
<br>
to apply only to perceptually-derived concepts; I think it should be
<br>
generalized.
<br>
<p><p>2)
<br>
Next, about Thoughts:
<br>
<p>You omit to mention that thoughts as well as concepts can be remembered.
<br>
Much of episodic memory consists of memories of thoughts!  Thus, thoughts
<br>
are not really “disposable one-time structures” as you say.  Most but not
<br>
all are disposed of.
<br>
<p>I like dredging up old thoughts from memory and reliving them.  Of course,
<br>
one can never tell how much change has taken place in the process ;&gt;
<br>
<p>When you say “A thought is a specific structure of combinatorial symbols
<br>
which builds or alters mental imagery” – I am not sure why “imagery” comes
<br>
into it.  It seems that you are using this word in a way that is not
<br>
necessarily related to visual imagery, which is a little bit confusing.  I’d
<br>
like to see a definition of “mental imagery” as you use it here.  Don’t you
<br>
believe some thoughts are entirely non-imagistic, purely abstract without
<br>
any reliance on sensory metaphors?  Some of mine appear to be,
<br>
introspectively -- and I am a highly visual thinker, more so than many
<br>
others.
<br>
<p><p>3)
<br>
The discussion of “smooth fitness landscapes” is confusing.
<br>
<p>Actually, the fitness landscapes confronting intelligent systems are almost
<br>
all what are called “rugged fitness landscapes” (a term I got from a whole
<br>
bunch of Santa Fe institute papers on rugged fitness landscapes, some by
<br>
biologist Alan Perelson).
<br>
<p>I.e., they are fractal, not smooth.
<br>
<p>They have a relatively small average Lipschitz constant, meaning that
<br>
|f(x)-f(y)|/|x-y| is on average not too big for (x,y) reasonably close
<br>
together.
<br>
<p>But “smooth” always means continuous (or differentiable) in mathematics, and
<br>
the cognitively &amp; evolutionarily relevant fitness landscapes definitely are
<br>
NOT.
<br>
<p>4)
<br>
About feature controllers &amp; feature detectors.  There is evidence for the
<br>
involvement of premotor neurons in conscious perception in the brain.   I
<br>
reference some old work along these lines in my online paper “Chance and
<br>
Consciousness.”  I’m sure there’s more recent work too.  This doesn’t
<br>
directly give evidence for feature controllers but it is a big step in that
<br>
direction.
<br>
<p>5)
<br>
About your suggested modalities: billiards, super-Go, and interpreted code…
<br>
it’s not clear that the former two have the richness to support the
<br>
education of a non-brittle intelligence.  Of course, you don't say they do,
<br>
wisely enough.  But what do you suggest for modalities for a slightly more
<br>
advanced AI?  Do you think we need to go to robot eyes and such, or do you
<br>
think the Net will suffice?
<br>
<p>6)
<br>
In 2.5.2, what do you mean by “verify the generalization”?    Could you give
<br>
a couple examples?
<br>
<p><p>7)
<br>
You say  “concepts are learned, thoughts are invented.”  I don’t quite catch
<br>
the sense of this.
<br>
<p>Complex concepts are certainly “invented” as well, under the normal
<br>
definition of “invention.” …
<br>
<p>The concept of a pseudoinverse of a matrix was invented by Moore and
<br>
Penrose, not learned by them.  I learned it from a textbook.
<br>
<p>The concept of &quot;Singularity&quot; was invented as well...
<br>
<p>8)
<br>
You say “the complexity of the thought level … arises from the cyclic
<br>
interaction of thoughts and mental imagery.”
<br>
<p>I think this is only one root of the complexity of thoughts.
<br>
<p>Self-organizing mental processes acting purely on the thought level seem to
<br>
play a big role as well.
<br>
<p>9)
<br>
You say, “in humans, the perception of confidence happens to exhibit a
<br>
roughly quantitative strength….”
<br>
<p>I don’t think this is something that “just happens” to be the case in
<br>
humans.  I think that this quantification of the qualitative (the creation
<br>
of numerical truth values corresponding to mental entities) is a key part of
<br>
intelligence.   I bet it will be part of ANY intelligence.  There is a huge
<br>
efficiency to operating with numbers.
<br>
<p>Western science only developed via the advent of widespread quantification –
<br>
it’s valuable in science for the same reason that it is in the brain.
<br>
<p>Also, in fact, I believe the human notion of truth value is not a single
<br>
number but involves at least 2-3 numbers; in Novamente we work minimally
<br>
with triples (probability, confidence, weight of evidence).
<br>
<p>10)
<br>
You say “ ‘one thought at a time’  is just the human way of doing things ….”
<br>
<p>Actually it isn’t, I often have more than one thought at a time.
<br>
<p>Right now, I am simultaneously thinking about thoughts, and thinking about
<br>
getting up to get something to eat .. and thinking about something
<br>
deliciously X-rated....  This particular kind of simultaneity usually
<br>
indicates to me that I've been working too long ;&gt;
<br>
<p>Usually one thought is in the foreground and the others are vying for
<br>
attention but dimmer.  But sometimes 2 thoughts share the foreground, e.g.
<br>
when chatting on the phone with my loquacious grandfather while
<br>
simultaneously answering e-mails...
<br>
<p>I do agree though that digital minds will be able to multitask actions and
<br>
thoughts much more thoroughly than humans can.  None of us can pursue more
<br>
than, say, 5 trains of thought simultaneously (I can only handle 2-3), but
<br>
an AI should be able to be much more flexible by diverting more resources
<br>
from unconscious processing as situationally necessary.
<br>
<p>11)
<br>
Regarding your discussion of the need (or otherwise) for language in digital
<br>
mind.
<br>
<p>I am guessing that AI will come most easily via building a community of
<br>
intercommunicating AI’s.  Communication between AI’s need not proceed using
<br>
linear sequences of characters or sounds, though.  It can proceed via
<br>
various sorts of brain-to-brain transfer.  But this requires some art; in
<br>
Novamente we’ve designed a language called Psynese for brain-to-brain
<br>
transfer between different Novamente instances.
<br>
<p>12)
<br>
When you discuss the various kinds of binding, I’m not sure why you have a
<br>
sensory binding but not an action binding.
<br>
<p>You deal with actions in the context of decisive bindings, but, I think
<br>
sometimes actions can be bound in a way that has nothing to do with goals.
<br>
<p><p>13)
<br>
You say that “evolution… cannot boast general intelligence.”
<br>
<p>This is not so clear to me.  Why?  It seems to me that evolution in fact
<br>
does display a pretty generalized kind of intelligence.
<br>
<p>This is a deep philosophical point of course, and not directly relevant to
<br>
digital mind design.
<br>
<p>You could say perhaps that evolution is relatively unintelligent because it
<br>
requires too many space and time resources to achieve its goals.
<br>
<p><p><p>OK, 13 is my lucky number, so I'll stop here.
<br>
<p>BTW, I'll be out of town Sunday afternoon thru Wednesday night, so my e-mail
<br>
responses will likely come daily rather than hourly ;-)
<br>
<p><p>-- ben g
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3339.html">Samantha Atkins: "Re: Why bother (was Re: Introducing myself)"</a>
<li><strong>Previous message:</strong> <a href="3337.html">Josh Yotty: "Re: Singularitarian Directory"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3340.html">Eliezer S. Yudkowsky: "Re: FW: DGI Paper"</a>
<li><strong>Reply:</strong> <a href="3340.html">Eliezer S. Yudkowsky: "Re: FW: DGI Paper"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3338">[ date ]</a>
<a href="index.html#3338">[ thread ]</a>
<a href="subject.html#3338">[ subject ]</a>
<a href="author.html#3338">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
