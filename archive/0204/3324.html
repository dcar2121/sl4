<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: PAPER: Levels of Organization in General Intelligence</title>
<meta name="Author" content="Ben Houston (ben@exocortex.org)">
<meta name="Subject" content="RE: PAPER: Levels of Organization in General Intelligence">
<meta name="Date" content="2002-04-10">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: PAPER: Levels of Organization in General Intelligence</h1>
<!-- received="Wed Apr 10 19:27:33 2002" -->
<!-- isoreceived="20020411012733" -->
<!-- sent="Wed, 10 Apr 2002 19:06:07 -0400" -->
<!-- isosent="20020410230607" -->
<!-- name="Ben Houston" -->
<!-- email="ben@exocortex.org" -->
<!-- subject="RE: PAPER: Levels of Organization in General Intelligence" -->
<!-- id="000301c1e0e4$4bc82de0$6601a8c0@exonode" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="3CB1BE57.B4D5AA6F@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Houston (<a href="mailto:ben@exocortex.org?Subject=RE:%20PAPER:%20Levels%20of%20Organization%20in%20General%20Intelligence"><em>ben@exocortex.org</em></a>)<br>
<strong>Date:</strong> Wed Apr 10 2002 - 17:06:07 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3325.html">Sabine Atkins: "Re: translated (was &quot;KRAUT: Die Schaffung eines k?nstlichen...&quot;)"</a>
<li><strong>Previous message:</strong> <a href="3323.html">Ben Houston: "RE: DGI: non-universality of codon-&gt;amino acid mapping"</a>
<li><strong>In reply to:</strong> <a href="3309.html">Eliezer S. Yudkowsky: "Re: PAPER: Levels of Organization in General Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3326.html">Eliezer S. Yudkowsky: "Re: PAPER: Levels of Organization in General Intelligence"</a>
<li><strong>Reply:</strong> <a href="3326.html">Eliezer S. Yudkowsky: "Re: PAPER: Levels of Organization in General Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3324">[ date ]</a>
<a href="index.html#3324">[ thread ]</a>
<a href="subject.html#3324">[ subject ]</a>
<a href="author.html#3324">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Hey Eliezer,
<br>
<p>Sorry for the late reply.  This is exam and essay writing season. :-/
<br>
<p><em>&gt; Eliezer Yudkowsky wrote: 
</em><br>
<em>&gt; Ben Houston wrote:
</em><br>
<em>&gt; &gt; I've seen some truly amazing things done in the computational
</em><br>
<em>&gt; &gt; pharmacology field dealing with cheap, but massive parallelization.
</em><br>
<em>&gt; &gt; Basically, a lot of short cuts are available in the parallelization
</em><br>
of
<br>
<em>&gt; &gt; an algorithm once you've solidified it.  In order words making a
</em><br>
<em>&gt; &gt; parallel problem solving is difficult and cost in the general case
</em><br>
but
<br>
<em>&gt; &gt; in a specific case it can be quite cheap.  The field of
</em><br>
computational
<br>
<em>&gt; &gt; pharmacology is working with special purpose multi-teraflop machines
</em><br>
<em>&gt; &gt; that cost less than $1,000,000 US for a year or so now.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; If you can run exactly the same algorithm on each of a billion pieces
</em><br>
of
<br>
<em>&gt; data with no interaction between instances of the algorithm, naturally
</em><br>
<em>&gt; parallelization is easy.
</em><br>
<p>If you glanced at any of the sites or papers I referenced you wouldn't
<br>
be able to dismiss it so quickly.  Basically the particular special
<br>
purpose computer I was referring to is made for QM/MM problems.  These
<br>
are N-body problems in which the next state of every particle (usually
<br>
numbering at least in the millions) depends on the previous state of
<br>
every other particle.  Thus these problems are about as interdependent
<br>
as possible -- and quite the opposite of what you describe above.
<br>
&nbsp;
<br>
<em>&gt; One serial bottleneck is enough to render overall consciousness
</em><br>
serial.
<br>
<em>&gt; The
</em><br>
<em>&gt; human brain, having been rendered serial, is adapted as a whole to
</em><br>
serial
<br>
<em>&gt; deliberation, no matter how many subprocesses are massively parallel.
</em><br>
<em>&gt; Sequiturs may run massively parallel searches to find thoughts, but
</em><br>
it's
<br>
<em>&gt; only one thought that wins.
</em><br>
<p>I guess we are just working with different terminology.  I guess your
<br>
use of &quot;the overall flow of cognition&quot; probably can be mapped to my
<br>
concept of &quot;specific cognitive flows&quot;.
<br>
<p><em>&gt; &gt; &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
<em>&gt; &gt; We know it is possible to evolve a general intelligence that runs on
</em><br>
a
<br>
<em>&gt; &gt; hundred trillion synapses with characteristic limiting speeds of
</em><br>
<em>&gt; &gt; approximately 200 spikes per second.
</em><br>
<em>&gt; &gt; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; 200 spikes/sec is probably the median for the brain.  Some neurons
</em><br>
I've
<br>
<em>&gt; &gt; studied in my courses have upper limits around 1000 spikes/sec.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Hence &quot;approximately&quot;.
</em><br>
<p>Cool stuff. :-)
<br>
<p><em>&gt; &gt; Neglect the sensory and motor systems I believe that in the CNS 'S'
</em><br>
<em>&gt; &gt; would be upwards of at least 5 as a result of the DAG-like
</em><br>
arrangements
<br>
<em>&gt; &gt; of the signal processing pathways -- ignoring backwards, regulatory
</em><br>
<em>&gt; &gt; projections.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 'S' is measured with respect to signal propagation speed measured in
</em><br>
clock
<br>
<em>&gt; ticks, not the characteristic number of links.  Maybe I should clarify
</em><br>
<em>&gt; this
</em><br>
<em>&gt; in the text.  Or just check out Anders Sandberg's original paper.
</em><br>
<p>I understood originally from your paper that a &quot;clock tick&quot; for the
<br>
brain was one 200th of a second.  I still think that the point applies
<br>
since a chain of 4 neurons will most likely require more than 1/200th of
<br>
a second to transmit a signal.  But overall I guess I find this
<br>
&quot;brain/cognitive clock tick&quot; concept sort of strange -- I'm probably
<br>
just boring.
<br>
<p><em>&gt; &gt; It seems plausible that the brain uses a resonance-like compare
</em><br>
<em>&gt; &gt; function.  Basically, a match may be recognized when a neural
</em><br>
assembly
<br>
<em>&gt; &gt; finds its group-firing greatly facilitated as a result of the
</em><br>
<em>&gt; &gt; presented/remembered stimulus.  Sort of like how a glass will
</em><br>
vibrate
<br>
<em>&gt; &gt; when exposed to its natural resonance frequency.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It's easy to postulate &quot;resonance&quot;, and in fact, I actually did.  But
</em><br>
you
<br>
<em>&gt; have to explain the specific similarity metric, before postulating
</em><br>
<em>&gt; &quot;resonance&quot; as &quot;a compare/similarity/clustering operation of some
</em><br>
kind,
<br>
<em>&gt; implemented on a neural substrate using feedforward and feedback
</em><br>
<em>&gt; connections, and synaptic computing in those huge dendritic trees to
</em><br>
<em>&gt; establish long-term potentiation with the memory's proper cues&quot; really
</em><br>
<em>&gt; says
</em><br>
<em>&gt; anything more than &quot;a compare operation implemented in the same
</em><br>
hardware
<br>
<em>&gt; devoted to storing the memories&quot;; everyone knows what neural hardware
</em><br>
<em>&gt; looks
</em><br>
<em>&gt; like.
</em><br>
<p>I guess I wasn't trying to explain how &quot;resonance&quot; is realized in the
<br>
neurons but was just mentioning it as a term that you could use.
<br>
<p><em>&gt; &gt; Actually, there is quite a collection of papers in PubMed discussing
</em><br>
the
<br>
<em>&gt; &gt; evidence that the corticothalamic feedback projections play a role
</em><br>
in
<br>
<em>&gt; &gt; image contrast control.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Why do you need ten times as many reciprocal feedback connections as
</em><br>
<em>&gt; feedforward connections to do contrast control?  I'm not saying that
</em><br>
there
<br>
<em>&gt; are no proposed explanations for the massive feedback connections or
</em><br>
that
<br>
<em>&gt; there are no known functions that require the neuroanatomical
</em><br>
backlink,
<br>
<em>&gt; just
</em><br>
<em>&gt; that the *massiveness* of the feedback connections has no *standard*
</em><br>
<em>&gt; explanation, and the greater computational complexity of feature
</em><br>
<em>&gt; controller
</em><br>
<em>&gt; structure relative to feature detector structure may have something to
</em><br>
do
<br>
<em>&gt; with it.
</em><br>
<p>Well, I'm just going from the empirical evidence.  I have seen some
<br>
evidence that these feedback projections play a role in modulating
<br>
contrast, low level attention, and possibly in short-term &quot;sensory
<br>
memory&quot;.  During &quot;visual working memory&quot; I suspect that if there is any
<br>
activation of the LGN it is only secondary to the activation of high
<br>
areas -- possibly as a result of the activation of attentional networks.
<br>
<p><em>&gt; &gt; It is an accepted fact that working memory, both verbal and spatial,
</em><br>
is
<br>
<em>&gt; &gt; maintained by mutual stimulation between the lateral prefrontal
</em><br>
cortex
<br>
<em>&gt; &gt; and certain posterior association areas:
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The existence of working memory is an accepted fact.  That working
</em><br>
memory
<br>
<em>&gt; is
</em><br>
<em>&gt; depictive is an absolutely established fact that is still not entirely
</em><br>
<em>&gt; accepted in some GOFAI circles.  Whether depictive mental imagery is
</em><br>
<em>&gt; governed by the concepts that appear in our internal narrative is
</em><br>
another
<br>
<em>&gt; fight entirely.
</em><br>
<p>Interesting additions... getting into this over email is really
<br>
difficult and though.
<br>
<p><em>&gt; &gt; I'm not sure if you mentioned it but did you know that 'verbs' seems
</em><br>
to
<br>
<em>&gt; &gt; be stored in a different brain region that 'nouns'?  And that 'noun'
</em><br>
<em>&gt; &gt; storage in the brain seems to be organized in a categorized spatial
</em><br>
<em>&gt; &gt; manner?  Neat stuff eh?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Yes, I know.
</em><br>
<p>I guess I only made the point because it seems in my quick reading that
<br>
the concept of &quot;concepts&quot; in your hierarchy had become somewhat
<br>
homogeneous.  This concern is probably minor though.
<br>
&nbsp;
<br>
<em>&gt; I'm afraid I didn't have room to mention, in the section on
</em><br>
<em>&gt; coevolution of thought and language, how cognitive selection pressures
</em><br>
for
<br>
<em>&gt; different treatment of verbs and nouns based on the different
</em><br>
perceptual
<br>
<em>&gt; structure of verbs and nouns could be responsible for the emergent
</em><br>
<em>&gt; existence
</em><br>
<em>&gt; of Chomskian deep grammar before its evolutionary fixation - as
</em><br>
Terrence
<br>
<em>&gt; Deacon points out, the evolutionary emergence of Chomskian grammar
</em><br>
from
<br>
<em>&gt; strictly linguistic selection pressures is a puzzle because Chomskian
</em><br>
<em>&gt; grammar has so many different surface forms; you would expect purely
</em><br>
<em>&gt; linguistic selection pressures to fix the computationally simpler
</em><br>
surface
<br>
<em>&gt; structures first.  But now I'm saying things that don't make any sense
</em><br>
<em>&gt; unless you've read Deacon's &quot;The Symbolic Species&quot; as well as DGI, so
</em><br>
I'd
<br>
<em>&gt; better shut up.
</em><br>
<p>I enjoyed Deacon's stuff as well. :-)  I choose to review Deacon's book,
<br>
M Donald's &quot;Origins of the Modern Mind&quot; and W Calvin's &quot;How the Brain
<br>
Things&quot; for one of my core cognitive sciences courses back in early
<br>
2000.  Although, I found Deacon's work was worthwhile and interesting I
<br>
found I preferred Donald's work.
<br>
<p><em>&gt; &gt; In your section on &quot;thought&quot; why don't you mention the cognitive
</em><br>
<em>&gt; &gt; psychology construct of &quot;working memory&quot;?  You seem to describe its
</em><br>
two
<br>
<em>&gt; &gt; part structure perfectly: (1) phonological loop and (2) visuospatial
</em><br>
<em>&gt; &gt; sketchpad.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; There are a thousand things that DGI does not mention, so don't feel
</em><br>
<em>&gt; slighted just because some of your favorite things were left out...
</em><br>
<p>I mention it because it seemed so central to your sections on &quot;thought&quot;
<br>
and &quot;deliberation.&quot;  It is a very hot topic (if not the hottest) in
<br>
cognitive neuroscience with over +500 papers published on the topic in
<br>
last year.
<br>
<p>Recently, I've been researching on my own time how the VTA and the NAc
<br>
interact with the PFC (and vice versa) in the modulation of attention in
<br>
regards to the perception of rewards or the expectation of reward.
<br>
Haven't gotten too far but this system seems like it may play a central
<br>
role in both &quot;deliberation&quot; and &quot;thought&quot;.
<br>
<p><em>&gt; As it
</em><br>
<em>&gt; happens, though, the phonological loop in working memory is just the
</em><br>
<em>&gt; prefrontal refreshment of workspace in the auditory cortex.
</em><br>
<p>Correct.  :-)  That's what the evidence has been suggesting since at
<br>
least 1993.
<br>
<p><em>&gt; the internal
</em><br>
<em>&gt; narrative may manifest in the same workspace but the phonological loop
</em><br>
<em>&gt; does
</em><br>
<em>&gt; not in itself implement an internal narrative, otherwise tape
</em><br>
recorders
<br>
<em>&gt; would be sentient.
</em><br>
<p>Interesting.  :-)  I've never had many problems with understanding the
<br>
neural substrates of the phenomena of &quot;internal narrative.&quot;   I guess I
<br>
has just assumed that it was realized by the same systems that were
<br>
responsible for the phonological loop and normal linguistic output with
<br>
the exception of the [phonological-code to motor-plan] and [motor-plan
<br>
to movement] &quot;modules&quot;.  (I am just regurgitating the seminal Levelt
<br>
framework.)
<br>
<p>Take care,
<br>
-ben
<br>
<a href="http://www.exocortex.org">http://www.exocortex.org</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3325.html">Sabine Atkins: "Re: translated (was &quot;KRAUT: Die Schaffung eines k?nstlichen...&quot;)"</a>
<li><strong>Previous message:</strong> <a href="3323.html">Ben Houston: "RE: DGI: non-universality of codon-&gt;amino acid mapping"</a>
<li><strong>In reply to:</strong> <a href="3309.html">Eliezer S. Yudkowsky: "Re: PAPER: Levels of Organization in General Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3326.html">Eliezer S. Yudkowsky: "Re: PAPER: Levels of Organization in General Intelligence"</a>
<li><strong>Reply:</strong> <a href="3326.html">Eliezer S. Yudkowsky: "Re: PAPER: Levels of Organization in General Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3324">[ date ]</a>
<a href="index.html#3324">[ thread ]</a>
<a href="subject.html#3324">[ subject ]</a>
<a href="author.html#3324">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
