<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: PAPER: Levels of Organization in General Intelligence</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: PAPER: Levels of Organization in General Intelligence">
<meta name="Date" content="2002-04-08">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: PAPER: Levels of Organization in General Intelligence</h1>
<!-- received="Mon Apr 08 12:16:46 2002" -->
<!-- isoreceived="20020408181646" -->
<!-- sent="Mon, 08 Apr 2002 11:59:19 -0400" -->
<!-- isosent="20020408155919" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: PAPER: Levels of Organization in General Intelligence" -->
<!-- id="3CB1BE57.B4D5AA6F@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="000001c1ded7$a95ca300$6601a8c0@exonode" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20PAPER:%20Levels%20of%20Organization%20in%20General%20Intelligence"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Mon Apr 08 2002 - 09:59:19 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3310.html">Eliezer S. Yudkowsky: "Essay: On psychological frames of reference"</a>
<li><strong>Previous message:</strong> <a href="3308.html">Eliezer S. Yudkowsky: "Re: DGI: non-universality of codon-&gt;amino acid mapping"</a>
<li><strong>In reply to:</strong> <a href="3301.html">Ben Houston: "RE: PAPER: Levels of Organization in General Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3324.html">Ben Houston: "RE: PAPER: Levels of Organization in General Intelligence"</a>
<li><strong>Reply:</strong> <a href="3324.html">Ben Houston: "RE: PAPER: Levels of Organization in General Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3309">[ date ]</a>
<a href="index.html#3309">[ thread ]</a>
<a href="subject.html#3309">[ subject ]</a>
<a href="author.html#3309">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Houston wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; I've seen some truly amazing things done in the computational
</em><br>
<em>&gt; pharmacology field dealing with cheap, but massive parallelization.
</em><br>
<em>&gt; Basically, a lot of short cuts are available in the parallelization of
</em><br>
<em>&gt; an algorithm once you've solidified it.  In order words making a
</em><br>
<em>&gt; parallel problem solving is difficult and cost in the general case but
</em><br>
<em>&gt; in a specific case it can be quite cheap.  The field of computational
</em><br>
<em>&gt; pharmacology is working with special purpose multi-teraflop machines
</em><br>
<em>&gt; that cost less than $1,000,000 US for a year or so now.
</em><br>
<p>If you can run exactly the same algorithm on each of a billion pieces of
<br>
data with no interaction between instances of the algorithm, naturally
<br>
parallelization is easy.
<br>
<p><em>&gt; &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
<em>&gt; Even if software parallelism were well-supported, AI developers will
</em><br>
<em>&gt; still need to spend time explicitly thinking on how to parallelize
</em><br>
<em>&gt; cognitive processes - human cognition may be massively parallel on the
</em><br>
<em>&gt; lower levels, but the overall flow of cognition is still serial.
</em><br>
<em>&gt; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Cognition, in my opinion, is quite parallel at all levels.  There are,
</em><br>
<em>&gt; in my understanding, only a few bottlenecks in the brain that forces
</em><br>
<em>&gt; things to become serial.  An obvious example would be the serial nature
</em><br>
<em>&gt; of linguistic output.
</em><br>
<p>One serial bottleneck is enough to render overall consciousness serial.  The
<br>
human brain, having been rendered serial, is adapted as a whole to serial
<br>
deliberation, no matter how many subprocesses are massively parallel. 
<br>
Sequiturs may run massively parallel searches to find thoughts, but it's
<br>
only one thought that wins.
<br>
<p><em>&gt; &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
<em>&gt; We know it is possible to evolve a general intelligence that runs on a
</em><br>
<em>&gt; hundred trillion synapses with characteristic limiting speeds of
</em><br>
<em>&gt; approximately 200 spikes per second.
</em><br>
<em>&gt; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 200 spikes/sec is probably the median for the brain.  Some neurons I've
</em><br>
<em>&gt; studied in my courses have upper limits around 1000 spikes/sec.
</em><br>
<p>Hence &quot;approximately&quot;.
<br>
<p><em>&gt; Neglect the sensory and motor systems I believe that in the CNS 'S'
</em><br>
<em>&gt; would be upwards of at least 5 as a result of the DAG-like arrangements
</em><br>
<em>&gt; of the signal processing pathways -- ignoring backwards, regulatory
</em><br>
<em>&gt; projections.
</em><br>
<p>'S' is measured with respect to signal propagation speed measured in clock
<br>
ticks, not the characteristic number of links.  Maybe I should clarify this
<br>
in the text.  Or just check out Anders Sandberg's original paper.
<br>
<p><em>&gt; &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
<em>&gt; Memory association may or may not use a &quot;compare&quot; operation (brute force
</em><br>
<em>&gt; or otherwise) of current imagery against all stored memories, but it
</em><br>
<em>&gt; seems likely that the brain uses a massively parallel algorithm at one
</em><br>
<em>&gt; point or another of its operation; memory association is simply a
</em><br>
<em>&gt; plausible candidate.
</em><br>
<em>&gt; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It seems plausible that the brain uses a resonance-like compare
</em><br>
<em>&gt; function.  Basically, a match may be recognized when a neural assembly
</em><br>
<em>&gt; finds its group-firing greatly facilitated as a result of the
</em><br>
<em>&gt; presented/remembered stimulus.  Sort of like how a glass will vibrate
</em><br>
<em>&gt; when exposed to its natural resonance frequency.
</em><br>
<p>It's easy to postulate &quot;resonance&quot;, and in fact, I actually did.  But you
<br>
have to explain the specific similarity metric, before postulating
<br>
&quot;resonance&quot; as &quot;a compare/similarity/clustering operation of some kind,
<br>
implemented on a neural substrate using feedforward and feedback
<br>
connections, and synaptic computing in those huge dendritic trees to
<br>
establish long-term potentiation with the memory's proper cues&quot; really says
<br>
anything more than &quot;a compare operation implemented in the same hardware
<br>
devoted to storing the memories&quot;; everyone knows what neural hardware looks
<br>
like.
<br>
<p><em>&gt; &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;
</em><br>
<em>&gt; The human brain's most fundamental limit is its speed.  Anything that
</em><br>
<em>&gt; happens in less than a second perforce must use less than 200 sequential
</em><br>
<em>&gt; operations, however massively parallelized.
</em><br>
<em>&gt; &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Although the simple firing of neurons represents a lot of the
</em><br>
<em>&gt; information that the brain is processing probably just as much
</em><br>
<em>&gt; information is represented in the dynamic molecular mechanisms of each
</em><br>
<em>&gt; cell.  Cells constantly change their gene expression on the order of
</em><br>
<em>&gt; minutes.  On the order of seconds in any one neuron there are probably
</em><br>
<em>&gt; dozens on interacting molecular signally cascades that are changing the
</em><br>
<em>&gt; neuron's electrophysiological behavior.
</em><br>
<p>That is correct, but the serial limiting speed is established by the fastest
<br>
process within the range of timescales.
<br>
<p><em>&gt; Actually, there is quite a collection of papers in PubMed discussing the
</em><br>
<em>&gt; evidence that the corticothalamic feedback projections play a role in
</em><br>
<em>&gt; image contrast control.
</em><br>
<p>Why do you need ten times as many reciprocal feedback connections as
<br>
feedforward connections to do contrast control?  I'm not saying that there
<br>
are no proposed explanations for the massive feedback connections or that
<br>
there are no known functions that require the neuroanatomical backlink, just
<br>
that the *massiveness* of the feedback connections has no *standard*
<br>
explanation, and the greater computational complexity of feature controller
<br>
structure relative to feature detector structure may have something to do
<br>
with it.
<br>
<p><em>&gt; It is an accepted fact that working memory, both verbal and spatial, is
</em><br>
<em>&gt; maintained by mutual stimulation between the lateral prefrontal cortex
</em><br>
<em>&gt; and certain posterior association areas:
</em><br>
<p>The existence of working memory is an accepted fact.  That working memory is
<br>
depictive is an absolutely established fact that is still not entirely
<br>
accepted in some GOFAI circles.  Whether depictive mental imagery is
<br>
governed by the concepts that appear in our internal narrative is another
<br>
fight entirely.
<br>
<p><em>&gt; I'm not sure if you mentioned it but did you know that 'verbs' seems to
</em><br>
<em>&gt; be stored in a different brain region that 'nouns'?  And that 'noun'
</em><br>
<em>&gt; storage in the brain seems to be organized in a categorized spatial
</em><br>
<em>&gt; manner?  Neat stuff eh?
</em><br>
<p>Yes, I know.  I'm afraid I didn't have room to mention, in the section on
<br>
coevolution of thought and language, how cognitive selection pressures for
<br>
different treatment of verbs and nouns based on the different perceptual
<br>
structure of verbs and nouns could be responsible for the emergent existence
<br>
of Chomskian deep grammar before its evolutionary fixation - as Terrence
<br>
Deacon points out, the evolutionary emergence of Chomskian grammar from
<br>
strictly linguistic selection pressures is a puzzle because Chomskian
<br>
grammar has so many different surface forms; you would expect purely
<br>
linguistic selection pressures to fix the computationally simpler surface
<br>
structures first.  But now I'm saying things that don't make any sense
<br>
unless you've read Deacon's &quot;The Symbolic Species&quot; as well as DGI, so I'd
<br>
better shut up.
<br>
<p><em>&gt; In your section on &quot;thought&quot; why don't you mention the cognitive
</em><br>
<em>&gt; psychology construct of &quot;working memory&quot;?  You seem to describe its two
</em><br>
<em>&gt; part structure perfectly: (1) phonological loop and (2) visuospatial
</em><br>
<em>&gt; sketchpad.
</em><br>
<p>There are a thousand things that DGI does not mention, so don't feel
<br>
slighted just because some of your favorite things were left out...  As it
<br>
happens, though, the phonological loop in working memory is just the
<br>
prefrontal refreshment of workspace in the auditory cortex - the internal
<br>
narrative may manifest in the same workspace but the phonological loop does
<br>
not in itself implement an internal narrative, otherwise tape recorders
<br>
would be sentient.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3310.html">Eliezer S. Yudkowsky: "Essay: On psychological frames of reference"</a>
<li><strong>Previous message:</strong> <a href="3308.html">Eliezer S. Yudkowsky: "Re: DGI: non-universality of codon-&gt;amino acid mapping"</a>
<li><strong>In reply to:</strong> <a href="3301.html">Ben Houston: "RE: PAPER: Levels of Organization in General Intelligence"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3324.html">Ben Houston: "RE: PAPER: Levels of Organization in General Intelligence"</a>
<li><strong>Reply:</strong> <a href="3324.html">Ben Houston: "RE: PAPER: Levels of Organization in General Intelligence"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3309">[ date ]</a>
<a href="index.html#3309">[ thread ]</a>
<a href="subject.html#3309">[ subject ]</a>
<a href="author.html#3309">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
