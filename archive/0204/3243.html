<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Deadly Sins of Real AI</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="RE: Deadly Sins of Real AI">
<meta name="Date" content="2002-04-02">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Deadly Sins of Real AI</h1>
<!-- received="Wed Apr 03 01:16:21 2002" -->
<!-- isoreceived="20020403081621" -->
<!-- sent="Tue, 2 Apr 2002 22:48:29 -0700" -->
<!-- isosent="20020403054829" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="RE: Deadly Sins of Real AI" -->
<!-- id="LAEGJLOGJIOELPNIOOAJMEIECFAA.ben@goertzel.org" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3CAA6906.A5091447@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=RE:%20Deadly%20Sins%20of%20Real%20AI"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Tue Apr 02 2002 - 22:48:29 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3244.html">Gordon Worley: "Re: AI and survival instinct."</a>
<li><strong>Previous message:</strong> <a href="3242.html">Ben Goertzel: "RE: AI and survival instinct."</a>
<li><strong>In reply to:</strong> <a href="3234.html">Eliezer S. Yudkowsky: "Re: Deadly Sins of Real AI"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3243">[ date ]</a>
<a href="index.html#3243">[ thread ]</a>
<a href="subject.html#3243">[ subject ]</a>
<a href="author.html#3243">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
hey there Eliezer...
<br>
<p><em>&gt; Are you sure you really mean &quot;human-equivalent&quot; in the paragraph
</em><br>
<em>&gt; above?
</em><br>
...
<br>
<em>&gt; When you say &quot;human-equivalent&quot; in
</em><br>
<em>&gt; your original statement, do you mean what I would call &quot;infrahuman&quot;, i.e.,
</em><br>
<em>&gt; intelligence of roughly the same character but substantially inferior in
</em><br>
<em>&gt; terms of actual capabilities?
</em><br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;I meant what I said
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;And I said what I meant
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;An elephant's faithful,
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;One hundred percent!&quot;
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-- Dr. Seuss
<br>
<p><em>&gt; It actually goes up from here to &quot;superintelligence&quot; and &quot;Power&quot;, but who
</em><br>
<em>&gt; cares.
</em><br>
<p>Ummm... George W. Bush ???
<br>
<p>Alfred E. Neumann???
<br>
<p>You tell me...
<br>
<p><em>&gt;Anyway, I would expect first steps toward seed AI to
</em><br>
<em>&gt; become possible
</em><br>
<em>&gt; at the prehuman or infrahuman level, depending on the approach
</em><br>
<em>&gt; and the kind
</em><br>
<em>&gt; of self-improvement being attempted.
</em><br>
<p>I am not sure exactly what you mean by &quot;first steps toward seed AI.&quot;  I
<br>
guess the first one-celled biological organism was a first step toward seed
<br>
AI, in a sense....  Or was it the Big Bang??
<br>
<p>I think that human-equivalent (and yes, I mean that!) AI will be
<br>
prerequisite for significant self-modification of cognitive algorithms and
<br>
data structures to occur.
<br>
<p>I think that this kind of self-modification will require mastery of advanced
<br>
math and computer science, which will probably be learned by an AI most
<br>
easily through communication with humans and through reading of human
<br>
research papers.  And talking to humans about advanced math and CS, or
<br>
reading the Communications of the ACM, seems to me like it'll require
<br>
roughly human-equivalent intelligence.
<br>
<p>Neither of my dogs is much good at reading the Communications of the ACM,
<br>
anyway, although they (idiotic as they are) arguably have greater general
<br>
intelligent than Deep Blue....
<br>
<p>Sometime in the next few weeks I'll be writing a paper on the current state
<br>
of automated global program optimization.  (I'm consulting for
<br>
Supercompilers LLC, a startup firm that's making a Java supercompiler.)
<br>
I'll post a link to it here, when I do.  Looking at this work, concretely,
<br>
has given me a pretty concrete sense of what's going to be required to get
<br>
strong self-modification to work.  I don't think an infrahuman AI is gonna
<br>
be able to do it.
<br>
<p>Of course, my intuition could well be wrong on this point -- it's just an
<br>
intuition....
<br>
<p><p>-- Ben G
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3244.html">Gordon Worley: "Re: AI and survival instinct."</a>
<li><strong>Previous message:</strong> <a href="3242.html">Ben Goertzel: "RE: AI and survival instinct."</a>
<li><strong>In reply to:</strong> <a href="3234.html">Eliezer S. Yudkowsky: "Re: Deadly Sins of Real AI"</a>
<!-- nextthread="start" -->
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3243">[ date ]</a>
<a href="index.html#3243">[ thread ]</a>
<a href="subject.html#3243">[ subject ]</a>
<a href="author.html#3243">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:38 MDT
</em></small></p>
</body>
</html>
