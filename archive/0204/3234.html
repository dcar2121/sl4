<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Deadly Sins of Real AI</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Deadly Sins of Real AI">
<meta name="Date" content="2002-04-02">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Deadly Sins of Real AI</h1>
<!-- received="Tue Apr 02 21:46:21 2002" -->
<!-- isoreceived="20020403044621" -->
<!-- sent="Tue, 02 Apr 2002 21:29:26 -0500" -->
<!-- isosent="20020403022926" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Deadly Sins of Real AI" -->
<!-- id="3CAA6906.A5091447@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="01C1DA29.128169F0.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Deadly%20Sins%20of%20Real%20AI"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Tue Apr 02 2002 - 19:29:26 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3235.html">James Rogers: "Re: Simplifying AI"</a>
<li><strong>Previous message:</strong> <a href="3233.html">Doug Keenan: "Bad link"</a>
<li><strong>In reply to:</strong> <a href="3225.html">ben goertzel: "Deadly Sins of Real AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3243.html">Ben Goertzel: "RE: Deadly Sins of Real AI"</a>
<li><strong>Reply:</strong> <a href="3243.html">Ben Goertzel: "RE: Deadly Sins of Real AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3234">[ date ]</a>
<a href="index.html#3234">[ thread ]</a>
<a href="subject.html#3234">[ subject ]</a>
<a href="author.html#3234">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
ben goertzel wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; I think that I have clarified my goals for you many times.  First a
</em><br>
<em>&gt; roughly-human-equivalent intelligence that can be taught and conversed
</em><br>
<em>&gt; with, then (growing out of this) a self-modifying intelligence that can
</em><br>
<em>&gt; bootstrap its way to tremendously superhuman intelligence.  If successful,
</em><br>
<em>&gt; this will lead either to the Singularity or -- perhaps, I hope not! -- to a
</em><br>
<em>&gt; system that understands the hidden obstacles to the Singularity that we
</em><br>
<em>&gt; stupid humans are missing...
</em><br>
<p>Are you sure you really mean &quot;human-equivalent&quot; in the paragraph above?  As
<br>
you know, I've spent some time thinking about epochs in AI intelligence, and
<br>
I would suggest the following terminology:
<br>
<p>&nbsp;&nbsp;Tool-level AI:  The AI's behaviors are immediately and 
<br>
directly specified by the programmers, or the AI &quot;learns&quot; 
<br>
in a single domain using prespecified learning algorithms.
<br>
<p>&nbsp;&nbsp;Prehuman AI:  The AI's intelligence is not a significant 
<br>
subset of human intelligence.  Nonetheless, the AI is a 
<br>
cognitive supersystem, with some subsystems we would 
<br>
recognize, and at least some mind-like behaviors.  (A 
<br>
toaster oven does not qualify as a &quot;prehuman chef&quot;; a 
<br>
general kitchen robot might do so.)
<br>
<p>&nbsp;&nbsp;Infrahuman AI:  The AI's intelligence is, overall, of the 
<br>
same basic character as human intelligence, but 
<br>
substantially inferior.  The AI may excel in a few domains 
<br>
where it possesses new sensory modalities or other 
<br>
brainware advantages not available to humans.  Humans 
<br>
talking to the AI usually recognize a mind on the other 
<br>
end.  (An AI that lacks the ability to communicate and 
<br>
model external minds does not yet qualify as infrahuman.)
<br>
<p>&nbsp;&nbsp;Near-human AI, human-equivalent AI:  The AI's 
<br>
intelligence is in the rough neigborhood of a human's.  It 
<br>
may be locally inferior or superior in various domains, 
<br>
but general intelligence, reasoning ability, and learning 
<br>
ability are roughly that of a human.
<br>
<p>&nbsp;&nbsp;Transhumanity.  &quot;Weak&quot; transhumanity is intelligence which 
<br>
reasons like a human but at a much higher speed.  &quot;Strong&quot;
<br>
transhumanity implies greater functional complexity and 
<br>
the ability to think thoughts uninventable by humans or 
<br>
manipulate concepts which are humanly incomprehensible.
<br>
<p>It actually goes up from here to &quot;superintelligence&quot; and &quot;Power&quot;, but who
<br>
cares.  Anyway, I would expect first steps toward seed AI to become possible
<br>
at the prehuman or infrahuman level, depending on the approach and the kind
<br>
of self-improvement being attempted.  When you say &quot;human-equivalent&quot; in
<br>
your original statement, do you mean what I would call &quot;infrahuman&quot;, i.e.,
<br>
intelligence of roughly the same character but substantially inferior in
<br>
terms of actual capabilities?
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3235.html">James Rogers: "Re: Simplifying AI"</a>
<li><strong>Previous message:</strong> <a href="3233.html">Doug Keenan: "Bad link"</a>
<li><strong>In reply to:</strong> <a href="3225.html">ben goertzel: "Deadly Sins of Real AI"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3243.html">Ben Goertzel: "RE: Deadly Sins of Real AI"</a>
<li><strong>Reply:</strong> <a href="3243.html">Ben Goertzel: "RE: Deadly Sins of Real AI"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3234">[ date ]</a>
<a href="index.html#3234">[ thread ]</a>
<a href="subject.html#3234">[ subject ]</a>
<a href="author.html#3234">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
