<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: [sl4] Re: A hypothesis for what our world might simulate</title>
<meta name="Author" content="Aleksei Riikonen (aleksei@iki.fi)">
<meta name="Subject" content="[sl4] Re: A hypothesis for what our world might simulate">
<meta name="Date" content="2009-01-12">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>[sl4] Re: A hypothesis for what our world might simulate</h1>
<!-- received="Mon Jan 12 19:13:32 2009" -->
<!-- isoreceived="20090113021332" -->
<!-- sent="Tue, 13 Jan 2009 04:13:25 +0200" -->
<!-- isosent="20090113021325" -->
<!-- name="Aleksei Riikonen" -->
<!-- email="aleksei@iki.fi" -->
<!-- subject="[sl4] Re: A hypothesis for what our world might simulate" -->
<!-- id="1db0b2da0901121813p3fa37effqbda3e6eab8ff968d@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="b54769d90901121338p10befd02t97a23b3f79ef5f30@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Aleksei Riikonen (<a href="mailto:aleksei@iki.fi?Subject=Re:%20[sl4]%20Re:%20A%20hypothesis%20for%20what%20our%20world%20might%20simulate"><em>aleksei@iki.fi</em></a>)<br>
<strong>Date:</strong> Mon Jan 12 2009 - 19:13:25 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="19735.html">J. Andrew Rogers: "Re: [sl4] A hypothesis for what our world might simulate"</a>
<li><strong>Previous message:</strong> <a href="19733.html">Krekoski Ross: "Re: [sl4] A hypothesis for what our world might simulate"</a>
<li><strong>In reply to:</strong> <a href="19730.html">Vladimir Nesov: "Re: [sl4] A hypothesis for what our world might simulate"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19731.html">Charles Hixson: "Re: [sl4] A hypothesis for what our world might simulate"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19734">[ date ]</a>
<a href="index.html#19734">[ thread ]</a>
<a href="subject.html#19734">[ subject ]</a>
<a href="author.html#19734">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On Mon, Jan 12, 2009 at 11:38 PM, Vladimir Nesov &lt;<a href="mailto:robotact@gmail.com?Subject=Re:%20[sl4]%20Re:%20A%20hypothesis%20for%20what%20our%20world%20might%20simulate">robotact@gmail.com</a>&gt; wrote:
<br>
<em>&gt; On Mon, Jan 12, 2009 at 5:26 PM, Aleksei Riikonen &lt;<a href="mailto:aleksei@iki.fi?Subject=Re:%20[sl4]%20Re:%20A%20hypothesis%20for%20what%20our%20world%20might%20simulate">aleksei@iki.fi</a>&gt; wrote:
</em><br>
<em>&gt;
</em><br>
<em>&gt;&gt; Suppose that we don't really learn how to build FAI before we learn
</em><br>
<em>&gt;&gt; e.g. to scan human brains and construct simulated humans in simulated
</em><br>
<em>&gt;&gt; universes that we can run at huge subjective speedups.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; What would be the safest (realistic) thing to do?
</em><br>
<em>&gt;
</em><br>
<em>&gt; Use hierarchies of communicating simulated Friendly AI programmers to
</em><br>
<em>&gt; optimize reliability of FAI design they create, peer-reviewing the
</em><br>
<em>&gt; theoretical and early experimental work between groups composed of
</em><br>
<em>&gt; different combinations of selected individuals running for
</em><br>
<em>&gt; considerable subjective time. Bootstrap implementation of FAI from
</em><br>
<em>&gt; this system, including nested simulated worlds in which AI is to start
</em><br>
<em>&gt; growing.
</em><br>
<p>I like that answer. Seems strictly superior to what I came up with.
<br>
Anyone have criticism for this answer?
<br>
<p>Could we say that we have a solution for FAI in this answer; a
<br>
successful strategy that can be implemented if only we can buy enough
<br>
time by preventing anyone from launching non-FAIs before such a
<br>
project can complete?
<br>
<p><p>On Mon, Jan 12, 2009 at 11:36 PM, Charles Hixson
<br>
&lt;<a href="mailto:charleshixsn@earthlink.net?Subject=Re:%20[sl4]%20Re:%20A%20hypothesis%20for%20what%20our%20world%20might%20simulate">charleshixsn@earthlink.net</a>&gt; wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; That does seem like a good reason to run the simulations, but you are
</em><br>
<em>&gt; assuming that the person in charge is a good guy who can be trusted with
</em><br>
<em>&gt; that kind of power, in which case why not use him as your first upload?
</em><br>
<em>&gt;  Given human political organization the only things that keep the
</em><br>
<em>&gt; power-hungry psychopaths from scrambling to be an upload are:
</em><br>
<em>&gt; 1)  They wouldn't see the upload as themself, and neither would the upload
</em><br>
<em>&gt; see itself as them.
</em><br>
<em>&gt; 2)  They don't believe it's possible anyway.
</em><br>
<em>&gt; 3)  They don't understand the amount of power that a computer running the
</em><br>
<em>&gt; country (under nominal external direction) would have.
</em><br>
<em>&gt;
</em><br>
<em>&gt; If such a thing happens, and we're very lucky, the first upload will be
</em><br>
<em>&gt; someone like Craig Ventner.  He's an egomaniac, but not a psychopath.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Simulations as you propose would be a good rational solution.  I just don't
</em><br>
<em>&gt; see them as the kind of thing our political systems are good at achieving.
</em><br>
<p>I think smart power-hungry psychopaths might very well refrain from
<br>
scrambling to be the first upload because of the realization that if
<br>
such a scramble were to take place, they would be competing with a
<br>
substantial number of roughly equally capable individuals, and
<br>
therefore wouldn't be likely to win. Cooperation to prevent the
<br>
scramble in the first place seems like the more rational solution, and
<br>
the choice the smartest ones would make (whether psychopathic or not).
<br>
Their coalition could then prevent the less smart psychopaths from
<br>
acquiring too much power.
<br>
<p><pre>
-- 
Aleksei Riikonen - <a href="http://www.iki.fi/aleksei">http://www.iki.fi/aleksei</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="19735.html">J. Andrew Rogers: "Re: [sl4] A hypothesis for what our world might simulate"</a>
<li><strong>Previous message:</strong> <a href="19733.html">Krekoski Ross: "Re: [sl4] A hypothesis for what our world might simulate"</a>
<li><strong>In reply to:</strong> <a href="19730.html">Vladimir Nesov: "Re: [sl4] A hypothesis for what our world might simulate"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="19731.html">Charles Hixson: "Re: [sl4] A hypothesis for what our world might simulate"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#19734">[ date ]</a>
<a href="index.html#19734">[ thread ]</a>
<a href="subject.html#19734">[ subject ]</a>
<a href="author.html#19734">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:01:03 MDT
</em></small></p>
</body>
</html>
