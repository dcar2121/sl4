<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=Windows-1252">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Goertzel's _PtS_</title>
<meta name="Author" content="Ben Goertzel (ben@webmind.com)">
<meta name="Subject" content="RE: Goertzel's _PtS_">
<meta name="Date" content="2001-05-02">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Goertzel's _PtS_</h1>
<!-- received="Wed May 02 21:54:04 2001" -->
<!-- isoreceived="20010503035404" -->
<!-- sent="Wed, 2 May 2001 21:52:53 -0400" -->
<!-- isosent="20010503015253" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@webmind.com" -->
<!-- subject="RE: Goertzel's _PtS_" -->
<!-- id="NDBBIBGFAPPPBODIPJMMCECAFIAA.ben@webmind.com" -->
<!-- charset="Windows-1252" -->
<!-- inreplyto="3AF06985.24E4AB86@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@webmind.com?Subject=RE:%20Goertzel's%20_PtS_"><em>ben@webmind.com</em></a>)<br>
<strong>Date:</strong> Wed May 02 2001 - 19:52:53 MDT
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="1323.html">Eliezer S. Yudkowsky: "Re: Goertzel's _PtS_"</a>
<li><strong>Previous message:</strong> <a href="1321.html">Eliezer S. Yudkowsky: "Goertzel's _PtS_"</a>
<li><strong>In reply to:</strong> <a href="1321.html">Eliezer S. Yudkowsky: "Goertzel's _PtS_"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1323.html">Eliezer S. Yudkowsky: "Re: Goertzel's _PtS_"</a>
<li><strong>Reply:</strong> <a href="1323.html">Eliezer S. Yudkowsky: "Re: Goertzel's _PtS_"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1322">[ date ]</a>
<a href="index.html#1322">[ thread ]</a>
<a href="subject.html#1322">[ subject ]</a>
<a href="author.html#1322">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
hi,
<br>
<p><em>&gt; &gt; the notion of Friendly AI – the creation of AI systems that, as they
</em><br>
<em>&gt; &gt; rewrite their own source code achieving progressively greater and
</em><br>
<em>&gt; &gt; greater intelligence, leave invariant the portion of their code
</em><br>
<em>&gt; &gt; requiring them to be friendly to human beings
</em><br>
<em>&gt;
</em><br>
<em>&gt; No offense - but no, *no*, NO, *NO*!
</em><br>
<em>&gt;
</em><br>
<p>Clearly we still have a lot to talk about here.  Sorry if I misrepresented
<br>
your views, it wasn't intentional.
<br>
<p>I don't have time to carry out this argument in 100% adequate detail right
<br>
now, because I'm going to Norway tomorrow to beg for $$ from some VC's there
<br>
;&gt;   But hopefully over the weekend I'll find time to write that essay on
<br>
the logic of Friendliness that I keep wanting to write, which will explain
<br>
what I mean by &quot;invariants&quot; and so forth...
<br>
<p>Anyway, I'll make a few comments...
<br>
<p><em>&gt; Point the 1st:  Friendliness is not, and cannot, be implemented on the
</em><br>
<em>&gt; level of source code.  Friendliness is cognitive content.
</em><br>
<p>Sure, but source code can bias the system in favor of certain cognitive
<br>
content
<br>
<p><em>&gt; Point the 2nd:  Friendliness is not a &quot;portion&quot; which &quot;requires&quot; an AI to
</em><br>
<em>&gt; be friendly to humans.  Friendliness is not an add-on or a plug-in.
</em><br>
<em>&gt; Friendliness is the whole of the goal system.  It is what the AI wants to
</em><br>
<em>&gt; do.
</em><br>
<p>I continue not to believe that Friendliness can viably be made &quot;the whole of
<br>
the goal system.&quot;  I'll clarify this point in my systematic write-up when I
<br>
get to it.  Logically, sure you CAN view any other worthy goal as a subgoal
<br>
of Friendliness, but I continue to believe this is a sufficiently awkward
<br>
way to manage other goals, that it's not a workable way for a mind to
<br>
function.
<br>
<p><em>&gt; Point the 3rd:  Friendliness is not &quot;invariant&quot; - a strange term to use
</em><br>
<em>&gt; for a system one of whose first and foremost recommendations is that
</em><br>
<em>&gt; supergoals should be probabilistic!
</em><br>
<p>What I meant is, as the system rewrites its own code, the fact of its
<br>
Friendliness is supposed to remain unchanged.  The specific content
<br>
underlying this Friendliness may of course change.  Mathematically, one
<br>
might say that the class of Friendly mind-states is supposed to be an
<br>
probabilistically almost-invariant subspace of the class of all mind-states.
<br>
<p><em>&gt; Friendliness can't be ensured by creating an enslaved AI that lacks the
</em><br>
<em>&gt; capability to alter the goal system; Friendliness is ensured by creating a
</em><br>
<em>&gt; Friendly AI that doesn't *want* to stop being Friendly, just as I don't
</em><br>
<em>&gt; want to stop being a nice person.
</em><br>
<p>OK, we agree there.  I guess we just disagree on how to build the goal
<br>
system.
<br>
<p><em>&gt; Point the 4th:  Friendliness is not &quot;hardwired&quot;, a term which I've seen
</em><br>
<em>&gt; you use several times.
</em><br>
<p>What I mean by &quot;hard-wiring Friendliness&quot; is placing Friendliness at the top
<br>
of the initial goal system and making the system express all other goals as
<br>
subgoals of this.  Is this not what you propose?  I thought that's what you
<br>
described to me in New York...
<br>
<p><p><em>&gt; The main part of the model where I disagree with you is that it'll take a
</em><br>
<em>&gt; lot more than a Java supercompiler description to give a general
</em><br>
<em>&gt; intelligence humanlike understanding of source code.  The Java
</em><br>
<em>&gt; supercompiler description is only the very first step.
</em><br>
<p>I agree there.  But I tend to think that if you put that first step together
<br>
with WM's higher-order inference engine, the second step will come all by
<br>
itself.
<br>
<p><em>&gt; What I'm saying is that *when the system reaches human intelligence*, it
</em><br>
<em>&gt; will probably be *in the middle of a hard takeoff*
</em><br>
<p>And this is another point on which our intuitions differ.  I think that
<br>
human-level intelligence will probably be achieved significantly **before**
<br>
a hard takeoff.  I think that optimizing your own mind processes requires
<br>
human-level intelligence or maybe a little more.
<br>
<p>We don't really disagree very profoundly; most of our disagreements are just
<br>
different intuitions about timings of things that none of us really has data
<br>
about.  The most significant difference I see is as to whether, initially,
<br>
one wants to rig a goal system with Friendliness at the top....
<br>
<p>ben
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="1323.html">Eliezer S. Yudkowsky: "Re: Goertzel's _PtS_"</a>
<li><strong>Previous message:</strong> <a href="1321.html">Eliezer S. Yudkowsky: "Goertzel's _PtS_"</a>
<li><strong>In reply to:</strong> <a href="1321.html">Eliezer S. Yudkowsky: "Goertzel's _PtS_"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="1323.html">Eliezer S. Yudkowsky: "Re: Goertzel's _PtS_"</a>
<li><strong>Reply:</strong> <a href="1323.html">Eliezer S. Yudkowsky: "Re: Goertzel's _PtS_"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#1322">[ date ]</a>
<a href="index.html#1322">[ thread ]</a>
<a href="subject.html#1322">[ subject ]</a>
<a href="author.html#1322">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:36 MDT
</em></small></p>
</body>
</html>
