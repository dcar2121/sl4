<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: guaranteeing friendliness</title>
<meta name="Author" content="H C (lphege@hotmail.com)">
<meta name="Subject" content="Re: guaranteeing friendliness">
<meta name="Date" content="2005-11-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: guaranteeing friendliness</h1>
<!-- received="Tue Nov 29 00:08:16 2005" -->
<!-- isoreceived="20051129070816" -->
<!-- sent="Tue, 29 Nov 2005 07:08:13 +0000" -->
<!-- isosent="20051129070813" -->
<!-- name="H C" -->
<!-- email="lphege@hotmail.com" -->
<!-- subject="Re: guaranteeing friendliness" -->
<!-- id="BAY101-F39D57C7E8CBC9880029399DC4B0@phx.gbl" -->
<!-- inreplyto="438887E4.8070402@pobox.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> H C (<a href="mailto:lphege@hotmail.com?Subject=Re:%20guaranteeing%20friendliness"><em>lphege@hotmail.com</em></a>)<br>
<strong>Date:</strong> Tue Nov 29 2005 - 00:08:13 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12966.html">Robin Lee Powell: "Re: guaranteeing friendliness"</a>
<li><strong>Previous message:</strong> <a href="12964.html">Anthony Mak: "Deontic logic any use?"</a>
<li><strong>In reply to:</strong> <a href="12946.html">Eliezer S. Yudkowsky: "Re: guaranteeing friendliness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12966.html">Robin Lee Powell: "Re: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12966.html">Robin Lee Powell: "Re: guaranteeing friendliness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12965">[ date ]</a>
<a href="index.html#12965">[ thread ]</a>
<a href="subject.html#12965">[ subject ]</a>
<a href="author.html#12965">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt;From: &quot;Eliezer S. Yudkowsky&quot; &lt;<a href="mailto:sentience@pobox.com?Subject=Re:%20guaranteeing%20friendliness">sentience@pobox.com</a>&gt;
</em><br>
<em>&gt;Reply-To: <a href="mailto:sl4@sl4.org?Subject=Re:%20guaranteeing%20friendliness">sl4@sl4.org</a>
</em><br>
<em>&gt;To: <a href="mailto:sl4@sl4.org?Subject=Re:%20guaranteeing%20friendliness">sl4@sl4.org</a>
</em><br>
<em>&gt;Subject: Re: guaranteeing friendliness
</em><br>
<em>&gt;Date: Sat, 26 Nov 2005 08:05:56 -0800
</em><br>
<em>&gt;
</em><br>
<em>&gt;Chris Capel wrote:
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;My understanding of where Phillip was going is that the techniques
</em><br>
<em>&gt;&gt;used to provide some measure of certainty about the direction the
</em><br>
<em>&gt;&gt;world climate is moving, if developed, would have a lot of
</em><br>
<em>&gt;&gt;resemblances to the sort of guarantee that Eliezer is trying to
</em><br>
<em>&gt;&gt;develop with friendliness. It would have to take a very complicated
</em><br>
<em>&gt;&gt;system, with lots of unknowns, and try to derive statistically certain
</em><br>
<em>&gt;&gt;conclusions about the long-term direction of those systems that we can
</em><br>
<em>&gt;&gt;be justified in believing are valid and immune to unintentional
</em><br>
<em>&gt;&gt;manipulation by the modeler and verifiable in some formal capacity.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Not so.  A FAI is *designed* to be verifiably predictably Friendly and not 
</em><br>
<em>&gt;in a statistical sense either.  The global warming dynamics are not thus 
</em><br>
<em>&gt;designed.  If we have to have controversial arguments about whether some 
</em><br>
<em>&gt;specific FAI design is Friendly in the technical sense, arguments like 
</em><br>
<em>&gt;we're having about global warming, then screw the design, come up with a 
</em><br>
<em>&gt;better one.
</em><br>
<em>&gt;
</em><br>
<em>&gt;As I recently said on wta-talk to James Hughes's proposal for &quot;morality 
</em><br>
<em>&gt;software&quot; for humans:
</em><br>
<em>&gt;
</em><br>
<em>&gt;**
</em><br>
<em>&gt;
</em><br>
<em>&gt;There's a theorem generalizing Turing's halting theorem, Rice's Theorem, 
</em><br>
<em>&gt;which says that you cannot *in general* determine whether a computational 
</em><br>
<em>&gt;process implements *any* nontrivial function - including, say, 
</em><br>
<em>&gt;multiplication.  Then how is it possible that human engineers build 
</em><br>
<em>&gt;computer chips which reliably perform multiplication?  Computer engineers 
</em><br>
<em>&gt;build special cases of chips, *not* chips in general.  They deliberately 
</em><br>
<em>&gt;use only those designs that they *can* understand.  They select an 
</em><br>
<em>&gt;architecture of which they can predict - and in some cases, formally prove 
</em><br>
<em>&gt;- that the chip design implements multiplication.
</em><br>
<em>&gt;
</em><br>
<em>&gt;SIAI's notion of Friendliness assurance relies on being able to design an 
</em><br>
<em>&gt;AI specifically for the sake of verifiability.  Needless to say, humans are 
</em><br>
<em>&gt;not so designed.  Needless to say, it is not a trivial project to thus 
</em><br>
<em>&gt;redesign a human.  I cannot imagine going about it in such way as to 
</em><br>
<em>&gt;preserve continuity of personal identity, the overall human cognitive 
</em><br>
<em>&gt;architecture, or much of anything.  SIAI's notion of Friendliness relies on 
</em><br>
<em>&gt;selecting an AI design of which we can verifiably say that it would never 
</em><br>
<em>&gt;choose to expend effort on defeating its own Friendliness.  As opposed to 
</em><br>
<em>&gt;superposing external &quot;morality software&quot; onto a mind that might not like 
</em><br>
<em>&gt;it, or a mind that might plan in advance to defeat it.
</em><br>
<em>&gt;
</em><br>
<em>&gt;--
</em><br>
<em>&gt;Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
</em><br>
<em>&gt;Research Fellow, Singularity Institute for Artificial Intelligence
</em><br>
<p><p>It's not so rediculous as it sounds.
<br>
<p>For example, provide an AGI with some sort of virtual environment, in which 
<br>
it is indirectly capable of action.
<br>
<p>It's direct actions would be in text only direct action area (imagine it's 
<br>
only direct actions being typing a letter on the keyboard, such as in a text 
<br>
editor).
<br>
<p>The only *effective* actions (outside of this text only direct action area) 
<br>
are those in proper syntatical format; specifically, it would essentially 
<br>
have to write an algorithm in some computer language in order to establish 
<br>
any effectual action in its environment.
<br>
<p>Then, before the compiled function or algorithm is executed, it must be 
<br>
reviewed by some human programming team.
<br>
<p>This could be carried much further, such humans could subjectively reject 
<br>
any algorithm, and even leave comments for the AGI to review in order for it 
<br>
to understand why its action was rejected (ex. confusing, incorrect syntax, 
<br>
difficult to understand, not sure of intention, not enough comments in code, 
<br>
etc).
<br>
<p>This would provide a perfectly controlled environment in which all the AGI's 
<br>
motivations, thoughts, and attempted and succesfull actions would be 
<br>
verifiably thoroughly understood by some human team. After a little practice 
<br>
with the AGI, the human team could (quite concievably) create several 
<br>
different tests that verify exactly the AGI's basic sentient drives, it's 
<br>
true motivations, etc.
<br>
<p>--Th3Hegem0n
<br>
<a href="http://smarterhippie.blogspot.com">http://smarterhippie.blogspot.com</a>
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12966.html">Robin Lee Powell: "Re: guaranteeing friendliness"</a>
<li><strong>Previous message:</strong> <a href="12964.html">Anthony Mak: "Deontic logic any use?"</a>
<li><strong>In reply to:</strong> <a href="12946.html">Eliezer S. Yudkowsky: "Re: guaranteeing friendliness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12966.html">Robin Lee Powell: "Re: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12966.html">Robin Lee Powell: "Re: guaranteeing friendliness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12965">[ date ]</a>
<a href="index.html#12965">[ thread ]</a>
<a href="subject.html#12965">[ subject ]</a>
<a href="author.html#12965">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:53 MDT
</em></small></p>
</body>
</html>
