<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: guaranteeing friendliness</title>
<meta name="Author" content="H C (lphege@hotmail.com)">
<meta name="Subject" content="RE: guaranteeing friendliness">
<meta name="Date" content="2005-11-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: guaranteeing friendliness</h1>
<!-- received="Wed Nov 30 16:02:03 2005" -->
<!-- isoreceived="20051130230203" -->
<!-- sent="Wed, 30 Nov 2005 23:02:00 +0000" -->
<!-- isosent="20051130230200" -->
<!-- name="H C" -->
<!-- email="lphege@hotmail.com" -->
<!-- subject="RE: guaranteeing friendliness" -->
<!-- id="BAY101-F6E0B9BB5C7499C6F87757DC4A0@phx.gbl" -->
<!-- inreplyto="EIQSG19-0008J4-P0@mail2.learnquick.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> H C (<a href="mailto:lphege@hotmail.com?Subject=RE:%20guaranteeing%20friendliness"><em>lphege@hotmail.com</em></a>)<br>
<strong>Date:</strong> Wed Nov 30 2005 - 16:02:00 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12983.html">Marc Geddes: "Cultishness as a high-entropy state"</a>
<li><strong>Previous message:</strong> <a href="12981.html">H C: "Re: guaranteeing friendliness"</a>
<li><strong>In reply to:</strong> <a href="12979.html">Herb Martin: "RE: guaranteeing friendliness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12984.html">Herb Martin: "RE: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12984.html">Herb Martin: "RE: guaranteeing friendliness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12982">[ date ]</a>
<a href="index.html#12982">[ thread ]</a>
<a href="subject.html#12982">[ subject ]</a>
<a href="author.html#12982">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
&quot;By the way, I believe that we will create friendly AI, but
<br>
we will also (eventually) create unfriendly AI, either by
<br>
accident or by design.  &quot;
<br>
<p><p>I'm just curious where you came up with that.
<br>
<p><p>By my understanding, these two are mutually exclusive... in the sense that 
<br>
if you actually create an FAI, it will quickly ensure that nobody create a 
<br>
UFAI (major existential risk), and if you create a UFAI first, then that 
<br>
tends to imply humans are, well, screwed.
<br>
<p><p>Th3Hegem0n
<br>
<p><p><p><p><em>&gt;From: &quot;Herb Martin&quot; &lt;<a href="mailto:HerbM@LearnQuick.Com?Subject=RE:%20guaranteeing%20friendliness">HerbM@LearnQuick.Com</a>&gt;
</em><br>
<em>&gt;Reply-To: <a href="mailto:sl4@sl4.org?Subject=RE:%20guaranteeing%20friendliness">sl4@sl4.org</a>
</em><br>
<em>&gt;To: &lt;<a href="mailto:sl4@sl4.org?Subject=RE:%20guaranteeing%20friendliness">sl4@sl4.org</a>&gt;
</em><br>
<em>&gt;Subject: RE: guaranteeing friendliness
</em><br>
<em>&gt;Date: Wed, 30 Nov 2005 14:04:44 -0800
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; -----Original Message-----
</em><br>
<em>&gt; &gt; From: Christian Rovner
</em><br>
<em>&gt; &gt; To: <a href="mailto:sl4@sl4.org?Subject=RE:%20guaranteeing%20friendliness">sl4@sl4.org</a>
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Richard Loosemore wrote:
</em><br>
<em>&gt; &gt; &gt;
</em><br>
<em>&gt; &gt; &gt; I repeat:  why is extreme smartness capable of extreme persuasion?
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; Persuasion is a special case of reality-optimization (aka
</em><br>
<em>&gt; &gt; goal-achieving).
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; If you are asking why extreme smartness is capable of
</em><br>
<em>&gt; &gt; achieving goals,
</em><br>
<em>&gt; &gt; then I really don't know--otherwise I would be programming
</em><br>
<em>&gt; &gt; AI. Of couse
</em><br>
<em>&gt; &gt; this is not obvious at all.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Persuasion is a teachable skill (to human level intelligences.)
</em><br>
<em>&gt;
</em><br>
<em>&gt;Much of the information for teaching and learning this skill set
</em><br>
<em>&gt;is documented in books and online.
</em><br>
<em>&gt;
</em><br>
<em>&gt; &gt; If you are asking why extreme smartness is capable of achieving this
</em><br>
<em>&gt; &gt; kind of goal in particular, I'll ask in return: Why not? Is there
</em><br>
<em>&gt; &gt; something special about a human mind that makes it unpredictable, no
</em><br>
<em>&gt; &gt; matter how detailed and accurate a (causal) model we use?
</em><br>
<em>&gt;
</em><br>
<em>&gt;Persuasion is a &quot;statistical skill&quot; that is best applied to
</em><br>
<em>&gt;individuals by using feedback and changes in strategy based
</em><br>
<em>&gt;on reaction to previous tactics.
</em><br>
<em>&gt;
</em><br>
<em>&gt;But make no mistake, persuasion is at least as teachable as
</em><br>
<em>&gt;an athletic sport skill set -- this analogy is picked
</em><br>
<em>&gt;because if you teach boxing or basketball no technique will
</em><br>
<em>&gt;be effective against an arbitrary opponent 100% of the time,
</em><br>
<em>&gt;but improvements are real and measurable.  The same is
</em><br>
<em>&gt;true for persuasion.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Even persuasion in the mass media is usually applied (today)
</em><br>
<em>&gt;by measuring feedback and adjusting the message where feasible.
</em><br>
<em>&gt;
</em><br>
<em>&gt;It's cheaper for advertisers to target their persuasive messages
</em><br>
<em>&gt;this way than to blindly blast the same (less than optimal)
</em><br>
<em>&gt;message, unless a threshold success rate is reached without need
</em><br>
<em>&gt;for adjustment.  Those who don't reach such thresholds go out
</em><br>
<em>&gt;of business in most cases.
</em><br>
<em>&gt;
</em><br>
<em>&gt;The most surprising persuasion technique [to me] is that of
</em><br>
<em>&gt;&quot;giving a reason&quot; since it apparently does require the reason
</em><br>
<em>&gt;make much sense or even have any substance.
</em><br>
<em>&gt;
</em><br>
<em>&gt;The classic experiment was to request to be allowed to go &quot;jump
</em><br>
<em>&gt;the line&quot; at a copier using, (separately) &quot;no reason&quot;, &quot;because
</em><br>
<em>&gt;[good reason goes here]&quot;, and &quot;because I am in a hurry&quot; or
</em><br>
<em>&gt;&quot;because its important that I go first&quot; type of 'reasons'.
</em><br>
<em>&gt;
</em><br>
<em>&gt;'Reasons' worked MUCH better.  'Nothing reasons' were just about
</em><br>
<em>&gt;as effective as giving real information.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Someone mentioned hypnosis (earlier in this thread I believe),
</em><br>
<em>&gt;and this is also a teachable skill (again to human level
</em><br>
<em>&gt;intelligences.)
</em><br>
<em>&gt;
</em><br>
<em>&gt;[And lest anyone think that hypnosis is fantasy, it's
</em><br>
<em>&gt;effectiveness has been documented scientifically for
</em><br>
<em>&gt;such uses as controlling bleeding -- a quite repeatable
</em><br>
<em>&gt;and testable result.]
</em><br>
<em>&gt;
</em><br>
<em>&gt;Hypnosis CAN be used to obtain behavior against the interests
</em><br>
<em>&gt;or morals of the subject but doing so it VERY difficult and
</em><br>
<em>&gt;generally requires misrepresenting the situation rather than
</em><br>
<em>&gt;directly ordering counter-interest behavior (if one expects
</em><br>
<em>&gt;reasonably reliable results.)
</em><br>
<em>&gt;
</em><br>
<em>&gt;We cannot even guarantee our children will grow up to be
</em><br>
<em>&gt;responsible human beings.
</em><br>
<em>&gt;
</em><br>
<em>&gt;We can follow generally accepted guidelines, and teach
</em><br>
<em>&gt;our children moral or ethical behavior, but we cannot
</em><br>
<em>&gt;guarantee that behavior completely; we only know that
</em><br>
<em>&gt;generally such parenting leads to children who become
</em><br>
<em>&gt;good human beings more often than to the opposite result.
</em><br>
<em>&gt;
</em><br>
<em>&gt;It is not likely that a &quot;programmer&quot; could even review
</em><br>
<em>&gt;enough of a (truly) human level intelligence to understand
</em><br>
<em>&gt;where things go wrong.
</em><br>
<em>&gt;
</em><br>
<em>&gt;It's not possible to create bug free software; imagine
</em><br>
<em>&gt;trying to just FIND the bugs in a large program like Microsoft
</em><br>
<em>&gt;Word, or even Windows itself (and this is true for Linux too
</em><br>
<em>&gt;but notice that Linux has the advantage of Open Source which
</em><br>
<em>&gt;is precisely what you CANNOT do if you must guarantee
</em><br>
<em>&gt;friendliness which includes guaranteeing that no one modifies
</em><br>
<em>&gt;the code in unfriendly ways.)
</em><br>
<em>&gt;
</em><br>
<em>&gt;When you couple this with the likelihood that human level
</em><br>
<em>&gt;intelligence will likely have neural nets (or similar nets)
</em><br>
<em>&gt;and genetic algorithms learned through training and
</em><br>
<em>&gt;adaptation and having no direct high level language
</em><br>
<em>&gt;representation then it is unlikely that the programmer
</em><br>
<em>&gt;can either read the source code OR even review ALL of it.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Current computer programs run on hardware with approximately
</em><br>
<em>&gt;10^9 memory locations (4 x 10^9 is the current limit for most
</em><br>
<em>&gt;PCs, but most don't have all the memory that is possible nor
</em><br>
<em>&gt;can the programs use that much.)  The operating systems
</em><br>
<em>&gt;alone use around one tenth (10^8) of that and it is unlikely
</em><br>
<em>&gt;that any one programmer could review just that.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Current estimates expect that human level intelligence will
</em><br>
<em>&gt;require IN EXCESS of 10^15 memory locations -- about ten
</em><br>
<em>&gt;million times (10^7) more ( than current operating systems.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Other estimates suggest it might take a thousand or more
</em><br>
<em>&gt;time as much for such intelligence levels so it is unlikely
</em><br>
<em>&gt;that anyone could ever review such a large body of code once
</em><br>
<em>&gt;it is made self-improving.
</em><br>
<em>&gt;
</em><br>
<em>&gt;It is practically impossible to &quot;guarantee friendly behavior&quot;
</em><br>
<em>&gt;OVER TIME -- to the extent that we are successful, our guard
</em><br>
<em>&gt;will tend to drop.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Human beings are lazy -- taking security precautions against
</em><br>
<em>&gt;imaginary threats is seldom maintained.  (Part of the reason
</em><br>
<em>&gt;our current security precautions against terrorists are
</em><br>
<em>&gt;doomed to failure if we don't remove the terrorists through
</em><br>
<em>&gt;offensive and strategic actions rather than purely defensive
</em><br>
<em>&gt;methods.)
</em><br>
<em>&gt;
</em><br>
<em>&gt;No rules will be 100% safe if the program learns and adapts.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Human beings probably cannot even agree on what is friendly
</em><br>
<em>&gt;behavior -- to the religious fanatic killing you to save the
</em><br>
<em>&gt;world or praise some deity may even constitute &quot;friendly
</em><br>
<em>&gt;behavior&quot; from this world view.  Total non-interference to
</em><br>
<em>&gt;the point of allowing suicide and other self-destructive
</em><br>
<em>&gt;behavior is likely acceptable to (most) Libertarians.
</em><br>
<em>&gt;
</em><br>
<em>&gt;The point here is (of course) NOT the particular beliefs used
</em><br>
<em>&gt;as examples but the fact that different programmers could
</em><br>
<em>&gt;not even agree on correct &quot;friendly behavior&quot;.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Doctors don't always agree on the behaviors that comply with
</em><br>
<em>&gt;the Hippocratic Oath, and that one is quite straightforward
</em><br>
<em>&gt;as human creeds go.
</em><br>
<em>&gt;
</em><br>
<em>&gt;And how many people would include allowing doctors to assist
</em><br>
<em>&gt;death if it relieves greater suffering, while others would
</em><br>
<em>&gt;read &quot;Do no harm&quot; literally and insist euthanasia is ALWAYS
</em><br>
<em>&gt;wrong.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Pick any serious moral or ethical belief and you will likely
</em><br>
<em>&gt;find someone who would disagree under some particular set
</em><br>
<em>&gt;of circumstances.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Killing is not always murder (e.g., defense of a child or other
</em><br>
<em>&gt;defenseless person from the criminally violent).
</em><br>
<em>&gt;
</em><br>
<em>&gt;But, notice that a Quaker might disagree with the above
</em><br>
<em>&gt;sentence -- and do so honestly and consistently.
</em><br>
<em>&gt;
</em><br>
<em>&gt;Allowing someone to live can constitute torture.  How many
</em><br>
<em>&gt;terminal bone cancer patients are quietly helped to die?
</em><br>
<em>&gt;
</em><br>
<em>&gt;Should a truly friendly AI prevent human beings from
</em><br>
<em>&gt;engaging in ANY dangerous behavior (including passive
</em><br>
<em>&gt;or long term behavior like failure to take vitamins or
</em><br>
<em>&gt;overeating),  or should it absolutely refuse to interfere
</em><br>
<em>&gt;with self-determination to the point of allowing suicide
</em><br>
<em>&gt;and other clearly destructive behavior?
</em><br>
<em>&gt;
</em><br>
<em>&gt;Most of us would expect the answer lies somewhere between
</em><br>
<em>&gt;the two extremes but few of us could agree where that
</em><br>
<em>&gt;line lies and we HAVE HUMAN LEVEL INTELLIGENCE.
</em><br>
<em>&gt;
</em><br>
<em>&gt;We might even find that our answers to this question change
</em><br>
<em>&gt;over time or even day to day (and on an absolute basis, i.e.,
</em><br>
<em>&gt;separately from the context).
</em><br>
<em>&gt;
</em><br>
<em>&gt;By the way, I believe that we will create friendly AI, but
</em><br>
<em>&gt;we will also (eventually) create unfriendly AI, either by
</em><br>
<em>&gt;accident or by design.
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt;--
</em><br>
<em>&gt;Herb Martin
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12983.html">Marc Geddes: "Cultishness as a high-entropy state"</a>
<li><strong>Previous message:</strong> <a href="12981.html">H C: "Re: guaranteeing friendliness"</a>
<li><strong>In reply to:</strong> <a href="12979.html">Herb Martin: "RE: guaranteeing friendliness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12984.html">Herb Martin: "RE: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12984.html">Herb Martin: "RE: guaranteeing friendliness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12982">[ date ]</a>
<a href="index.html#12982">[ thread ]</a>
<a href="subject.html#12982">[ subject ]</a>
<a href="author.html#12982">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:53 MDT
</em></small></p>
</body>
</html>
