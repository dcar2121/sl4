<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: guaranteeing friendliness</title>
<meta name="Author" content="Richard Loosemore (rpwl@lightlink.com)">
<meta name="Subject" content="Re: guaranteeing friendliness">
<meta name="Date" content="2005-11-29">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: guaranteeing friendliness</h1>
<!-- received="Tue Nov 29 18:14:46 2005" -->
<!-- isoreceived="20051130011446" -->
<!-- sent="Tue, 29 Nov 2005 20:13:55 -0500" -->
<!-- isosent="20051130011355" -->
<!-- name="Richard Loosemore" -->
<!-- email="rpwl@lightlink.com" -->
<!-- subject="Re: guaranteeing friendliness" -->
<!-- id="438CFCD3.2020805@lightlink.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20051129183340.GW16858@chain.digitalkingdom.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Richard Loosemore (<a href="mailto:rpwl@lightlink.com?Subject=Re:%20guaranteeing%20friendliness"><em>rpwl@lightlink.com</em></a>)<br>
<strong>Date:</strong> Tue Nov 29 2005 - 18:13:55 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12971.html">Chris Capel: "Re: guaranteeing friendliness"</a>
<li><strong>Previous message:</strong> <a href="12969.html">John Stick: "Re: Deontic logic any use?"</a>
<li><strong>In reply to:</strong> <a href="12968.html">Robin Lee Powell: "Re: guaranteeing friendliness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12971.html">Chris Capel: "Re: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12971.html">Chris Capel: "Re: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12972.html">sam kayley: "Re: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12975.html">David Picon Alvarez: "Re: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12976.html">Christian Rovner: "Re: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12985.html">Peter de Blanc: "Re: guaranteeing friendliness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12970">[ date ]</a>
<a href="index.html#12970">[ thread ]</a>
<a href="subject.html#12970">[ subject ]</a>
<a href="author.html#12970">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
The short summary of my responses (laid out in detail below) is that you 
<br>
have only repeated your assertion that a very smart AGI would 
<br>
&quot;obviously&quot; be able to convince us to do anything it wanted.  You have 
<br>
given no reason to believe in this other than you, personally, declaring 
<br>
it to be a rejected idea.
<br>
<p>I repeat:  why is extreme smartness capable of extreme persuasion?
<br>
<p>This is not even slightly obvious.
<br>
<p><p>Richard Loosemore
<br>
<p><p><p><p><p>Robin Lee Powell wrote:
<br>
<em>&gt; On Tue, Nov 29, 2005 at 11:53:57AM -0500, Richard Loosemore wrote:
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt;Robin Lee Powell wrote:
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;On Tue, Nov 29, 2005 at 07:08:13AM +0000, H C wrote:
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;&gt;It's not so rediculous as it sounds.
</em><br>
<em>&gt;&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;&gt;For example, provide an AGI with some sort of virtual
</em><br>
<em>&gt;&gt;&gt;&gt;environment, in which it is indirectly capable of action.
</em><br>
<em>&gt;&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;&gt;It's direct actions would be in text only direct action area
</em><br>
<em>&gt;&gt;&gt;&gt;(imagine it's only direct actions being typing a letter on the
</em><br>
<em>&gt;&gt;&gt;&gt;keyboard, such as in a text editor).
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;Oh god, not again.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;I am going to address your points out of order.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;Quick tip #3: Search the archives/google for &quot;ai box&quot;.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;Myself, I am one of those people who do know about that previous
</em><br>
<em>&gt;&gt;discussion.  If there is a succinct answer to my question below,
</em><br>
<em>&gt;&gt;that was clearly outlined in the previous discussion, would you be
</em><br>
<em>&gt;&gt;able to summarize it for us?  Many thanks.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; The succinct answer is &quot;Someone only marginally smarter than most
</em><br>
<em>&gt; humans appears to be able to pretty consistently convince them to
</em><br>
<em>&gt; let the AI out.  The capabilities of something *MUCH* smarter than
</em><br>
<em>&gt; most humans should be assumed to be much greater.&quot;.
</em><br>
<p>I can't understand what you are saying here.  Who is the &quot;someone&quot; you 
<br>
are referring to, who is convincing &quot;them&quot; to let &quot;the&quot; AI out?
<br>
<p>You say that the capabilities of something much smarter than most humans 
<br>
should be assumed to be much greater.  That's like saying that because 
<br>
we are very much smarter than calculators, we should be assumed to be 
<br>
better at calculating sine functions to fifteen decimal places than they 
<br>
are.  There is no logic in this whatsoever.
<br>
<p><p><em>&gt;&gt;&gt;Quick tip #1: if it's *smarter than you*, it can convince you of
</em><br>
<em>&gt;&gt;&gt;*anything it wants*.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;I recently heard the depressing story of a British/Canadian
</em><br>
<em>&gt;&gt;worker, out in Saudi Arabia who was falsely accused of planting
</em><br>
<em>&gt;&gt;bombs that killed other British workers.  He was tortured for
</em><br>
<em>&gt;&gt;three years by Saudi intelligence officers.  My question is:  he
</em><br>
<em>&gt;&gt;was probably smarter than his torturers.  
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Really?  In what sense?  For what definition of &quot;smarter&quot;?  How do
</em><br>
<em>&gt; you know?
</em><br>
<p>I think you understand my rhetoric here.
<br>
<p><em>&gt;&gt;He *could* have been very much smarter than them.  Why did he not
</em><br>
<em>&gt;&gt;convince them to do anything that he wanted?  How much higher
</em><br>
<em>&gt;&gt;would his IQ have to have been for him to have convinced them to
</em><br>
<em>&gt;&gt;set him free?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Wow.  Who said anything about IQ?  In fact, I suspect you'll find
</em><br>
<em>&gt; that IQ above a certain point is *inversely* correlated with being
</em><br>
<em>&gt; able to convince people of things.  People with high IQ tend to have
</em><br>
<em>&gt; crappy social intelligence.
</em><br>
<em>&gt; 
</em><br>
<p>You make more unsupported assertions out of the blue.  This time about 
<br>
correlations between IQ and ability to convince people, and about 
<br>
&quot;crappy social intelligence&quot; of people with high IQ.
<br>
<p>I was trying to get at a serious point, but the point is being evaded, I 
<br>
think.
<br>
<p><p><em>&gt;&gt;More generally, could you explain why you might consider it beyond
</em><br>
<em>&gt;&gt;question that persuasiveness is an approximately monotonic
</em><br>
<em>&gt;&gt;function of intelligence?  That more smartness always means more
</em><br>
<em>&gt;&gt;persuasiveness?
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;Is it not possible that persuasiveness might flatten out after a
</em><br>
<em>&gt;&gt;while? 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; It's certainly *possible*, but you and I seem to be talking about
</em><br>
<em>&gt; different things when we say &quot;smarter&quot; in this context.  You seem to
</em><br>
<em>&gt; be talking about smarter in the way that, say, Eliezer is smarter
</em><br>
<em>&gt; than me.  I'm talking about smarter in the way that I am smarter
</em><br>
<em>&gt; than a worm, or a tree, or a rock.
</em><br>
<p>You are referring to extreme values of smartness.  I am not making any 
<br>
assumptions about how extreme the continuum of smartness might be, I am 
<br>
asking you why you assert certain facts about those extreme values.
<br>
<p><p><em>&gt; I reject pretty much categorically that a being smart enough to hold
</em><br>
<em>&gt; my entire mental state in its head could not convince me of anything
</em><br>
<em>&gt; it likes.  Further, I reject that anything much *less* smart than
</em><br>
<em>&gt; that is of any real existential threat.
</em><br>
<em>&gt; 
</em><br>
<p>So, when we focus down on the question I asked, your answer seems to be 
<br>
that you simply &quot;reject&quot; the possibility that you might be mistaken?
<br>
<p>You simply assert that if an AGI could hold your entire mental state in 
<br>
its head (what on earth does that mean, anyway?), it would obviously be 
<br>
able to convince you of anything it wanted.  Why?  There is no reasoning 
<br>
behind this assertion
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12971.html">Chris Capel: "Re: guaranteeing friendliness"</a>
<li><strong>Previous message:</strong> <a href="12969.html">John Stick: "Re: Deontic logic any use?"</a>
<li><strong>In reply to:</strong> <a href="12968.html">Robin Lee Powell: "Re: guaranteeing friendliness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12971.html">Chris Capel: "Re: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12971.html">Chris Capel: "Re: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12972.html">sam kayley: "Re: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12975.html">David Picon Alvarez: "Re: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12976.html">Christian Rovner: "Re: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12985.html">Peter de Blanc: "Re: guaranteeing friendliness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12970">[ date ]</a>
<a href="index.html#12970">[ thread ]</a>
<a href="subject.html#12970">[ subject ]</a>
<a href="author.html#12970">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:53 MDT
</em></small></p>
</body>
</html>
