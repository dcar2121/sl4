<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Cultishness as a high-entropy state</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Cultishness as a high-entropy state">
<meta name="Date" content="2005-11-26">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Cultishness as a high-entropy state</h1>
<!-- received="Sat Nov 26 09:45:32 2005" -->
<!-- isoreceived="20051126164532" -->
<!-- sent="Sat, 26 Nov 2005 08:45:31 -0800" -->
<!-- isosent="20051126164531" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Cultishness as a high-entropy state" -->
<!-- id="4388912B.6030800@pobox.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="BAY106-F2433712F21B5ACF304804BBA560@phx.gbl" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Cultishness%20as%20a%20high-entropy%20state"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Sat Nov 26 2005 - 09:45:31 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12950.html">Eliezer S. Yudkowsky: "Re: guaranteeing friendliness"</a>
<li><strong>Previous message:</strong> <a href="12948.html">Ben Goertzel: "Re: guaranteeing friendliness"</a>
<li><strong>In reply to:</strong> <a href="12943.html">Olie L: "Re: famous Eliezer, puzzle game"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12961.html">Olie L: "RE: Cultishness as a high-entropy state"</a>
<li><strong>Reply:</strong> <a href="12961.html">Olie L: "RE: Cultishness as a high-entropy state"</a>
<li><strong>Reply:</strong> <a href="12978.html">Amy Hale: "Re: Cultishness as a high-entropy state"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12949">[ date ]</a>
<a href="index.html#12949">[ thread ]</a>
<a href="subject.html#12949">[ subject ]</a>
<a href="author.html#12949">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Olie L wrote:
<br>
<em>&gt;&gt; From: &quot;David Picon Alvarez&quot; &lt;<a href="mailto:eleuteri@myrealbox.com?Subject=Re:%20Cultishness%20as%20a%20high-entropy%20state">eleuteri@myrealbox.com</a>&gt;
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; Eliezer said:
</em><br>
<em>&gt;&gt;&gt; The following is quite an interesting opinion, and it is, of
</em><br>
<em>&gt;&gt;&gt; course, your own - why preface it by attributing it to me?
</em><br>
<em>&gt;&gt; 
</em><br>
<em>&gt;&gt; I believe that this kind of thinking, the &quot;what would Eliezer do&quot; 
</em><br>
<em>&gt;&gt; thinking, no matter how well one knows Eliezer and how tractable
</em><br>
<em>&gt;&gt; Eliezer is about his thought processes, is one of the reasons why
</em><br>
<em>&gt;&gt; many people consider the SIAI and other SL4 groups as cultish.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Are you insinuating that just because I have a poster of Eliezer on
</em><br>
<em>&gt; my bedroom wall, a &quot;Yudkowski is our saviour&quot; poster in my lounge and
</em><br>
<em>&gt; a &quot;What would Eliezer do?&quot; bumper sticker, that I'm somehow
</em><br>
<em>&gt; subscribing to some sort of cult?
</em><br>
<p>I think it is important to emphasize that *every* Cause good bad or ugly 
<br>
*wants* to be a cult, in the same sense that every thermal differential 
<br>
wants to equalize itself and every computer program wants to become a 
<br>
collection of ad-hoc patches.  It's a high-entropy state into which the 
<br>
system trends, a trap laid in human psychology.  It has nothing to do 
<br>
with whether the Cause is a worthy one.  *Every* Cause wants to be a cult.
<br>
<p>If you know anything at all about cults in the real world, you know that 
<br>
transhumanism is not a cult.  Prospective transhumanists are not 
<br>
surrounded by wall-to-wall proselytizers showing perfect agreement among 
<br>
themselves.  People who join are not separated from friends and family. 
<br>
&nbsp;&nbsp;People who question the prevailing opinion are not ostracized, 
<br>
deprived of sleep or worse, or threatened with expulsion.
<br>
<p>But there's a deeper question behind this, which most people don't think 
<br>
to ask because they're too busy arguing that transhumanism is a cult or 
<br>
alternatively that transhumanism is not a cult.  *Why* isn't 
<br>
transhumanism a cult?  Why *aren't* prospective transhumanists 
<br>
surrounded by wall-to-wall proselytizers?  This is an anomaly, which 
<br>
needs to be explained.  Usually when a room full of people agree with 
<br>
each other on something, they are a lot more obnoxious.
<br>
<p>The first reason is that transhumanists tend to be recruited from the 
<br>
ranks of secular rationalists and SF fans, and we already have 
<br>
anticultish habits of thought - &quot;herding cats&quot; is the usual phrase.
<br>
<p>The second reason is that it's harder for cults to form over the 
<br>
Internet.  The wall-to-wall agreement effect is much weaker if the 
<br>
proselytizers aren't present in person, and if the recruit isn't 
<br>
separated from friends and family.
<br>
<p>The third reason is that the leading lights of transhumanism, such as 
<br>
myself in the case of Singularitarianism, know damn well that every 
<br>
Cause wants to be a cult.  We exert a continuing, deliberate effort to 
<br>
prevent transhumanism (or Singularitarianism) from becoming a cult. 
<br>
Like expending energy to keep a room refrigerated; fighting entropy 
<br>
takes work.
<br>
<p>People think of cultishness as if it were a special case, a defect of 
<br>
certain causes or certain people.  It's not.  Cultishness happens by 
<br>
default, unless you exert work to keep the Cause in an unnatural 
<br>
condition of noncultishness.
<br>
<p>What goes into this work?  Off the top of my head, here are some of the 
<br>
obvious ones:
<br>
<p>1)  Deliberately restrict the scope of the meme.  If you have ideas 
<br>
about AI, then *just* talk about AI.  Don't tell people what food to 
<br>
eat, what clothes to wear, which music to listen to, what art to view, 
<br>
who to marry, who to sleep with, who to vote for, which games to play, 
<br>
or how to live their own damn lives.
<br>
<p>2)  Exert a deliberate effort to tolerate dissent - visibly, publicly 
<br>
so.  One of the reasons Marc Geddes is still on this list is that I am 
<br>
reluctant to kick off a resident crackpot who at least knows how to 
<br>
spell and is more or less polite.  If I remove Marc Geddes, then someone 
<br>
*else* will stand out as the most disagreeable person - should I remove 
<br>
them too?  While Marc Geddes stays on the list, other people will feel 
<br>
that much more comfortable about disagreeing - there's an example to 
<br>
follow, someone who dared to disagree, who is in fact clearly an idiot, 
<br>
yet was not struck down for his sins.  Of course this does annoy the 
<br>
other readers and I did eventually have to moderate Geddes.  I worry in 
<br>
fact that transhumanists have swung too far the other way, that we no 
<br>
longer tolerate public conformity, that people are afraid to agree in 
<br>
public for fear of being labeled cultish.  And this is just as severe a 
<br>
mistake.  At least cults get things done instead of arguing endlessly - 
<br>
the wrong things, but they get them done.
<br>
<p>3)  Don't wonder what the local leading lights would say about an idea. 
<br>
&nbsp;&nbsp;Don't wonder what Transhumanism thinks of a concept, or what 
<br>
Singularitarianism has to say about it, or what SIAI's position on the 
<br>
issue is.  Ask yourself whether it's a good idea or a bad idea, and then 
<br>
speak for yourself.  How do you think I steer my own life?  Not by 
<br>
asking myself, &quot;What would Eliezer do?&quot; for that is an infinite loop.
<br>
<p>4)  Draw on the strengths of Traditional Rationalist culture.  Exerting 
<br>
a deliberate effort to tolerate dissent is just one case of this.  And: 
<br>
&nbsp;&nbsp;Attend to arguments, not to authorities; demand reasoned justification 
<br>
no matter who the speaker is.  And so on.  I don't have to explain this 
<br>
stuff, you know it already.
<br>
<p><pre>
-- 
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a>
Research Fellow, Singularity Institute for Artificial Intelligence
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12950.html">Eliezer S. Yudkowsky: "Re: guaranteeing friendliness"</a>
<li><strong>Previous message:</strong> <a href="12948.html">Ben Goertzel: "Re: guaranteeing friendliness"</a>
<li><strong>In reply to:</strong> <a href="12943.html">Olie L: "Re: famous Eliezer, puzzle game"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12961.html">Olie L: "RE: Cultishness as a high-entropy state"</a>
<li><strong>Reply:</strong> <a href="12961.html">Olie L: "RE: Cultishness as a high-entropy state"</a>
<li><strong>Reply:</strong> <a href="12978.html">Amy Hale: "Re: Cultishness as a high-entropy state"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12949">[ date ]</a>
<a href="index.html#12949">[ thread ]</a>
<a href="subject.html#12949">[ subject ]</a>
<a href="author.html#12949">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:53 MDT
</em></small></p>
</body>
</html>
