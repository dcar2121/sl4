<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: guaranteeing friendliness</title>
<meta name="Author" content="Herb Martin (HerbM@LearnQuick.Com)">
<meta name="Subject" content="RE: guaranteeing friendliness">
<meta name="Date" content="2005-11-30">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: guaranteeing friendliness</h1>
<!-- received="Wed Nov 30 15:05:01 2005" -->
<!-- isoreceived="20051130220501" -->
<!-- sent="Wed, 30 Nov 2005 14:04:44 -0800" -->
<!-- isosent="20051130220444" -->
<!-- name="Herb Martin" -->
<!-- email="HerbM@LearnQuick.Com" -->
<!-- subject="RE: guaranteeing friendliness" -->
<!-- id="EIQSG19-0008J4-P0@mail2.learnquick.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="438DA699.40708@tutopia.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Herb Martin (<a href="mailto:HerbM@LearnQuick.Com?Subject=RE:%20guaranteeing%20friendliness"><em>HerbM@LearnQuick.Com</em></a>)<br>
<strong>Date:</strong> Wed Nov 30 2005 - 15:04:44 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="12980.html">Herb Martin: "RE: guaranteeing friendliness"</a>
<li><strong>Previous message:</strong> <a href="12978.html">Amy Hale: "Re: Cultishness as a high-entropy state"</a>
<li><strong>In reply to:</strong> <a href="12976.html">Christian Rovner: "Re: guaranteeing friendliness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12982.html">H C: "RE: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12982.html">H C: "RE: guaranteeing friendliness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12979">[ date ]</a>
<a href="index.html#12979">[ thread ]</a>
<a href="subject.html#12979">[ subject ]</a>
<a href="author.html#12979">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
<em>&gt; -----Original Message-----
</em><br>
<em>&gt; From: Christian Rovner
</em><br>
<em>&gt; To: <a href="mailto:sl4@sl4.org?Subject=RE:%20guaranteeing%20friendliness">sl4@sl4.org</a>
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Richard Loosemore wrote:
</em><br>
<em>&gt; &gt; 
</em><br>
<em>&gt; &gt; I repeat:  why is extreme smartness capable of extreme persuasion?
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Persuasion is a special case of reality-optimization (aka 
</em><br>
<em>&gt; goal-achieving).
</em><br>
<em>&gt; 
</em><br>
<em>&gt; If you are asking why extreme smartness is capable of 
</em><br>
<em>&gt; achieving goals, 
</em><br>
<em>&gt; then I really don't know--otherwise I would be programming 
</em><br>
<em>&gt; AI. Of couse 
</em><br>
<em>&gt; this is not obvious at all.
</em><br>
<p>Persuasion is a teachable skill (to human level intelligences.)
<br>
<p>Much of the information for teaching and learning this skill set
<br>
is documented in books and online.
<br>
<p><em>&gt; If you are asking why extreme smartness is capable of achieving this 
</em><br>
<em>&gt; kind of goal in particular, I'll ask in return: Why not? Is there 
</em><br>
<em>&gt; something special about a human mind that makes it unpredictable, no 
</em><br>
<em>&gt; matter how detailed and accurate a (causal) model we use?
</em><br>
<p>Persuasion is a &quot;statistical skill&quot; that is best applied to 
<br>
individuals by using feedback and changes in strategy based
<br>
on reaction to previous tactics.
<br>
<p>But make no mistake, persuasion is at least as teachable as
<br>
an athletic sport skill set -- this analogy is picked 
<br>
because if you teach boxing or basketball no technique will
<br>
be effective against an arbitrary opponent 100% of the time,
<br>
but improvements are real and measurable.  The same is
<br>
true for persuasion.
<br>
<p>Even persuasion in the mass media is usually applied (today)
<br>
by measuring feedback and adjusting the message where feasible.
<br>
<p>It's cheaper for advertisers to target their persuasive messages
<br>
this way than to blindly blast the same (less than optimal)
<br>
message, unless a threshold success rate is reached without need
<br>
for adjustment.  Those who don't reach such thresholds go out 
<br>
of business in most cases.
<br>
<p>The most surprising persuasion technique [to me] is that of 
<br>
&quot;giving a reason&quot; since it apparently does require the reason 
<br>
make much sense or even have any substance.
<br>
<p>The classic experiment was to request to be allowed to go &quot;jump
<br>
the line&quot; at a copier using, (separately) &quot;no reason&quot;, &quot;because
<br>
[good reason goes here]&quot;, and &quot;because I am in a hurry&quot; or 
<br>
&quot;because its important that I go first&quot; type of 'reasons'.
<br>
<p>'Reasons' worked MUCH better.  'Nothing reasons' were just about
<br>
as effective as giving real information.
<br>
<p>Someone mentioned hypnosis (earlier in this thread I believe),
<br>
and this is also a teachable skill (again to human level 
<br>
intelligences.)
<br>
<p>[And lest anyone think that hypnosis is fantasy, it's 
<br>
effectiveness has been documented scientifically for 
<br>
such uses as controlling bleeding -- a quite repeatable
<br>
and testable result.]
<br>
<p>Hypnosis CAN be used to obtain behavior against the interests
<br>
or morals of the subject but doing so it VERY difficult and
<br>
generally requires misrepresenting the situation rather than
<br>
directly ordering counter-interest behavior (if one expects
<br>
reasonably reliable results.)
<br>
<p>We cannot even guarantee our children will grow up to be
<br>
responsible human beings.
<br>
<p>We can follow generally accepted guidelines, and teach
<br>
our children moral or ethical behavior, but we cannot
<br>
guarantee that behavior completely; we only know that 
<br>
generally such parenting leads to children who become
<br>
good human beings more often than to the opposite result.
<br>
<p>It is not likely that a &quot;programmer&quot; could even review 
<br>
enough of a (truly) human level intelligence to understand 
<br>
where things go wrong.
<br>
<p>It's not possible to create bug free software; imagine
<br>
trying to just FIND the bugs in a large program like Microsoft
<br>
Word, or even Windows itself (and this is true for Linux too
<br>
but notice that Linux has the advantage of Open Source which
<br>
is precisely what you CANNOT do if you must guarantee 
<br>
friendliness which includes guaranteeing that no one modifies
<br>
the code in unfriendly ways.)
<br>
<p>When you couple this with the likelihood that human level 
<br>
intelligence will likely have neural nets (or similar nets)
<br>
and genetic algorithms learned through training and 
<br>
adaptation and having no direct high level language 
<br>
representation then it is unlikely that the programmer
<br>
can either read the source code OR even review ALL of it.
<br>
<p>Current computer programs run on hardware with approximately
<br>
10^9 memory locations (4 x 10^9 is the current limit for most
<br>
PCs, but most don't have all the memory that is possible nor
<br>
can the programs use that much.)  The operating systems
<br>
alone use around one tenth (10^8) of that and it is unlikely
<br>
that any one programmer could review just that.
<br>
<p>Current estimates expect that human level intelligence will
<br>
require IN EXCESS of 10^15 memory locations -- about ten 
<br>
million times (10^7) more ( than current operating systems.
<br>
<p>Other estimates suggest it might take a thousand or more
<br>
time as much for such intelligence levels so it is unlikely
<br>
that anyone could ever review such a large body of code once
<br>
it is made self-improving.
<br>
<p>It is practically impossible to &quot;guarantee friendly behavior&quot;
<br>
OVER TIME -- to the extent that we are successful, our guard
<br>
will tend to drop.
<br>
<p>Human beings are lazy -- taking security precautions against
<br>
imaginary threats is seldom maintained.  (Part of the reason
<br>
our current security precautions against terrorists are 
<br>
doomed to failure if we don't remove the terrorists through
<br>
offensive and strategic actions rather than purely defensive
<br>
methods.)
<br>
<p>No rules will be 100% safe if the program learns and adapts.
<br>
<p>Human beings probably cannot even agree on what is friendly
<br>
behavior -- to the religious fanatic killing you to save the
<br>
world or praise some deity may even constitute &quot;friendly
<br>
behavior&quot; from this world view.  Total non-interference to
<br>
the point of allowing suicide and other self-destructive 
<br>
behavior is likely acceptable to (most) Libertarians.
<br>
<p>The point here is (of course) NOT the particular beliefs used
<br>
as examples but the fact that different programmers could
<br>
not even agree on correct &quot;friendly behavior&quot;.
<br>
<p>Doctors don't always agree on the behaviors that comply with 
<br>
the Hippocratic Oath, and that one is quite straightforward 
<br>
as human creeds go.  
<br>
<p>And how many people would include allowing doctors to assist 
<br>
death if it relieves greater suffering, while others would 
<br>
read &quot;Do no harm&quot; literally and insist euthanasia is ALWAYS 
<br>
wrong.
<br>
<p>Pick any serious moral or ethical belief and you will likely
<br>
find someone who would disagree under some particular set
<br>
of circumstances.
<br>
<p>Killing is not always murder (e.g., defense of a child or other
<br>
defenseless person from the criminally violent).
<br>
<p>But, notice that a Quaker might disagree with the above
<br>
sentence -- and do so honestly and consistently.
<br>
<p>Allowing someone to live can constitute torture.  How many
<br>
terminal bone cancer patients are quietly helped to die?
<br>
<p>Should a truly friendly AI prevent human beings from 
<br>
engaging in ANY dangerous behavior (including passive
<br>
or long term behavior like failure to take vitamins or
<br>
overeating),  or should it absolutely refuse to interfere 
<br>
with self-determination to the point of allowing suicide
<br>
and other clearly destructive behavior?
<br>
<p>Most of us would expect the answer lies somewhere between
<br>
the two extremes but few of us could agree where that
<br>
line lies and we HAVE HUMAN LEVEL INTELLIGENCE.
<br>
<p>We might even find that our answers to this question change
<br>
over time or even day to day (and on an absolute basis, i.e.,
<br>
separately from the context).
<br>
<p>By the way, I believe that we will create friendly AI, but
<br>
we will also (eventually) create unfriendly AI, either by
<br>
accident or by design.  
<br>
<p><p><pre>
--
Herb Martin
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="12980.html">Herb Martin: "RE: guaranteeing friendliness"</a>
<li><strong>Previous message:</strong> <a href="12978.html">Amy Hale: "Re: Cultishness as a high-entropy state"</a>
<li><strong>In reply to:</strong> <a href="12976.html">Christian Rovner: "Re: guaranteeing friendliness"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="12982.html">H C: "RE: guaranteeing friendliness"</a>
<li><strong>Reply:</strong> <a href="12982.html">H C: "RE: guaranteeing friendliness"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#12979">[ date ]</a>
<a href="index.html#12979">[ thread ]</a>
<a href="subject.html#12979">[ subject ]</a>
<a href="author.html#12979">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:53 MDT
</em></small></p>
</body>
</html>
