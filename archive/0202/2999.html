<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Seed AI milestones (was: Microsoft aflare)</title>
<meta name="Author" content="Eliezer S. Yudkowsky (sentience@pobox.com)">
<meta name="Subject" content="Re: Seed AI milestones (was: Microsoft aflare)">
<meta name="Date" content="2002-02-27">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Seed AI milestones (was: Microsoft aflare)</h1>
<!-- received="Wed Feb 27 11:28:02 2002" -->
<!-- isoreceived="20020227182802" -->
<!-- sent="Wed, 27 Feb 2002 11:02:14 -0500" -->
<!-- isosent="20020227160214" -->
<!-- name="Eliezer S. Yudkowsky" -->
<!-- email="sentience@pobox.com" -->
<!-- subject="Re: Seed AI milestones (was: Microsoft aflare)" -->
<!-- id="3C7D0306.F198CEEE@pobox.com" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="LAEGJLOGJIOELPNIOOAJOEBHCEAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eliezer S. Yudkowsky (<a href="mailto:sentience@pobox.com?Subject=Re:%20Seed%20AI%20milestones%20(was:%20Microsoft%20aflare)"><em>sentience@pobox.com</em></a>)<br>
<strong>Date:</strong> Wed Feb 27 2002 - 09:02:14 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3000.html">Christian Szegedy: "Re: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>Previous message:</strong> <a href="2998.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>In reply to:</strong> <a href="2997.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3001.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>Reply:</strong> <a href="3001.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2999">[ date ]</a>
<a href="index.html#2999">[ thread ]</a>
<a href="subject.html#2999">[ subject ]</a>
<a href="author.html#2999">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Ben Goertzel wrote:
<br>
<em>&gt; 
</em><br>
<em>&gt; A) paths that begin with unintelligent self-modification
</em><br>
<em>&gt; B) paths that begin with purposeful intelligent non-self-modifying behavior
</em><br>
<em>&gt; C) paths that begin with a mixture of self-modification and purposeful
</em><br>
<em>&gt; intelligent behavior
</em><br>
<em>&gt; 
</em><br>
<em>&gt; Eli and I, at this point, seem to share the intuition that B is the right
</em><br>
<em>&gt; approach. I have been clear on this for a while, but Eli's recent e-mail
</em><br>
<em>&gt; is the first time I've heard him clearly agree with me on this.
</em><br>
<p>I suspect that's because you and I use the terms &quot;hard takeoff&quot; and &quot;seed
<br>
AI&quot; to refer to different phases of the AI's development.  To be precise:
<br>
<p>*** (Excerpt from a work in progress, may contain terms here undefined.)
<br>
<p>Epochs for holonic programming:
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;First epoch:  The AI can transform code in ways that do 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;not affect the algorithm implemented.  (&quot;Understanding&quot; 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;on the order of an optimizing compiler.)
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Second epoch:  The AI can transform algorithms in order 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to fit simple abstract beliefs about the design purposes 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;of code.  That is, the AI would understand what a stack 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;implemented as a linked list and a stack implemented as 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;an array have in common.  (Note that this is already out 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;of range of current AI.)
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Third epoch:  The AI can draw a holonic line from simple 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;internal metrics of cognitive usefulness (how fast a 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;concept is cued, the usefulness of the concept returned) 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;to specific algorithms.  Consequently the AI would have 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the theoretical capability to invent and test new 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;algorithms.  This does not necessarily mean the AI would 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;have the ability to invent good algorithms or better 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;algorithms, just that invention in this domain would 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;become possible.  (A theoretical capacity for invention 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;does not inherently imply improvement over and above the 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;inventions of the programmers.  This is determined by 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;relative domain competency and by relative effort 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expended at a given focal point.)
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fourth epoch:  The AI has a concept of &quot;intelligence&quot; as 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the top-level product of a continuous holonic system.  
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The AI can draw a continuous holonic line from (a) its 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;understanding of intelligence to (b) its understanding of 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cognitive subsystems and cognitive content to (c) its 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;understanding of source code and stored data.  Given a 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sufficiently complete understanding of the higher-level 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;purpose of a cognitive subsystem, the AI would be able to 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;design a new subsystem within the overall architecture.  
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(Again, this does not intrinsically imply improvement.)
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fifth epoch:  The AI understands almost all of the design 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;purposes of its lower and higher levels of organization.  
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The AI would have the ability to design new cognitive 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;architectures.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sixth epoch:  The AI's understanding of itself, and the 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;AI's understanding of intelligence, matches or surpasses 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;that of the human programmers.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;Epochs for sparse and continuous self-improvement:
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;First epoch:  The AI has a limited set of rigid routines 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;which it applies uniformly.  Once these routines are used 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;up, they are gone.  This is essentially analogous to the 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;externally driven improvement of an optimizing compiler.  
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;An optimizing compiler may make a large number of 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;improvements&quot;, but they are not self-improvements, and 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;they are not design improvements.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Second epoch:  The cognitive processes which create 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;improvements have characteristic complexity on the order 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;of Blue Gene, rather than on the order of an optimizing 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;compiler.  Sufficient investments of computing power can 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sometimes yield extra design improvements, beyond the 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;default operations, but it is essentially an exponential 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;investment for a linear improvement, and no matter how 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;much computing power is invested, the total number of 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;improvements conceivable are limited.  (I would identify 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;this as EURISKO's epoch.)
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Third epoch:  Cognitive complexity in the AI's domain 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;competency for programming is high enough that at any 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;given point there is a large number of visible 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;possibilities for improvement, albeit minor 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;improvements.  The AI typically does not completely 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;exhaust a given supply of opportunities before 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;discovering new ones.  However, it is only 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;programmer-driven improvements in intelligence which are 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;large enough to make new opportunities for 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;self-improvement visible.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fourth epoch:  Internal improvements sometimes result in 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;genuine improvements to &quot;smartness&quot;, &quot;creativity&quot;, or 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;holonic understanding&quot;, enough to make new possible 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;improvements visible.  AI-driven acquisition of domain 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;expertise - independent learning - may also be powerful 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;enough to &quot;increase the opportunity supply&quot; or &quot;survey a 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new portion of the self-improvement landscape&quot;.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fifth epoch:  Self-improvement is, theoretically, 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;open-ended.  Even in the complete absence of the human 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;programmers, by the time the AI had used up all the 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;improvements visible at a given level, that amount of 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;improvement would be enough to &quot;climb the next step of 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the ladder&quot; and make a new set of improvements visible.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sixth epoch:  The AI does not &quot;use up all the 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;improvements visible at a given level&quot;.  Taking only a 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;small subset of the immediately obvious opportunities is 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;enough for the AI to climb the next step of the ladder, 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;survey a new portion of the self-improvement landscape, 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and start over in a new space of possible improvements.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;Epochs for human-dominated and AI-dominated improvement:
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;First epoch: The AI can make optimizations at most on the 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;order of an optimizing compiler, and cannot make design 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;improvements or increase functional complexity.  The 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;combination of AI and programmer is not noticeably better 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;than a programmer armed with an ordinary optimizing 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;compiler.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Second epoch:  The AI can understand a small handful of 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;components and make improvements to them, but the total 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;amount of AI-driven improvement is small by comparison 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;with programmer-driven development.  However, 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sufficiently major programmer improvements do very 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;occasionally trigger secondary improvement.  The total 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;amount of work done by the AI serves only as a 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;measurement of progress and does not significantly 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accelerate work on the AI.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Third epoch:  AI-driven improvement is significant, but 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;development is &quot;strongly&quot; programmer-dominated in the 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sense that overall systemic progress is driven almost 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entirely by the creativity of the programmers.  The AI 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;may have taken over some significant portion of the work 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;from the programmers.  The AI's domain competencies for 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;programming and the deliberative manipulation of 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cognitive content may be critical to the AI's continued 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;functioning.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fourth epoch:  AI-driven improvement is significant, but 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;development is &quot;weakly&quot; programmer-dominated.  AI-driven 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;improvements and programmer-driven improvements are 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;roughly of the same order, but the programmers are better 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;at it.  Alternatively, the programmers have more 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;subjective time in which to make improvements, due to the 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;number of programmers or the slowness of the AI.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fifth epoch:  AI-driven improvement is roughly equal to 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;the amount of programmer-driven improvement.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sixth epoch:  AI-driven improvement significantly 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;outweighs programmer-driven improvement.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Seventh epoch:  Programmer-driven improvement is 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;insignificant.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;Epochs for overall intelligence:
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tool-level AI:  The AI's behaviors are immediately and 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;directly specified by the programmers, or the AI &quot;learns&quot; 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in a single domain using prespecified learning 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;algorithms.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Prehuman AI:  The AI's intelligence is not a significant 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;subset of human intelligence.  Nonetheless, the AI is a 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cognitive supersystem, with some subsystems we would 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;recognize, and at least some mind-like behaviors.  (A 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;toaster oven does not qualify as a &quot;prehuman chef&quot;; a 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;general kitchen robot might do so.)
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Infrahuman AI:  The AI's intelligence is, overall, of the 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;same basic character as human intelligence, but 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;substantially inferior.  The AI may excel in a few 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;domains where it possesses new sensory modalities or 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;other brainware advantages not available to humans.  
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Humans talking to the AI usually recognize a mind on the 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;other end.  (An AI that lacks the ability to communicate 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and model external minds does not yet qualify as 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;infrahuman.)
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Near-human AI, human-equivalent AI:  The AI's 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;intelligence is in the rough neigborhood of a human's.  
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It may be locally inferior or superior in various 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;domains, but general intelligence, reasoning ability, and 
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;learning ability are roughly that of a human.
<br>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Transhumanity.
<br>
<p>*** (/excerpt)
<br>
<p>Note that these are *epochs*, not *milestones*.  They describe progress over
<br>
very long periods.
<br>
<p>Anyway, Ben uses the term &quot;hard takeoff&quot; to refer to what I would describe
<br>
as the first or second epochs.  I use &quot;hard takeoff&quot; in the sense that I
<br>
believe is standard in the transhumanist community, to refer to events past
<br>
the fifth or sixth epochs in various categories.  This would seem to explain
<br>
Ben's belief that I &quot;underestimate&quot; the amount of work involved in &quot;getting
<br>
to the Singularity from a hard takeoff&quot;.
<br>
<p>--              --              --              --              -- 
<br>
Eliezer S. Yudkowsky                          <a href="http://intelligence.org/">http://intelligence.org/</a> 
<br>
Research Fellow, Singularity Institute for Artificial Intelligence
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3000.html">Christian Szegedy: "Re: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>Previous message:</strong> <a href="2998.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>In reply to:</strong> <a href="2997.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3001.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>Reply:</strong> <a href="3001.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#2999">[ date ]</a>
<a href="index.html#2999">[ thread ]</a>
<a href="subject.html#2999">[ subject ]</a>
<a href="author.html#2999">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
