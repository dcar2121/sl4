<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: RE: Seed AI milestones (was: Microsoft aflare)</title>
<meta name="Author" content="Eugene Leitl (Eugene.Leitl@lrz.uni-muenchen.de)">
<meta name="Subject" content="RE: Seed AI milestones (was: Microsoft aflare)">
<meta name="Date" content="2002-02-27">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>RE: Seed AI milestones (was: Microsoft aflare)</h1>
<!-- received="Wed Feb 27 11:58:04 2002" -->
<!-- isoreceived="20020227185804" -->
<!-- sent="Wed, 27 Feb 2002 17:55:03 +0100 (MET)" -->
<!-- isosent="20020227165503" -->
<!-- name="Eugene Leitl" -->
<!-- email="Eugene.Leitl@lrz.uni-muenchen.de" -->
<!-- subject="RE: Seed AI milestones (was: Microsoft aflare)" -->
<!-- id="Pine.SOL.4.44.0202271714410.12790-100000@sun4.lrz-muenchen.de" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="LAEGJLOGJIOELPNIOOAJOEBJCEAA.ben@goertzel.org" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Eugene Leitl (<a href="mailto:Eugene.Leitl@lrz.uni-muenchen.de?Subject=RE:%20Seed%20AI%20milestones%20(was:%20Microsoft%20aflare)"><em>Eugene.Leitl@lrz.uni-muenchen.de</em></a>)<br>
<strong>Date:</strong> Wed Feb 27 2002 - 09:55:03 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="3003.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>Previous message:</strong> <a href="3001.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>In reply to:</strong> <a href="2998.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3005.html">Eliezer S. Yudkowsky: "Re: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>Reply:</strong> <a href="3005.html">Eliezer S. Yudkowsky: "Re: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>Reply:</strong> <a href="3007.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>Reply:</strong> <a href="3017.html">Samantha Atkins: "Re: Seed AI milestones (was: Microsoft aflare)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3002">[ date ]</a>
<a href="index.html#3002">[ thread ]</a>
<a href="subject.html#3002">[ subject ]</a>
<a href="author.html#3002">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
[I'm going to reply to your other message properly, i.e. at home. This is
<br>
quick reply from work]
<br>
<p>On Wed, 27 Feb 2002, Ben Goertzel wrote:
<br>
<p><em>&gt; I have never understood your &quot;complexity barrier&quot; argument as anything
</em><br>
<em>&gt; but an intuition.
</em><br>
<p>No, merely expressing a well known truth about software engineering.. And
<br>
not only about software engineering, engineering in general. Minds are one
<br>
thing: complex. Look at the hardware layer, it is that very obviously. And
<br>
we're getting increased evidence that these structures are indeed doing a
<br>
lot, are not very reducible. This is not an intuition, I can cite you a
<br>
few papers indicating that there's not much averaging going on. Each
<br>
incoming bit of info from the trenches makes me lose any residual optimism
<br>
I had.
<br>
<p>There's a bareer to the complexity of a system you can build as a single
<br>
person. Different persons have different ceilings, mine is quite low.
<br>
Teams do not really scale in that regard. A ceiling of a group is not
<br>
dramatically higher than of a single individual, and the ceiling of a
<br>
large group can be actually lower. This is basic software engineering
<br>
knowledge.
<br>
<p>General intelligence is not property of a simple system. Far from it.
<br>
As a result I predict that human software engineers coding an AI
<br>
explicitly (i.e. using not stochastic/noisy/evolutionary methods) are
<br>
going to fall short of the goal.
<br>
<p><em>&gt; I agree that goal-directed self-modification is a specialized mental
</em><br>
<em>&gt; function, similar (very roughly speaking) to, say, vision processing, or
</em><br>
<em>&gt; mathematical reasoning, or social interaction.  However, also like these
</em><br>
<em>&gt; other things, it will be achieved by a combination of general
</em><br>
<em>&gt; intelligence processes with more specialized heuristics.
</em><br>
<p>Am I correct to assume that we're talking about explicit codification of
<br>
knowledge destilled from human experts? Is there any reason to suspect
<br>
that we're going to do any better than Lenat &amp; Co? The record track so far
<br>
is not overwhelming.
<br>
<p><em>&gt; I think you are wrong about losing &quot;orders of magnitude&quot; of performance.
</em><br>
<em>&gt; If you have any detailed calculations to back up this estimate, please
</em><br>
<em>&gt; share them.
</em><br>
<p>I don't have to cite any detailed calculations, citing benchmarks results
<br>
would seem to be enough. Current architectures are not all-purpose. As the
<br>
result careful tweaks and measurements for a given chunk of code must be
<br>
conducted, before it exploits the hardware optimally (while being remote
<br>
from a hand-coded solution by a competent human). We're talking compiled C
<br>
here. I'm not mentioning holistic aspects, as the impact of the messagin
<br>
latency or choice of the right device driver/kernel version, which can
<br>
most assuredly kill performance. We're talking dumping some high-level
<br>
language into C (not C++, because improper use of C++ is a sure
<br>
performance killer), by a system completely agnostic about its deepr
<br>
layers.
<br>
<p>At *least* two orders of magnitude. Probably more.
<br>
<p><em>&gt; My own experience, based on prototyping in this space for a while, is that
</em><br>
<em>&gt; you will lose about order of magnitude of performance by doing self-
</em><br>
<em>&gt; modification in a *properly optimized* high-level language rather than in a
</em><br>
<em>&gt; low-level language like C++.
</em><br>
<p>Um, C++ can easily lose an order of magnitude of performance over C, if
<br>
you don't know what you're doing. Not to mention tweaking the compiler
<br>
flags, and jiggle the code, trying to not run into performance killers
<br>
(longword align, for instance).
<br>
<p>We seem to mean very different systems, when speaking high-performance.
<br>
The absence of high-performance computing types in AI is notable.
<br>
<p><em>&gt; Our first self-modification experiments in Novamente (our new AI system,
</em><br>
<em>&gt; the Webmind successor) will not involve Novamente rewriting its C++
</em><br>
<em>&gt; source, but rather Novamente rewriting what we call &quot;schema&quot; that
</em><br>
<em>&gt; control its cognitive functioning (which are equivalent to programs in
</em><br>
<em>&gt; our own high-level language, that we call Sasha (named after our
</em><br>
<em>&gt; departed collaborator Sasha Chislenko)).
</em><br>
<p>You will let us know, how well self modification will do, will you? This
<br>
is a genuinely interesting experiment.
<br>
<p><em>&gt; In the first-draft Novamente schema module, executing a schema will
</em><br>
<em>&gt; about 2 orders of mag. slower than executing an analogous C++ program,
</em><br>
<em>&gt; but this is because the first-draft schema module will not embody
</em><br>
<em>&gt; sophisticated schema optimization procedures. We have a fairly detailed
</em><br>
<em>&gt; design for a second-version schema module that we believe will narrow
</em><br>
<em>&gt; the performance gap to within 1 order of magnitude.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Why accept a 1 order of magnitude slowdown?  Because we are
</em><br>
<em>&gt; *confronting* the complexity barrier you mention rather than hiding in
</em><br>
<em>&gt; fear from it. Novamente is very complex, both in its design and in its
</em><br>
<p>Bootstrap requires *more* resources, not less of it. Nonchalance about
<br>
losing touch with bare metal in bootstrap design phase sounds very wrong
<br>
to me.
<br>
<p><em>&gt; emergent behaviors, but we are working to keep it manageably complex.
</em><br>
<em>&gt; In our judgment, having the system modify schema (Sasha programs) rather
</em><br>
<em>&gt; than C++ source is a big help in keeping the complexity manageable.
</em><br>
<em>&gt; And this added manageability is more than worth an order of magnitude
</em><br>
<em>&gt; slowdown.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Eli and I are fashioning solutions (or trying!!) whereas you are
</em><br>
<em>&gt; pointing out potential problems.  There is nothing wrong with pointing
</em><br>
<p>Actually, I'm pretty happy that there so many problems. I would really
<br>
hate to see a SysOp made reality, because it would mean a man-made Blight.
<br>
<p><em>&gt; out problems; however, it is a fact that both the nature of the problems
</em><br>
<em>&gt; and the potential workarounds that exist become far clearer once one
</em><br>
<em>&gt; starts working at solving the problems, rather than just talking about
</em><br>
<em>&gt; them.
</em><br>
<p>Um, implementing a runaway AI is certainly not my problem. I'm interested
<br>
in modelling biological organisms, which does not involve such dangerous
<br>
components. This is the wrong forum to discuss it, however.
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="3003.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>Previous message:</strong> <a href="3001.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>In reply to:</strong> <a href="2998.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="3005.html">Eliezer S. Yudkowsky: "Re: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>Reply:</strong> <a href="3005.html">Eliezer S. Yudkowsky: "Re: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>Reply:</strong> <a href="3007.html">Ben Goertzel: "RE: Seed AI milestones (was: Microsoft aflare)"</a>
<li><strong>Reply:</strong> <a href="3017.html">Samantha Atkins: "Re: Seed AI milestones (was: Microsoft aflare)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#3002">[ date ]</a>
<a href="index.html#3002">[ thread ]</a>
<a href="subject.html#3002">[ subject ]</a>
<a href="author.html#3002">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:37 MDT
</em></small></p>
</body>
</html>
