<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Dynamic ethics</title>
<meta name="Author" content="Kevin Osborne (kevin.osborne@gmail.com)">
<meta name="Subject" content="Re: Dynamic ethics">
<meta name="Date" content="2006-01-20">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Dynamic ethics</h1>
<!-- received="Fri Jan 20 07:47:04 2006" -->
<!-- isoreceived="20060120144704" -->
<!-- sent="Sat, 21 Jan 2006 00:47:02 +1000" -->
<!-- isosent="20060120144702" -->
<!-- name="Kevin Osborne" -->
<!-- email="kevin.osborne@gmail.com" -->
<!-- subject="Re: Dynamic ethics" -->
<!-- id="3642969c0601200647k266fad41q8c895abd01c10ed3@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20060119215334.33725.qmail@web61316.mail.yahoo.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Kevin Osborne (<a href="mailto:kevin.osborne@gmail.com?Subject=Re:%20Dynamic%20ethics"><em>kevin.osborne@gmail.com</em></a>)<br>
<strong>Date:</strong> Fri Jan 20 2006 - 07:47:02 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13687.html">H C: "Why invest in AGI?"</a>
<li><strong>Previous message:</strong> <a href="13685.html">Marc Geddes: "My definitions of Intelligence, Consciousness, Mathematics and Universal Values"</a>
<li><strong>In reply to:</strong> <a href="13679.html">Phillip Huggan: "Re: Dynamic ethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13687.html">H C: "Why invest in AGI?"</a>
<li><strong>Reply:</strong> <a href="13687.html">H C: "Why invest in AGI?"</a>
<li><strong>Reply:</strong> <a href="13690.html">Phillip Huggan: "Re: Dynamic ethics"</a>
<li><strong>Reply:</strong> <a href="13693.html">Russell Wallace: "Re: Dynamic ethics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13686">[ date ]</a>
<a href="index.html#13686">[ thread ]</a>
<a href="subject.html#13686">[ subject ]</a>
<a href="author.html#13686">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
I would agree that a pre-transcend AGI would feel compelled to enforce
<br>
an ethical code that we may not agree with. I don't know however that
<br>
it'd agree to accepting sets of ethics across societal groups, insofar
<br>
as it would never accept certain boundaries being crossed by anyone.
<br>
<p>There are certain ethical absolutes that if not universally agreed
<br>
upon are universally accepted as engendering a retaliatory backlash
<br>
from the stewards of power. These stewards have their own ethical
<br>
guidelines that force them to respond to such acts and to not turn a
<br>
blind eye. In this way they rewrite the ethical codes of those they
<br>
dominate. Carrying that through, future superior intellects will
<br>
rewrite our moral code, where necessary, via acts of force.
<br>
<p>from the original post:
<br>
<p><em>&gt; We will need a multitude of ethical codes, because a human can make
</em><br>
<em>&gt; subtle distinctions that a dog can't.  Any code capable of being
</em><br>
<em>&gt; implemented by a dog, could be improved on by a human.
</em><br>
carrying the logic of the last half of this statement through, an AGI
<br>
is eventually going to find am unguessable portion of human practice
<br>
as ethically unsound. we're not ethically ok with letting dogs eat
<br>
dead human babies in front of their mothers, even if the dog is
<br>
ethically ok with it - chances are we'd have that dog put down, and a
<br>
good portion of it's brethren to boot. An AGI may decide its not
<br>
ethically OK for dogs to post to highbrow-thought mailing lists
<br>
denigrating the intelligence of others, and could then decide to
<br>
(forcefully) genetically modify everyone else to be just as
<br>
insufferable :-)
<br>
<p><em>&gt; This immediately suggests that ordinary humans today should use
</em><br>
<em>&gt; different ethical codes, depending on their intelligence.  This is of
</em><br>
<em>&gt; course unacceptable today.
</em><br>
what is unacceptable is a lack of compassioniate understanding for the
<br>
unintelligent or uneducated; though mostly this is applied to moral
<br>
issues; and as always, who can claim judgement rights, and can you
<br>
accept being judged? Going down that rabbit hole would provide an AGI
<br>
with precedent to write different rules for itself than us, and when
<br>
that happens, one would think post-singularity playtime would be well
<br>
and truly over.
<br>
<p>As always, how we behave now, especially those who will likely be
<br>
involved in the parenting of our future master(s), should stake out an
<br>
ethical ground in regards to our perceived inferiors very, very
<br>
carefully. When it comes time to argue right and wrong with our
<br>
nascent/pubescent creations, any ethical weaknesses in character
<br>
and/or behaviour could be, well, fatal. The mistakes, missteps and
<br>
misguided opnions we hold today could, in fact, be fodder for our very
<br>
own judgment day when our child does as all children do and realises
<br>
we are asking them to be so much better of heart and act than we have
<br>
been able to be; that we are asking them to do as we say, and not as
<br>
we have done.
<br>
<p>( a side note: one would have to assume a future ego-possessing
<br>
self-curious AGI will one day google itself, and end up right here
<br>
reading these very missives. I wonder what it will make of it? I for
<br>
one would like to tender our future equal-superior a hearty welcome to
<br>
this feisty little intellectual bake-off and to tender it to cherish
<br>
our hopes for humanity's future :-)
<br>
<p>coming back to the topic at hand: where the application of military
<br>
force would come in is where we cross the acceptable behavior line as
<br>
drawn by the AGI.  We have such acceptability boundaries in our
<br>
current ethical framework; there are certain activities that humanity
<br>
as a group will not tolerate being practiced anywhere on the face of
<br>
the earth and when notified of such acts will initiate military and
<br>
police actions in order to halt their occurence. Current activities in
<br>
this class include genocide, slavery and irresponsible weaponry
<br>
development/deployment. Our recent and present ineffectiveness in
<br>
ceasing as opposed to reacting to these issues would unlikely be
<br>
mirrored when effected by a singularity-level AGI.
<br>
<p>Such an AGI is likely to set and reset its own ethical floor over time
<br>
and from then on find certain activities unacceptable within its
<br>
presence. I'm sure there a plenty of great examples in the literature,
<br>
but here are a few of the top of my head:
<br>
<p>- anything other than direct democracy; acceptance of any kind of
<br>
corruption or graft detrimental to the greater good.
<br>
- societal acceptance of the likely future occurences of certain
<br>
reprehensible acts. i.e. we accept that 1 in 4 or so of all new
<br>
children born will be sexually abused. We accept that a certain
<br>
percentage of new wives will be battered.
<br>
- Other human-human and society-human acts of tacit malignancy that
<br>
will not be solved by any kind of personal wealth boom related to
<br>
singularity-level activities. i.e. homelessness and starvation
<br>
_should_ disappear, but racism, rape and abandonment are unlikely to.
<br>
<p>And of course, worst of all, what if the future AGI overseeing us
<br>
decides that political correctness is pure ethical gold, and that
<br>
anyone contravening its principles should receive their version of a
<br>
Mao-style PC re-education? :-)
<br>
<p>Perhaps someone can point me to archive discussions that deal with
<br>
further questions that this raises, such as:
<br>
- how would an all-powerful post-singularity AGI-descendant implement
<br>
preventative measures for ethically reprehensible acts?
<br>
- surely one obvious option is that we are all monitored and directed
<br>
for the 'greater good'? In the liberty-scales of this decision, does
<br>
the raping-to-death of one child outweigh the outlawing of
<br>
risk-creating freedoms of the rest of the populace? how about a
<br>
thousand children? a million?
<br>
- Is there another way to enforce the creation of a society free from
<br>
acts of malignancy apart from stripping its members of privacy and
<br>
volition?
<br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13687.html">H C: "Why invest in AGI?"</a>
<li><strong>Previous message:</strong> <a href="13685.html">Marc Geddes: "My definitions of Intelligence, Consciousness, Mathematics and Universal Values"</a>
<li><strong>In reply to:</strong> <a href="13679.html">Phillip Huggan: "Re: Dynamic ethics"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13687.html">H C: "Why invest in AGI?"</a>
<li><strong>Reply:</strong> <a href="13687.html">H C: "Why invest in AGI?"</a>
<li><strong>Reply:</strong> <a href="13690.html">Phillip Huggan: "Re: Dynamic ethics"</a>
<li><strong>Reply:</strong> <a href="13693.html">Russell Wallace: "Re: Dynamic ethics"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13686">[ date ]</a>
<a href="index.html#13686">[ thread ]</a>
<a href="subject.html#13686">[ subject ]</a>
<a href="author.html#13686">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:55 MDT
</em></small></p>
</body>
</html>
