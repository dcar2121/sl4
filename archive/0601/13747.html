<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Why invest in AGI?</title>
<meta name="Author" content="Ben Goertzel (ben@goertzel.org)">
<meta name="Subject" content="Re: Why invest in AGI?">
<meta name="Date" content="2006-01-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Why invest in AGI?</h1>
<!-- received="Mon Jan 23 09:16:28 2006" -->
<!-- isoreceived="20060123161628" -->
<!-- sent="Mon, 23 Jan 2006 11:16:26 -0500" -->
<!-- isosent="20060123161626" -->
<!-- name="Ben Goertzel" -->
<!-- email="ben@goertzel.org" -->
<!-- subject="Re: Why invest in AGI?" -->
<!-- id="638d4e150601230816l588f0d58vccd6224e13f28889@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="43D5A700.1000902@lightlink.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Ben Goertzel (<a href="mailto:ben@goertzel.org?Subject=Re:%20Why%20invest%20in%20AGI?"><em>ben@goertzel.org</em></a>)<br>
<strong>Date:</strong> Mon Jan 23 2006 - 09:16:26 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13748.html">Philip Goetz: "Re: Dynamic ethics"</a>
<li><strong>Previous message:</strong> <a href="13746.html">Richard Loosemore: "Re: Why invest in AGI?"</a>
<li><strong>In reply to:</strong> <a href="13746.html">Richard Loosemore: "Re: Why invest in AGI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13764.html">Dani Eder: "Re: Why invest in AGI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13747">[ date ]</a>
<a href="index.html#13747">[ thread ]</a>
<a href="subject.html#13747">[ subject ]</a>
<a href="author.html#13747">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Terminology is being used very loosely in this thread.
<br>
<p>I believe the Novamente design suffices for the creation of a &quot;mind in
<br>
a box&quot;.  Whether you want to call this a &quot;brain in a box&quot; is a whole
<br>
other issue -- we are not trying to emulate human brain function,
<br>
which as Richard notes is not really feasible given the currently poor
<br>
understanding of the human brain.
<br>
<p>-- Ben
<br>
<p>On 1/23/06, Richard Loosemore &lt;<a href="mailto:rpwl@lightlink.com?Subject=Re:%20Why%20invest%20in%20AGI?">rpwl@lightlink.com</a>&gt; wrote:
<br>
<em>&gt; Not any time soon:  nobody has the detailed information necessary to
</em><br>
<em>&gt; actually *do* that.   Assembling a computer with the same number of
</em><br>
<em>&gt; processing units and wires as a brain is pretty easy:  making all the
</em><br>
<em>&gt; processors behave exactly as they behave in a particular brain, and
</em><br>
<em>&gt; making all the wires exactly follow the neural pathways in that same
</em><br>
<em>&gt; particular brain, are devastatingly hard with current technology.  I
</em><br>
<em>&gt; mean, the word &quot;hard&quot; is a silly understatement here!  I don't think it
</em><br>
<em>&gt; will be done before a superintelligent AGI is built.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Which is why I castigated the IBM brain simulation project in a previous
</em><br>
<em>&gt; post.  You hear a lot about the fantastic things achieved with fMRI
</em><br>
<em>&gt; technology:  don't believe the hype.  It's just marketing BS.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Place a call with your friendly local neuroscientist today:  ask if the
</em><br>
<em>&gt; IBM project is going to supply details of every neuron, the route of
</em><br>
<em>&gt; every axon path, the strength of every synapse and the spatial structure
</em><br>
<em>&gt; of every dendritic tree in a brain.  Listen carefully to the answer.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Richard Loosemore
</em><br>
<em>&gt;
</em><br>
<em>&gt; H C wrote:
</em><br>
<em>&gt; &gt; Well, it is arguable that IF you simulate an entire human brain, then
</em><br>
<em>&gt; &gt; you could create an AGI, in a sense (I guess you would be simulating an
</em><br>
<em>&gt; &gt; actual person). Thus, your Singularity take-off happens.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; -hegem0n
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;&gt; From: Richard Loosemore &lt;<a href="mailto:rpwl@lightlink.com?Subject=Re:%20Why%20invest%20in%20AGI?">rpwl@lightlink.com</a>&gt;
</em><br>
<em>&gt; &gt;&gt; Reply-To: <a href="mailto:sl4@sl4.org?Subject=Re:%20Why%20invest%20in%20AGI?">sl4@sl4.org</a>
</em><br>
<em>&gt; &gt;&gt; To: <a href="mailto:sl4@sl4.org?Subject=Re:%20Why%20invest%20in%20AGI?">sl4@sl4.org</a>
</em><br>
<em>&gt; &gt;&gt; Subject: Re: Why invest in AGI?
</em><br>
<em>&gt; &gt;&gt; Date: Sun, 22 Jan 2006 21:18:02 -0500
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt; There is only one problem with your story:  I very much fear that it
</em><br>
<em>&gt; &gt;&gt; is not true that if we got brain-power hardware, we would get an AI.
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt; If you gave Microsoft a set of four Blue Gene-L machines, they *still*
</em><br>
<em>&gt; &gt;&gt; would not be able to deliver a bug-free version of Word any time in
</em><br>
<em>&gt; &gt;&gt; the next century.
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt; We probably have the hardware power right now.  What we lack are the
</em><br>
<em>&gt; &gt;&gt; right theoretical approach and software techniques.  More
</em><br>
<em>&gt; &gt;&gt; particularly, I think we lack the right software-construction tools.
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt; You might respond that it does neverthless make a compact story to
</em><br>
<em>&gt; &gt;&gt; give to an investor:  I'm not sure, though, because I think they know,
</em><br>
<em>&gt; &gt;&gt; intuitively, that it has a false ring to it.
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt; Richard Loosemore.
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt; Dani Eder wrote:
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt; My simple story for potential investors:
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt; The human brain has 100 billion neurons, each with
</em><br>
<em>&gt; &gt;&gt;&gt; 10,000
</em><br>
<em>&gt; &gt;&gt;&gt; synapses firing at an average of 100 Hz, for a total
</em><br>
<em>&gt; &gt;&gt;&gt; synapse
</em><br>
<em>&gt; &gt;&gt;&gt; firing rate of 100 x 10^15/sec.
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt; A modern CPU chip (Athlon 64 X2 4800+, 2.4 GHz) has
</em><br>
<em>&gt; &gt;&gt;&gt; two cores
</em><br>
<em>&gt; &gt;&gt;&gt; each processing an average of 1.5 calculations/cycle x
</em><br>
<em>&gt; &gt;&gt;&gt; 64 bits.
</em><br>
<em>&gt; &gt;&gt;&gt; This gives a bit rate of 460 x 10^9.
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt; There is some question about how much data a synapse
</em><br>
<em>&gt; &gt;&gt;&gt; firing
</em><br>
<em>&gt; &gt;&gt;&gt; equates to, but assume 1 bit/synapse firing for now. Thus
</em><br>
<em>&gt; &gt;&gt;&gt; it would take 217,000 of these CPU chips to equate to
</em><br>
<em>&gt; &gt;&gt;&gt; a human
</em><br>
<em>&gt; &gt;&gt;&gt; brain.
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt; The most powerful computer in the world (Blue Gene-L)
</em><br>
<em>&gt; &gt;&gt;&gt; has
</em><br>
<em>&gt; &gt;&gt;&gt; 40% fewer CPU chips, and they are each 39% as powerful
</em><br>
<em>&gt; &gt;&gt;&gt; as the
</em><br>
<em>&gt; &gt;&gt;&gt; Athlon above, for a total of about 1/4 of the required
</em><br>
<em>&gt; &gt;&gt;&gt; power.
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt; So the failure of AI to date can be explained by the
</em><br>
<em>&gt; &gt;&gt;&gt; lack of
</em><br>
<em>&gt; &gt;&gt;&gt; adequate hardware.
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt; Special purpose AI accelerator chips, similar to
</em><br>
<em>&gt; &gt;&gt;&gt; graphics
</em><br>
<em>&gt; &gt;&gt;&gt; accelerator ships, may buy you a factor of
</em><br>
<em>&gt; &gt;&gt;&gt; 10 improvement.  Clever programming may buy you
</em><br>
<em>&gt; &gt;&gt;&gt; another
</em><br>
<em>&gt; &gt;&gt;&gt; factor of 10, and the expected improvement in
</em><br>
<em>&gt; &gt;&gt;&gt; computers
</em><br>
<em>&gt; &gt;&gt;&gt; in the next 5 years will get you another factor of 5.
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt; This would bring the number of blade servers required
</em><br>
<em>&gt; &gt;&gt;&gt; down
</em><br>
<em>&gt; &gt;&gt;&gt; to ~430, which is a reasonably small number.  So an
</em><br>
<em>&gt; &gt;&gt;&gt; investment
</em><br>
<em>&gt; &gt;&gt;&gt; in accelerator chip design and AI programming, coupled
</em><br>
<em>&gt; &gt;&gt;&gt; with
</em><br>
<em>&gt; &gt;&gt;&gt; the expected improvement in computers overall, could
</em><br>
<em>&gt; &gt;&gt;&gt; yield
</em><br>
<em>&gt; &gt;&gt;&gt; true AI in 5 years.
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt; DRN (I've previously signed my messages 'Daniel', but
</em><br>
<em>&gt; &gt;&gt;&gt; Daniel Radetsky signs his messages the same way.  To avoid confusion
</em><br>
<em>&gt; &gt;&gt;&gt; I'm now using the initials of my
</em><br>
<em>&gt; &gt;&gt;&gt; historical
</em><br>
<em>&gt; &gt;&gt;&gt; re-enactment persona 'Daniel of Raven's Nest', which
</em><br>
<em>&gt; &gt;&gt;&gt; is
</em><br>
<em>&gt; &gt;&gt;&gt; where my email address comes from.  Dani Eder is my
</em><br>
<em>&gt; &gt;&gt;&gt; real
</em><br>
<em>&gt; &gt;&gt;&gt; world name)
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt; __________________________________________________
</em><br>
<em>&gt; &gt;&gt;&gt; Do You Yahoo!?
</em><br>
<em>&gt; &gt;&gt;&gt; Tired of spam?  Yahoo! Mail has the best spam protection around
</em><br>
<em>&gt; &gt;&gt;&gt; <a href="http://mail.yahoo.com">http://mail.yahoo.com</a>
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;&gt;&gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13748.html">Philip Goetz: "Re: Dynamic ethics"</a>
<li><strong>Previous message:</strong> <a href="13746.html">Richard Loosemore: "Re: Why invest in AGI?"</a>
<li><strong>In reply to:</strong> <a href="13746.html">Richard Loosemore: "Re: Why invest in AGI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13764.html">Dani Eder: "Re: Why invest in AGI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13747">[ date ]</a>
<a href="index.html#13747">[ thread ]</a>
<a href="subject.html#13747">[ subject ]</a>
<a href="author.html#13747">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:55 MDT
</em></small></p>
</body>
</html>
