<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: Why invest in AGI?</title>
<meta name="Author" content="Richard Loosemore (rpwl@lightlink.com)">
<meta name="Subject" content="Re: Why invest in AGI?">
<meta name="Date" content="2006-01-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: Why invest in AGI?</h1>
<!-- received="Mon Jan 23 09:00:04 2006" -->
<!-- isoreceived="20060123160004" -->
<!-- sent="Mon, 23 Jan 2006 23:03:12 -0500" -->
<!-- isosent="20060124040312" -->
<!-- name="Richard Loosemore" -->
<!-- email="rpwl@lightlink.com" -->
<!-- subject="Re: Why invest in AGI?" -->
<!-- id="43D5A700.1000902@lightlink.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="BAY101-F714B2DB2059AAD63D3B89DC110@phx.gbl" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Richard Loosemore (<a href="mailto:rpwl@lightlink.com?Subject=Re:%20Why%20invest%20in%20AGI?"><em>rpwl@lightlink.com</em></a>)<br>
<strong>Date:</strong> Mon Jan 23 2006 - 21:03:12 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13747.html">Ben Goertzel: "Re: Why invest in AGI?"</a>
<li><strong>Previous message:</strong> <a href="13745.html">Ben Goertzel: "Re: My definitions of Intelligence, Consciousness, Mathematics and Universal Values"</a>
<li><strong>In reply to:</strong> <a href="13733.html">H C: "Re: Why invest in AGI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13747.html">Ben Goertzel: "Re: Why invest in AGI?"</a>
<li><strong>Reply:</strong> <a href="13747.html">Ben Goertzel: "Re: Why invest in AGI?"</a>
<li><strong>Reply:</strong> <a href="13764.html">Dani Eder: "Re: Why invest in AGI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13746">[ date ]</a>
<a href="index.html#13746">[ thread ]</a>
<a href="subject.html#13746">[ subject ]</a>
<a href="author.html#13746">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Not any time soon:  nobody has the detailed information necessary to 
<br>
actually *do* that.   Assembling a computer with the same number of 
<br>
processing units and wires as a brain is pretty easy:  making all the 
<br>
processors behave exactly as they behave in a particular brain, and 
<br>
making all the wires exactly follow the neural pathways in that same 
<br>
particular brain, are devastatingly hard with current technology.  I 
<br>
mean, the word &quot;hard&quot; is a silly understatement here!  I don't think it 
<br>
will be done before a superintelligent AGI is built.
<br>
<p>Which is why I castigated the IBM brain simulation project in a previous 
<br>
post.  You hear a lot about the fantastic things achieved with fMRI 
<br>
technology:  don't believe the hype.  It's just marketing BS.
<br>
<p>Place a call with your friendly local neuroscientist today:  ask if the 
<br>
IBM project is going to supply details of every neuron, the route of 
<br>
every axon path, the strength of every synapse and the spatial structure 
<br>
of every dendritic tree in a brain.  Listen carefully to the answer.
<br>
<p>Richard Loosemore
<br>
<p>H C wrote:
<br>
<em>&gt; Well, it is arguable that IF you simulate an entire human brain, then 
</em><br>
<em>&gt; you could create an AGI, in a sense (I guess you would be simulating an 
</em><br>
<em>&gt; actual person). Thus, your Singularity take-off happens.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -hegem0n
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt; From: Richard Loosemore &lt;<a href="mailto:rpwl@lightlink.com?Subject=Re:%20Why%20invest%20in%20AGI?">rpwl@lightlink.com</a>&gt;
</em><br>
<em>&gt;&gt; Reply-To: <a href="mailto:sl4@sl4.org?Subject=Re:%20Why%20invest%20in%20AGI?">sl4@sl4.org</a>
</em><br>
<em>&gt;&gt; To: <a href="mailto:sl4@sl4.org?Subject=Re:%20Why%20invest%20in%20AGI?">sl4@sl4.org</a>
</em><br>
<em>&gt;&gt; Subject: Re: Why invest in AGI?
</em><br>
<em>&gt;&gt; Date: Sun, 22 Jan 2006 21:18:02 -0500
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; There is only one problem with your story:  I very much fear that it 
</em><br>
<em>&gt;&gt; is not true that if we got brain-power hardware, we would get an AI.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; If you gave Microsoft a set of four Blue Gene-L machines, they *still* 
</em><br>
<em>&gt;&gt; would not be able to deliver a bug-free version of Word any time in 
</em><br>
<em>&gt;&gt; the next century.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; We probably have the hardware power right now.  What we lack are the 
</em><br>
<em>&gt;&gt; right theoretical approach and software techniques.  More 
</em><br>
<em>&gt;&gt; particularly, I think we lack the right software-construction tools.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; You might respond that it does neverthless make a compact story to 
</em><br>
<em>&gt;&gt; give to an investor:  I'm not sure, though, because I think they know, 
</em><br>
<em>&gt;&gt; intuitively, that it has a false ring to it.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Richard Loosemore.
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Dani Eder wrote:
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; My simple story for potential investors:
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; The human brain has 100 billion neurons, each with
</em><br>
<em>&gt;&gt;&gt; 10,000
</em><br>
<em>&gt;&gt;&gt; synapses firing at an average of 100 Hz, for a total
</em><br>
<em>&gt;&gt;&gt; synapse
</em><br>
<em>&gt;&gt;&gt; firing rate of 100 x 10^15/sec.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; A modern CPU chip (Athlon 64 X2 4800+, 2.4 GHz) has
</em><br>
<em>&gt;&gt;&gt; two cores
</em><br>
<em>&gt;&gt;&gt; each processing an average of 1.5 calculations/cycle x
</em><br>
<em>&gt;&gt;&gt; 64 bits.
</em><br>
<em>&gt;&gt;&gt; This gives a bit rate of 460 x 10^9.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; There is some question about how much data a synapse
</em><br>
<em>&gt;&gt;&gt; firing
</em><br>
<em>&gt;&gt;&gt; equates to, but assume 1 bit/synapse firing for now. Thus
</em><br>
<em>&gt;&gt;&gt; it would take 217,000 of these CPU chips to equate to
</em><br>
<em>&gt;&gt;&gt; a human
</em><br>
<em>&gt;&gt;&gt; brain.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; The most powerful computer in the world (Blue Gene-L)
</em><br>
<em>&gt;&gt;&gt; has
</em><br>
<em>&gt;&gt;&gt; 40% fewer CPU chips, and they are each 39% as powerful
</em><br>
<em>&gt;&gt;&gt; as the
</em><br>
<em>&gt;&gt;&gt; Athlon above, for a total of about 1/4 of the required
</em><br>
<em>&gt;&gt;&gt; power.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; So the failure of AI to date can be explained by the
</em><br>
<em>&gt;&gt;&gt; lack of
</em><br>
<em>&gt;&gt;&gt; adequate hardware.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; Special purpose AI accelerator chips, similar to
</em><br>
<em>&gt;&gt;&gt; graphics
</em><br>
<em>&gt;&gt;&gt; accelerator ships, may buy you a factor of
</em><br>
<em>&gt;&gt;&gt; 10 improvement.  Clever programming may buy you
</em><br>
<em>&gt;&gt;&gt; another
</em><br>
<em>&gt;&gt;&gt; factor of 10, and the expected improvement in
</em><br>
<em>&gt;&gt;&gt; computers
</em><br>
<em>&gt;&gt;&gt; in the next 5 years will get you another factor of 5.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; This would bring the number of blade servers required
</em><br>
<em>&gt;&gt;&gt; down
</em><br>
<em>&gt;&gt;&gt; to ~430, which is a reasonably small number.  So an
</em><br>
<em>&gt;&gt;&gt; investment
</em><br>
<em>&gt;&gt;&gt; in accelerator chip design and AI programming, coupled
</em><br>
<em>&gt;&gt;&gt; with
</em><br>
<em>&gt;&gt;&gt; the expected improvement in computers overall, could
</em><br>
<em>&gt;&gt;&gt; yield
</em><br>
<em>&gt;&gt;&gt; true AI in 5 years.
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; DRN (I've previously signed my messages 'Daniel', but
</em><br>
<em>&gt;&gt;&gt; Daniel Radetsky signs his messages the same way.  To avoid confusion 
</em><br>
<em>&gt;&gt;&gt; I'm now using the initials of my
</em><br>
<em>&gt;&gt;&gt; historical
</em><br>
<em>&gt;&gt;&gt; re-enactment persona 'Daniel of Raven's Nest', which
</em><br>
<em>&gt;&gt;&gt; is
</em><br>
<em>&gt;&gt;&gt; where my email address comes from.  Dani Eder is my
</em><br>
<em>&gt;&gt;&gt; real
</em><br>
<em>&gt;&gt;&gt; world name)
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt; __________________________________________________
</em><br>
<em>&gt;&gt;&gt; Do You Yahoo!?
</em><br>
<em>&gt;&gt;&gt; Tired of spam?  Yahoo! Mail has the best spam protection around 
</em><br>
<em>&gt;&gt;&gt; <a href="http://mail.yahoo.com">http://mail.yahoo.com</a>
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt;&gt;&gt;
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13747.html">Ben Goertzel: "Re: Why invest in AGI?"</a>
<li><strong>Previous message:</strong> <a href="13745.html">Ben Goertzel: "Re: My definitions of Intelligence, Consciousness, Mathematics and Universal Values"</a>
<li><strong>In reply to:</strong> <a href="13733.html">H C: "Re: Why invest in AGI?"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13747.html">Ben Goertzel: "Re: Why invest in AGI?"</a>
<li><strong>Reply:</strong> <a href="13747.html">Ben Goertzel: "Re: Why invest in AGI?"</a>
<li><strong>Reply:</strong> <a href="13764.html">Dani Eder: "Re: Why invest in AGI?"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13746">[ date ]</a>
<a href="index.html#13746">[ thread ]</a>
<a href="subject.html#13746">[ subject ]</a>
<a href="author.html#13746">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:55 MDT
</em></small></p>
</body>
</html>
