<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: neural nets</title>
<meta name="Author" content="CyTG (cytg.net@gmail.com)">
<meta name="Subject" content="Re: neural nets">
<meta name="Date" content="2006-01-24">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: neural nets</h1>
<!-- received="Tue Jan 24 07:06:13 2006" -->
<!-- isoreceived="20060124140613" -->
<!-- sent="Tue, 24 Jan 2006 15:06:11 +0100" -->
<!-- isosent="20060124140611" -->
<!-- name="CyTG" -->
<!-- email="cytg.net@gmail.com" -->
<!-- subject="Re: neural nets" -->
<!-- id="ce299b890601240606y9e3d6bfje0cd06e52718ac8e@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="43C6BE90.6070709@lightlink.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> CyTG (<a href="mailto:cytg.net@gmail.com?Subject=Re:%20neural%20nets"><em>cytg.net@gmail.com</em></a>)<br>
<strong>Date:</strong> Tue Jan 24 2006 - 07:06:11 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13773.html">Rick Geniale: "Re: Some considerations about AGI"</a>
<li><strong>Previous message:</strong> <a href="13771.html">BillK: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<li><strong>In reply to:</strong> <a href="13505.html">Richard Loosemore: "Re: neural nets"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13774.html">Richard Loosemore: "Re: neural nets"</a>
<li><strong>Reply:</strong> <a href="13774.html">Richard Loosemore: "Re: neural nets"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13772">[ date ]</a>
<a href="index.html#13772">[ thread ]</a>
<a href="subject.html#13772">[ subject ]</a>
<a href="author.html#13772">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
Daniel -&gt; Indeed, that's why im not basing the comparison upon ticks (MHz)
<br>
rather actual performed (ops), the (~3 x 10^9/sec) figure is not saying a
<br>
whole lot. It may be relatively easy and fast to implement a boolean
<br>
fulladder circuit, while the same neural net would take significantly more
<br>
resources and be less time efficeient.
<br>
But we're not talking fulladders here.
<br>
I assume (wrong perhaps) that the only thing capable of emulating a humanoid
<br>
intellect is an emulation of the micro construct that makes up the macro,
<br>
the whole, the brain.(I have a hard time seeing anyone beating the universal
<br>
approximation engine called nature through darwinistic natural selection!)
<br>
But I agree, specialized hardware could easily speed this up by a factor of
<br>
10 or even more. (See how GPU's have been (mis)used for calculations not
<br>
related to graphics). But even so, that moves me from 10^8 to 10^7
<br>
<p>Richard -&gt; You state it's a dumb way, as a fact. Is it indeed a fact?
<br>
We'd have to have a complete clinical envoirment in wich we have complete
<br>
control and measuring capabilites on the IO of such a column, to dertermine
<br>
whether it indeed obeys simple deterministic boolean logic or not. If such
<br>
experiment has not been done, or even not attainable, then i'd say its a
<br>
pretty bold move to assume that i can emulate a cortical column with a few
<br>
lines of code..(for example)  ;)
<br>
<p>- The humble student picking your brains ;)
<br>
<p><p>On 1/12/06, Richard Loosemore &lt;<a href="mailto:rpwl@lightlink.com?Subject=Re:%20neural%20nets">rpwl@lightlink.com</a>&gt; wrote:
<br>
<em>&gt;
</em><br>
<em>&gt; You must be kidding.
</em><br>
<em>&gt;
</em><br>
<em>&gt; As far as Blue Brain is concerned, don't hold your breath.
</em><br>
<em>&gt;
</em><br>
<em>&gt; This is more like Big Fat White Elephant Designed To Suck Federal
</em><br>
<em>&gt; Dollars Into IBM.
</em><br>
<em>&gt;
</em><br>
<em>&gt; There is no point simulating something whose functional structure you
</em><br>
<em>&gt; don't have a clue about.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Mark my words:  the net result of the Blue Brain project will be just as
</em><br>
<em>&gt; world-shaking as Japan's Fifth Generation Project.  Remember that?  Ten
</em><br>
<em>&gt; year superproject to build a complete human-level artificial
</em><br>
<em>&gt; intelligence?  Net result:  nowt.
</em><br>
<em>&gt;
</em><br>
<em>&gt; Richard Loosemore
</em><br>
<em>&gt;
</em><br>
<em>&gt;
</em><br>
<em>&gt; H C wrote:
</em><br>
<em>&gt; &gt; Not to get into any actual math (too often grossly flawed by factors not
</em><br>
<em>&gt; &gt; taken into consideration), projects like Blue Brain
</em><br>
<em>&gt; &gt; (<a href="http://bluebrainproject.epfl.ch/">http://bluebrainproject.epfl.ch/</a>) are probably the most important to
</em><br>
<em>&gt; &gt; take into account when discussing neural network AI implementations.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; &quot;Scientists have been accummulating knowledge on the structure and
</em><br>
<em>&gt; &gt; function of the brain for the past 100 years. It is now time to start
</em><br>
<em>&gt; &gt; gathering this data together in a unified model and putting it to the
</em><br>
<em>&gt; &gt; test in simulations. We still need to learn a lot about the brain before
</em><br>
<em>&gt; &gt; we understand it's inner workings, but building this model should help
</em><br>
<em>&gt; &gt; organize and accelerate** this quest.&quot; Henry Markram
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; This institute has BIG funding, and really 'effing big computers (which
</em><br>
<em>&gt; &gt; are only going to get bigger). I'm not an expert, but in terms of the
</em><br>
<em>&gt; &gt; neural modeling approach to AI, it appears they are at the top of the
</em><br>
<em>&gt; &gt; game, and they are certainly raising the stakes immensely.
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt; -hegem0n
</em><br>
<em>&gt; &gt; <a href="http://smarterhippie.blogspot.com">http://smarterhippie.blogspot.com</a>
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;&gt; From: CyTG &lt;<a href="mailto:cytg.net@gmail.com?Subject=Re:%20neural%20nets">cytg.net@gmail.com</a>&gt;
</em><br>
<em>&gt; &gt;&gt; Reply-To: <a href="mailto:sl4@sl4.org?Subject=Re:%20neural%20nets">sl4@sl4.org</a>
</em><br>
<em>&gt; &gt;&gt; To: <a href="mailto:sl4@sl4.org?Subject=Re:%20neural%20nets">sl4@sl4.org</a>
</em><br>
<em>&gt; &gt;&gt; Subject: neural nets
</em><br>
<em>&gt; &gt;&gt; Date: Thu, 12 Jan 2006 15:01:26 +0100
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt; SL4
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt; Hello.
</em><br>
<em>&gt; &gt;&gt; Im trying to wrap my head around this AI thing, and entirely how far
</em><br>
<em>&gt; &gt;&gt; along
</em><br>
<em>&gt; &gt;&gt; we are in measures of computational power compared to whats going on
</em><br>
<em>&gt; &gt;&gt; in the
</em><br>
<em>&gt; &gt;&gt; human body.
</em><br>
<em>&gt; &gt;&gt; I know many believes that there's shortcuts to be made, even
</em><br>
<em>&gt; &gt;&gt; improvements of
</em><br>
<em>&gt; &gt;&gt; that model nature has provided us with, the biological neural network.
</em><br>
<em>&gt; &gt;&gt; Still. Humor me.
</em><br>
<em>&gt; &gt;&gt; Here's my approximated assumptions, based on practical experience with
</em><br>
<em>&gt; &gt;&gt; ann's
</em><br>
<em>&gt; &gt;&gt; and some wiki.
</em><br>
<em>&gt; &gt;&gt; Computational power of the human mind ;
</em><br>
<em>&gt; &gt;&gt; 100*10^9 neurons, 1000 connections each gives about 100*10^12
</em><br>
<em>&gt; &gt;&gt; operations _at
</em><br>
<em>&gt; &gt;&gt; the same time_ .. now on average a neuron fires about 80 times each
</em><br>
<em>&gt; &gt;&gt; second,
</em><br>
<em>&gt; &gt;&gt; that gives us a whopping ~10^14 operations/computations each second.
</em><br>
<em>&gt; &gt;&gt; On my machine, a 3GHz workstation, im able to run a feedforward
</em><br>
<em>&gt; &gt;&gt; network at
</em><br>
<em>&gt; &gt;&gt; about 150.000 operations /second WITH training(backprop) .. take
</em><br>
<em>&gt; training
</em><br>
<em>&gt; &gt;&gt; out of the equation and we may, lets shoot high, land on 1 million
</em><br>
<em>&gt; &gt;&gt; 'touched'
</em><br>
<em>&gt; &gt;&gt; neurons/second .. now from 10^6 -&gt; 10^14 .. that's one hell of a big
</em><br>
<em>&gt; &gt;&gt; number!!
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt; Also .. thinking about training over several training sets (as is
</em><br>
<em>&gt; &gt;&gt; usual the
</em><br>
<em>&gt; &gt;&gt; case) wouldn't I be correct at making an analogy to linear algebra ?
</em><br>
<em>&gt; &gt;&gt; thinking of each training set as a vector, each set having their own
</em><br>
<em>&gt; &gt;&gt; direction. In essense, two identical training sets would be linear
</em><br>
<em>&gt; &gt;&gt; 'depended' on each other and subject for elimination? (thinking there
</em><br>
<em>&gt; &gt;&gt; could
</em><br>
<em>&gt; &gt;&gt; be an mathematical sound approach here towards eliminating
</em><br>
<em>&gt; semi-redundant
</em><br>
<em>&gt; &gt;&gt; training data!)
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt; Hope its not too far off topic!
</em><br>
<em>&gt; &gt;&gt;
</em><br>
<em>&gt; &gt;&gt; Best regards
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt; &gt;
</em><br>
<em>&gt;
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13773.html">Rick Geniale: "Re: Some considerations about AGI"</a>
<li><strong>Previous message:</strong> <a href="13771.html">BillK: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<li><strong>In reply to:</strong> <a href="13505.html">Richard Loosemore: "Re: neural nets"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13774.html">Richard Loosemore: "Re: neural nets"</a>
<li><strong>Reply:</strong> <a href="13774.html">Richard Loosemore: "Re: neural nets"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13772">[ date ]</a>
<a href="index.html#13772">[ thread ]</a>
<a href="subject.html#13772">[ subject ]</a>
<a href="author.html#13772">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:55 MDT
</em></small></p>
</body>
</html>
