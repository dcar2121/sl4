<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: physical pain is bad (was Re: Dynamic ethics)</title>
<meta name="Author" content="Jeff Medina (analyticphilosophy@gmail.com)">
<meta name="Subject" content="Re: physical pain is bad (was Re: Dynamic ethics)">
<meta name="Date" content="2006-01-23">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: physical pain is bad (was Re: Dynamic ethics)</h1>
<!-- received="Mon Jan 23 15:51:23 2006" -->
<!-- isoreceived="20060123225123" -->
<!-- sent="Mon, 23 Jan 2006 17:51:21 -0500" -->
<!-- isosent="20060123225121" -->
<!-- name="Jeff Medina" -->
<!-- email="analyticphilosophy@gmail.com" -->
<!-- subject="Re: physical pain is bad (was Re: Dynamic ethics)" -->
<!-- id="5844e22f0601231451m54fb398tf66dc484746f57b8@mail.gmail.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="6fdad3790601231337q338f2e12k3302d3a70c120d64@mail.gmail.com" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Jeff Medina (<a href="mailto:analyticphilosophy@gmail.com?Subject=Re:%20physical%20pain%20is%20bad%20(was%20Re:%20Dynamic%20ethics)"><em>analyticphilosophy@gmail.com</em></a>)<br>
<strong>Date:</strong> Mon Jan 23 2006 - 15:51:21 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13761.html">Eliezer S. Yudkowsky: "Re: Some considerations about AGI"</a>
<li><strong>Previous message:</strong> <a href="13759.html">Jeff Medina: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<li><strong>In reply to:</strong> <a href="13758.html">Philip Goetz: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13765.html">Russell Wallace: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<li><strong>Reply:</strong> <a href="13765.html">Russell Wallace: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<li><strong>Reply:</strong> <a href="13766.html">Daniel Radetsky: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<li><strong>Reply:</strong> <a href="13771.html">BillK: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<li><strong>Reply:</strong> <a href="13776.html">Philip Goetz: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13760">[ date ]</a>
<a href="index.html#13760">[ thread ]</a>
<a href="subject.html#13760">[ subject ]</a>
<a href="author.html#13760">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
On 1/23/06, Philip Goetz &lt;<a href="mailto:philgoetz@gmail.com?Subject=Re:%20physical%20pain%20is%20bad%20(was%20Re:%20Dynamic%20ethics)">philgoetz@gmail.com</a>&gt; wrote:
<br>
<em>&gt; is that THE LION STANDS IN RELATIONSHIP TO US IN THE SAME
</em><br>
<em>&gt; WAY THAT WE STAND IN RELATION TO AN AI.  You say we have
</em><br>
<em>&gt; the moral authority to put the lion in a fake simulation without asking
</em><br>
<em>&gt; or telling it.  Hence the AI has the moral authority to put us in the
</em><br>
<em>&gt; Matrix, or dispose of us in any way it sees fit.
</em><br>
<p>I'll probably draw a lot of fire for this, but here goes...
<br>
<p>I've yet to see a decent argument for why this would be a bad thing.
<br>
I've seen a whole lot of responses along the lines of &quot;I get to choose
<br>
for myself what I want to do!&quot; and &quot;We must respect the wishes of
<br>
autonomous, intelligent, rational adult humans!&quot;, and both of these
<br>
fail.
<br>
<p>The first reply is effectively the same argument a puppy gives when
<br>
you take it to the vet, or a child gives when you make it eat its
<br>
vegetables. And we near-universally agree that it doesn't matter that
<br>
the puppy or the child or the
<br>
other-less-intelligent-less-rational-sentient-being thinks it wants;
<br>
we know better (most of the time), and we impose our will for the good
<br>
of the &quot;lesser&quot; being.
<br>
<p>The second reply is a variation on the first, but requires more
<br>
comment. Specifically, it holds up the *current* level of autonomy,
<br>
intelligence, or rationality most humans exhibit as sacrosanct, an
<br>
in-practice binary distinction between our level and that of &quot;lesser&quot;
<br>
beings. But one of the key realizations leading to transhumanism is
<br>
that there is nothing special or sacred about humans-as-they-are-now
<br>
in and of itself. To claim the current level of rationality found in
<br>
humans is the delineator for when we or any other higher beings should
<br>
respect another being's choices/autonomy is to place yourself squarely
<br>
in the Fukuyama/Kass camp of error.
<br>
<p>One of the main problems I personally have with being forced to live
<br>
this or that way or do thus-and-such or undergo certain medical
<br>
procedures is that I can't be sure the higher being has my best
<br>
interests in mind. But neither can puppies and neither can children,
<br>
and that fact doesn't stop us from forcing our decisions on puppies &amp;
<br>
children, so why should our petulant protests stop posthumans from
<br>
doing the same to us? &quot;Waaah, I wanna do what *I* want, dad!&quot; is not
<br>
an acceptable response.
<br>
<p><em>&gt; This is not a recipe for a good singularity.  UNLESS WE PROVIDE
</em><br>
<em>&gt; A NEW ETHICAL FRAMEWORK PRE-SINGULARITY, humans
</em><br>
<em>&gt; will assume that transhumans will operate in just the way Huggins
</em><br>
<em>&gt; is proposing, and they will (justifiably) either prevent anyone from
</em><br>
<em>&gt; developing transhuman technology (which is EXACTLY what Leon
</em><br>
<em>&gt; Kass is doing now, for roughly the same reason that I just gave!),
</em><br>
<em>&gt; or they will KILL TRANSHUMANS ON SIGHT.
</em><br>
<p>They might try. Dogs try to bite humans giving them life-saving
<br>
medicines sometimes, too. That some humans objecting to their
<br>
'parents' telling them what to do poses a problem, let alone the major
<br>
one you suggest, is no more to be assumed than noting that dogs object
<br>
to our help at times.
<br>
<p>If you have a way out of this, please let me know, because I can't see
<br>
it. But I go where the rational justification leads, so just noting
<br>
that the rational conclusion makes us (or even 85% of the population)
<br>
uneasy or unhappy doesn't change the fact that it's the right answer.
<br>
This &quot;new ethics&quot; you seek that would solve everyone's problems
<br>
simultaneously no matter what view of ethics or the future or autonomy
<br>
(etc.) they hold sure would be nice. But that doesn't mean it exists
<br>
or is constructable.
<br>
<p><pre>
--
Jeff Medina
<a href="http://www.painfullyclear.com/">http://www.painfullyclear.com/</a>
Community Director
Singularity Institute for Artificial Intelligence
<a href="http://www.intelligence.org/">http://www.intelligence.org/</a>
Relationships &amp; Community Fellow
Institute for Ethics &amp; Emerging Technologies
<a href="http://www.ieet.org/">http://www.ieet.org/</a>
School of Philosophy, Birkbeck, University of London
<a href="http://www.bbk.ac.uk/phil/">http://www.bbk.ac.uk/phil/</a>
</pre>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13761.html">Eliezer S. Yudkowsky: "Re: Some considerations about AGI"</a>
<li><strong>Previous message:</strong> <a href="13759.html">Jeff Medina: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<li><strong>In reply to:</strong> <a href="13758.html">Philip Goetz: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13765.html">Russell Wallace: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<li><strong>Reply:</strong> <a href="13765.html">Russell Wallace: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<li><strong>Reply:</strong> <a href="13766.html">Daniel Radetsky: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<li><strong>Reply:</strong> <a href="13771.html">BillK: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<li><strong>Reply:</strong> <a href="13776.html">Philip Goetz: "Re: physical pain is bad (was Re: Dynamic ethics)"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13760">[ date ]</a>
<a href="index.html#13760">[ thread ]</a>
<a href="subject.html#13760">[ subject ]</a>
<a href="author.html#13760">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:55 MDT
</em></small></p>
</body>
</html>
