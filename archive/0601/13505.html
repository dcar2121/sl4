<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
                      "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta name="generator" content="hypermail 2.1.5, see http://www.hypermail.org/">
<title>SL4: Re: neural nets</title>
<meta name="Author" content="Richard Loosemore (rpwl@lightlink.com)">
<meta name="Subject" content="Re: neural nets">
<meta name="Date" content="2006-01-12">
<style type="text/css">
body {color: black; background: #ffffff}
h1.center {text-align: center}
div.center {text-align: center}
</style>
</head>
<body>
<h1>Re: neural nets</h1>
<!-- received="Thu Jan 12 13:41:49 2006" -->
<!-- isoreceived="20060112204149" -->
<!-- sent="Thu, 12 Jan 2006 15:39:44 -0500" -->
<!-- isosent="20060112203944" -->
<!-- name="Richard Loosemore" -->
<!-- email="rpwl@lightlink.com" -->
<!-- subject="Re: neural nets" -->
<!-- id="43C6BE90.6070709@lightlink.com" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="BAY101-F253ED5A7D21816D6939D4CDC270@phx.gbl" -->
<!-- expires="-1" -->
<p>
<strong>From:</strong> Richard Loosemore (<a href="mailto:rpwl@lightlink.com?Subject=Re:%20neural%20nets"><em>rpwl@lightlink.com</em></a>)<br>
<strong>Date:</strong> Thu Jan 12 2006 - 13:39:44 MST
</p>
<!-- next="start" -->
<ul>
<li><strong>Next message:</strong> <a href="13506.html">Phil Goetz: "Re: Everything I know is wrong"</a>
<li><strong>Previous message:</strong> <a href="13504.html">Phil Goetz: "Re: Knee-jerk posting and high traffic topics"</a>
<li><strong>In reply to:</strong> <a href="13501.html">H C: "RE: neural nets"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13772.html">CyTG: "Re: neural nets"</a>
<li><strong>Reply:</strong> <a href="13772.html">CyTG: "Re: neural nets"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13505">[ date ]</a>
<a href="index.html#13505">[ thread ]</a>
<a href="subject.html#13505">[ subject ]</a>
<a href="author.html#13505">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<hr>
<!-- body="start" -->
<p>
You must be kidding.
<br>
<p>As far as Blue Brain is concerned, don't hold your breath.
<br>
<p>This is more like Big Fat White Elephant Designed To Suck Federal 
<br>
Dollars Into IBM.
<br>
<p>There is no point simulating something whose functional structure you 
<br>
don't have a clue about.
<br>
<p>Mark my words:  the net result of the Blue Brain project will be just as 
<br>
world-shaking as Japan's Fifth Generation Project.  Remember that?  Ten 
<br>
year superproject to build a complete human-level artificial 
<br>
intelligence?  Net result:  nowt.
<br>
<p>Richard Loosemore
<br>
<p><p>H C wrote:
<br>
<em>&gt; Not to get into any actual math (too often grossly flawed by factors not 
</em><br>
<em>&gt; taken into consideration), projects like Blue Brain 
</em><br>
<em>&gt; (<a href="http://bluebrainproject.epfl.ch/">http://bluebrainproject.epfl.ch/</a>) are probably the most important to 
</em><br>
<em>&gt; take into account when discussing neural network AI implementations.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; &quot;Scientists have been accummulating knowledge on the structure and 
</em><br>
<em>&gt; function of the brain for the past 100 years. It is now time to start 
</em><br>
<em>&gt; gathering this data together in a unified model and putting it to the 
</em><br>
<em>&gt; test in simulations. We still need to learn a lot about the brain before 
</em><br>
<em>&gt; we understand it's inner workings, but building this model should help 
</em><br>
<em>&gt; organize and accelerate** this quest.&quot; Henry Markram
</em><br>
<em>&gt; 
</em><br>
<em>&gt; This institute has BIG funding, and really 'effing big computers (which 
</em><br>
<em>&gt; are only going to get bigger). I'm not an expert, but in terms of the 
</em><br>
<em>&gt; neural modeling approach to AI, it appears they are at the top of the 
</em><br>
<em>&gt; game, and they are certainly raising the stakes immensely.
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; -hegem0n
</em><br>
<em>&gt; <a href="http://smarterhippie.blogspot.com">http://smarterhippie.blogspot.com</a>
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt;&gt; From: CyTG &lt;<a href="mailto:cytg.net@gmail.com?Subject=Re:%20neural%20nets">cytg.net@gmail.com</a>&gt;
</em><br>
<em>&gt;&gt; Reply-To: <a href="mailto:sl4@sl4.org?Subject=Re:%20neural%20nets">sl4@sl4.org</a>
</em><br>
<em>&gt;&gt; To: <a href="mailto:sl4@sl4.org?Subject=Re:%20neural%20nets">sl4@sl4.org</a>
</em><br>
<em>&gt;&gt; Subject: neural nets
</em><br>
<em>&gt;&gt; Date: Thu, 12 Jan 2006 15:01:26 +0100
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; SL4
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Hello.
</em><br>
<em>&gt;&gt; Im trying to wrap my head around this AI thing, and entirely how far 
</em><br>
<em>&gt;&gt; along
</em><br>
<em>&gt;&gt; we are in measures of computational power compared to whats going on 
</em><br>
<em>&gt;&gt; in the
</em><br>
<em>&gt;&gt; human body.
</em><br>
<em>&gt;&gt; I know many believes that there's shortcuts to be made, even 
</em><br>
<em>&gt;&gt; improvements of
</em><br>
<em>&gt;&gt; that model nature has provided us with, the biological neural network.
</em><br>
<em>&gt;&gt; Still. Humor me.
</em><br>
<em>&gt;&gt; Here's my approximated assumptions, based on practical experience with 
</em><br>
<em>&gt;&gt; ann's
</em><br>
<em>&gt;&gt; and some wiki.
</em><br>
<em>&gt;&gt; Computational power of the human mind ;
</em><br>
<em>&gt;&gt; 100*10^9 neurons, 1000 connections each gives about 100*10^12 
</em><br>
<em>&gt;&gt; operations _at
</em><br>
<em>&gt;&gt; the same time_ .. now on average a neuron fires about 80 times each 
</em><br>
<em>&gt;&gt; second,
</em><br>
<em>&gt;&gt; that gives us a whopping ~10^14 operations/computations each second.
</em><br>
<em>&gt;&gt; On my machine, a 3GHz workstation, im able to run a feedforward 
</em><br>
<em>&gt;&gt; network at
</em><br>
<em>&gt;&gt; about 150.000 operations /second WITH training(backprop) .. take training
</em><br>
<em>&gt;&gt; out of the equation and we may, lets shoot high, land on 1 million 
</em><br>
<em>&gt;&gt; 'touched'
</em><br>
<em>&gt;&gt; neurons/second .. now from 10^6 -&gt; 10^14 .. that's one hell of a big
</em><br>
<em>&gt;&gt; number!!
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Also .. thinking about training over several training sets (as is 
</em><br>
<em>&gt;&gt; usual the
</em><br>
<em>&gt;&gt; case) wouldn't I be correct at making an analogy to linear algebra ?
</em><br>
<em>&gt;&gt; thinking of each training set as a vector, each set having their own
</em><br>
<em>&gt;&gt; direction. In essense, two identical training sets would be linear
</em><br>
<em>&gt;&gt; 'depended' on each other and subject for elimination? (thinking there 
</em><br>
<em>&gt;&gt; could
</em><br>
<em>&gt;&gt; be an mathematical sound approach here towards eliminating semi-redundant
</em><br>
<em>&gt;&gt; training data!)
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Hope its not too far off topic!
</em><br>
<em>&gt;&gt;
</em><br>
<em>&gt;&gt; Best regards
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<em>&gt; 
</em><br>
<!-- body="end" -->
<hr>
<ul>
<!-- next="start" -->
<li><strong>Next message:</strong> <a href="13506.html">Phil Goetz: "Re: Everything I know is wrong"</a>
<li><strong>Previous message:</strong> <a href="13504.html">Phil Goetz: "Re: Knee-jerk posting and high traffic topics"</a>
<li><strong>In reply to:</strong> <a href="13501.html">H C: "RE: neural nets"</a>
<!-- nextthread="start" -->
<li><strong>Next in thread:</strong> <a href="13772.html">CyTG: "Re: neural nets"</a>
<li><strong>Reply:</strong> <a href="13772.html">CyTG: "Re: neural nets"</a>
<!-- reply="end" -->
<li><strong>Messages sorted by:</strong> 
<a href="date.html#13505">[ date ]</a>
<a href="index.html#13505">[ thread ]</a>
<a href="subject.html#13505">[ subject ]</a>
<a href="author.html#13505">[ author ]</a>
<a href="attachment.html">[ attachment ]</a>
</ul>
<!-- trailer="footer" -->
<hr>
<p><small><em>
This archive was generated by <a href="http://www.hypermail.org/">hypermail 2.1.5</a> 
: Wed Jul 17 2013 - 04:00:55 MDT
</em></small></p>
</body>
</html>
